{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "import cv2, os, math, time\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle\n",
    "from numpy.lib.stride_tricks import as_strided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configuration\n",
    "\"\"\"\n",
    "Data Configurations/Paths\n",
    "\"\"\"\n",
    "img_dir=\"../../original_images/SD\"\n",
    "img_lbls=\"\"\n",
    "base_model = 'SD/sd_01_.ckpt'\n",
    "model_20000 = 'SD/sd_20000.ckpt'\n",
    "model_30000 = 'SD/sd_30000.ckpt'\n",
    "model_40000 = 'SD/sd_40000.ckpt'\n",
    "model_50000 = 'SD/sd_50000.ckpt'\n",
    "model2_50000 = 'SD/sd2_50000.ckpt'\n",
    "\n",
    "connected_model = 'SD/sd_conected.ckpt'\n",
    "\n",
    "##\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 4          # Convolution filters are 4 x 4 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters2 = 32         # There are 32 of these filters.\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters3 = 64         # There are 64 of these filters.\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size4 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters4 = 128         # There are 128 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 2000             # Number of neurons in fully-connected layer.\n",
    "\n",
    "# We know that images are 60 pixels in each dimension.\n",
    "# img_size = 8 * 4\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 10 * 10\n",
    "\n",
    "# Number of colour channels for the images: 3 channel for RGB.\n",
    "num_channels = 1\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (10, 10, num_channels)\n",
    "\n",
    "# Number of classes, one class for same or different image\n",
    "num_classes = 4*2\n",
    "patch_size = (2, 2)\n",
    "npatches = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_dir):\n",
    "        list_of_imgs = []\n",
    "        list_of_labels = []\n",
    "        list_same_diff = []\n",
    "        list_img_keys = []\n",
    "        for img in os.listdir(img_dir):\n",
    "            \n",
    "            img_path = os.path.join(img_dir, img)\n",
    "            list_same_diff.append(int(os.listdir(img_path)[0]))\n",
    "            list_img_keys.append(img)\n",
    "            img_path = img_path + \"/\" + os.listdir(img_path)[0]\n",
    "            for img_label in os.listdir(img_path):\n",
    "                img_data = os.path.join(img_path, img_label)\n",
    "                if img_label == \"img\":\n",
    "#                     print(img_data + \"/img.png\")\n",
    "                    list_of_imgs.append(img_data + \"/predicted_mask.png\")\n",
    "                else:\n",
    "                    list_of_labels.append([os.path.join(img_data, label) for label in os.listdir(img_data)])\n",
    "\n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_labels = np.array(list_of_labels)\n",
    "        data_same_diff = np.array(list_same_diff)\n",
    "        data_img_keys = np.array(list_img_keys)\n",
    "\n",
    "        return data_imgs, data_labels, data_same_diff, data_img_keys\n",
    "\n",
    "    \n",
    "def get_batch_images(data, label, same_diff, img_keys, rshp, grey_scale):\n",
    "        list_of_imgs = []\n",
    "        list_of_labels = []\n",
    "        list_of_same_diff = []\n",
    "        list_of_img_keys = []\n",
    "        for img, lbl, img_type, img_key in zip(data, label, same_diff, img_keys):\n",
    "            orig_img = cv2.imread(img)\n",
    "            orig_lbl = cv2.imread(lbl)\n",
    "            if orig_img is None or orig_lbl is None:\n",
    "                    print (\"Unable to read image{} or {}\".format(img, lbl))\n",
    "                    continue\n",
    "            \n",
    "            if (grey_scale):\n",
    "                orig_lbl = rgb2grey(orig_lbl)\n",
    "\n",
    "            flattened_img = orig_img.flatten()\n",
    "            flattened_lbl = orig_lbl.flatten()\n",
    "\n",
    "            list_of_imgs.append(np.asarray(flattened_img, dtype=np.float32))\n",
    "            list_of_labels.append(np.asarray(flattened_lbl, dtype=np.float32))\n",
    "            list_of_same_diff.append(img_type)\n",
    "            list_of_img_keys.append(img_key)\n",
    "\n",
    "        data_labels = np.array(list_of_labels)\n",
    "#         print(data_labels.shape)\n",
    "#         print(rshp)\n",
    "        reshaped_labels = np.reshape(data_labels, rshp)\n",
    "        data_labels = np.squeeze(reshaped_labels[:, :, :1])\n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_img_type = np.array(list_of_same_diff)\n",
    "        data_img_keys = np.array(list_of_img_keys)\n",
    "        \n",
    "        return data_imgs, data_labels, data_img_type, data_img_keys\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "def rgb2grey(rgb):\n",
    "    return(np.dot(rgb[...,:3], [0.299, 0.587, 0.114]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape, layer_name):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape), name=layer_name+'_W')\n",
    "\n",
    "def new_bias(length, layer_name):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]), name=layer_name+'_b')\n",
    "\n",
    "def new_conv_layer(input,\n",
    "                   num_input_channels,\n",
    "                   filter_size,\n",
    "                   num_filters,\n",
    "                   name_scope,\n",
    "                   layer_name='',\n",
    "                   use_pooling=True):\n",
    "\n",
    "    with tf.name_scope(name_scope):\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "        weights = new_weights(shape, layer_name)\n",
    "        biases = new_bias(num_filters, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.nn.conv2d(input=input, filter=weights, strides=[1,1,1,1], padding='SAME'), biases, name=layer_name)\n",
    "\n",
    "        if use_pooling:\n",
    "            layer = tf.nn.max_pool(value=layer,\n",
    "                                   ksize=[1, 3, 3, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME', name=layer_name+'_max')\n",
    "        layer = tf.nn.relu(layer, name=layer_name+'_activation')\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                name_scope,\n",
    "                layer_name='',\n",
    "                use_relu=True):\n",
    "    \n",
    "    with tf.name_scope(name_scope):\n",
    "        weights = new_weights([num_inputs, num_outputs], layer_name)\n",
    "        biases = new_bias(num_outputs, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.matmul(input, weights),biases,name=layer_name)\n",
    "    #     layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer, layer_name+'_activation')\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def normalise(tensor):\n",
    "    return tf.div(\n",
    "   tf.subtract(\n",
    "      tensor, \n",
    "      tf.reduce_min(tensor)\n",
    "   ), \n",
    "   tf.subtract(\n",
    "      tf.reduce_max(tensor), \n",
    "      tf.reduce_min(tensor)\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat*num_channels], name='x')\n",
    "x_image = tf.reshape(x, [-1, 10, 10, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "# y_true_cls = tf.argmax(y_true, axis=1)\n",
    "y_true_cls = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true_cls')\n",
    "x_image.shape, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train_labels = train_labels[:][:, 0]\n",
    "total_imgs = len(train_data)\n",
    "train_batch_size = 64\n",
    "\n",
    "def optimize(num_epochs, save_model=True,save_name= \"base_model\",restore_model=False,restore_name=None):\n",
    "    total_iterations = 0\n",
    "    done_train_imgs = 0\n",
    "    start_time = time.time()\n",
    "    start_ = 0\n",
    "    end_ = train_batch_size    \n",
    "    plot_accuracy=[]\n",
    "    plot_accuracy_epoch=[]\n",
    "    plot_training_size=[]\n",
    "    plot_training_size_epoch=[]\n",
    "    saver = tf.train.Saver()\n",
    "    sum_accuracy = 0.0\n",
    "    n = 1\n",
    "    \n",
    "        #to save the model\n",
    "    for i in range(0, num_epochs):   \n",
    "        start_batch=0\n",
    "        end_batch = train_batch_size\n",
    "        \n",
    "        print(\"Epoch:\", i + 1)\n",
    "        \n",
    "        if restore_model==True:\n",
    "            if restore_name==None:\n",
    "                print(\"No model file specified\")\n",
    "                return\n",
    "            else:\n",
    "                saver.restore(session,restore_name)\n",
    "        \n",
    "        sum_accuracy = 0.0\n",
    "        n = 1\n",
    "        while end_batch < total_imgs:\n",
    "            train = train_data[start_batch:end_batch]\n",
    "            labels = train_labels[start_batch:end_batch]\n",
    "            img_type_lbl = img_type[start_:end_]\n",
    "            img_key = img_keys[start_:end_]\n",
    "            dims = (len(train), num_classes, 1)\n",
    "            train, labels, img_type_lbl, img_key = get_batch_images(train, labels, img_type_lbl, img_key, dims)\n",
    "            if not len(train) and not len(labels):\n",
    "                print(\"All images have been processed.\")\n",
    "                break;\n",
    "\n",
    "            x_batch, y_true_batch = next_batch(len(train), train, labels)\n",
    "            feed_dict_train = {x: x_batch,\n",
    "                       y_true: y_true_batch}\n",
    "            \n",
    "            session.run(optimizer, feed_dict=feed_dict_train)\n",
    "    \n",
    "            acc,co = session.run([accuracy, cost], feed_dict=feed_dict_train)\n",
    "            sum_accuracy += acc\n",
    "            n+=1\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "            print(msg.format(end_batch + 1, acc, co))\n",
    "            if i == num_epochs - 1:\n",
    "                plot_accuracy.append(acc)\n",
    "                plot_training_size.append(end_batch + 1)\n",
    "\n",
    "            start_batch += train_batch_size\n",
    "            end_batch += train_batch_size\n",
    "    \n",
    "        if save_model==True:\n",
    "            if save_name==None:\n",
    "                print(\"No model specified, model not being saved\")\n",
    "                return\n",
    "            else:\n",
    "                save_path = saver.save(session, save_name)\n",
    "                restore_model = True\n",
    "                print(\"Model saved in file: %s\" % save_name)\n",
    "        plot_accuracy_epoch.append(sum_accuracy/n)\n",
    "        plot_training_size_epoch.append(i + 1)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))  \n",
    "    print(plot_accuracy)\n",
    "    print(plot_training_size)\n",
    "    print(plot_accuracy_epoch)\n",
    "    print(plot_training_size_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "save_name = model2_50000\n",
    "restore_model=False\n",
    "restore_name=model2_50000\n",
    "\n",
    "optimize(50, save_model=True,save_name=model2_50000,restore_model=False,restore_name=model2_50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
