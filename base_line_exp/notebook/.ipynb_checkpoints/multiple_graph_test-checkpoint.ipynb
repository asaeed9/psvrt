{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../original_images/psvrt.py:3: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-fce1b3103be7>\", line 1, in <module>\n",
      "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2131, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-107>\", line 2, in matplotlib\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2, os, math, time, sys\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle\n",
    "sys.path.append('../../original_images')\n",
    "from gen_data_batch import generate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configuration\n",
    "\"\"\"\n",
    "Data Configurations/Paths\n",
    "\"\"\"\n",
    "img_dir_patch=\"./SD/predicted_patches\"\n",
    "img_dir_orig = \"../../original_images/SD\"\n",
    "\n",
    "modelsd_test = 'SD/modelsd_test.ckpt'\n",
    "modelsr_test = 'SD/modelsr_test.ckpt'\n",
    "modelleft = 'SD/modelleft.ckpt'\n",
    "modelright = 'SD/modelright.ckpt'\n",
    "model_mask_sd = 'SD/model_mask_sd.ckpt'\n",
    "\n",
    "# img_type = \"original\"\n",
    "img_type = \"patch\"\n",
    "\n",
    "##\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 4          # Convolution filters are 4 x 4 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters2 = 32         # There are 32 of these filters.\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters3 = 64         # There are 64 of these filters.\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size4 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters4 = 128         # There are 128 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 256             # Number of neurons in fully-connected layer.\n",
    "\n",
    "# Number of colour channels for the images: 3 channel for RGB.\n",
    "num_channels = 3\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (60, 60, num_channels)\n",
    "item_size = (5,5)\n",
    "mask_sd_input = (10,5, num_channels)\n",
    "# Number of classes, one class for same and one for different image\n",
    "num_classes = 2\n",
    "nitems = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "train_data, mask_labels, left_mask, right_mask, labels = generate_batch(train_batch_size, img_shape, item_size, nitems)\n",
    "print(train_data.shape)\n",
    "print(mask_labels.shape)\n",
    "print(left_mask.shape)\n",
    "print(right_mask.shape)\n",
    "see_output(np.reshape(train_data, [64, 60,60,3])[:1, :,:,:])\n",
    "see_output_grey(mask_labels[:1, :,:])\n",
    "see_output_grey(left_mask[:1, :, :])\n",
    "see_output_grey(right_mask[:1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_dir, img_type=\"patch\"):\n",
    "        list_of_imgs = []\n",
    "        list_same_diff = []\n",
    "        for img_no in os.listdir(img_dir):\n",
    "            img_no_path = os.path.join(img_dir, img_no)\n",
    "            for img_label in os.listdir(img_no_path):\n",
    "                    \n",
    "                list_same_diff.append(int(img_label))\n",
    "                img_lbl_path = os.path.join(img_no_path, img_label)\n",
    "#                 print(img_lbl_path)\n",
    "                if img_type == \"original\":\n",
    "                    img_lbl_path = img_lbl_path + \"/img/\"\n",
    "                    \n",
    "                if img_type == \"patch\":\n",
    "                    for img in os.listdir(img_lbl_path):\n",
    "#                         if img == \"labels\":\n",
    "                        img_path = os.path.join(img_lbl_path, img)\n",
    "#                             img_path = img_path + \"/merged_patch.png\"\n",
    "                        list_of_imgs.append(img_path)\n",
    "                else:    \n",
    "                    for img in os.listdir(img_lbl_path):\n",
    "                        img_path = os.path.join(img_lbl_path, img)\n",
    "                        list_of_imgs.append(img_path)\n",
    "#         print(list_of_imgs)\n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_same_diff = np.array(list_same_diff)\n",
    "\n",
    "        return data_imgs, data_same_diff\n",
    "    \n",
    "def get_batch_images(data, same_diff, type_img = \"patch\"):\n",
    "        list_of_imgs = []\n",
    "        list_of_same_diff = []\n",
    "        for img, img_type in zip(data, same_diff):\n",
    "            orig_img = cv2.imread(img)\n",
    "            #only first image as a label\n",
    "            if orig_img is None:\n",
    "                    print (\"Unable to read image{}\".format(img))\n",
    "                    continue\n",
    "            \n",
    "            if type_img == \"original\":\n",
    "                flattened_img = orig_img.flatten()\n",
    "                list_of_imgs.append(np.asarray(flattened_img, dtype=np.float32))\n",
    "                \n",
    "                if img_type == 1: #0 is same and 1 is different\n",
    "                    list_of_same_diff.append([0,1])\n",
    "                else:\n",
    "                    list_of_same_diff.append([1,0])\n",
    "            else:            \n",
    "                if orig_img.shape == (4, 2, 3):\n",
    "                    flattened_img = orig_img.flatten()\n",
    "                    list_of_imgs.append(np.asarray(flattened_img, dtype=np.float32))\n",
    "\n",
    "                    if img_type == 1: #0 is same and 1 is different\n",
    "                        list_of_same_diff.append([0,1])\n",
    "                    else:\n",
    "                        list_of_same_diff.append([1,0])\n",
    "        \n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_img_type = np.array(list_of_same_diff)\n",
    "        \n",
    "        return data_imgs, data_img_type\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "def patch_next_batch(num, data, lft_lbls, rght_lbls, img_tlbl, img_key):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_orig = data[0, :]\n",
    "    data_pred = data[1, :]\n",
    "    data_orig_shuffle = [data[0, i] for i in idx]\n",
    "    data_pred_shuffle = [data[1, i] for i in idx]\n",
    "    lft_labels = [lft_lbls[ i] for i in idx]\n",
    "    rght_labels = [rght_lbls[ i] for i in idx]\n",
    "    img_tlbl = [img_tlbl[ i] for i in idx]\n",
    "    img_key = [img_key[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_orig_shuffle), np.asarray(data_pred_shuffle), np.asarray(lft_labels), np.asarray(rght_labels), np.asarray(img_tlbl), np.asarray(img_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape, layer_name):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape), name=layer_name+'_W')\n",
    "\n",
    "def new_bias(length, layer_name):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]), name=layer_name+'_b')\n",
    "\n",
    "def new_conv_layer(input,\n",
    "                   num_input_channels,\n",
    "                   filter_size,\n",
    "                   num_filters,\n",
    "                   name_scope,\n",
    "                   layer_name='',\n",
    "                   use_pooling=True):\n",
    "\n",
    "    with tf.name_scope(name_scope):\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "        weights = new_weights(shape, layer_name)\n",
    "        biases = new_bias(num_filters, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.nn.conv2d(input=input, filter=weights, strides=[1,1,1,1], padding='SAME'), biases, name=layer_name)\n",
    "\n",
    "        if use_pooling:\n",
    "            layer = tf.nn.max_pool(value=layer,\n",
    "                                   ksize=[1, 3, 3, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME', name=layer_name+'_max')\n",
    "        layer = tf.nn.relu(layer, name=layer_name+'_activation')\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                name_scope,\n",
    "                layer_name='',\n",
    "                use_relu=True):\n",
    "    \n",
    "    with tf.name_scope(name_scope):\n",
    "        weights = new_weights([num_inputs, num_outputs], layer_name)\n",
    "        biases = new_bias(num_outputs, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.matmul(input, weights),biases,name=layer_name)\n",
    "    #     layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer, layer_name+'_activation')\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def normalise(tensor):\n",
    "    return tf.div(\n",
    "   tf.subtract(\n",
    "      tensor, \n",
    "      tf.reduce_min(tensor)\n",
    "   ), \n",
    "   tf.subtract(\n",
    "      tf.reduce_max(tensor), \n",
    "      tf.reduce_min(tensor)\n",
    "   )\n",
    ")\n",
    "\n",
    "def normalized(arr):\n",
    "    return (arr - np.min(arr))/(np.max(arr) - np.min(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_graph layer configurations\n",
    "m_filter_size0 = 16          # Convolution filters are 4 x 4 pixels.\n",
    "m_num_filters0 = 16         # There are 16 of these filters.\n",
    "\n",
    "m_filter_size1 = 8          # Convolution filters are 4 x 4 pixels.\n",
    "m_num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "m_filter_size2 = 8          # Convolution filters are 2 x 2 pixels.\n",
    "m_num_filters2 = 16         # There are 32 of these filters.\n",
    "\n",
    "m_filter_size3 = 8          # Convolution filters are 2 x 2 pixels.\n",
    "m_num_filters3 = 4         # There are 32 of these filters.\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "m_filter_size4 = 4          # Convolution filters are 2 x 2 pixels.\n",
    "m_num_filters4 = 32         # There are 64 of these filters.\n",
    "\n",
    "m_filter_size5 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "m_num_filters5 = 16         # There are 64 of these filters.\n",
    "\n",
    "\n",
    "# Fully-connected layer.\n",
    "m_fc_size = 2000             # Number of neurons in fully-connected layer.\n",
    "\n",
    "mask_graph = tf.Graph()\n",
    "with mask_graph.as_default():\n",
    "    m_x = tf.placeholder(tf.float32, shape=[None, img_shape[0] * img_shape[1] * img_shape[2]], name='m_x')\n",
    "    m_x_image = tf.reshape(m_x, [-1, img_shape[0], img_shape[1], num_channels])\n",
    "    m_y_true = tf.placeholder(tf.float32, shape=[None, img_shape[0] * img_shape[1]], name='m_y_true')\n",
    "    m_y_true_cls = tf.placeholder(tf.float32, shape=[None, img_shape[0] * img_shape[1]], name='m_y_true_cls')    \n",
    "    \n",
    "    layer0_conv0, weights_conv0 = new_conv_layer(input=m_x_image,\n",
    "                                                num_input_channels=num_channels,\n",
    "                                                filter_size=m_filter_size0,\n",
    "                                                num_filters=m_num_filters0,\n",
    "                                                 name_scope = 'mask',\n",
    "                                                 layer_name = 'conv1',\n",
    "                                                use_pooling=True)\n",
    "\n",
    "    layer1_conv1, weights_conv1 = new_conv_layer(input=layer0_conv0,\n",
    "                                                num_input_channels=m_num_filters0,\n",
    "                                                filter_size=m_filter_size1,\n",
    "                                                num_filters=m_num_filters1,\n",
    "                                                 name_scope = 'mask',\n",
    "                                                 layer_name = 'conv2',\n",
    "                                                use_pooling=True)\n",
    "\n",
    "\n",
    "    layer2_conv2, weights_conv2 =  new_conv_layer(input=layer1_conv1,\n",
    "                                               num_input_channels=m_num_filters1,\n",
    "                                               filter_size=m_filter_size2,\n",
    "                                               num_filters=m_num_filters2,\n",
    "                                                 name_scope = 'mask',\n",
    "                                                 layer_name = 'conv3',\n",
    "                                               use_pooling=True)\n",
    "\n",
    "    layer3_conv3, weights_conv3 =  new_conv_layer(input=layer2_conv2,\n",
    "                                               num_input_channels=m_num_filters2,\n",
    "                                               filter_size=m_filter_size3,\n",
    "                                               num_filters=m_num_filters3,\n",
    "                                                 name_scope = 'mask',\n",
    "                                                 layer_name = 'conv4',\n",
    "                                               use_pooling=True)\n",
    "\n",
    "    layer4_conv4, weights_conv4 =  new_conv_layer(input=layer3_conv3,\n",
    "                                               num_input_channels=m_num_filters3,\n",
    "                                               filter_size=m_filter_size4,\n",
    "                                               num_filters=m_num_filters4,\n",
    "                                                 name_scope = 'mask',\n",
    "                                                 layer_name = 'conv5',\n",
    "                                               use_pooling=True)\n",
    "\n",
    "\n",
    "    layer5_conv5, weights_conv5 =  new_conv_layer(input=layer4_conv4,\n",
    "                                               num_input_channels=m_num_filters4,\n",
    "                                               filter_size=m_filter_size5,\n",
    "                                               num_filters=m_num_filters5,\n",
    "                                                 name_scope = 'mask',\n",
    "                                                 layer_name = 'conv6',\n",
    "                                               use_pooling=True)\n",
    "\n",
    "    layer_flat, num_features = flatten_layer(layer5_conv5)\n",
    "\n",
    "    layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                             num_inputs=num_features,\n",
    "                             num_outputs=m_fc_size,\n",
    "                             name_scope = 'mask',\n",
    "                             layer_name = 'fc1',\n",
    "                             use_relu=True)\n",
    "\n",
    "    layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                             num_inputs=m_fc_size,\n",
    "                             num_outputs=m_fc_size,\n",
    "                             name_scope = 'mask',\n",
    "                             layer_name = 'fc2',\n",
    "                             use_relu=False)\n",
    "\n",
    "    layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "                             num_inputs=m_fc_size,\n",
    "                             num_outputs=m_fc_size,\n",
    "                             name_scope = 'mask',\n",
    "                             layer_name = 'fc3',\n",
    "                             use_relu=False)\n",
    "\n",
    "    mask_layer_fc4 = new_fc_layer(input=layer_fc3,\n",
    "                             num_inputs=m_fc_size,\n",
    "                             num_outputs=img_shape[0] * img_shape[1],\n",
    "                             name_scope = 'mask',\n",
    "                             layer_name = 'fc4',\n",
    "                             use_relu=False)\n",
    "\n",
    "    # drop_out = tf.nn.dropout(layer_fc4, 0.5, name=\"drop_out\")\n",
    "#     print(layer_fc4)\n",
    "    # y_pred = tf.nn.softmax(layer_fc4, name=\"softmax_output\")\n",
    "    y_pred = mask_layer_fc4\n",
    "    cost = tf.reduce_mean(tf.square(m_y_true - y_pred))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "    # ## some more performance measures\n",
    "    correct_prediction = tf.equal(y_pred, m_y_true)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_graph = tf.Graph()\n",
    "with sd_graph.as_default():\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, img_shape[0]*img_shape[1]*num_channels], name='x')\n",
    "    x_image = tf.reshape(x, [-1, img_shape[0], img_shape[1], num_channels])\n",
    "    s_y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "    s_y_true_cls = tf.argmax(s_y_true, axis=1)        \n",
    "\n",
    "    layer1_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
    "                                                num_input_channels=num_channels,\n",
    "                                                filter_size=filter_size1,\n",
    "                                                num_filters=num_filters1,\n",
    "                                                 name_scope = 'sd_graph',\n",
    "                                                 layer_name = 'conv1',\n",
    "                                                use_pooling=True)\n",
    "\n",
    "    layer2_conv2, weights_conv2 = new_conv_layer(input=layer1_conv1,\n",
    "                                                num_input_channels=num_filters1,\n",
    "                                                filter_size=filter_size2,\n",
    "                                                num_filters=num_filters2,\n",
    "                                                 name_scope = 'sd_graph',\n",
    "                                                 layer_name = 'conv2',\n",
    "                                                use_pooling=True)\n",
    "\n",
    "\n",
    "    layer3_conv3, weights_conv3 =  new_conv_layer(input=layer2_conv2,\n",
    "                                               num_input_channels=num_filters2,\n",
    "                                               filter_size=filter_size3,\n",
    "                                               num_filters=num_filters3,\n",
    "                                                 name_scope = 'sd_graph',\n",
    "                                                 layer_name = 'conv3',\n",
    "                                               use_pooling=True)\n",
    "\n",
    "    layer4_conv4, weights_conv4 =  new_conv_layer(input=layer3_conv3,\n",
    "                                               num_input_channels=num_filters3,\n",
    "                                               filter_size=filter_size4,\n",
    "                                               num_filters=num_filters4,\n",
    "                                                 name_scope = 'sd_graph',\n",
    "                                                 layer_name = 'conv4',\n",
    "                                               use_pooling=True)\n",
    "\n",
    "    layer_flat, num_features = flatten_layer(layer4_conv4)       \n",
    "\n",
    "    layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                     num_inputs=num_features,\n",
    "                     num_outputs=fc_size,\n",
    "                     name_scope = 'sd_graph',\n",
    "                     layer_name = 'fc1',\n",
    "                     use_relu=True)\n",
    "\n",
    "    layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                             num_inputs=fc_size,\n",
    "                             num_outputs=fc_size,\n",
    "                             name_scope = 'sd_graph',\n",
    "                             layer_name = 'fc2',\n",
    "                             use_relu=False)\n",
    "\n",
    "    layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "                             num_inputs=fc_size,\n",
    "                             num_outputs=fc_size,\n",
    "                             name_scope = 'sd_graph',\n",
    "                             layer_name = 'fc3',\n",
    "                             use_relu=False)\n",
    "\n",
    "    layer_fc4 = new_fc_layer(input=layer_fc3,\n",
    "                             num_inputs=fc_size,\n",
    "                             num_outputs=num_classes,\n",
    "                             name_scope = 'sd_graph',\n",
    "                             layer_name = 'fc4',\n",
    "                             use_relu=False)\n",
    "\n",
    "    s_drop_out = tf.nn.dropout(layer_fc4, 0.5)\n",
    "    s_y_pred = tf.nn.softmax(s_drop_out)\n",
    "    s_y_pred_cls = tf.argmax(s_y_pred, axis=1)        \n",
    "    s_cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=s_drop_out, labels=s_y_true)\n",
    "    s_cost = tf.reduce_mean(s_cross_entropy)\n",
    "    s_optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(s_cost)\n",
    "    s_correct_prediction = tf.equal(s_y_pred_cls, s_y_true_cls)\n",
    "    s_accuracy = tf.reduce_mean(tf.cast(s_correct_prediction, tf.float32))        \n",
    "\n",
    "    #         y_pred = layer_fc4        \n",
    "    #         cost = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    #         optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "    #         # ## some more performance measures\n",
    "    #         correct_prediction = tf.equal(y_pred, y_true)\n",
    "    #         accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_sd_graph = tf.Graph()\n",
    "with mask_sd_graph.as_default():\n",
    "    mask_sd_x = tf.placeholder(tf.float32, shape=[None, mask_sd_input[0]*mask_sd_input[1]*num_channels], name='mask_sd_x')\n",
    "    mask_sd_x_image = tf.reshape(mask_sd_x, [-1, mask_sd_input[0], mask_sd_input[1], num_channels])\n",
    "\n",
    "    mask_sd_y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='mask_sd_y_true')\n",
    "    mask_sd_y_true_cls = tf.argmax(mask_sd_y_true, axis=1)        \n",
    "\n",
    "    layer1_conv1, weights_conv1 = new_conv_layer(input=mask_sd_x_image,\n",
    "                                                num_input_channels=num_channels,\n",
    "                                                filter_size=filter_size1,\n",
    "                                                num_filters=num_filters1,\n",
    "                                                 name_scope = 'mask_sd_graph',\n",
    "                                                 layer_name = 'conv1',\n",
    "                                                use_pooling=True)\n",
    "\n",
    "    layer2_conv2, weights_conv2 = new_conv_layer(input=layer1_conv1,\n",
    "                                                num_input_channels=num_filters1,\n",
    "                                                filter_size=filter_size2,\n",
    "                                                num_filters=num_filters2,\n",
    "                                                 name_scope = 'mask_sd_graph',\n",
    "                                                 layer_name = 'conv2',\n",
    "                                                use_pooling=True)\n",
    "\n",
    "\n",
    "    layer3_conv3, weights_conv3 =  new_conv_layer(input=layer2_conv2,\n",
    "                                               num_input_channels=num_filters2,\n",
    "                                               filter_size=filter_size3,\n",
    "                                               num_filters=num_filters3,\n",
    "                                                 name_scope = 'mask_sd_graph',\n",
    "                                                 layer_name = 'conv3',\n",
    "                                               use_pooling=True)\n",
    "\n",
    "    layer4_conv4, weights_conv4 =  new_conv_layer(input=layer3_conv3,\n",
    "                                               num_input_channels=num_filters3,\n",
    "                                               filter_size=filter_size4,\n",
    "                                               num_filters=num_filters4,\n",
    "                                                 name_scope = 'mask_sd_graph',\n",
    "                                                 layer_name = 'conv4',\n",
    "                                               use_pooling=True)\n",
    "\n",
    "    layer_flat, num_features = flatten_layer(layer4_conv4)       \n",
    "\n",
    "    layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                     num_inputs=num_features,\n",
    "                     num_outputs=fc_size,\n",
    "                     name_scope = 'mask_sd_graph',\n",
    "                     layer_name = 'fc1',\n",
    "                     use_relu=True)\n",
    "\n",
    "    layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                             num_inputs=fc_size,\n",
    "                             num_outputs=fc_size,\n",
    "                             name_scope = 'mask_sd_graph',\n",
    "                             layer_name = 'fc2',\n",
    "                             use_relu=False)\n",
    "\n",
    "    layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "                             num_inputs=fc_size,\n",
    "                             num_outputs=fc_size,\n",
    "                             name_scope = 'mask_sd_graph',\n",
    "                             layer_name = 'fc3',\n",
    "                             use_relu=False)\n",
    "\n",
    "    layer_fc4 = new_fc_layer(input=layer_fc3,\n",
    "                             num_inputs=fc_size,\n",
    "                             num_outputs=num_classes,\n",
    "                             name_scope = 'mask_sd_graph',\n",
    "                             layer_name = 'fc4',\n",
    "                             use_relu=False)\n",
    "\n",
    "    mask_sd_drop_out = tf.nn.dropout(layer_fc4, 0.5)\n",
    "    mask_sd_y_pred = tf.nn.softmax(mask_sd_drop_out)\n",
    "    mask_sd_y_pred_cls = tf.argmax(mask_sd_y_pred, axis=1)        \n",
    "    mask_sd_cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=mask_sd_drop_out, labels=mask_sd_y_true)\n",
    "    mask_sd_cost = tf.reduce_mean(mask_sd_cross_entropy)\n",
    "    mask_sd_optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(mask_sd_cost)\n",
    "    mask_sd_correct_prediction = tf.equal(mask_sd_y_pred_cls, mask_sd_y_true_cls)\n",
    "    mask_sd_accuracy = tf.reduce_mean(tf.cast(mask_sd_correct_prediction, tf.float32))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_subm(a):\n",
    "    n,m=np.shape(a)\n",
    "\n",
    "    #Get Down Value\n",
    "    b = np.delete(a, (0), axis=0)\n",
    "    bz = np.zeros((1,m))\n",
    "    b_full=np.vstack([b, bz])\n",
    "\n",
    "    #Get Right Value\n",
    "    c = np.delete(a,(0), axis=1)\n",
    "    cz = np.zeros((n,1))\n",
    "    c_full=np.hstack((c,cz))\n",
    "\n",
    "    #Get Diagonal Value\n",
    "    d= np.delete(b, (0), axis=1)\n",
    "    dz=np.zeros((1,m-1))\n",
    "    dz2=np.zeros((n,1))\n",
    "    d_v=np.vstack([d, dz])\n",
    "    d_full=np.hstack([d_v, dz2])\n",
    "\n",
    "    #Add All Matrices\n",
    "    sum_2b2=np.add(np.add(np.add(a,b_full),c_full),d_full)\n",
    "\n",
    "    #Get Coordinates \n",
    "    cord = np.where(sum_2b2 == sum_2b2.max())\n",
    "    return np.reshape(np.array([cord[0], cord[1]]), [1,2])\n",
    "\n",
    "def extract_patch(locs, orig_batch):\n",
    "    orig_batch = np.reshape(orig_batch, [-1,img_shape[0],img_shape[1],img_shape[2]])\n",
    "#     print(orig_batch)\n",
    "#     print(locs)\n",
    "#     return np.array([loc for loc in locs])\n",
    "    return np.array([orig_batch[idx:idx+1, loc[0]:loc[0]+item_size[0], loc[1]:loc[1]+item_size[1], :] for idx, loc in enumerate(locs)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mask(save_model, restore_model, restore_name, saver, session, end_batch, train_data, train_label):\n",
    "    feed_dict_train = {m_x: train_data,\n",
    "               m_y_true: train_label}\n",
    "\n",
    "    session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "    pred, acc,co = session.run([mask_layer_fc4, accuracy, cost], feed_dict=feed_dict_train)            \n",
    "    msg = \"Optimization Iteration: {0:>6}, Mask Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "    print(msg.format(end_batch + 1, acc, co))\n",
    "    \n",
    "    #once the training is done, run a test and return the patch\n",
    "    \n",
    "    return pred\n",
    "    \n",
    "\n",
    "def train_mask_sd(save_model, restore_model, restore_name, saver, session, end_batch, train_data, train_label):\n",
    "    feed_dict_train = {mask_sd_x: train_data,\n",
    "               mask_sd_y_true: train_label}\n",
    "\n",
    "    session.run(mask_sd_optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "    acc,co = session.run([mask_sd_accuracy, mask_sd_cost], feed_dict=feed_dict_train)            \n",
    "    msg = \"Optimization Iteration: {0:>6}, Masked SD Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "    print(msg.format(end_batch + 1, acc, co))\n",
    "\n",
    "\n",
    "def train_sd(save_model, restore_model, restore_name, saver, session, end_batch, train_data, train_label):\n",
    "    feed_dict_train = {x: train_data,\n",
    "               s_y_true: train_label}\n",
    "\n",
    "    session.run(s_optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "    acc,co = session.run([s_accuracy, s_cost], feed_dict=feed_dict_train)            \n",
    "    msg = \"Optimization Iteration: {0:>6}, SD/SR Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "    print(msg.format(end_batch + 1, acc, co))\n",
    "                        \n",
    "def restore_see_layer(orig, input_name, model_name=None, var_name=None):\n",
    "    with tf.Session('', tf.Graph()) as s:\n",
    "        with s.graph.as_default():\n",
    "            if ((model_name != None) and var_name != None):\n",
    "                saver = tf.train.import_meta_graph(model_name+\".meta\")\n",
    "                saver.restore(s, model_name)\n",
    "                fd = {input_name +':0': orig}\n",
    "#                 print(fd.shape)\n",
    "                var_name=var_name+\":0\"\n",
    "                \n",
    "                result = 0\n",
    "                result = s.run(var_name, feed_dict=fd)\n",
    "    return result  \n",
    "\n",
    "def restore_see_layer_session(session, orig, input_name, var_name=None):\n",
    "    result = 0\n",
    "    with session.graph.as_default():\n",
    "        fd = {input_name +':0': orig}\n",
    "        var_name=var_name+\":0\"\n",
    "        result = session.run(var_name, feed_dict=fd)\n",
    "            \n",
    "    return result  \n",
    "    \n",
    "def prepare_train_mask_sd(lft_preds, rght_preds, train_data, left_mask, right_mask):   \n",
    "    \n",
    "    print(\"prepare_train_mask_sd\")\n",
    "    \n",
    "    cor_prd_imgs = 0\n",
    "\n",
    "#     lft_preds = restore_see_layer_session(left_sess, orig=train_data, input_name = 'm_x', var_name='mask_9/fc4')\n",
    "#     rght_preds = restore_see_layer_session(right_sess, orig=train_data, input_name = 'm_x', var_name='mask_9/fc4')\n",
    "\n",
    "#     print(lft_preds)\n",
    "#     print(rght_preds)\n",
    "#     print(left_mask)\n",
    "    lft_lbl_cds = get_max_subm(left_mask)\n",
    "    rght_lbl_cds = get_max_subm(right_mask)\n",
    "    lft_pred_cds = get_max_subm(lft_preds)\n",
    "    rght_pred_cds = get_max_subm(rght_preds)\n",
    "    \n",
    "#     print(lft_lbl_cds)\n",
    "#     print(\"******left predicted\")\n",
    "#     print(lft_pred_cds)\n",
    "#     print(\"******\")\n",
    "#     print(rght_lbl_cds)\n",
    "#     print(\"******right predicted\")\n",
    "#     print(rght_pred_cds)    \n",
    "    \n",
    "    left_patch = extract_patch(lft_pred_cds, train_data)\n",
    "    right_patch = extract_patch(rght_pred_cds, train_data)\n",
    "        \n",
    "#     print(left_patch.shape, right_patch.shape)\n",
    "    \n",
    "    cor_prd_imgs = np.sum([True for llc, lpc, rlc, rpc  in zip(lft_lbl_cds, lft_pred_cds, rght_lbl_cds, rght_pred_cds) if np.array_equal(llc, lpc) and np.array_equal(rlc, rpc)])\n",
    "                \n",
    "#         for img0,img_key_x in zip(x_orig_batch, img_key):\n",
    "#             print('key:', img_key_x)\n",
    "#             see_output(np.expand_dims(np.reshape(img0, [10,10,3]), axis=0))\n",
    "#             see_output_grey(np.expand_dims(np.reshape(np.rint(img1), [10,10]), axis=0))\n",
    "#             see_output_grey(np.expand_dims(np.reshape(np.rint(img2), [10,10]), axis=0))\n",
    "        \n",
    "    train_mask_sd_batch = np.array([np.reshape(np.stack([lft,rght], axis=0), [mask_sd_input[0] * mask_sd_input[1] * mask_sd_input[2]]) for lft, rght in zip(left_patch, right_patch)])\n",
    "#         prediction = np.reshape(np.stack([lft,rght], axis=0), [1,mask_sd_input[0],mask_sd_input[1],mask_sd_input[2]])\n",
    "#         print(lft, rght, prediction, prediction.shape)\n",
    "    \n",
    "#     print(train_mask_sd_batch.shape)\n",
    "    \n",
    "    return train_mask_sd_batch\n",
    "    \n",
    "def test_mask(train_batch_size, left_model_name, right_model_name):\n",
    "\n",
    "    cor_prd_imgs = 0\n",
    "    train_data, mask_labels, left_mask, right_mask, labels = generate_batch(train_batch_size, img_shape, item_size, nitems)\n",
    "    if not len(train_data) and not len(labels) and not len(mask_labels):\n",
    "        print(\"All images have been processed.\")\n",
    "#         break;    \n",
    "    \n",
    "    lft_preds = restore_see_layer(orig=train_data, input_name = 'm_x', model_name=left_model_name, var_name='mask_9/fc4')\n",
    "    rght_preds = restore_see_layer(orig=train_data, input_name = 'm_x', model_name=right_model_name, var_name='mask_9/fc4')\n",
    "    \n",
    "#     print(left_mask.shape, right_mask.shape)\n",
    "    lft_lbl_cds = get_coords(left_mask, 1)\n",
    "    rght_lbl_cds = get_coords(right_mask, 1)\n",
    "    lft_pred_cds = get_coords(lft_preds, 1)\n",
    "    rght_pred_cds = get_coords(rght_preds, 1)\n",
    "    \n",
    "#     print(lft_lbl_cds)\n",
    "#     print(\"******left predicted\")\n",
    "#     print(lft_pred_cds)\n",
    "#     print(\"******\")\n",
    "#     print(rght_lbl_cds)\n",
    "#     print(\"******right predicted\")\n",
    "#     print(rght_pred_cds)\n",
    "    \n",
    "    cor_prd_imgs = np.sum([True for llc, lpc, rlc, rpc  in zip(lft_lbl_cds, lft_pred_cds, rght_lbl_cds, rght_pred_cds) if np.array_equal(llc, lpc) and np.array_equal(rlc, rpc)])\n",
    "    \n",
    "#     print('Total Correct:', cor_prd_imgs)\n",
    "    mask_accuracy = cor_prd_imgs/train_batch_size\n",
    "    print('Mask Accuracy:{0:.4f}'.format(mask_accuracy))\n",
    "    \n",
    "    \n",
    "    left_patch = extract_patch(lft_pred_cds, train_data)\n",
    "    right_patch = extract_patch(rght_pred_cds, train_data)\n",
    "        \n",
    "    print(left_patch.shape, right_patch.shape)\n",
    "    \n",
    "    cor_prd_imgs = np.sum([True for llc, lpc, rlc, rpc  in zip(lft_lbl_cds, lft_pred_cds, rght_lbl_cds, rght_pred_cds) if np.array_equal(llc, lpc) and np.array_equal(rlc, rpc)])\n",
    "                \n",
    "#         for img0,img_key_x in zip(x_orig_batch, img_key):\n",
    "#             print('key:', img_key_x)\n",
    "#             see_output(np.expand_dims(np.reshape(img0, [10,10,3]), axis=0))\n",
    "#             see_output_grey(np.expand_dims(np.reshape(np.rint(img1), [10,10]), axis=0))\n",
    "#             see_output_grey(np.expand_dims(np.reshape(np.rint(img2), [10,10]), axis=0))\n",
    "        \n",
    "    train_mask_sd_batch = np.array([np.reshape(np.stack([lft,rght], axis=0), [mask_sd_input[0] * mask_sd_input[1] * mask_sd_input[2]]) for lft, rght in zip(left_patch, right_patch)])\n",
    "#         prediction = np.reshape(np.stack([lft,rght], axis=0), [1,mask_sd_input[0],mask_sd_input[1],mask_sd_input[2]])\n",
    "#         print(lft, rght, prediction, prediction.shape)\n",
    "    \n",
    "    print(train_mask_sd_batch.shape)\n",
    "    \n",
    "    return mask_accuracy, train_mask_sd_batch, labels\n",
    "\n",
    "def test_sd(train_batch_size, model_sd, prob_type):\n",
    "    np.set_printoptions(suppress=True)\n",
    "    cor_prd_imgs = 0\n",
    "    if prob_type == \"SD\":\n",
    "        train_data, mask_labels, left_mask, right_mask, labels = generate_batch(train_batch_size, img_shape, item_size, nitems)\n",
    "    else:\n",
    "        train_data, mask_labels, left_mask, right_mask, labels = generate_batch(train_batch_size, img_shape, item_size, nitems, 'SR')\n",
    "        \n",
    "    if not len(train_data) and not len(labels) and not len(mask_labels):\n",
    "        print(\"All images have been processed.\")\n",
    "#         break;    \n",
    "\n",
    "    mod_preds = restore_see_layer(orig=train_data, input_name = 'x', model_name=model_sd, var_name='Softmax')\n",
    "    \n",
    "    pred_lbls = np.zeros(mod_preds.shape)\n",
    "    pred_lbls[np.arange(mod_preds.shape[0]), np.argmax(mod_preds, axis=1)] = 1\n",
    "\n",
    "    cor_prd_imgs = np.sum([True for llc, lpc  in zip(labels, pred_lbls) if np.array_equal(llc, lpc)])    \n",
    "\n",
    "#     print('Total Correct:', cor_prd_imgs)\n",
    "    accuracy = cor_prd_imgs/train_batch_size\n",
    "    print('Accuracy:{0:.4f}'.format(accuracy))\n",
    "    \n",
    "#     print(mod_preds)\n",
    "#     print(pred_lbls)\n",
    "#     print(labels)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def test_mask_sd(train_batch_size, data, labels, model_mask_sd):\n",
    "    \n",
    "    mod_preds = restore_see_layer(orig=data, input_name = 'mask_sd_x', model_name=model_mask_sd, var_name='Softmax')\n",
    "    \n",
    "    pred_lbls = np.zeros(mod_preds.shape)\n",
    "    pred_lbls[np.arange(mod_preds.shape[0]), np.argmax(mod_preds, axis=1)] = 1\n",
    "\n",
    "    cor_prd_imgs = np.sum([True for llc, lpc  in zip(labels, pred_lbls) if np.array_equal(llc, lpc)])    \n",
    "\n",
    "#     print('Total Correct:', cor_prd_imgs)\n",
    "    accuracy = cor_prd_imgs/train_batch_size\n",
    "    print('Mask SD Test Accuracy:{0:.4f}'.format(accuracy))\n",
    "    \n",
    "#     print(mod_preds)\n",
    "#     print(pred_lbls)\n",
    "#     print(labels)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(num_epochs, save_model=True,save_name= \"base_model\",restore_model=False,restore_name=None):\n",
    "    total_iterations = 0\n",
    "    done_train_imgs = 0\n",
    "    start_time = time.time()\n",
    "    start_batch=0\n",
    "    end_batch = train_batch_size\n",
    "    test_batch_size = 256\n",
    "    plot_accuracy=[]\n",
    "    plot_accuracy_epoch=[]\n",
    "    plot_training_size=[]\n",
    "    plot_training_size_epoch=[]\n",
    "    plot_mask = []\n",
    "    plot_mask_sd = []\n",
    "    plot_sd = []\n",
    "    plot_sr = []\n",
    "    \n",
    "    sum_accuracy = 0.0\n",
    "    n = 1\n",
    "    \n",
    "    with sd_graph.as_default():\n",
    "        sd_saver = tf.train.Saver()\n",
    "        session_sd = tf.Session(graph=sd_graph)         \n",
    "        session_sd.run(tf.global_variables_initializer())\n",
    "        session_sr = tf.Session(graph=sd_graph)         \n",
    "        session_sr.run(tf.global_variables_initializer())\n",
    "        \n",
    "    \n",
    "    with mask_graph.as_default():\n",
    "        mask_saver = tf.train.Saver()\n",
    "        left_mask_saver = tf.train.Saver()\n",
    "        right_mask_saver = tf.train.Saver()\n",
    "    \n",
    "    with mask_graph.as_default():\n",
    "        session_left = tf.Session(graph = mask_graph)\n",
    "        session_right = tf.Session(graph = mask_graph)\n",
    "        session_left.run(tf.global_variables_initializer())\n",
    "        session_right.run(tf.global_variables_initializer())\n",
    "        \n",
    "    with mask_sd_graph.as_default():\n",
    "        mask_sd_saver = tf.train.Saver()\n",
    "        session_mask_sd = tf.Session(graph=mask_sd_graph)         \n",
    "        session_mask_sd.run(tf.global_variables_initializer())\n",
    "        \n",
    "\n",
    "            #to save the model\n",
    "        for i in range(0, num_epochs):   \n",
    "            start_batch=0\n",
    "            end_batch = train_batch_size\n",
    "\n",
    "            print(\"Epoch:\", i + 1)\n",
    "\n",
    "            if restore_model==True:\n",
    "                mask_saver.restore(session_left,modelleft)\n",
    "                mask_saver.restore(session_right,modelright)\n",
    "                sd_saver.restore(session_sd, modelsd_test)\n",
    "                sd_saver.restore(session_sr, modelsr_test)\n",
    "                mask_sd_saver.restore(session_mask_sd, model_mask_sd)\n",
    "\n",
    "            sum_accuracy = 0.0\n",
    "            n = 1\n",
    "            while end_batch < total_imgs:\n",
    "\n",
    "                train_data, mask_labels, left_mask, right_mask, labels = generate_batch(train_batch_size, img_shape, item_size, nitems)\n",
    "                train_data_r, mask_labels_r, left_mask_r, right_mask_r, labels_r = generate_batch(train_batch_size, img_shape, item_size, nitems, 'SR')\n",
    "                \n",
    "                if not len(train_data) and not len(labels) and not len(mask_labels):\n",
    "                    print(\"All images have been processed.\")\n",
    "                    break;\n",
    "                s_time = time.time()   \n",
    "                left_pred = train_mask(save_model, restore_model, modelleft, left_mask_saver, session_left, end_batch, train_data, left_mask)   \n",
    "                right_pred = train_mask(save_model, restore_model, modelright, right_mask_saver, session_right, end_batch, train_data, right_mask)   \n",
    "                e_time = time.time()\n",
    "                time_dif = e_time - s_time\n",
    "\n",
    "                # Print the time-usage.\n",
    "                print(\"train_mask Time usage: \" + str(timedelta(seconds=int(round(time_dif))))) \n",
    "                s_time = time.time()   \n",
    "#                 mask_sd_batch = prepare_train_mask_sd(left_pred, right_pred, train_data, left_mask, right_mask)\n",
    "                e_time = time.time()\n",
    "                time_dif = e_time - s_time\n",
    "\n",
    "                # Print the time-usage.\n",
    "                print(\"prepare_train_mask_sd Time usage: \" + str(timedelta(seconds=int(round(time_dif))))) \n",
    "                s_time = time.time()\n",
    "                \n",
    "                train_sd(save_model, restore_model, modelsd_test, sd_saver, session_sd, end_batch, train_data, labels)\n",
    "                train_sd(save_model, restore_model, modelsr_test, sd_saver, session_sr, end_batch, train_data_r, labels_r)\n",
    "                e_time = time.time()\n",
    "                time_dif = e_time - s_time\n",
    "\n",
    "                # Print the time-usage.\n",
    "                print(\"train_sd Time usage: \" + str(timedelta(seconds=int(round(time_dif))))) \n",
    "                s_time = time.time()   \n",
    "#                 train_mask_sd(save_model, restore_model, model_mask_sd, sd_saver, session_mask_sd, end_batch, mask_sd_batch, labels)\n",
    "                e_time = time.time()\n",
    "                time_dif = e_time - s_time\n",
    "\n",
    "                # Print the time-usage.\n",
    "                print(\"train_mask_sd Time usage: \" + str(timedelta(seconds=int(round(time_dif))))) \n",
    "\n",
    "                start_batch += train_batch_size\n",
    "                end_batch += train_batch_size\n",
    "\n",
    "            if save_model==True:\n",
    "                if save_name==None:\n",
    "                    print(\"No model specified, model not being saved\")\n",
    "                    return\n",
    "                else:\n",
    "                    save_path = mask_saver.save(session_left, modelleft)\n",
    "                    save_path = mask_saver.save(session_right, modelright)\n",
    "                    \n",
    "                    save_path = sd_saver.save(session_sd, modelsd_test)\n",
    "                    save_path = sd_saver.save(session_sr, modelsr_test)\n",
    "                    save_path = mask_sd_saver.save(session_mask_sd, model_mask_sd)\n",
    "                    \n",
    "                    restore_model = True\n",
    "#                     print(\"Model saved in file: %s\" % save_name)\n",
    "            s_time = time.time()                    \n",
    "            mask_acc, mask_sd_train, mask_sd_lbl = test_mask(test_batch_size, modelleft, modelright)\n",
    "            e_time = time.time()\n",
    "            time_dif = e_time - s_time\n",
    "\n",
    "            # Print the time-usage.\n",
    "            print(\"test_mask Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))         \n",
    "            s_time = time.time()                    \n",
    "\n",
    "            mask_sd_acc = test_mask_sd(train_batch_size, mask_sd_batch, mask_sd_lbl, model_mask_sd)\n",
    "            e_time = time.time()\n",
    "            time_dif = e_time - s_time\n",
    "\n",
    "            # Print the time-usage.\n",
    "            print(\"test_mask_sd Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))         \n",
    "            s_time = time.time()                    \n",
    "            sd_acc = test_sd(test_batch_size, modelsd_test, 'SD')\n",
    "            sr_acc = test_sd(test_batch_size, modelsr_test, 'SR')\n",
    "            e_time = time.time()\n",
    "            time_dif = e_time - s_time\n",
    "            # Print the time-usage.\n",
    "            print(\"test_sd Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))         \n",
    "            \n",
    "            plot_mask.append(mask_acc)\n",
    "            plot_mask_sd.append(mask_sd_acc)\n",
    "            plot_sd.append(sd_acc)\n",
    "            plot_sr.append(sr_acc)\n",
    "#             plot_accuracy_epoch.append(sum_accuracy/n)\n",
    "#             plot_training_size_epoch.append(i + 1)\n",
    "\n",
    "        end_time = time.time()\n",
    "        # Difference between start and end-times.\n",
    "        time_dif = end_time - start_time\n",
    "\n",
    "        # Print the time-usage.\n",
    "        print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif))))) \n",
    "        mask_saver = None\n",
    "        left_mask_saver = None\n",
    "        right_mask_saver = None\n",
    "        print(plot_mask)\n",
    "        print(plot_mask_sd)\n",
    "        print(plot_sd)\n",
    "        print(plot_sr)\n",
    "#         print(plot_accuracy)\n",
    "#         print(plot_training_size)\n",
    "#         print(plot_accuracy_epoch)\n",
    "#         print(plot_training_size_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_imgs = 10000\n",
    "train_batch_size = 64\n",
    "\n",
    "save_model = True\n",
    "save_name = modelleft\n",
    "restore_model=False\n",
    "restore_name=modelleft\n",
    "optimize(num_epochs=10, save_model=True,save_name=modelleft,restore_model=False,restore_name=modelleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_output_grey(iNp,depth_filter_to_see=0,cmap=\"gray\",figsize=(4,4)):\n",
    "    img_x = iNp[0,:,:]\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.imshow(img_x, interpolation='none', aspect='auto')\n",
    "#     plt.colorbar(img_x, orientation='horizontal')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def see_output(iNp,depth_filter_to_see=0,cmap=\"gray\",figsize=(4,4)):\n",
    "    img_x = iNp[0,:,:,:]\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if cmap == \"gray\":\n",
    "        plt.imshow(img_x, cmap=plt.get_cmap('gray'))\n",
    "    else:\n",
    "        plt.imshow(img_x, interpolation='none', aspect='auto')\n",
    "#     plt.colorbar(img_x, orientation='horizontal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors(graph=tf.get_default_graph()):\n",
    "    return [t for op in graph.get_operations() for t in op.values()]\n",
    "get_tensors(sd_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_subm(img, top_k):\n",
    "\n",
    "    input_shape = img.shape\n",
    "    rows, cols = input_shape[0], input_shape[1]\n",
    "    d_rows, d_cols = (2, 2)\n",
    "    subm_rows, subm_cols = rows - d_rows + 1, cols - d_cols + 1\n",
    "\n",
    "    ind_rows = np.reshape(np.array([[r] * subm_rows for r in range(subm_rows)]), [subm_rows * subm_cols])\n",
    "    ind_cols = np.reshape(np.array([r for r in range(subm_rows)] * subm_cols), [subm_rows * subm_cols])\n",
    "\n",
    "    elems = np.array([img[r:r+d_rows, c:c+d_cols] for r,c in zip(ind_rows, ind_cols)])\n",
    "    elem_shape = elems.shape\n",
    "    sum_sub = np.sum(np.reshape(elems, [elem_shape[0],elem_shape[1]*elem_shape[2]]), axis=1)\n",
    "    top_idx = sum_sub.argsort()[-top_k:][::-1]\n",
    "\n",
    "    top_row = top_idx // subm_rows\n",
    "    top_col = top_idx % subm_cols\n",
    "\n",
    "    result = np.stack([top_row, top_col], axis=-1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
