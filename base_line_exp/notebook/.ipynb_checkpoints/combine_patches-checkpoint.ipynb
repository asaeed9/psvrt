{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "import cv2, os, math, time\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle\n",
    "from numpy.lib.stride_tricks import as_strided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configuration\n",
    "\"\"\"\n",
    "Data Configurations/Paths\n",
    "\"\"\"\n",
    "img_dir=\"../../original_images/SD\"\n",
    "img_lbls=\"\"\n",
    "base_model = 'SD/sd_01_.ckpt'\n",
    "model_20000 = 'SD/sd_20000.ckpt'\n",
    "model_30000 = 'SD/sd_30000.ckpt'\n",
    "model_40000 = 'SD/sd_40000.ckpt'\n",
    "model_50000 = 'SD/sd_50000.ckpt'\n",
    "model2_50000 = 'SD/sd2_50000.ckpt'\n",
    "\n",
    "connected_model = 'SD/sd_conected.ckpt'\n",
    "\n",
    "##\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 4          # Convolution filters are 4 x 4 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters2 = 32         # There are 32 of these filters.\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters3 = 64         # There are 64 of these filters.\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size4 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters4 = 128         # There are 128 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 2000             # Number of neurons in fully-connected layer.\n",
    "\n",
    "# We know that images are 60 pixels in each dimension.\n",
    "# img_size = 8 * 4\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 10 * 10\n",
    "\n",
    "# Number of colour channels for the images: 3 channel for RGB.\n",
    "num_channels = 1\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (10, 10, num_channels)\n",
    "\n",
    "# Number of classes, one class for same or different image\n",
    "num_classes = 4*2\n",
    "patch_size = (2, 2)\n",
    "npatches = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_dir):\n",
    "        list_of_imgs = []\n",
    "        list_of_labels = []\n",
    "        list_same_diff = []\n",
    "        list_img_keys = []\n",
    "        for img in os.listdir(img_dir):\n",
    "            \n",
    "            img_path = os.path.join(img_dir, img)\n",
    "            list_same_diff.append(int(os.listdir(img_path)[0]))\n",
    "            list_img_keys.append(img)\n",
    "            img_path = img_path + \"/\" + os.listdir(img_path)[0]\n",
    "            for img_label in os.listdir(img_path):\n",
    "                img_data = os.path.join(img_path, img_label)\n",
    "                if img_label == \"img\":\n",
    "#                     print(img_data + \"/img.png\")\n",
    "                    list_of_imgs.append(img_data + \"/predicted_mask.png\")\n",
    "                else:\n",
    "                    list_of_labels.append([os.path.join(img_data, label) for label in os.listdir(img_data)])\n",
    "\n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_labels = np.array(list_of_labels)\n",
    "        data_same_diff = np.array(list_same_diff)\n",
    "        data_img_keys = np.array(list_img_keys)\n",
    "\n",
    "        return data_imgs, data_labels, data_same_diff, data_img_keys\n",
    "\n",
    "    \n",
    "def get_batch_images(data, label, same_diff, img_keys, rshp, grey_scale):\n",
    "        list_of_imgs = []\n",
    "        list_of_labels = []\n",
    "        list_of_same_diff = []\n",
    "        list_of_img_keys = []\n",
    "        for img, lbl, img_type, img_key in zip(data, label, same_diff, img_keys):\n",
    "            orig_img = cv2.imread(img)\n",
    "            orig_lbl = cv2.imread(lbl)\n",
    "            if orig_img is None or orig_lbl is None:\n",
    "                    print (\"Unable to read image{} or {}\".format(img, lbl))\n",
    "                    continue\n",
    "            \n",
    "            if (grey_scale):\n",
    "                orig_lbl = rgb2grey(orig_lbl)\n",
    "\n",
    "            flattened_img = orig_img.flatten()\n",
    "            flattened_lbl = orig_lbl.flatten()\n",
    "\n",
    "            list_of_imgs.append(np.asarray(flattened_img, dtype=np.float32))\n",
    "            list_of_labels.append(np.asarray(flattened_lbl, dtype=np.float32))\n",
    "            list_of_same_diff.append(img_type)\n",
    "            list_of_img_keys.append(img_key)\n",
    "\n",
    "        data_labels = np.array(list_of_labels)\n",
    "#         print(data_labels.shape)\n",
    "#         print(rshp)\n",
    "        reshaped_labels = np.reshape(data_labels, rshp)\n",
    "        data_labels = np.squeeze(reshaped_labels[:, :, :1])\n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_img_type = np.array(list_of_same_diff)\n",
    "        data_img_keys = np.array(list_of_img_keys)\n",
    "        \n",
    "        return data_imgs, data_labels, data_img_type, data_img_keys\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "def rgb2grey(rgb):\n",
    "    return(np.dot(rgb[...,:3], [0.299, 0.587, 0.114]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../original_images/SD/15970/0/img/predicted_mask.png'] ['../../original_images/SD/15970/0/labels/merged_patch.png'] ['../../original_images/SD/15970/0/labels/mask.png']\n",
      "(4, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train = train_data[0:1]\n",
    "merged_patch_lbls = train_labels[0:1, 0]\n",
    "mask_lbls = train_labels[0:1, 1]\n",
    "img_type_lbl = img_type[0:1]\n",
    "img_key = img_keys[0:1]\n",
    "dims = (1, num_classes, num_channels)\n",
    "print(train, merged_patch_lbls, mask_lbls)\n",
    "train, labels, img_type_lbl, img_key = get_batch_images(train, predicted_lbls, img_type_lbl, img_key, dims, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape, layer_name):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape), name=layer_name+'_W')\n",
    "\n",
    "def new_bias(length, layer_name):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]), name=layer_name+'_b')\n",
    "\n",
    "def new_conv_layer(input,\n",
    "                   num_input_channels,\n",
    "                   filter_size,\n",
    "                   num_filters,\n",
    "                   name_scope,\n",
    "                   layer_name='',\n",
    "                   use_pooling=True):\n",
    "\n",
    "    with tf.name_scope(name_scope):\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "        weights = new_weights(shape, layer_name)\n",
    "        biases = new_bias(num_filters, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.nn.conv2d(input=input, filter=weights, strides=[1,1,1,1], padding='SAME'), biases, name=layer_name)\n",
    "\n",
    "        if use_pooling:\n",
    "            layer = tf.nn.max_pool(value=layer,\n",
    "                                   ksize=[1, 3, 3, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME', name=layer_name+'_max')\n",
    "        layer = tf.nn.relu(layer, name=layer_name+'_activation')\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                name_scope,\n",
    "                layer_name='',\n",
    "                use_relu=True):\n",
    "    \n",
    "    with tf.name_scope(name_scope):\n",
    "        weights = new_weights([num_inputs, num_outputs], layer_name)\n",
    "        biases = new_bias(num_outputs, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.matmul(input, weights),biases,name=layer_name)\n",
    "    #     layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer, layer_name+'_activation')\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def normalise(tensor):\n",
    "    return tf.div(\n",
    "   tf.subtract(\n",
    "      tensor, \n",
    "      tf.reduce_min(tensor)\n",
    "   ), \n",
    "   tf.subtract(\n",
    "      tf.reduce_max(tensor), \n",
    "      tf.reduce_min(tensor)\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(10), Dimension(10), Dimension(1)]),\n",
       " <tf.Tensor 'y_true_3:0' shape=(?, 8) dtype=float32>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat*num_channels], name='x')\n",
    "x_image = tf.reshape(x, [-1, 10, 10, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "# y_true_cls = tf.argmax(y_true, axis=1)\n",
    "y_true_cls = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true_cls')\n",
    "x_image.shape, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2, 3)\n",
      "(4, 2)\n",
      "[[ 29.07  255.   ]\n",
      " [105.315  29.07 ]\n",
      " [ 29.07  255.   ]\n",
      " [105.315  29.07 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_x = cv2.imread(\"../../original_images/SD/15970/0/labels/merged_patch.png\")\n",
    "print(img_x.shape)\n",
    "reshaped_img_x = np.expand_dims(img_x, axis=0)\n",
    "\n",
    "grey_img = np.dot(img_x[...,:3], [0.299, 0.587, 0.114])\n",
    "print(grey_img.shape)\n",
    "\n",
    "# see_output(reshaped_img_x, figsize=(2,4))\n",
    "\n",
    "fig = plt.figure(figsize=(2,4))\n",
    "print(grey_img)\n",
    "plt.imshow(grey_img, interpolation='none', aspect='auto')\n",
    "see_output(reshaped_img_x, figsize = (2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 4 4]\n",
      " [1 1 4 4]\n",
      " [3 3 2 2]\n",
      " [3 3 2 2]]\n",
      "[ 4 10 16  8 10 12 12 10  8]\n",
      "[2 5]\n",
      "[3, array([2, 2], dtype=int32)]\n",
      "[[0 2]\n",
      " [1 2]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Input data\n",
    "# input = tf.placeholder(tf.int32, [None, None])\n",
    "# Submatrix dimension\n",
    "# dims = tf.placeholder(tf.int32, [2])\n",
    "# Number of top submatrices to find\n",
    "# k = tf.placeholder(tf.int32, [])\n",
    "\n",
    "input = tf.constant([\n",
    "        [1, 1, 4, 4],\n",
    "        [1, 1, 4, 4],\n",
    "        [3, 3, 2, 2],\n",
    "        [3, 3, 2, 2],\n",
    "    ])\n",
    "\n",
    "dims = tf.constant([2,2])\n",
    "k = tf.constant(2)\n",
    "\n",
    "input_shape = tf.shape(input)\n",
    "rows, cols = input_shape[0], input_shape[1]\n",
    "d_rows, d_cols = dims[0], dims[1]\n",
    "subm_rows, subm_cols = rows - d_rows + 1, cols - d_cols + 1\n",
    "# Index grids\n",
    "ii, jj = tf.meshgrid(tf.range(subm_rows), tf.range(subm_cols), indexing='ij')\n",
    "d_ii, d_jj = tf.meshgrid(tf.range(d_rows), tf.range(d_cols), indexing='ij')\n",
    "\n",
    "# Add indices\n",
    "subm_ii = ii[:, :, tf.newaxis, tf.newaxis] + d_ii\n",
    "subm_jj = jj[:, :, tf.newaxis, tf.newaxis] + d_jj\n",
    "\n",
    "# Make submatrices tensor\n",
    "subm = tf.gather_nd(input, tf.stack([subm_ii, subm_jj], axis=-1))\n",
    "\n",
    "# Add submatrices\n",
    "subm_sum = tf.reduce_sum(subm, axis=(2, 3))\n",
    "\n",
    "\n",
    "# Use TopK to find top submatrices\n",
    "_, top_idx = tf.nn.top_k(tf.reshape(subm_sum, [-1]), tf.minimum(k, tf.size(subm_sum)))\n",
    "\n",
    "# Get row and column\n",
    "top_row = top_idx // subm_cols\n",
    "top_col = top_idx % subm_cols\n",
    "result = tf.stack([top_row, top_col], axis=-1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print(sess.run(input))\n",
    "#     print(sess.run(subm_sum))\n",
    "    print(sess.run(tf.reshape(subm_sum, [-1])))\n",
    "    print(sess.run(top_idx))\n",
    "    print(sess.run([subm_rows, top_col]))\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 56,  78, 103,  83,  64,  67,  53,  72,  73,  56],\n",
       "        [ 58,  72,  92,  94, 101,  83,  30,  54,  69,  61],\n",
       "        [ 61,  60,  33,  77, 104,  70,  32,  67,  62,  43],\n",
       "        [ 67,  73,  53,  61,  57,  33,  56,  82,  66,  38],\n",
       "        [ 56,  41,  47,  58,  58,  57,  59,  36,  38,  61],\n",
       "        [ 49,  40,  56,  61,  68,  61,  38,  51, 179, 180],\n",
       "        [ 56,  67,  63,  57,  64,  41,  33,  73, 215, 189],\n",
       "        [ 64,  60,  41,  55,  67,  61,  64,  61,  69,  69],\n",
       "        [ 73,  64,  36,  60,  59,  56,  61,  45,  47,  53],\n",
       "        [ 61,  64,  61,  61,  54,  47,  50,  50,  49,  49]], dtype=uint8),\n",
       " array([[  0,   0,   0, 255, 255,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0, 255, 255,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0, 255, 255],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0, 255, 255],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_img, mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[179. 180.]\n",
      " [215. 189.]\n",
      " [215. 189.]\n",
      " [ 69.  69.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Input data\n",
    "input = tf.placeholder(tf.float32, [None, None])\n",
    "# Submatrix dimension\n",
    "dims = tf.placeholder(tf.int32, [2])\n",
    "# Number of top submatrices to find\n",
    "k = tf.placeholder(tf.int32, [])\n",
    "\n",
    "# input = tf.constant([\n",
    "#         [1, 1, 4, 4],\n",
    "#         [1, 1, 4, 4],\n",
    "#         [3, 3, 2, 2],\n",
    "#         [3, 3, 2, 2],\n",
    "#     ])\n",
    "\n",
    "# dims = tf.constant([2,2])\n",
    "# k = tf.constant(2)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "\n",
    "#     session.run(k)\n",
    "\n",
    "# Sizes\n",
    "input_shape = tf.shape(input)\n",
    "rows, cols = input_shape[0], input_shape[1]\n",
    "d_rows, d_cols = dims[0], dims[1]\n",
    "subm_rows, subm_cols = rows - d_rows + 1, cols - d_cols + 1\n",
    "\n",
    "# Index grids\n",
    "ii, jj = tf.meshgrid(tf.range(subm_rows), tf.range(subm_cols), indexing='ij')\n",
    "d_ii, d_jj = tf.meshgrid(tf.range(d_rows), tf.range(d_cols), indexing='ij')\n",
    "# Add indices\n",
    "subm_ii = ii[:, :, tf.newaxis, tf.newaxis] + d_ii\n",
    "subm_jj = jj[:, :, tf.newaxis, tf.newaxis] + d_jj\n",
    "# Make submatrices tensor\n",
    "subm = tf.gather_nd(input, tf.stack([subm_ii, subm_jj], axis=-1))\n",
    "# Add submatrices\n",
    "subm_sum = tf.reduce_sum(subm, axis=(2, 3))\n",
    "# Use TopK to find top submatrices\n",
    "_, top_idx = tf.nn.top_k(tf.reshape(subm_sum, [-1]), tf.minimum(k, tf.size(subm_sum)))\n",
    "# Get row and column\n",
    "top_row = top_idx // subm_cols\n",
    "top_col = top_idx % subm_cols\n",
    "result = tf.stack([top_row, top_col], axis=-1)\n",
    "\n",
    "patches = tf.map_fn(lambda x: tf.slice(input, x, patch_size), result, dtype=tf.float32)\n",
    "\n",
    "reshaped_patches = tf.squeeze(tf.reshape(patches, [tf.shape(patches)[0] * tf.shape(patches)[1], tf.shape(patches)[2] , -1]))\n",
    "\n",
    "# Test\n",
    "# with tf.Session() as sess:\n",
    "#     mat = [\n",
    "#         [1, 1, 4, 4],\n",
    "#         [1, 1, 4, 4],\n",
    "#         [3, 3, 2, 2],\n",
    "#         [3, 3, 2, 2],\n",
    "#     ]\n",
    "#     print(sess.run(reshaped_patches, feed_dict={input: predicted_img, dims: patch_size, k: npatches}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255. 255.]\n",
      "  [255. 255.]]\n",
      "\n",
      " [[255. 255.]\n",
      "  [255. 255.]]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant([[[255., 255.],\n",
    "  [255., 255.]],\n",
    " [[255., 255.],\n",
    "  [255., 255.]]])\n",
    "\n",
    "shape = X.get_shape().as_list()\n",
    "\n",
    "reshaped_X = tf.squeeze(tf.reshape(X, [shape[0], shape[1], shape[2] , -1]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(session.run(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  4]\n",
      " [ 1  5]\n",
      " [ 5  9]\n",
      " [ 6 10]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# build a tensor\n",
    "x = np.arange(25)\n",
    "x = np.reshape(x, [5, 5])\n",
    "y = x + 4\n",
    "three_d_array = np.stack([x, y], axis=2)\n",
    "# make it into a tf tensor\n",
    "three_d_tensor = tf.constant(three_d_array)\n",
    "\n",
    "row_0, col_0 = 0, 0\n",
    "row_1, col_1 = 0, 1\n",
    "row_2, col_2 = 1, 0\n",
    "row_3, col_3 = 1, 1\n",
    "slice_tensor = tf.constant([\n",
    "    [row_0, col_0],\n",
    "    [row_1, col_1],\n",
    "    [row_2, col_2],\n",
    "    [row_3, col_3]\n",
    "])\n",
    "slices = tf.Variable(initial_value=slice_tensor)\n",
    "gather_op = tf.gather_nd(three_d_tensor, slices)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    submatrices = sess.run(gather_op)\n",
    "    print(submatrices)\n",
    "#     print(submatrices[0,:] == three_d_array[row_0, col_0])\n",
    "#     print(submatrices[1,:] == three_d_array[row_1, col_1])\n",
    "#     print(submatrices[2,:] == three_d_array[row_2, col_2])\n",
    "#     print(submatrices[3,:] == three_d_array[row_3, col_3])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "[ True  True]\n",
      "[ True  True]\n",
      "[ True  True]\n",
      "[ True  True]\n",
      "[ True  True]\n",
      "[ True  True]\n",
      "[ True  True]\n",
      "[ True  True]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# build a tensor\n",
    "x = np.arange(25)\n",
    "x = np.reshape(x, [5, 5])\n",
    "y = x + 4\n",
    "three_d_array = np.stack([x, y], axis=2)\n",
    "# just so you can see the shape its made of\n",
    "print(np.all(x == three_d_array[:,:,0]))\n",
    "print(np.all(y == three_d_array[:,:,1]))\n",
    "# make it into a tf tensor\n",
    "three_d_tensor = tf.constant(three_d_array)\n",
    "\n",
    "# create a variable for tensor valued slice indices\n",
    "row_0, col_0 = 0, 0\n",
    "row_1, col_1 = 0, 1\n",
    "row_2, col_2 = 1, 0\n",
    "row_3, col_3 = 1, 1\n",
    "slice_tensor = tf.constant([\n",
    "    [row_0, col_0],\n",
    "    [row_1, col_1],\n",
    "    [row_2, col_2],\n",
    "    [row_3, col_3]\n",
    "])\n",
    "slices = tf.Variable(initial_value=slice_tensor)\n",
    "\n",
    "# op to get the sub matrices\n",
    "gather_op = tf.gather_nd(three_d_tensor, slices)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    submatrices = sess.run(gather_op)\n",
    "    print(submatrices[0,:] == three_d_array[row_0, col_0])\n",
    "    print(submatrices[1,:] == three_d_array[row_1, col_1])\n",
    "    print(submatrices[2,:] == three_d_array[row_2, col_2])\n",
    "    print(submatrices[3,:] == three_d_array[row_3, col_3])\n",
    "\n",
    "    # shift down 2 along 2\n",
    "    offset_top_left = tf.constant([2,2])\n",
    "    update_variable_op = tf.assign(slices, slices + offset_top_left[None,:])\n",
    "    sess.run(update_variable_op)\n",
    "    submatrices = sess.run(gather_op)\n",
    "    print(submatrices[0, :] == three_d_array[row_0 + 2, col_0 + 2])\n",
    "    print(submatrices[1, :] == three_d_array[row_1 + 2, col_1 + 2])\n",
    "    print(submatrices[2, :] == three_d_array[row_2 + 2, col_2 + 2])\n",
    "    print(submatrices[3, :] == three_d_array[row_3 + 2, col_3 + 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1.],\n",
       "        [1., 1.]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "session = tf.Session()\n",
    "# x = [[0, 0, 1, 1],\n",
    "#      [0, 0, 1, 1],\n",
    "#      [2, 2, 0, 0],\n",
    "#      [2, 2, 0, 0]]\n",
    "# X = tf.Variable(x, dtype=tf.float32)\n",
    "\n",
    "# elems = tf.constant([[0,2]])\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "tf.map_fn(lambda s: tf.slice(tf.constant([[0,0,1,1],[0,0,1,1]], dtype=tf.float64), s, [2,2]), tf.constant([[0,2]], dtype=tf.int32), dtype=tf.float64).eval(session=session)\n",
    "# tf.map_fn(lambda x: tf.slice(X, x, [2,2]), tf.constant([[0,2],[2,0]])).eval(session=session)\n",
    "# X[elems[0]].eval(session=session)\n",
    "# squares = tf.map_fn(lambda x: tf.shape(x), elems)\n",
    "# squares.eval(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = [[0, 0, 1, 1],\n",
    "     [0, 0, 1, 1],\n",
    "     [2, 2, 0, 0],\n",
    "     [2, 2, 0, 0]]\n",
    "X = tf.Variable(x, dtype=tf.float32)\n",
    "patch_starts = tf.constant([[0,2], [2,0]])\n",
    "s1 = tf.map_fn(tf.slice(X, patch_starts[i], patch_size), patch_starts)\n",
    "# s1 = tf.slice(X, [0,2], [2,2])\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run([s1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.constant(1)\n",
    "c = lambda i: tf.less(i, tf.shape(patch_starts)[0])\n",
    "# patch_starts = tf.constant([[0,2], [1,2]])\n",
    "# print(tf.less(i, tf.shape(patch_starts)[0]).eval(session=session))\n",
    "\n",
    "\n",
    "\n",
    "# print(tf.less(i, 10).eval(session=session))\n",
    "b = lambda i: tf.add(i, 1)\n",
    "r = tf.while_loop(c, b, [1])\n",
    "\n",
    "r.eval(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [2 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 1.],\n",
       "        [1., 1.]],\n",
       "\n",
       "       [[1., 1.],\n",
       "        [1., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ones = tf.ones([3, 3], tf.float32)\n",
    "mat_box = tf.constant([[0.0,0.0,1.0,1.0], [0.0,0.0,1.0,1.0], [1.0,1.0,0.0,0.0], [1.0,1.0,0.0,0.0]], dtype=tf.float32, name=\"mat_box\")\n",
    "kernel = tf.reshape(all_ones, [3, 3, 1, 1], name='kernel')\n",
    "# image  = tf.reshape(mat_box, [1, 4, 4, 1], name='image')\n",
    "\n",
    "sliced_patches = tf.extract_image_patches(mat_box[tf.newaxis,:,:,tf.newaxis],\n",
    "    [1, 3, 3, 1], [1, 1, 1, 1], [1, 1, 1, 1], padding='VALID')\n",
    "sliced_patches = tf.reshape(sliced_patches, [-1, 3, 3])\n",
    "cornered_patch = tf.scan(lambda a, b: tf.multiply(a, b), sliced_patches)[-1]\n",
    "\n",
    "condition = tf.squeeze(tf.where(tf.equal(cornered_patch, [1.])))\n",
    "\n",
    "print(condition.eval(session=session))\n",
    "\n",
    "\n",
    "patches = tf.map_fn(lambda x: tf.slice(mat_box, x, patch_size), condition, dtype=tf.float32)\n",
    "patches.eval(session=session)\n",
    "# print(patch_starts.eval(session=session))\n",
    "# print(mat_box[patch_start[0]:patch_start[0] + patch_size[0], :].eval(session=session))\n",
    "\n",
    "# print(tf.gather(mat_box[:,], patch_start[0] + 2).eval(session=session))\n",
    "\n",
    "# print(condition.eval(session=session))\n",
    "# print(tf.where(cornered_patch = 1).eval(session=session))\n",
    "\n",
    "# if len(np.where(cornered_image == 1)[0]) > 0:\n",
    "# tmp_patch = reshaped_img[:, x[0]:x[0] + patch_size[0], y[0]:y[0]+patch_size[1], :]\n",
    "\n",
    "\n",
    "\n",
    "# session.run(tf.global_variables_initializer())\n",
    "# print(mat_box.eval(session=session))\n",
    "# print(cornered_patch.eval(session=session))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2, 3)\n",
      "[[[255   0 255]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0 255   0]\n",
      "  [255   0   0]]\n",
      "\n",
      " [[255   0 255]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0 255   0]\n",
      "  [255   0   0]]]\n",
      "[[ 56  78 103  83  64  67  53  72  73  56]\n",
      " [ 58  72  92  94 101  83  30  54  69  61]\n",
      " [ 61  60  33  77 104  70  32  67  62  43]\n",
      " [ 67  73  53  61  57  33  56  82  66  38]\n",
      " [ 56  41  47  58  58  57  59  36  38  61]\n",
      " [ 49  40  56  61  68  61  38  51 179 180]\n",
      " [ 56  67  63  57  64  41  33  73 215 189]\n",
      " [ 64  60  41  55  67  61  64  61  69  69]\n",
      " [ 73  64  36  60  59  56  61  45  47  53]\n",
      " [ 61  64  61  61  54  47  50  50  49  49]]\n"
     ]
    }
   ],
   "source": [
    "# key = 36372\n",
    "# img_keys[36372]\n",
    "np.set_printoptions(suppress=True)\n",
    "orig_img = cv2.imread(\"../../original_images/SD/1984/0/img/img.png\", cv2.IMREAD_GRAYSCALE)\n",
    "predicted_img = cv2.imread(train_data[36372], cv2.IMREAD_GRAYSCALE)\n",
    "merged_img = cv2.imread(train_labels[36372, 0])\n",
    "\n",
    "print(merged_img.shape)\n",
    "print(merged_img)\n",
    "print(predicted_img)\n",
    "# print(orig_img)\n",
    "# print(train_data[36372])\n",
    "# orig_patches = train_labels[36372, 0]\n",
    "# img_tensor = tf.constant(img_x, dtype=tf.float64)\n",
    "# layer = normalise(img_tensor)\n",
    "# layer.eval(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer1_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
    "#                                             num_input_channels=num_channels,\n",
    "#                                             filter_size=filter_size1,\n",
    "#                                             num_filters=num_filters1,\n",
    "#                                              name_scope = 'cv',\n",
    "#                                              layer_name='conv1',\n",
    "#                                             use_pooling=True)\n",
    "\n",
    "#     with tf.name_scope(name_scope):\n",
    "\n",
    "# filter_size1 = 8          # Convolution filters are 4 x 4 pixels.\n",
    "# num_filters1 = 8         # There are 16 of these filters.\n",
    "# layer_name = \"layer1\"\n",
    "# shape = [filter_size1, filter_size1, num_input_channels, num_filters1]\n",
    "\n",
    "# initializer = tf.contrib.layers.xavier_initializer()\n",
    "# weights1 = tf.Variable(initializer(shape), name=layer_name+'_W')\n",
    "# biases1 = tf.Variable(tf.constant(0.05, shape=[length]), name=layer_name+'_b')\n",
    "\n",
    "tf.random_normal\n",
    "\n",
    "mat_box = tf.constant([[0.0,0.0,1.0,1.0], [0.0,0.0,1.0,1.0], [1.0,1.0,0.0,0.0], [1.0,1.0,0.0,0.0]], dtype=tf.float32, name=\"mat_box\")\n",
    "\n",
    "layer = normalise(x_image)\n",
    "\n",
    "all_ones = tf.ones([3, 3], tf.float32)\n",
    "kernel = tf.reshape(all_ones, [3, 3, 1, 1], name='kernel')\n",
    "# image  = tf.reshape(mat_box, [1, 4, 4, 1], name='image')\n",
    "\n",
    "sliced_patches = tf.extract_image_patches(mat_box[tf.newaxis,:,:,tf.newaxis],\n",
    "    [1, 3, 3, 1], [1, 1, 1, 1], [1, 1, 1, 1], padding='VALID')\n",
    "sliced_patches = tf.reshape(sliced_patches, [-1, 3, 3])\n",
    "cornered_patch = tf.scan(lambda a, b: tf.multiply(a, b), sliced_patches)[-1]\n",
    "\n",
    "condition = tf.squeeze(tf.where(tf.equal(cornered_patch, [1.])))\n",
    "\n",
    "print(condition.eval(session=session))\n",
    "\n",
    "\n",
    "patches = tf.map_fn(lambda x: tf.slice(mat_box, x, patch_size), condition, dtype=tf.float32)\n",
    "patches.eval(session=session)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# layer = tf.add(tf.matmul(input, weights),biases,name=layer_name)\n",
    "#     layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "\n",
    "#get patched corner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer4_conv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size+2,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc1',\n",
    "                         use_relu=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred_cls = layer_fc4\n",
    "y_pred = layer_fc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(y_true - y_pred_cls))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "## some more performance measures\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental details of Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train_labels = train_labels[:][:, 0]\n",
    "total_imgs = len(train_data)\n",
    "train_batch_size = 64\n",
    "\n",
    "def optimize(num_epochs, save_model=True,save_name= \"base_model\",restore_model=False,restore_name=None):\n",
    "    total_iterations = 0\n",
    "    done_train_imgs = 0\n",
    "    start_time = time.time()\n",
    "    start_ = 0\n",
    "    end_ = train_batch_size    \n",
    "    plot_accuracy=[]\n",
    "    plot_accuracy_epoch=[]\n",
    "    plot_training_size=[]\n",
    "    plot_training_size_epoch=[]\n",
    "    saver = tf.train.Saver()\n",
    "    sum_accuracy = 0.0\n",
    "    n = 1\n",
    "    \n",
    "        #to save the model\n",
    "    for i in range(0, num_epochs):   \n",
    "        start_batch=0\n",
    "        end_batch = train_batch_size\n",
    "        \n",
    "        print(\"Epoch:\", i + 1)\n",
    "        \n",
    "        if restore_model==True:\n",
    "            if restore_name==None:\n",
    "                print(\"No model file specified\")\n",
    "                return\n",
    "            else:\n",
    "                saver.restore(session,restore_name)\n",
    "        \n",
    "        sum_accuracy = 0.0\n",
    "        n = 1\n",
    "        while end_batch < total_imgs:\n",
    "            train = train_data[start_batch:end_batch]\n",
    "            labels = train_labels[start_batch:end_batch]\n",
    "            img_type_lbl = img_type[start_:end_]\n",
    "            img_key = img_keys[start_:end_]\n",
    "            dims = (len(train), num_classes, 1)\n",
    "            train, labels, img_type_lbl, img_key = get_batch_images(train, labels, img_type_lbl, img_key, dims)\n",
    "            if not len(train) and not len(labels):\n",
    "                print(\"All images have been processed.\")\n",
    "                break;\n",
    "\n",
    "            x_batch, y_true_batch = next_batch(len(train), train, labels)\n",
    "            feed_dict_train = {x: x_batch,\n",
    "                       y_true: y_true_batch}\n",
    "            \n",
    "            session.run(optimizer, feed_dict=feed_dict_train)\n",
    "    \n",
    "            acc,co = session.run([accuracy, cost], feed_dict=feed_dict_train)\n",
    "            sum_accuracy += acc\n",
    "            n+=1\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "            print(msg.format(end_batch + 1, acc, co))\n",
    "            if i == num_epochs - 1:\n",
    "                plot_accuracy.append(acc)\n",
    "                plot_training_size.append(end_batch + 1)\n",
    "\n",
    "            start_batch += train_batch_size\n",
    "            end_batch += train_batch_size\n",
    "    \n",
    "        if save_model==True:\n",
    "            if save_name==None:\n",
    "                print(\"No model specified, model not being saved\")\n",
    "                return\n",
    "            else:\n",
    "                save_path = saver.save(session, save_name)\n",
    "                restore_model = True\n",
    "                print(\"Model saved in file: %s\" % save_name)\n",
    "        plot_accuracy_epoch.append(sum_accuracy/n)\n",
    "        plot_training_size_epoch.append(i + 1)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))  \n",
    "    print(plot_accuracy)\n",
    "    print(plot_training_size)\n",
    "    print(plot_accuracy_epoch)\n",
    "    print(plot_training_size_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "save_name = model2_50000\n",
    "restore_model=False\n",
    "restore_name=model2_50000\n",
    "\n",
    "optimize(50, save_model=True,save_name=model2_50000,restore_model=False,restore_name=model2_50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../original_images/SD/1984/0/labels/merged_patch.png'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#key = 36372\n",
    "\n",
    "# labels = train_mask_labels[0:2]\n",
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "# img_keys[36372]\n",
    "img_type[36372]\n",
    "train_data[36372]\n",
    "train_labels[36372, 0]\n",
    "\n",
    "# np.where(img_keys == '1984')\n",
    "\n",
    "\n",
    "# dims = (2, num_classes, num_channels)\n",
    "# train, labels, img_type_lbl, img_key = get_batch_images(train, labels, img_type_lbl, img_key, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_see_layer(ix, model_name=None, var_name=None):\n",
    "    with tf.Session('', tf.Graph()) as s:\n",
    "        with s.graph.as_default():\n",
    "            if ((model_name != None) and var_name != None):\n",
    "                saver = tf.train.import_meta_graph(model_name+\".meta\")\n",
    "                saver.restore(s, model_name)\n",
    "                fd = {'x:0':ix}\n",
    "                var_name=var_name+\":0\"\n",
    "                    \n",
    "                result = 0\n",
    "                result = s.run(var_name, feed_dict=fd)\n",
    "    return result\n",
    "\n",
    "def see_output(iNp,depth_filter_to_see=0,cmap=\"gray\",figsize=(4,4)):\n",
    "    img_x = iNp[0,:,:,:]\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.imshow(img_x, interpolation='none', aspect='auto')\n",
    "#     plt.colorbar(img_x, orientation='horizontal')\n",
    "    plt.show()\n",
    "    \n",
    "def get_patch_corner(img):\n",
    "    r = img_shape[0]\n",
    "    c = img_shape[1]\n",
    "    rp = patch_size[0]\n",
    "    cp = patch_size[1]\n",
    "    conv_r= r - rp + 1\n",
    "    conv_c = c - cp + 1\n",
    "\n",
    "    all_ones = np.ones((conv_r,conv_c))\n",
    "    for i in range(0, rp):\n",
    "        for j in range(0, cp):\n",
    "    #         print(np_m[0+i:conv_r+i, 0+j:conv_c+j])\n",
    "            all_ones = np.multiply(all_ones, img[0+i:conv_r+i, 0+j:conv_c+j])\n",
    "\n",
    "    return(all_ones)\n",
    "\n",
    "\n",
    "\n",
    "def normalized(arr):\n",
    "    return (arr - np.min(arr))/(np.max(arr) - np.min(arr))\n",
    "\n",
    "def save_patch_images(img_x1, lbl_x1, index):\n",
    "    if not os.path.exists('./SD/predicted_mask/' + str(index)):\n",
    "        os.makedirs('./SD/predicted_mask/' + str(index))\n",
    "        os.makedirs('./SD/predicted_mask/' + str(index) + \"/\" + str(lbl_x1))\n",
    "        \n",
    "#     print(np.squeeze(img_x1).shape)\n",
    "    plt.imsave('./SD/predicted_mask/' + str(index) + \"/\" + str(lbl_x1) + '/img.png', np.squeeze(img_x1))\n",
    "    \n",
    "\n",
    "def predict_nd_save(train, labels, img_type_lbl, img_key, start_idx):\n",
    "\n",
    "    for index in range(0, len(train)):\n",
    "        img_x = train[index:index+1, :]\n",
    "        lbl_x = labels[index:index+1, :]\n",
    "        img_type_x = img_type_lbl[index]\n",
    "        img_key_x = img_key[index]\n",
    "        prediction = restore_see_layer(ix=img_x,model_name=model_50000,var_name='fc_3/fc4')\n",
    "        prediction = np.reshape(prediction, (1, 10,10, 1))   \n",
    "        save_patch_images(prediction, img_type_x, img_key_x)\n",
    "            \n",
    "# def save_patch_images(img_x1, lbl_x1, index):\n",
    "#     if not os.path.exists('./SD/patched_images/' + str(index)):\n",
    "#         os.makedirs('./SD/patched_images/' + str(index))\n",
    "#         os.makedirs('./SD/patched_images/' + str(index) + \"/\" + str(lbl_x1))\n",
    "        \n",
    "\n",
    "#     plt.imsave('./SD/patched_images/' + str(index) + \"/\" + str(lbl_x1) + '/img.png', np.squeeze(img_x1))\n",
    "\n",
    "    \n",
    "# def extract_combine_patches(train, labels, img_type_lbl, img_key, start_idx):\n",
    "#     patched_images = []\n",
    "    \n",
    "#     for index in range(0, len(train)):\n",
    "# #         print(index)\n",
    "#         img_x = train[index:index+1, :]\n",
    "#         lbl_x = labels[index:index+1, :]\n",
    "#         img_type_x = img_type_lbl[index]\n",
    "#         img_key_x = img_key[index]\n",
    "#         output_cl1 = restore_see_layer(ix=img_x,model_name=model_50000,var_name='fc_3/fc4')\n",
    "#         output_fc4_w = restore_see_layer(ix=img_x,model_name=model_50000,var_name='fc_3/fc4_W')\n",
    "#         normalized_output = np.rint(normalized(output_cl1))\n",
    "#         np_m = np.squeeze(np.reshape(normalized_output, (1,10,10,1)))\n",
    "#         cornered_image = get_patch_corner(np_m)\n",
    "\n",
    "#         reshaped_img = np.reshape(img_x, (1, 10,10, 3))\n",
    "#         x, y = np.where(cornered_image == 1)\n",
    "        \n",
    "#         if len(np.where(cornered_image == 1)[0]) > 0:\n",
    "#             tmp_patch = reshaped_img[:, x[0]:x[0] + patch_size[0], y[0]:y[0]+patch_size[1], :]\n",
    "#         else:\n",
    "#             continue\n",
    "            \n",
    "#         for idx in range(1, len(np.where(cornered_image == 1)[0])):\n",
    "# #             print(\"index:\", idx)\n",
    "# #             print(\"X:\", x)\n",
    "# #             print(\"Y:\", y)\n",
    "# #             print(\"reshaped image:\", reshaped_img)\n",
    "#             tmp_patch1 = reshaped_img[:, x[idx]:x[idx] + patch_size[0], y[idx]:y[idx]+patch_size[1], :]\n",
    "#             tmp_patch = np.expand_dims(np.concatenate((np.squeeze(tmp_patch), np.squeeze(tmp_patch1)), axis=0), axis=0)\n",
    "        \n",
    "# #         print(tmp_patch.shape)\n",
    "# #         save_patch_images(tmp_patch, img_type_x, start_idx + index)\n",
    "#         save_patch_images(tmp_patch, img_type_x, img_key_x)\n",
    "\n",
    "#         patched_images.append(tmp_patch)\n",
    "#         tmp_patch = []\n",
    "        \n",
    "#     return patched_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train_mask_labels = train_labels[:][:, 1]\n",
    "train_patch_labels = train_labels[:][:, 0]\n",
    "\n",
    "batch_s = 64\n",
    "total_iterations = 0\n",
    "start_ = 0\n",
    "end_ = batch_s\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "if not os.path.exists('./SD/predicted_mask'):\n",
    "    os.makedirs('./SD/predicted_mask')\n",
    "\n",
    "while True:\n",
    "    train = train_data[start_:end_]\n",
    "    labels = train_mask_labels[start_:end_]\n",
    "    img_type_lbl = img_type[start_:end_]\n",
    "    img_key = img_keys[start_:end_]\n",
    "    dims = (batch_s, num_classes, num_channels)\n",
    "    train, labels, img_type_lbl, img_key = get_batch_images(train, labels, img_type_lbl, img_key, dims)\n",
    "    predict_nd_save(train, labels, img_type_lbl, img_key, start_)\n",
    "    \n",
    "    #do my stuff\n",
    "    if len(train_data) < start_ + batch_s:\n",
    "        print(\"{} Images have been processed.\".format(total_iterations))\n",
    "        break\n",
    "    \n",
    "    total_iterations +=batch_s\n",
    "    start_ = end_\n",
    "    end_ = end_ + batch_s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train_mask_labels = train_labels[:][:, 1]\n",
    "train_patch_labels = train_labels[:][:, 0]\n",
    "batch_s = 64\n",
    "total_iterations = 0\n",
    "start_ = 0\n",
    "end_ = batch_s\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "if not os.path.exists('./SD/patched_images'):\n",
    "    os.makedirs('./SD/patched_images')\n",
    "\n",
    "while True:\n",
    "\n",
    "    train = train_data[start_:end_]\n",
    "    labels = train_labels[start_:end_]\n",
    "    img_type_lbl = img_type[start_:end_]\n",
    "    img_key = img_keys[start_:end_]\n",
    "    dims = (batch_s, num_classes, num_channels)\n",
    "    train, labels, img_type_lbl, img_key = get_batch_images(train, labels, img_type_lbl, img_key, dims)\n",
    "    patch_images = extract_combine_patches(train, labels, img_type_lbl, img_key, start_)\n",
    "    \n",
    "    #do my stuff\n",
    "    if len(train_data) < start_ + batch_s:\n",
    "        print(\"{} Images have been processed.\".format(total_iterations))\n",
    "        break\n",
    "    \n",
    "    total_iterations +=batch_s\n",
    "    start_ = end_\n",
    "    end_ = end_ + batch_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-b543e2dc2b23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msee_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msee_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_lbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-126-2855da5c4683>\u001b[0m in \u001b[0;36msee_output\u001b[0;34m(iNp, depth_filter_to_see, cmap, figsize)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msee_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miNp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth_filter_to_see\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miNp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     plt.colorbar(img_x, orientation='horizontal')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "see_output(np.expand_dims(orig_img, axis=0))\n",
    "see_output(np.expand_dims(orig_lbl, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'restore_see_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-1b84df8c4787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moutput_cl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_see_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2_50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc_3/fc4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mshow_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_cl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'restore_see_layer' is not defined"
     ]
    }
   ],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train = train_data[0:1]\n",
    "labels = train_labels[0:1, 0]\n",
    "labels\n",
    "img_type_lbl = img_type[0:1]\n",
    "img_key = img_keys[0:1]\n",
    "dims = (1, num_classes, num_channels)\n",
    "train, labels, img_type_lbl, img_key = get_batch_images(train, labels, img_type_lbl, img_key, dims)\n",
    "\n",
    "# train[0:1]\n",
    "# img_x = cv2.imread(\"../../original_images/SD/15970/0/img/predicted_mask.png\")\n",
    "\n",
    "# img_x = np.expand_dims(img_x[:,:,0].flatten(), axis=0)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "output_cl1 = restore_see_layer(ix=img_x,model_name=model2_50000,var_name='fc_3/fc4')\n",
    "show_img = np.expand_dims(np.reshape(output_cl1, (4,2,3)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_output(iNp,depth_filter_to_see=0,cmap=\"gray\",figsize=(4,4)):\n",
    "    img_x = iNp[0,:,:,:]\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.imshow(img_x, interpolation='none', aspect='auto')\n",
    "#     plt.colorbar(img_x, orientation='horizontal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_x = cv2.imread(\"../../original_images/SD/15970/0/labels/merged_patch.png\")\n",
    "reshaped_img_x\n",
    "see_output(np.expand_dims(img_x, axis=0), figsize=(2,4))\n",
    "# see_output(img_x, figsize = (2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flattened_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-01d06fdf80fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mflat_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moutput_cl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_see_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc_3/fc4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_fc4_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_see_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc_3/fc4_W'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flattened_img' is not defined"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "flat_img = np.expand_dims(flattened_img, axis=0)\n",
    "output_cl1 = restore_see_layer(ix=flat_img,model_name=model_50000,var_name='fc_3/fc4')\n",
    "output_fc4_w = restore_see_layer(ix=flat_img,model_name=model_50000,var_name='fc_3/fc4_W')\n",
    "\n",
    "normalized_output = np.rint(normalized(output_cl1))\n",
    "np_m = np.squeeze(np.reshape(normalized_output, (1,10,10,1)))\n",
    "# np_m.shape\n",
    "cornered_image = get_patch_corner(np_m)\n",
    "# print(np.reshape(output_cl1, (1, 10, 10, 1)))\n",
    "print(normalized(output_cl1))\n",
    "print(normalized_output)\n",
    "print(np_m)\n",
    "print(cornered_image)\n",
    "# reshaped_img = np.reshape(flat_img, (1, 10,10, 3))\n",
    "\n",
    "# x, y = np.where(cornered_image == 1)\n",
    "# tmp_patch = reshaped_img[:, x[0]:x[0] + patch_size[0], y[0]:y[0]+patch_size[1], :]\n",
    "# tmp_patch1 = reshaped_img[:, x[1]:x[1] + patch_size[0], y[1]:y[1]+patch_size[1], :]\n",
    "# tmp_patch = np.expand_dims(np.concatenate((np.squeeze(tmp_patch), np.squeeze(tmp_patch1)), axis=0), axis=0)\n",
    "\n",
    "# see_output(tmp_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
