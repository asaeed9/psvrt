{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2, os, math, time\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configuration\n",
    "\"\"\"\n",
    "Data Configurations/Paths\n",
    "\"\"\"\n",
    "img_dir_patch=\"./SD/predicted_patches\"\n",
    "img_dir_orig = \"./SD/original_images\"\n",
    "\n",
    "model50_SD = 'SD/50kSD_Model.ckpt'\n",
    "# img_type = \"original\"\n",
    "img_type = \"patch\"\n",
    "\n",
    "##\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 4          # Convolution filters are 4 x 4 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters2 = 32         # There are 32 of these filters.\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters3 = 64         # There are 64 of these filters.\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size4 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters4 = 128         # There are 128 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 256             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label_dimensions(labels):\n",
    "    label_temp = np.zeros((len(labels), 2))\n",
    "    \n",
    "    for idx in range(0, len(labels)):\n",
    "        if labels[idx] == 1:\n",
    "            label_temp[idx][1] = 1\n",
    "        else:\n",
    "            label_temp[idx][0] = 1\n",
    "    \n",
    "    return label_temp\n",
    "\n",
    "def load_data(img_dir, img_type=\"patch\"):\n",
    "        list_of_imgs = []\n",
    "        list_same_diff = []\n",
    "        for img_no in os.listdir(img_dir):\n",
    "            img_no_path = os.path.join(img_dir, img_no)\n",
    "            for img_label in os.listdir(img_no_path):\n",
    "                    \n",
    "                list_same_diff.append(int(img_label))\n",
    "                img_lbl_path = os.path.join(img_no_path, img_label)\n",
    "                \n",
    "                if img_type == \"original\":\n",
    "                    img_lbl_path = img_lbl_path + \"/img/\"\n",
    "                \n",
    "                for img in os.listdir(img_lbl_path):\n",
    "                    img_path = os.path.join(img_lbl_path, img)\n",
    "                    list_of_imgs.append(img_path)\n",
    "\n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_same_diff = np.array(list_same_diff)\n",
    "\n",
    "        return data_imgs, data_same_diff\n",
    "\n",
    "# def load_data(img_dir):\n",
    "#         list_of_imgs = []\n",
    "#         list_same_diff = []\n",
    "#         for img_no in os.listdir(img_dir):\n",
    "#             if img_no == \".DS_Store\":\n",
    "#                 continue\n",
    "\n",
    "#             img_no_path = os.path.join(img_dir, img_no)\n",
    "#             for img_label in os.listdir(img_no_path):\n",
    "#                 if img_label == \".DS_Store\":\n",
    "#                     continue\n",
    "                    \n",
    "#                 list_same_diff.append(int(img_label))\n",
    "#                 img_lbl_path = os.path.join(img_no_path, img_label)\n",
    "#                 for img in os.listdir(img_lbl_path):\n",
    "#                     img_path = os.path.join(img_lbl_path, img)\n",
    "#                     list_of_imgs.append(img_path)\n",
    "\n",
    "#         data_imgs = np.array(list_of_imgs)\n",
    "#         data_same_diff = np.array(list_same_diff)\n",
    "\n",
    "#         return data_imgs, data_same_diff\n",
    "\n",
    "    \n",
    "def get_batch_images(data, same_diff, type_img = \"patch\"):\n",
    "        list_of_imgs = []\n",
    "        list_of_same_diff = []\n",
    "        for img, img_type in zip(data, same_diff):\n",
    "            orig_img = cv2.imread(img)\n",
    "            #only first image as a label\n",
    "            if orig_img is None:\n",
    "                    print (\"Unable to read image{}\".format(img))\n",
    "                    continue\n",
    "            \n",
    "            if type_img == \"original\":\n",
    "                flattened_img = orig_img.flatten()\n",
    "                list_of_imgs.append(np.asarray(flattened_img, dtype=np.float32))\n",
    "                \n",
    "                if img_type == 1: #0 is same and 1 is different\n",
    "                    list_of_same_diff.append([0,1])\n",
    "                else:\n",
    "                    list_of_same_diff.append([1,0])\n",
    "            else:            \n",
    "                if orig_img.shape == (4, 2, 3):\n",
    "                    flattened_img = orig_img.flatten()\n",
    "                    list_of_imgs.append(np.asarray(flattened_img, dtype=np.float32))\n",
    "\n",
    "                    if img_type == 1: #0 is same and 1 is different\n",
    "                        list_of_same_diff.append([0,1])\n",
    "                    else:\n",
    "                        list_of_same_diff.append([1,0])\n",
    "        \n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_img_type = np.array(list_of_same_diff)\n",
    "        \n",
    "        return data_imgs, data_img_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Batch Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that images are 60 pixels in each dimension.\n",
    "img_size = 4*2\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 4 * 2\n",
    "\n",
    "# Number of colour channels for the images: 3 channel for RGB.\n",
    "num_channels = 3\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (4, 2, num_channels)\n",
    "\n",
    "\n",
    "# Number of classes, one class for same and one for different image\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(cv2.imread(images[i]).flatten().reshape((8,4, 3)), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def generate_size_graph(fig_no, training_size, accuracy, loss, patch_only,patch_conv, start_size, end_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(training_size,accuracy)\n",
    "    plt.plot(training_size,loss)\n",
    "    plt.plot(training_size, patch_only)\n",
    "    plt.plot(training_size, patch_conv)\n",
    "    plt.xlabel('Training Size')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Size vs Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['SD Original Accuracy','SR Accuracy', 'SD Patch Accuracy', 'SD Patch Conv'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(path + '/batch_graphs/' +  str(start_size) + '_' + str(end_size) + '.jpg') \n",
    "        \n",
    "def generate_graph(fig_no, epochs, train, val, label, train_title, val_title, train_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(epochs,train)\n",
    "    plt.plot(epochs,val)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel(label)\n",
    "    plt.title(train_title + ' vs ' + val_title + '( Samples:' + str(train_size) + ')')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['Patch','SD'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "#     plt.savefig(results_path + '/batch_graphs/' +  label + '_' + str(train_size) + '.jpg')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Helper Functions for TF Graph Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape))\n",
    "#     return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def new_bias(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,\n",
    "                   num_input_channels,\n",
    "                   filter_size,\n",
    "                   num_filters,\n",
    "                   use_pooling=True):\n",
    "\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    weights = new_weights(shape)\n",
    "    biases = new_bias(length=num_filters)\n",
    "    \n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                     filter=weights,\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                     padding='SAME')\n",
    "    layer += biases\n",
    "\n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 3, 3, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                use_relu=True):\n",
    "\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_bias(length=num_outputs)\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    \n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(4), Dimension(2), Dimension(3)]),\n",
       " <tf.Tensor 'y_true:0' shape=(?, 2) dtype=float32>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat*num_channels], name='x')\n",
    "x_image = tf.reshape(x, [-1, 4, 2, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)\n",
    "x_image.shape, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
    "                                            num_input_channels=num_channels,\n",
    "                                            filter_size=filter_size1,\n",
    "                                            num_filters=num_filters1,\n",
    "                                            use_pooling=True)\n",
    "\n",
    "layer2_conv2, weights_conv2 =  new_conv_layer(input=layer1_conv1,\n",
    "                                           num_input_channels=num_filters1,\n",
    "                                           filter_size=filter_size2,\n",
    "                                           num_filters=num_filters2,\n",
    "                                           use_pooling=True)\n",
    "\n",
    "layer3_conv3, weights_conv3 =  new_conv_layer(input=layer2_conv2,\n",
    "                                           num_input_channels=num_filters2,\n",
    "                                           filter_size=filter_size3,\n",
    "                                           num_filters=num_filters3,\n",
    "                                           use_pooling=True)\n",
    "\n",
    "layer4_conv4, weights_conv4 =  new_conv_layer(input=layer3_conv3,\n",
    "                                           num_input_channels=num_filters3,\n",
    "                                           filter_size=filter_size4,\n",
    "                                           num_filters=num_filters4,\n",
    "                                           use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer4_conv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "\n",
    "\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=False)\n",
    "\n",
    "layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=False)\n",
    "\n",
    "layer_fc4 = new_fc_layer(input=layer_fc3,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)\n",
    "\n",
    "drop_out = tf.nn.dropout(layer_fc4, 0.5)\n",
    "\n",
    "##Normalize the numbers(apply softmax!)\n",
    "\n",
    "y_pred = tf.nn.softmax(drop_out)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=drop_out,\n",
    "                                                        labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "## some more performance measures\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = load_data(\"./SD/patched_images\", img_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tensorflow on Defined Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "train_data, train_labels = load_data(\"./SD/patched_images\", img_type)\n",
    "total_imgs = len(train_data)\n",
    "train_batch_size = 64\n",
    "\n",
    "def optimize(num_epochs, save_model=True,save_name= \"base_model\",restore_model=False,restore_name=None):\n",
    "    total_iterations = 0\n",
    "    done_train_imgs = 0\n",
    "    start_time = time.time()\n",
    "    start_batch=0\n",
    "    end_batch = train_batch_size\n",
    "    plot_accuracy=[]\n",
    "    plot_accuracy_epoch=[]\n",
    "    plot_training_size=[]\n",
    "    plot_training_size_epoch=[]\n",
    "    saver = tf.train.Saver()\n",
    "    sum_accuracy = 0.0\n",
    "    n = 1\n",
    "    \n",
    "        #to save the model\n",
    "    for i in range(0, num_epochs):   \n",
    "        start_batch=0\n",
    "        end_batch = train_batch_size\n",
    "        \n",
    "        print(\"Epoch:\", i + 1)\n",
    "        \n",
    "        if restore_model==True:\n",
    "            if restore_name==None:\n",
    "                print(\"No model file specified\")\n",
    "                return\n",
    "            else:\n",
    "                saver.restore(session,restore_name)\n",
    "        \n",
    "        sum_accuracy = 0.0\n",
    "        n = 1\n",
    "        while end_batch < total_imgs:\n",
    "            train = train_data[start_batch:end_batch]\n",
    "            labels = train_labels[start_batch:end_batch]\n",
    "            train, labels = get_batch_images(train, labels, img_type)\n",
    "            if not len(train) and not len(labels):\n",
    "                print(\"All images have been processed.\")\n",
    "                break;\n",
    "\n",
    "            x_batch, y_true_batch = next_batch(len(train), train, labels)\n",
    "            feed_dict_train = {x: x_batch,\n",
    "                       y_true: y_true_batch}\n",
    "            \n",
    "            session.run(optimizer, feed_dict=feed_dict_train)\n",
    "    \n",
    "            acc,co = session.run([accuracy, cost], feed_dict=feed_dict_train)\n",
    "            sum_accuracy += acc\n",
    "            n+=1\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "            print(msg.format(end_batch + 1, acc, co))\n",
    "            if i == num_epochs - 1:\n",
    "                plot_accuracy.append(acc)\n",
    "                plot_training_size.append(end_batch + 1)\n",
    "\n",
    "            start_batch += train_batch_size\n",
    "            end_batch += train_batch_size\n",
    "    \n",
    "        if save_model==True:\n",
    "            if save_name==None:\n",
    "                print(\"No model specified, model not being saved\")\n",
    "                return\n",
    "            else:\n",
    "                save_path = saver.save(session, save_name)\n",
    "                restore_model = True\n",
    "                print(\"Model saved in file: %s\" % save_name)\n",
    "        plot_accuracy_epoch.append(sum_accuracy/n)\n",
    "        plot_training_size_epoch.append(i + 1)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))  \n",
    "    print(plot_accuracy)\n",
    "    print(plot_training_size)\n",
    "    print(plot_accuracy_epoch)\n",
    "    print(plot_training_size_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance/Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Optimization Iteration:     65, Training Accuracy:  45.3%, Loss: 0.9071\n",
      "Optimization Iteration:    129, Training Accuracy:  62.5%, Loss: 0.7410\n",
      "Optimization Iteration:    193, Training Accuracy:  46.9%, Loss: 0.7863\n",
      "Optimization Iteration:    257, Training Accuracy:  46.9%, Loss: 0.8689\n",
      "Optimization Iteration:    321, Training Accuracy:  45.3%, Loss: 0.8494\n",
      "Optimization Iteration:    385, Training Accuracy:  53.1%, Loss: 0.7782\n",
      "Optimization Iteration:    449, Training Accuracy:  46.9%, Loss: 0.7702\n",
      "Optimization Iteration:    513, Training Accuracy:  53.1%, Loss: 0.7342\n",
      "Optimization Iteration:    577, Training Accuracy:  62.5%, Loss: 0.7191\n",
      "Optimization Iteration:    641, Training Accuracy:  42.2%, Loss: 0.8538\n",
      "Optimization Iteration:    705, Training Accuracy:  56.2%, Loss: 0.7670\n",
      "Optimization Iteration:    769, Training Accuracy:  56.2%, Loss: 0.7906\n",
      "Optimization Iteration:    833, Training Accuracy:  48.4%, Loss: 0.7517\n",
      "Optimization Iteration:    897, Training Accuracy:  56.2%, Loss: 0.7596\n",
      "Optimization Iteration:    961, Training Accuracy:  45.3%, Loss: 0.7899\n",
      "Optimization Iteration:   1025, Training Accuracy:  46.9%, Loss: 0.7182\n",
      "Optimization Iteration:   1089, Training Accuracy:  54.7%, Loss: 0.6876\n",
      "Optimization Iteration:   1153, Training Accuracy:  53.1%, Loss: 0.7641\n",
      "Optimization Iteration:   1217, Training Accuracy:  59.4%, Loss: 0.7357\n",
      "Optimization Iteration:   1281, Training Accuracy:  50.0%, Loss: 0.8212\n",
      "Optimization Iteration:   1345, Training Accuracy:  56.2%, Loss: 0.7378\n",
      "Optimization Iteration:   1409, Training Accuracy:  50.0%, Loss: 0.7517\n",
      "Optimization Iteration:   1473, Training Accuracy:  50.0%, Loss: 0.7510\n",
      "Optimization Iteration:   1537, Training Accuracy:  43.8%, Loss: 0.7040\n",
      "Optimization Iteration:   1601, Training Accuracy:  62.5%, Loss: 0.6873\n",
      "Optimization Iteration:   1665, Training Accuracy:  51.6%, Loss: 0.7640\n",
      "Optimization Iteration:   1729, Training Accuracy:  48.4%, Loss: 0.8098\n",
      "Optimization Iteration:   1793, Training Accuracy:  45.3%, Loss: 0.7592\n",
      "Optimization Iteration:   1857, Training Accuracy:  53.1%, Loss: 0.7012\n",
      "Optimization Iteration:   1921, Training Accuracy:  39.1%, Loss: 0.8212\n",
      "Optimization Iteration:   1985, Training Accuracy:  59.4%, Loss: 0.7279\n",
      "Optimization Iteration:   2049, Training Accuracy:  67.2%, Loss: 0.6515\n",
      "Optimization Iteration:   2113, Training Accuracy:  57.8%, Loss: 0.6645\n",
      "Optimization Iteration:   2177, Training Accuracy:  65.6%, Loss: 0.6703\n",
      "Optimization Iteration:   2241, Training Accuracy:  64.1%, Loss: 0.6362\n",
      "Optimization Iteration:   2305, Training Accuracy:  51.6%, Loss: 0.6859\n",
      "Optimization Iteration:   2369, Training Accuracy:  57.8%, Loss: 0.6859\n",
      "Optimization Iteration:   2433, Training Accuracy:  57.8%, Loss: 0.7331\n",
      "Optimization Iteration:   2497, Training Accuracy:  54.7%, Loss: 0.7354\n",
      "Optimization Iteration:   2561, Training Accuracy:  46.9%, Loss: 0.6827\n",
      "Optimization Iteration:   2625, Training Accuracy:  65.6%, Loss: 0.6447\n",
      "Optimization Iteration:   2689, Training Accuracy:  51.6%, Loss: 0.6289\n",
      "Optimization Iteration:   2753, Training Accuracy:  50.0%, Loss: 0.7209\n",
      "Optimization Iteration:   2817, Training Accuracy:  56.2%, Loss: 0.6961\n",
      "Optimization Iteration:   2881, Training Accuracy:  48.4%, Loss: 0.7744\n",
      "Optimization Iteration:   2945, Training Accuracy:  67.2%, Loss: 0.6612\n",
      "Optimization Iteration:   3009, Training Accuracy:  57.8%, Loss: 0.6723\n",
      "Optimization Iteration:   3073, Training Accuracy:  54.7%, Loss: 0.7032\n",
      "Optimization Iteration:   3137, Training Accuracy:  54.7%, Loss: 0.6525\n",
      "Optimization Iteration:   3201, Training Accuracy:  54.7%, Loss: 0.6486\n",
      "Optimization Iteration:   3265, Training Accuracy:  54.7%, Loss: 0.7381\n",
      "Optimization Iteration:   3329, Training Accuracy:  51.6%, Loss: 0.6841\n",
      "Optimization Iteration:   3393, Training Accuracy:  46.9%, Loss: 0.7239\n",
      "Optimization Iteration:   3457, Training Accuracy:  57.8%, Loss: 0.7233\n",
      "Optimization Iteration:   3521, Training Accuracy:  50.0%, Loss: 0.7204\n",
      "Optimization Iteration:   3585, Training Accuracy:  54.7%, Loss: 0.6677\n",
      "Optimization Iteration:   3649, Training Accuracy:  57.8%, Loss: 0.6643\n",
      "Optimization Iteration:   3713, Training Accuracy:  48.4%, Loss: 0.6821\n",
      "Optimization Iteration:   3777, Training Accuracy:  57.8%, Loss: 0.6698\n",
      "Optimization Iteration:   3841, Training Accuracy:  62.5%, Loss: 0.6734\n",
      "Optimization Iteration:   3905, Training Accuracy:  53.1%, Loss: 0.7333\n",
      "Optimization Iteration:   3969, Training Accuracy:  53.1%, Loss: 0.6765\n",
      "Optimization Iteration:   4033, Training Accuracy:  46.9%, Loss: 0.6833\n",
      "Optimization Iteration:   4097, Training Accuracy:  62.5%, Loss: 0.6345\n",
      "Optimization Iteration:   4161, Training Accuracy:  56.2%, Loss: 0.6322\n",
      "Optimization Iteration:   4225, Training Accuracy:  48.4%, Loss: 0.6969\n",
      "Optimization Iteration:   4289, Training Accuracy:  64.1%, Loss: 0.6467\n",
      "Optimization Iteration:   4353, Training Accuracy:  53.1%, Loss: 0.7263\n",
      "Optimization Iteration:   4417, Training Accuracy:  57.8%, Loss: 0.7065\n",
      "Optimization Iteration:   4481, Training Accuracy:  53.1%, Loss: 0.7075\n",
      "Optimization Iteration:   4545, Training Accuracy:  56.2%, Loss: 0.6725\n",
      "Optimization Iteration:   4609, Training Accuracy:  50.0%, Loss: 0.6818\n",
      "Optimization Iteration:   4673, Training Accuracy:  48.4%, Loss: 0.6991\n",
      "Optimization Iteration:   4737, Training Accuracy:  57.8%, Loss: 0.6521\n",
      "Optimization Iteration:   4801, Training Accuracy:  48.4%, Loss: 0.7299\n",
      "Optimization Iteration:   4865, Training Accuracy:  56.2%, Loss: 0.6814\n",
      "Optimization Iteration:   4929, Training Accuracy:  53.1%, Loss: 0.6670\n",
      "Optimization Iteration:   4993, Training Accuracy:  59.4%, Loss: 0.6558\n",
      "Optimization Iteration:   5057, Training Accuracy:  64.1%, Loss: 0.6067\n",
      "Optimization Iteration:   5121, Training Accuracy:  60.9%, Loss: 0.6821\n",
      "Optimization Iteration:   5185, Training Accuracy:  65.6%, Loss: 0.6394\n",
      "Optimization Iteration:   5249, Training Accuracy:  62.5%, Loss: 0.6608\n",
      "Optimization Iteration:   5313, Training Accuracy:  65.6%, Loss: 0.6841\n",
      "Optimization Iteration:   5377, Training Accuracy:  59.4%, Loss: 0.6481\n",
      "Optimization Iteration:   5441, Training Accuracy:  51.6%, Loss: 0.7391\n",
      "Optimization Iteration:   5505, Training Accuracy:  68.8%, Loss: 0.6468\n",
      "Optimization Iteration:   5569, Training Accuracy:  54.7%, Loss: 0.6935\n",
      "Optimization Iteration:   5633, Training Accuracy:  46.9%, Loss: 0.7423\n",
      "Optimization Iteration:   5697, Training Accuracy:  59.4%, Loss: 0.7060\n",
      "Optimization Iteration:   5761, Training Accuracy:  53.1%, Loss: 0.6590\n",
      "Optimization Iteration:   5825, Training Accuracy:  54.7%, Loss: 0.7194\n",
      "Optimization Iteration:   5889, Training Accuracy:  60.9%, Loss: 0.6591\n",
      "Optimization Iteration:   5953, Training Accuracy:  56.2%, Loss: 0.6662\n",
      "Optimization Iteration:   6017, Training Accuracy:  48.4%, Loss: 0.7325\n",
      "Optimization Iteration:   6081, Training Accuracy:  64.1%, Loss: 0.6943\n",
      "Optimization Iteration:   6145, Training Accuracy:  60.9%, Loss: 0.6468\n",
      "Optimization Iteration:   6209, Training Accuracy:  53.1%, Loss: 0.7099\n",
      "Optimization Iteration:   6273, Training Accuracy:  67.2%, Loss: 0.6305\n",
      "Optimization Iteration:   6337, Training Accuracy:  67.2%, Loss: 0.6362\n",
      "Optimization Iteration:   6401, Training Accuracy:  53.1%, Loss: 0.6551\n",
      "Optimization Iteration:   6465, Training Accuracy:  64.1%, Loss: 0.6461\n",
      "Optimization Iteration:   6529, Training Accuracy:  67.2%, Loss: 0.6406\n",
      "Optimization Iteration:   6593, Training Accuracy:  45.3%, Loss: 0.8515\n",
      "Optimization Iteration:   6657, Training Accuracy:  53.1%, Loss: 0.7159\n",
      "Optimization Iteration:   6721, Training Accuracy:  45.3%, Loss: 0.7517\n",
      "Optimization Iteration:   6785, Training Accuracy:  56.2%, Loss: 0.6980\n",
      "Optimization Iteration:   6849, Training Accuracy:  56.2%, Loss: 0.6934\n",
      "Optimization Iteration:   6913, Training Accuracy:  60.9%, Loss: 0.6550\n",
      "Optimization Iteration:   6977, Training Accuracy:  46.9%, Loss: 0.7150\n",
      "Optimization Iteration:   7041, Training Accuracy:  65.6%, Loss: 0.6624\n",
      "Optimization Iteration:   7105, Training Accuracy:  65.6%, Loss: 0.6199\n",
      "Optimization Iteration:   7169, Training Accuracy:  56.2%, Loss: 0.6484\n",
      "Optimization Iteration:   7233, Training Accuracy:  51.6%, Loss: 0.6856\n",
      "Optimization Iteration:   7297, Training Accuracy:  60.9%, Loss: 0.6912\n",
      "Optimization Iteration:   7361, Training Accuracy:  60.9%, Loss: 0.6344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7425, Training Accuracy:  48.4%, Loss: 0.7689\n",
      "Optimization Iteration:   7489, Training Accuracy:  64.1%, Loss: 0.6543\n",
      "Optimization Iteration:   7553, Training Accuracy:  50.0%, Loss: 0.7121\n",
      "Optimization Iteration:   7617, Training Accuracy:  48.4%, Loss: 0.7050\n",
      "Optimization Iteration:   7681, Training Accuracy:  51.6%, Loss: 0.7540\n",
      "Optimization Iteration:   7745, Training Accuracy:  48.4%, Loss: 0.6792\n",
      "Optimization Iteration:   7809, Training Accuracy:  46.9%, Loss: 0.7398\n",
      "Optimization Iteration:   7873, Training Accuracy:  51.6%, Loss: 0.6874\n",
      "Optimization Iteration:   7937, Training Accuracy:  59.4%, Loss: 0.6795\n",
      "Optimization Iteration:   8001, Training Accuracy:  45.3%, Loss: 0.7515\n",
      "Optimization Iteration:   8065, Training Accuracy:  51.6%, Loss: 0.6822\n",
      "Optimization Iteration:   8129, Training Accuracy:  56.2%, Loss: 0.7010\n",
      "Optimization Iteration:   8193, Training Accuracy:  53.1%, Loss: 0.6550\n",
      "Optimization Iteration:   8257, Training Accuracy:  50.0%, Loss: 0.7179\n",
      "Optimization Iteration:   8321, Training Accuracy:  56.2%, Loss: 0.7318\n",
      "Optimization Iteration:   8385, Training Accuracy:  57.8%, Loss: 0.6866\n",
      "Optimization Iteration:   8449, Training Accuracy:  56.2%, Loss: 0.6879\n",
      "Optimization Iteration:   8513, Training Accuracy:  57.8%, Loss: 0.6701\n",
      "Optimization Iteration:   8577, Training Accuracy:  53.1%, Loss: 0.6916\n",
      "Optimization Iteration:   8641, Training Accuracy:  65.6%, Loss: 0.6148\n",
      "Optimization Iteration:   8705, Training Accuracy:  40.6%, Loss: 0.7417\n",
      "Optimization Iteration:   8769, Training Accuracy:  57.8%, Loss: 0.6472\n",
      "Optimization Iteration:   8833, Training Accuracy:  43.8%, Loss: 0.7376\n",
      "Optimization Iteration:   8897, Training Accuracy:  54.7%, Loss: 0.6826\n",
      "Optimization Iteration:   8961, Training Accuracy:  54.7%, Loss: 0.6753\n",
      "Optimization Iteration:   9025, Training Accuracy:  43.8%, Loss: 0.7722\n",
      "Optimization Iteration:   9089, Training Accuracy:  46.9%, Loss: 0.7188\n",
      "Optimization Iteration:   9153, Training Accuracy:  53.1%, Loss: 0.6613\n",
      "Optimization Iteration:   9217, Training Accuracy:  60.9%, Loss: 0.6364\n",
      "Optimization Iteration:   9281, Training Accuracy:  53.1%, Loss: 0.6701\n",
      "Optimization Iteration:   9345, Training Accuracy:  75.0%, Loss: 0.5754\n",
      "Optimization Iteration:   9409, Training Accuracy:  60.9%, Loss: 0.6866\n",
      "Optimization Iteration:   9473, Training Accuracy:  35.9%, Loss: 0.8028\n",
      "Optimization Iteration:   9537, Training Accuracy:  50.0%, Loss: 0.7010\n",
      "Optimization Iteration:   9601, Training Accuracy:  62.5%, Loss: 0.6111\n",
      "Optimization Iteration:   9665, Training Accuracy:  53.1%, Loss: 0.6679\n",
      "Optimization Iteration:   9729, Training Accuracy:  54.7%, Loss: 0.6621\n",
      "Optimization Iteration:   9793, Training Accuracy:  54.7%, Loss: 0.6689\n",
      "Optimization Iteration:   9857, Training Accuracy:  48.4%, Loss: 0.7683\n",
      "Optimization Iteration:   9921, Training Accuracy:  56.2%, Loss: 0.6405\n",
      "Optimization Iteration:   9985, Training Accuracy:  54.7%, Loss: 0.7360\n",
      "Optimization Iteration:  10049, Training Accuracy:  54.7%, Loss: 0.6692\n",
      "Optimization Iteration:  10113, Training Accuracy:  53.1%, Loss: 0.6896\n",
      "Optimization Iteration:  10177, Training Accuracy:  53.1%, Loss: 0.7143\n",
      "Optimization Iteration:  10241, Training Accuracy:  67.2%, Loss: 0.6097\n",
      "Optimization Iteration:  10305, Training Accuracy:  59.4%, Loss: 0.7292\n",
      "Optimization Iteration:  10369, Training Accuracy:  51.6%, Loss: 0.6710\n",
      "Optimization Iteration:  10433, Training Accuracy:  60.9%, Loss: 0.6050\n",
      "Optimization Iteration:  10497, Training Accuracy:  50.0%, Loss: 0.7678\n",
      "Optimization Iteration:  10561, Training Accuracy:  54.7%, Loss: 0.6876\n",
      "Optimization Iteration:  10625, Training Accuracy:  51.6%, Loss: 0.6359\n",
      "Optimization Iteration:  10689, Training Accuracy:  60.9%, Loss: 0.6671\n",
      "Optimization Iteration:  10753, Training Accuracy:  60.9%, Loss: 0.6338\n",
      "Optimization Iteration:  10817, Training Accuracy:  53.1%, Loss: 0.7311\n",
      "Optimization Iteration:  10881, Training Accuracy:  48.4%, Loss: 0.7043\n",
      "Optimization Iteration:  10945, Training Accuracy:  64.1%, Loss: 0.6676\n",
      "Optimization Iteration:  11009, Training Accuracy:  65.6%, Loss: 0.6354\n",
      "Optimization Iteration:  11073, Training Accuracy:  59.4%, Loss: 0.6156\n",
      "Optimization Iteration:  11137, Training Accuracy:  54.7%, Loss: 0.6676\n",
      "Optimization Iteration:  11201, Training Accuracy:  67.2%, Loss: 0.6407\n",
      "Optimization Iteration:  11265, Training Accuracy:  60.9%, Loss: 0.6408\n",
      "Optimization Iteration:  11329, Training Accuracy:  50.0%, Loss: 0.7418\n",
      "Optimization Iteration:  11393, Training Accuracy:  62.5%, Loss: 0.6792\n",
      "Optimization Iteration:  11457, Training Accuracy:  64.1%, Loss: 0.6405\n",
      "Optimization Iteration:  11521, Training Accuracy:  53.1%, Loss: 0.7031\n",
      "Optimization Iteration:  11585, Training Accuracy:  51.6%, Loss: 0.7452\n",
      "Optimization Iteration:  11649, Training Accuracy:  51.6%, Loss: 0.6998\n",
      "Optimization Iteration:  11713, Training Accuracy:  60.9%, Loss: 0.6101\n",
      "Optimization Iteration:  11777, Training Accuracy:  60.9%, Loss: 0.6146\n",
      "Optimization Iteration:  11841, Training Accuracy:  67.2%, Loss: 0.6207\n",
      "Optimization Iteration:  11905, Training Accuracy:  65.6%, Loss: 0.6753\n",
      "Optimization Iteration:  11969, Training Accuracy:  65.6%, Loss: 0.6373\n",
      "Optimization Iteration:  12033, Training Accuracy:  57.8%, Loss: 0.7444\n",
      "Optimization Iteration:  12097, Training Accuracy:  54.7%, Loss: 0.7101\n",
      "Optimization Iteration:  12161, Training Accuracy:  62.5%, Loss: 0.6101\n",
      "Optimization Iteration:  12225, Training Accuracy:  64.1%, Loss: 0.6540\n",
      "Optimization Iteration:  12289, Training Accuracy:  60.9%, Loss: 0.6364\n",
      "Optimization Iteration:  12353, Training Accuracy:  60.9%, Loss: 0.6303\n",
      "Optimization Iteration:  12417, Training Accuracy:  64.1%, Loss: 0.6690\n",
      "Optimization Iteration:  12481, Training Accuracy:  59.4%, Loss: 0.6822\n",
      "Optimization Iteration:  12545, Training Accuracy:  65.6%, Loss: 0.6528\n",
      "Optimization Iteration:  12609, Training Accuracy:  53.1%, Loss: 0.6874\n",
      "Optimization Iteration:  12673, Training Accuracy:  54.7%, Loss: 0.7073\n",
      "Optimization Iteration:  12737, Training Accuracy:  59.4%, Loss: 0.6848\n",
      "Optimization Iteration:  12801, Training Accuracy:  62.5%, Loss: 0.6217\n",
      "Optimization Iteration:  12865, Training Accuracy:  57.8%, Loss: 0.6885\n",
      "Optimization Iteration:  12929, Training Accuracy:  51.6%, Loss: 0.6529\n",
      "Optimization Iteration:  12993, Training Accuracy:  53.1%, Loss: 0.7030\n",
      "Optimization Iteration:  13057, Training Accuracy:  64.1%, Loss: 0.6426\n",
      "Optimization Iteration:  13121, Training Accuracy:  54.7%, Loss: 0.7049\n",
      "Optimization Iteration:  13185, Training Accuracy:  57.8%, Loss: 0.7007\n",
      "Optimization Iteration:  13249, Training Accuracy:  64.1%, Loss: 0.6414\n",
      "Optimization Iteration:  13313, Training Accuracy:  62.5%, Loss: 0.6116\n",
      "Optimization Iteration:  13377, Training Accuracy:  65.6%, Loss: 0.6726\n",
      "Optimization Iteration:  13441, Training Accuracy:  53.1%, Loss: 0.6756\n",
      "Optimization Iteration:  13505, Training Accuracy:  64.1%, Loss: 0.6341\n",
      "Optimization Iteration:  13569, Training Accuracy:  56.2%, Loss: 0.6992\n",
      "Optimization Iteration:  13633, Training Accuracy:  67.2%, Loss: 0.5840\n",
      "Optimization Iteration:  13697, Training Accuracy:  65.6%, Loss: 0.6447\n",
      "Optimization Iteration:  13761, Training Accuracy:  60.9%, Loss: 0.6838\n",
      "Optimization Iteration:  13825, Training Accuracy:  50.0%, Loss: 0.7985\n",
      "Optimization Iteration:  13889, Training Accuracy:  68.8%, Loss: 0.6472\n",
      "Optimization Iteration:  13953, Training Accuracy:  57.8%, Loss: 0.6549\n",
      "Optimization Iteration:  14017, Training Accuracy:  56.2%, Loss: 0.7120\n",
      "Optimization Iteration:  14081, Training Accuracy:  46.9%, Loss: 0.7105\n",
      "Optimization Iteration:  14145, Training Accuracy:  48.4%, Loss: 0.7233\n",
      "Optimization Iteration:  14209, Training Accuracy:  56.2%, Loss: 0.7549\n",
      "Optimization Iteration:  14273, Training Accuracy:  53.1%, Loss: 0.6318\n",
      "Optimization Iteration:  14337, Training Accuracy:  60.9%, Loss: 0.6683\n",
      "Optimization Iteration:  14401, Training Accuracy:  60.9%, Loss: 0.7028\n",
      "Optimization Iteration:  14465, Training Accuracy:  57.8%, Loss: 0.6421\n",
      "Optimization Iteration:  14529, Training Accuracy:  65.6%, Loss: 0.6617\n",
      "Optimization Iteration:  14593, Training Accuracy:  60.9%, Loss: 0.6964\n",
      "Optimization Iteration:  14657, Training Accuracy:  57.8%, Loss: 0.6705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  14721, Training Accuracy:  65.6%, Loss: 0.6715\n",
      "Optimization Iteration:  14785, Training Accuracy:  62.5%, Loss: 0.5907\n",
      "Optimization Iteration:  14849, Training Accuracy:  59.4%, Loss: 0.6340\n",
      "Optimization Iteration:  14913, Training Accuracy:  62.5%, Loss: 0.6507\n",
      "Optimization Iteration:  14977, Training Accuracy:  56.2%, Loss: 0.7099\n",
      "Optimization Iteration:  15041, Training Accuracy:  50.0%, Loss: 0.6905\n",
      "Optimization Iteration:  15105, Training Accuracy:  57.8%, Loss: 0.6596\n",
      "Optimization Iteration:  15169, Training Accuracy:  65.6%, Loss: 0.6359\n",
      "Optimization Iteration:  15233, Training Accuracy:  60.9%, Loss: 0.6494\n",
      "Optimization Iteration:  15297, Training Accuracy:  60.9%, Loss: 0.6174\n",
      "Optimization Iteration:  15361, Training Accuracy:  65.6%, Loss: 0.6131\n",
      "Optimization Iteration:  15425, Training Accuracy:  57.8%, Loss: 0.6680\n",
      "Optimization Iteration:  15489, Training Accuracy:  56.2%, Loss: 0.6638\n",
      "Optimization Iteration:  15553, Training Accuracy:  54.7%, Loss: 0.6195\n",
      "Optimization Iteration:  15617, Training Accuracy:  64.1%, Loss: 0.6008\n",
      "Optimization Iteration:  15681, Training Accuracy:  59.4%, Loss: 0.6688\n",
      "Optimization Iteration:  15745, Training Accuracy:  60.9%, Loss: 0.6246\n",
      "Optimization Iteration:  15809, Training Accuracy:  60.9%, Loss: 0.6776\n",
      "Optimization Iteration:  15873, Training Accuracy:  64.1%, Loss: 0.6585\n",
      "Optimization Iteration:  15937, Training Accuracy:  56.2%, Loss: 0.6220\n",
      "Optimization Iteration:  16001, Training Accuracy:  53.1%, Loss: 0.7142\n",
      "Optimization Iteration:  16065, Training Accuracy:  48.4%, Loss: 0.6641\n",
      "Optimization Iteration:  16129, Training Accuracy:  48.4%, Loss: 0.7038\n",
      "Optimization Iteration:  16193, Training Accuracy:  75.0%, Loss: 0.6020\n",
      "Optimization Iteration:  16257, Training Accuracy:  57.8%, Loss: 0.7115\n",
      "Optimization Iteration:  16321, Training Accuracy:  57.8%, Loss: 0.6276\n",
      "Optimization Iteration:  16385, Training Accuracy:  59.4%, Loss: 0.6349\n",
      "Optimization Iteration:  16449, Training Accuracy:  60.9%, Loss: 0.6825\n",
      "Optimization Iteration:  16513, Training Accuracy:  54.7%, Loss: 0.6449\n",
      "Optimization Iteration:  16577, Training Accuracy:  57.8%, Loss: 0.6661\n",
      "Optimization Iteration:  16641, Training Accuracy:  56.2%, Loss: 0.6956\n",
      "Optimization Iteration:  16705, Training Accuracy:  57.8%, Loss: 0.6551\n",
      "Optimization Iteration:  16769, Training Accuracy:  65.6%, Loss: 0.6319\n",
      "Optimization Iteration:  16833, Training Accuracy:  56.2%, Loss: 0.6625\n",
      "Optimization Iteration:  16897, Training Accuracy:  62.5%, Loss: 0.6820\n",
      "Optimization Iteration:  16961, Training Accuracy:  54.7%, Loss: 0.6825\n",
      "Optimization Iteration:  17025, Training Accuracy:  59.4%, Loss: 0.6849\n",
      "Optimization Iteration:  17089, Training Accuracy:  62.5%, Loss: 0.6827\n",
      "Optimization Iteration:  17153, Training Accuracy:  60.9%, Loss: 0.6936\n",
      "Optimization Iteration:  17217, Training Accuracy:  59.4%, Loss: 0.6651\n",
      "Optimization Iteration:  17281, Training Accuracy:  59.4%, Loss: 0.6948\n",
      "Optimization Iteration:  17345, Training Accuracy:  48.4%, Loss: 0.7542\n",
      "Optimization Iteration:  17409, Training Accuracy:  60.9%, Loss: 0.6271\n",
      "Optimization Iteration:  17473, Training Accuracy:  56.2%, Loss: 0.6499\n",
      "Optimization Iteration:  17537, Training Accuracy:  46.9%, Loss: 0.7197\n",
      "Optimization Iteration:  17601, Training Accuracy:  53.1%, Loss: 0.6621\n",
      "Optimization Iteration:  17665, Training Accuracy:  64.1%, Loss: 0.6465\n",
      "Optimization Iteration:  17729, Training Accuracy:  53.1%, Loss: 0.7226\n",
      "Optimization Iteration:  17793, Training Accuracy:  54.7%, Loss: 0.6799\n",
      "Optimization Iteration:  17857, Training Accuracy:  60.9%, Loss: 0.7043\n",
      "Optimization Iteration:  17921, Training Accuracy:  59.4%, Loss: 0.6583\n",
      "Optimization Iteration:  17985, Training Accuracy:  53.1%, Loss: 0.6880\n",
      "Optimization Iteration:  18049, Training Accuracy:  56.2%, Loss: 0.6472\n",
      "Optimization Iteration:  18113, Training Accuracy:  54.7%, Loss: 0.6785\n",
      "Optimization Iteration:  18177, Training Accuracy:  54.7%, Loss: 0.6914\n",
      "Optimization Iteration:  18241, Training Accuracy:  53.1%, Loss: 0.6331\n",
      "Optimization Iteration:  18305, Training Accuracy:  59.4%, Loss: 0.6140\n",
      "Optimization Iteration:  18369, Training Accuracy:  54.7%, Loss: 0.6493\n",
      "Optimization Iteration:  18433, Training Accuracy:  57.8%, Loss: 0.6952\n",
      "Optimization Iteration:  18497, Training Accuracy:  48.4%, Loss: 0.6804\n",
      "Optimization Iteration:  18561, Training Accuracy:  54.7%, Loss: 0.7144\n",
      "Optimization Iteration:  18625, Training Accuracy:  53.1%, Loss: 0.7184\n",
      "Optimization Iteration:  18689, Training Accuracy:  53.1%, Loss: 0.6800\n",
      "Optimization Iteration:  18753, Training Accuracy:  56.2%, Loss: 0.6614\n",
      "Optimization Iteration:  18817, Training Accuracy:  53.1%, Loss: 0.6833\n",
      "Optimization Iteration:  18881, Training Accuracy:  64.1%, Loss: 0.6222\n",
      "Optimization Iteration:  18945, Training Accuracy:  57.8%, Loss: 0.6449\n",
      "Optimization Iteration:  19009, Training Accuracy:  53.1%, Loss: 0.6562\n",
      "Optimization Iteration:  19073, Training Accuracy:  64.1%, Loss: 0.6771\n",
      "Optimization Iteration:  19137, Training Accuracy:  68.8%, Loss: 0.6542\n",
      "Optimization Iteration:  19201, Training Accuracy:  64.1%, Loss: 0.6703\n",
      "Optimization Iteration:  19265, Training Accuracy:  57.8%, Loss: 0.6379\n",
      "Optimization Iteration:  19329, Training Accuracy:  57.8%, Loss: 0.6452\n",
      "Optimization Iteration:  19393, Training Accuracy:  62.5%, Loss: 0.6556\n",
      "Optimization Iteration:  19457, Training Accuracy:  64.1%, Loss: 0.6212\n",
      "Optimization Iteration:  19521, Training Accuracy:  65.6%, Loss: 0.6270\n",
      "Optimization Iteration:  19585, Training Accuracy:  68.8%, Loss: 0.6023\n",
      "Optimization Iteration:  19649, Training Accuracy:  65.6%, Loss: 0.6182\n",
      "Optimization Iteration:  19713, Training Accuracy:  65.6%, Loss: 0.6262\n",
      "Optimization Iteration:  19777, Training Accuracy:  64.1%, Loss: 0.6572\n",
      "Optimization Iteration:  19841, Training Accuracy:  50.0%, Loss: 0.6454\n",
      "Optimization Iteration:  19905, Training Accuracy:  46.9%, Loss: 0.7299\n",
      "Optimization Iteration:  19969, Training Accuracy:  60.9%, Loss: 0.5967\n",
      "Optimization Iteration:  20033, Training Accuracy:  54.7%, Loss: 0.6952\n",
      "Optimization Iteration:  20097, Training Accuracy:  54.7%, Loss: 0.6714\n",
      "Optimization Iteration:  20161, Training Accuracy:  50.0%, Loss: 0.6924\n",
      "Optimization Iteration:  20225, Training Accuracy:  51.6%, Loss: 0.7683\n",
      "Optimization Iteration:  20289, Training Accuracy:  53.1%, Loss: 0.6917\n",
      "Optimization Iteration:  20353, Training Accuracy:  59.4%, Loss: 0.6641\n",
      "Optimization Iteration:  20417, Training Accuracy:  56.2%, Loss: 0.6868\n",
      "Optimization Iteration:  20481, Training Accuracy:  62.5%, Loss: 0.5980\n",
      "Optimization Iteration:  20545, Training Accuracy:  54.7%, Loss: 0.7316\n",
      "Optimization Iteration:  20609, Training Accuracy:  50.0%, Loss: 0.7062\n",
      "Optimization Iteration:  20673, Training Accuracy:  53.1%, Loss: 0.6745\n",
      "Optimization Iteration:  20737, Training Accuracy:  64.1%, Loss: 0.6260\n",
      "Optimization Iteration:  20801, Training Accuracy:  53.1%, Loss: 0.7193\n",
      "Optimization Iteration:  20865, Training Accuracy:  57.8%, Loss: 0.6646\n",
      "Optimization Iteration:  20929, Training Accuracy:  57.8%, Loss: 0.6154\n",
      "Optimization Iteration:  20993, Training Accuracy:  60.9%, Loss: 0.6368\n",
      "Optimization Iteration:  21057, Training Accuracy:  62.5%, Loss: 0.6805\n",
      "Optimization Iteration:  21121, Training Accuracy:  50.0%, Loss: 0.6816\n",
      "Optimization Iteration:  21185, Training Accuracy:  56.2%, Loss: 0.6688\n",
      "Optimization Iteration:  21249, Training Accuracy:  53.1%, Loss: 0.6646\n",
      "Optimization Iteration:  21313, Training Accuracy:  54.7%, Loss: 0.6843\n",
      "Optimization Iteration:  21377, Training Accuracy:  59.4%, Loss: 0.6347\n",
      "Optimization Iteration:  21441, Training Accuracy:  65.6%, Loss: 0.5617\n",
      "Optimization Iteration:  21505, Training Accuracy:  53.1%, Loss: 0.6792\n",
      "Optimization Iteration:  21569, Training Accuracy:  53.1%, Loss: 0.6685\n",
      "Optimization Iteration:  21633, Training Accuracy:  60.9%, Loss: 0.6579\n",
      "Optimization Iteration:  21697, Training Accuracy:  57.8%, Loss: 0.6277\n",
      "Optimization Iteration:  21761, Training Accuracy:  57.8%, Loss: 0.5864\n",
      "Optimization Iteration:  21825, Training Accuracy:  51.6%, Loss: 0.6687\n",
      "Optimization Iteration:  21889, Training Accuracy:  54.7%, Loss: 0.6695\n",
      "Optimization Iteration:  21953, Training Accuracy:  56.2%, Loss: 0.6175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  22017, Training Accuracy:  53.1%, Loss: 0.7165\n",
      "Optimization Iteration:  22081, Training Accuracy:  71.9%, Loss: 0.6208\n",
      "Optimization Iteration:  22145, Training Accuracy:  71.9%, Loss: 0.6132\n",
      "Optimization Iteration:  22209, Training Accuracy:  65.6%, Loss: 0.6455\n",
      "Optimization Iteration:  22273, Training Accuracy:  48.4%, Loss: 0.7114\n",
      "Optimization Iteration:  22337, Training Accuracy:  57.8%, Loss: 0.6938\n",
      "Optimization Iteration:  22401, Training Accuracy:  45.3%, Loss: 0.6649\n",
      "Optimization Iteration:  22465, Training Accuracy:  64.1%, Loss: 0.6353\n",
      "Optimization Iteration:  22529, Training Accuracy:  64.1%, Loss: 0.6007\n",
      "Optimization Iteration:  22593, Training Accuracy:  60.9%, Loss: 0.7418\n",
      "Optimization Iteration:  22657, Training Accuracy:  54.7%, Loss: 0.7358\n",
      "Optimization Iteration:  22721, Training Accuracy:  67.2%, Loss: 0.6287\n",
      "Optimization Iteration:  22785, Training Accuracy:  51.6%, Loss: 0.7041\n",
      "Optimization Iteration:  22849, Training Accuracy:  67.2%, Loss: 0.6061\n",
      "Optimization Iteration:  22913, Training Accuracy:  60.9%, Loss: 0.6813\n",
      "Optimization Iteration:  22977, Training Accuracy:  50.0%, Loss: 0.6964\n",
      "Optimization Iteration:  23041, Training Accuracy:  51.6%, Loss: 0.6687\n",
      "Optimization Iteration:  23105, Training Accuracy:  60.9%, Loss: 0.6273\n",
      "Optimization Iteration:  23169, Training Accuracy:  67.2%, Loss: 0.6100\n",
      "Optimization Iteration:  23233, Training Accuracy:  68.8%, Loss: 0.5847\n",
      "Optimization Iteration:  23297, Training Accuracy:  53.1%, Loss: 0.7620\n",
      "Optimization Iteration:  23361, Training Accuracy:  67.2%, Loss: 0.6249\n",
      "Optimization Iteration:  23425, Training Accuracy:  64.1%, Loss: 0.6815\n",
      "Optimization Iteration:  23489, Training Accuracy:  57.8%, Loss: 0.6547\n",
      "Optimization Iteration:  23553, Training Accuracy:  54.7%, Loss: 0.6912\n",
      "Optimization Iteration:  23617, Training Accuracy:  59.4%, Loss: 0.6594\n",
      "Optimization Iteration:  23681, Training Accuracy:  51.6%, Loss: 0.7435\n",
      "Optimization Iteration:  23745, Training Accuracy:  50.0%, Loss: 0.6838\n",
      "Optimization Iteration:  23809, Training Accuracy:  65.6%, Loss: 0.6639\n",
      "Optimization Iteration:  23873, Training Accuracy:  59.4%, Loss: 0.6530\n",
      "Optimization Iteration:  23937, Training Accuracy:  60.9%, Loss: 0.6318\n",
      "Optimization Iteration:  24001, Training Accuracy:  70.3%, Loss: 0.5827\n",
      "Optimization Iteration:  24065, Training Accuracy:  59.4%, Loss: 0.6450\n",
      "Optimization Iteration:  24129, Training Accuracy:  54.7%, Loss: 0.6698\n",
      "Optimization Iteration:  24193, Training Accuracy:  62.5%, Loss: 0.6003\n",
      "Optimization Iteration:  24257, Training Accuracy:  57.8%, Loss: 0.7191\n",
      "Optimization Iteration:  24321, Training Accuracy:  68.8%, Loss: 0.5789\n",
      "Optimization Iteration:  24385, Training Accuracy:  59.4%, Loss: 0.6540\n",
      "Optimization Iteration:  24449, Training Accuracy:  62.5%, Loss: 0.6463\n",
      "Optimization Iteration:  24513, Training Accuracy:  62.5%, Loss: 0.6445\n",
      "Optimization Iteration:  24577, Training Accuracy:  56.2%, Loss: 0.6545\n",
      "Optimization Iteration:  24641, Training Accuracy:  53.1%, Loss: 0.6267\n",
      "Optimization Iteration:  24705, Training Accuracy:  62.5%, Loss: 0.6412\n",
      "Optimization Iteration:  24769, Training Accuracy:  59.4%, Loss: 0.6605\n",
      "Optimization Iteration:  24833, Training Accuracy:  54.7%, Loss: 0.6411\n",
      "Optimization Iteration:  24897, Training Accuracy:  59.4%, Loss: 0.6524\n",
      "Optimization Iteration:  24961, Training Accuracy:  67.2%, Loss: 0.5837\n",
      "Optimization Iteration:  25025, Training Accuracy:  56.2%, Loss: 0.6706\n",
      "Optimization Iteration:  25089, Training Accuracy:  62.5%, Loss: 0.6128\n",
      "Optimization Iteration:  25153, Training Accuracy:  59.4%, Loss: 0.6153\n",
      "Optimization Iteration:  25217, Training Accuracy:  50.0%, Loss: 0.6467\n",
      "Optimization Iteration:  25281, Training Accuracy:  60.9%, Loss: 0.6690\n",
      "Optimization Iteration:  25345, Training Accuracy:  70.3%, Loss: 0.6278\n",
      "Optimization Iteration:  25409, Training Accuracy:  56.2%, Loss: 0.6778\n",
      "Optimization Iteration:  25473, Training Accuracy:  48.4%, Loss: 0.7079\n",
      "Optimization Iteration:  25537, Training Accuracy:  65.6%, Loss: 0.6346\n",
      "Optimization Iteration:  25601, Training Accuracy:  68.8%, Loss: 0.6233\n",
      "Optimization Iteration:  25665, Training Accuracy:  73.4%, Loss: 0.6250\n",
      "Optimization Iteration:  25729, Training Accuracy:  48.4%, Loss: 0.6380\n",
      "Optimization Iteration:  25793, Training Accuracy:  59.4%, Loss: 0.6207\n",
      "Optimization Iteration:  25857, Training Accuracy:  56.2%, Loss: 0.6480\n",
      "Optimization Iteration:  25921, Training Accuracy:  65.6%, Loss: 0.6286\n",
      "Optimization Iteration:  25985, Training Accuracy:  56.2%, Loss: 0.6907\n",
      "Optimization Iteration:  26049, Training Accuracy:  62.5%, Loss: 0.6161\n",
      "Optimization Iteration:  26113, Training Accuracy:  65.6%, Loss: 0.6243\n",
      "Optimization Iteration:  26177, Training Accuracy:  65.6%, Loss: 0.6424\n",
      "Optimization Iteration:  26241, Training Accuracy:  65.6%, Loss: 0.6249\n",
      "Optimization Iteration:  26305, Training Accuracy:  57.8%, Loss: 0.6371\n",
      "Optimization Iteration:  26369, Training Accuracy:  64.1%, Loss: 0.6153\n",
      "Optimization Iteration:  26433, Training Accuracy:  50.0%, Loss: 0.6993\n",
      "Optimization Iteration:  26497, Training Accuracy:  60.9%, Loss: 0.6894\n",
      "Optimization Iteration:  26561, Training Accuracy:  60.9%, Loss: 0.6712\n",
      "Optimization Iteration:  26625, Training Accuracy:  65.6%, Loss: 0.6373\n",
      "Optimization Iteration:  26689, Training Accuracy:  56.2%, Loss: 0.6381\n",
      "Optimization Iteration:  26753, Training Accuracy:  59.4%, Loss: 0.6452\n",
      "Optimization Iteration:  26817, Training Accuracy:  68.8%, Loss: 0.6206\n",
      "Optimization Iteration:  26881, Training Accuracy:  73.4%, Loss: 0.5853\n",
      "Optimization Iteration:  26945, Training Accuracy:  64.1%, Loss: 0.5854\n",
      "Optimization Iteration:  27009, Training Accuracy:  53.1%, Loss: 0.7041\n",
      "Optimization Iteration:  27073, Training Accuracy:  70.3%, Loss: 0.6670\n",
      "Optimization Iteration:  27137, Training Accuracy:  65.6%, Loss: 0.6446\n",
      "Optimization Iteration:  27201, Training Accuracy:  71.9%, Loss: 0.5695\n",
      "Optimization Iteration:  27265, Training Accuracy:  59.4%, Loss: 0.6592\n",
      "Optimization Iteration:  27329, Training Accuracy:  60.9%, Loss: 0.7054\n",
      "Optimization Iteration:  27393, Training Accuracy:  57.8%, Loss: 0.6169\n",
      "Optimization Iteration:  27457, Training Accuracy:  57.8%, Loss: 0.6530\n",
      "Optimization Iteration:  27521, Training Accuracy:  70.3%, Loss: 0.6025\n",
      "Optimization Iteration:  27585, Training Accuracy:  62.5%, Loss: 0.6215\n",
      "Optimization Iteration:  27649, Training Accuracy:  67.2%, Loss: 0.6986\n",
      "Optimization Iteration:  27713, Training Accuracy:  60.9%, Loss: 0.6827\n",
      "Optimization Iteration:  27777, Training Accuracy:  68.8%, Loss: 0.6513\n",
      "Optimization Iteration:  27841, Training Accuracy:  56.2%, Loss: 0.6638\n",
      "Optimization Iteration:  27905, Training Accuracy:  59.4%, Loss: 0.6512\n",
      "Optimization Iteration:  27969, Training Accuracy:  51.6%, Loss: 0.6333\n",
      "Optimization Iteration:  28033, Training Accuracy:  67.2%, Loss: 0.6898\n",
      "Optimization Iteration:  28097, Training Accuracy:  60.9%, Loss: 0.6178\n",
      "Optimization Iteration:  28161, Training Accuracy:  71.9%, Loss: 0.5372\n",
      "Optimization Iteration:  28225, Training Accuracy:  57.8%, Loss: 0.6455\n",
      "Optimization Iteration:  28289, Training Accuracy:  57.8%, Loss: 0.7029\n",
      "Optimization Iteration:  28353, Training Accuracy:  51.6%, Loss: 0.6551\n",
      "Optimization Iteration:  28417, Training Accuracy:  50.0%, Loss: 0.7803\n",
      "Optimization Iteration:  28481, Training Accuracy:  59.4%, Loss: 0.6134\n",
      "Optimization Iteration:  28545, Training Accuracy:  62.5%, Loss: 0.6205\n",
      "Optimization Iteration:  28609, Training Accuracy:  57.8%, Loss: 0.6853\n",
      "Optimization Iteration:  28673, Training Accuracy:  56.2%, Loss: 0.6747\n",
      "Optimization Iteration:  28737, Training Accuracy:  57.8%, Loss: 0.6639\n",
      "Optimization Iteration:  28801, Training Accuracy:  53.1%, Loss: 0.7241\n",
      "Optimization Iteration:  28865, Training Accuracy:  56.2%, Loss: 0.6666\n",
      "Optimization Iteration:  28929, Training Accuracy:  59.4%, Loss: 0.6734\n",
      "Optimization Iteration:  28993, Training Accuracy:  71.9%, Loss: 0.5909\n",
      "Optimization Iteration:  29057, Training Accuracy:  62.5%, Loss: 0.6434\n",
      "Optimization Iteration:  29121, Training Accuracy:  54.7%, Loss: 0.7452\n",
      "Optimization Iteration:  29185, Training Accuracy:  59.4%, Loss: 0.6545\n",
      "Optimization Iteration:  29249, Training Accuracy:  60.9%, Loss: 0.6553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  29313, Training Accuracy:  68.8%, Loss: 0.5915\n",
      "Optimization Iteration:  29377, Training Accuracy:  57.8%, Loss: 0.6043\n",
      "Optimization Iteration:  29441, Training Accuracy:  71.9%, Loss: 0.5807\n",
      "Optimization Iteration:  29505, Training Accuracy:  56.2%, Loss: 0.6689\n",
      "Optimization Iteration:  29569, Training Accuracy:  51.6%, Loss: 0.6726\n",
      "Optimization Iteration:  29633, Training Accuracy:  50.0%, Loss: 0.6749\n",
      "Optimization Iteration:  29697, Training Accuracy:  53.1%, Loss: 0.6546\n",
      "Optimization Iteration:  29761, Training Accuracy:  64.1%, Loss: 0.6498\n",
      "Optimization Iteration:  29825, Training Accuracy:  59.4%, Loss: 0.6838\n",
      "Optimization Iteration:  29889, Training Accuracy:  62.5%, Loss: 0.6962\n",
      "Optimization Iteration:  29953, Training Accuracy:  68.8%, Loss: 0.7315\n",
      "Optimization Iteration:  30017, Training Accuracy:  67.2%, Loss: 0.6716\n",
      "Optimization Iteration:  30081, Training Accuracy:  76.6%, Loss: 0.5887\n",
      "Optimization Iteration:  30145, Training Accuracy:  68.8%, Loss: 0.5767\n",
      "Optimization Iteration:  30209, Training Accuracy:  67.2%, Loss: 0.6029\n",
      "Optimization Iteration:  30273, Training Accuracy:  56.2%, Loss: 0.7027\n",
      "Optimization Iteration:  30337, Training Accuracy:  54.7%, Loss: 0.6858\n",
      "Optimization Iteration:  30401, Training Accuracy:  65.6%, Loss: 0.6116\n",
      "Optimization Iteration:  30465, Training Accuracy:  59.4%, Loss: 0.6334\n",
      "Optimization Iteration:  30529, Training Accuracy:  59.4%, Loss: 0.6386\n",
      "Optimization Iteration:  30593, Training Accuracy:  59.4%, Loss: 0.6288\n",
      "Optimization Iteration:  30657, Training Accuracy:  57.8%, Loss: 0.6843\n",
      "Optimization Iteration:  30721, Training Accuracy:  65.6%, Loss: 0.5755\n",
      "Optimization Iteration:  30785, Training Accuracy:  50.0%, Loss: 0.7337\n",
      "Optimization Iteration:  30849, Training Accuracy:  51.6%, Loss: 0.7368\n",
      "Optimization Iteration:  30913, Training Accuracy:  64.1%, Loss: 0.6020\n",
      "Optimization Iteration:  30977, Training Accuracy:  56.2%, Loss: 0.6032\n",
      "Optimization Iteration:  31041, Training Accuracy:  54.7%, Loss: 0.5932\n",
      "Optimization Iteration:  31105, Training Accuracy:  64.1%, Loss: 0.5876\n",
      "Optimization Iteration:  31169, Training Accuracy:  56.2%, Loss: 0.6313\n",
      "Optimization Iteration:  31233, Training Accuracy:  65.6%, Loss: 0.6250\n",
      "Optimization Iteration:  31297, Training Accuracy:  60.9%, Loss: 0.6506\n",
      "Optimization Iteration:  31361, Training Accuracy:  59.4%, Loss: 0.6344\n",
      "Optimization Iteration:  31425, Training Accuracy:  62.5%, Loss: 0.6218\n",
      "Optimization Iteration:  31489, Training Accuracy:  71.9%, Loss: 0.6058\n",
      "Optimization Iteration:  31553, Training Accuracy:  64.1%, Loss: 0.5874\n",
      "Optimization Iteration:  31617, Training Accuracy:  59.4%, Loss: 0.6242\n",
      "Optimization Iteration:  31681, Training Accuracy:  62.5%, Loss: 0.7482\n",
      "Optimization Iteration:  31745, Training Accuracy:  67.2%, Loss: 0.6436\n",
      "Optimization Iteration:  31809, Training Accuracy:  56.2%, Loss: 0.6623\n",
      "Optimization Iteration:  31873, Training Accuracy:  56.2%, Loss: 0.6430\n",
      "Optimization Iteration:  31937, Training Accuracy:  57.8%, Loss: 0.6722\n",
      "Optimization Iteration:  32001, Training Accuracy:  62.5%, Loss: 0.6052\n",
      "Optimization Iteration:  32065, Training Accuracy:  48.4%, Loss: 0.6835\n",
      "Optimization Iteration:  32129, Training Accuracy:  60.9%, Loss: 0.6009\n",
      "Optimization Iteration:  32193, Training Accuracy:  67.2%, Loss: 0.6194\n",
      "Optimization Iteration:  32257, Training Accuracy:  59.4%, Loss: 0.6450\n",
      "Optimization Iteration:  32321, Training Accuracy:  67.2%, Loss: 0.6046\n",
      "Optimization Iteration:  32385, Training Accuracy:  59.4%, Loss: 0.6470\n",
      "Optimization Iteration:  32449, Training Accuracy:  53.1%, Loss: 0.6663\n",
      "Optimization Iteration:  32513, Training Accuracy:  64.1%, Loss: 0.6350\n",
      "Optimization Iteration:  32577, Training Accuracy:  62.5%, Loss: 0.6576\n",
      "Optimization Iteration:  32641, Training Accuracy:  54.7%, Loss: 0.6304\n",
      "Optimization Iteration:  32705, Training Accuracy:  70.3%, Loss: 0.6069\n",
      "Optimization Iteration:  32769, Training Accuracy:  59.4%, Loss: 0.6150\n",
      "Optimization Iteration:  32833, Training Accuracy:  70.3%, Loss: 0.5432\n",
      "Optimization Iteration:  32897, Training Accuracy:  60.9%, Loss: 0.7070\n",
      "Optimization Iteration:  32961, Training Accuracy:  59.4%, Loss: 0.6851\n",
      "Optimization Iteration:  33025, Training Accuracy:  64.1%, Loss: 0.6068\n",
      "Optimization Iteration:  33089, Training Accuracy:  65.6%, Loss: 0.6378\n",
      "Optimization Iteration:  33153, Training Accuracy:  60.9%, Loss: 0.6566\n",
      "Optimization Iteration:  33217, Training Accuracy:  48.4%, Loss: 0.7061\n",
      "Optimization Iteration:  33281, Training Accuracy:  53.1%, Loss: 0.7227\n",
      "Optimization Iteration:  33345, Training Accuracy:  60.9%, Loss: 0.6238\n",
      "Optimization Iteration:  33409, Training Accuracy:  64.1%, Loss: 0.6130\n",
      "Optimization Iteration:  33473, Training Accuracy:  65.6%, Loss: 0.6531\n",
      "Optimization Iteration:  33537, Training Accuracy:  67.2%, Loss: 0.6772\n",
      "Optimization Iteration:  33601, Training Accuracy:  56.2%, Loss: 0.6647\n",
      "Optimization Iteration:  33665, Training Accuracy:  70.3%, Loss: 0.6146\n",
      "Optimization Iteration:  33729, Training Accuracy:  70.3%, Loss: 0.6095\n",
      "Optimization Iteration:  33793, Training Accuracy:  56.2%, Loss: 0.6348\n",
      "Optimization Iteration:  33857, Training Accuracy:  56.2%, Loss: 0.6990\n",
      "Optimization Iteration:  33921, Training Accuracy:  57.8%, Loss: 0.6035\n",
      "Optimization Iteration:  33985, Training Accuracy:  65.6%, Loss: 0.6198\n",
      "Optimization Iteration:  34049, Training Accuracy:  60.9%, Loss: 0.6418\n",
      "Optimization Iteration:  34113, Training Accuracy:  64.1%, Loss: 0.5817\n",
      "Optimization Iteration:  34177, Training Accuracy:  62.5%, Loss: 0.5851\n",
      "Optimization Iteration:  34241, Training Accuracy:  65.6%, Loss: 0.6373\n",
      "Optimization Iteration:  34305, Training Accuracy:  57.8%, Loss: 0.6895\n",
      "Optimization Iteration:  34369, Training Accuracy:  62.5%, Loss: 0.6488\n",
      "Optimization Iteration:  34433, Training Accuracy:  60.9%, Loss: 0.7423\n",
      "Optimization Iteration:  34497, Training Accuracy:  57.8%, Loss: 0.6548\n",
      "Optimization Iteration:  34561, Training Accuracy:  65.6%, Loss: 0.6485\n",
      "Optimization Iteration:  34625, Training Accuracy:  73.4%, Loss: 0.5881\n",
      "Optimization Iteration:  34689, Training Accuracy:  54.7%, Loss: 0.6865\n",
      "Optimization Iteration:  34753, Training Accuracy:  59.4%, Loss: 0.6269\n",
      "Optimization Iteration:  34817, Training Accuracy:  67.2%, Loss: 0.5853\n",
      "Optimization Iteration:  34881, Training Accuracy:  59.4%, Loss: 0.6157\n",
      "Optimization Iteration:  34945, Training Accuracy:  67.2%, Loss: 0.6360\n",
      "Optimization Iteration:  35009, Training Accuracy:  67.2%, Loss: 0.6629\n",
      "Optimization Iteration:  35073, Training Accuracy:  56.2%, Loss: 0.6921\n",
      "Optimization Iteration:  35137, Training Accuracy:  67.2%, Loss: 0.5836\n",
      "Optimization Iteration:  35201, Training Accuracy:  64.1%, Loss: 0.6227\n",
      "Optimization Iteration:  35265, Training Accuracy:  51.6%, Loss: 0.7111\n",
      "Optimization Iteration:  35329, Training Accuracy:  71.9%, Loss: 0.6123\n",
      "Optimization Iteration:  35393, Training Accuracy:  60.9%, Loss: 0.6529\n",
      "Optimization Iteration:  35457, Training Accuracy:  60.9%, Loss: 0.6601\n",
      "Optimization Iteration:  35521, Training Accuracy:  67.2%, Loss: 0.6429\n",
      "Optimization Iteration:  35585, Training Accuracy:  60.9%, Loss: 0.6440\n",
      "Optimization Iteration:  35649, Training Accuracy:  60.9%, Loss: 0.6305\n",
      "Optimization Iteration:  35713, Training Accuracy:  68.8%, Loss: 0.6775\n",
      "Optimization Iteration:  35777, Training Accuracy:  60.9%, Loss: 0.7053\n",
      "Optimization Iteration:  35841, Training Accuracy:  60.9%, Loss: 0.6568\n",
      "Optimization Iteration:  35905, Training Accuracy:  54.7%, Loss: 0.6525\n",
      "Optimization Iteration:  35969, Training Accuracy:  53.1%, Loss: 0.6647\n",
      "Optimization Iteration:  36033, Training Accuracy:  64.1%, Loss: 0.5988\n",
      "Optimization Iteration:  36097, Training Accuracy:  62.5%, Loss: 0.6411\n",
      "Optimization Iteration:  36161, Training Accuracy:  54.7%, Loss: 0.7128\n",
      "Optimization Iteration:  36225, Training Accuracy:  62.5%, Loss: 0.7195\n",
      "Optimization Iteration:  36289, Training Accuracy:  54.7%, Loss: 0.6433\n",
      "Optimization Iteration:  36353, Training Accuracy:  62.5%, Loss: 0.6213\n",
      "Optimization Iteration:  36417, Training Accuracy:  65.6%, Loss: 0.6075\n",
      "Optimization Iteration:  36481, Training Accuracy:  60.9%, Loss: 0.6353\n",
      "Optimization Iteration:  36545, Training Accuracy:  75.0%, Loss: 0.5856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  36609, Training Accuracy:  57.8%, Loss: 0.6386\n",
      "Optimization Iteration:  36673, Training Accuracy:  62.5%, Loss: 0.6859\n",
      "Optimization Iteration:  36737, Training Accuracy:  60.9%, Loss: 0.6245\n",
      "Optimization Iteration:  36801, Training Accuracy:  62.5%, Loss: 0.6135\n",
      "Optimization Iteration:  36865, Training Accuracy:  64.1%, Loss: 0.6446\n",
      "Optimization Iteration:  36929, Training Accuracy:  54.7%, Loss: 0.7098\n",
      "Optimization Iteration:  36993, Training Accuracy:  64.1%, Loss: 0.6179\n",
      "Optimization Iteration:  37057, Training Accuracy:  54.7%, Loss: 0.6956\n",
      "Optimization Iteration:  37121, Training Accuracy:  73.4%, Loss: 0.5263\n",
      "Optimization Iteration:  37185, Training Accuracy:  51.6%, Loss: 0.7097\n",
      "Optimization Iteration:  37249, Training Accuracy:  62.5%, Loss: 0.6332\n",
      "Optimization Iteration:  37313, Training Accuracy:  62.5%, Loss: 0.5544\n",
      "Optimization Iteration:  37377, Training Accuracy:  56.2%, Loss: 0.6877\n",
      "Optimization Iteration:  37441, Training Accuracy:  50.0%, Loss: 0.6716\n",
      "Optimization Iteration:  37505, Training Accuracy:  71.9%, Loss: 0.6024\n",
      "Optimization Iteration:  37569, Training Accuracy:  51.6%, Loss: 0.7035\n",
      "Optimization Iteration:  37633, Training Accuracy:  56.2%, Loss: 0.6172\n",
      "Optimization Iteration:  37697, Training Accuracy:  67.2%, Loss: 0.5743\n",
      "Optimization Iteration:  37761, Training Accuracy:  70.3%, Loss: 0.5899\n",
      "Optimization Iteration:  37825, Training Accuracy:  56.2%, Loss: 0.6751\n",
      "Optimization Iteration:  37889, Training Accuracy:  75.0%, Loss: 0.5849\n",
      "Optimization Iteration:  37953, Training Accuracy:  60.9%, Loss: 0.6431\n",
      "Optimization Iteration:  38017, Training Accuracy:  54.7%, Loss: 0.6543\n",
      "Optimization Iteration:  38081, Training Accuracy:  60.9%, Loss: 0.6044\n",
      "Optimization Iteration:  38145, Training Accuracy:  64.1%, Loss: 0.6958\n",
      "Optimization Iteration:  38209, Training Accuracy:  68.8%, Loss: 0.6185\n",
      "Optimization Iteration:  38273, Training Accuracy:  62.5%, Loss: 0.6294\n",
      "Optimization Iteration:  38337, Training Accuracy:  70.3%, Loss: 0.5896\n",
      "Optimization Iteration:  38401, Training Accuracy:  68.8%, Loss: 0.5598\n",
      "Optimization Iteration:  38465, Training Accuracy:  56.2%, Loss: 0.6878\n",
      "Optimization Iteration:  38529, Training Accuracy:  68.8%, Loss: 0.5548\n",
      "Optimization Iteration:  38593, Training Accuracy:  59.4%, Loss: 0.6389\n",
      "Optimization Iteration:  38657, Training Accuracy:  70.3%, Loss: 0.6142\n",
      "Optimization Iteration:  38721, Training Accuracy:  67.2%, Loss: 0.5682\n",
      "Optimization Iteration:  38785, Training Accuracy:  57.8%, Loss: 0.6667\n",
      "Optimization Iteration:  38849, Training Accuracy:  64.1%, Loss: 0.5521\n",
      "Optimization Iteration:  38913, Training Accuracy:  64.1%, Loss: 0.6486\n",
      "Optimization Iteration:  38977, Training Accuracy:  53.1%, Loss: 0.6584\n",
      "Optimization Iteration:  39041, Training Accuracy:  67.2%, Loss: 0.6993\n",
      "Optimization Iteration:  39105, Training Accuracy:  51.6%, Loss: 0.7366\n",
      "Optimization Iteration:  39169, Training Accuracy:  59.4%, Loss: 0.6738\n",
      "Optimization Iteration:  39233, Training Accuracy:  48.4%, Loss: 0.7554\n",
      "Optimization Iteration:  39297, Training Accuracy:  53.1%, Loss: 0.6650\n",
      "Optimization Iteration:  39361, Training Accuracy:  57.8%, Loss: 0.7268\n",
      "Optimization Iteration:  39425, Training Accuracy:  59.4%, Loss: 0.5980\n",
      "Optimization Iteration:  39489, Training Accuracy:  68.8%, Loss: 0.5450\n",
      "Optimization Iteration:  39553, Training Accuracy:  70.3%, Loss: 0.5495\n",
      "Optimization Iteration:  39617, Training Accuracy:  68.8%, Loss: 0.6184\n",
      "Optimization Iteration:  39681, Training Accuracy:  59.4%, Loss: 0.6418\n",
      "Optimization Iteration:  39745, Training Accuracy:  70.3%, Loss: 0.6009\n",
      "Optimization Iteration:  39809, Training Accuracy:  67.2%, Loss: 0.6603\n",
      "Optimization Iteration:  39873, Training Accuracy:  64.1%, Loss: 0.6955\n",
      "Optimization Iteration:  39937, Training Accuracy:  48.4%, Loss: 0.7576\n",
      "Optimization Iteration:  40001, Training Accuracy:  65.6%, Loss: 0.5597\n",
      "Optimization Iteration:  40065, Training Accuracy:  54.7%, Loss: 0.6757\n",
      "Optimization Iteration:  40129, Training Accuracy:  59.4%, Loss: 0.5755\n",
      "Optimization Iteration:  40193, Training Accuracy:  60.9%, Loss: 0.6152\n",
      "Optimization Iteration:  40257, Training Accuracy:  54.7%, Loss: 0.6495\n",
      "Optimization Iteration:  40321, Training Accuracy:  62.5%, Loss: 0.6438\n",
      "Optimization Iteration:  40385, Training Accuracy:  62.5%, Loss: 0.6320\n",
      "Optimization Iteration:  40449, Training Accuracy:  70.3%, Loss: 0.5521\n",
      "Optimization Iteration:  40513, Training Accuracy:  73.4%, Loss: 0.5766\n",
      "Optimization Iteration:  40577, Training Accuracy:  62.5%, Loss: 0.6470\n",
      "Optimization Iteration:  40641, Training Accuracy:  65.6%, Loss: 0.6049\n",
      "Optimization Iteration:  40705, Training Accuracy:  57.8%, Loss: 0.6991\n",
      "Optimization Iteration:  40769, Training Accuracy:  64.1%, Loss: 0.5766\n",
      "Optimization Iteration:  40833, Training Accuracy:  68.8%, Loss: 0.5788\n",
      "Optimization Iteration:  40897, Training Accuracy:  70.3%, Loss: 0.5974\n",
      "Optimization Iteration:  40961, Training Accuracy:  71.9%, Loss: 0.6224\n",
      "Optimization Iteration:  41025, Training Accuracy:  57.8%, Loss: 0.6296\n",
      "Optimization Iteration:  41089, Training Accuracy:  68.8%, Loss: 0.5826\n",
      "Optimization Iteration:  41153, Training Accuracy:  59.4%, Loss: 0.6028\n",
      "Optimization Iteration:  41217, Training Accuracy:  57.8%, Loss: 0.6731\n",
      "Optimization Iteration:  41281, Training Accuracy:  59.4%, Loss: 0.5966\n",
      "Optimization Iteration:  41345, Training Accuracy:  70.3%, Loss: 0.5396\n",
      "Optimization Iteration:  41409, Training Accuracy:  67.2%, Loss: 0.5818\n",
      "Optimization Iteration:  41473, Training Accuracy:  64.1%, Loss: 0.7076\n",
      "Optimization Iteration:  41537, Training Accuracy:  60.9%, Loss: 0.6472\n",
      "Optimization Iteration:  41601, Training Accuracy:  64.1%, Loss: 0.6627\n",
      "Optimization Iteration:  41665, Training Accuracy:  51.6%, Loss: 0.7242\n",
      "Optimization Iteration:  41729, Training Accuracy:  70.3%, Loss: 0.6055\n",
      "Optimization Iteration:  41793, Training Accuracy:  56.2%, Loss: 0.6754\n",
      "Optimization Iteration:  41857, Training Accuracy:  65.6%, Loss: 0.6082\n",
      "Optimization Iteration:  41921, Training Accuracy:  59.4%, Loss: 0.6313\n",
      "Optimization Iteration:  41985, Training Accuracy:  62.5%, Loss: 0.6761\n",
      "Optimization Iteration:  42049, Training Accuracy:  64.1%, Loss: 0.6088\n",
      "Optimization Iteration:  42113, Training Accuracy:  57.8%, Loss: 0.6566\n",
      "Optimization Iteration:  42177, Training Accuracy:  62.5%, Loss: 0.5721\n",
      "Optimization Iteration:  42241, Training Accuracy:  68.8%, Loss: 0.6308\n",
      "Optimization Iteration:  42305, Training Accuracy:  65.6%, Loss: 0.6236\n",
      "Optimization Iteration:  42369, Training Accuracy:  62.5%, Loss: 0.6427\n",
      "Optimization Iteration:  42433, Training Accuracy:  56.2%, Loss: 0.6576\n",
      "Optimization Iteration:  42497, Training Accuracy:  62.5%, Loss: 0.6481\n",
      "Optimization Iteration:  42561, Training Accuracy:  73.4%, Loss: 0.5348\n",
      "Optimization Iteration:  42625, Training Accuracy:  67.2%, Loss: 0.5585\n",
      "Optimization Iteration:  42689, Training Accuracy:  71.9%, Loss: 0.5536\n",
      "Optimization Iteration:  42753, Training Accuracy:  65.6%, Loss: 0.6136\n",
      "Optimization Iteration:  42817, Training Accuracy:  75.0%, Loss: 0.5338\n",
      "Optimization Iteration:  42881, Training Accuracy:  54.7%, Loss: 0.6419\n",
      "Optimization Iteration:  42945, Training Accuracy:  62.5%, Loss: 0.6223\n",
      "Optimization Iteration:  43009, Training Accuracy:  73.4%, Loss: 0.5902\n",
      "Optimization Iteration:  43073, Training Accuracy:  60.9%, Loss: 0.5968\n",
      "Optimization Iteration:  43137, Training Accuracy:  65.6%, Loss: 0.5680\n",
      "Optimization Iteration:  43201, Training Accuracy:  53.1%, Loss: 0.6692\n",
      "Optimization Iteration:  43265, Training Accuracy:  53.1%, Loss: 0.6923\n",
      "Optimization Iteration:  43329, Training Accuracy:  68.8%, Loss: 0.6321\n",
      "Optimization Iteration:  43393, Training Accuracy:  57.8%, Loss: 0.6755\n",
      "Optimization Iteration:  43457, Training Accuracy:  59.4%, Loss: 0.7083\n",
      "Optimization Iteration:  43521, Training Accuracy:  57.8%, Loss: 0.6171\n",
      "Optimization Iteration:  43585, Training Accuracy:  60.9%, Loss: 0.6428\n",
      "Optimization Iteration:  43649, Training Accuracy:  71.9%, Loss: 0.5595\n",
      "Optimization Iteration:  43713, Training Accuracy:  70.3%, Loss: 0.5483\n",
      "Optimization Iteration:  43777, Training Accuracy:  67.2%, Loss: 0.5692\n",
      "Optimization Iteration:  43841, Training Accuracy:  60.9%, Loss: 0.6436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  43905, Training Accuracy:  75.0%, Loss: 0.4954\n",
      "Optimization Iteration:  43969, Training Accuracy:  56.2%, Loss: 0.7363\n",
      "Optimization Iteration:  44033, Training Accuracy:  67.2%, Loss: 0.6164\n",
      "Optimization Iteration:  44097, Training Accuracy:  68.8%, Loss: 0.5443\n",
      "Optimization Iteration:  44161, Training Accuracy:  57.8%, Loss: 0.6526\n",
      "Optimization Iteration:  44225, Training Accuracy:  56.2%, Loss: 0.6331\n",
      "Optimization Iteration:  44289, Training Accuracy:  70.3%, Loss: 0.5645\n",
      "Optimization Iteration:  44353, Training Accuracy:  59.4%, Loss: 0.6561\n",
      "Optimization Iteration:  44417, Training Accuracy:  62.5%, Loss: 0.5789\n",
      "Optimization Iteration:  44481, Training Accuracy:  70.3%, Loss: 0.6223\n",
      "Optimization Iteration:  44545, Training Accuracy:  68.8%, Loss: 0.5416\n",
      "Optimization Iteration:  44609, Training Accuracy:  64.1%, Loss: 0.6127\n",
      "Optimization Iteration:  44673, Training Accuracy:  53.1%, Loss: 0.6457\n",
      "Optimization Iteration:  44737, Training Accuracy:  59.4%, Loss: 0.6311\n",
      "Optimization Iteration:  44801, Training Accuracy:  64.1%, Loss: 0.6029\n",
      "Optimization Iteration:  44865, Training Accuracy:  59.4%, Loss: 0.6660\n",
      "Optimization Iteration:  44929, Training Accuracy:  62.5%, Loss: 0.5599\n",
      "Optimization Iteration:  44993, Training Accuracy:  62.5%, Loss: 0.6316\n",
      "Optimization Iteration:  45057, Training Accuracy:  67.2%, Loss: 0.5671\n",
      "Optimization Iteration:  45121, Training Accuracy:  75.0%, Loss: 0.5357\n",
      "Optimization Iteration:  45185, Training Accuracy:  68.8%, Loss: 0.5345\n",
      "Optimization Iteration:  45249, Training Accuracy:  67.2%, Loss: 0.5807\n",
      "Optimization Iteration:  45313, Training Accuracy:  73.4%, Loss: 0.5629\n",
      "Optimization Iteration:  45377, Training Accuracy:  65.6%, Loss: 0.6324\n",
      "Optimization Iteration:  45441, Training Accuracy:  65.6%, Loss: 0.6655\n",
      "Optimization Iteration:  45505, Training Accuracy:  62.5%, Loss: 0.6499\n",
      "Optimization Iteration:  45569, Training Accuracy:  57.8%, Loss: 0.7070\n",
      "Optimization Iteration:  45633, Training Accuracy:  67.2%, Loss: 0.5450\n",
      "Optimization Iteration:  45697, Training Accuracy:  59.4%, Loss: 0.6256\n",
      "Optimization Iteration:  45761, Training Accuracy:  67.2%, Loss: 0.6281\n",
      "Optimization Iteration:  45825, Training Accuracy:  65.6%, Loss: 0.6004\n",
      "Optimization Iteration:  45889, Training Accuracy:  65.6%, Loss: 0.6671\n",
      "Optimization Iteration:  45953, Training Accuracy:  56.2%, Loss: 0.6106\n",
      "Optimization Iteration:  46017, Training Accuracy:  60.9%, Loss: 0.6203\n",
      "Optimization Iteration:  46081, Training Accuracy:  75.0%, Loss: 0.5681\n",
      "Optimization Iteration:  46145, Training Accuracy:  57.8%, Loss: 0.6253\n",
      "Optimization Iteration:  46209, Training Accuracy:  75.0%, Loss: 0.5336\n",
      "Optimization Iteration:  46273, Training Accuracy:  67.2%, Loss: 0.5860\n",
      "Optimization Iteration:  46337, Training Accuracy:  67.2%, Loss: 0.5887\n",
      "Optimization Iteration:  46401, Training Accuracy:  60.9%, Loss: 0.5828\n",
      "Optimization Iteration:  46465, Training Accuracy:  62.5%, Loss: 0.6539\n",
      "Optimization Iteration:  46529, Training Accuracy:  57.8%, Loss: 0.6337\n",
      "Optimization Iteration:  46593, Training Accuracy:  54.7%, Loss: 0.5908\n",
      "Optimization Iteration:  46657, Training Accuracy:  67.2%, Loss: 0.5346\n",
      "Optimization Iteration:  46721, Training Accuracy:  73.4%, Loss: 0.5639\n",
      "Optimization Iteration:  46785, Training Accuracy:  51.6%, Loss: 0.6820\n",
      "Optimization Iteration:  46849, Training Accuracy:  59.4%, Loss: 0.6135\n",
      "Optimization Iteration:  46913, Training Accuracy:  57.8%, Loss: 0.6219\n",
      "Optimization Iteration:  46977, Training Accuracy:  59.4%, Loss: 0.8029\n",
      "Optimization Iteration:  47041, Training Accuracy:  62.5%, Loss: 0.5949\n",
      "Optimization Iteration:  47105, Training Accuracy:  54.7%, Loss: 0.6423\n",
      "Optimization Iteration:  47169, Training Accuracy:  57.8%, Loss: 0.6216\n",
      "Optimization Iteration:  47233, Training Accuracy:  60.9%, Loss: 0.6281\n",
      "Optimization Iteration:  47297, Training Accuracy:  56.2%, Loss: 0.5867\n",
      "Optimization Iteration:  47361, Training Accuracy:  59.4%, Loss: 0.6295\n",
      "Optimization Iteration:  47425, Training Accuracy:  67.2%, Loss: 0.5580\n",
      "Optimization Iteration:  47489, Training Accuracy:  59.4%, Loss: 0.5820\n",
      "Optimization Iteration:  47553, Training Accuracy:  71.9%, Loss: 0.5510\n",
      "Optimization Iteration:  47617, Training Accuracy:  68.8%, Loss: 0.5946\n",
      "Optimization Iteration:  47681, Training Accuracy:  73.4%, Loss: 0.5233\n",
      "Optimization Iteration:  47745, Training Accuracy:  64.1%, Loss: 0.6012\n",
      "Optimization Iteration:  47809, Training Accuracy:  65.6%, Loss: 0.5619\n",
      "Optimization Iteration:  47873, Training Accuracy:  64.1%, Loss: 0.5607\n",
      "Optimization Iteration:  47937, Training Accuracy:  59.4%, Loss: 0.6946\n",
      "Optimization Iteration:  48001, Training Accuracy:  64.1%, Loss: 0.6332\n",
      "Optimization Iteration:  48065, Training Accuracy:  56.2%, Loss: 0.6480\n",
      "Optimization Iteration:  48129, Training Accuracy:  65.6%, Loss: 0.6886\n",
      "Optimization Iteration:  48193, Training Accuracy:  62.5%, Loss: 0.6330\n",
      "Optimization Iteration:  48257, Training Accuracy:  64.1%, Loss: 0.5729\n",
      "Optimization Iteration:  48321, Training Accuracy:  70.3%, Loss: 0.5603\n",
      "Optimization Iteration:  48385, Training Accuracy:  65.6%, Loss: 0.5545\n",
      "Optimization Iteration:  48449, Training Accuracy:  56.2%, Loss: 0.7062\n",
      "Optimization Iteration:  48513, Training Accuracy:  71.9%, Loss: 0.5821\n",
      "Optimization Iteration:  48577, Training Accuracy:  65.6%, Loss: 0.6279\n",
      "Optimization Iteration:  48641, Training Accuracy:  68.8%, Loss: 0.5912\n",
      "Optimization Iteration:  48705, Training Accuracy:  76.6%, Loss: 0.5401\n",
      "Optimization Iteration:  48769, Training Accuracy:  64.1%, Loss: 0.6712\n",
      "Optimization Iteration:  48833, Training Accuracy:  73.4%, Loss: 0.5247\n",
      "Optimization Iteration:  48897, Training Accuracy:  62.5%, Loss: 0.5398\n",
      "Optimization Iteration:  48961, Training Accuracy:  73.4%, Loss: 0.6007\n",
      "Optimization Iteration:  49025, Training Accuracy:  60.9%, Loss: 0.6653\n",
      "Optimization Iteration:  49089, Training Accuracy:  60.9%, Loss: 0.5742\n",
      "Optimization Iteration:  49153, Training Accuracy:  68.8%, Loss: 0.5543\n",
      "Optimization Iteration:  49217, Training Accuracy:  64.1%, Loss: 0.6345\n",
      "Optimization Iteration:  49281, Training Accuracy:  67.2%, Loss: 0.6241\n",
      "Optimization Iteration:  49345, Training Accuracy:  71.9%, Loss: 0.5818\n",
      "Optimization Iteration:  49409, Training Accuracy:  68.8%, Loss: 0.5455\n",
      "Optimization Iteration:  49473, Training Accuracy:  68.8%, Loss: 0.5882\n",
      "Optimization Iteration:  49537, Training Accuracy:  76.6%, Loss: 0.5242\n",
      "Optimization Iteration:  49601, Training Accuracy:  60.9%, Loss: 0.6613\n",
      "Optimization Iteration:  49665, Training Accuracy:  67.2%, Loss: 0.5097\n",
      "Optimization Iteration:  49729, Training Accuracy:  54.7%, Loss: 0.6680\n",
      "Optimization Iteration:  49793, Training Accuracy:  60.9%, Loss: 0.6103\n",
      "Optimization Iteration:  49857, Training Accuracy:  60.9%, Loss: 0.6370\n",
      "Optimization Iteration:  49921, Training Accuracy:  64.1%, Loss: 0.6204\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 2\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  64.1%, Loss: 0.5685\n",
      "Optimization Iteration:    129, Training Accuracy:  71.9%, Loss: 0.5618\n",
      "Optimization Iteration:    193, Training Accuracy:  60.9%, Loss: 0.6379\n",
      "Optimization Iteration:    257, Training Accuracy:  65.6%, Loss: 0.5925\n",
      "Optimization Iteration:    321, Training Accuracy:  73.4%, Loss: 0.5214\n",
      "Optimization Iteration:    385, Training Accuracy:  65.6%, Loss: 0.6127\n",
      "Optimization Iteration:    449, Training Accuracy:  62.5%, Loss: 0.5454\n",
      "Optimization Iteration:    513, Training Accuracy:  57.8%, Loss: 0.5967\n",
      "Optimization Iteration:    577, Training Accuracy:  62.5%, Loss: 0.6258\n",
      "Optimization Iteration:    641, Training Accuracy:  59.4%, Loss: 0.6890\n",
      "Optimization Iteration:    705, Training Accuracy:  70.3%, Loss: 0.6141\n",
      "Optimization Iteration:    769, Training Accuracy:  65.6%, Loss: 0.6206\n",
      "Optimization Iteration:    833, Training Accuracy:  70.3%, Loss: 0.5661\n",
      "Optimization Iteration:    897, Training Accuracy:  65.6%, Loss: 0.5932\n",
      "Optimization Iteration:    961, Training Accuracy:  67.2%, Loss: 0.5162\n",
      "Optimization Iteration:   1025, Training Accuracy:  60.9%, Loss: 0.5987\n",
      "Optimization Iteration:   1089, Training Accuracy:  65.6%, Loss: 0.5737\n",
      "Optimization Iteration:   1153, Training Accuracy:  71.9%, Loss: 0.6587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   1217, Training Accuracy:  65.6%, Loss: 0.6002\n",
      "Optimization Iteration:   1281, Training Accuracy:  64.1%, Loss: 0.5475\n",
      "Optimization Iteration:   1345, Training Accuracy:  64.1%, Loss: 0.6232\n",
      "Optimization Iteration:   1409, Training Accuracy:  68.8%, Loss: 0.5825\n",
      "Optimization Iteration:   1473, Training Accuracy:  68.8%, Loss: 0.5616\n",
      "Optimization Iteration:   1537, Training Accuracy:  59.4%, Loss: 0.6395\n",
      "Optimization Iteration:   1601, Training Accuracy:  73.4%, Loss: 0.5195\n",
      "Optimization Iteration:   1665, Training Accuracy:  62.5%, Loss: 0.5279\n",
      "Optimization Iteration:   1729, Training Accuracy:  60.9%, Loss: 0.6483\n",
      "Optimization Iteration:   1793, Training Accuracy:  71.9%, Loss: 0.5936\n",
      "Optimization Iteration:   1857, Training Accuracy:  65.6%, Loss: 0.6055\n",
      "Optimization Iteration:   1921, Training Accuracy:  62.5%, Loss: 0.5872\n",
      "Optimization Iteration:   1985, Training Accuracy:  64.1%, Loss: 0.7441\n",
      "Optimization Iteration:   2049, Training Accuracy:  78.1%, Loss: 0.4951\n",
      "Optimization Iteration:   2113, Training Accuracy:  64.1%, Loss: 0.5980\n",
      "Optimization Iteration:   2177, Training Accuracy:  65.6%, Loss: 0.6386\n",
      "Optimization Iteration:   2241, Training Accuracy:  65.6%, Loss: 0.5999\n",
      "Optimization Iteration:   2305, Training Accuracy:  71.9%, Loss: 0.6369\n",
      "Optimization Iteration:   2369, Training Accuracy:  64.1%, Loss: 0.6115\n",
      "Optimization Iteration:   2433, Training Accuracy:  62.5%, Loss: 0.5844\n",
      "Optimization Iteration:   2497, Training Accuracy:  56.2%, Loss: 0.6491\n",
      "Optimization Iteration:   2561, Training Accuracy:  60.9%, Loss: 0.5688\n",
      "Optimization Iteration:   2625, Training Accuracy:  70.3%, Loss: 0.5623\n",
      "Optimization Iteration:   2689, Training Accuracy:  59.4%, Loss: 0.5408\n",
      "Optimization Iteration:   2753, Training Accuracy:  68.8%, Loss: 0.6486\n",
      "Optimization Iteration:   2817, Training Accuracy:  56.2%, Loss: 0.6265\n",
      "Optimization Iteration:   2881, Training Accuracy:  57.8%, Loss: 0.6031\n",
      "Optimization Iteration:   2945, Training Accuracy:  68.8%, Loss: 0.5985\n",
      "Optimization Iteration:   3009, Training Accuracy:  60.9%, Loss: 0.5721\n",
      "Optimization Iteration:   3073, Training Accuracy:  59.4%, Loss: 0.6093\n",
      "Optimization Iteration:   3137, Training Accuracy:  59.4%, Loss: 0.5897\n",
      "Optimization Iteration:   3201, Training Accuracy:  73.4%, Loss: 0.5889\n",
      "Optimization Iteration:   3265, Training Accuracy:  59.4%, Loss: 0.6253\n",
      "Optimization Iteration:   3329, Training Accuracy:  59.4%, Loss: 0.5473\n",
      "Optimization Iteration:   3393, Training Accuracy:  59.4%, Loss: 0.6357\n",
      "Optimization Iteration:   3457, Training Accuracy:  65.6%, Loss: 0.5522\n",
      "Optimization Iteration:   3521, Training Accuracy:  70.3%, Loss: 0.5803\n",
      "Optimization Iteration:   3585, Training Accuracy:  60.9%, Loss: 0.5715\n",
      "Optimization Iteration:   3649, Training Accuracy:  62.5%, Loss: 0.5936\n",
      "Optimization Iteration:   3713, Training Accuracy:  64.1%, Loss: 0.5447\n",
      "Optimization Iteration:   3777, Training Accuracy:  62.5%, Loss: 0.6373\n",
      "Optimization Iteration:   3841, Training Accuracy:  67.2%, Loss: 0.5120\n",
      "Optimization Iteration:   3905, Training Accuracy:  65.6%, Loss: 0.6546\n",
      "Optimization Iteration:   3969, Training Accuracy:  71.9%, Loss: 0.6137\n",
      "Optimization Iteration:   4033, Training Accuracy:  76.6%, Loss: 0.5523\n",
      "Optimization Iteration:   4097, Training Accuracy:  81.2%, Loss: 0.4896\n",
      "Optimization Iteration:   4161, Training Accuracy:  70.3%, Loss: 0.5445\n",
      "Optimization Iteration:   4225, Training Accuracy:  62.5%, Loss: 0.5608\n",
      "Optimization Iteration:   4289, Training Accuracy:  64.1%, Loss: 0.5513\n",
      "Optimization Iteration:   4353, Training Accuracy:  60.9%, Loss: 0.5951\n",
      "Optimization Iteration:   4417, Training Accuracy:  54.7%, Loss: 0.6480\n",
      "Optimization Iteration:   4481, Training Accuracy:  65.6%, Loss: 0.5838\n",
      "Optimization Iteration:   4545, Training Accuracy:  71.9%, Loss: 0.5789\n",
      "Optimization Iteration:   4609, Training Accuracy:  57.8%, Loss: 0.5948\n",
      "Optimization Iteration:   4673, Training Accuracy:  65.6%, Loss: 0.6394\n",
      "Optimization Iteration:   4737, Training Accuracy:  64.1%, Loss: 0.6563\n",
      "Optimization Iteration:   4801, Training Accuracy:  67.2%, Loss: 0.5717\n",
      "Optimization Iteration:   4865, Training Accuracy:  75.0%, Loss: 0.5496\n",
      "Optimization Iteration:   4929, Training Accuracy:  70.3%, Loss: 0.5112\n",
      "Optimization Iteration:   4993, Training Accuracy:  75.0%, Loss: 0.5342\n",
      "Optimization Iteration:   5057, Training Accuracy:  67.2%, Loss: 0.5626\n",
      "Optimization Iteration:   5121, Training Accuracy:  64.1%, Loss: 0.6039\n",
      "Optimization Iteration:   5185, Training Accuracy:  78.1%, Loss: 0.5202\n",
      "Optimization Iteration:   5249, Training Accuracy:  57.8%, Loss: 0.6593\n",
      "Optimization Iteration:   5313, Training Accuracy:  67.2%, Loss: 0.6170\n",
      "Optimization Iteration:   5377, Training Accuracy:  68.8%, Loss: 0.5927\n",
      "Optimization Iteration:   5441, Training Accuracy:  64.1%, Loss: 0.5519\n",
      "Optimization Iteration:   5505, Training Accuracy:  81.2%, Loss: 0.4894\n",
      "Optimization Iteration:   5569, Training Accuracy:  76.6%, Loss: 0.5249\n",
      "Optimization Iteration:   5633, Training Accuracy:  70.3%, Loss: 0.5760\n",
      "Optimization Iteration:   5697, Training Accuracy:  67.2%, Loss: 0.5961\n",
      "Optimization Iteration:   5761, Training Accuracy:  64.1%, Loss: 0.6048\n",
      "Optimization Iteration:   5825, Training Accuracy:  54.7%, Loss: 0.6737\n",
      "Optimization Iteration:   5889, Training Accuracy:  67.2%, Loss: 0.5978\n",
      "Optimization Iteration:   5953, Training Accuracy:  71.9%, Loss: 0.5948\n",
      "Optimization Iteration:   6017, Training Accuracy:  60.9%, Loss: 0.6061\n",
      "Optimization Iteration:   6081, Training Accuracy:  62.5%, Loss: 0.6004\n",
      "Optimization Iteration:   6145, Training Accuracy:  64.1%, Loss: 0.5700\n",
      "Optimization Iteration:   6209, Training Accuracy:  67.2%, Loss: 0.5877\n",
      "Optimization Iteration:   6273, Training Accuracy:  59.4%, Loss: 0.6493\n",
      "Optimization Iteration:   6337, Training Accuracy:  67.2%, Loss: 0.5344\n",
      "Optimization Iteration:   6401, Training Accuracy:  79.7%, Loss: 0.5272\n",
      "Optimization Iteration:   6465, Training Accuracy:  82.8%, Loss: 0.4615\n",
      "Optimization Iteration:   6529, Training Accuracy:  75.0%, Loss: 0.5398\n",
      "Optimization Iteration:   6593, Training Accuracy:  59.4%, Loss: 0.6339\n",
      "Optimization Iteration:   6657, Training Accuracy:  75.0%, Loss: 0.4869\n",
      "Optimization Iteration:   6721, Training Accuracy:  59.4%, Loss: 0.5754\n",
      "Optimization Iteration:   6785, Training Accuracy:  65.6%, Loss: 0.6071\n",
      "Optimization Iteration:   6849, Training Accuracy:  62.5%, Loss: 0.5965\n",
      "Optimization Iteration:   6913, Training Accuracy:  68.8%, Loss: 0.5348\n",
      "Optimization Iteration:   6977, Training Accuracy:  64.1%, Loss: 0.5938\n",
      "Optimization Iteration:   7041, Training Accuracy:  71.9%, Loss: 0.5217\n",
      "Optimization Iteration:   7105, Training Accuracy:  85.9%, Loss: 0.4882\n",
      "Optimization Iteration:   7169, Training Accuracy:  67.2%, Loss: 0.5847\n",
      "Optimization Iteration:   7233, Training Accuracy:  57.8%, Loss: 0.6514\n",
      "Optimization Iteration:   7297, Training Accuracy:  64.1%, Loss: 0.5713\n",
      "Optimization Iteration:   7361, Training Accuracy:  56.2%, Loss: 0.6284\n",
      "Optimization Iteration:   7425, Training Accuracy:  70.3%, Loss: 0.5616\n",
      "Optimization Iteration:   7489, Training Accuracy:  62.5%, Loss: 0.6184\n",
      "Optimization Iteration:   7553, Training Accuracy:  68.8%, Loss: 0.5977\n",
      "Optimization Iteration:   7617, Training Accuracy:  65.6%, Loss: 0.5716\n",
      "Optimization Iteration:   7681, Training Accuracy:  62.5%, Loss: 0.6007\n",
      "Optimization Iteration:   7745, Training Accuracy:  71.9%, Loss: 0.5650\n",
      "Optimization Iteration:   7809, Training Accuracy:  67.2%, Loss: 0.5654\n",
      "Optimization Iteration:   7873, Training Accuracy:  76.6%, Loss: 0.5191\n",
      "Optimization Iteration:   7937, Training Accuracy:  67.2%, Loss: 0.5833\n",
      "Optimization Iteration:   8001, Training Accuracy:  62.5%, Loss: 0.6665\n",
      "Optimization Iteration:   8065, Training Accuracy:  71.9%, Loss: 0.5562\n",
      "Optimization Iteration:   8129, Training Accuracy:  54.7%, Loss: 0.7393\n",
      "Optimization Iteration:   8193, Training Accuracy:  62.5%, Loss: 0.6484\n",
      "Optimization Iteration:   8257, Training Accuracy:  59.4%, Loss: 0.6746\n",
      "Optimization Iteration:   8321, Training Accuracy:  57.8%, Loss: 0.6827\n",
      "Optimization Iteration:   8385, Training Accuracy:  65.6%, Loss: 0.5170\n",
      "Optimization Iteration:   8449, Training Accuracy:  64.1%, Loss: 0.6657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   8513, Training Accuracy:  65.6%, Loss: 0.5175\n",
      "Optimization Iteration:   8577, Training Accuracy:  59.4%, Loss: 0.5826\n",
      "Optimization Iteration:   8641, Training Accuracy:  64.1%, Loss: 0.5651\n",
      "Optimization Iteration:   8705, Training Accuracy:  68.8%, Loss: 0.5650\n",
      "Optimization Iteration:   8769, Training Accuracy:  65.6%, Loss: 0.6202\n",
      "Optimization Iteration:   8833, Training Accuracy:  67.2%, Loss: 0.6131\n",
      "Optimization Iteration:   8897, Training Accuracy:  65.6%, Loss: 0.5814\n",
      "Optimization Iteration:   8961, Training Accuracy:  70.3%, Loss: 0.5623\n",
      "Optimization Iteration:   9025, Training Accuracy:  62.5%, Loss: 0.6958\n",
      "Optimization Iteration:   9089, Training Accuracy:  51.6%, Loss: 0.6994\n",
      "Optimization Iteration:   9153, Training Accuracy:  67.2%, Loss: 0.5799\n",
      "Optimization Iteration:   9217, Training Accuracy:  75.0%, Loss: 0.5165\n",
      "Optimization Iteration:   9281, Training Accuracy:  62.5%, Loss: 0.6099\n",
      "Optimization Iteration:   9345, Training Accuracy:  75.0%, Loss: 0.5236\n",
      "Optimization Iteration:   9409, Training Accuracy:  64.1%, Loss: 0.6088\n",
      "Optimization Iteration:   9473, Training Accuracy:  70.3%, Loss: 0.5576\n",
      "Optimization Iteration:   9537, Training Accuracy:  70.3%, Loss: 0.5182\n",
      "Optimization Iteration:   9601, Training Accuracy:  67.2%, Loss: 0.5493\n",
      "Optimization Iteration:   9665, Training Accuracy:  60.9%, Loss: 0.6424\n",
      "Optimization Iteration:   9729, Training Accuracy:  57.8%, Loss: 0.6021\n",
      "Optimization Iteration:   9793, Training Accuracy:  73.4%, Loss: 0.4487\n",
      "Optimization Iteration:   9857, Training Accuracy:  71.9%, Loss: 0.5540\n",
      "Optimization Iteration:   9921, Training Accuracy:  64.1%, Loss: 0.5569\n",
      "Optimization Iteration:   9985, Training Accuracy:  71.9%, Loss: 0.5475\n",
      "Optimization Iteration:  10049, Training Accuracy:  68.8%, Loss: 0.5448\n",
      "Optimization Iteration:  10113, Training Accuracy:  68.8%, Loss: 0.5386\n",
      "Optimization Iteration:  10177, Training Accuracy:  62.5%, Loss: 0.6675\n",
      "Optimization Iteration:  10241, Training Accuracy:  68.8%, Loss: 0.5806\n",
      "Optimization Iteration:  10305, Training Accuracy:  73.4%, Loss: 0.6301\n",
      "Optimization Iteration:  10369, Training Accuracy:  60.9%, Loss: 0.5993\n",
      "Optimization Iteration:  10433, Training Accuracy:  60.9%, Loss: 0.5646\n",
      "Optimization Iteration:  10497, Training Accuracy:  57.8%, Loss: 0.6779\n",
      "Optimization Iteration:  10561, Training Accuracy:  67.2%, Loss: 0.4993\n",
      "Optimization Iteration:  10625, Training Accuracy:  68.8%, Loss: 0.5776\n",
      "Optimization Iteration:  10689, Training Accuracy:  71.9%, Loss: 0.5775\n",
      "Optimization Iteration:  10753, Training Accuracy:  70.3%, Loss: 0.5314\n",
      "Optimization Iteration:  10817, Training Accuracy:  64.1%, Loss: 0.6084\n",
      "Optimization Iteration:  10881, Training Accuracy:  75.0%, Loss: 0.5532\n",
      "Optimization Iteration:  10945, Training Accuracy:  76.6%, Loss: 0.5344\n",
      "Optimization Iteration:  11009, Training Accuracy:  67.2%, Loss: 0.5691\n",
      "Optimization Iteration:  11073, Training Accuracy:  70.3%, Loss: 0.5252\n",
      "Optimization Iteration:  11137, Training Accuracy:  64.1%, Loss: 0.6370\n",
      "Optimization Iteration:  11201, Training Accuracy:  71.9%, Loss: 0.5200\n",
      "Optimization Iteration:  11265, Training Accuracy:  75.0%, Loss: 0.4741\n",
      "Optimization Iteration:  11329, Training Accuracy:  64.1%, Loss: 0.5609\n",
      "Optimization Iteration:  11393, Training Accuracy:  57.8%, Loss: 0.6097\n",
      "Optimization Iteration:  11457, Training Accuracy:  78.1%, Loss: 0.5121\n",
      "Optimization Iteration:  11521, Training Accuracy:  65.6%, Loss: 0.6406\n",
      "Optimization Iteration:  11585, Training Accuracy:  67.2%, Loss: 0.5830\n",
      "Optimization Iteration:  11649, Training Accuracy:  54.7%, Loss: 0.6333\n",
      "Optimization Iteration:  11713, Training Accuracy:  67.2%, Loss: 0.6149\n",
      "Optimization Iteration:  11777, Training Accuracy:  68.8%, Loss: 0.5742\n",
      "Optimization Iteration:  11841, Training Accuracy:  73.4%, Loss: 0.5481\n",
      "Optimization Iteration:  11905, Training Accuracy:  71.9%, Loss: 0.5823\n",
      "Optimization Iteration:  11969, Training Accuracy:  71.9%, Loss: 0.5032\n",
      "Optimization Iteration:  12033, Training Accuracy:  70.3%, Loss: 0.5990\n",
      "Optimization Iteration:  12097, Training Accuracy:  60.9%, Loss: 0.6478\n",
      "Optimization Iteration:  12161, Training Accuracy:  62.5%, Loss: 0.6087\n",
      "Optimization Iteration:  12225, Training Accuracy:  62.5%, Loss: 0.6533\n",
      "Optimization Iteration:  12289, Training Accuracy:  75.0%, Loss: 0.5015\n",
      "Optimization Iteration:  12353, Training Accuracy:  67.2%, Loss: 0.5607\n",
      "Optimization Iteration:  12417, Training Accuracy:  59.4%, Loss: 0.5634\n",
      "Optimization Iteration:  12481, Training Accuracy:  68.8%, Loss: 0.5409\n",
      "Optimization Iteration:  12545, Training Accuracy:  64.1%, Loss: 0.5892\n",
      "Optimization Iteration:  12609, Training Accuracy:  65.6%, Loss: 0.6310\n",
      "Optimization Iteration:  12673, Training Accuracy:  73.4%, Loss: 0.5276\n",
      "Optimization Iteration:  12737, Training Accuracy:  64.1%, Loss: 0.6470\n",
      "Optimization Iteration:  12801, Training Accuracy:  68.8%, Loss: 0.5262\n",
      "Optimization Iteration:  12865, Training Accuracy:  60.9%, Loss: 0.6268\n",
      "Optimization Iteration:  12929, Training Accuracy:  73.4%, Loss: 0.4873\n",
      "Optimization Iteration:  12993, Training Accuracy:  46.9%, Loss: 0.6212\n",
      "Optimization Iteration:  13057, Training Accuracy:  57.8%, Loss: 0.6208\n",
      "Optimization Iteration:  13121, Training Accuracy:  67.2%, Loss: 0.5995\n",
      "Optimization Iteration:  13185, Training Accuracy:  60.9%, Loss: 0.7000\n",
      "Optimization Iteration:  13249, Training Accuracy:  73.4%, Loss: 0.5560\n",
      "Optimization Iteration:  13313, Training Accuracy:  70.3%, Loss: 0.5805\n",
      "Optimization Iteration:  13377, Training Accuracy:  71.9%, Loss: 0.5601\n",
      "Optimization Iteration:  13441, Training Accuracy:  71.9%, Loss: 0.5499\n",
      "Optimization Iteration:  13505, Training Accuracy:  62.5%, Loss: 0.6043\n",
      "Optimization Iteration:  13569, Training Accuracy:  71.9%, Loss: 0.4776\n",
      "Optimization Iteration:  13633, Training Accuracy:  81.2%, Loss: 0.4594\n",
      "Optimization Iteration:  13697, Training Accuracy:  71.9%, Loss: 0.5575\n",
      "Optimization Iteration:  13761, Training Accuracy:  65.6%, Loss: 0.5812\n",
      "Optimization Iteration:  13825, Training Accuracy:  56.2%, Loss: 0.7503\n",
      "Optimization Iteration:  13889, Training Accuracy:  68.8%, Loss: 0.6093\n",
      "Optimization Iteration:  13953, Training Accuracy:  76.6%, Loss: 0.4659\n",
      "Optimization Iteration:  14017, Training Accuracy:  67.2%, Loss: 0.5952\n",
      "Optimization Iteration:  14081, Training Accuracy:  73.4%, Loss: 0.5886\n",
      "Optimization Iteration:  14145, Training Accuracy:  60.9%, Loss: 0.6555\n",
      "Optimization Iteration:  14209, Training Accuracy:  65.6%, Loss: 0.6062\n",
      "Optimization Iteration:  14273, Training Accuracy:  62.5%, Loss: 0.6007\n",
      "Optimization Iteration:  14337, Training Accuracy:  70.3%, Loss: 0.5768\n",
      "Optimization Iteration:  14401, Training Accuracy:  73.4%, Loss: 0.5204\n",
      "Optimization Iteration:  14465, Training Accuracy:  67.2%, Loss: 0.5716\n",
      "Optimization Iteration:  14529, Training Accuracy:  75.0%, Loss: 0.5026\n",
      "Optimization Iteration:  14593, Training Accuracy:  65.6%, Loss: 0.5504\n",
      "Optimization Iteration:  14657, Training Accuracy:  70.3%, Loss: 0.5361\n",
      "Optimization Iteration:  14721, Training Accuracy:  65.6%, Loss: 0.4996\n",
      "Optimization Iteration:  14785, Training Accuracy:  65.6%, Loss: 0.6078\n",
      "Optimization Iteration:  14849, Training Accuracy:  62.5%, Loss: 0.5634\n",
      "Optimization Iteration:  14913, Training Accuracy:  78.1%, Loss: 0.4796\n",
      "Optimization Iteration:  14977, Training Accuracy:  73.4%, Loss: 0.6057\n",
      "Optimization Iteration:  15041, Training Accuracy:  60.9%, Loss: 0.6757\n",
      "Optimization Iteration:  15105, Training Accuracy:  65.6%, Loss: 0.5794\n",
      "Optimization Iteration:  15169, Training Accuracy:  67.2%, Loss: 0.5560\n",
      "Optimization Iteration:  15233, Training Accuracy:  68.8%, Loss: 0.5467\n",
      "Optimization Iteration:  15297, Training Accuracy:  75.0%, Loss: 0.5077\n",
      "Optimization Iteration:  15361, Training Accuracy:  81.2%, Loss: 0.5141\n",
      "Optimization Iteration:  15425, Training Accuracy:  62.5%, Loss: 0.5470\n",
      "Optimization Iteration:  15489, Training Accuracy:  57.8%, Loss: 0.7141\n",
      "Optimization Iteration:  15553, Training Accuracy:  68.8%, Loss: 0.4973\n",
      "Optimization Iteration:  15617, Training Accuracy:  75.0%, Loss: 0.5197\n",
      "Optimization Iteration:  15681, Training Accuracy:  65.6%, Loss: 0.5591\n",
      "Optimization Iteration:  15745, Training Accuracy:  76.6%, Loss: 0.4846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  15809, Training Accuracy:  75.0%, Loss: 0.5641\n",
      "Optimization Iteration:  15873, Training Accuracy:  65.6%, Loss: 0.5735\n",
      "Optimization Iteration:  15937, Training Accuracy:  78.1%, Loss: 0.4881\n",
      "Optimization Iteration:  16001, Training Accuracy:  60.9%, Loss: 0.6113\n",
      "Optimization Iteration:  16065, Training Accuracy:  65.6%, Loss: 0.6193\n",
      "Optimization Iteration:  16129, Training Accuracy:  64.1%, Loss: 0.6363\n",
      "Optimization Iteration:  16193, Training Accuracy:  81.2%, Loss: 0.4533\n",
      "Optimization Iteration:  16257, Training Accuracy:  67.2%, Loss: 0.5884\n",
      "Optimization Iteration:  16321, Training Accuracy:  70.3%, Loss: 0.5701\n",
      "Optimization Iteration:  16385, Training Accuracy:  68.8%, Loss: 0.5835\n",
      "Optimization Iteration:  16449, Training Accuracy:  76.6%, Loss: 0.5520\n",
      "Optimization Iteration:  16513, Training Accuracy:  64.1%, Loss: 0.6201\n",
      "Optimization Iteration:  16577, Training Accuracy:  65.6%, Loss: 0.5631\n",
      "Optimization Iteration:  16641, Training Accuracy:  79.7%, Loss: 0.5258\n",
      "Optimization Iteration:  16705, Training Accuracy:  68.8%, Loss: 0.5770\n",
      "Optimization Iteration:  16769, Training Accuracy:  71.9%, Loss: 0.5840\n",
      "Optimization Iteration:  16833, Training Accuracy:  70.3%, Loss: 0.5087\n",
      "Optimization Iteration:  16897, Training Accuracy:  79.7%, Loss: 0.4907\n",
      "Optimization Iteration:  16961, Training Accuracy:  70.3%, Loss: 0.5957\n",
      "Optimization Iteration:  17025, Training Accuracy:  56.2%, Loss: 0.7235\n",
      "Optimization Iteration:  17089, Training Accuracy:  65.6%, Loss: 0.5787\n",
      "Optimization Iteration:  17153, Training Accuracy:  64.1%, Loss: 0.5638\n",
      "Optimization Iteration:  17217, Training Accuracy:  65.6%, Loss: 0.6403\n",
      "Optimization Iteration:  17281, Training Accuracy:  68.8%, Loss: 0.4998\n",
      "Optimization Iteration:  17345, Training Accuracy:  76.6%, Loss: 0.5915\n",
      "Optimization Iteration:  17409, Training Accuracy:  76.6%, Loss: 0.5099\n",
      "Optimization Iteration:  17473, Training Accuracy:  59.4%, Loss: 0.6266\n",
      "Optimization Iteration:  17537, Training Accuracy:  71.9%, Loss: 0.4865\n",
      "Optimization Iteration:  17601, Training Accuracy:  57.8%, Loss: 0.6140\n",
      "Optimization Iteration:  17665, Training Accuracy:  71.9%, Loss: 0.5382\n",
      "Optimization Iteration:  17729, Training Accuracy:  76.6%, Loss: 0.5231\n",
      "Optimization Iteration:  17793, Training Accuracy:  71.9%, Loss: 0.5330\n",
      "Optimization Iteration:  17857, Training Accuracy:  73.4%, Loss: 0.5931\n",
      "Optimization Iteration:  17921, Training Accuracy:  68.8%, Loss: 0.5754\n",
      "Optimization Iteration:  17985, Training Accuracy:  60.9%, Loss: 0.6044\n",
      "Optimization Iteration:  18049, Training Accuracy:  67.2%, Loss: 0.5320\n",
      "Optimization Iteration:  18113, Training Accuracy:  60.9%, Loss: 0.5913\n",
      "Optimization Iteration:  18177, Training Accuracy:  67.2%, Loss: 0.5939\n",
      "Optimization Iteration:  18241, Training Accuracy:  73.4%, Loss: 0.5011\n",
      "Optimization Iteration:  18305, Training Accuracy:  67.2%, Loss: 0.5924\n",
      "Optimization Iteration:  18369, Training Accuracy:  65.6%, Loss: 0.4996\n",
      "Optimization Iteration:  18433, Training Accuracy:  68.8%, Loss: 0.5997\n",
      "Optimization Iteration:  18497, Training Accuracy:  68.8%, Loss: 0.5218\n",
      "Optimization Iteration:  18561, Training Accuracy:  75.0%, Loss: 0.5933\n",
      "Optimization Iteration:  18625, Training Accuracy:  60.9%, Loss: 0.6688\n",
      "Optimization Iteration:  18689, Training Accuracy:  62.5%, Loss: 0.5593\n",
      "Optimization Iteration:  18753, Training Accuracy:  56.2%, Loss: 0.6178\n",
      "Optimization Iteration:  18817, Training Accuracy:  64.1%, Loss: 0.5571\n",
      "Optimization Iteration:  18881, Training Accuracy:  64.1%, Loss: 0.5925\n",
      "Optimization Iteration:  18945, Training Accuracy:  73.4%, Loss: 0.5683\n",
      "Optimization Iteration:  19009, Training Accuracy:  64.1%, Loss: 0.6081\n",
      "Optimization Iteration:  19073, Training Accuracy:  60.9%, Loss: 0.6534\n",
      "Optimization Iteration:  19137, Training Accuracy:  68.8%, Loss: 0.5687\n",
      "Optimization Iteration:  19201, Training Accuracy:  71.9%, Loss: 0.5160\n",
      "Optimization Iteration:  19265, Training Accuracy:  79.7%, Loss: 0.4967\n",
      "Optimization Iteration:  19329, Training Accuracy:  71.9%, Loss: 0.4732\n",
      "Optimization Iteration:  19393, Training Accuracy:  68.8%, Loss: 0.5972\n",
      "Optimization Iteration:  19457, Training Accuracy:  71.9%, Loss: 0.4795\n",
      "Optimization Iteration:  19521, Training Accuracy:  64.1%, Loss: 0.5586\n",
      "Optimization Iteration:  19585, Training Accuracy:  64.1%, Loss: 0.5711\n",
      "Optimization Iteration:  19649, Training Accuracy:  62.5%, Loss: 0.6935\n",
      "Optimization Iteration:  19713, Training Accuracy:  71.9%, Loss: 0.5892\n",
      "Optimization Iteration:  19777, Training Accuracy:  68.8%, Loss: 0.5436\n",
      "Optimization Iteration:  19841, Training Accuracy:  65.6%, Loss: 0.5441\n",
      "Optimization Iteration:  19905, Training Accuracy:  64.1%, Loss: 0.5742\n",
      "Optimization Iteration:  19969, Training Accuracy:  73.4%, Loss: 0.4779\n",
      "Optimization Iteration:  20033, Training Accuracy:  73.4%, Loss: 0.5526\n",
      "Optimization Iteration:  20097, Training Accuracy:  73.4%, Loss: 0.5353\n",
      "Optimization Iteration:  20161, Training Accuracy:  68.8%, Loss: 0.5726\n",
      "Optimization Iteration:  20225, Training Accuracy:  65.6%, Loss: 0.6086\n",
      "Optimization Iteration:  20289, Training Accuracy:  60.9%, Loss: 0.6033\n",
      "Optimization Iteration:  20353, Training Accuracy:  65.6%, Loss: 0.5805\n",
      "Optimization Iteration:  20417, Training Accuracy:  68.8%, Loss: 0.5606\n",
      "Optimization Iteration:  20481, Training Accuracy:  64.1%, Loss: 0.5222\n",
      "Optimization Iteration:  20545, Training Accuracy:  64.1%, Loss: 0.5931\n",
      "Optimization Iteration:  20609, Training Accuracy:  70.3%, Loss: 0.5705\n",
      "Optimization Iteration:  20673, Training Accuracy:  60.9%, Loss: 0.5967\n",
      "Optimization Iteration:  20737, Training Accuracy:  76.6%, Loss: 0.5300\n",
      "Optimization Iteration:  20801, Training Accuracy:  71.9%, Loss: 0.5266\n",
      "Optimization Iteration:  20865, Training Accuracy:  76.6%, Loss: 0.5388\n",
      "Optimization Iteration:  20929, Training Accuracy:  79.7%, Loss: 0.4585\n",
      "Optimization Iteration:  20993, Training Accuracy:  84.4%, Loss: 0.4846\n",
      "Optimization Iteration:  21057, Training Accuracy:  68.8%, Loss: 0.5014\n",
      "Optimization Iteration:  21121, Training Accuracy:  67.2%, Loss: 0.5665\n",
      "Optimization Iteration:  21185, Training Accuracy:  75.0%, Loss: 0.5272\n",
      "Optimization Iteration:  21249, Training Accuracy:  65.6%, Loss: 0.5839\n",
      "Optimization Iteration:  21313, Training Accuracy:  71.9%, Loss: 0.5663\n",
      "Optimization Iteration:  21377, Training Accuracy:  71.9%, Loss: 0.5273\n",
      "Optimization Iteration:  21441, Training Accuracy:  68.8%, Loss: 0.5676\n",
      "Optimization Iteration:  21505, Training Accuracy:  64.1%, Loss: 0.6214\n",
      "Optimization Iteration:  21569, Training Accuracy:  70.3%, Loss: 0.4841\n",
      "Optimization Iteration:  21633, Training Accuracy:  68.8%, Loss: 0.5386\n",
      "Optimization Iteration:  21697, Training Accuracy:  67.2%, Loss: 0.5805\n",
      "Optimization Iteration:  21761, Training Accuracy:  73.4%, Loss: 0.4816\n",
      "Optimization Iteration:  21825, Training Accuracy:  59.4%, Loss: 0.5996\n",
      "Optimization Iteration:  21889, Training Accuracy:  59.4%, Loss: 0.6003\n",
      "Optimization Iteration:  21953, Training Accuracy:  71.9%, Loss: 0.5552\n",
      "Optimization Iteration:  22017, Training Accuracy:  60.9%, Loss: 0.6129\n",
      "Optimization Iteration:  22081, Training Accuracy:  57.8%, Loss: 0.5863\n",
      "Optimization Iteration:  22145, Training Accuracy:  71.9%, Loss: 0.5173\n",
      "Optimization Iteration:  22209, Training Accuracy:  65.6%, Loss: 0.5778\n",
      "Optimization Iteration:  22273, Training Accuracy:  62.5%, Loss: 0.5807\n",
      "Optimization Iteration:  22337, Training Accuracy:  73.4%, Loss: 0.4979\n",
      "Optimization Iteration:  22401, Training Accuracy:  78.1%, Loss: 0.5323\n",
      "Optimization Iteration:  22465, Training Accuracy:  68.8%, Loss: 0.5212\n",
      "Optimization Iteration:  22529, Training Accuracy:  70.3%, Loss: 0.5897\n",
      "Optimization Iteration:  22593, Training Accuracy:  64.1%, Loss: 0.5463\n",
      "Optimization Iteration:  22657, Training Accuracy:  70.3%, Loss: 0.6409\n",
      "Optimization Iteration:  22721, Training Accuracy:  60.9%, Loss: 0.5414\n",
      "Optimization Iteration:  22785, Training Accuracy:  67.2%, Loss: 0.5986\n",
      "Optimization Iteration:  22849, Training Accuracy:  62.5%, Loss: 0.5361\n",
      "Optimization Iteration:  22913, Training Accuracy:  75.0%, Loss: 0.5449\n",
      "Optimization Iteration:  22977, Training Accuracy:  65.6%, Loss: 0.5194\n",
      "Optimization Iteration:  23041, Training Accuracy:  65.6%, Loss: 0.5397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  23105, Training Accuracy:  64.1%, Loss: 0.5502\n",
      "Optimization Iteration:  23169, Training Accuracy:  82.8%, Loss: 0.4476\n",
      "Optimization Iteration:  23233, Training Accuracy:  68.8%, Loss: 0.5909\n",
      "Optimization Iteration:  23297, Training Accuracy:  70.3%, Loss: 0.5747\n",
      "Optimization Iteration:  23361, Training Accuracy:  65.6%, Loss: 0.5932\n",
      "Optimization Iteration:  23425, Training Accuracy:  71.9%, Loss: 0.5866\n",
      "Optimization Iteration:  23489, Training Accuracy:  62.5%, Loss: 0.5516\n",
      "Optimization Iteration:  23553, Training Accuracy:  67.2%, Loss: 0.5049\n",
      "Optimization Iteration:  23617, Training Accuracy:  59.4%, Loss: 0.5584\n",
      "Optimization Iteration:  23681, Training Accuracy:  59.4%, Loss: 0.5927\n",
      "Optimization Iteration:  23745, Training Accuracy:  70.3%, Loss: 0.5543\n",
      "Optimization Iteration:  23809, Training Accuracy:  67.2%, Loss: 0.5865\n",
      "Optimization Iteration:  23873, Training Accuracy:  67.2%, Loss: 0.5000\n",
      "Optimization Iteration:  23937, Training Accuracy:  65.6%, Loss: 0.6378\n",
      "Optimization Iteration:  24001, Training Accuracy:  68.8%, Loss: 0.5318\n",
      "Optimization Iteration:  24065, Training Accuracy:  65.6%, Loss: 0.5602\n",
      "Optimization Iteration:  24129, Training Accuracy:  73.4%, Loss: 0.5360\n",
      "Optimization Iteration:  24193, Training Accuracy:  71.9%, Loss: 0.5285\n",
      "Optimization Iteration:  24257, Training Accuracy:  65.6%, Loss: 0.5511\n",
      "Optimization Iteration:  24321, Training Accuracy:  68.8%, Loss: 0.4892\n",
      "Optimization Iteration:  24385, Training Accuracy:  67.2%, Loss: 0.6093\n",
      "Optimization Iteration:  24449, Training Accuracy:  68.8%, Loss: 0.5326\n",
      "Optimization Iteration:  24513, Training Accuracy:  70.3%, Loss: 0.4801\n",
      "Optimization Iteration:  24577, Training Accuracy:  62.5%, Loss: 0.7048\n",
      "Optimization Iteration:  24641, Training Accuracy:  79.7%, Loss: 0.4790\n",
      "Optimization Iteration:  24705, Training Accuracy:  70.3%, Loss: 0.5358\n",
      "Optimization Iteration:  24769, Training Accuracy:  54.7%, Loss: 0.6476\n",
      "Optimization Iteration:  24833, Training Accuracy:  60.9%, Loss: 0.5569\n",
      "Optimization Iteration:  24897, Training Accuracy:  53.1%, Loss: 0.5899\n",
      "Optimization Iteration:  24961, Training Accuracy:  75.0%, Loss: 0.4784\n",
      "Optimization Iteration:  25025, Training Accuracy:  71.9%, Loss: 0.5261\n",
      "Optimization Iteration:  25089, Training Accuracy:  65.6%, Loss: 0.4926\n",
      "Optimization Iteration:  25153, Training Accuracy:  64.1%, Loss: 0.5819\n",
      "Optimization Iteration:  25217, Training Accuracy:  68.8%, Loss: 0.5577\n",
      "Optimization Iteration:  25281, Training Accuracy:  71.9%, Loss: 0.5688\n",
      "Optimization Iteration:  25345, Training Accuracy:  73.4%, Loss: 0.5451\n",
      "Optimization Iteration:  25409, Training Accuracy:  57.8%, Loss: 0.7355\n",
      "Optimization Iteration:  25473, Training Accuracy:  68.8%, Loss: 0.6439\n",
      "Optimization Iteration:  25537, Training Accuracy:  65.6%, Loss: 0.6001\n",
      "Optimization Iteration:  25601, Training Accuracy:  68.8%, Loss: 0.5925\n",
      "Optimization Iteration:  25665, Training Accuracy:  56.2%, Loss: 0.5680\n",
      "Optimization Iteration:  25729, Training Accuracy:  64.1%, Loss: 0.5312\n",
      "Optimization Iteration:  25793, Training Accuracy:  73.4%, Loss: 0.5619\n",
      "Optimization Iteration:  25857, Training Accuracy:  62.5%, Loss: 0.5723\n",
      "Optimization Iteration:  25921, Training Accuracy:  67.2%, Loss: 0.5850\n",
      "Optimization Iteration:  25985, Training Accuracy:  56.2%, Loss: 0.6943\n",
      "Optimization Iteration:  26049, Training Accuracy:  65.6%, Loss: 0.5812\n",
      "Optimization Iteration:  26113, Training Accuracy:  70.3%, Loss: 0.5272\n",
      "Optimization Iteration:  26177, Training Accuracy:  68.8%, Loss: 0.5218\n",
      "Optimization Iteration:  26241, Training Accuracy:  68.8%, Loss: 0.5577\n",
      "Optimization Iteration:  26305, Training Accuracy:  64.1%, Loss: 0.5955\n",
      "Optimization Iteration:  26369, Training Accuracy:  62.5%, Loss: 0.5400\n",
      "Optimization Iteration:  26433, Training Accuracy:  68.8%, Loss: 0.5417\n",
      "Optimization Iteration:  26497, Training Accuracy:  73.4%, Loss: 0.5278\n",
      "Optimization Iteration:  26561, Training Accuracy:  70.3%, Loss: 0.5423\n",
      "Optimization Iteration:  26625, Training Accuracy:  73.4%, Loss: 0.5563\n",
      "Optimization Iteration:  26689, Training Accuracy:  62.5%, Loss: 0.5468\n",
      "Optimization Iteration:  26753, Training Accuracy:  64.1%, Loss: 0.5908\n",
      "Optimization Iteration:  26817, Training Accuracy:  59.4%, Loss: 0.6525\n",
      "Optimization Iteration:  26881, Training Accuracy:  70.3%, Loss: 0.4646\n",
      "Optimization Iteration:  26945, Training Accuracy:  60.9%, Loss: 0.5578\n",
      "Optimization Iteration:  27009, Training Accuracy:  64.1%, Loss: 0.5715\n",
      "Optimization Iteration:  27073, Training Accuracy:  67.2%, Loss: 0.5727\n",
      "Optimization Iteration:  27137, Training Accuracy:  67.2%, Loss: 0.6127\n",
      "Optimization Iteration:  27201, Training Accuracy:  73.4%, Loss: 0.4833\n",
      "Optimization Iteration:  27265, Training Accuracy:  68.8%, Loss: 0.5616\n",
      "Optimization Iteration:  27329, Training Accuracy:  81.2%, Loss: 0.4628\n",
      "Optimization Iteration:  27393, Training Accuracy:  68.8%, Loss: 0.5609\n",
      "Optimization Iteration:  27457, Training Accuracy:  73.4%, Loss: 0.5483\n",
      "Optimization Iteration:  27521, Training Accuracy:  67.2%, Loss: 0.5966\n",
      "Optimization Iteration:  27585, Training Accuracy:  71.9%, Loss: 0.4964\n",
      "Optimization Iteration:  27649, Training Accuracy:  67.2%, Loss: 0.5826\n",
      "Optimization Iteration:  27713, Training Accuracy:  59.4%, Loss: 0.5733\n",
      "Optimization Iteration:  27777, Training Accuracy:  73.4%, Loss: 0.4649\n",
      "Optimization Iteration:  27841, Training Accuracy:  60.9%, Loss: 0.6263\n",
      "Optimization Iteration:  27905, Training Accuracy:  59.4%, Loss: 0.5614\n",
      "Optimization Iteration:  27969, Training Accuracy:  65.6%, Loss: 0.6241\n",
      "Optimization Iteration:  28033, Training Accuracy:  67.2%, Loss: 0.5631\n",
      "Optimization Iteration:  28097, Training Accuracy:  75.0%, Loss: 0.5210\n",
      "Optimization Iteration:  28161, Training Accuracy:  70.3%, Loss: 0.4852\n",
      "Optimization Iteration:  28225, Training Accuracy:  57.8%, Loss: 0.5987\n",
      "Optimization Iteration:  28289, Training Accuracy:  67.2%, Loss: 0.6652\n",
      "Optimization Iteration:  28353, Training Accuracy:  71.9%, Loss: 0.4690\n",
      "Optimization Iteration:  28417, Training Accuracy:  64.1%, Loss: 0.5469\n",
      "Optimization Iteration:  28481, Training Accuracy:  65.6%, Loss: 0.6062\n",
      "Optimization Iteration:  28545, Training Accuracy:  76.6%, Loss: 0.4792\n",
      "Optimization Iteration:  28609, Training Accuracy:  64.1%, Loss: 0.5547\n",
      "Optimization Iteration:  28673, Training Accuracy:  64.1%, Loss: 0.6018\n",
      "Optimization Iteration:  28737, Training Accuracy:  67.2%, Loss: 0.6169\n",
      "Optimization Iteration:  28801, Training Accuracy:  65.6%, Loss: 0.5151\n",
      "Optimization Iteration:  28865, Training Accuracy:  75.0%, Loss: 0.5505\n",
      "Optimization Iteration:  28929, Training Accuracy:  59.4%, Loss: 0.5730\n",
      "Optimization Iteration:  28993, Training Accuracy:  75.0%, Loss: 0.5198\n",
      "Optimization Iteration:  29057, Training Accuracy:  68.8%, Loss: 0.5969\n",
      "Optimization Iteration:  29121, Training Accuracy:  67.2%, Loss: 0.5759\n",
      "Optimization Iteration:  29185, Training Accuracy:  81.2%, Loss: 0.4983\n",
      "Optimization Iteration:  29249, Training Accuracy:  67.2%, Loss: 0.5454\n",
      "Optimization Iteration:  29313, Training Accuracy:  79.7%, Loss: 0.5224\n",
      "Optimization Iteration:  29377, Training Accuracy:  71.9%, Loss: 0.5090\n",
      "Optimization Iteration:  29441, Training Accuracy:  60.9%, Loss: 0.6712\n",
      "Optimization Iteration:  29505, Training Accuracy:  76.6%, Loss: 0.5116\n",
      "Optimization Iteration:  29569, Training Accuracy:  73.4%, Loss: 0.4753\n",
      "Optimization Iteration:  29633, Training Accuracy:  64.1%, Loss: 0.5529\n",
      "Optimization Iteration:  29697, Training Accuracy:  73.4%, Loss: 0.4677\n",
      "Optimization Iteration:  29761, Training Accuracy:  67.2%, Loss: 0.6341\n",
      "Optimization Iteration:  29825, Training Accuracy:  64.1%, Loss: 0.6068\n",
      "Optimization Iteration:  29889, Training Accuracy:  76.6%, Loss: 0.5288\n",
      "Optimization Iteration:  29953, Training Accuracy:  60.9%, Loss: 0.5759\n",
      "Optimization Iteration:  30017, Training Accuracy:  71.9%, Loss: 0.5029\n",
      "Optimization Iteration:  30081, Training Accuracy:  76.6%, Loss: 0.4452\n",
      "Optimization Iteration:  30145, Training Accuracy:  70.3%, Loss: 0.5268\n",
      "Optimization Iteration:  30209, Training Accuracy:  73.4%, Loss: 0.4808\n",
      "Optimization Iteration:  30273, Training Accuracy:  73.4%, Loss: 0.4886\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.4756\n",
      "Optimization Iteration:  30401, Training Accuracy:  78.1%, Loss: 0.5409\n",
      "Optimization Iteration:  30465, Training Accuracy:  73.4%, Loss: 0.5651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  30529, Training Accuracy:  73.4%, Loss: 0.5218\n",
      "Optimization Iteration:  30593, Training Accuracy:  71.9%, Loss: 0.4772\n",
      "Optimization Iteration:  30657, Training Accuracy:  62.5%, Loss: 0.5008\n",
      "Optimization Iteration:  30721, Training Accuracy:  71.9%, Loss: 0.5591\n",
      "Optimization Iteration:  30785, Training Accuracy:  67.2%, Loss: 0.5575\n",
      "Optimization Iteration:  30849, Training Accuracy:  68.8%, Loss: 0.5337\n",
      "Optimization Iteration:  30913, Training Accuracy:  68.8%, Loss: 0.5050\n",
      "Optimization Iteration:  30977, Training Accuracy:  75.0%, Loss: 0.5366\n",
      "Optimization Iteration:  31041, Training Accuracy:  71.9%, Loss: 0.4497\n",
      "Optimization Iteration:  31105, Training Accuracy:  65.6%, Loss: 0.5472\n",
      "Optimization Iteration:  31169, Training Accuracy:  65.6%, Loss: 0.5247\n",
      "Optimization Iteration:  31233, Training Accuracy:  71.9%, Loss: 0.4910\n",
      "Optimization Iteration:  31297, Training Accuracy:  71.9%, Loss: 0.5633\n",
      "Optimization Iteration:  31361, Training Accuracy:  65.6%, Loss: 0.4947\n",
      "Optimization Iteration:  31425, Training Accuracy:  78.1%, Loss: 0.5268\n",
      "Optimization Iteration:  31489, Training Accuracy:  75.0%, Loss: 0.5069\n",
      "Optimization Iteration:  31553, Training Accuracy:  68.8%, Loss: 0.4870\n",
      "Optimization Iteration:  31617, Training Accuracy:  73.4%, Loss: 0.4994\n",
      "Optimization Iteration:  31681, Training Accuracy:  60.9%, Loss: 0.6626\n",
      "Optimization Iteration:  31745, Training Accuracy:  65.6%, Loss: 0.5640\n",
      "Optimization Iteration:  31809, Training Accuracy:  62.5%, Loss: 0.5989\n",
      "Optimization Iteration:  31873, Training Accuracy:  68.8%, Loss: 0.4892\n",
      "Optimization Iteration:  31937, Training Accuracy:  70.3%, Loss: 0.5209\n",
      "Optimization Iteration:  32001, Training Accuracy:  78.1%, Loss: 0.5156\n",
      "Optimization Iteration:  32065, Training Accuracy:  59.4%, Loss: 0.5429\n",
      "Optimization Iteration:  32129, Training Accuracy:  65.6%, Loss: 0.5250\n",
      "Optimization Iteration:  32193, Training Accuracy:  59.4%, Loss: 0.6242\n",
      "Optimization Iteration:  32257, Training Accuracy:  64.1%, Loss: 0.6217\n",
      "Optimization Iteration:  32321, Training Accuracy:  75.0%, Loss: 0.4634\n",
      "Optimization Iteration:  32385, Training Accuracy:  73.4%, Loss: 0.4932\n",
      "Optimization Iteration:  32449, Training Accuracy:  73.4%, Loss: 0.5004\n",
      "Optimization Iteration:  32513, Training Accuracy:  70.3%, Loss: 0.6159\n",
      "Optimization Iteration:  32577, Training Accuracy:  59.4%, Loss: 0.5983\n",
      "Optimization Iteration:  32641, Training Accuracy:  64.1%, Loss: 0.5183\n",
      "Optimization Iteration:  32705, Training Accuracy:  73.4%, Loss: 0.5173\n",
      "Optimization Iteration:  32769, Training Accuracy:  75.0%, Loss: 0.4696\n",
      "Optimization Iteration:  32833, Training Accuracy:  68.8%, Loss: 0.5293\n",
      "Optimization Iteration:  32897, Training Accuracy:  75.0%, Loss: 0.5314\n",
      "Optimization Iteration:  32961, Training Accuracy:  67.2%, Loss: 0.5541\n",
      "Optimization Iteration:  33025, Training Accuracy:  70.3%, Loss: 0.5147\n",
      "Optimization Iteration:  33089, Training Accuracy:  60.9%, Loss: 0.6614\n",
      "Optimization Iteration:  33153, Training Accuracy:  70.3%, Loss: 0.4779\n",
      "Optimization Iteration:  33217, Training Accuracy:  71.9%, Loss: 0.4793\n",
      "Optimization Iteration:  33281, Training Accuracy:  60.9%, Loss: 0.7323\n",
      "Optimization Iteration:  33345, Training Accuracy:  70.3%, Loss: 0.5053\n",
      "Optimization Iteration:  33409, Training Accuracy:  62.5%, Loss: 0.5111\n",
      "Optimization Iteration:  33473, Training Accuracy:  70.3%, Loss: 0.5654\n",
      "Optimization Iteration:  33537, Training Accuracy:  60.9%, Loss: 0.6011\n",
      "Optimization Iteration:  33601, Training Accuracy:  70.3%, Loss: 0.5270\n",
      "Optimization Iteration:  33665, Training Accuracy:  67.2%, Loss: 0.5060\n",
      "Optimization Iteration:  33729, Training Accuracy:  65.6%, Loss: 0.6335\n",
      "Optimization Iteration:  33793, Training Accuracy:  68.8%, Loss: 0.4742\n",
      "Optimization Iteration:  33857, Training Accuracy:  65.6%, Loss: 0.5941\n",
      "Optimization Iteration:  33921, Training Accuracy:  70.3%, Loss: 0.5038\n",
      "Optimization Iteration:  33985, Training Accuracy:  64.1%, Loss: 0.5314\n",
      "Optimization Iteration:  34049, Training Accuracy:  73.4%, Loss: 0.5322\n",
      "Optimization Iteration:  34113, Training Accuracy:  71.9%, Loss: 0.5038\n",
      "Optimization Iteration:  34177, Training Accuracy:  65.6%, Loss: 0.4942\n",
      "Optimization Iteration:  34241, Training Accuracy:  71.9%, Loss: 0.5444\n",
      "Optimization Iteration:  34305, Training Accuracy:  75.0%, Loss: 0.4836\n",
      "Optimization Iteration:  34369, Training Accuracy:  73.4%, Loss: 0.4667\n",
      "Optimization Iteration:  34433, Training Accuracy:  65.6%, Loss: 0.5579\n",
      "Optimization Iteration:  34497, Training Accuracy:  71.9%, Loss: 0.5075\n",
      "Optimization Iteration:  34561, Training Accuracy:  76.6%, Loss: 0.4918\n",
      "Optimization Iteration:  34625, Training Accuracy:  71.9%, Loss: 0.6046\n",
      "Optimization Iteration:  34689, Training Accuracy:  73.4%, Loss: 0.5369\n",
      "Optimization Iteration:  34753, Training Accuracy:  76.6%, Loss: 0.5104\n",
      "Optimization Iteration:  34817, Training Accuracy:  67.2%, Loss: 0.4814\n",
      "Optimization Iteration:  34881, Training Accuracy:  65.6%, Loss: 0.4780\n",
      "Optimization Iteration:  34945, Training Accuracy:  79.7%, Loss: 0.5417\n",
      "Optimization Iteration:  35009, Training Accuracy:  75.0%, Loss: 0.4903\n",
      "Optimization Iteration:  35073, Training Accuracy:  68.8%, Loss: 0.4956\n",
      "Optimization Iteration:  35137, Training Accuracy:  73.4%, Loss: 0.5303\n",
      "Optimization Iteration:  35201, Training Accuracy:  73.4%, Loss: 0.4412\n",
      "Optimization Iteration:  35265, Training Accuracy:  75.0%, Loss: 0.4871\n",
      "Optimization Iteration:  35329, Training Accuracy:  79.7%, Loss: 0.5200\n",
      "Optimization Iteration:  35393, Training Accuracy:  75.0%, Loss: 0.5320\n",
      "Optimization Iteration:  35457, Training Accuracy:  78.1%, Loss: 0.5480\n",
      "Optimization Iteration:  35521, Training Accuracy:  70.3%, Loss: 0.5354\n",
      "Optimization Iteration:  35585, Training Accuracy:  68.8%, Loss: 0.4848\n",
      "Optimization Iteration:  35649, Training Accuracy:  68.8%, Loss: 0.5831\n",
      "Optimization Iteration:  35713, Training Accuracy:  76.6%, Loss: 0.4582\n",
      "Optimization Iteration:  35777, Training Accuracy:  73.4%, Loss: 0.5134\n",
      "Optimization Iteration:  35841, Training Accuracy:  67.2%, Loss: 0.5321\n",
      "Optimization Iteration:  35905, Training Accuracy:  64.1%, Loss: 0.5770\n",
      "Optimization Iteration:  35969, Training Accuracy:  73.4%, Loss: 0.5089\n",
      "Optimization Iteration:  36033, Training Accuracy:  65.6%, Loss: 0.4983\n",
      "Optimization Iteration:  36097, Training Accuracy:  64.1%, Loss: 0.5594\n",
      "Optimization Iteration:  36161, Training Accuracy:  68.8%, Loss: 0.4600\n",
      "Optimization Iteration:  36225, Training Accuracy:  70.3%, Loss: 0.5288\n",
      "Optimization Iteration:  36289, Training Accuracy:  70.3%, Loss: 0.5367\n",
      "Optimization Iteration:  36353, Training Accuracy:  73.4%, Loss: 0.4745\n",
      "Optimization Iteration:  36417, Training Accuracy:  67.2%, Loss: 0.5797\n",
      "Optimization Iteration:  36481, Training Accuracy:  76.6%, Loss: 0.3944\n",
      "Optimization Iteration:  36545, Training Accuracy:  75.0%, Loss: 0.5128\n",
      "Optimization Iteration:  36609, Training Accuracy:  70.3%, Loss: 0.5113\n",
      "Optimization Iteration:  36673, Training Accuracy:  68.8%, Loss: 0.4843\n",
      "Optimization Iteration:  36737, Training Accuracy:  65.6%, Loss: 0.5596\n",
      "Optimization Iteration:  36801, Training Accuracy:  71.9%, Loss: 0.5720\n",
      "Optimization Iteration:  36865, Training Accuracy:  70.3%, Loss: 0.5636\n",
      "Optimization Iteration:  36929, Training Accuracy:  60.9%, Loss: 0.5223\n",
      "Optimization Iteration:  36993, Training Accuracy:  67.2%, Loss: 0.5541\n",
      "Optimization Iteration:  37057, Training Accuracy:  70.3%, Loss: 0.4891\n",
      "Optimization Iteration:  37121, Training Accuracy:  71.9%, Loss: 0.4906\n",
      "Optimization Iteration:  37185, Training Accuracy:  76.6%, Loss: 0.4830\n",
      "Optimization Iteration:  37249, Training Accuracy:  70.3%, Loss: 0.5585\n",
      "Optimization Iteration:  37313, Training Accuracy:  70.3%, Loss: 0.4812\n",
      "Optimization Iteration:  37377, Training Accuracy:  70.3%, Loss: 0.5468\n",
      "Optimization Iteration:  37441, Training Accuracy:  76.6%, Loss: 0.5021\n",
      "Optimization Iteration:  37505, Training Accuracy:  64.1%, Loss: 0.5612\n",
      "Optimization Iteration:  37569, Training Accuracy:  68.8%, Loss: 0.5565\n",
      "Optimization Iteration:  37633, Training Accuracy:  68.8%, Loss: 0.5271\n",
      "Optimization Iteration:  37697, Training Accuracy:  57.8%, Loss: 0.5950\n",
      "Optimization Iteration:  37761, Training Accuracy:  71.9%, Loss: 0.4890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  37825, Training Accuracy:  68.8%, Loss: 0.4917\n",
      "Optimization Iteration:  37889, Training Accuracy:  71.9%, Loss: 0.4585\n",
      "Optimization Iteration:  37953, Training Accuracy:  68.8%, Loss: 0.5082\n",
      "Optimization Iteration:  38017, Training Accuracy:  64.1%, Loss: 0.5285\n",
      "Optimization Iteration:  38081, Training Accuracy:  68.8%, Loss: 0.4625\n",
      "Optimization Iteration:  38145, Training Accuracy:  68.8%, Loss: 0.4704\n",
      "Optimization Iteration:  38209, Training Accuracy:  78.1%, Loss: 0.4741\n",
      "Optimization Iteration:  38273, Training Accuracy:  73.4%, Loss: 0.4860\n",
      "Optimization Iteration:  38337, Training Accuracy:  82.8%, Loss: 0.3450\n",
      "Optimization Iteration:  38401, Training Accuracy:  68.8%, Loss: 0.4565\n",
      "Optimization Iteration:  38465, Training Accuracy:  71.9%, Loss: 0.5151\n",
      "Optimization Iteration:  38529, Training Accuracy:  75.0%, Loss: 0.4629\n",
      "Optimization Iteration:  38593, Training Accuracy:  67.2%, Loss: 0.5467\n",
      "Optimization Iteration:  38657, Training Accuracy:  67.2%, Loss: 0.6066\n",
      "Optimization Iteration:  38721, Training Accuracy:  65.6%, Loss: 0.5172\n",
      "Optimization Iteration:  38785, Training Accuracy:  71.9%, Loss: 0.4521\n",
      "Optimization Iteration:  38849, Training Accuracy:  75.0%, Loss: 0.4512\n",
      "Optimization Iteration:  38913, Training Accuracy:  75.0%, Loss: 0.4565\n",
      "Optimization Iteration:  38977, Training Accuracy:  64.1%, Loss: 0.5437\n",
      "Optimization Iteration:  39041, Training Accuracy:  76.6%, Loss: 0.5905\n",
      "Optimization Iteration:  39105, Training Accuracy:  65.6%, Loss: 0.5914\n",
      "Optimization Iteration:  39169, Training Accuracy:  71.9%, Loss: 0.5485\n",
      "Optimization Iteration:  39233, Training Accuracy:  68.8%, Loss: 0.6123\n",
      "Optimization Iteration:  39297, Training Accuracy:  75.0%, Loss: 0.4746\n",
      "Optimization Iteration:  39361, Training Accuracy:  67.2%, Loss: 0.5573\n",
      "Optimization Iteration:  39425, Training Accuracy:  75.0%, Loss: 0.5614\n",
      "Optimization Iteration:  39489, Training Accuracy:  76.6%, Loss: 0.4540\n",
      "Optimization Iteration:  39553, Training Accuracy:  75.0%, Loss: 0.5700\n",
      "Optimization Iteration:  39617, Training Accuracy:  76.6%, Loss: 0.5147\n",
      "Optimization Iteration:  39681, Training Accuracy:  60.9%, Loss: 0.5793\n",
      "Optimization Iteration:  39745, Training Accuracy:  68.8%, Loss: 0.5596\n",
      "Optimization Iteration:  39809, Training Accuracy:  67.2%, Loss: 0.5178\n",
      "Optimization Iteration:  39873, Training Accuracy:  67.2%, Loss: 0.6274\n",
      "Optimization Iteration:  39937, Training Accuracy:  60.9%, Loss: 0.5738\n",
      "Optimization Iteration:  40001, Training Accuracy:  65.6%, Loss: 0.4904\n",
      "Optimization Iteration:  40065, Training Accuracy:  79.7%, Loss: 0.4330\n",
      "Optimization Iteration:  40129, Training Accuracy:  70.3%, Loss: 0.4777\n",
      "Optimization Iteration:  40193, Training Accuracy:  75.0%, Loss: 0.5064\n",
      "Optimization Iteration:  40257, Training Accuracy:  68.8%, Loss: 0.4846\n",
      "Optimization Iteration:  40321, Training Accuracy:  76.6%, Loss: 0.5135\n",
      "Optimization Iteration:  40385, Training Accuracy:  78.1%, Loss: 0.4529\n",
      "Optimization Iteration:  40449, Training Accuracy:  85.9%, Loss: 0.3995\n",
      "Optimization Iteration:  40513, Training Accuracy:  73.4%, Loss: 0.5343\n",
      "Optimization Iteration:  40577, Training Accuracy:  76.6%, Loss: 0.4793\n",
      "Optimization Iteration:  40641, Training Accuracy:  75.0%, Loss: 0.4778\n",
      "Optimization Iteration:  40705, Training Accuracy:  67.2%, Loss: 0.7262\n",
      "Optimization Iteration:  40769, Training Accuracy:  73.4%, Loss: 0.4581\n",
      "Optimization Iteration:  40833, Training Accuracy:  75.0%, Loss: 0.4205\n",
      "Optimization Iteration:  40897, Training Accuracy:  68.8%, Loss: 0.4341\n",
      "Optimization Iteration:  40961, Training Accuracy:  71.9%, Loss: 0.5217\n",
      "Optimization Iteration:  41025, Training Accuracy:  75.0%, Loss: 0.5003\n",
      "Optimization Iteration:  41089, Training Accuracy:  73.4%, Loss: 0.4858\n",
      "Optimization Iteration:  41153, Training Accuracy:  71.9%, Loss: 0.5150\n",
      "Optimization Iteration:  41217, Training Accuracy:  65.6%, Loss: 0.5420\n",
      "Optimization Iteration:  41281, Training Accuracy:  67.2%, Loss: 0.5284\n",
      "Optimization Iteration:  41345, Training Accuracy:  60.9%, Loss: 0.5385\n",
      "Optimization Iteration:  41409, Training Accuracy:  62.5%, Loss: 0.5777\n",
      "Optimization Iteration:  41473, Training Accuracy:  73.4%, Loss: 0.4765\n",
      "Optimization Iteration:  41537, Training Accuracy:  62.5%, Loss: 0.6789\n",
      "Optimization Iteration:  41601, Training Accuracy:  82.8%, Loss: 0.3944\n",
      "Optimization Iteration:  41665, Training Accuracy:  57.8%, Loss: 0.5828\n",
      "Optimization Iteration:  41729, Training Accuracy:  70.3%, Loss: 0.4720\n",
      "Optimization Iteration:  41793, Training Accuracy:  60.9%, Loss: 0.6460\n",
      "Optimization Iteration:  41857, Training Accuracy:  65.6%, Loss: 0.5761\n",
      "Optimization Iteration:  41921, Training Accuracy:  78.1%, Loss: 0.5288\n",
      "Optimization Iteration:  41985, Training Accuracy:  64.1%, Loss: 0.5700\n",
      "Optimization Iteration:  42049, Training Accuracy:  70.3%, Loss: 0.5791\n",
      "Optimization Iteration:  42113, Training Accuracy:  68.8%, Loss: 0.5269\n",
      "Optimization Iteration:  42177, Training Accuracy:  62.5%, Loss: 0.5662\n",
      "Optimization Iteration:  42241, Training Accuracy:  73.4%, Loss: 0.5169\n",
      "Optimization Iteration:  42305, Training Accuracy:  64.1%, Loss: 0.5762\n",
      "Optimization Iteration:  42369, Training Accuracy:  75.0%, Loss: 0.5086\n",
      "Optimization Iteration:  42433, Training Accuracy:  70.3%, Loss: 0.5406\n",
      "Optimization Iteration:  42497, Training Accuracy:  64.1%, Loss: 0.6620\n",
      "Optimization Iteration:  42561, Training Accuracy:  75.0%, Loss: 0.4011\n",
      "Optimization Iteration:  42625, Training Accuracy:  73.4%, Loss: 0.4514\n",
      "Optimization Iteration:  42689, Training Accuracy:  65.6%, Loss: 0.4478\n",
      "Optimization Iteration:  42753, Training Accuracy:  70.3%, Loss: 0.5088\n",
      "Optimization Iteration:  42817, Training Accuracy:  71.9%, Loss: 0.4577\n",
      "Optimization Iteration:  42881, Training Accuracy:  67.2%, Loss: 0.4957\n",
      "Optimization Iteration:  42945, Training Accuracy:  68.8%, Loss: 0.5233\n",
      "Optimization Iteration:  43009, Training Accuracy:  64.1%, Loss: 0.5561\n",
      "Optimization Iteration:  43073, Training Accuracy:  71.9%, Loss: 0.6183\n",
      "Optimization Iteration:  43137, Training Accuracy:  76.6%, Loss: 0.5087\n",
      "Optimization Iteration:  43201, Training Accuracy:  68.8%, Loss: 0.5265\n",
      "Optimization Iteration:  43265, Training Accuracy:  67.2%, Loss: 0.5055\n",
      "Optimization Iteration:  43329, Training Accuracy:  76.6%, Loss: 0.4657\n",
      "Optimization Iteration:  43393, Training Accuracy:  62.5%, Loss: 0.5725\n",
      "Optimization Iteration:  43457, Training Accuracy:  71.9%, Loss: 0.4898\n",
      "Optimization Iteration:  43521, Training Accuracy:  70.3%, Loss: 0.5608\n",
      "Optimization Iteration:  43585, Training Accuracy:  75.0%, Loss: 0.5076\n",
      "Optimization Iteration:  43649, Training Accuracy:  62.5%, Loss: 0.5468\n",
      "Optimization Iteration:  43713, Training Accuracy:  64.1%, Loss: 0.5325\n",
      "Optimization Iteration:  43777, Training Accuracy:  67.2%, Loss: 0.5147\n",
      "Optimization Iteration:  43841, Training Accuracy:  68.8%, Loss: 0.5808\n",
      "Optimization Iteration:  43905, Training Accuracy:  71.9%, Loss: 0.4889\n",
      "Optimization Iteration:  43969, Training Accuracy:  65.6%, Loss: 0.5725\n",
      "Optimization Iteration:  44033, Training Accuracy:  75.0%, Loss: 0.5653\n",
      "Optimization Iteration:  44097, Training Accuracy:  71.9%, Loss: 0.5137\n",
      "Optimization Iteration:  44161, Training Accuracy:  78.1%, Loss: 0.4286\n",
      "Optimization Iteration:  44225, Training Accuracy:  68.8%, Loss: 0.5208\n",
      "Optimization Iteration:  44289, Training Accuracy:  71.9%, Loss: 0.5350\n",
      "Optimization Iteration:  44353, Training Accuracy:  73.4%, Loss: 0.4892\n",
      "Optimization Iteration:  44417, Training Accuracy:  79.7%, Loss: 0.4669\n",
      "Optimization Iteration:  44481, Training Accuracy:  68.8%, Loss: 0.5545\n",
      "Optimization Iteration:  44545, Training Accuracy:  64.1%, Loss: 0.5794\n",
      "Optimization Iteration:  44609, Training Accuracy:  75.0%, Loss: 0.4817\n",
      "Optimization Iteration:  44673, Training Accuracy:  62.5%, Loss: 0.6293\n",
      "Optimization Iteration:  44737, Training Accuracy:  65.6%, Loss: 0.5529\n",
      "Optimization Iteration:  44801, Training Accuracy:  78.1%, Loss: 0.4818\n",
      "Optimization Iteration:  44865, Training Accuracy:  71.9%, Loss: 0.4913\n",
      "Optimization Iteration:  44929, Training Accuracy:  78.1%, Loss: 0.4026\n",
      "Optimization Iteration:  44993, Training Accuracy:  68.8%, Loss: 0.5197\n",
      "Optimization Iteration:  45057, Training Accuracy:  75.0%, Loss: 0.5251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  45121, Training Accuracy:  76.6%, Loss: 0.5152\n",
      "Optimization Iteration:  45185, Training Accuracy:  79.7%, Loss: 0.4134\n",
      "Optimization Iteration:  45249, Training Accuracy:  67.2%, Loss: 0.5692\n",
      "Optimization Iteration:  45313, Training Accuracy:  71.9%, Loss: 0.4752\n",
      "Optimization Iteration:  45377, Training Accuracy:  71.9%, Loss: 0.6090\n",
      "Optimization Iteration:  45441, Training Accuracy:  75.0%, Loss: 0.5024\n",
      "Optimization Iteration:  45505, Training Accuracy:  75.0%, Loss: 0.4562\n",
      "Optimization Iteration:  45569, Training Accuracy:  51.6%, Loss: 0.6862\n",
      "Optimization Iteration:  45633, Training Accuracy:  76.6%, Loss: 0.4663\n",
      "Optimization Iteration:  45697, Training Accuracy:  67.2%, Loss: 0.4825\n",
      "Optimization Iteration:  45761, Training Accuracy:  78.1%, Loss: 0.5206\n",
      "Optimization Iteration:  45825, Training Accuracy:  64.1%, Loss: 0.5635\n",
      "Optimization Iteration:  45889, Training Accuracy:  65.6%, Loss: 0.5122\n",
      "Optimization Iteration:  45953, Training Accuracy:  73.4%, Loss: 0.4517\n",
      "Optimization Iteration:  46017, Training Accuracy:  64.1%, Loss: 0.5785\n",
      "Optimization Iteration:  46081, Training Accuracy:  75.0%, Loss: 0.4551\n",
      "Optimization Iteration:  46145, Training Accuracy:  71.9%, Loss: 0.4666\n",
      "Optimization Iteration:  46209, Training Accuracy:  75.0%, Loss: 0.4457\n",
      "Optimization Iteration:  46273, Training Accuracy:  73.4%, Loss: 0.5093\n",
      "Optimization Iteration:  46337, Training Accuracy:  75.0%, Loss: 0.5124\n",
      "Optimization Iteration:  46401, Training Accuracy:  76.6%, Loss: 0.4774\n",
      "Optimization Iteration:  46465, Training Accuracy:  68.8%, Loss: 0.5314\n",
      "Optimization Iteration:  46529, Training Accuracy:  65.6%, Loss: 0.5930\n",
      "Optimization Iteration:  46593, Training Accuracy:  70.3%, Loss: 0.5967\n",
      "Optimization Iteration:  46657, Training Accuracy:  67.2%, Loss: 0.5474\n",
      "Optimization Iteration:  46721, Training Accuracy:  71.9%, Loss: 0.6579\n",
      "Optimization Iteration:  46785, Training Accuracy:  65.6%, Loss: 0.5871\n",
      "Optimization Iteration:  46849, Training Accuracy:  67.2%, Loss: 0.5038\n",
      "Optimization Iteration:  46913, Training Accuracy:  71.9%, Loss: 0.5204\n",
      "Optimization Iteration:  46977, Training Accuracy:  65.6%, Loss: 0.5454\n",
      "Optimization Iteration:  47041, Training Accuracy:  70.3%, Loss: 0.5053\n",
      "Optimization Iteration:  47105, Training Accuracy:  65.6%, Loss: 0.6089\n",
      "Optimization Iteration:  47169, Training Accuracy:  78.1%, Loss: 0.4955\n",
      "Optimization Iteration:  47233, Training Accuracy:  62.5%, Loss: 0.5880\n",
      "Optimization Iteration:  47297, Training Accuracy:  65.6%, Loss: 0.5090\n",
      "Optimization Iteration:  47361, Training Accuracy:  73.4%, Loss: 0.4998\n",
      "Optimization Iteration:  47425, Training Accuracy:  70.3%, Loss: 0.5124\n",
      "Optimization Iteration:  47489, Training Accuracy:  81.2%, Loss: 0.4490\n",
      "Optimization Iteration:  47553, Training Accuracy:  68.8%, Loss: 0.5625\n",
      "Optimization Iteration:  47617, Training Accuracy:  73.4%, Loss: 0.4977\n",
      "Optimization Iteration:  47681, Training Accuracy:  78.1%, Loss: 0.4214\n",
      "Optimization Iteration:  47745, Training Accuracy:  64.1%, Loss: 0.4918\n",
      "Optimization Iteration:  47809, Training Accuracy:  70.3%, Loss: 0.4860\n",
      "Optimization Iteration:  47873, Training Accuracy:  78.1%, Loss: 0.4712\n",
      "Optimization Iteration:  47937, Training Accuracy:  60.9%, Loss: 0.6480\n",
      "Optimization Iteration:  48001, Training Accuracy:  81.2%, Loss: 0.4724\n",
      "Optimization Iteration:  48065, Training Accuracy:  67.2%, Loss: 0.5847\n",
      "Optimization Iteration:  48129, Training Accuracy:  75.0%, Loss: 0.5704\n",
      "Optimization Iteration:  48193, Training Accuracy:  60.9%, Loss: 0.5916\n",
      "Optimization Iteration:  48257, Training Accuracy:  78.1%, Loss: 0.4920\n",
      "Optimization Iteration:  48321, Training Accuracy:  71.9%, Loss: 0.4309\n",
      "Optimization Iteration:  48385, Training Accuracy:  79.7%, Loss: 0.5092\n",
      "Optimization Iteration:  48449, Training Accuracy:  62.5%, Loss: 0.5773\n",
      "Optimization Iteration:  48513, Training Accuracy:  73.4%, Loss: 0.5545\n",
      "Optimization Iteration:  48577, Training Accuracy:  65.6%, Loss: 0.5766\n",
      "Optimization Iteration:  48641, Training Accuracy:  75.0%, Loss: 0.4509\n",
      "Optimization Iteration:  48705, Training Accuracy:  73.4%, Loss: 0.4823\n",
      "Optimization Iteration:  48769, Training Accuracy:  81.2%, Loss: 0.5404\n",
      "Optimization Iteration:  48833, Training Accuracy:  75.0%, Loss: 0.4769\n",
      "Optimization Iteration:  48897, Training Accuracy:  75.0%, Loss: 0.4600\n",
      "Optimization Iteration:  48961, Training Accuracy:  75.0%, Loss: 0.5658\n",
      "Optimization Iteration:  49025, Training Accuracy:  75.0%, Loss: 0.5304\n",
      "Optimization Iteration:  49089, Training Accuracy:  71.9%, Loss: 0.5003\n",
      "Optimization Iteration:  49153, Training Accuracy:  68.8%, Loss: 0.4807\n",
      "Optimization Iteration:  49217, Training Accuracy:  76.6%, Loss: 0.4748\n",
      "Optimization Iteration:  49281, Training Accuracy:  73.4%, Loss: 0.5020\n",
      "Optimization Iteration:  49345, Training Accuracy:  81.2%, Loss: 0.4058\n",
      "Optimization Iteration:  49409, Training Accuracy:  78.1%, Loss: 0.3781\n",
      "Optimization Iteration:  49473, Training Accuracy:  75.0%, Loss: 0.4116\n",
      "Optimization Iteration:  49537, Training Accuracy:  78.1%, Loss: 0.4069\n",
      "Optimization Iteration:  49601, Training Accuracy:  73.4%, Loss: 0.6413\n",
      "Optimization Iteration:  49665, Training Accuracy:  71.9%, Loss: 0.4648\n",
      "Optimization Iteration:  49729, Training Accuracy:  70.3%, Loss: 0.5438\n",
      "Optimization Iteration:  49793, Training Accuracy:  67.2%, Loss: 0.4660\n",
      "Optimization Iteration:  49857, Training Accuracy:  60.9%, Loss: 0.5129\n",
      "Optimization Iteration:  49921, Training Accuracy:  73.4%, Loss: 0.5608\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 3\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  73.4%, Loss: 0.4780\n",
      "Optimization Iteration:    129, Training Accuracy:  73.4%, Loss: 0.5009\n",
      "Optimization Iteration:    193, Training Accuracy:  64.1%, Loss: 0.6239\n",
      "Optimization Iteration:    257, Training Accuracy:  59.4%, Loss: 0.6003\n",
      "Optimization Iteration:    321, Training Accuracy:  71.9%, Loss: 0.4570\n",
      "Optimization Iteration:    385, Training Accuracy:  75.0%, Loss: 0.4436\n",
      "Optimization Iteration:    449, Training Accuracy:  73.4%, Loss: 0.4311\n",
      "Optimization Iteration:    513, Training Accuracy:  70.3%, Loss: 0.5042\n",
      "Optimization Iteration:    577, Training Accuracy:  67.2%, Loss: 0.5151\n",
      "Optimization Iteration:    641, Training Accuracy:  76.6%, Loss: 0.5742\n",
      "Optimization Iteration:    705, Training Accuracy:  60.9%, Loss: 0.6710\n",
      "Optimization Iteration:    769, Training Accuracy:  67.2%, Loss: 0.5402\n",
      "Optimization Iteration:    833, Training Accuracy:  70.3%, Loss: 0.5455\n",
      "Optimization Iteration:    897, Training Accuracy:  79.7%, Loss: 0.3755\n",
      "Optimization Iteration:    961, Training Accuracy:  73.4%, Loss: 0.4344\n",
      "Optimization Iteration:   1025, Training Accuracy:  70.3%, Loss: 0.4994\n",
      "Optimization Iteration:   1089, Training Accuracy:  78.1%, Loss: 0.4909\n",
      "Optimization Iteration:   1153, Training Accuracy:  67.2%, Loss: 0.5602\n",
      "Optimization Iteration:   1217, Training Accuracy:  68.8%, Loss: 0.5400\n",
      "Optimization Iteration:   1281, Training Accuracy:  76.6%, Loss: 0.4577\n",
      "Optimization Iteration:   1345, Training Accuracy:  70.3%, Loss: 0.4707\n",
      "Optimization Iteration:   1409, Training Accuracy:  70.3%, Loss: 0.4847\n",
      "Optimization Iteration:   1473, Training Accuracy:  60.9%, Loss: 0.6561\n",
      "Optimization Iteration:   1537, Training Accuracy:  67.2%, Loss: 0.4792\n",
      "Optimization Iteration:   1601, Training Accuracy:  73.4%, Loss: 0.4654\n",
      "Optimization Iteration:   1665, Training Accuracy:  70.3%, Loss: 0.4822\n",
      "Optimization Iteration:   1729, Training Accuracy:  65.6%, Loss: 0.5207\n",
      "Optimization Iteration:   1793, Training Accuracy:  62.5%, Loss: 0.5187\n",
      "Optimization Iteration:   1857, Training Accuracy:  70.3%, Loss: 0.5006\n",
      "Optimization Iteration:   1921, Training Accuracy:  71.9%, Loss: 0.5202\n",
      "Optimization Iteration:   1985, Training Accuracy:  76.6%, Loss: 0.5149\n",
      "Optimization Iteration:   2049, Training Accuracy:  70.3%, Loss: 0.4379\n",
      "Optimization Iteration:   2113, Training Accuracy:  68.8%, Loss: 0.4644\n",
      "Optimization Iteration:   2177, Training Accuracy:  73.4%, Loss: 0.4609\n",
      "Optimization Iteration:   2241, Training Accuracy:  76.6%, Loss: 0.5006\n",
      "Optimization Iteration:   2305, Training Accuracy:  75.0%, Loss: 0.4322\n",
      "Optimization Iteration:   2369, Training Accuracy:  73.4%, Loss: 0.5519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   2433, Training Accuracy:  71.9%, Loss: 0.5059\n",
      "Optimization Iteration:   2497, Training Accuracy:  70.3%, Loss: 0.4891\n",
      "Optimization Iteration:   2561, Training Accuracy:  79.7%, Loss: 0.4000\n",
      "Optimization Iteration:   2625, Training Accuracy:  76.6%, Loss: 0.4433\n",
      "Optimization Iteration:   2689, Training Accuracy:  67.2%, Loss: 0.4670\n",
      "Optimization Iteration:   2753, Training Accuracy:  71.9%, Loss: 0.4976\n",
      "Optimization Iteration:   2817, Training Accuracy:  70.3%, Loss: 0.4616\n",
      "Optimization Iteration:   2881, Training Accuracy:  75.0%, Loss: 0.4525\n",
      "Optimization Iteration:   2945, Training Accuracy:  75.0%, Loss: 0.5202\n",
      "Optimization Iteration:   3009, Training Accuracy:  79.7%, Loss: 0.4700\n",
      "Optimization Iteration:   3073, Training Accuracy:  71.9%, Loss: 0.4462\n",
      "Optimization Iteration:   3137, Training Accuracy:  82.8%, Loss: 0.4117\n",
      "Optimization Iteration:   3201, Training Accuracy:  76.6%, Loss: 0.4792\n",
      "Optimization Iteration:   3265, Training Accuracy:  70.3%, Loss: 0.4723\n",
      "Optimization Iteration:   3329, Training Accuracy:  73.4%, Loss: 0.4637\n",
      "Optimization Iteration:   3393, Training Accuracy:  68.8%, Loss: 0.4851\n",
      "Optimization Iteration:   3457, Training Accuracy:  70.3%, Loss: 0.6041\n",
      "Optimization Iteration:   3521, Training Accuracy:  71.9%, Loss: 0.5014\n",
      "Optimization Iteration:   3585, Training Accuracy:  59.4%, Loss: 0.5926\n",
      "Optimization Iteration:   3649, Training Accuracy:  76.6%, Loss: 0.5025\n",
      "Optimization Iteration:   3713, Training Accuracy:  68.8%, Loss: 0.4910\n",
      "Optimization Iteration:   3777, Training Accuracy:  68.8%, Loss: 0.5562\n",
      "Optimization Iteration:   3841, Training Accuracy:  76.6%, Loss: 0.4891\n",
      "Optimization Iteration:   3905, Training Accuracy:  71.9%, Loss: 0.4616\n",
      "Optimization Iteration:   3969, Training Accuracy:  76.6%, Loss: 0.4826\n",
      "Optimization Iteration:   4033, Training Accuracy:  71.9%, Loss: 0.4961\n",
      "Optimization Iteration:   4097, Training Accuracy:  64.1%, Loss: 0.4923\n",
      "Optimization Iteration:   4161, Training Accuracy:  68.8%, Loss: 0.4898\n",
      "Optimization Iteration:   4225, Training Accuracy:  73.4%, Loss: 0.4336\n",
      "Optimization Iteration:   4289, Training Accuracy:  70.3%, Loss: 0.4500\n",
      "Optimization Iteration:   4353, Training Accuracy:  68.8%, Loss: 0.5496\n",
      "Optimization Iteration:   4417, Training Accuracy:  56.2%, Loss: 0.5541\n",
      "Optimization Iteration:   4481, Training Accuracy:  67.2%, Loss: 0.5691\n",
      "Optimization Iteration:   4545, Training Accuracy:  75.0%, Loss: 0.5104\n",
      "Optimization Iteration:   4609, Training Accuracy:  75.0%, Loss: 0.5029\n",
      "Optimization Iteration:   4673, Training Accuracy:  68.8%, Loss: 0.5388\n",
      "Optimization Iteration:   4737, Training Accuracy:  65.6%, Loss: 0.5125\n",
      "Optimization Iteration:   4801, Training Accuracy:  79.7%, Loss: 0.4350\n",
      "Optimization Iteration:   4865, Training Accuracy:  71.9%, Loss: 0.5065\n",
      "Optimization Iteration:   4929, Training Accuracy:  79.7%, Loss: 0.5311\n",
      "Optimization Iteration:   4993, Training Accuracy:  81.2%, Loss: 0.4257\n",
      "Optimization Iteration:   5057, Training Accuracy:  73.4%, Loss: 0.5044\n",
      "Optimization Iteration:   5121, Training Accuracy:  76.6%, Loss: 0.4456\n",
      "Optimization Iteration:   5185, Training Accuracy:  71.9%, Loss: 0.5114\n",
      "Optimization Iteration:   5249, Training Accuracy:  70.3%, Loss: 0.5204\n",
      "Optimization Iteration:   5313, Training Accuracy:  73.4%, Loss: 0.5508\n",
      "Optimization Iteration:   5377, Training Accuracy:  78.1%, Loss: 0.4133\n",
      "Optimization Iteration:   5441, Training Accuracy:  75.0%, Loss: 0.4568\n",
      "Optimization Iteration:   5505, Training Accuracy:  70.3%, Loss: 0.4423\n",
      "Optimization Iteration:   5569, Training Accuracy:  78.1%, Loss: 0.4056\n",
      "Optimization Iteration:   5633, Training Accuracy:  78.1%, Loss: 0.4475\n",
      "Optimization Iteration:   5697, Training Accuracy:  70.3%, Loss: 0.5093\n",
      "Optimization Iteration:   5761, Training Accuracy:  73.4%, Loss: 0.4563\n",
      "Optimization Iteration:   5825, Training Accuracy:  76.6%, Loss: 0.5276\n",
      "Optimization Iteration:   5889, Training Accuracy:  78.1%, Loss: 0.4552\n",
      "Optimization Iteration:   5953, Training Accuracy:  73.4%, Loss: 0.5786\n",
      "Optimization Iteration:   6017, Training Accuracy:  59.4%, Loss: 0.5786\n",
      "Optimization Iteration:   6081, Training Accuracy:  76.6%, Loss: 0.5046\n",
      "Optimization Iteration:   6145, Training Accuracy:  64.1%, Loss: 0.5557\n",
      "Optimization Iteration:   6209, Training Accuracy:  65.6%, Loss: 0.5118\n",
      "Optimization Iteration:   6273, Training Accuracy:  67.2%, Loss: 0.5012\n",
      "Optimization Iteration:   6337, Training Accuracy:  75.0%, Loss: 0.4607\n",
      "Optimization Iteration:   6401, Training Accuracy:  70.3%, Loss: 0.4578\n",
      "Optimization Iteration:   6465, Training Accuracy:  75.0%, Loss: 0.4280\n",
      "Optimization Iteration:   6529, Training Accuracy:  79.7%, Loss: 0.5167\n",
      "Optimization Iteration:   6593, Training Accuracy:  64.1%, Loss: 0.6148\n",
      "Optimization Iteration:   6657, Training Accuracy:  73.4%, Loss: 0.4524\n",
      "Optimization Iteration:   6721, Training Accuracy:  71.9%, Loss: 0.5037\n",
      "Optimization Iteration:   6785, Training Accuracy:  68.8%, Loss: 0.5240\n",
      "Optimization Iteration:   6849, Training Accuracy:  70.3%, Loss: 0.4647\n",
      "Optimization Iteration:   6913, Training Accuracy:  75.0%, Loss: 0.4008\n",
      "Optimization Iteration:   6977, Training Accuracy:  73.4%, Loss: 0.4666\n",
      "Optimization Iteration:   7041, Training Accuracy:  73.4%, Loss: 0.4259\n",
      "Optimization Iteration:   7105, Training Accuracy:  79.7%, Loss: 0.4271\n",
      "Optimization Iteration:   7169, Training Accuracy:  75.0%, Loss: 0.4592\n",
      "Optimization Iteration:   7233, Training Accuracy:  76.6%, Loss: 0.4747\n",
      "Optimization Iteration:   7297, Training Accuracy:  73.4%, Loss: 0.5528\n",
      "Optimization Iteration:   7361, Training Accuracy:  81.2%, Loss: 0.4413\n",
      "Optimization Iteration:   7425, Training Accuracy:  71.9%, Loss: 0.5047\n",
      "Optimization Iteration:   7489, Training Accuracy:  67.2%, Loss: 0.5406\n",
      "Optimization Iteration:   7553, Training Accuracy:  73.4%, Loss: 0.5026\n",
      "Optimization Iteration:   7617, Training Accuracy:  75.0%, Loss: 0.5082\n",
      "Optimization Iteration:   7681, Training Accuracy:  73.4%, Loss: 0.5028\n",
      "Optimization Iteration:   7745, Training Accuracy:  75.0%, Loss: 0.5364\n",
      "Optimization Iteration:   7809, Training Accuracy:  65.6%, Loss: 0.5891\n",
      "Optimization Iteration:   7873, Training Accuracy:  68.8%, Loss: 0.5175\n",
      "Optimization Iteration:   7937, Training Accuracy:  81.2%, Loss: 0.4800\n",
      "Optimization Iteration:   8001, Training Accuracy:  73.4%, Loss: 0.4685\n",
      "Optimization Iteration:   8065, Training Accuracy:  78.1%, Loss: 0.4745\n",
      "Optimization Iteration:   8129, Training Accuracy:  62.5%, Loss: 0.5607\n",
      "Optimization Iteration:   8193, Training Accuracy:  81.2%, Loss: 0.4283\n",
      "Optimization Iteration:   8257, Training Accuracy:  67.2%, Loss: 0.4620\n",
      "Optimization Iteration:   8321, Training Accuracy:  67.2%, Loss: 0.5978\n",
      "Optimization Iteration:   8385, Training Accuracy:  64.1%, Loss: 0.5533\n",
      "Optimization Iteration:   8449, Training Accuracy:  65.6%, Loss: 0.6296\n",
      "Optimization Iteration:   8513, Training Accuracy:  68.8%, Loss: 0.5150\n",
      "Optimization Iteration:   8577, Training Accuracy:  71.9%, Loss: 0.4713\n",
      "Optimization Iteration:   8641, Training Accuracy:  76.6%, Loss: 0.4726\n",
      "Optimization Iteration:   8705, Training Accuracy:  65.6%, Loss: 0.5960\n",
      "Optimization Iteration:   8769, Training Accuracy:  67.2%, Loss: 0.5644\n",
      "Optimization Iteration:   8833, Training Accuracy:  59.4%, Loss: 0.5822\n",
      "Optimization Iteration:   8897, Training Accuracy:  82.8%, Loss: 0.5090\n",
      "Optimization Iteration:   8961, Training Accuracy:  75.0%, Loss: 0.5016\n",
      "Optimization Iteration:   9025, Training Accuracy:  67.2%, Loss: 0.5901\n",
      "Optimization Iteration:   9089, Training Accuracy:  67.2%, Loss: 0.5680\n",
      "Optimization Iteration:   9153, Training Accuracy:  65.6%, Loss: 0.5911\n",
      "Optimization Iteration:   9217, Training Accuracy:  78.1%, Loss: 0.4388\n",
      "Optimization Iteration:   9281, Training Accuracy:  60.9%, Loss: 0.5423\n",
      "Optimization Iteration:   9345, Training Accuracy:  70.3%, Loss: 0.5906\n",
      "Optimization Iteration:   9409, Training Accuracy:  71.9%, Loss: 0.5373\n",
      "Optimization Iteration:   9473, Training Accuracy:  71.9%, Loss: 0.4506\n",
      "Optimization Iteration:   9537, Training Accuracy:  76.6%, Loss: 0.4688\n",
      "Optimization Iteration:   9601, Training Accuracy:  71.9%, Loss: 0.5170\n",
      "Optimization Iteration:   9665, Training Accuracy:  60.9%, Loss: 0.5889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   9729, Training Accuracy:  67.2%, Loss: 0.5277\n",
      "Optimization Iteration:   9793, Training Accuracy:  85.9%, Loss: 0.3817\n",
      "Optimization Iteration:   9857, Training Accuracy:  67.2%, Loss: 0.5352\n",
      "Optimization Iteration:   9921, Training Accuracy:  73.4%, Loss: 0.4746\n",
      "Optimization Iteration:   9985, Training Accuracy:  70.3%, Loss: 0.5208\n",
      "Optimization Iteration:  10049, Training Accuracy:  68.8%, Loss: 0.5075\n",
      "Optimization Iteration:  10113, Training Accuracy:  65.6%, Loss: 0.5945\n",
      "Optimization Iteration:  10177, Training Accuracy:  67.2%, Loss: 0.5170\n",
      "Optimization Iteration:  10241, Training Accuracy:  73.4%, Loss: 0.4936\n",
      "Optimization Iteration:  10305, Training Accuracy:  71.9%, Loss: 0.4423\n",
      "Optimization Iteration:  10369, Training Accuracy:  71.9%, Loss: 0.4536\n",
      "Optimization Iteration:  10433, Training Accuracy:  73.4%, Loss: 0.4624\n",
      "Optimization Iteration:  10497, Training Accuracy:  70.3%, Loss: 0.4933\n",
      "Optimization Iteration:  10561, Training Accuracy:  76.6%, Loss: 0.4842\n",
      "Optimization Iteration:  10625, Training Accuracy:  78.1%, Loss: 0.4482\n",
      "Optimization Iteration:  10689, Training Accuracy:  73.4%, Loss: 0.4885\n",
      "Optimization Iteration:  10753, Training Accuracy:  71.9%, Loss: 0.4749\n",
      "Optimization Iteration:  10817, Training Accuracy:  71.9%, Loss: 0.5508\n",
      "Optimization Iteration:  10881, Training Accuracy:  79.7%, Loss: 0.4337\n",
      "Optimization Iteration:  10945, Training Accuracy:  73.4%, Loss: 0.4934\n",
      "Optimization Iteration:  11009, Training Accuracy:  70.3%, Loss: 0.4813\n",
      "Optimization Iteration:  11073, Training Accuracy:  81.2%, Loss: 0.3793\n",
      "Optimization Iteration:  11137, Training Accuracy:  73.4%, Loss: 0.4667\n",
      "Optimization Iteration:  11201, Training Accuracy:  81.2%, Loss: 0.4177\n",
      "Optimization Iteration:  11265, Training Accuracy:  75.0%, Loss: 0.4014\n",
      "Optimization Iteration:  11329, Training Accuracy:  67.2%, Loss: 0.5925\n",
      "Optimization Iteration:  11393, Training Accuracy:  73.4%, Loss: 0.5355\n",
      "Optimization Iteration:  11457, Training Accuracy:  79.7%, Loss: 0.4180\n",
      "Optimization Iteration:  11521, Training Accuracy:  68.8%, Loss: 0.6108\n",
      "Optimization Iteration:  11585, Training Accuracy:  68.8%, Loss: 0.4722\n",
      "Optimization Iteration:  11649, Training Accuracy:  71.9%, Loss: 0.4964\n",
      "Optimization Iteration:  11713, Training Accuracy:  81.2%, Loss: 0.4057\n",
      "Optimization Iteration:  11777, Training Accuracy:  76.6%, Loss: 0.5505\n",
      "Optimization Iteration:  11841, Training Accuracy:  67.2%, Loss: 0.4986\n",
      "Optimization Iteration:  11905, Training Accuracy:  79.7%, Loss: 0.3858\n",
      "Optimization Iteration:  11969, Training Accuracy:  76.6%, Loss: 0.4760\n",
      "Optimization Iteration:  12033, Training Accuracy:  73.4%, Loss: 0.5110\n",
      "Optimization Iteration:  12097, Training Accuracy:  71.9%, Loss: 0.5296\n",
      "Optimization Iteration:  12161, Training Accuracy:  75.0%, Loss: 0.4717\n",
      "Optimization Iteration:  12225, Training Accuracy:  78.1%, Loss: 0.5374\n",
      "Optimization Iteration:  12289, Training Accuracy:  73.4%, Loss: 0.4352\n",
      "Optimization Iteration:  12353, Training Accuracy:  76.6%, Loss: 0.4260\n",
      "Optimization Iteration:  12417, Training Accuracy:  73.4%, Loss: 0.4918\n",
      "Optimization Iteration:  12481, Training Accuracy:  71.9%, Loss: 0.5704\n",
      "Optimization Iteration:  12545, Training Accuracy:  75.0%, Loss: 0.5235\n",
      "Optimization Iteration:  12609, Training Accuracy:  76.6%, Loss: 0.4680\n",
      "Optimization Iteration:  12673, Training Accuracy:  71.9%, Loss: 0.4472\n",
      "Optimization Iteration:  12737, Training Accuracy:  73.4%, Loss: 0.5366\n",
      "Optimization Iteration:  12801, Training Accuracy:  68.8%, Loss: 0.5522\n",
      "Optimization Iteration:  12865, Training Accuracy:  73.4%, Loss: 0.5585\n",
      "Optimization Iteration:  12929, Training Accuracy:  71.9%, Loss: 0.4860\n",
      "Optimization Iteration:  12993, Training Accuracy:  65.6%, Loss: 0.5157\n",
      "Optimization Iteration:  13057, Training Accuracy:  70.3%, Loss: 0.4751\n",
      "Optimization Iteration:  13121, Training Accuracy:  70.3%, Loss: 0.4601\n",
      "Optimization Iteration:  13185, Training Accuracy:  62.5%, Loss: 0.5596\n",
      "Optimization Iteration:  13249, Training Accuracy:  75.0%, Loss: 0.5391\n",
      "Optimization Iteration:  13313, Training Accuracy:  67.2%, Loss: 0.5579\n",
      "Optimization Iteration:  13377, Training Accuracy:  65.6%, Loss: 0.5235\n",
      "Optimization Iteration:  13441, Training Accuracy:  64.1%, Loss: 0.5771\n",
      "Optimization Iteration:  13505, Training Accuracy:  64.1%, Loss: 0.5605\n",
      "Optimization Iteration:  13569, Training Accuracy:  79.7%, Loss: 0.4774\n",
      "Optimization Iteration:  13633, Training Accuracy:  85.9%, Loss: 0.3866\n",
      "Optimization Iteration:  13697, Training Accuracy:  70.3%, Loss: 0.4817\n",
      "Optimization Iteration:  13761, Training Accuracy:  73.4%, Loss: 0.4111\n",
      "Optimization Iteration:  13825, Training Accuracy:  64.1%, Loss: 0.5056\n",
      "Optimization Iteration:  13889, Training Accuracy:  68.8%, Loss: 0.5858\n",
      "Optimization Iteration:  13953, Training Accuracy:  70.3%, Loss: 0.4097\n",
      "Optimization Iteration:  14017, Training Accuracy:  73.4%, Loss: 0.5356\n",
      "Optimization Iteration:  14081, Training Accuracy:  68.8%, Loss: 0.4348\n",
      "Optimization Iteration:  14145, Training Accuracy:  81.2%, Loss: 0.4283\n",
      "Optimization Iteration:  14209, Training Accuracy:  67.2%, Loss: 0.4814\n",
      "Optimization Iteration:  14273, Training Accuracy:  70.3%, Loss: 0.5368\n",
      "Optimization Iteration:  14337, Training Accuracy:  75.0%, Loss: 0.4699\n",
      "Optimization Iteration:  14401, Training Accuracy:  73.4%, Loss: 0.5072\n",
      "Optimization Iteration:  14465, Training Accuracy:  64.1%, Loss: 0.5640\n",
      "Optimization Iteration:  14529, Training Accuracy:  71.9%, Loss: 0.5087\n",
      "Optimization Iteration:  14593, Training Accuracy:  75.0%, Loss: 0.4589\n",
      "Optimization Iteration:  14657, Training Accuracy:  68.8%, Loss: 0.5254\n",
      "Optimization Iteration:  14721, Training Accuracy:  60.9%, Loss: 0.5017\n",
      "Optimization Iteration:  14785, Training Accuracy:  70.3%, Loss: 0.5050\n",
      "Optimization Iteration:  14849, Training Accuracy:  71.9%, Loss: 0.5087\n",
      "Optimization Iteration:  14913, Training Accuracy:  71.9%, Loss: 0.4480\n",
      "Optimization Iteration:  14977, Training Accuracy:  68.8%, Loss: 0.6708\n",
      "Optimization Iteration:  15041, Training Accuracy:  71.9%, Loss: 0.5843\n",
      "Optimization Iteration:  15105, Training Accuracy:  70.3%, Loss: 0.5926\n",
      "Optimization Iteration:  15169, Training Accuracy:  70.3%, Loss: 0.4826\n",
      "Optimization Iteration:  15233, Training Accuracy:  68.8%, Loss: 0.4462\n",
      "Optimization Iteration:  15297, Training Accuracy:  59.4%, Loss: 0.4951\n",
      "Optimization Iteration:  15361, Training Accuracy:  79.7%, Loss: 0.4507\n",
      "Optimization Iteration:  15425, Training Accuracy:  78.1%, Loss: 0.4290\n",
      "Optimization Iteration:  15489, Training Accuracy:  60.9%, Loss: 0.6412\n",
      "Optimization Iteration:  15553, Training Accuracy:  73.4%, Loss: 0.5088\n",
      "Optimization Iteration:  15617, Training Accuracy:  64.1%, Loss: 0.5461\n",
      "Optimization Iteration:  15681, Training Accuracy:  78.1%, Loss: 0.4680\n",
      "Optimization Iteration:  15745, Training Accuracy:  68.8%, Loss: 0.4857\n",
      "Optimization Iteration:  15809, Training Accuracy:  76.6%, Loss: 0.4583\n",
      "Optimization Iteration:  15873, Training Accuracy:  64.1%, Loss: 0.4629\n",
      "Optimization Iteration:  15937, Training Accuracy:  71.9%, Loss: 0.4415\n",
      "Optimization Iteration:  16001, Training Accuracy:  68.8%, Loss: 0.4906\n",
      "Optimization Iteration:  16065, Training Accuracy:  70.3%, Loss: 0.5077\n",
      "Optimization Iteration:  16129, Training Accuracy:  79.7%, Loss: 0.4207\n",
      "Optimization Iteration:  16193, Training Accuracy:  70.3%, Loss: 0.4599\n",
      "Optimization Iteration:  16257, Training Accuracy:  68.8%, Loss: 0.5853\n",
      "Optimization Iteration:  16321, Training Accuracy:  78.1%, Loss: 0.4379\n",
      "Optimization Iteration:  16385, Training Accuracy:  68.8%, Loss: 0.5137\n",
      "Optimization Iteration:  16449, Training Accuracy:  78.1%, Loss: 0.4196\n",
      "Optimization Iteration:  16513, Training Accuracy:  73.4%, Loss: 0.5421\n",
      "Optimization Iteration:  16577, Training Accuracy:  71.9%, Loss: 0.4962\n",
      "Optimization Iteration:  16641, Training Accuracy:  67.2%, Loss: 0.5221\n",
      "Optimization Iteration:  16705, Training Accuracy:  65.6%, Loss: 0.5086\n",
      "Optimization Iteration:  16769, Training Accuracy:  68.8%, Loss: 0.4846\n",
      "Optimization Iteration:  16833, Training Accuracy:  75.0%, Loss: 0.5579\n",
      "Optimization Iteration:  16897, Training Accuracy:  71.9%, Loss: 0.4432\n",
      "Optimization Iteration:  16961, Training Accuracy:  76.6%, Loss: 0.4463\n",
      "Optimization Iteration:  17025, Training Accuracy:  75.0%, Loss: 0.4602\n",
      "Optimization Iteration:  17089, Training Accuracy:  64.1%, Loss: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  17153, Training Accuracy:  68.8%, Loss: 0.5659\n",
      "Optimization Iteration:  17217, Training Accuracy:  68.8%, Loss: 0.6039\n",
      "Optimization Iteration:  17281, Training Accuracy:  75.0%, Loss: 0.4146\n",
      "Optimization Iteration:  17345, Training Accuracy:  67.2%, Loss: 0.5011\n",
      "Optimization Iteration:  17409, Training Accuracy:  73.4%, Loss: 0.4096\n",
      "Optimization Iteration:  17473, Training Accuracy:  65.6%, Loss: 0.5827\n",
      "Optimization Iteration:  17537, Training Accuracy:  73.4%, Loss: 0.4672\n",
      "Optimization Iteration:  17601, Training Accuracy:  68.8%, Loss: 0.4974\n",
      "Optimization Iteration:  17665, Training Accuracy:  71.9%, Loss: 0.4312\n",
      "Optimization Iteration:  17729, Training Accuracy:  65.6%, Loss: 0.4873\n",
      "Optimization Iteration:  17793, Training Accuracy:  65.6%, Loss: 0.5508\n",
      "Optimization Iteration:  17857, Training Accuracy:  70.3%, Loss: 0.5362\n",
      "Optimization Iteration:  17921, Training Accuracy:  64.1%, Loss: 0.5548\n",
      "Optimization Iteration:  17985, Training Accuracy:  79.7%, Loss: 0.5125\n",
      "Optimization Iteration:  18049, Training Accuracy:  62.5%, Loss: 0.5194\n",
      "Optimization Iteration:  18113, Training Accuracy:  67.2%, Loss: 0.5552\n",
      "Optimization Iteration:  18177, Training Accuracy:  65.6%, Loss: 0.4624\n",
      "Optimization Iteration:  18241, Training Accuracy:  73.4%, Loss: 0.5160\n",
      "Optimization Iteration:  18305, Training Accuracy:  65.6%, Loss: 0.5326\n",
      "Optimization Iteration:  18369, Training Accuracy:  70.3%, Loss: 0.4239\n",
      "Optimization Iteration:  18433, Training Accuracy:  57.8%, Loss: 0.5263\n",
      "Optimization Iteration:  18497, Training Accuracy:  87.5%, Loss: 0.3821\n",
      "Optimization Iteration:  18561, Training Accuracy:  65.6%, Loss: 0.5898\n",
      "Optimization Iteration:  18625, Training Accuracy:  67.2%, Loss: 0.5518\n",
      "Optimization Iteration:  18689, Training Accuracy:  54.7%, Loss: 0.5402\n",
      "Optimization Iteration:  18753, Training Accuracy:  68.8%, Loss: 0.5267\n",
      "Optimization Iteration:  18817, Training Accuracy:  75.0%, Loss: 0.4609\n",
      "Optimization Iteration:  18881, Training Accuracy:  65.6%, Loss: 0.4332\n",
      "Optimization Iteration:  18945, Training Accuracy:  78.1%, Loss: 0.5407\n",
      "Optimization Iteration:  19009, Training Accuracy:  65.6%, Loss: 0.4935\n",
      "Optimization Iteration:  19073, Training Accuracy:  78.1%, Loss: 0.6653\n",
      "Optimization Iteration:  19137, Training Accuracy:  78.1%, Loss: 0.4403\n",
      "Optimization Iteration:  19201, Training Accuracy:  76.6%, Loss: 0.4423\n",
      "Optimization Iteration:  19265, Training Accuracy:  68.8%, Loss: 0.5681\n",
      "Optimization Iteration:  19329, Training Accuracy:  75.0%, Loss: 0.4396\n",
      "Optimization Iteration:  19393, Training Accuracy:  76.6%, Loss: 0.6082\n",
      "Optimization Iteration:  19457, Training Accuracy:  71.9%, Loss: 0.5158\n",
      "Optimization Iteration:  19521, Training Accuracy:  78.1%, Loss: 0.5038\n",
      "Optimization Iteration:  19585, Training Accuracy:  70.3%, Loss: 0.5696\n",
      "Optimization Iteration:  19649, Training Accuracy:  71.9%, Loss: 0.5093\n",
      "Optimization Iteration:  19713, Training Accuracy:  78.1%, Loss: 0.4650\n",
      "Optimization Iteration:  19777, Training Accuracy:  75.0%, Loss: 0.4898\n",
      "Optimization Iteration:  19841, Training Accuracy:  65.6%, Loss: 0.5339\n",
      "Optimization Iteration:  19905, Training Accuracy:  64.1%, Loss: 0.4703\n",
      "Optimization Iteration:  19969, Training Accuracy:  81.2%, Loss: 0.3802\n",
      "Optimization Iteration:  20033, Training Accuracy:  65.6%, Loss: 0.4993\n",
      "Optimization Iteration:  20097, Training Accuracy:  60.9%, Loss: 0.5565\n",
      "Optimization Iteration:  20161, Training Accuracy:  78.1%, Loss: 0.4672\n",
      "Optimization Iteration:  20225, Training Accuracy:  65.6%, Loss: 0.5580\n",
      "Optimization Iteration:  20289, Training Accuracy:  59.4%, Loss: 0.5485\n",
      "Optimization Iteration:  20353, Training Accuracy:  68.8%, Loss: 0.4563\n",
      "Optimization Iteration:  20417, Training Accuracy:  73.4%, Loss: 0.4740\n",
      "Optimization Iteration:  20481, Training Accuracy:  85.9%, Loss: 0.3893\n",
      "Optimization Iteration:  20545, Training Accuracy:  73.4%, Loss: 0.5257\n",
      "Optimization Iteration:  20609, Training Accuracy:  67.2%, Loss: 0.5363\n",
      "Optimization Iteration:  20673, Training Accuracy:  68.8%, Loss: 0.5678\n",
      "Optimization Iteration:  20737, Training Accuracy:  82.8%, Loss: 0.3619\n",
      "Optimization Iteration:  20801, Training Accuracy:  71.9%, Loss: 0.4433\n",
      "Optimization Iteration:  20865, Training Accuracy:  71.9%, Loss: 0.5184\n",
      "Optimization Iteration:  20929, Training Accuracy:  79.7%, Loss: 0.3617\n",
      "Optimization Iteration:  20993, Training Accuracy:  76.6%, Loss: 0.4579\n",
      "Optimization Iteration:  21057, Training Accuracy:  75.0%, Loss: 0.4099\n",
      "Optimization Iteration:  21121, Training Accuracy:  76.6%, Loss: 0.4069\n",
      "Optimization Iteration:  21185, Training Accuracy:  84.4%, Loss: 0.4169\n",
      "Optimization Iteration:  21249, Training Accuracy:  62.5%, Loss: 0.6132\n",
      "Optimization Iteration:  21313, Training Accuracy:  71.9%, Loss: 0.4350\n",
      "Optimization Iteration:  21377, Training Accuracy:  76.6%, Loss: 0.4046\n",
      "Optimization Iteration:  21441, Training Accuracy:  73.4%, Loss: 0.4702\n",
      "Optimization Iteration:  21505, Training Accuracy:  68.8%, Loss: 0.5230\n",
      "Optimization Iteration:  21569, Training Accuracy:  73.4%, Loss: 0.4593\n",
      "Optimization Iteration:  21633, Training Accuracy:  87.5%, Loss: 0.3497\n",
      "Optimization Iteration:  21697, Training Accuracy:  70.3%, Loss: 0.4864\n",
      "Optimization Iteration:  21761, Training Accuracy:  64.1%, Loss: 0.4922\n",
      "Optimization Iteration:  21825, Training Accuracy:  78.1%, Loss: 0.4531\n",
      "Optimization Iteration:  21889, Training Accuracy:  87.5%, Loss: 0.4016\n",
      "Optimization Iteration:  21953, Training Accuracy:  76.6%, Loss: 0.5171\n",
      "Optimization Iteration:  22017, Training Accuracy:  67.2%, Loss: 0.4886\n",
      "Optimization Iteration:  22081, Training Accuracy:  73.4%, Loss: 0.4906\n",
      "Optimization Iteration:  22145, Training Accuracy:  78.1%, Loss: 0.4937\n",
      "Optimization Iteration:  22209, Training Accuracy:  79.7%, Loss: 0.5437\n",
      "Optimization Iteration:  22273, Training Accuracy:  70.3%, Loss: 0.5072\n",
      "Optimization Iteration:  22337, Training Accuracy:  76.6%, Loss: 0.4251\n",
      "Optimization Iteration:  22401, Training Accuracy:  67.2%, Loss: 0.5231\n",
      "Optimization Iteration:  22465, Training Accuracy:  65.6%, Loss: 0.5222\n",
      "Optimization Iteration:  22529, Training Accuracy:  75.0%, Loss: 0.5510\n",
      "Optimization Iteration:  22593, Training Accuracy:  71.9%, Loss: 0.5115\n",
      "Optimization Iteration:  22657, Training Accuracy:  68.8%, Loss: 0.4898\n",
      "Optimization Iteration:  22721, Training Accuracy:  67.2%, Loss: 0.4904\n",
      "Optimization Iteration:  22785, Training Accuracy:  71.9%, Loss: 0.5677\n",
      "Optimization Iteration:  22849, Training Accuracy:  82.8%, Loss: 0.3840\n",
      "Optimization Iteration:  22913, Training Accuracy:  64.1%, Loss: 0.4970\n",
      "Optimization Iteration:  22977, Training Accuracy:  76.6%, Loss: 0.5032\n",
      "Optimization Iteration:  23041, Training Accuracy:  64.1%, Loss: 0.5182\n",
      "Optimization Iteration:  23105, Training Accuracy:  71.9%, Loss: 0.4809\n",
      "Optimization Iteration:  23169, Training Accuracy:  81.2%, Loss: 0.4153\n",
      "Optimization Iteration:  23233, Training Accuracy:  75.0%, Loss: 0.5415\n",
      "Optimization Iteration:  23297, Training Accuracy:  62.5%, Loss: 0.5599\n",
      "Optimization Iteration:  23361, Training Accuracy:  81.2%, Loss: 0.4357\n",
      "Optimization Iteration:  23425, Training Accuracy:  82.8%, Loss: 0.4021\n",
      "Optimization Iteration:  23489, Training Accuracy:  67.2%, Loss: 0.5348\n",
      "Optimization Iteration:  23553, Training Accuracy:  76.6%, Loss: 0.4449\n",
      "Optimization Iteration:  23617, Training Accuracy:  71.9%, Loss: 0.4676\n",
      "Optimization Iteration:  23681, Training Accuracy:  64.1%, Loss: 0.5782\n",
      "Optimization Iteration:  23745, Training Accuracy:  71.9%, Loss: 0.5009\n",
      "Optimization Iteration:  23809, Training Accuracy:  78.1%, Loss: 0.5097\n",
      "Optimization Iteration:  23873, Training Accuracy:  79.7%, Loss: 0.4178\n",
      "Optimization Iteration:  23937, Training Accuracy:  60.9%, Loss: 0.6816\n",
      "Optimization Iteration:  24001, Training Accuracy:  75.0%, Loss: 0.3859\n",
      "Optimization Iteration:  24065, Training Accuracy:  73.4%, Loss: 0.4338\n",
      "Optimization Iteration:  24129, Training Accuracy:  71.9%, Loss: 0.4826\n",
      "Optimization Iteration:  24193, Training Accuracy:  78.1%, Loss: 0.3822\n",
      "Optimization Iteration:  24257, Training Accuracy:  73.4%, Loss: 0.4016\n",
      "Optimization Iteration:  24321, Training Accuracy:  73.4%, Loss: 0.4531\n",
      "Optimization Iteration:  24385, Training Accuracy:  71.9%, Loss: 0.4756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  24449, Training Accuracy:  73.4%, Loss: 0.4015\n",
      "Optimization Iteration:  24513, Training Accuracy:  73.4%, Loss: 0.4585\n",
      "Optimization Iteration:  24577, Training Accuracy:  64.1%, Loss: 0.6652\n",
      "Optimization Iteration:  24641, Training Accuracy:  75.0%, Loss: 0.5214\n",
      "Optimization Iteration:  24705, Training Accuracy:  75.0%, Loss: 0.4010\n",
      "Optimization Iteration:  24769, Training Accuracy:  67.2%, Loss: 0.5284\n",
      "Optimization Iteration:  24833, Training Accuracy:  70.3%, Loss: 0.4691\n",
      "Optimization Iteration:  24897, Training Accuracy:  56.2%, Loss: 0.5378\n",
      "Optimization Iteration:  24961, Training Accuracy:  82.8%, Loss: 0.3896\n",
      "Optimization Iteration:  25025, Training Accuracy:  60.9%, Loss: 0.5412\n",
      "Optimization Iteration:  25089, Training Accuracy:  71.9%, Loss: 0.4759\n",
      "Optimization Iteration:  25153, Training Accuracy:  67.2%, Loss: 0.4882\n",
      "Optimization Iteration:  25217, Training Accuracy:  70.3%, Loss: 0.4992\n",
      "Optimization Iteration:  25281, Training Accuracy:  81.2%, Loss: 0.4751\n",
      "Optimization Iteration:  25345, Training Accuracy:  67.2%, Loss: 0.6539\n",
      "Optimization Iteration:  25409, Training Accuracy:  68.8%, Loss: 0.5738\n",
      "Optimization Iteration:  25473, Training Accuracy:  68.8%, Loss: 0.5826\n",
      "Optimization Iteration:  25537, Training Accuracy:  79.7%, Loss: 0.4832\n",
      "Optimization Iteration:  25601, Training Accuracy:  65.6%, Loss: 0.5636\n",
      "Optimization Iteration:  25665, Training Accuracy:  68.8%, Loss: 0.5293\n",
      "Optimization Iteration:  25729, Training Accuracy:  78.1%, Loss: 0.4330\n",
      "Optimization Iteration:  25793, Training Accuracy:  79.7%, Loss: 0.3935\n",
      "Optimization Iteration:  25857, Training Accuracy:  60.9%, Loss: 0.4862\n",
      "Optimization Iteration:  25921, Training Accuracy:  75.0%, Loss: 0.4454\n",
      "Optimization Iteration:  25985, Training Accuracy:  68.8%, Loss: 0.6228\n",
      "Optimization Iteration:  26049, Training Accuracy:  68.8%, Loss: 0.5108\n",
      "Optimization Iteration:  26113, Training Accuracy:  75.0%, Loss: 0.4495\n",
      "Optimization Iteration:  26177, Training Accuracy:  71.9%, Loss: 0.4747\n",
      "Optimization Iteration:  26241, Training Accuracy:  73.4%, Loss: 0.5178\n",
      "Optimization Iteration:  26305, Training Accuracy:  68.8%, Loss: 0.5785\n",
      "Optimization Iteration:  26369, Training Accuracy:  73.4%, Loss: 0.4164\n",
      "Optimization Iteration:  26433, Training Accuracy:  65.6%, Loss: 0.5105\n",
      "Optimization Iteration:  26497, Training Accuracy:  68.8%, Loss: 0.4548\n",
      "Optimization Iteration:  26561, Training Accuracy:  73.4%, Loss: 0.4353\n",
      "Optimization Iteration:  26625, Training Accuracy:  73.4%, Loss: 0.5425\n",
      "Optimization Iteration:  26689, Training Accuracy:  70.3%, Loss: 0.5115\n",
      "Optimization Iteration:  26753, Training Accuracy:  71.9%, Loss: 0.4850\n",
      "Optimization Iteration:  26817, Training Accuracy:  70.3%, Loss: 0.4743\n",
      "Optimization Iteration:  26881, Training Accuracy:  82.8%, Loss: 0.3919\n",
      "Optimization Iteration:  26945, Training Accuracy:  65.6%, Loss: 0.5488\n",
      "Optimization Iteration:  27009, Training Accuracy:  79.7%, Loss: 0.4325\n",
      "Optimization Iteration:  27073, Training Accuracy:  64.1%, Loss: 0.5320\n",
      "Optimization Iteration:  27137, Training Accuracy:  64.1%, Loss: 0.6473\n",
      "Optimization Iteration:  27201, Training Accuracy:  82.8%, Loss: 0.3970\n",
      "Optimization Iteration:  27265, Training Accuracy:  65.6%, Loss: 0.4967\n",
      "Optimization Iteration:  27329, Training Accuracy:  78.1%, Loss: 0.4397\n",
      "Optimization Iteration:  27393, Training Accuracy:  70.3%, Loss: 0.4789\n",
      "Optimization Iteration:  27457, Training Accuracy:  75.0%, Loss: 0.4892\n",
      "Optimization Iteration:  27521, Training Accuracy:  71.9%, Loss: 0.4707\n",
      "Optimization Iteration:  27585, Training Accuracy:  73.4%, Loss: 0.5106\n",
      "Optimization Iteration:  27649, Training Accuracy:  70.3%, Loss: 0.4248\n",
      "Optimization Iteration:  27713, Training Accuracy:  68.8%, Loss: 0.5198\n",
      "Optimization Iteration:  27777, Training Accuracy:  81.2%, Loss: 0.3875\n",
      "Optimization Iteration:  27841, Training Accuracy:  73.4%, Loss: 0.5078\n",
      "Optimization Iteration:  27905, Training Accuracy:  75.0%, Loss: 0.4213\n",
      "Optimization Iteration:  27969, Training Accuracy:  76.6%, Loss: 0.5435\n",
      "Optimization Iteration:  28033, Training Accuracy:  65.6%, Loss: 0.5079\n",
      "Optimization Iteration:  28097, Training Accuracy:  71.9%, Loss: 0.4626\n",
      "Optimization Iteration:  28161, Training Accuracy:  87.5%, Loss: 0.3363\n",
      "Optimization Iteration:  28225, Training Accuracy:  71.9%, Loss: 0.4988\n",
      "Optimization Iteration:  28289, Training Accuracy:  71.9%, Loss: 0.5598\n",
      "Optimization Iteration:  28353, Training Accuracy:  68.8%, Loss: 0.4475\n",
      "Optimization Iteration:  28417, Training Accuracy:  64.1%, Loss: 0.4943\n",
      "Optimization Iteration:  28481, Training Accuracy:  70.3%, Loss: 0.5164\n",
      "Optimization Iteration:  28545, Training Accuracy:  81.2%, Loss: 0.4149\n",
      "Optimization Iteration:  28609, Training Accuracy:  78.1%, Loss: 0.4516\n",
      "Optimization Iteration:  28673, Training Accuracy:  67.2%, Loss: 0.5675\n",
      "Optimization Iteration:  28737, Training Accuracy:  62.5%, Loss: 0.5045\n",
      "Optimization Iteration:  28801, Training Accuracy:  73.4%, Loss: 0.3933\n",
      "Optimization Iteration:  28865, Training Accuracy:  79.7%, Loss: 0.4060\n",
      "Optimization Iteration:  28929, Training Accuracy:  79.7%, Loss: 0.4120\n",
      "Optimization Iteration:  28993, Training Accuracy:  70.3%, Loss: 0.4894\n",
      "Optimization Iteration:  29057, Training Accuracy:  65.6%, Loss: 0.4617\n",
      "Optimization Iteration:  29121, Training Accuracy:  60.9%, Loss: 0.6361\n",
      "Optimization Iteration:  29185, Training Accuracy:  78.1%, Loss: 0.4149\n",
      "Optimization Iteration:  29249, Training Accuracy:  75.0%, Loss: 0.4187\n",
      "Optimization Iteration:  29313, Training Accuracy:  71.9%, Loss: 0.5132\n",
      "Optimization Iteration:  29377, Training Accuracy:  73.4%, Loss: 0.4255\n",
      "Optimization Iteration:  29441, Training Accuracy:  68.8%, Loss: 0.6095\n",
      "Optimization Iteration:  29505, Training Accuracy:  78.1%, Loss: 0.4612\n",
      "Optimization Iteration:  29569, Training Accuracy:  78.1%, Loss: 0.4465\n",
      "Optimization Iteration:  29633, Training Accuracy:  65.6%, Loss: 0.4981\n",
      "Optimization Iteration:  29697, Training Accuracy:  82.8%, Loss: 0.4658\n",
      "Optimization Iteration:  29761, Training Accuracy:  71.9%, Loss: 0.5697\n",
      "Optimization Iteration:  29825, Training Accuracy:  67.2%, Loss: 0.4751\n",
      "Optimization Iteration:  29889, Training Accuracy:  78.1%, Loss: 0.4189\n",
      "Optimization Iteration:  29953, Training Accuracy:  68.8%, Loss: 0.6375\n",
      "Optimization Iteration:  30017, Training Accuracy:  70.3%, Loss: 0.4287\n",
      "Optimization Iteration:  30081, Training Accuracy:  76.6%, Loss: 0.4286\n",
      "Optimization Iteration:  30145, Training Accuracy:  71.9%, Loss: 0.4986\n",
      "Optimization Iteration:  30209, Training Accuracy:  73.4%, Loss: 0.4452\n",
      "Optimization Iteration:  30273, Training Accuracy:  76.6%, Loss: 0.4598\n",
      "Optimization Iteration:  30337, Training Accuracy:  71.9%, Loss: 0.4556\n",
      "Optimization Iteration:  30401, Training Accuracy:  75.0%, Loss: 0.4702\n",
      "Optimization Iteration:  30465, Training Accuracy:  78.1%, Loss: 0.4778\n",
      "Optimization Iteration:  30529, Training Accuracy:  73.4%, Loss: 0.5178\n",
      "Optimization Iteration:  30593, Training Accuracy:  73.4%, Loss: 0.4697\n",
      "Optimization Iteration:  30657, Training Accuracy:  76.6%, Loss: 0.4019\n",
      "Optimization Iteration:  30721, Training Accuracy:  76.6%, Loss: 0.4808\n",
      "Optimization Iteration:  30785, Training Accuracy:  78.1%, Loss: 0.4239\n",
      "Optimization Iteration:  30849, Training Accuracy:  67.2%, Loss: 0.4894\n",
      "Optimization Iteration:  30913, Training Accuracy:  82.8%, Loss: 0.4386\n",
      "Optimization Iteration:  30977, Training Accuracy:  67.2%, Loss: 0.5034\n",
      "Optimization Iteration:  31041, Training Accuracy:  68.8%, Loss: 0.4233\n",
      "Optimization Iteration:  31105, Training Accuracy:  73.4%, Loss: 0.4301\n",
      "Optimization Iteration:  31169, Training Accuracy:  64.1%, Loss: 0.5284\n",
      "Optimization Iteration:  31233, Training Accuracy:  73.4%, Loss: 0.4829\n",
      "Optimization Iteration:  31297, Training Accuracy:  78.1%, Loss: 0.5454\n",
      "Optimization Iteration:  31361, Training Accuracy:  78.1%, Loss: 0.4371\n",
      "Optimization Iteration:  31425, Training Accuracy:  76.6%, Loss: 0.4565\n",
      "Optimization Iteration:  31489, Training Accuracy:  78.1%, Loss: 0.3928\n",
      "Optimization Iteration:  31553, Training Accuracy:  67.2%, Loss: 0.5175\n",
      "Optimization Iteration:  31617, Training Accuracy:  76.6%, Loss: 0.3617\n",
      "Optimization Iteration:  31681, Training Accuracy:  76.6%, Loss: 0.5876\n",
      "Optimization Iteration:  31745, Training Accuracy:  71.9%, Loss: 0.4817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  31809, Training Accuracy:  68.8%, Loss: 0.5359\n",
      "Optimization Iteration:  31873, Training Accuracy:  78.1%, Loss: 0.3993\n",
      "Optimization Iteration:  31937, Training Accuracy:  51.6%, Loss: 0.5856\n",
      "Optimization Iteration:  32001, Training Accuracy:  70.3%, Loss: 0.5125\n",
      "Optimization Iteration:  32065, Training Accuracy:  70.3%, Loss: 0.4485\n",
      "Optimization Iteration:  32129, Training Accuracy:  65.6%, Loss: 0.5400\n",
      "Optimization Iteration:  32193, Training Accuracy:  73.4%, Loss: 0.4811\n",
      "Optimization Iteration:  32257, Training Accuracy:  71.9%, Loss: 0.5002\n",
      "Optimization Iteration:  32321, Training Accuracy:  79.7%, Loss: 0.4081\n",
      "Optimization Iteration:  32385, Training Accuracy:  70.3%, Loss: 0.4536\n",
      "Optimization Iteration:  32449, Training Accuracy:  78.1%, Loss: 0.4434\n",
      "Optimization Iteration:  32513, Training Accuracy:  76.6%, Loss: 0.4845\n",
      "Optimization Iteration:  32577, Training Accuracy:  78.1%, Loss: 0.5228\n",
      "Optimization Iteration:  32641, Training Accuracy:  70.3%, Loss: 0.4822\n",
      "Optimization Iteration:  32705, Training Accuracy:  78.1%, Loss: 0.3725\n",
      "Optimization Iteration:  32769, Training Accuracy:  76.6%, Loss: 0.3822\n",
      "Optimization Iteration:  32833, Training Accuracy:  68.8%, Loss: 0.4793\n",
      "Optimization Iteration:  32897, Training Accuracy:  68.8%, Loss: 0.5502\n",
      "Optimization Iteration:  32961, Training Accuracy:  71.9%, Loss: 0.5241\n",
      "Optimization Iteration:  33025, Training Accuracy:  75.0%, Loss: 0.4288\n",
      "Optimization Iteration:  33089, Training Accuracy:  68.8%, Loss: 0.5486\n",
      "Optimization Iteration:  33153, Training Accuracy:  68.8%, Loss: 0.5558\n",
      "Optimization Iteration:  33217, Training Accuracy:  71.9%, Loss: 0.4266\n",
      "Optimization Iteration:  33281, Training Accuracy:  64.1%, Loss: 0.5711\n",
      "Optimization Iteration:  33345, Training Accuracy:  71.9%, Loss: 0.5033\n",
      "Optimization Iteration:  33409, Training Accuracy:  71.9%, Loss: 0.4715\n",
      "Optimization Iteration:  33473, Training Accuracy:  70.3%, Loss: 0.4638\n",
      "Optimization Iteration:  33537, Training Accuracy:  68.8%, Loss: 0.5353\n",
      "Optimization Iteration:  33601, Training Accuracy:  65.6%, Loss: 0.5541\n",
      "Optimization Iteration:  33665, Training Accuracy:  68.8%, Loss: 0.4784\n",
      "Optimization Iteration:  33729, Training Accuracy:  73.4%, Loss: 0.5298\n",
      "Optimization Iteration:  33793, Training Accuracy:  65.6%, Loss: 0.5154\n",
      "Optimization Iteration:  33857, Training Accuracy:  67.2%, Loss: 0.4966\n",
      "Optimization Iteration:  33921, Training Accuracy:  68.8%, Loss: 0.5035\n",
      "Optimization Iteration:  33985, Training Accuracy:  68.8%, Loss: 0.5122\n",
      "Optimization Iteration:  34049, Training Accuracy:  68.8%, Loss: 0.5259\n",
      "Optimization Iteration:  34113, Training Accuracy:  71.9%, Loss: 0.4422\n",
      "Optimization Iteration:  34177, Training Accuracy:  68.8%, Loss: 0.4380\n",
      "Optimization Iteration:  34241, Training Accuracy:  68.8%, Loss: 0.4311\n",
      "Optimization Iteration:  34305, Training Accuracy:  73.4%, Loss: 0.5343\n",
      "Optimization Iteration:  34369, Training Accuracy:  81.2%, Loss: 0.4150\n",
      "Optimization Iteration:  34433, Training Accuracy:  65.6%, Loss: 0.5187\n",
      "Optimization Iteration:  34497, Training Accuracy:  85.9%, Loss: 0.3910\n",
      "Optimization Iteration:  34561, Training Accuracy:  70.3%, Loss: 0.4435\n",
      "Optimization Iteration:  34625, Training Accuracy:  70.3%, Loss: 0.5929\n",
      "Optimization Iteration:  34689, Training Accuracy:  70.3%, Loss: 0.5012\n",
      "Optimization Iteration:  34753, Training Accuracy:  73.4%, Loss: 0.4557\n",
      "Optimization Iteration:  34817, Training Accuracy:  75.0%, Loss: 0.4303\n",
      "Optimization Iteration:  34881, Training Accuracy:  68.8%, Loss: 0.4746\n",
      "Optimization Iteration:  34945, Training Accuracy:  64.1%, Loss: 0.5033\n",
      "Optimization Iteration:  35009, Training Accuracy:  73.4%, Loss: 0.5051\n",
      "Optimization Iteration:  35073, Training Accuracy:  75.0%, Loss: 0.4295\n",
      "Optimization Iteration:  35137, Training Accuracy:  73.4%, Loss: 0.4430\n",
      "Optimization Iteration:  35201, Training Accuracy:  70.3%, Loss: 0.4815\n",
      "Optimization Iteration:  35265, Training Accuracy:  67.2%, Loss: 0.4094\n",
      "Optimization Iteration:  35329, Training Accuracy:  71.9%, Loss: 0.4290\n",
      "Optimization Iteration:  35393, Training Accuracy:  78.1%, Loss: 0.3894\n",
      "Optimization Iteration:  35457, Training Accuracy:  67.2%, Loss: 0.5229\n",
      "Optimization Iteration:  35521, Training Accuracy:  68.8%, Loss: 0.4916\n",
      "Optimization Iteration:  35585, Training Accuracy:  73.4%, Loss: 0.3937\n",
      "Optimization Iteration:  35649, Training Accuracy:  67.2%, Loss: 0.4675\n",
      "Optimization Iteration:  35713, Training Accuracy:  79.7%, Loss: 0.5076\n",
      "Optimization Iteration:  35777, Training Accuracy:  76.6%, Loss: 0.3823\n",
      "Optimization Iteration:  35841, Training Accuracy:  73.4%, Loss: 0.4069\n",
      "Optimization Iteration:  35905, Training Accuracy:  73.4%, Loss: 0.4164\n",
      "Optimization Iteration:  35969, Training Accuracy:  67.2%, Loss: 0.4972\n",
      "Optimization Iteration:  36033, Training Accuracy:  65.6%, Loss: 0.4232\n",
      "Optimization Iteration:  36097, Training Accuracy:  78.1%, Loss: 0.4120\n",
      "Optimization Iteration:  36161, Training Accuracy:  73.4%, Loss: 0.4312\n",
      "Optimization Iteration:  36225, Training Accuracy:  76.6%, Loss: 0.4410\n",
      "Optimization Iteration:  36289, Training Accuracy:  78.1%, Loss: 0.4040\n",
      "Optimization Iteration:  36353, Training Accuracy:  71.9%, Loss: 0.4830\n",
      "Optimization Iteration:  36417, Training Accuracy:  65.6%, Loss: 0.5366\n",
      "Optimization Iteration:  36481, Training Accuracy:  78.1%, Loss: 0.3847\n",
      "Optimization Iteration:  36545, Training Accuracy:  71.9%, Loss: 0.5266\n",
      "Optimization Iteration:  36609, Training Accuracy:  68.8%, Loss: 0.4358\n",
      "Optimization Iteration:  36673, Training Accuracy:  67.2%, Loss: 0.4796\n",
      "Optimization Iteration:  36737, Training Accuracy:  78.1%, Loss: 0.4425\n",
      "Optimization Iteration:  36801, Training Accuracy:  76.6%, Loss: 0.4404\n",
      "Optimization Iteration:  36865, Training Accuracy:  79.7%, Loss: 0.4104\n",
      "Optimization Iteration:  36929, Training Accuracy:  70.3%, Loss: 0.5031\n",
      "Optimization Iteration:  36993, Training Accuracy:  68.8%, Loss: 0.4914\n",
      "Optimization Iteration:  37057, Training Accuracy:  73.4%, Loss: 0.4147\n",
      "Optimization Iteration:  37121, Training Accuracy:  79.7%, Loss: 0.6237\n",
      "Optimization Iteration:  37185, Training Accuracy:  76.6%, Loss: 0.5037\n",
      "Optimization Iteration:  37249, Training Accuracy:  67.2%, Loss: 0.5648\n",
      "Optimization Iteration:  37313, Training Accuracy:  75.0%, Loss: 0.3861\n",
      "Optimization Iteration:  37377, Training Accuracy:  73.4%, Loss: 0.5690\n",
      "Optimization Iteration:  37441, Training Accuracy:  78.1%, Loss: 0.4274\n",
      "Optimization Iteration:  37505, Training Accuracy:  70.3%, Loss: 0.4707\n",
      "Optimization Iteration:  37569, Training Accuracy:  57.8%, Loss: 0.5684\n",
      "Optimization Iteration:  37633, Training Accuracy:  75.0%, Loss: 0.5171\n",
      "Optimization Iteration:  37697, Training Accuracy:  73.4%, Loss: 0.4860\n",
      "Optimization Iteration:  37761, Training Accuracy:  82.8%, Loss: 0.4302\n",
      "Optimization Iteration:  37825, Training Accuracy:  82.8%, Loss: 0.4059\n",
      "Optimization Iteration:  37889, Training Accuracy:  67.2%, Loss: 0.4958\n",
      "Optimization Iteration:  37953, Training Accuracy:  78.1%, Loss: 0.3573\n",
      "Optimization Iteration:  38017, Training Accuracy:  71.9%, Loss: 0.3911\n",
      "Optimization Iteration:  38081, Training Accuracy:  67.2%, Loss: 0.4638\n",
      "Optimization Iteration:  38145, Training Accuracy:  81.2%, Loss: 0.3793\n",
      "Optimization Iteration:  38209, Training Accuracy:  71.9%, Loss: 0.4258\n",
      "Optimization Iteration:  38273, Training Accuracy:  68.8%, Loss: 0.4942\n",
      "Optimization Iteration:  38337, Training Accuracy:  79.7%, Loss: 0.3592\n",
      "Optimization Iteration:  38401, Training Accuracy:  68.8%, Loss: 0.5360\n",
      "Optimization Iteration:  38465, Training Accuracy:  68.8%, Loss: 0.5871\n",
      "Optimization Iteration:  38529, Training Accuracy:  78.1%, Loss: 0.4552\n",
      "Optimization Iteration:  38593, Training Accuracy:  75.0%, Loss: 0.4955\n",
      "Optimization Iteration:  38657, Training Accuracy:  73.4%, Loss: 0.5239\n",
      "Optimization Iteration:  38721, Training Accuracy:  75.0%, Loss: 0.4536\n",
      "Optimization Iteration:  38785, Training Accuracy:  75.0%, Loss: 0.4992\n",
      "Optimization Iteration:  38849, Training Accuracy:  84.4%, Loss: 0.3489\n",
      "Optimization Iteration:  38913, Training Accuracy:  71.9%, Loss: 0.4970\n",
      "Optimization Iteration:  38977, Training Accuracy:  73.4%, Loss: 0.5004\n",
      "Optimization Iteration:  39041, Training Accuracy:  79.7%, Loss: 0.5330\n",
      "Optimization Iteration:  39105, Training Accuracy:  70.3%, Loss: 0.5549\n",
      "Optimization Iteration:  39169, Training Accuracy:  73.4%, Loss: 0.4364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  39233, Training Accuracy:  71.9%, Loss: 0.5178\n",
      "Optimization Iteration:  39297, Training Accuracy:  76.6%, Loss: 0.4528\n",
      "Optimization Iteration:  39361, Training Accuracy:  78.1%, Loss: 0.4543\n",
      "Optimization Iteration:  39425, Training Accuracy:  65.6%, Loss: 0.4977\n",
      "Optimization Iteration:  39489, Training Accuracy:  82.8%, Loss: 0.4047\n",
      "Optimization Iteration:  39553, Training Accuracy:  73.4%, Loss: 0.4367\n",
      "Optimization Iteration:  39617, Training Accuracy:  64.1%, Loss: 0.5034\n",
      "Optimization Iteration:  39681, Training Accuracy:  71.9%, Loss: 0.4889\n",
      "Optimization Iteration:  39745, Training Accuracy:  75.0%, Loss: 0.5102\n",
      "Optimization Iteration:  39809, Training Accuracy:  68.8%, Loss: 0.4667\n",
      "Optimization Iteration:  39873, Training Accuracy:  64.1%, Loss: 0.6473\n",
      "Optimization Iteration:  39937, Training Accuracy:  71.9%, Loss: 0.5533\n",
      "Optimization Iteration:  40001, Training Accuracy:  65.6%, Loss: 0.5013\n",
      "Optimization Iteration:  40065, Training Accuracy:  62.5%, Loss: 0.4632\n",
      "Optimization Iteration:  40129, Training Accuracy:  76.6%, Loss: 0.5072\n",
      "Optimization Iteration:  40193, Training Accuracy:  67.2%, Loss: 0.5471\n",
      "Optimization Iteration:  40257, Training Accuracy:  75.0%, Loss: 0.4519\n",
      "Optimization Iteration:  40321, Training Accuracy:  62.5%, Loss: 0.5305\n",
      "Optimization Iteration:  40385, Training Accuracy:  73.4%, Loss: 0.5498\n",
      "Optimization Iteration:  40449, Training Accuracy:  81.2%, Loss: 0.3965\n",
      "Optimization Iteration:  40513, Training Accuracy:  81.2%, Loss: 0.3871\n",
      "Optimization Iteration:  40577, Training Accuracy:  70.3%, Loss: 0.5000\n",
      "Optimization Iteration:  40641, Training Accuracy:  71.9%, Loss: 0.3946\n",
      "Optimization Iteration:  40705, Training Accuracy:  68.8%, Loss: 0.5491\n",
      "Optimization Iteration:  40769, Training Accuracy:  67.2%, Loss: 0.4338\n",
      "Optimization Iteration:  40833, Training Accuracy:  73.4%, Loss: 0.4364\n",
      "Optimization Iteration:  40897, Training Accuracy:  79.7%, Loss: 0.3973\n",
      "Optimization Iteration:  40961, Training Accuracy:  84.4%, Loss: 0.4268\n",
      "Optimization Iteration:  41025, Training Accuracy:  76.6%, Loss: 0.4154\n",
      "Optimization Iteration:  41089, Training Accuracy:  76.6%, Loss: 0.3823\n",
      "Optimization Iteration:  41153, Training Accuracy:  76.6%, Loss: 0.4397\n",
      "Optimization Iteration:  41217, Training Accuracy:  81.2%, Loss: 0.4004\n",
      "Optimization Iteration:  41281, Training Accuracy:  68.8%, Loss: 0.5292\n",
      "Optimization Iteration:  41345, Training Accuracy:  68.8%, Loss: 0.5537\n",
      "Optimization Iteration:  41409, Training Accuracy:  71.9%, Loss: 0.4398\n",
      "Optimization Iteration:  41473, Training Accuracy:  67.2%, Loss: 0.4342\n",
      "Optimization Iteration:  41537, Training Accuracy:  73.4%, Loss: 0.5612\n",
      "Optimization Iteration:  41601, Training Accuracy:  60.9%, Loss: 0.5724\n",
      "Optimization Iteration:  41665, Training Accuracy:  68.8%, Loss: 0.5201\n",
      "Optimization Iteration:  41729, Training Accuracy:  67.2%, Loss: 0.4308\n",
      "Optimization Iteration:  41793, Training Accuracy:  67.2%, Loss: 0.6411\n",
      "Optimization Iteration:  41857, Training Accuracy:  76.6%, Loss: 0.4623\n",
      "Optimization Iteration:  41921, Training Accuracy:  76.6%, Loss: 0.4177\n",
      "Optimization Iteration:  41985, Training Accuracy:  65.6%, Loss: 0.5388\n",
      "Optimization Iteration:  42049, Training Accuracy:  68.8%, Loss: 0.5412\n",
      "Optimization Iteration:  42113, Training Accuracy:  70.3%, Loss: 0.4975\n",
      "Optimization Iteration:  42177, Training Accuracy:  60.9%, Loss: 0.5746\n",
      "Optimization Iteration:  42241, Training Accuracy:  81.2%, Loss: 0.4610\n",
      "Optimization Iteration:  42305, Training Accuracy:  79.7%, Loss: 0.4951\n",
      "Optimization Iteration:  42369, Training Accuracy:  76.6%, Loss: 0.4946\n",
      "Optimization Iteration:  42433, Training Accuracy:  67.2%, Loss: 0.4836\n",
      "Optimization Iteration:  42497, Training Accuracy:  75.0%, Loss: 0.4290\n",
      "Optimization Iteration:  42561, Training Accuracy:  75.0%, Loss: 0.4439\n",
      "Optimization Iteration:  42625, Training Accuracy:  78.1%, Loss: 0.4429\n",
      "Optimization Iteration:  42689, Training Accuracy:  71.9%, Loss: 0.4154\n",
      "Optimization Iteration:  42753, Training Accuracy:  71.9%, Loss: 0.5050\n",
      "Optimization Iteration:  42817, Training Accuracy:  84.4%, Loss: 0.3538\n",
      "Optimization Iteration:  42881, Training Accuracy:  71.9%, Loss: 0.4650\n",
      "Optimization Iteration:  42945, Training Accuracy:  76.6%, Loss: 0.4745\n",
      "Optimization Iteration:  43009, Training Accuracy:  76.6%, Loss: 0.5101\n",
      "Optimization Iteration:  43073, Training Accuracy:  68.8%, Loss: 0.5052\n",
      "Optimization Iteration:  43137, Training Accuracy:  78.1%, Loss: 0.4684\n",
      "Optimization Iteration:  43201, Training Accuracy:  65.6%, Loss: 0.4799\n",
      "Optimization Iteration:  43265, Training Accuracy:  70.3%, Loss: 0.4925\n",
      "Optimization Iteration:  43329, Training Accuracy:  71.9%, Loss: 0.4912\n",
      "Optimization Iteration:  43393, Training Accuracy:  76.6%, Loss: 0.4560\n",
      "Optimization Iteration:  43457, Training Accuracy:  75.0%, Loss: 0.4178\n",
      "Optimization Iteration:  43521, Training Accuracy:  67.2%, Loss: 0.5506\n",
      "Optimization Iteration:  43585, Training Accuracy:  75.0%, Loss: 0.4077\n",
      "Optimization Iteration:  43649, Training Accuracy:  71.9%, Loss: 0.4445\n",
      "Optimization Iteration:  43713, Training Accuracy:  68.8%, Loss: 0.5127\n",
      "Optimization Iteration:  43777, Training Accuracy:  78.1%, Loss: 0.4382\n",
      "Optimization Iteration:  43841, Training Accuracy:  70.3%, Loss: 0.5287\n",
      "Optimization Iteration:  43905, Training Accuracy:  73.4%, Loss: 0.4476\n",
      "Optimization Iteration:  43969, Training Accuracy:  75.0%, Loss: 0.4270\n",
      "Optimization Iteration:  44033, Training Accuracy:  71.9%, Loss: 0.5210\n",
      "Optimization Iteration:  44097, Training Accuracy:  81.2%, Loss: 0.4420\n",
      "Optimization Iteration:  44161, Training Accuracy:  70.3%, Loss: 0.4238\n",
      "Optimization Iteration:  44225, Training Accuracy:  68.8%, Loss: 0.4901\n",
      "Optimization Iteration:  44289, Training Accuracy:  70.3%, Loss: 0.4606\n",
      "Optimization Iteration:  44353, Training Accuracy:  68.8%, Loss: 0.5263\n",
      "Optimization Iteration:  44417, Training Accuracy:  76.6%, Loss: 0.4608\n",
      "Optimization Iteration:  44481, Training Accuracy:  78.1%, Loss: 0.4977\n",
      "Optimization Iteration:  44545, Training Accuracy:  75.0%, Loss: 0.4954\n",
      "Optimization Iteration:  44609, Training Accuracy:  78.1%, Loss: 0.4826\n",
      "Optimization Iteration:  44673, Training Accuracy:  64.1%, Loss: 0.6058\n",
      "Optimization Iteration:  44737, Training Accuracy:  70.3%, Loss: 0.4752\n",
      "Optimization Iteration:  44801, Training Accuracy:  76.6%, Loss: 0.4976\n",
      "Optimization Iteration:  44865, Training Accuracy:  76.6%, Loss: 0.4513\n",
      "Optimization Iteration:  44929, Training Accuracy:  82.8%, Loss: 0.4029\n",
      "Optimization Iteration:  44993, Training Accuracy:  76.6%, Loss: 0.6031\n",
      "Optimization Iteration:  45057, Training Accuracy:  76.6%, Loss: 0.4515\n",
      "Optimization Iteration:  45121, Training Accuracy:  76.6%, Loss: 0.5035\n",
      "Optimization Iteration:  45185, Training Accuracy:  82.8%, Loss: 0.3653\n",
      "Optimization Iteration:  45249, Training Accuracy:  62.5%, Loss: 0.5329\n",
      "Optimization Iteration:  45313, Training Accuracy:  76.6%, Loss: 0.4385\n",
      "Optimization Iteration:  45377, Training Accuracy:  76.6%, Loss: 0.5308\n",
      "Optimization Iteration:  45441, Training Accuracy:  70.3%, Loss: 0.4400\n",
      "Optimization Iteration:  45505, Training Accuracy:  84.4%, Loss: 0.4347\n",
      "Optimization Iteration:  45569, Training Accuracy:  70.3%, Loss: 0.5725\n",
      "Optimization Iteration:  45633, Training Accuracy:  75.0%, Loss: 0.5500\n",
      "Optimization Iteration:  45697, Training Accuracy:  71.9%, Loss: 0.3881\n",
      "Optimization Iteration:  45761, Training Accuracy:  76.6%, Loss: 0.3779\n",
      "Optimization Iteration:  45825, Training Accuracy:  70.3%, Loss: 0.5266\n",
      "Optimization Iteration:  45889, Training Accuracy:  75.0%, Loss: 0.3908\n",
      "Optimization Iteration:  45953, Training Accuracy:  75.0%, Loss: 0.4218\n",
      "Optimization Iteration:  46017, Training Accuracy:  76.6%, Loss: 0.4491\n",
      "Optimization Iteration:  46081, Training Accuracy:  81.2%, Loss: 0.3894\n",
      "Optimization Iteration:  46145, Training Accuracy:  75.0%, Loss: 0.4098\n",
      "Optimization Iteration:  46209, Training Accuracy:  82.8%, Loss: 0.3533\n",
      "Optimization Iteration:  46273, Training Accuracy:  71.9%, Loss: 0.5408\n",
      "Optimization Iteration:  46337, Training Accuracy:  76.6%, Loss: 0.4543\n",
      "Optimization Iteration:  46401, Training Accuracy:  82.8%, Loss: 0.4228\n",
      "Optimization Iteration:  46465, Training Accuracy:  70.3%, Loss: 0.5638\n",
      "Optimization Iteration:  46529, Training Accuracy:  75.0%, Loss: 0.4049\n",
      "Optimization Iteration:  46593, Training Accuracy:  73.4%, Loss: 0.4848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  46657, Training Accuracy:  64.1%, Loss: 0.5842\n",
      "Optimization Iteration:  46721, Training Accuracy:  70.3%, Loss: 0.5236\n",
      "Optimization Iteration:  46785, Training Accuracy:  67.2%, Loss: 0.5310\n",
      "Optimization Iteration:  46849, Training Accuracy:  65.6%, Loss: 0.5312\n",
      "Optimization Iteration:  46913, Training Accuracy:  78.1%, Loss: 0.3869\n",
      "Optimization Iteration:  46977, Training Accuracy:  78.1%, Loss: 0.4167\n",
      "Optimization Iteration:  47041, Training Accuracy:  81.2%, Loss: 0.4335\n",
      "Optimization Iteration:  47105, Training Accuracy:  62.5%, Loss: 0.5817\n",
      "Optimization Iteration:  47169, Training Accuracy:  67.2%, Loss: 0.5114\n",
      "Optimization Iteration:  47233, Training Accuracy:  75.0%, Loss: 0.4787\n",
      "Optimization Iteration:  47297, Training Accuracy:  73.4%, Loss: 0.4454\n",
      "Optimization Iteration:  47361, Training Accuracy:  82.8%, Loss: 0.3808\n",
      "Optimization Iteration:  47425, Training Accuracy:  78.1%, Loss: 0.4270\n",
      "Optimization Iteration:  47489, Training Accuracy:  76.6%, Loss: 0.4426\n",
      "Optimization Iteration:  47553, Training Accuracy:  78.1%, Loss: 0.4979\n",
      "Optimization Iteration:  47617, Training Accuracy:  76.6%, Loss: 0.4994\n",
      "Optimization Iteration:  47681, Training Accuracy:  78.1%, Loss: 0.4524\n",
      "Optimization Iteration:  47745, Training Accuracy:  67.2%, Loss: 0.5824\n",
      "Optimization Iteration:  47809, Training Accuracy:  70.3%, Loss: 0.4665\n",
      "Optimization Iteration:  47873, Training Accuracy:  78.1%, Loss: 0.4303\n",
      "Optimization Iteration:  47937, Training Accuracy:  68.8%, Loss: 0.4811\n",
      "Optimization Iteration:  48001, Training Accuracy:  78.1%, Loss: 0.5291\n",
      "Optimization Iteration:  48065, Training Accuracy:  64.1%, Loss: 0.5327\n",
      "Optimization Iteration:  48129, Training Accuracy:  68.8%, Loss: 0.5113\n",
      "Optimization Iteration:  48193, Training Accuracy:  71.9%, Loss: 0.5399\n",
      "Optimization Iteration:  48257, Training Accuracy:  71.9%, Loss: 0.4388\n",
      "Optimization Iteration:  48321, Training Accuracy:  79.7%, Loss: 0.4141\n",
      "Optimization Iteration:  48385, Training Accuracy:  78.1%, Loss: 0.4143\n",
      "Optimization Iteration:  48449, Training Accuracy:  68.8%, Loss: 0.5309\n",
      "Optimization Iteration:  48513, Training Accuracy:  75.0%, Loss: 0.4957\n",
      "Optimization Iteration:  48577, Training Accuracy:  62.5%, Loss: 0.5198\n",
      "Optimization Iteration:  48641, Training Accuracy:  76.6%, Loss: 0.4707\n",
      "Optimization Iteration:  48705, Training Accuracy:  64.1%, Loss: 0.5270\n",
      "Optimization Iteration:  48769, Training Accuracy:  76.6%, Loss: 0.4449\n",
      "Optimization Iteration:  48833, Training Accuracy:  79.7%, Loss: 0.4206\n",
      "Optimization Iteration:  48897, Training Accuracy:  70.3%, Loss: 0.5685\n",
      "Optimization Iteration:  48961, Training Accuracy:  76.6%, Loss: 0.5000\n",
      "Optimization Iteration:  49025, Training Accuracy:  64.1%, Loss: 0.4892\n",
      "Optimization Iteration:  49089, Training Accuracy:  70.3%, Loss: 0.4401\n",
      "Optimization Iteration:  49153, Training Accuracy:  82.8%, Loss: 0.4164\n",
      "Optimization Iteration:  49217, Training Accuracy:  78.1%, Loss: 0.4193\n",
      "Optimization Iteration:  49281, Training Accuracy:  73.4%, Loss: 0.4610\n",
      "Optimization Iteration:  49345, Training Accuracy:  78.1%, Loss: 0.4190\n",
      "Optimization Iteration:  49409, Training Accuracy:  71.9%, Loss: 0.4074\n",
      "Optimization Iteration:  49473, Training Accuracy:  75.0%, Loss: 0.3771\n",
      "Optimization Iteration:  49537, Training Accuracy:  73.4%, Loss: 0.4180\n",
      "Optimization Iteration:  49601, Training Accuracy:  62.5%, Loss: 0.6598\n",
      "Optimization Iteration:  49665, Training Accuracy:  75.0%, Loss: 0.4298\n",
      "Optimization Iteration:  49729, Training Accuracy:  68.8%, Loss: 0.5124\n",
      "Optimization Iteration:  49793, Training Accuracy:  62.5%, Loss: 0.5252\n",
      "Optimization Iteration:  49857, Training Accuracy:  65.6%, Loss: 0.5397\n",
      "Optimization Iteration:  49921, Training Accuracy:  70.3%, Loss: 0.5841\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 4\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  70.3%, Loss: 0.5336\n",
      "Optimization Iteration:    129, Training Accuracy:  71.9%, Loss: 0.4855\n",
      "Optimization Iteration:    193, Training Accuracy:  73.4%, Loss: 0.4848\n",
      "Optimization Iteration:    257, Training Accuracy:  70.3%, Loss: 0.4585\n",
      "Optimization Iteration:    321, Training Accuracy:  76.6%, Loss: 0.4274\n",
      "Optimization Iteration:    385, Training Accuracy:  81.2%, Loss: 0.4146\n",
      "Optimization Iteration:    449, Training Accuracy:  71.9%, Loss: 0.4411\n",
      "Optimization Iteration:    513, Training Accuracy:  71.9%, Loss: 0.4555\n",
      "Optimization Iteration:    577, Training Accuracy:  65.6%, Loss: 0.4930\n",
      "Optimization Iteration:    641, Training Accuracy:  65.6%, Loss: 0.4566\n",
      "Optimization Iteration:    705, Training Accuracy:  62.5%, Loss: 0.4979\n",
      "Optimization Iteration:    769, Training Accuracy:  68.8%, Loss: 0.4459\n",
      "Optimization Iteration:    833, Training Accuracy:  78.1%, Loss: 0.3607\n",
      "Optimization Iteration:    897, Training Accuracy:  82.8%, Loss: 0.3407\n",
      "Optimization Iteration:    961, Training Accuracy:  73.4%, Loss: 0.3656\n",
      "Optimization Iteration:   1025, Training Accuracy:  73.4%, Loss: 0.4805\n",
      "Optimization Iteration:   1089, Training Accuracy:  67.2%, Loss: 0.4636\n",
      "Optimization Iteration:   1153, Training Accuracy:  78.1%, Loss: 0.5105\n",
      "Optimization Iteration:   1217, Training Accuracy:  75.0%, Loss: 0.4020\n",
      "Optimization Iteration:   1281, Training Accuracy:  79.7%, Loss: 0.3930\n",
      "Optimization Iteration:   1345, Training Accuracy:  70.3%, Loss: 0.4753\n",
      "Optimization Iteration:   1409, Training Accuracy:  70.3%, Loss: 0.5048\n",
      "Optimization Iteration:   1473, Training Accuracy:  75.0%, Loss: 0.5209\n",
      "Optimization Iteration:   1537, Training Accuracy:  67.2%, Loss: 0.4582\n",
      "Optimization Iteration:   1601, Training Accuracy:  76.6%, Loss: 0.4381\n",
      "Optimization Iteration:   1665, Training Accuracy:  75.0%, Loss: 0.4117\n",
      "Optimization Iteration:   1729, Training Accuracy:  79.7%, Loss: 0.4049\n",
      "Optimization Iteration:   1793, Training Accuracy:  67.2%, Loss: 0.5006\n",
      "Optimization Iteration:   1857, Training Accuracy:  76.6%, Loss: 0.4582\n",
      "Optimization Iteration:   1921, Training Accuracy:  68.8%, Loss: 0.4539\n",
      "Optimization Iteration:   1985, Training Accuracy:  75.0%, Loss: 0.4725\n",
      "Optimization Iteration:   2049, Training Accuracy:  75.0%, Loss: 0.4635\n",
      "Optimization Iteration:   2113, Training Accuracy:  75.0%, Loss: 0.4397\n",
      "Optimization Iteration:   2177, Training Accuracy:  71.9%, Loss: 0.4164\n",
      "Optimization Iteration:   2241, Training Accuracy:  75.0%, Loss: 0.4465\n",
      "Optimization Iteration:   2305, Training Accuracy:  68.8%, Loss: 0.4046\n",
      "Optimization Iteration:   2369, Training Accuracy:  78.1%, Loss: 0.4969\n",
      "Optimization Iteration:   2433, Training Accuracy:  70.3%, Loss: 0.4568\n",
      "Optimization Iteration:   2497, Training Accuracy:  82.8%, Loss: 0.4469\n",
      "Optimization Iteration:   2561, Training Accuracy:  76.6%, Loss: 0.3900\n",
      "Optimization Iteration:   2625, Training Accuracy:  81.2%, Loss: 0.4124\n",
      "Optimization Iteration:   2689, Training Accuracy:  68.8%, Loss: 0.4244\n",
      "Optimization Iteration:   2753, Training Accuracy:  71.9%, Loss: 0.4327\n",
      "Optimization Iteration:   2817, Training Accuracy:  64.1%, Loss: 0.5194\n",
      "Optimization Iteration:   2881, Training Accuracy:  71.9%, Loss: 0.4629\n",
      "Optimization Iteration:   2945, Training Accuracy:  65.6%, Loss: 0.5425\n",
      "Optimization Iteration:   3009, Training Accuracy:  70.3%, Loss: 0.4020\n",
      "Optimization Iteration:   3073, Training Accuracy:  81.2%, Loss: 0.3494\n",
      "Optimization Iteration:   3137, Training Accuracy:  76.6%, Loss: 0.4094\n",
      "Optimization Iteration:   3201, Training Accuracy:  73.4%, Loss: 0.4068\n",
      "Optimization Iteration:   3265, Training Accuracy:  73.4%, Loss: 0.4221\n",
      "Optimization Iteration:   3329, Training Accuracy:  81.2%, Loss: 0.3747\n",
      "Optimization Iteration:   3393, Training Accuracy:  78.1%, Loss: 0.4154\n",
      "Optimization Iteration:   3457, Training Accuracy:  76.6%, Loss: 0.5542\n",
      "Optimization Iteration:   3521, Training Accuracy:  76.6%, Loss: 0.4407\n",
      "Optimization Iteration:   3585, Training Accuracy:  65.6%, Loss: 0.6054\n",
      "Optimization Iteration:   3649, Training Accuracy:  79.7%, Loss: 0.3662\n",
      "Optimization Iteration:   3713, Training Accuracy:  78.1%, Loss: 0.3858\n",
      "Optimization Iteration:   3777, Training Accuracy:  60.9%, Loss: 0.5286\n",
      "Optimization Iteration:   3841, Training Accuracy:  78.1%, Loss: 0.4764\n",
      "Optimization Iteration:   3905, Training Accuracy:  64.1%, Loss: 0.5230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   3969, Training Accuracy:  75.0%, Loss: 0.4281\n",
      "Optimization Iteration:   4033, Training Accuracy:  75.0%, Loss: 0.3811\n",
      "Optimization Iteration:   4097, Training Accuracy:  71.9%, Loss: 0.4752\n",
      "Optimization Iteration:   4161, Training Accuracy:  71.9%, Loss: 0.4786\n",
      "Optimization Iteration:   4225, Training Accuracy:  76.6%, Loss: 0.3822\n",
      "Optimization Iteration:   4289, Training Accuracy:  76.6%, Loss: 0.4585\n",
      "Optimization Iteration:   4353, Training Accuracy:  67.2%, Loss: 0.5182\n",
      "Optimization Iteration:   4417, Training Accuracy:  67.2%, Loss: 0.4747\n",
      "Optimization Iteration:   4481, Training Accuracy:  71.9%, Loss: 0.4548\n",
      "Optimization Iteration:   4545, Training Accuracy:  65.6%, Loss: 0.4387\n",
      "Optimization Iteration:   4609, Training Accuracy:  75.0%, Loss: 0.4096\n",
      "Optimization Iteration:   4673, Training Accuracy:  73.4%, Loss: 0.4738\n",
      "Optimization Iteration:   4737, Training Accuracy:  70.3%, Loss: 0.4274\n",
      "Optimization Iteration:   4801, Training Accuracy:  67.2%, Loss: 0.4720\n",
      "Optimization Iteration:   4865, Training Accuracy:  76.6%, Loss: 0.4288\n",
      "Optimization Iteration:   4929, Training Accuracy:  73.4%, Loss: 0.5362\n",
      "Optimization Iteration:   4993, Training Accuracy:  75.0%, Loss: 0.4734\n",
      "Optimization Iteration:   5057, Training Accuracy:  67.2%, Loss: 0.4706\n",
      "Optimization Iteration:   5121, Training Accuracy:  84.4%, Loss: 0.4066\n",
      "Optimization Iteration:   5185, Training Accuracy:  70.3%, Loss: 0.4845\n",
      "Optimization Iteration:   5249, Training Accuracy:  64.1%, Loss: 0.5452\n",
      "Optimization Iteration:   5313, Training Accuracy:  76.6%, Loss: 0.4604\n",
      "Optimization Iteration:   5377, Training Accuracy:  78.1%, Loss: 0.4348\n",
      "Optimization Iteration:   5441, Training Accuracy:  68.8%, Loss: 0.4741\n",
      "Optimization Iteration:   5505, Training Accuracy:  76.6%, Loss: 0.3975\n",
      "Optimization Iteration:   5569, Training Accuracy:  70.3%, Loss: 0.4394\n",
      "Optimization Iteration:   5633, Training Accuracy:  76.6%, Loss: 0.4334\n",
      "Optimization Iteration:   5697, Training Accuracy:  76.6%, Loss: 0.5096\n",
      "Optimization Iteration:   5761, Training Accuracy:  85.9%, Loss: 0.3677\n",
      "Optimization Iteration:   5825, Training Accuracy:  65.6%, Loss: 0.4663\n",
      "Optimization Iteration:   5889, Training Accuracy:  76.6%, Loss: 0.5055\n",
      "Optimization Iteration:   5953, Training Accuracy:  75.0%, Loss: 0.4732\n",
      "Optimization Iteration:   6017, Training Accuracy:  60.9%, Loss: 0.5649\n",
      "Optimization Iteration:   6081, Training Accuracy:  81.2%, Loss: 0.4801\n",
      "Optimization Iteration:   6145, Training Accuracy:  64.1%, Loss: 0.5666\n",
      "Optimization Iteration:   6209, Training Accuracy:  71.9%, Loss: 0.4563\n",
      "Optimization Iteration:   6273, Training Accuracy:  68.8%, Loss: 0.4841\n",
      "Optimization Iteration:   6337, Training Accuracy:  65.6%, Loss: 0.4845\n",
      "Optimization Iteration:   6401, Training Accuracy:  71.9%, Loss: 0.4384\n",
      "Optimization Iteration:   6465, Training Accuracy:  81.2%, Loss: 0.3978\n",
      "Optimization Iteration:   6529, Training Accuracy:  71.9%, Loss: 0.4541\n",
      "Optimization Iteration:   6593, Training Accuracy:  70.3%, Loss: 0.5198\n",
      "Optimization Iteration:   6657, Training Accuracy:  75.0%, Loss: 0.3946\n",
      "Optimization Iteration:   6721, Training Accuracy:  78.1%, Loss: 0.4528\n",
      "Optimization Iteration:   6785, Training Accuracy:  79.7%, Loss: 0.4846\n",
      "Optimization Iteration:   6849, Training Accuracy:  71.9%, Loss: 0.5444\n",
      "Optimization Iteration:   6913, Training Accuracy:  81.2%, Loss: 0.3748\n",
      "Optimization Iteration:   6977, Training Accuracy:  67.2%, Loss: 0.4359\n",
      "Optimization Iteration:   7041, Training Accuracy:  75.0%, Loss: 0.3909\n",
      "Optimization Iteration:   7105, Training Accuracy:  81.2%, Loss: 0.3356\n",
      "Optimization Iteration:   7169, Training Accuracy:  71.9%, Loss: 0.4570\n",
      "Optimization Iteration:   7233, Training Accuracy:  81.2%, Loss: 0.3975\n",
      "Optimization Iteration:   7297, Training Accuracy:  68.8%, Loss: 0.5021\n",
      "Optimization Iteration:   7361, Training Accuracy:  73.4%, Loss: 0.4348\n",
      "Optimization Iteration:   7425, Training Accuracy:  70.3%, Loss: 0.4929\n",
      "Optimization Iteration:   7489, Training Accuracy:  79.7%, Loss: 0.4462\n",
      "Optimization Iteration:   7553, Training Accuracy:  75.0%, Loss: 0.4755\n",
      "Optimization Iteration:   7617, Training Accuracy:  71.9%, Loss: 0.4837\n",
      "Optimization Iteration:   7681, Training Accuracy:  76.6%, Loss: 0.4380\n",
      "Optimization Iteration:   7745, Training Accuracy:  78.1%, Loss: 0.4391\n",
      "Optimization Iteration:   7809, Training Accuracy:  68.8%, Loss: 0.5602\n",
      "Optimization Iteration:   7873, Training Accuracy:  76.6%, Loss: 0.4182\n",
      "Optimization Iteration:   7937, Training Accuracy:  76.6%, Loss: 0.4298\n",
      "Optimization Iteration:   8001, Training Accuracy:  65.6%, Loss: 0.5129\n",
      "Optimization Iteration:   8065, Training Accuracy:  73.4%, Loss: 0.4241\n",
      "Optimization Iteration:   8129, Training Accuracy:  68.8%, Loss: 0.5048\n",
      "Optimization Iteration:   8193, Training Accuracy:  78.1%, Loss: 0.4170\n",
      "Optimization Iteration:   8257, Training Accuracy:  67.2%, Loss: 0.5058\n",
      "Optimization Iteration:   8321, Training Accuracy:  73.4%, Loss: 0.4696\n",
      "Optimization Iteration:   8385, Training Accuracy:  75.0%, Loss: 0.5106\n",
      "Optimization Iteration:   8449, Training Accuracy:  70.3%, Loss: 0.5475\n",
      "Optimization Iteration:   8513, Training Accuracy:  78.1%, Loss: 0.4275\n",
      "Optimization Iteration:   8577, Training Accuracy:  75.0%, Loss: 0.4297\n",
      "Optimization Iteration:   8641, Training Accuracy:  78.1%, Loss: 0.4624\n",
      "Optimization Iteration:   8705, Training Accuracy:  75.0%, Loss: 0.4385\n",
      "Optimization Iteration:   8769, Training Accuracy:  73.4%, Loss: 0.5055\n",
      "Optimization Iteration:   8833, Training Accuracy:  70.3%, Loss: 0.5050\n",
      "Optimization Iteration:   8897, Training Accuracy:  71.9%, Loss: 0.5006\n",
      "Optimization Iteration:   8961, Training Accuracy:  73.4%, Loss: 0.5076\n",
      "Optimization Iteration:   9025, Training Accuracy:  59.4%, Loss: 0.6092\n",
      "Optimization Iteration:   9089, Training Accuracy:  70.3%, Loss: 0.4838\n",
      "Optimization Iteration:   9153, Training Accuracy:  71.9%, Loss: 0.4468\n",
      "Optimization Iteration:   9217, Training Accuracy:  78.1%, Loss: 0.3972\n",
      "Optimization Iteration:   9281, Training Accuracy:  81.2%, Loss: 0.4287\n",
      "Optimization Iteration:   9345, Training Accuracy:  84.4%, Loss: 0.4274\n",
      "Optimization Iteration:   9409, Training Accuracy:  76.6%, Loss: 0.5100\n",
      "Optimization Iteration:   9473, Training Accuracy:  75.0%, Loss: 0.4427\n",
      "Optimization Iteration:   9537, Training Accuracy:  81.2%, Loss: 0.3818\n",
      "Optimization Iteration:   9601, Training Accuracy:  68.8%, Loss: 0.5449\n",
      "Optimization Iteration:   9665, Training Accuracy:  70.3%, Loss: 0.4197\n",
      "Optimization Iteration:   9729, Training Accuracy:  71.9%, Loss: 0.5219\n",
      "Optimization Iteration:   9793, Training Accuracy:  81.2%, Loss: 0.3844\n",
      "Optimization Iteration:   9857, Training Accuracy:  76.6%, Loss: 0.4810\n",
      "Optimization Iteration:   9921, Training Accuracy:  70.3%, Loss: 0.5481\n",
      "Optimization Iteration:   9985, Training Accuracy:  68.8%, Loss: 0.4943\n",
      "Optimization Iteration:  10049, Training Accuracy:  71.9%, Loss: 0.4907\n",
      "Optimization Iteration:  10113, Training Accuracy:  64.1%, Loss: 0.5145\n",
      "Optimization Iteration:  10177, Training Accuracy:  67.2%, Loss: 0.5194\n",
      "Optimization Iteration:  10241, Training Accuracy:  76.6%, Loss: 0.4329\n",
      "Optimization Iteration:  10305, Training Accuracy:  79.7%, Loss: 0.3866\n",
      "Optimization Iteration:  10369, Training Accuracy:  79.7%, Loss: 0.4206\n",
      "Optimization Iteration:  10433, Training Accuracy:  81.2%, Loss: 0.4252\n",
      "Optimization Iteration:  10497, Training Accuracy:  71.9%, Loss: 0.4776\n",
      "Optimization Iteration:  10561, Training Accuracy:  82.8%, Loss: 0.3953\n",
      "Optimization Iteration:  10625, Training Accuracy:  75.0%, Loss: 0.4165\n",
      "Optimization Iteration:  10689, Training Accuracy:  76.6%, Loss: 0.4176\n",
      "Optimization Iteration:  10753, Training Accuracy:  75.0%, Loss: 0.5063\n",
      "Optimization Iteration:  10817, Training Accuracy:  71.9%, Loss: 0.5186\n",
      "Optimization Iteration:  10881, Training Accuracy:  85.9%, Loss: 0.3717\n",
      "Optimization Iteration:  10945, Training Accuracy:  64.1%, Loss: 0.5177\n",
      "Optimization Iteration:  11009, Training Accuracy:  73.4%, Loss: 0.3883\n",
      "Optimization Iteration:  11073, Training Accuracy:  76.6%, Loss: 0.4027\n",
      "Optimization Iteration:  11137, Training Accuracy:  71.9%, Loss: 0.4483\n",
      "Optimization Iteration:  11201, Training Accuracy:  79.7%, Loss: 0.4396\n",
      "Optimization Iteration:  11265, Training Accuracy:  87.5%, Loss: 0.3379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  11329, Training Accuracy:  68.8%, Loss: 0.6171\n",
      "Optimization Iteration:  11393, Training Accuracy:  78.1%, Loss: 0.5086\n",
      "Optimization Iteration:  11457, Training Accuracy:  78.1%, Loss: 0.4017\n",
      "Optimization Iteration:  11521, Training Accuracy:  70.3%, Loss: 0.5234\n",
      "Optimization Iteration:  11585, Training Accuracy:  71.9%, Loss: 0.4244\n",
      "Optimization Iteration:  11649, Training Accuracy:  65.6%, Loss: 0.4325\n",
      "Optimization Iteration:  11713, Training Accuracy:  75.0%, Loss: 0.4293\n",
      "Optimization Iteration:  11777, Training Accuracy:  76.6%, Loss: 0.5149\n",
      "Optimization Iteration:  11841, Training Accuracy:  76.6%, Loss: 0.4876\n",
      "Optimization Iteration:  11905, Training Accuracy:  79.7%, Loss: 0.4581\n",
      "Optimization Iteration:  11969, Training Accuracy:  81.2%, Loss: 0.3964\n",
      "Optimization Iteration:  12033, Training Accuracy:  71.9%, Loss: 0.4918\n",
      "Optimization Iteration:  12097, Training Accuracy:  76.6%, Loss: 0.4222\n",
      "Optimization Iteration:  12161, Training Accuracy:  79.7%, Loss: 0.4035\n",
      "Optimization Iteration:  12225, Training Accuracy:  73.4%, Loss: 0.4376\n",
      "Optimization Iteration:  12289, Training Accuracy:  73.4%, Loss: 0.4514\n",
      "Optimization Iteration:  12353, Training Accuracy:  70.3%, Loss: 0.4732\n",
      "Optimization Iteration:  12417, Training Accuracy:  71.9%, Loss: 0.4277\n",
      "Optimization Iteration:  12481, Training Accuracy:  73.4%, Loss: 0.5688\n",
      "Optimization Iteration:  12545, Training Accuracy:  60.9%, Loss: 0.5296\n",
      "Optimization Iteration:  12609, Training Accuracy:  68.8%, Loss: 0.5016\n",
      "Optimization Iteration:  12673, Training Accuracy:  78.1%, Loss: 0.4473\n",
      "Optimization Iteration:  12737, Training Accuracy:  68.8%, Loss: 0.6493\n",
      "Optimization Iteration:  12801, Training Accuracy:  76.6%, Loss: 0.4115\n",
      "Optimization Iteration:  12865, Training Accuracy:  68.8%, Loss: 0.4474\n",
      "Optimization Iteration:  12929, Training Accuracy:  75.0%, Loss: 0.5134\n",
      "Optimization Iteration:  12993, Training Accuracy:  78.1%, Loss: 0.4126\n",
      "Optimization Iteration:  13057, Training Accuracy:  71.9%, Loss: 0.5106\n",
      "Optimization Iteration:  13121, Training Accuracy:  71.9%, Loss: 0.4800\n",
      "Optimization Iteration:  13185, Training Accuracy:  64.1%, Loss: 0.5081\n",
      "Optimization Iteration:  13249, Training Accuracy:  70.3%, Loss: 0.4927\n",
      "Optimization Iteration:  13313, Training Accuracy:  76.6%, Loss: 0.4714\n",
      "Optimization Iteration:  13377, Training Accuracy:  68.8%, Loss: 0.4888\n",
      "Optimization Iteration:  13441, Training Accuracy:  75.0%, Loss: 0.4257\n",
      "Optimization Iteration:  13505, Training Accuracy:  70.3%, Loss: 0.4642\n",
      "Optimization Iteration:  13569, Training Accuracy:  85.9%, Loss: 0.4355\n",
      "Optimization Iteration:  13633, Training Accuracy:  75.0%, Loss: 0.3829\n",
      "Optimization Iteration:  13697, Training Accuracy:  70.3%, Loss: 0.4708\n",
      "Optimization Iteration:  13761, Training Accuracy:  84.4%, Loss: 0.3534\n",
      "Optimization Iteration:  13825, Training Accuracy:  73.4%, Loss: 0.4980\n",
      "Optimization Iteration:  13889, Training Accuracy:  67.2%, Loss: 0.6597\n",
      "Optimization Iteration:  13953, Training Accuracy:  71.9%, Loss: 0.4128\n",
      "Optimization Iteration:  14017, Training Accuracy:  71.9%, Loss: 0.4684\n",
      "Optimization Iteration:  14081, Training Accuracy:  73.4%, Loss: 0.4345\n",
      "Optimization Iteration:  14145, Training Accuracy:  81.2%, Loss: 0.3925\n",
      "Optimization Iteration:  14209, Training Accuracy:  70.3%, Loss: 0.4765\n",
      "Optimization Iteration:  14273, Training Accuracy:  76.6%, Loss: 0.4752\n",
      "Optimization Iteration:  14337, Training Accuracy:  82.8%, Loss: 0.3418\n",
      "Optimization Iteration:  14401, Training Accuracy:  82.8%, Loss: 0.4086\n",
      "Optimization Iteration:  14465, Training Accuracy:  68.8%, Loss: 0.5079\n",
      "Optimization Iteration:  14529, Training Accuracy:  67.2%, Loss: 0.4578\n",
      "Optimization Iteration:  14593, Training Accuracy:  79.7%, Loss: 0.3814\n",
      "Optimization Iteration:  14657, Training Accuracy:  62.5%, Loss: 0.5748\n",
      "Optimization Iteration:  14721, Training Accuracy:  68.8%, Loss: 0.4614\n",
      "Optimization Iteration:  14785, Training Accuracy:  68.8%, Loss: 0.5095\n",
      "Optimization Iteration:  14849, Training Accuracy:  65.6%, Loss: 0.4634\n",
      "Optimization Iteration:  14913, Training Accuracy:  76.6%, Loss: 0.3939\n",
      "Optimization Iteration:  14977, Training Accuracy:  78.1%, Loss: 0.4911\n",
      "Optimization Iteration:  15041, Training Accuracy:  67.2%, Loss: 0.5317\n",
      "Optimization Iteration:  15105, Training Accuracy:  70.3%, Loss: 0.4473\n",
      "Optimization Iteration:  15169, Training Accuracy:  70.3%, Loss: 0.4675\n",
      "Optimization Iteration:  15233, Training Accuracy:  71.9%, Loss: 0.4769\n",
      "Optimization Iteration:  15297, Training Accuracy:  64.1%, Loss: 0.5153\n",
      "Optimization Iteration:  15361, Training Accuracy:  85.9%, Loss: 0.4330\n",
      "Optimization Iteration:  15425, Training Accuracy:  73.4%, Loss: 0.4698\n",
      "Optimization Iteration:  15489, Training Accuracy:  62.5%, Loss: 0.5197\n",
      "Optimization Iteration:  15553, Training Accuracy:  84.4%, Loss: 0.3288\n",
      "Optimization Iteration:  15617, Training Accuracy:  71.9%, Loss: 0.4807\n",
      "Optimization Iteration:  15681, Training Accuracy:  79.7%, Loss: 0.4841\n",
      "Optimization Iteration:  15745, Training Accuracy:  81.2%, Loss: 0.4056\n",
      "Optimization Iteration:  15809, Training Accuracy:  71.9%, Loss: 0.5112\n",
      "Optimization Iteration:  15873, Training Accuracy:  76.6%, Loss: 0.3978\n",
      "Optimization Iteration:  15937, Training Accuracy:  79.7%, Loss: 0.4343\n",
      "Optimization Iteration:  16001, Training Accuracy:  79.7%, Loss: 0.4181\n",
      "Optimization Iteration:  16065, Training Accuracy:  70.3%, Loss: 0.4463\n",
      "Optimization Iteration:  16129, Training Accuracy:  73.4%, Loss: 0.5105\n",
      "Optimization Iteration:  16193, Training Accuracy:  67.2%, Loss: 0.4807\n",
      "Optimization Iteration:  16257, Training Accuracy:  81.2%, Loss: 0.3719\n",
      "Optimization Iteration:  16321, Training Accuracy:  65.6%, Loss: 0.4906\n",
      "Optimization Iteration:  16385, Training Accuracy:  64.1%, Loss: 0.5801\n",
      "Optimization Iteration:  16449, Training Accuracy:  81.2%, Loss: 0.4263\n",
      "Optimization Iteration:  16513, Training Accuracy:  75.0%, Loss: 0.5152\n",
      "Optimization Iteration:  16577, Training Accuracy:  75.0%, Loss: 0.4828\n",
      "Optimization Iteration:  16641, Training Accuracy:  64.1%, Loss: 0.5420\n",
      "Optimization Iteration:  16705, Training Accuracy:  78.1%, Loss: 0.4500\n",
      "Optimization Iteration:  16769, Training Accuracy:  75.0%, Loss: 0.4073\n",
      "Optimization Iteration:  16833, Training Accuracy:  60.9%, Loss: 0.4696\n",
      "Optimization Iteration:  16897, Training Accuracy:  75.0%, Loss: 0.4416\n",
      "Optimization Iteration:  16961, Training Accuracy:  70.3%, Loss: 0.4354\n",
      "Optimization Iteration:  17025, Training Accuracy:  60.9%, Loss: 0.5067\n",
      "Optimization Iteration:  17089, Training Accuracy:  78.1%, Loss: 0.5119\n",
      "Optimization Iteration:  17153, Training Accuracy:  68.8%, Loss: 0.5006\n",
      "Optimization Iteration:  17217, Training Accuracy:  67.2%, Loss: 0.5070\n",
      "Optimization Iteration:  17281, Training Accuracy:  67.2%, Loss: 0.4488\n",
      "Optimization Iteration:  17345, Training Accuracy:  75.0%, Loss: 0.4421\n",
      "Optimization Iteration:  17409, Training Accuracy:  68.8%, Loss: 0.4282\n",
      "Optimization Iteration:  17473, Training Accuracy:  82.8%, Loss: 0.4662\n",
      "Optimization Iteration:  17537, Training Accuracy:  71.9%, Loss: 0.4767\n",
      "Optimization Iteration:  17601, Training Accuracy:  71.9%, Loss: 0.4736\n",
      "Optimization Iteration:  17665, Training Accuracy:  71.9%, Loss: 0.4544\n",
      "Optimization Iteration:  17729, Training Accuracy:  75.0%, Loss: 0.4109\n",
      "Optimization Iteration:  17793, Training Accuracy:  71.9%, Loss: 0.4622\n",
      "Optimization Iteration:  17857, Training Accuracy:  70.3%, Loss: 0.4950\n",
      "Optimization Iteration:  17921, Training Accuracy:  71.9%, Loss: 0.4588\n",
      "Optimization Iteration:  17985, Training Accuracy:  78.1%, Loss: 0.3907\n",
      "Optimization Iteration:  18049, Training Accuracy:  76.6%, Loss: 0.4346\n",
      "Optimization Iteration:  18113, Training Accuracy:  81.2%, Loss: 0.5047\n",
      "Optimization Iteration:  18177, Training Accuracy:  67.2%, Loss: 0.5799\n",
      "Optimization Iteration:  18241, Training Accuracy:  82.8%, Loss: 0.4630\n",
      "Optimization Iteration:  18305, Training Accuracy:  65.6%, Loss: 0.4734\n",
      "Optimization Iteration:  18369, Training Accuracy:  81.2%, Loss: 0.3552\n",
      "Optimization Iteration:  18433, Training Accuracy:  75.0%, Loss: 0.5040\n",
      "Optimization Iteration:  18497, Training Accuracy:  79.7%, Loss: 0.3916\n",
      "Optimization Iteration:  18561, Training Accuracy:  76.6%, Loss: 0.4399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  18625, Training Accuracy:  57.8%, Loss: 0.5484\n",
      "Optimization Iteration:  18689, Training Accuracy:  75.0%, Loss: 0.4185\n",
      "Optimization Iteration:  18753, Training Accuracy:  73.4%, Loss: 0.4493\n",
      "Optimization Iteration:  18817, Training Accuracy:  76.6%, Loss: 0.4788\n",
      "Optimization Iteration:  18881, Training Accuracy:  84.4%, Loss: 0.3446\n",
      "Optimization Iteration:  18945, Training Accuracy:  75.0%, Loss: 0.4313\n",
      "Optimization Iteration:  19009, Training Accuracy:  79.7%, Loss: 0.4032\n",
      "Optimization Iteration:  19073, Training Accuracy:  71.9%, Loss: 0.5901\n",
      "Optimization Iteration:  19137, Training Accuracy:  71.9%, Loss: 0.4796\n",
      "Optimization Iteration:  19201, Training Accuracy:  70.3%, Loss: 0.4726\n",
      "Optimization Iteration:  19265, Training Accuracy:  70.3%, Loss: 0.4686\n",
      "Optimization Iteration:  19329, Training Accuracy:  76.6%, Loss: 0.4111\n",
      "Optimization Iteration:  19393, Training Accuracy:  62.5%, Loss: 0.5869\n",
      "Optimization Iteration:  19457, Training Accuracy:  70.3%, Loss: 0.4222\n",
      "Optimization Iteration:  19521, Training Accuracy:  65.6%, Loss: 0.4868\n",
      "Optimization Iteration:  19585, Training Accuracy:  71.9%, Loss: 0.4722\n",
      "Optimization Iteration:  19649, Training Accuracy:  71.9%, Loss: 0.5187\n",
      "Optimization Iteration:  19713, Training Accuracy:  78.1%, Loss: 0.4489\n",
      "Optimization Iteration:  19777, Training Accuracy:  75.0%, Loss: 0.4901\n",
      "Optimization Iteration:  19841, Training Accuracy:  78.1%, Loss: 0.4346\n",
      "Optimization Iteration:  19905, Training Accuracy:  79.7%, Loss: 0.3899\n",
      "Optimization Iteration:  19969, Training Accuracy:  78.1%, Loss: 0.3665\n",
      "Optimization Iteration:  20033, Training Accuracy:  68.8%, Loss: 0.4987\n",
      "Optimization Iteration:  20097, Training Accuracy:  73.4%, Loss: 0.4408\n",
      "Optimization Iteration:  20161, Training Accuracy:  68.8%, Loss: 0.4882\n",
      "Optimization Iteration:  20225, Training Accuracy:  70.3%, Loss: 0.5069\n",
      "Optimization Iteration:  20289, Training Accuracy:  75.0%, Loss: 0.4768\n",
      "Optimization Iteration:  20353, Training Accuracy:  67.2%, Loss: 0.4612\n",
      "Optimization Iteration:  20417, Training Accuracy:  76.6%, Loss: 0.4039\n",
      "Optimization Iteration:  20481, Training Accuracy:  75.0%, Loss: 0.4033\n",
      "Optimization Iteration:  20545, Training Accuracy:  70.3%, Loss: 0.4800\n",
      "Optimization Iteration:  20609, Training Accuracy:  68.8%, Loss: 0.5734\n",
      "Optimization Iteration:  20673, Training Accuracy:  67.2%, Loss: 0.5094\n",
      "Optimization Iteration:  20737, Training Accuracy:  73.4%, Loss: 0.5012\n",
      "Optimization Iteration:  20801, Training Accuracy:  81.2%, Loss: 0.3869\n",
      "Optimization Iteration:  20865, Training Accuracy:  78.1%, Loss: 0.4427\n",
      "Optimization Iteration:  20929, Training Accuracy:  76.6%, Loss: 0.4075\n",
      "Optimization Iteration:  20993, Training Accuracy:  79.7%, Loss: 0.4275\n",
      "Optimization Iteration:  21057, Training Accuracy:  75.0%, Loss: 0.4827\n",
      "Optimization Iteration:  21121, Training Accuracy:  75.0%, Loss: 0.5570\n",
      "Optimization Iteration:  21185, Training Accuracy:  76.6%, Loss: 0.4217\n",
      "Optimization Iteration:  21249, Training Accuracy:  70.3%, Loss: 0.5644\n",
      "Optimization Iteration:  21313, Training Accuracy:  70.3%, Loss: 0.5308\n",
      "Optimization Iteration:  21377, Training Accuracy:  76.6%, Loss: 0.4231\n",
      "Optimization Iteration:  21441, Training Accuracy:  73.4%, Loss: 0.4287\n",
      "Optimization Iteration:  21505, Training Accuracy:  71.9%, Loss: 0.4888\n",
      "Optimization Iteration:  21569, Training Accuracy:  76.6%, Loss: 0.4013\n",
      "Optimization Iteration:  21633, Training Accuracy:  82.8%, Loss: 0.4164\n",
      "Optimization Iteration:  21697, Training Accuracy:  76.6%, Loss: 0.4651\n",
      "Optimization Iteration:  21761, Training Accuracy:  71.9%, Loss: 0.4371\n",
      "Optimization Iteration:  21825, Training Accuracy:  71.9%, Loss: 0.5597\n",
      "Optimization Iteration:  21889, Training Accuracy:  68.8%, Loss: 0.4513\n",
      "Optimization Iteration:  21953, Training Accuracy:  71.9%, Loss: 0.5137\n",
      "Optimization Iteration:  22017, Training Accuracy:  81.2%, Loss: 0.4264\n",
      "Optimization Iteration:  22081, Training Accuracy:  76.6%, Loss: 0.4348\n",
      "Optimization Iteration:  22145, Training Accuracy:  78.1%, Loss: 0.4534\n",
      "Optimization Iteration:  22209, Training Accuracy:  71.9%, Loss: 0.5523\n",
      "Optimization Iteration:  22273, Training Accuracy:  75.0%, Loss: 0.4358\n",
      "Optimization Iteration:  22337, Training Accuracy:  75.0%, Loss: 0.4593\n",
      "Optimization Iteration:  22401, Training Accuracy:  62.5%, Loss: 0.4954\n",
      "Optimization Iteration:  22465, Training Accuracy:  65.6%, Loss: 0.5007\n",
      "Optimization Iteration:  22529, Training Accuracy:  67.2%, Loss: 0.5313\n",
      "Optimization Iteration:  22593, Training Accuracy:  64.1%, Loss: 0.4748\n",
      "Optimization Iteration:  22657, Training Accuracy:  70.3%, Loss: 0.4592\n",
      "Optimization Iteration:  22721, Training Accuracy:  75.0%, Loss: 0.4081\n",
      "Optimization Iteration:  22785, Training Accuracy:  75.0%, Loss: 0.4847\n",
      "Optimization Iteration:  22849, Training Accuracy:  71.9%, Loss: 0.4032\n",
      "Optimization Iteration:  22913, Training Accuracy:  65.6%, Loss: 0.4893\n",
      "Optimization Iteration:  22977, Training Accuracy:  70.3%, Loss: 0.4618\n",
      "Optimization Iteration:  23041, Training Accuracy:  75.0%, Loss: 0.4065\n",
      "Optimization Iteration:  23105, Training Accuracy:  59.4%, Loss: 0.4918\n",
      "Optimization Iteration:  23169, Training Accuracy:  84.4%, Loss: 0.4218\n",
      "Optimization Iteration:  23233, Training Accuracy:  65.6%, Loss: 0.5443\n",
      "Optimization Iteration:  23297, Training Accuracy:  67.2%, Loss: 0.4819\n",
      "Optimization Iteration:  23361, Training Accuracy:  73.4%, Loss: 0.4457\n",
      "Optimization Iteration:  23425, Training Accuracy:  79.7%, Loss: 0.3937\n",
      "Optimization Iteration:  23489, Training Accuracy:  71.9%, Loss: 0.4917\n",
      "Optimization Iteration:  23553, Training Accuracy:  79.7%, Loss: 0.4333\n",
      "Optimization Iteration:  23617, Training Accuracy:  68.8%, Loss: 0.5106\n",
      "Optimization Iteration:  23681, Training Accuracy:  62.5%, Loss: 0.5561\n",
      "Optimization Iteration:  23745, Training Accuracy:  67.2%, Loss: 0.4498\n",
      "Optimization Iteration:  23809, Training Accuracy:  75.0%, Loss: 0.4611\n",
      "Optimization Iteration:  23873, Training Accuracy:  70.3%, Loss: 0.3925\n",
      "Optimization Iteration:  23937, Training Accuracy:  64.1%, Loss: 0.5920\n",
      "Optimization Iteration:  24001, Training Accuracy:  81.2%, Loss: 0.3335\n",
      "Optimization Iteration:  24065, Training Accuracy:  75.0%, Loss: 0.4504\n",
      "Optimization Iteration:  24129, Training Accuracy:  64.1%, Loss: 0.5028\n",
      "Optimization Iteration:  24193, Training Accuracy:  75.0%, Loss: 0.4366\n",
      "Optimization Iteration:  24257, Training Accuracy:  70.3%, Loss: 0.4291\n",
      "Optimization Iteration:  24321, Training Accuracy:  73.4%, Loss: 0.5303\n",
      "Optimization Iteration:  24385, Training Accuracy:  67.2%, Loss: 0.5642\n",
      "Optimization Iteration:  24449, Training Accuracy:  70.3%, Loss: 0.4940\n",
      "Optimization Iteration:  24513, Training Accuracy:  78.1%, Loss: 0.3566\n",
      "Optimization Iteration:  24577, Training Accuracy:  67.2%, Loss: 0.5195\n",
      "Optimization Iteration:  24641, Training Accuracy:  70.3%, Loss: 0.5218\n",
      "Optimization Iteration:  24705, Training Accuracy:  68.8%, Loss: 0.4642\n",
      "Optimization Iteration:  24769, Training Accuracy:  76.6%, Loss: 0.4721\n",
      "Optimization Iteration:  24833, Training Accuracy:  73.4%, Loss: 0.4064\n",
      "Optimization Iteration:  24897, Training Accuracy:  62.5%, Loss: 0.5207\n",
      "Optimization Iteration:  24961, Training Accuracy:  76.6%, Loss: 0.3729\n",
      "Optimization Iteration:  25025, Training Accuracy:  71.9%, Loss: 0.4490\n",
      "Optimization Iteration:  25089, Training Accuracy:  68.8%, Loss: 0.4770\n",
      "Optimization Iteration:  25153, Training Accuracy:  60.9%, Loss: 0.5212\n",
      "Optimization Iteration:  25217, Training Accuracy:  76.6%, Loss: 0.4355\n",
      "Optimization Iteration:  25281, Training Accuracy:  65.6%, Loss: 0.4954\n",
      "Optimization Iteration:  25345, Training Accuracy:  71.9%, Loss: 0.5675\n",
      "Optimization Iteration:  25409, Training Accuracy:  65.6%, Loss: 0.4962\n",
      "Optimization Iteration:  25473, Training Accuracy:  65.6%, Loss: 0.5346\n",
      "Optimization Iteration:  25537, Training Accuracy:  71.9%, Loss: 0.4080\n",
      "Optimization Iteration:  25601, Training Accuracy:  81.2%, Loss: 0.4872\n",
      "Optimization Iteration:  25665, Training Accuracy:  60.9%, Loss: 0.5579\n",
      "Optimization Iteration:  25729, Training Accuracy:  73.4%, Loss: 0.3852\n",
      "Optimization Iteration:  25793, Training Accuracy:  73.4%, Loss: 0.4360\n",
      "Optimization Iteration:  25857, Training Accuracy:  70.3%, Loss: 0.4922\n",
      "Optimization Iteration:  25921, Training Accuracy:  71.9%, Loss: 0.4549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  25985, Training Accuracy:  68.8%, Loss: 0.6985\n",
      "Optimization Iteration:  26049, Training Accuracy:  70.3%, Loss: 0.4483\n",
      "Optimization Iteration:  26113, Training Accuracy:  71.9%, Loss: 0.4121\n",
      "Optimization Iteration:  26177, Training Accuracy:  65.6%, Loss: 0.4271\n",
      "Optimization Iteration:  26241, Training Accuracy:  84.4%, Loss: 0.3749\n",
      "Optimization Iteration:  26305, Training Accuracy:  73.4%, Loss: 0.5066\n",
      "Optimization Iteration:  26369, Training Accuracy:  78.1%, Loss: 0.4426\n",
      "Optimization Iteration:  26433, Training Accuracy:  70.3%, Loss: 0.4407\n",
      "Optimization Iteration:  26497, Training Accuracy:  81.2%, Loss: 0.4181\n",
      "Optimization Iteration:  26561, Training Accuracy:  76.6%, Loss: 0.4068\n",
      "Optimization Iteration:  26625, Training Accuracy:  75.0%, Loss: 0.4589\n",
      "Optimization Iteration:  26689, Training Accuracy:  71.9%, Loss: 0.4549\n",
      "Optimization Iteration:  26753, Training Accuracy:  59.4%, Loss: 0.5086\n",
      "Optimization Iteration:  26817, Training Accuracy:  68.8%, Loss: 0.4945\n",
      "Optimization Iteration:  26881, Training Accuracy:  84.4%, Loss: 0.3255\n",
      "Optimization Iteration:  26945, Training Accuracy:  78.1%, Loss: 0.4265\n",
      "Optimization Iteration:  27009, Training Accuracy:  70.3%, Loss: 0.4976\n",
      "Optimization Iteration:  27073, Training Accuracy:  71.9%, Loss: 0.5594\n",
      "Optimization Iteration:  27137, Training Accuracy:  67.2%, Loss: 0.5991\n",
      "Optimization Iteration:  27201, Training Accuracy:  84.4%, Loss: 0.3228\n",
      "Optimization Iteration:  27265, Training Accuracy:  76.6%, Loss: 0.4748\n",
      "Optimization Iteration:  27329, Training Accuracy:  76.6%, Loss: 0.4026\n",
      "Optimization Iteration:  27393, Training Accuracy:  68.8%, Loss: 0.4700\n",
      "Optimization Iteration:  27457, Training Accuracy:  70.3%, Loss: 0.5095\n",
      "Optimization Iteration:  27521, Training Accuracy:  75.0%, Loss: 0.5073\n",
      "Optimization Iteration:  27585, Training Accuracy:  78.1%, Loss: 0.4216\n",
      "Optimization Iteration:  27649, Training Accuracy:  75.0%, Loss: 0.4198\n",
      "Optimization Iteration:  27713, Training Accuracy:  73.4%, Loss: 0.4967\n",
      "Optimization Iteration:  27777, Training Accuracy:  67.2%, Loss: 0.4959\n",
      "Optimization Iteration:  27841, Training Accuracy:  64.1%, Loss: 0.4990\n",
      "Optimization Iteration:  27905, Training Accuracy:  70.3%, Loss: 0.4068\n",
      "Optimization Iteration:  27969, Training Accuracy:  79.7%, Loss: 0.4125\n",
      "Optimization Iteration:  28033, Training Accuracy:  78.1%, Loss: 0.3899\n",
      "Optimization Iteration:  28097, Training Accuracy:  78.1%, Loss: 0.4256\n",
      "Optimization Iteration:  28161, Training Accuracy:  81.2%, Loss: 0.3653\n",
      "Optimization Iteration:  28225, Training Accuracy:  75.0%, Loss: 0.3684\n",
      "Optimization Iteration:  28289, Training Accuracy:  71.9%, Loss: 0.5863\n",
      "Optimization Iteration:  28353, Training Accuracy:  79.7%, Loss: 0.4145\n",
      "Optimization Iteration:  28417, Training Accuracy:  67.2%, Loss: 0.4236\n",
      "Optimization Iteration:  28481, Training Accuracy:  73.4%, Loss: 0.4494\n",
      "Optimization Iteration:  28545, Training Accuracy:  82.8%, Loss: 0.3359\n",
      "Optimization Iteration:  28609, Training Accuracy:  73.4%, Loss: 0.4660\n",
      "Optimization Iteration:  28673, Training Accuracy:  70.3%, Loss: 0.5321\n",
      "Optimization Iteration:  28737, Training Accuracy:  73.4%, Loss: 0.4442\n",
      "Optimization Iteration:  28801, Training Accuracy:  76.6%, Loss: 0.3846\n",
      "Optimization Iteration:  28865, Training Accuracy:  79.7%, Loss: 0.3587\n",
      "Optimization Iteration:  28929, Training Accuracy:  76.6%, Loss: 0.3931\n",
      "Optimization Iteration:  28993, Training Accuracy:  79.7%, Loss: 0.4194\n",
      "Optimization Iteration:  29057, Training Accuracy:  70.3%, Loss: 0.4420\n",
      "Optimization Iteration:  29121, Training Accuracy:  70.3%, Loss: 0.5220\n",
      "Optimization Iteration:  29185, Training Accuracy:  70.3%, Loss: 0.3866\n",
      "Optimization Iteration:  29249, Training Accuracy:  73.4%, Loss: 0.4323\n",
      "Optimization Iteration:  29313, Training Accuracy:  65.6%, Loss: 0.5120\n",
      "Optimization Iteration:  29377, Training Accuracy:  71.9%, Loss: 0.3853\n",
      "Optimization Iteration:  29441, Training Accuracy:  73.4%, Loss: 0.6030\n",
      "Optimization Iteration:  29505, Training Accuracy:  76.6%, Loss: 0.3824\n",
      "Optimization Iteration:  29569, Training Accuracy:  70.3%, Loss: 0.4356\n",
      "Optimization Iteration:  29633, Training Accuracy:  67.2%, Loss: 0.5472\n",
      "Optimization Iteration:  29697, Training Accuracy:  68.8%, Loss: 0.4332\n",
      "Optimization Iteration:  29761, Training Accuracy:  76.6%, Loss: 0.4672\n",
      "Optimization Iteration:  29825, Training Accuracy:  76.6%, Loss: 0.4076\n",
      "Optimization Iteration:  29889, Training Accuracy:  73.4%, Loss: 0.4895\n",
      "Optimization Iteration:  29953, Training Accuracy:  60.9%, Loss: 0.6466\n",
      "Optimization Iteration:  30017, Training Accuracy:  82.8%, Loss: 0.2987\n",
      "Optimization Iteration:  30081, Training Accuracy:  79.7%, Loss: 0.3701\n",
      "Optimization Iteration:  30145, Training Accuracy:  73.4%, Loss: 0.4440\n",
      "Optimization Iteration:  30209, Training Accuracy:  76.6%, Loss: 0.4124\n",
      "Optimization Iteration:  30273, Training Accuracy:  76.6%, Loss: 0.3972\n",
      "Optimization Iteration:  30337, Training Accuracy:  70.3%, Loss: 0.4227\n",
      "Optimization Iteration:  30401, Training Accuracy:  84.4%, Loss: 0.4456\n",
      "Optimization Iteration:  30465, Training Accuracy:  70.3%, Loss: 0.5451\n",
      "Optimization Iteration:  30529, Training Accuracy:  76.6%, Loss: 0.4070\n",
      "Optimization Iteration:  30593, Training Accuracy:  70.3%, Loss: 0.4495\n",
      "Optimization Iteration:  30657, Training Accuracy:  78.1%, Loss: 0.3980\n",
      "Optimization Iteration:  30721, Training Accuracy:  78.1%, Loss: 0.4130\n",
      "Optimization Iteration:  30785, Training Accuracy:  68.8%, Loss: 0.4208\n",
      "Optimization Iteration:  30849, Training Accuracy:  75.0%, Loss: 0.4402\n",
      "Optimization Iteration:  30913, Training Accuracy:  79.7%, Loss: 0.3998\n",
      "Optimization Iteration:  30977, Training Accuracy:  76.6%, Loss: 0.5098\n",
      "Optimization Iteration:  31041, Training Accuracy:  73.4%, Loss: 0.4133\n",
      "Optimization Iteration:  31105, Training Accuracy:  71.9%, Loss: 0.4373\n",
      "Optimization Iteration:  31169, Training Accuracy:  71.9%, Loss: 0.4377\n",
      "Optimization Iteration:  31233, Training Accuracy:  79.7%, Loss: 0.4386\n",
      "Optimization Iteration:  31297, Training Accuracy:  70.3%, Loss: 0.5630\n",
      "Optimization Iteration:  31361, Training Accuracy:  71.9%, Loss: 0.5032\n",
      "Optimization Iteration:  31425, Training Accuracy:  82.8%, Loss: 0.3678\n",
      "Optimization Iteration:  31489, Training Accuracy:  73.4%, Loss: 0.4507\n",
      "Optimization Iteration:  31553, Training Accuracy:  70.3%, Loss: 0.4516\n",
      "Optimization Iteration:  31617, Training Accuracy:  76.6%, Loss: 0.4088\n",
      "Optimization Iteration:  31681, Training Accuracy:  73.4%, Loss: 0.4648\n",
      "Optimization Iteration:  31745, Training Accuracy:  75.0%, Loss: 0.4246\n",
      "Optimization Iteration:  31809, Training Accuracy:  78.1%, Loss: 0.4691\n",
      "Optimization Iteration:  31873, Training Accuracy:  75.0%, Loss: 0.4082\n",
      "Optimization Iteration:  31937, Training Accuracy:  67.2%, Loss: 0.4919\n",
      "Optimization Iteration:  32001, Training Accuracy:  68.8%, Loss: 0.5270\n",
      "Optimization Iteration:  32065, Training Accuracy:  70.3%, Loss: 0.4684\n",
      "Optimization Iteration:  32129, Training Accuracy:  68.8%, Loss: 0.4845\n",
      "Optimization Iteration:  32193, Training Accuracy:  76.6%, Loss: 0.4762\n",
      "Optimization Iteration:  32257, Training Accuracy:  67.2%, Loss: 0.5070\n",
      "Optimization Iteration:  32321, Training Accuracy:  65.6%, Loss: 0.4148\n",
      "Optimization Iteration:  32385, Training Accuracy:  78.1%, Loss: 0.4535\n",
      "Optimization Iteration:  32449, Training Accuracy:  65.6%, Loss: 0.4768\n",
      "Optimization Iteration:  32513, Training Accuracy:  76.6%, Loss: 0.4450\n",
      "Optimization Iteration:  32577, Training Accuracy:  78.1%, Loss: 0.4470\n",
      "Optimization Iteration:  32641, Training Accuracy:  73.4%, Loss: 0.5021\n",
      "Optimization Iteration:  32705, Training Accuracy:  85.9%, Loss: 0.3504\n",
      "Optimization Iteration:  32769, Training Accuracy:  71.9%, Loss: 0.4312\n",
      "Optimization Iteration:  32833, Training Accuracy:  73.4%, Loss: 0.4366\n",
      "Optimization Iteration:  32897, Training Accuracy:  76.6%, Loss: 0.5162\n",
      "Optimization Iteration:  32961, Training Accuracy:  65.6%, Loss: 0.5205\n",
      "Optimization Iteration:  33025, Training Accuracy:  70.3%, Loss: 0.4376\n",
      "Optimization Iteration:  33089, Training Accuracy:  71.9%, Loss: 0.5329\n",
      "Optimization Iteration:  33153, Training Accuracy:  71.9%, Loss: 0.5633\n",
      "Optimization Iteration:  33217, Training Accuracy:  67.2%, Loss: 0.4350\n",
      "Optimization Iteration:  33281, Training Accuracy:  59.4%, Loss: 0.5868\n",
      "Optimization Iteration:  33345, Training Accuracy:  68.8%, Loss: 0.4637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  33409, Training Accuracy:  73.4%, Loss: 0.4657\n",
      "Optimization Iteration:  33473, Training Accuracy:  71.9%, Loss: 0.5023\n",
      "Optimization Iteration:  33537, Training Accuracy:  67.2%, Loss: 0.4781\n",
      "Optimization Iteration:  33601, Training Accuracy:  70.3%, Loss: 0.5221\n",
      "Optimization Iteration:  33665, Training Accuracy:  71.9%, Loss: 0.3906\n",
      "Optimization Iteration:  33729, Training Accuracy:  71.9%, Loss: 0.6922\n",
      "Optimization Iteration:  33793, Training Accuracy:  67.2%, Loss: 0.5668\n",
      "Optimization Iteration:  33857, Training Accuracy:  64.1%, Loss: 0.4684\n",
      "Optimization Iteration:  33921, Training Accuracy:  73.4%, Loss: 0.4806\n",
      "Optimization Iteration:  33985, Training Accuracy:  70.3%, Loss: 0.4740\n",
      "Optimization Iteration:  34049, Training Accuracy:  70.3%, Loss: 0.4558\n",
      "Optimization Iteration:  34113, Training Accuracy:  71.9%, Loss: 0.4667\n",
      "Optimization Iteration:  34177, Training Accuracy:  71.9%, Loss: 0.4073\n",
      "Optimization Iteration:  34241, Training Accuracy:  79.7%, Loss: 0.4495\n",
      "Optimization Iteration:  34305, Training Accuracy:  65.6%, Loss: 0.5260\n",
      "Optimization Iteration:  34369, Training Accuracy:  89.1%, Loss: 0.2779\n",
      "Optimization Iteration:  34433, Training Accuracy:  73.4%, Loss: 0.4695\n",
      "Optimization Iteration:  34497, Training Accuracy:  84.4%, Loss: 0.3739\n",
      "Optimization Iteration:  34561, Training Accuracy:  73.4%, Loss: 0.4435\n",
      "Optimization Iteration:  34625, Training Accuracy:  73.4%, Loss: 0.5753\n",
      "Optimization Iteration:  34689, Training Accuracy:  73.4%, Loss: 0.4654\n",
      "Optimization Iteration:  34753, Training Accuracy:  60.9%, Loss: 0.4783\n",
      "Optimization Iteration:  34817, Training Accuracy:  82.8%, Loss: 0.4532\n",
      "Optimization Iteration:  34881, Training Accuracy:  68.8%, Loss: 0.4783\n",
      "Optimization Iteration:  34945, Training Accuracy:  76.6%, Loss: 0.4249\n",
      "Optimization Iteration:  35009, Training Accuracy:  79.7%, Loss: 0.3884\n",
      "Optimization Iteration:  35073, Training Accuracy:  75.0%, Loss: 0.4044\n",
      "Optimization Iteration:  35137, Training Accuracy:  75.0%, Loss: 0.4641\n",
      "Optimization Iteration:  35201, Training Accuracy:  70.3%, Loss: 0.3973\n",
      "Optimization Iteration:  35265, Training Accuracy:  76.6%, Loss: 0.4360\n",
      "Optimization Iteration:  35329, Training Accuracy:  65.6%, Loss: 0.4808\n",
      "Optimization Iteration:  35393, Training Accuracy:  78.1%, Loss: 0.3918\n",
      "Optimization Iteration:  35457, Training Accuracy:  70.3%, Loss: 0.4552\n",
      "Optimization Iteration:  35521, Training Accuracy:  68.8%, Loss: 0.4445\n",
      "Optimization Iteration:  35585, Training Accuracy:  78.1%, Loss: 0.3738\n",
      "Optimization Iteration:  35649, Training Accuracy:  65.6%, Loss: 0.5381\n",
      "Optimization Iteration:  35713, Training Accuracy:  84.4%, Loss: 0.3976\n",
      "Optimization Iteration:  35777, Training Accuracy:  73.4%, Loss: 0.4311\n",
      "Optimization Iteration:  35841, Training Accuracy:  73.4%, Loss: 0.4991\n",
      "Optimization Iteration:  35905, Training Accuracy:  78.1%, Loss: 0.4262\n",
      "Optimization Iteration:  35969, Training Accuracy:  59.4%, Loss: 0.4976\n",
      "Optimization Iteration:  36033, Training Accuracy:  73.4%, Loss: 0.4144\n",
      "Optimization Iteration:  36097, Training Accuracy:  70.3%, Loss: 0.4462\n",
      "Optimization Iteration:  36161, Training Accuracy:  78.1%, Loss: 0.4207\n",
      "Optimization Iteration:  36225, Training Accuracy:  71.9%, Loss: 0.4189\n",
      "Optimization Iteration:  36289, Training Accuracy:  73.4%, Loss: 0.4437\n",
      "Optimization Iteration:  36353, Training Accuracy:  79.7%, Loss: 0.3706\n",
      "Optimization Iteration:  36417, Training Accuracy:  76.6%, Loss: 0.4995\n",
      "Optimization Iteration:  36481, Training Accuracy:  73.4%, Loss: 0.3476\n",
      "Optimization Iteration:  36545, Training Accuracy:  82.8%, Loss: 0.4382\n",
      "Optimization Iteration:  36609, Training Accuracy:  67.2%, Loss: 0.4493\n",
      "Optimization Iteration:  36673, Training Accuracy:  68.8%, Loss: 0.5070\n",
      "Optimization Iteration:  36737, Training Accuracy:  73.4%, Loss: 0.4723\n",
      "Optimization Iteration:  36801, Training Accuracy:  76.6%, Loss: 0.3696\n",
      "Optimization Iteration:  36865, Training Accuracy:  75.0%, Loss: 0.4344\n",
      "Optimization Iteration:  36929, Training Accuracy:  71.9%, Loss: 0.5118\n",
      "Optimization Iteration:  36993, Training Accuracy:  64.1%, Loss: 0.5027\n",
      "Optimization Iteration:  37057, Training Accuracy:  70.3%, Loss: 0.3948\n",
      "Optimization Iteration:  37121, Training Accuracy:  67.2%, Loss: 0.5161\n",
      "Optimization Iteration:  37185, Training Accuracy:  67.2%, Loss: 0.4903\n",
      "Optimization Iteration:  37249, Training Accuracy:  64.1%, Loss: 0.7035\n",
      "Optimization Iteration:  37313, Training Accuracy:  70.3%, Loss: 0.4717\n",
      "Optimization Iteration:  37377, Training Accuracy:  71.9%, Loss: 0.4944\n",
      "Optimization Iteration:  37441, Training Accuracy:  70.3%, Loss: 0.4349\n",
      "Optimization Iteration:  37505, Training Accuracy:  70.3%, Loss: 0.5303\n",
      "Optimization Iteration:  37569, Training Accuracy:  65.6%, Loss: 0.4970\n",
      "Optimization Iteration:  37633, Training Accuracy:  65.6%, Loss: 0.5273\n",
      "Optimization Iteration:  37697, Training Accuracy:  71.9%, Loss: 0.4588\n",
      "Optimization Iteration:  37761, Training Accuracy:  79.7%, Loss: 0.4555\n",
      "Optimization Iteration:  37825, Training Accuracy:  78.1%, Loss: 0.4214\n",
      "Optimization Iteration:  37889, Training Accuracy:  71.9%, Loss: 0.4464\n",
      "Optimization Iteration:  37953, Training Accuracy:  81.2%, Loss: 0.3765\n",
      "Optimization Iteration:  38017, Training Accuracy:  65.6%, Loss: 0.4446\n",
      "Optimization Iteration:  38081, Training Accuracy:  73.4%, Loss: 0.4668\n",
      "Optimization Iteration:  38145, Training Accuracy:  65.6%, Loss: 0.3976\n",
      "Optimization Iteration:  38209, Training Accuracy:  75.0%, Loss: 0.4670\n",
      "Optimization Iteration:  38273, Training Accuracy:  75.0%, Loss: 0.4321\n",
      "Optimization Iteration:  38337, Training Accuracy:  84.4%, Loss: 0.2809\n",
      "Optimization Iteration:  38401, Training Accuracy:  73.4%, Loss: 0.5073\n",
      "Optimization Iteration:  38465, Training Accuracy:  71.9%, Loss: 0.5316\n",
      "Optimization Iteration:  38529, Training Accuracy:  75.0%, Loss: 0.4624\n",
      "Optimization Iteration:  38593, Training Accuracy:  68.8%, Loss: 0.5412\n",
      "Optimization Iteration:  38657, Training Accuracy:  65.6%, Loss: 0.4922\n",
      "Optimization Iteration:  38721, Training Accuracy:  73.4%, Loss: 0.4237\n",
      "Optimization Iteration:  38785, Training Accuracy:  73.4%, Loss: 0.5325\n",
      "Optimization Iteration:  38849, Training Accuracy:  82.8%, Loss: 0.3320\n",
      "Optimization Iteration:  38913, Training Accuracy:  78.1%, Loss: 0.4328\n",
      "Optimization Iteration:  38977, Training Accuracy:  78.1%, Loss: 0.4315\n",
      "Optimization Iteration:  39041, Training Accuracy:  78.1%, Loss: 0.4532\n",
      "Optimization Iteration:  39105, Training Accuracy:  70.3%, Loss: 0.5090\n",
      "Optimization Iteration:  39169, Training Accuracy:  68.8%, Loss: 0.4935\n",
      "Optimization Iteration:  39233, Training Accuracy:  73.4%, Loss: 0.4972\n",
      "Optimization Iteration:  39297, Training Accuracy:  70.3%, Loss: 0.4486\n",
      "Optimization Iteration:  39361, Training Accuracy:  73.4%, Loss: 0.4211\n",
      "Optimization Iteration:  39425, Training Accuracy:  75.0%, Loss: 0.4503\n",
      "Optimization Iteration:  39489, Training Accuracy:  68.8%, Loss: 0.3825\n",
      "Optimization Iteration:  39553, Training Accuracy:  78.1%, Loss: 0.3942\n",
      "Optimization Iteration:  39617, Training Accuracy:  71.9%, Loss: 0.4406\n",
      "Optimization Iteration:  39681, Training Accuracy:  62.5%, Loss: 0.4659\n",
      "Optimization Iteration:  39745, Training Accuracy:  62.5%, Loss: 0.5283\n",
      "Optimization Iteration:  39809, Training Accuracy:  67.2%, Loss: 0.5462\n",
      "Optimization Iteration:  39873, Training Accuracy:  65.6%, Loss: 0.4708\n",
      "Optimization Iteration:  39937, Training Accuracy:  76.6%, Loss: 0.4972\n",
      "Optimization Iteration:  40001, Training Accuracy:  68.8%, Loss: 0.4861\n",
      "Optimization Iteration:  40065, Training Accuracy:  78.1%, Loss: 0.4483\n",
      "Optimization Iteration:  40129, Training Accuracy:  79.7%, Loss: 0.3911\n",
      "Optimization Iteration:  40193, Training Accuracy:  81.2%, Loss: 0.4279\n",
      "Optimization Iteration:  40257, Training Accuracy:  68.8%, Loss: 0.4443\n",
      "Optimization Iteration:  40321, Training Accuracy:  76.6%, Loss: 0.4922\n",
      "Optimization Iteration:  40385, Training Accuracy:  62.5%, Loss: 0.5035\n",
      "Optimization Iteration:  40449, Training Accuracy:  79.7%, Loss: 0.4277\n",
      "Optimization Iteration:  40513, Training Accuracy:  76.6%, Loss: 0.3902\n",
      "Optimization Iteration:  40577, Training Accuracy:  84.4%, Loss: 0.3923\n",
      "Optimization Iteration:  40641, Training Accuracy:  82.8%, Loss: 0.3420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  40705, Training Accuracy:  78.1%, Loss: 0.4777\n",
      "Optimization Iteration:  40769, Training Accuracy:  82.8%, Loss: 0.3601\n",
      "Optimization Iteration:  40833, Training Accuracy:  76.6%, Loss: 0.4089\n",
      "Optimization Iteration:  40897, Training Accuracy:  85.9%, Loss: 0.3427\n",
      "Optimization Iteration:  40961, Training Accuracy:  71.9%, Loss: 0.4516\n",
      "Optimization Iteration:  41025, Training Accuracy:  84.4%, Loss: 0.3382\n",
      "Optimization Iteration:  41089, Training Accuracy:  79.7%, Loss: 0.4279\n",
      "Optimization Iteration:  41153, Training Accuracy:  79.7%, Loss: 0.4140\n",
      "Optimization Iteration:  41217, Training Accuracy:  78.1%, Loss: 0.4102\n",
      "Optimization Iteration:  41281, Training Accuracy:  78.1%, Loss: 0.4517\n",
      "Optimization Iteration:  41345, Training Accuracy:  68.8%, Loss: 0.4658\n",
      "Optimization Iteration:  41409, Training Accuracy:  85.9%, Loss: 0.3675\n",
      "Optimization Iteration:  41473, Training Accuracy:  75.0%, Loss: 0.4429\n",
      "Optimization Iteration:  41537, Training Accuracy:  71.9%, Loss: 0.4940\n",
      "Optimization Iteration:  41601, Training Accuracy:  68.8%, Loss: 0.4505\n",
      "Optimization Iteration:  41665, Training Accuracy:  64.1%, Loss: 0.4938\n",
      "Optimization Iteration:  41729, Training Accuracy:  79.7%, Loss: 0.3809\n",
      "Optimization Iteration:  41793, Training Accuracy:  81.2%, Loss: 0.4297\n",
      "Optimization Iteration:  41857, Training Accuracy:  68.8%, Loss: 0.5044\n",
      "Optimization Iteration:  41921, Training Accuracy:  73.4%, Loss: 0.3911\n",
      "Optimization Iteration:  41985, Training Accuracy:  68.8%, Loss: 0.4898\n",
      "Optimization Iteration:  42049, Training Accuracy:  78.1%, Loss: 0.4288\n",
      "Optimization Iteration:  42113, Training Accuracy:  64.1%, Loss: 0.5043\n",
      "Optimization Iteration:  42177, Training Accuracy:  68.8%, Loss: 0.5320\n",
      "Optimization Iteration:  42241, Training Accuracy:  76.6%, Loss: 0.4645\n",
      "Optimization Iteration:  42305, Training Accuracy:  73.4%, Loss: 0.4762\n",
      "Optimization Iteration:  42369, Training Accuracy:  76.6%, Loss: 0.4939\n",
      "Optimization Iteration:  42433, Training Accuracy:  67.2%, Loss: 0.4779\n",
      "Optimization Iteration:  42497, Training Accuracy:  67.2%, Loss: 0.4166\n",
      "Optimization Iteration:  42561, Training Accuracy:  82.8%, Loss: 0.3569\n",
      "Optimization Iteration:  42625, Training Accuracy:  82.8%, Loss: 0.4117\n",
      "Optimization Iteration:  42689, Training Accuracy:  79.7%, Loss: 0.3736\n",
      "Optimization Iteration:  42753, Training Accuracy:  71.9%, Loss: 0.3979\n",
      "Optimization Iteration:  42817, Training Accuracy:  87.5%, Loss: 0.3606\n",
      "Optimization Iteration:  42881, Training Accuracy:  75.0%, Loss: 0.4727\n",
      "Optimization Iteration:  42945, Training Accuracy:  81.2%, Loss: 0.3949\n",
      "Optimization Iteration:  43009, Training Accuracy:  62.5%, Loss: 0.5855\n",
      "Optimization Iteration:  43073, Training Accuracy:  70.3%, Loss: 0.4779\n",
      "Optimization Iteration:  43137, Training Accuracy:  75.0%, Loss: 0.4556\n",
      "Optimization Iteration:  43201, Training Accuracy:  62.5%, Loss: 0.5205\n",
      "Optimization Iteration:  43265, Training Accuracy:  73.4%, Loss: 0.4497\n",
      "Optimization Iteration:  43329, Training Accuracy:  76.6%, Loss: 0.4054\n",
      "Optimization Iteration:  43393, Training Accuracy:  75.0%, Loss: 0.4392\n",
      "Optimization Iteration:  43457, Training Accuracy:  85.9%, Loss: 0.3874\n",
      "Optimization Iteration:  43521, Training Accuracy:  75.0%, Loss: 0.4359\n",
      "Optimization Iteration:  43585, Training Accuracy:  76.6%, Loss: 0.4248\n",
      "Optimization Iteration:  43649, Training Accuracy:  75.0%, Loss: 0.4174\n",
      "Optimization Iteration:  43713, Training Accuracy:  73.4%, Loss: 0.4650\n",
      "Optimization Iteration:  43777, Training Accuracy:  76.6%, Loss: 0.3621\n",
      "Optimization Iteration:  43841, Training Accuracy:  64.1%, Loss: 0.5196\n",
      "Optimization Iteration:  43905, Training Accuracy:  75.0%, Loss: 0.4478\n",
      "Optimization Iteration:  43969, Training Accuracy:  78.1%, Loss: 0.3917\n",
      "Optimization Iteration:  44033, Training Accuracy:  70.3%, Loss: 0.4484\n",
      "Optimization Iteration:  44097, Training Accuracy:  67.2%, Loss: 0.4382\n",
      "Optimization Iteration:  44161, Training Accuracy:  78.1%, Loss: 0.3381\n",
      "Optimization Iteration:  44225, Training Accuracy:  79.7%, Loss: 0.4306\n",
      "Optimization Iteration:  44289, Training Accuracy:  76.6%, Loss: 0.4636\n",
      "Optimization Iteration:  44353, Training Accuracy:  79.7%, Loss: 0.3979\n",
      "Optimization Iteration:  44417, Training Accuracy:  81.2%, Loss: 0.3901\n",
      "Optimization Iteration:  44481, Training Accuracy:  71.9%, Loss: 0.4160\n",
      "Optimization Iteration:  44545, Training Accuracy:  71.9%, Loss: 0.4507\n",
      "Optimization Iteration:  44609, Training Accuracy:  78.1%, Loss: 0.4465\n",
      "Optimization Iteration:  44673, Training Accuracy:  75.0%, Loss: 0.4611\n",
      "Optimization Iteration:  44737, Training Accuracy:  76.6%, Loss: 0.4041\n",
      "Optimization Iteration:  44801, Training Accuracy:  75.0%, Loss: 0.4376\n",
      "Optimization Iteration:  44865, Training Accuracy:  73.4%, Loss: 0.4721\n",
      "Optimization Iteration:  44929, Training Accuracy:  78.1%, Loss: 0.4414\n",
      "Optimization Iteration:  44993, Training Accuracy:  73.4%, Loss: 0.5318\n",
      "Optimization Iteration:  45057, Training Accuracy:  70.3%, Loss: 0.4590\n",
      "Optimization Iteration:  45121, Training Accuracy:  71.9%, Loss: 0.4312\n",
      "Optimization Iteration:  45185, Training Accuracy:  75.0%, Loss: 0.3637\n",
      "Optimization Iteration:  45249, Training Accuracy:  67.2%, Loss: 0.5442\n",
      "Optimization Iteration:  45313, Training Accuracy:  71.9%, Loss: 0.4579\n",
      "Optimization Iteration:  45377, Training Accuracy:  76.6%, Loss: 0.5043\n",
      "Optimization Iteration:  45441, Training Accuracy:  78.1%, Loss: 0.4286\n",
      "Optimization Iteration:  45505, Training Accuracy:  71.9%, Loss: 0.4184\n",
      "Optimization Iteration:  45569, Training Accuracy:  56.2%, Loss: 0.5112\n",
      "Optimization Iteration:  45633, Training Accuracy:  75.0%, Loss: 0.5459\n",
      "Optimization Iteration:  45697, Training Accuracy:  81.2%, Loss: 0.3530\n",
      "Optimization Iteration:  45761, Training Accuracy:  82.8%, Loss: 0.3772\n",
      "Optimization Iteration:  45825, Training Accuracy:  67.2%, Loss: 0.4819\n",
      "Optimization Iteration:  45889, Training Accuracy:  76.6%, Loss: 0.4322\n",
      "Optimization Iteration:  45953, Training Accuracy:  76.6%, Loss: 0.4067\n",
      "Optimization Iteration:  46017, Training Accuracy:  73.4%, Loss: 0.4365\n",
      "Optimization Iteration:  46081, Training Accuracy:  82.8%, Loss: 0.3678\n",
      "Optimization Iteration:  46145, Training Accuracy:  73.4%, Loss: 0.4973\n",
      "Optimization Iteration:  46209, Training Accuracy:  78.1%, Loss: 0.4231\n",
      "Optimization Iteration:  46273, Training Accuracy:  75.0%, Loss: 0.4739\n",
      "Optimization Iteration:  46337, Training Accuracy:  70.3%, Loss: 0.4839\n",
      "Optimization Iteration:  46401, Training Accuracy:  78.1%, Loss: 0.4098\n",
      "Optimization Iteration:  46465, Training Accuracy:  76.6%, Loss: 0.4512\n",
      "Optimization Iteration:  46529, Training Accuracy:  76.6%, Loss: 0.3970\n",
      "Optimization Iteration:  46593, Training Accuracy:  79.7%, Loss: 0.4825\n",
      "Optimization Iteration:  46657, Training Accuracy:  64.1%, Loss: 0.5221\n",
      "Optimization Iteration:  46721, Training Accuracy:  76.6%, Loss: 0.4986\n",
      "Optimization Iteration:  46785, Training Accuracy:  65.6%, Loss: 0.4873\n",
      "Optimization Iteration:  46849, Training Accuracy:  78.1%, Loss: 0.4106\n",
      "Optimization Iteration:  46913, Training Accuracy:  73.4%, Loss: 0.3962\n",
      "Optimization Iteration:  46977, Training Accuracy:  73.4%, Loss: 0.4036\n",
      "Optimization Iteration:  47041, Training Accuracy:  75.0%, Loss: 0.4210\n",
      "Optimization Iteration:  47105, Training Accuracy:  64.1%, Loss: 0.4937\n",
      "Optimization Iteration:  47169, Training Accuracy:  71.9%, Loss: 0.4444\n",
      "Optimization Iteration:  47233, Training Accuracy:  71.9%, Loss: 0.4709\n",
      "Optimization Iteration:  47297, Training Accuracy:  73.4%, Loss: 0.4379\n",
      "Optimization Iteration:  47361, Training Accuracy:  68.8%, Loss: 0.4262\n",
      "Optimization Iteration:  47425, Training Accuracy:  67.2%, Loss: 0.4684\n",
      "Optimization Iteration:  47489, Training Accuracy:  73.4%, Loss: 0.4536\n",
      "Optimization Iteration:  47553, Training Accuracy:  78.1%, Loss: 0.4244\n",
      "Optimization Iteration:  47617, Training Accuracy:  70.3%, Loss: 0.5025\n",
      "Optimization Iteration:  47681, Training Accuracy:  81.2%, Loss: 0.3629\n",
      "Optimization Iteration:  47745, Training Accuracy:  67.2%, Loss: 0.5405\n",
      "Optimization Iteration:  47809, Training Accuracy:  75.0%, Loss: 0.5167\n",
      "Optimization Iteration:  47873, Training Accuracy:  76.6%, Loss: 0.4696\n",
      "Optimization Iteration:  47937, Training Accuracy:  68.8%, Loss: 0.5371\n",
      "Optimization Iteration:  48001, Training Accuracy:  70.3%, Loss: 0.4491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  48065, Training Accuracy:  65.6%, Loss: 0.5143\n",
      "Optimization Iteration:  48129, Training Accuracy:  70.3%, Loss: 0.5008\n",
      "Optimization Iteration:  48193, Training Accuracy:  65.6%, Loss: 0.5057\n",
      "Optimization Iteration:  48257, Training Accuracy:  70.3%, Loss: 0.4125\n",
      "Optimization Iteration:  48321, Training Accuracy:  76.6%, Loss: 0.4544\n",
      "Optimization Iteration:  48385, Training Accuracy:  82.8%, Loss: 0.4564\n",
      "Optimization Iteration:  48449, Training Accuracy:  75.0%, Loss: 0.4917\n",
      "Optimization Iteration:  48513, Training Accuracy:  68.8%, Loss: 0.4853\n",
      "Optimization Iteration:  48577, Training Accuracy:  59.4%, Loss: 0.5453\n",
      "Optimization Iteration:  48641, Training Accuracy:  76.6%, Loss: 0.3936\n",
      "Optimization Iteration:  48705, Training Accuracy:  73.4%, Loss: 0.3839\n",
      "Optimization Iteration:  48769, Training Accuracy:  76.6%, Loss: 0.4082\n",
      "Optimization Iteration:  48833, Training Accuracy:  78.1%, Loss: 0.3777\n",
      "Optimization Iteration:  48897, Training Accuracy:  70.3%, Loss: 0.5295\n",
      "Optimization Iteration:  48961, Training Accuracy:  76.6%, Loss: 0.4523\n",
      "Optimization Iteration:  49025, Training Accuracy:  79.7%, Loss: 0.4681\n",
      "Optimization Iteration:  49089, Training Accuracy:  78.1%, Loss: 0.4182\n",
      "Optimization Iteration:  49153, Training Accuracy:  75.0%, Loss: 0.4254\n",
      "Optimization Iteration:  49217, Training Accuracy:  73.4%, Loss: 0.4048\n",
      "Optimization Iteration:  49281, Training Accuracy:  76.6%, Loss: 0.4329\n",
      "Optimization Iteration:  49345, Training Accuracy:  78.1%, Loss: 0.3675\n",
      "Optimization Iteration:  49409, Training Accuracy:  81.2%, Loss: 0.3652\n",
      "Optimization Iteration:  49473, Training Accuracy:  76.6%, Loss: 0.3905\n",
      "Optimization Iteration:  49537, Training Accuracy:  65.6%, Loss: 0.4589\n",
      "Optimization Iteration:  49601, Training Accuracy:  73.4%, Loss: 0.4591\n",
      "Optimization Iteration:  49665, Training Accuracy:  70.3%, Loss: 0.4101\n",
      "Optimization Iteration:  49729, Training Accuracy:  67.2%, Loss: 0.5960\n",
      "Optimization Iteration:  49793, Training Accuracy:  70.3%, Loss: 0.4405\n",
      "Optimization Iteration:  49857, Training Accuracy:  78.1%, Loss: 0.3951\n",
      "Optimization Iteration:  49921, Training Accuracy:  79.7%, Loss: 0.4022\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 5\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  71.9%, Loss: 0.4504\n",
      "Optimization Iteration:    129, Training Accuracy:  76.6%, Loss: 0.5004\n",
      "Optimization Iteration:    193, Training Accuracy:  71.9%, Loss: 0.5326\n",
      "Optimization Iteration:    257, Training Accuracy:  71.9%, Loss: 0.4320\n",
      "Optimization Iteration:    321, Training Accuracy:  79.7%, Loss: 0.3828\n",
      "Optimization Iteration:    385, Training Accuracy:  78.1%, Loss: 0.4305\n",
      "Optimization Iteration:    449, Training Accuracy:  81.2%, Loss: 0.4214\n",
      "Optimization Iteration:    513, Training Accuracy:  70.3%, Loss: 0.5016\n",
      "Optimization Iteration:    577, Training Accuracy:  56.2%, Loss: 0.5265\n",
      "Optimization Iteration:    641, Training Accuracy:  64.1%, Loss: 0.5395\n",
      "Optimization Iteration:    705, Training Accuracy:  67.2%, Loss: 0.5389\n",
      "Optimization Iteration:    769, Training Accuracy:  70.3%, Loss: 0.5045\n",
      "Optimization Iteration:    833, Training Accuracy:  89.1%, Loss: 0.2862\n",
      "Optimization Iteration:    897, Training Accuracy:  79.7%, Loss: 0.3407\n",
      "Optimization Iteration:    961, Training Accuracy:  73.4%, Loss: 0.3557\n",
      "Optimization Iteration:   1025, Training Accuracy:  75.0%, Loss: 0.4664\n",
      "Optimization Iteration:   1089, Training Accuracy:  75.0%, Loss: 0.4389\n",
      "Optimization Iteration:   1153, Training Accuracy:  81.2%, Loss: 0.4787\n",
      "Optimization Iteration:   1217, Training Accuracy:  78.1%, Loss: 0.4091\n",
      "Optimization Iteration:   1281, Training Accuracy:  73.4%, Loss: 0.4506\n",
      "Optimization Iteration:   1345, Training Accuracy:  78.1%, Loss: 0.4424\n",
      "Optimization Iteration:   1409, Training Accuracy:  87.5%, Loss: 0.4245\n",
      "Optimization Iteration:   1473, Training Accuracy:  68.8%, Loss: 0.4611\n",
      "Optimization Iteration:   1537, Training Accuracy:  73.4%, Loss: 0.4142\n",
      "Optimization Iteration:   1601, Training Accuracy:  73.4%, Loss: 0.4493\n",
      "Optimization Iteration:   1665, Training Accuracy:  68.8%, Loss: 0.4252\n",
      "Optimization Iteration:   1729, Training Accuracy:  67.2%, Loss: 0.4528\n",
      "Optimization Iteration:   1793, Training Accuracy:  70.3%, Loss: 0.4501\n",
      "Optimization Iteration:   1857, Training Accuracy:  75.0%, Loss: 0.4577\n",
      "Optimization Iteration:   1921, Training Accuracy:  75.0%, Loss: 0.4166\n",
      "Optimization Iteration:   1985, Training Accuracy:  70.3%, Loss: 0.4612\n",
      "Optimization Iteration:   2049, Training Accuracy:  78.1%, Loss: 0.3760\n",
      "Optimization Iteration:   2113, Training Accuracy:  73.4%, Loss: 0.4831\n",
      "Optimization Iteration:   2177, Training Accuracy:  81.2%, Loss: 0.3701\n",
      "Optimization Iteration:   2241, Training Accuracy:  73.4%, Loss: 0.4118\n",
      "Optimization Iteration:   2305, Training Accuracy:  75.0%, Loss: 0.4476\n",
      "Optimization Iteration:   2369, Training Accuracy:  81.2%, Loss: 0.4635\n",
      "Optimization Iteration:   2433, Training Accuracy:  75.0%, Loss: 0.5169\n",
      "Optimization Iteration:   2497, Training Accuracy:  68.8%, Loss: 0.4390\n",
      "Optimization Iteration:   2561, Training Accuracy:  79.7%, Loss: 0.3145\n",
      "Optimization Iteration:   2625, Training Accuracy:  78.1%, Loss: 0.4312\n",
      "Optimization Iteration:   2689, Training Accuracy:  70.3%, Loss: 0.4402\n",
      "Optimization Iteration:   2753, Training Accuracy:  75.0%, Loss: 0.3619\n",
      "Optimization Iteration:   2817, Training Accuracy:  76.6%, Loss: 0.4056\n",
      "Optimization Iteration:   2881, Training Accuracy:  65.6%, Loss: 0.5045\n",
      "Optimization Iteration:   2945, Training Accuracy:  70.3%, Loss: 0.4830\n",
      "Optimization Iteration:   3009, Training Accuracy:  71.9%, Loss: 0.4490\n",
      "Optimization Iteration:   3073, Training Accuracy:  73.4%, Loss: 0.3934\n",
      "Optimization Iteration:   3137, Training Accuracy:  75.0%, Loss: 0.4469\n",
      "Optimization Iteration:   3201, Training Accuracy:  73.4%, Loss: 0.4505\n",
      "Optimization Iteration:   3265, Training Accuracy:  78.1%, Loss: 0.4009\n",
      "Optimization Iteration:   3329, Training Accuracy:  76.6%, Loss: 0.4075\n",
      "Optimization Iteration:   3393, Training Accuracy:  67.2%, Loss: 0.4423\n",
      "Optimization Iteration:   3457, Training Accuracy:  79.7%, Loss: 0.5096\n",
      "Optimization Iteration:   3521, Training Accuracy:  73.4%, Loss: 0.4116\n",
      "Optimization Iteration:   3585, Training Accuracy:  70.3%, Loss: 0.4865\n",
      "Optimization Iteration:   3649, Training Accuracy:  70.3%, Loss: 0.5271\n",
      "Optimization Iteration:   3713, Training Accuracy:  68.8%, Loss: 0.3841\n",
      "Optimization Iteration:   3777, Training Accuracy:  70.3%, Loss: 0.4615\n",
      "Optimization Iteration:   3841, Training Accuracy:  71.9%, Loss: 0.4077\n",
      "Optimization Iteration:   3905, Training Accuracy:  78.1%, Loss: 0.4995\n",
      "Optimization Iteration:   3969, Training Accuracy:  70.3%, Loss: 0.5059\n",
      "Optimization Iteration:   4033, Training Accuracy:  76.6%, Loss: 0.3544\n",
      "Optimization Iteration:   4097, Training Accuracy:  70.3%, Loss: 0.4185\n",
      "Optimization Iteration:   4161, Training Accuracy:  73.4%, Loss: 0.4807\n",
      "Optimization Iteration:   4225, Training Accuracy:  68.8%, Loss: 0.3893\n",
      "Optimization Iteration:   4289, Training Accuracy:  67.2%, Loss: 0.4292\n",
      "Optimization Iteration:   4353, Training Accuracy:  78.1%, Loss: 0.3660\n",
      "Optimization Iteration:   4417, Training Accuracy:  71.9%, Loss: 0.4491\n",
      "Optimization Iteration:   4481, Training Accuracy:  65.6%, Loss: 0.6117\n",
      "Optimization Iteration:   4545, Training Accuracy:  81.2%, Loss: 0.3998\n",
      "Optimization Iteration:   4609, Training Accuracy:  82.8%, Loss: 0.4224\n",
      "Optimization Iteration:   4673, Training Accuracy:  85.9%, Loss: 0.3869\n",
      "Optimization Iteration:   4737, Training Accuracy:  70.3%, Loss: 0.4507\n",
      "Optimization Iteration:   4801, Training Accuracy:  65.6%, Loss: 0.4897\n",
      "Optimization Iteration:   4865, Training Accuracy:  62.5%, Loss: 0.4497\n",
      "Optimization Iteration:   4929, Training Accuracy:  79.7%, Loss: 0.4894\n",
      "Optimization Iteration:   4993, Training Accuracy:  78.1%, Loss: 0.4026\n",
      "Optimization Iteration:   5057, Training Accuracy:  78.1%, Loss: 0.4913\n",
      "Optimization Iteration:   5121, Training Accuracy:  76.6%, Loss: 0.3711\n",
      "Optimization Iteration:   5185, Training Accuracy:  76.6%, Loss: 0.4561\n",
      "Optimization Iteration:   5249, Training Accuracy:  65.6%, Loss: 0.5091\n",
      "Optimization Iteration:   5313, Training Accuracy:  73.4%, Loss: 0.5347\n",
      "Optimization Iteration:   5377, Training Accuracy:  73.4%, Loss: 0.5111\n",
      "Optimization Iteration:   5441, Training Accuracy:  76.6%, Loss: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   5505, Training Accuracy:  82.8%, Loss: 0.3958\n",
      "Optimization Iteration:   5569, Training Accuracy:  81.2%, Loss: 0.3727\n",
      "Optimization Iteration:   5633, Training Accuracy:  78.1%, Loss: 0.3875\n",
      "Optimization Iteration:   5697, Training Accuracy:  65.6%, Loss: 0.4932\n",
      "Optimization Iteration:   5761, Training Accuracy:  81.2%, Loss: 0.3609\n",
      "Optimization Iteration:   5825, Training Accuracy:  70.3%, Loss: 0.4286\n",
      "Optimization Iteration:   5889, Training Accuracy:  79.7%, Loss: 0.4865\n",
      "Optimization Iteration:   5953, Training Accuracy:  70.3%, Loss: 0.4754\n",
      "Optimization Iteration:   6017, Training Accuracy:  59.4%, Loss: 0.6225\n",
      "Optimization Iteration:   6081, Training Accuracy:  81.2%, Loss: 0.4430\n",
      "Optimization Iteration:   6145, Training Accuracy:  64.1%, Loss: 0.5407\n",
      "Optimization Iteration:   6209, Training Accuracy:  70.3%, Loss: 0.4037\n",
      "Optimization Iteration:   6273, Training Accuracy:  78.1%, Loss: 0.4568\n",
      "Optimization Iteration:   6337, Training Accuracy:  71.9%, Loss: 0.4593\n",
      "Optimization Iteration:   6401, Training Accuracy:  73.4%, Loss: 0.4826\n",
      "Optimization Iteration:   6465, Training Accuracy:  79.7%, Loss: 0.3005\n",
      "Optimization Iteration:   6529, Training Accuracy:  81.2%, Loss: 0.3851\n",
      "Optimization Iteration:   6593, Training Accuracy:  73.4%, Loss: 0.4377\n",
      "Optimization Iteration:   6657, Training Accuracy:  78.1%, Loss: 0.3642\n",
      "Optimization Iteration:   6721, Training Accuracy:  75.0%, Loss: 0.3750\n",
      "Optimization Iteration:   6785, Training Accuracy:  71.9%, Loss: 0.4219\n",
      "Optimization Iteration:   6849, Training Accuracy:  76.6%, Loss: 0.4683\n",
      "Optimization Iteration:   6913, Training Accuracy:  82.8%, Loss: 0.3475\n",
      "Optimization Iteration:   6977, Training Accuracy:  78.1%, Loss: 0.4426\n",
      "Optimization Iteration:   7041, Training Accuracy:  84.4%, Loss: 0.3277\n",
      "Optimization Iteration:   7105, Training Accuracy:  75.0%, Loss: 0.4088\n",
      "Optimization Iteration:   7169, Training Accuracy:  75.0%, Loss: 0.4915\n",
      "Optimization Iteration:   7233, Training Accuracy:  71.9%, Loss: 0.4711\n",
      "Optimization Iteration:   7297, Training Accuracy:  65.6%, Loss: 0.5862\n",
      "Optimization Iteration:   7361, Training Accuracy:  75.0%, Loss: 0.4453\n",
      "Optimization Iteration:   7425, Training Accuracy:  76.6%, Loss: 0.4590\n",
      "Optimization Iteration:   7489, Training Accuracy:  73.4%, Loss: 0.4641\n",
      "Optimization Iteration:   7553, Training Accuracy:  73.4%, Loss: 0.4364\n",
      "Optimization Iteration:   7617, Training Accuracy:  75.0%, Loss: 0.4797\n",
      "Optimization Iteration:   7681, Training Accuracy:  75.0%, Loss: 0.4916\n",
      "Optimization Iteration:   7745, Training Accuracy:  70.3%, Loss: 0.4499\n",
      "Optimization Iteration:   7809, Training Accuracy:  64.1%, Loss: 0.5589\n",
      "Optimization Iteration:   7873, Training Accuracy:  67.2%, Loss: 0.4396\n",
      "Optimization Iteration:   7937, Training Accuracy:  75.0%, Loss: 0.4422\n",
      "Optimization Iteration:   8001, Training Accuracy:  70.3%, Loss: 0.4583\n",
      "Optimization Iteration:   8065, Training Accuracy:  65.6%, Loss: 0.4902\n",
      "Optimization Iteration:   8129, Training Accuracy:  68.8%, Loss: 0.4909\n",
      "Optimization Iteration:   8193, Training Accuracy:  75.0%, Loss: 0.4271\n",
      "Optimization Iteration:   8257, Training Accuracy:  65.6%, Loss: 0.5236\n",
      "Optimization Iteration:   8321, Training Accuracy:  68.8%, Loss: 0.4694\n",
      "Optimization Iteration:   8385, Training Accuracy:  76.6%, Loss: 0.4722\n",
      "Optimization Iteration:   8449, Training Accuracy:  65.6%, Loss: 0.5805\n",
      "Optimization Iteration:   8513, Training Accuracy:  85.9%, Loss: 0.3429\n",
      "Optimization Iteration:   8577, Training Accuracy:  81.2%, Loss: 0.3849\n",
      "Optimization Iteration:   8641, Training Accuracy:  75.0%, Loss: 0.4572\n",
      "Optimization Iteration:   8705, Training Accuracy:  70.3%, Loss: 0.4543\n",
      "Optimization Iteration:   8769, Training Accuracy:  67.2%, Loss: 0.4307\n",
      "Optimization Iteration:   8833, Training Accuracy:  70.3%, Loss: 0.4780\n",
      "Optimization Iteration:   8897, Training Accuracy:  75.0%, Loss: 0.4872\n",
      "Optimization Iteration:   8961, Training Accuracy:  71.9%, Loss: 0.4555\n",
      "Optimization Iteration:   9025, Training Accuracy:  62.5%, Loss: 0.5350\n",
      "Optimization Iteration:   9089, Training Accuracy:  62.5%, Loss: 0.5300\n",
      "Optimization Iteration:   9153, Training Accuracy:  75.0%, Loss: 0.4635\n",
      "Optimization Iteration:   9217, Training Accuracy:  73.4%, Loss: 0.4498\n",
      "Optimization Iteration:   9281, Training Accuracy:  73.4%, Loss: 0.5101\n",
      "Optimization Iteration:   9345, Training Accuracy:  78.1%, Loss: 0.4398\n",
      "Optimization Iteration:   9409, Training Accuracy:  78.1%, Loss: 0.4827\n",
      "Optimization Iteration:   9473, Training Accuracy:  76.6%, Loss: 0.3668\n",
      "Optimization Iteration:   9537, Training Accuracy:  76.6%, Loss: 0.3829\n",
      "Optimization Iteration:   9601, Training Accuracy:  70.3%, Loss: 0.5014\n",
      "Optimization Iteration:   9665, Training Accuracy:  62.5%, Loss: 0.4567\n",
      "Optimization Iteration:   9729, Training Accuracy:  84.4%, Loss: 0.4400\n",
      "Optimization Iteration:   9793, Training Accuracy:  76.6%, Loss: 0.4112\n",
      "Optimization Iteration:   9857, Training Accuracy:  71.9%, Loss: 0.4482\n",
      "Optimization Iteration:   9921, Training Accuracy:  73.4%, Loss: 0.4837\n",
      "Optimization Iteration:   9985, Training Accuracy:  75.0%, Loss: 0.5179\n",
      "Optimization Iteration:  10049, Training Accuracy:  70.3%, Loss: 0.4627\n",
      "Optimization Iteration:  10113, Training Accuracy:  70.3%, Loss: 0.4459\n",
      "Optimization Iteration:  10177, Training Accuracy:  64.1%, Loss: 0.5501\n",
      "Optimization Iteration:  10241, Training Accuracy:  73.4%, Loss: 0.4996\n",
      "Optimization Iteration:  10305, Training Accuracy:  79.7%, Loss: 0.4123\n",
      "Optimization Iteration:  10369, Training Accuracy:  68.8%, Loss: 0.4703\n",
      "Optimization Iteration:  10433, Training Accuracy:  70.3%, Loss: 0.4458\n",
      "Optimization Iteration:  10497, Training Accuracy:  71.9%, Loss: 0.4944\n",
      "Optimization Iteration:  10561, Training Accuracy:  70.3%, Loss: 0.4368\n",
      "Optimization Iteration:  10625, Training Accuracy:  71.9%, Loss: 0.3902\n",
      "Optimization Iteration:  10689, Training Accuracy:  68.8%, Loss: 0.4243\n",
      "Optimization Iteration:  10753, Training Accuracy:  70.3%, Loss: 0.5085\n",
      "Optimization Iteration:  10817, Training Accuracy:  70.3%, Loss: 0.5123\n",
      "Optimization Iteration:  10881, Training Accuracy:  75.0%, Loss: 0.4046\n",
      "Optimization Iteration:  10945, Training Accuracy:  75.0%, Loss: 0.4509\n",
      "Optimization Iteration:  11009, Training Accuracy:  81.2%, Loss: 0.3489\n",
      "Optimization Iteration:  11073, Training Accuracy:  76.6%, Loss: 0.4320\n",
      "Optimization Iteration:  11137, Training Accuracy:  76.6%, Loss: 0.4134\n",
      "Optimization Iteration:  11201, Training Accuracy:  71.9%, Loss: 0.4140\n",
      "Optimization Iteration:  11265, Training Accuracy:  79.7%, Loss: 0.3569\n",
      "Optimization Iteration:  11329, Training Accuracy:  64.1%, Loss: 0.6456\n",
      "Optimization Iteration:  11393, Training Accuracy:  78.1%, Loss: 0.4050\n",
      "Optimization Iteration:  11457, Training Accuracy:  81.2%, Loss: 0.3519\n",
      "Optimization Iteration:  11521, Training Accuracy:  76.6%, Loss: 0.4496\n",
      "Optimization Iteration:  11585, Training Accuracy:  73.4%, Loss: 0.4054\n",
      "Optimization Iteration:  11649, Training Accuracy:  68.8%, Loss: 0.4831\n",
      "Optimization Iteration:  11713, Training Accuracy:  75.0%, Loss: 0.3775\n",
      "Optimization Iteration:  11777, Training Accuracy:  70.3%, Loss: 0.5043\n",
      "Optimization Iteration:  11841, Training Accuracy:  81.2%, Loss: 0.3963\n",
      "Optimization Iteration:  11905, Training Accuracy:  79.7%, Loss: 0.4131\n",
      "Optimization Iteration:  11969, Training Accuracy:  75.0%, Loss: 0.4850\n",
      "Optimization Iteration:  12033, Training Accuracy:  68.8%, Loss: 0.4533\n",
      "Optimization Iteration:  12097, Training Accuracy:  75.0%, Loss: 0.4701\n",
      "Optimization Iteration:  12161, Training Accuracy:  78.1%, Loss: 0.4818\n",
      "Optimization Iteration:  12225, Training Accuracy:  79.7%, Loss: 0.4486\n",
      "Optimization Iteration:  12289, Training Accuracy:  76.6%, Loss: 0.4109\n",
      "Optimization Iteration:  12353, Training Accuracy:  81.2%, Loss: 0.4392\n",
      "Optimization Iteration:  12417, Training Accuracy:  76.6%, Loss: 0.4086\n",
      "Optimization Iteration:  12481, Training Accuracy:  76.6%, Loss: 0.4583\n",
      "Optimization Iteration:  12545, Training Accuracy:  64.1%, Loss: 0.4892\n",
      "Optimization Iteration:  12609, Training Accuracy:  79.7%, Loss: 0.3950\n",
      "Optimization Iteration:  12673, Training Accuracy:  73.4%, Loss: 0.4132\n",
      "Optimization Iteration:  12737, Training Accuracy:  67.2%, Loss: 0.5358\n",
      "Optimization Iteration:  12801, Training Accuracy:  71.9%, Loss: 0.4888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  12865, Training Accuracy:  81.2%, Loss: 0.4672\n",
      "Optimization Iteration:  12929, Training Accuracy:  75.0%, Loss: 0.4238\n",
      "Optimization Iteration:  12993, Training Accuracy:  67.2%, Loss: 0.3916\n",
      "Optimization Iteration:  13057, Training Accuracy:  68.8%, Loss: 0.4775\n",
      "Optimization Iteration:  13121, Training Accuracy:  65.6%, Loss: 0.4968\n",
      "Optimization Iteration:  13185, Training Accuracy:  73.4%, Loss: 0.4834\n",
      "Optimization Iteration:  13249, Training Accuracy:  68.8%, Loss: 0.5107\n",
      "Optimization Iteration:  13313, Training Accuracy:  70.3%, Loss: 0.5126\n",
      "Optimization Iteration:  13377, Training Accuracy:  65.6%, Loss: 0.4888\n",
      "Optimization Iteration:  13441, Training Accuracy:  67.2%, Loss: 0.5132\n",
      "Optimization Iteration:  13505, Training Accuracy:  67.2%, Loss: 0.5086\n",
      "Optimization Iteration:  13569, Training Accuracy:  84.4%, Loss: 0.3448\n",
      "Optimization Iteration:  13633, Training Accuracy:  78.1%, Loss: 0.3909\n",
      "Optimization Iteration:  13697, Training Accuracy:  70.3%, Loss: 0.4319\n",
      "Optimization Iteration:  13761, Training Accuracy:  68.8%, Loss: 0.3999\n",
      "Optimization Iteration:  13825, Training Accuracy:  75.0%, Loss: 0.4425\n",
      "Optimization Iteration:  13889, Training Accuracy:  73.4%, Loss: 0.4271\n",
      "Optimization Iteration:  13953, Training Accuracy:  76.6%, Loss: 0.4017\n",
      "Optimization Iteration:  14017, Training Accuracy:  75.0%, Loss: 0.4349\n",
      "Optimization Iteration:  14081, Training Accuracy:  67.2%, Loss: 0.4347\n",
      "Optimization Iteration:  14145, Training Accuracy:  81.2%, Loss: 0.4077\n",
      "Optimization Iteration:  14209, Training Accuracy:  75.0%, Loss: 0.4289\n",
      "Optimization Iteration:  14273, Training Accuracy:  71.9%, Loss: 0.5090\n",
      "Optimization Iteration:  14337, Training Accuracy:  82.8%, Loss: 0.3620\n",
      "Optimization Iteration:  14401, Training Accuracy:  76.6%, Loss: 0.3922\n",
      "Optimization Iteration:  14465, Training Accuracy:  73.4%, Loss: 0.4802\n",
      "Optimization Iteration:  14529, Training Accuracy:  75.0%, Loss: 0.4517\n",
      "Optimization Iteration:  14593, Training Accuracy:  82.8%, Loss: 0.3468\n",
      "Optimization Iteration:  14657, Training Accuracy:  68.8%, Loss: 0.5024\n",
      "Optimization Iteration:  14721, Training Accuracy:  73.4%, Loss: 0.3906\n",
      "Optimization Iteration:  14785, Training Accuracy:  75.0%, Loss: 0.4601\n",
      "Optimization Iteration:  14849, Training Accuracy:  70.3%, Loss: 0.4339\n",
      "Optimization Iteration:  14913, Training Accuracy:  73.4%, Loss: 0.3634\n",
      "Optimization Iteration:  14977, Training Accuracy:  76.6%, Loss: 0.5255\n",
      "Optimization Iteration:  15041, Training Accuracy:  67.2%, Loss: 0.6355\n",
      "Optimization Iteration:  15105, Training Accuracy:  79.7%, Loss: 0.4508\n",
      "Optimization Iteration:  15169, Training Accuracy:  78.1%, Loss: 0.3993\n",
      "Optimization Iteration:  15233, Training Accuracy:  71.9%, Loss: 0.4318\n",
      "Optimization Iteration:  15297, Training Accuracy:  78.1%, Loss: 0.4183\n",
      "Optimization Iteration:  15361, Training Accuracy:  79.7%, Loss: 0.3952\n",
      "Optimization Iteration:  15425, Training Accuracy:  75.0%, Loss: 0.4129\n",
      "Optimization Iteration:  15489, Training Accuracy:  70.3%, Loss: 0.4748\n",
      "Optimization Iteration:  15553, Training Accuracy:  79.7%, Loss: 0.3641\n",
      "Optimization Iteration:  15617, Training Accuracy:  70.3%, Loss: 0.5667\n",
      "Optimization Iteration:  15681, Training Accuracy:  81.2%, Loss: 0.3952\n",
      "Optimization Iteration:  15745, Training Accuracy:  75.0%, Loss: 0.4421\n",
      "Optimization Iteration:  15809, Training Accuracy:  71.9%, Loss: 0.5081\n",
      "Optimization Iteration:  15873, Training Accuracy:  81.2%, Loss: 0.3885\n",
      "Optimization Iteration:  15937, Training Accuracy:  76.6%, Loss: 0.4143\n",
      "Optimization Iteration:  16001, Training Accuracy:  76.6%, Loss: 0.3873\n",
      "Optimization Iteration:  16065, Training Accuracy:  76.6%, Loss: 0.3926\n",
      "Optimization Iteration:  16129, Training Accuracy:  78.1%, Loss: 0.3832\n",
      "Optimization Iteration:  16193, Training Accuracy:  71.9%, Loss: 0.4634\n",
      "Optimization Iteration:  16257, Training Accuracy:  67.2%, Loss: 0.5497\n",
      "Optimization Iteration:  16321, Training Accuracy:  76.6%, Loss: 0.4770\n",
      "Optimization Iteration:  16385, Training Accuracy:  76.6%, Loss: 0.5230\n",
      "Optimization Iteration:  16449, Training Accuracy:  71.9%, Loss: 0.4345\n",
      "Optimization Iteration:  16513, Training Accuracy:  65.6%, Loss: 0.5126\n",
      "Optimization Iteration:  16577, Training Accuracy:  78.1%, Loss: 0.4241\n",
      "Optimization Iteration:  16641, Training Accuracy:  79.7%, Loss: 0.4144\n",
      "Optimization Iteration:  16705, Training Accuracy:  78.1%, Loss: 0.4166\n",
      "Optimization Iteration:  16769, Training Accuracy:  75.0%, Loss: 0.4066\n",
      "Optimization Iteration:  16833, Training Accuracy:  70.3%, Loss: 0.5024\n",
      "Optimization Iteration:  16897, Training Accuracy:  81.2%, Loss: 0.3776\n",
      "Optimization Iteration:  16961, Training Accuracy:  79.7%, Loss: 0.3921\n",
      "Optimization Iteration:  17025, Training Accuracy:  71.9%, Loss: 0.4957\n",
      "Optimization Iteration:  17089, Training Accuracy:  75.0%, Loss: 0.5071\n",
      "Optimization Iteration:  17153, Training Accuracy:  70.3%, Loss: 0.5093\n",
      "Optimization Iteration:  17217, Training Accuracy:  81.2%, Loss: 0.4419\n",
      "Optimization Iteration:  17281, Training Accuracy:  68.8%, Loss: 0.4520\n",
      "Optimization Iteration:  17345, Training Accuracy:  70.3%, Loss: 0.4041\n",
      "Optimization Iteration:  17409, Training Accuracy:  75.0%, Loss: 0.4229\n",
      "Optimization Iteration:  17473, Training Accuracy:  73.4%, Loss: 0.6031\n",
      "Optimization Iteration:  17537, Training Accuracy:  79.7%, Loss: 0.3718\n",
      "Optimization Iteration:  17601, Training Accuracy:  79.7%, Loss: 0.4588\n",
      "Optimization Iteration:  17665, Training Accuracy:  70.3%, Loss: 0.4692\n",
      "Optimization Iteration:  17729, Training Accuracy:  73.4%, Loss: 0.4212\n",
      "Optimization Iteration:  17793, Training Accuracy:  70.3%, Loss: 0.5117\n",
      "Optimization Iteration:  17857, Training Accuracy:  78.1%, Loss: 0.4598\n",
      "Optimization Iteration:  17921, Training Accuracy:  75.0%, Loss: 0.4350\n",
      "Optimization Iteration:  17985, Training Accuracy:  71.9%, Loss: 0.4007\n",
      "Optimization Iteration:  18049, Training Accuracy:  81.2%, Loss: 0.3850\n",
      "Optimization Iteration:  18113, Training Accuracy:  71.9%, Loss: 0.5287\n",
      "Optimization Iteration:  18177, Training Accuracy:  73.4%, Loss: 0.4616\n",
      "Optimization Iteration:  18241, Training Accuracy:  71.9%, Loss: 0.4800\n",
      "Optimization Iteration:  18305, Training Accuracy:  73.4%, Loss: 0.4775\n",
      "Optimization Iteration:  18369, Training Accuracy:  73.4%, Loss: 0.4548\n",
      "Optimization Iteration:  18433, Training Accuracy:  68.8%, Loss: 0.4508\n",
      "Optimization Iteration:  18497, Training Accuracy:  79.7%, Loss: 0.3719\n",
      "Optimization Iteration:  18561, Training Accuracy:  71.9%, Loss: 0.4688\n",
      "Optimization Iteration:  18625, Training Accuracy:  67.2%, Loss: 0.5374\n",
      "Optimization Iteration:  18689, Training Accuracy:  68.8%, Loss: 0.4333\n",
      "Optimization Iteration:  18753, Training Accuracy:  70.3%, Loss: 0.4419\n",
      "Optimization Iteration:  18817, Training Accuracy:  79.7%, Loss: 0.3629\n",
      "Optimization Iteration:  18881, Training Accuracy:  73.4%, Loss: 0.4153\n",
      "Optimization Iteration:  18945, Training Accuracy:  81.2%, Loss: 0.4839\n",
      "Optimization Iteration:  19009, Training Accuracy:  78.1%, Loss: 0.3679\n",
      "Optimization Iteration:  19073, Training Accuracy:  75.0%, Loss: 0.4618\n",
      "Optimization Iteration:  19137, Training Accuracy:  75.0%, Loss: 0.4545\n",
      "Optimization Iteration:  19201, Training Accuracy:  82.8%, Loss: 0.4233\n",
      "Optimization Iteration:  19265, Training Accuracy:  75.0%, Loss: 0.4723\n",
      "Optimization Iteration:  19329, Training Accuracy:  79.7%, Loss: 0.3667\n",
      "Optimization Iteration:  19393, Training Accuracy:  67.2%, Loss: 0.5139\n",
      "Optimization Iteration:  19457, Training Accuracy:  70.3%, Loss: 0.4378\n",
      "Optimization Iteration:  19521, Training Accuracy:  73.4%, Loss: 0.4371\n",
      "Optimization Iteration:  19585, Training Accuracy:  65.6%, Loss: 0.4747\n",
      "Optimization Iteration:  19649, Training Accuracy:  73.4%, Loss: 0.4991\n",
      "Optimization Iteration:  19713, Training Accuracy:  76.6%, Loss: 0.4260\n",
      "Optimization Iteration:  19777, Training Accuracy:  71.9%, Loss: 0.5157\n",
      "Optimization Iteration:  19841, Training Accuracy:  71.9%, Loss: 0.4772\n",
      "Optimization Iteration:  19905, Training Accuracy:  79.7%, Loss: 0.3852\n",
      "Optimization Iteration:  19969, Training Accuracy:  78.1%, Loss: 0.3709\n",
      "Optimization Iteration:  20033, Training Accuracy:  75.0%, Loss: 0.4644\n",
      "Optimization Iteration:  20097, Training Accuracy:  71.9%, Loss: 0.4736\n",
      "Optimization Iteration:  20161, Training Accuracy:  75.0%, Loss: 0.4261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  20225, Training Accuracy:  78.1%, Loss: 0.3966\n",
      "Optimization Iteration:  20289, Training Accuracy:  71.9%, Loss: 0.5095\n",
      "Optimization Iteration:  20353, Training Accuracy:  71.9%, Loss: 0.3930\n",
      "Optimization Iteration:  20417, Training Accuracy:  67.2%, Loss: 0.4700\n",
      "Optimization Iteration:  20481, Training Accuracy:  70.3%, Loss: 0.4573\n",
      "Optimization Iteration:  20545, Training Accuracy:  75.0%, Loss: 0.5858\n",
      "Optimization Iteration:  20609, Training Accuracy:  67.2%, Loss: 0.4958\n",
      "Optimization Iteration:  20673, Training Accuracy:  71.9%, Loss: 0.4291\n",
      "Optimization Iteration:  20737, Training Accuracy:  82.8%, Loss: 0.3752\n",
      "Optimization Iteration:  20801, Training Accuracy:  68.8%, Loss: 0.4982\n",
      "Optimization Iteration:  20865, Training Accuracy:  68.8%, Loss: 0.4074\n",
      "Optimization Iteration:  20929, Training Accuracy:  84.4%, Loss: 0.3458\n",
      "Optimization Iteration:  20993, Training Accuracy:  79.7%, Loss: 0.4608\n",
      "Optimization Iteration:  21057, Training Accuracy:  78.1%, Loss: 0.4288\n",
      "Optimization Iteration:  21121, Training Accuracy:  64.1%, Loss: 0.5616\n",
      "Optimization Iteration:  21185, Training Accuracy:  76.6%, Loss: 0.4422\n",
      "Optimization Iteration:  21249, Training Accuracy:  65.6%, Loss: 0.6356\n",
      "Optimization Iteration:  21313, Training Accuracy:  67.2%, Loss: 0.5044\n",
      "Optimization Iteration:  21377, Training Accuracy:  73.4%, Loss: 0.3727\n",
      "Optimization Iteration:  21441, Training Accuracy:  71.9%, Loss: 0.4275\n",
      "Optimization Iteration:  21505, Training Accuracy:  78.1%, Loss: 0.3501\n",
      "Optimization Iteration:  21569, Training Accuracy:  75.0%, Loss: 0.4545\n",
      "Optimization Iteration:  21633, Training Accuracy:  87.5%, Loss: 0.3326\n",
      "Optimization Iteration:  21697, Training Accuracy:  75.0%, Loss: 0.4253\n",
      "Optimization Iteration:  21761, Training Accuracy:  78.1%, Loss: 0.3766\n",
      "Optimization Iteration:  21825, Training Accuracy:  60.9%, Loss: 0.5815\n",
      "Optimization Iteration:  21889, Training Accuracy:  79.7%, Loss: 0.4332\n",
      "Optimization Iteration:  21953, Training Accuracy:  73.4%, Loss: 0.5334\n",
      "Optimization Iteration:  22017, Training Accuracy:  78.1%, Loss: 0.3742\n",
      "Optimization Iteration:  22081, Training Accuracy:  73.4%, Loss: 0.4176\n",
      "Optimization Iteration:  22145, Training Accuracy:  76.6%, Loss: 0.4381\n",
      "Optimization Iteration:  22209, Training Accuracy:  82.8%, Loss: 0.5127\n",
      "Optimization Iteration:  22273, Training Accuracy:  64.1%, Loss: 0.5279\n",
      "Optimization Iteration:  22337, Training Accuracy:  73.4%, Loss: 0.4098\n",
      "Optimization Iteration:  22401, Training Accuracy:  75.0%, Loss: 0.4419\n",
      "Optimization Iteration:  22465, Training Accuracy:  75.0%, Loss: 0.4156\n",
      "Optimization Iteration:  22529, Training Accuracy:  75.0%, Loss: 0.4397\n",
      "Optimization Iteration:  22593, Training Accuracy:  71.9%, Loss: 0.4726\n",
      "Optimization Iteration:  22657, Training Accuracy:  78.1%, Loss: 0.4256\n",
      "Optimization Iteration:  22721, Training Accuracy:  71.9%, Loss: 0.4134\n",
      "Optimization Iteration:  22785, Training Accuracy:  68.8%, Loss: 0.5345\n",
      "Optimization Iteration:  22849, Training Accuracy:  65.6%, Loss: 0.3837\n",
      "Optimization Iteration:  22913, Training Accuracy:  76.6%, Loss: 0.4561\n",
      "Optimization Iteration:  22977, Training Accuracy:  73.4%, Loss: 0.4431\n",
      "Optimization Iteration:  23041, Training Accuracy:  71.9%, Loss: 0.3726\n",
      "Optimization Iteration:  23105, Training Accuracy:  68.8%, Loss: 0.4278\n",
      "Optimization Iteration:  23169, Training Accuracy:  84.4%, Loss: 0.4049\n",
      "Optimization Iteration:  23233, Training Accuracy:  71.9%, Loss: 0.5055\n",
      "Optimization Iteration:  23297, Training Accuracy:  68.8%, Loss: 0.5122\n",
      "Optimization Iteration:  23361, Training Accuracy:  75.0%, Loss: 0.4492\n",
      "Optimization Iteration:  23425, Training Accuracy:  78.1%, Loss: 0.4252\n",
      "Optimization Iteration:  23489, Training Accuracy:  70.3%, Loss: 0.5023\n",
      "Optimization Iteration:  23553, Training Accuracy:  84.4%, Loss: 0.3748\n",
      "Optimization Iteration:  23617, Training Accuracy:  76.6%, Loss: 0.4545\n",
      "Optimization Iteration:  23681, Training Accuracy:  73.4%, Loss: 0.4649\n",
      "Optimization Iteration:  23745, Training Accuracy:  76.6%, Loss: 0.4339\n",
      "Optimization Iteration:  23809, Training Accuracy:  68.8%, Loss: 0.4624\n",
      "Optimization Iteration:  23873, Training Accuracy:  71.9%, Loss: 0.4551\n",
      "Optimization Iteration:  23937, Training Accuracy:  62.5%, Loss: 0.5795\n",
      "Optimization Iteration:  24001, Training Accuracy:  71.9%, Loss: 0.4315\n",
      "Optimization Iteration:  24065, Training Accuracy:  73.4%, Loss: 0.4625\n",
      "Optimization Iteration:  24129, Training Accuracy:  70.3%, Loss: 0.3893\n",
      "Optimization Iteration:  24193, Training Accuracy:  70.3%, Loss: 0.4420\n",
      "Optimization Iteration:  24257, Training Accuracy:  71.9%, Loss: 0.4603\n",
      "Optimization Iteration:  24321, Training Accuracy:  65.6%, Loss: 0.5128\n",
      "Optimization Iteration:  24385, Training Accuracy:  64.1%, Loss: 0.5220\n",
      "Optimization Iteration:  24449, Training Accuracy:  78.1%, Loss: 0.3963\n",
      "Optimization Iteration:  24513, Training Accuracy:  71.9%, Loss: 0.3985\n",
      "Optimization Iteration:  24577, Training Accuracy:  64.1%, Loss: 0.5263\n",
      "Optimization Iteration:  24641, Training Accuracy:  79.7%, Loss: 0.4389\n",
      "Optimization Iteration:  24705, Training Accuracy:  76.6%, Loss: 0.3930\n",
      "Optimization Iteration:  24769, Training Accuracy:  68.8%, Loss: 0.4779\n",
      "Optimization Iteration:  24833, Training Accuracy:  70.3%, Loss: 0.3999\n",
      "Optimization Iteration:  24897, Training Accuracy:  62.5%, Loss: 0.5112\n",
      "Optimization Iteration:  24961, Training Accuracy:  78.1%, Loss: 0.3654\n",
      "Optimization Iteration:  25025, Training Accuracy:  82.8%, Loss: 0.4071\n",
      "Optimization Iteration:  25089, Training Accuracy:  67.2%, Loss: 0.4418\n",
      "Optimization Iteration:  25153, Training Accuracy:  64.1%, Loss: 0.5283\n",
      "Optimization Iteration:  25217, Training Accuracy:  70.3%, Loss: 0.4515\n",
      "Optimization Iteration:  25281, Training Accuracy:  79.7%, Loss: 0.3845\n",
      "Optimization Iteration:  25345, Training Accuracy:  67.2%, Loss: 0.4811\n",
      "Optimization Iteration:  25409, Training Accuracy:  68.8%, Loss: 0.4668\n",
      "Optimization Iteration:  25473, Training Accuracy:  71.9%, Loss: 0.4368\n",
      "Optimization Iteration:  25537, Training Accuracy:  73.4%, Loss: 0.4194\n",
      "Optimization Iteration:  25601, Training Accuracy:  67.2%, Loss: 0.4923\n",
      "Optimization Iteration:  25665, Training Accuracy:  71.9%, Loss: 0.5657\n",
      "Optimization Iteration:  25729, Training Accuracy:  75.0%, Loss: 0.4007\n",
      "Optimization Iteration:  25793, Training Accuracy:  68.8%, Loss: 0.4524\n",
      "Optimization Iteration:  25857, Training Accuracy:  68.8%, Loss: 0.4506\n",
      "Optimization Iteration:  25921, Training Accuracy:  73.4%, Loss: 0.4255\n",
      "Optimization Iteration:  25985, Training Accuracy:  68.8%, Loss: 0.5815\n",
      "Optimization Iteration:  26049, Training Accuracy:  73.4%, Loss: 0.4715\n",
      "Optimization Iteration:  26113, Training Accuracy:  75.0%, Loss: 0.3766\n",
      "Optimization Iteration:  26177, Training Accuracy:  73.4%, Loss: 0.4390\n",
      "Optimization Iteration:  26241, Training Accuracy:  71.9%, Loss: 0.4795\n",
      "Optimization Iteration:  26305, Training Accuracy:  78.1%, Loss: 0.4709\n",
      "Optimization Iteration:  26369, Training Accuracy:  70.3%, Loss: 0.5290\n",
      "Optimization Iteration:  26433, Training Accuracy:  65.6%, Loss: 0.4597\n",
      "Optimization Iteration:  26497, Training Accuracy:  73.4%, Loss: 0.4352\n",
      "Optimization Iteration:  26561, Training Accuracy:  79.7%, Loss: 0.3782\n",
      "Optimization Iteration:  26625, Training Accuracy:  73.4%, Loss: 0.5062\n",
      "Optimization Iteration:  26689, Training Accuracy:  78.1%, Loss: 0.4599\n",
      "Optimization Iteration:  26753, Training Accuracy:  70.3%, Loss: 0.4967\n",
      "Optimization Iteration:  26817, Training Accuracy:  76.6%, Loss: 0.4232\n",
      "Optimization Iteration:  26881, Training Accuracy:  81.2%, Loss: 0.3806\n",
      "Optimization Iteration:  26945, Training Accuracy:  71.9%, Loss: 0.4695\n",
      "Optimization Iteration:  27009, Training Accuracy:  73.4%, Loss: 0.4377\n",
      "Optimization Iteration:  27073, Training Accuracy:  68.8%, Loss: 0.6197\n",
      "Optimization Iteration:  27137, Training Accuracy:  68.8%, Loss: 0.5131\n",
      "Optimization Iteration:  27201, Training Accuracy:  81.2%, Loss: 0.2989\n",
      "Optimization Iteration:  27265, Training Accuracy:  73.4%, Loss: 0.4323\n",
      "Optimization Iteration:  27329, Training Accuracy:  81.2%, Loss: 0.3760\n",
      "Optimization Iteration:  27393, Training Accuracy:  68.8%, Loss: 0.4797\n",
      "Optimization Iteration:  27457, Training Accuracy:  68.8%, Loss: 0.4999\n",
      "Optimization Iteration:  27521, Training Accuracy:  68.8%, Loss: 0.5467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  27585, Training Accuracy:  76.6%, Loss: 0.4703\n",
      "Optimization Iteration:  27649, Training Accuracy:  75.0%, Loss: 0.4618\n",
      "Optimization Iteration:  27713, Training Accuracy:  76.6%, Loss: 0.4254\n",
      "Optimization Iteration:  27777, Training Accuracy:  82.8%, Loss: 0.4012\n",
      "Optimization Iteration:  27841, Training Accuracy:  70.3%, Loss: 0.4856\n",
      "Optimization Iteration:  27905, Training Accuracy:  75.0%, Loss: 0.4237\n",
      "Optimization Iteration:  27969, Training Accuracy:  68.8%, Loss: 0.4935\n",
      "Optimization Iteration:  28033, Training Accuracy:  76.6%, Loss: 0.3992\n",
      "Optimization Iteration:  28097, Training Accuracy:  79.7%, Loss: 0.4257\n",
      "Optimization Iteration:  28161, Training Accuracy:  85.9%, Loss: 0.3674\n",
      "Optimization Iteration:  28225, Training Accuracy:  68.8%, Loss: 0.4731\n",
      "Optimization Iteration:  28289, Training Accuracy:  76.6%, Loss: 0.4573\n",
      "Optimization Iteration:  28353, Training Accuracy:  73.4%, Loss: 0.4502\n",
      "Optimization Iteration:  28417, Training Accuracy:  78.1%, Loss: 0.4166\n",
      "Optimization Iteration:  28481, Training Accuracy:  70.3%, Loss: 0.4805\n",
      "Optimization Iteration:  28545, Training Accuracy:  75.0%, Loss: 0.3313\n",
      "Optimization Iteration:  28609, Training Accuracy:  84.4%, Loss: 0.3773\n",
      "Optimization Iteration:  28673, Training Accuracy:  71.9%, Loss: 0.4839\n",
      "Optimization Iteration:  28737, Training Accuracy:  70.3%, Loss: 0.4578\n",
      "Optimization Iteration:  28801, Training Accuracy:  75.0%, Loss: 0.4306\n",
      "Optimization Iteration:  28865, Training Accuracy:  81.2%, Loss: 0.3406\n",
      "Optimization Iteration:  28929, Training Accuracy:  79.7%, Loss: 0.3816\n",
      "Optimization Iteration:  28993, Training Accuracy:  70.3%, Loss: 0.4853\n",
      "Optimization Iteration:  29057, Training Accuracy:  70.3%, Loss: 0.4261\n",
      "Optimization Iteration:  29121, Training Accuracy:  71.9%, Loss: 0.5589\n",
      "Optimization Iteration:  29185, Training Accuracy:  78.1%, Loss: 0.3312\n",
      "Optimization Iteration:  29249, Training Accuracy:  79.7%, Loss: 0.3863\n",
      "Optimization Iteration:  29313, Training Accuracy:  64.1%, Loss: 0.5659\n",
      "Optimization Iteration:  29377, Training Accuracy:  71.9%, Loss: 0.4479\n",
      "Optimization Iteration:  29441, Training Accuracy:  70.3%, Loss: 0.5421\n",
      "Optimization Iteration:  29505, Training Accuracy:  68.8%, Loss: 0.5112\n",
      "Optimization Iteration:  29569, Training Accuracy:  67.2%, Loss: 0.4856\n",
      "Optimization Iteration:  29633, Training Accuracy:  65.6%, Loss: 0.4884\n",
      "Optimization Iteration:  29697, Training Accuracy:  79.7%, Loss: 0.4320\n",
      "Optimization Iteration:  29761, Training Accuracy:  78.1%, Loss: 0.4434\n",
      "Optimization Iteration:  29825, Training Accuracy:  64.1%, Loss: 0.5359\n",
      "Optimization Iteration:  29889, Training Accuracy:  76.6%, Loss: 0.4251\n",
      "Optimization Iteration:  29953, Training Accuracy:  65.6%, Loss: 0.5243\n",
      "Optimization Iteration:  30017, Training Accuracy:  76.6%, Loss: 0.3668\n",
      "Optimization Iteration:  30081, Training Accuracy:  71.9%, Loss: 0.4442\n",
      "Optimization Iteration:  30145, Training Accuracy:  75.0%, Loss: 0.3988\n",
      "Optimization Iteration:  30209, Training Accuracy:  76.6%, Loss: 0.4094\n",
      "Optimization Iteration:  30273, Training Accuracy:  67.2%, Loss: 0.4709\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.3683\n",
      "Optimization Iteration:  30401, Training Accuracy:  71.9%, Loss: 0.4257\n",
      "Optimization Iteration:  30465, Training Accuracy:  70.3%, Loss: 0.5296\n",
      "Optimization Iteration:  30529, Training Accuracy:  75.0%, Loss: 0.4656\n",
      "Optimization Iteration:  30593, Training Accuracy:  75.0%, Loss: 0.4391\n",
      "Optimization Iteration:  30657, Training Accuracy:  73.4%, Loss: 0.4429\n",
      "Optimization Iteration:  30721, Training Accuracy:  79.7%, Loss: 0.4032\n",
      "Optimization Iteration:  30785, Training Accuracy:  62.5%, Loss: 0.4570\n",
      "Optimization Iteration:  30849, Training Accuracy:  73.4%, Loss: 0.4787\n",
      "Optimization Iteration:  30913, Training Accuracy:  81.2%, Loss: 0.3928\n",
      "Optimization Iteration:  30977, Training Accuracy:  70.3%, Loss: 0.4193\n",
      "Optimization Iteration:  31041, Training Accuracy:  75.0%, Loss: 0.4540\n",
      "Optimization Iteration:  31105, Training Accuracy:  73.4%, Loss: 0.4139\n",
      "Optimization Iteration:  31169, Training Accuracy:  73.4%, Loss: 0.3735\n",
      "Optimization Iteration:  31233, Training Accuracy:  75.0%, Loss: 0.4415\n",
      "Optimization Iteration:  31297, Training Accuracy:  75.0%, Loss: 0.3740\n",
      "Optimization Iteration:  31361, Training Accuracy:  71.9%, Loss: 0.4348\n",
      "Optimization Iteration:  31425, Training Accuracy:  81.2%, Loss: 0.4602\n",
      "Optimization Iteration:  31489, Training Accuracy:  84.4%, Loss: 0.4019\n",
      "Optimization Iteration:  31553, Training Accuracy:  67.2%, Loss: 0.5628\n",
      "Optimization Iteration:  31617, Training Accuracy:  71.9%, Loss: 0.4662\n",
      "Optimization Iteration:  31681, Training Accuracy:  71.9%, Loss: 0.4885\n",
      "Optimization Iteration:  31745, Training Accuracy:  71.9%, Loss: 0.4627\n",
      "Optimization Iteration:  31809, Training Accuracy:  68.8%, Loss: 0.5064\n",
      "Optimization Iteration:  31873, Training Accuracy:  79.7%, Loss: 0.3770\n",
      "Optimization Iteration:  31937, Training Accuracy:  67.2%, Loss: 0.5115\n",
      "Optimization Iteration:  32001, Training Accuracy:  75.0%, Loss: 0.4105\n",
      "Optimization Iteration:  32065, Training Accuracy:  70.3%, Loss: 0.4375\n",
      "Optimization Iteration:  32129, Training Accuracy:  62.5%, Loss: 0.5533\n",
      "Optimization Iteration:  32193, Training Accuracy:  70.3%, Loss: 0.5135\n",
      "Optimization Iteration:  32257, Training Accuracy:  73.4%, Loss: 0.4649\n",
      "Optimization Iteration:  32321, Training Accuracy:  84.4%, Loss: 0.3693\n",
      "Optimization Iteration:  32385, Training Accuracy:  73.4%, Loss: 0.4586\n",
      "Optimization Iteration:  32449, Training Accuracy:  78.1%, Loss: 0.4342\n",
      "Optimization Iteration:  32513, Training Accuracy:  78.1%, Loss: 0.3745\n",
      "Optimization Iteration:  32577, Training Accuracy:  76.6%, Loss: 0.4819\n",
      "Optimization Iteration:  32641, Training Accuracy:  73.4%, Loss: 0.4930\n",
      "Optimization Iteration:  32705, Training Accuracy:  78.1%, Loss: 0.4476\n",
      "Optimization Iteration:  32769, Training Accuracy:  68.8%, Loss: 0.4130\n",
      "Optimization Iteration:  32833, Training Accuracy:  76.6%, Loss: 0.3889\n",
      "Optimization Iteration:  32897, Training Accuracy:  73.4%, Loss: 0.5160\n",
      "Optimization Iteration:  32961, Training Accuracy:  75.0%, Loss: 0.5537\n",
      "Optimization Iteration:  33025, Training Accuracy:  73.4%, Loss: 0.4110\n",
      "Optimization Iteration:  33089, Training Accuracy:  73.4%, Loss: 0.5324\n",
      "Optimization Iteration:  33153, Training Accuracy:  73.4%, Loss: 0.4166\n",
      "Optimization Iteration:  33217, Training Accuracy:  79.7%, Loss: 0.3762\n",
      "Optimization Iteration:  33281, Training Accuracy:  71.9%, Loss: 0.5040\n",
      "Optimization Iteration:  33345, Training Accuracy:  71.9%, Loss: 0.4540\n",
      "Optimization Iteration:  33409, Training Accuracy:  70.3%, Loss: 0.4709\n",
      "Optimization Iteration:  33473, Training Accuracy:  68.8%, Loss: 0.4892\n",
      "Optimization Iteration:  33537, Training Accuracy:  73.4%, Loss: 0.4731\n",
      "Optimization Iteration:  33601, Training Accuracy:  75.0%, Loss: 0.4194\n",
      "Optimization Iteration:  33665, Training Accuracy:  73.4%, Loss: 0.4208\n",
      "Optimization Iteration:  33729, Training Accuracy:  67.2%, Loss: 0.6680\n",
      "Optimization Iteration:  33793, Training Accuracy:  67.2%, Loss: 0.5546\n",
      "Optimization Iteration:  33857, Training Accuracy:  75.0%, Loss: 0.4456\n",
      "Optimization Iteration:  33921, Training Accuracy:  71.9%, Loss: 0.4530\n",
      "Optimization Iteration:  33985, Training Accuracy:  68.8%, Loss: 0.4663\n",
      "Optimization Iteration:  34049, Training Accuracy:  71.9%, Loss: 0.4732\n",
      "Optimization Iteration:  34113, Training Accuracy:  71.9%, Loss: 0.3965\n",
      "Optimization Iteration:  34177, Training Accuracy:  71.9%, Loss: 0.3806\n",
      "Optimization Iteration:  34241, Training Accuracy:  78.1%, Loss: 0.3954\n",
      "Optimization Iteration:  34305, Training Accuracy:  67.2%, Loss: 0.4981\n",
      "Optimization Iteration:  34369, Training Accuracy:  85.9%, Loss: 0.3630\n",
      "Optimization Iteration:  34433, Training Accuracy:  78.1%, Loss: 0.5571\n",
      "Optimization Iteration:  34497, Training Accuracy:  82.8%, Loss: 0.3416\n",
      "Optimization Iteration:  34561, Training Accuracy:  78.1%, Loss: 0.4726\n",
      "Optimization Iteration:  34625, Training Accuracy:  73.4%, Loss: 0.5085\n",
      "Optimization Iteration:  34689, Training Accuracy:  71.9%, Loss: 0.4522\n",
      "Optimization Iteration:  34753, Training Accuracy:  75.0%, Loss: 0.4528\n",
      "Optimization Iteration:  34817, Training Accuracy:  76.6%, Loss: 0.4411\n",
      "Optimization Iteration:  34881, Training Accuracy:  78.1%, Loss: 0.4117\n",
      "Optimization Iteration:  34945, Training Accuracy:  76.6%, Loss: 0.4297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  35009, Training Accuracy:  81.2%, Loss: 0.3846\n",
      "Optimization Iteration:  35073, Training Accuracy:  82.8%, Loss: 0.3996\n",
      "Optimization Iteration:  35137, Training Accuracy:  82.8%, Loss: 0.3631\n",
      "Optimization Iteration:  35201, Training Accuracy:  75.0%, Loss: 0.3876\n",
      "Optimization Iteration:  35265, Training Accuracy:  81.2%, Loss: 0.3945\n",
      "Optimization Iteration:  35329, Training Accuracy:  68.8%, Loss: 0.4905\n",
      "Optimization Iteration:  35393, Training Accuracy:  70.3%, Loss: 0.3844\n",
      "Optimization Iteration:  35457, Training Accuracy:  78.1%, Loss: 0.4006\n",
      "Optimization Iteration:  35521, Training Accuracy:  59.4%, Loss: 0.4803\n",
      "Optimization Iteration:  35585, Training Accuracy:  89.1%, Loss: 0.2753\n",
      "Optimization Iteration:  35649, Training Accuracy:  67.2%, Loss: 0.4409\n",
      "Optimization Iteration:  35713, Training Accuracy:  79.7%, Loss: 0.4084\n",
      "Optimization Iteration:  35777, Training Accuracy:  75.0%, Loss: 0.3716\n",
      "Optimization Iteration:  35841, Training Accuracy:  73.4%, Loss: 0.4282\n",
      "Optimization Iteration:  35905, Training Accuracy:  75.0%, Loss: 0.4406\n",
      "Optimization Iteration:  35969, Training Accuracy:  70.3%, Loss: 0.4807\n",
      "Optimization Iteration:  36033, Training Accuracy:  75.0%, Loss: 0.3873\n",
      "Optimization Iteration:  36097, Training Accuracy:  71.9%, Loss: 0.4810\n",
      "Optimization Iteration:  36161, Training Accuracy:  73.4%, Loss: 0.4112\n",
      "Optimization Iteration:  36225, Training Accuracy:  67.2%, Loss: 0.4436\n",
      "Optimization Iteration:  36289, Training Accuracy:  70.3%, Loss: 0.4354\n",
      "Optimization Iteration:  36353, Training Accuracy:  64.1%, Loss: 0.4867\n",
      "Optimization Iteration:  36417, Training Accuracy:  82.8%, Loss: 0.4129\n",
      "Optimization Iteration:  36481, Training Accuracy:  78.1%, Loss: 0.3560\n",
      "Optimization Iteration:  36545, Training Accuracy:  79.7%, Loss: 0.3994\n",
      "Optimization Iteration:  36609, Training Accuracy:  75.0%, Loss: 0.4331\n",
      "Optimization Iteration:  36673, Training Accuracy:  81.2%, Loss: 0.3875\n",
      "Optimization Iteration:  36737, Training Accuracy:  76.6%, Loss: 0.4587\n",
      "Optimization Iteration:  36801, Training Accuracy:  76.6%, Loss: 0.3792\n",
      "Optimization Iteration:  36865, Training Accuracy:  79.7%, Loss: 0.4077\n",
      "Optimization Iteration:  36929, Training Accuracy:  82.8%, Loss: 0.4021\n",
      "Optimization Iteration:  36993, Training Accuracy:  67.2%, Loss: 0.4924\n",
      "Optimization Iteration:  37057, Training Accuracy:  75.0%, Loss: 0.4073\n",
      "Optimization Iteration:  37121, Training Accuracy:  71.9%, Loss: 0.4804\n",
      "Optimization Iteration:  37185, Training Accuracy:  71.9%, Loss: 0.3967\n",
      "Optimization Iteration:  37249, Training Accuracy:  71.9%, Loss: 0.6628\n",
      "Optimization Iteration:  37313, Training Accuracy:  82.8%, Loss: 0.3713\n",
      "Optimization Iteration:  37377, Training Accuracy:  67.2%, Loss: 0.4877\n",
      "Optimization Iteration:  37441, Training Accuracy:  79.7%, Loss: 0.4047\n",
      "Optimization Iteration:  37505, Training Accuracy:  70.3%, Loss: 0.5897\n",
      "Optimization Iteration:  37569, Training Accuracy:  64.1%, Loss: 0.5059\n",
      "Optimization Iteration:  37633, Training Accuracy:  65.6%, Loss: 0.5927\n",
      "Optimization Iteration:  37697, Training Accuracy:  68.8%, Loss: 0.4726\n",
      "Optimization Iteration:  37761, Training Accuracy:  71.9%, Loss: 0.3905\n",
      "Optimization Iteration:  37825, Training Accuracy:  79.7%, Loss: 0.4012\n",
      "Optimization Iteration:  37889, Training Accuracy:  78.1%, Loss: 0.3871\n",
      "Optimization Iteration:  37953, Training Accuracy:  79.7%, Loss: 0.3427\n",
      "Optimization Iteration:  38017, Training Accuracy:  73.4%, Loss: 0.4745\n",
      "Optimization Iteration:  38081, Training Accuracy:  75.0%, Loss: 0.4448\n",
      "Optimization Iteration:  38145, Training Accuracy:  68.8%, Loss: 0.4020\n",
      "Optimization Iteration:  38209, Training Accuracy:  79.7%, Loss: 0.4173\n",
      "Optimization Iteration:  38273, Training Accuracy:  75.0%, Loss: 0.3841\n",
      "Optimization Iteration:  38337, Training Accuracy:  78.1%, Loss: 0.2899\n",
      "Optimization Iteration:  38401, Training Accuracy:  70.3%, Loss: 0.4993\n",
      "Optimization Iteration:  38465, Training Accuracy:  65.6%, Loss: 0.4883\n",
      "Optimization Iteration:  38529, Training Accuracy:  78.1%, Loss: 0.4764\n",
      "Optimization Iteration:  38593, Training Accuracy:  67.2%, Loss: 0.5835\n",
      "Optimization Iteration:  38657, Training Accuracy:  73.4%, Loss: 0.5234\n",
      "Optimization Iteration:  38721, Training Accuracy:  68.8%, Loss: 0.3770\n",
      "Optimization Iteration:  38785, Training Accuracy:  70.3%, Loss: 0.4566\n",
      "Optimization Iteration:  38849, Training Accuracy:  70.3%, Loss: 0.4245\n",
      "Optimization Iteration:  38913, Training Accuracy:  85.9%, Loss: 0.3667\n",
      "Optimization Iteration:  38977, Training Accuracy:  73.4%, Loss: 0.4239\n",
      "Optimization Iteration:  39041, Training Accuracy:  68.8%, Loss: 0.5953\n",
      "Optimization Iteration:  39105, Training Accuracy:  71.9%, Loss: 0.4714\n",
      "Optimization Iteration:  39169, Training Accuracy:  76.6%, Loss: 0.3944\n",
      "Optimization Iteration:  39233, Training Accuracy:  71.9%, Loss: 0.5184\n",
      "Optimization Iteration:  39297, Training Accuracy:  78.1%, Loss: 0.3890\n",
      "Optimization Iteration:  39361, Training Accuracy:  87.5%, Loss: 0.3868\n",
      "Optimization Iteration:  39425, Training Accuracy:  73.4%, Loss: 0.4960\n",
      "Optimization Iteration:  39489, Training Accuracy:  68.8%, Loss: 0.4223\n",
      "Optimization Iteration:  39553, Training Accuracy:  75.0%, Loss: 0.3999\n",
      "Optimization Iteration:  39617, Training Accuracy:  70.3%, Loss: 0.4670\n",
      "Optimization Iteration:  39681, Training Accuracy:  71.9%, Loss: 0.4621\n",
      "Optimization Iteration:  39745, Training Accuracy:  78.1%, Loss: 0.3947\n",
      "Optimization Iteration:  39809, Training Accuracy:  62.5%, Loss: 0.5785\n",
      "Optimization Iteration:  39873, Training Accuracy:  71.9%, Loss: 0.4399\n",
      "Optimization Iteration:  39937, Training Accuracy:  67.2%, Loss: 0.4703\n",
      "Optimization Iteration:  40001, Training Accuracy:  64.1%, Loss: 0.4848\n",
      "Optimization Iteration:  40065, Training Accuracy:  70.3%, Loss: 0.3974\n",
      "Optimization Iteration:  40129, Training Accuracy:  82.8%, Loss: 0.3376\n",
      "Optimization Iteration:  40193, Training Accuracy:  79.7%, Loss: 0.4424\n",
      "Optimization Iteration:  40257, Training Accuracy:  67.2%, Loss: 0.4328\n",
      "Optimization Iteration:  40321, Training Accuracy:  70.3%, Loss: 0.4315\n",
      "Optimization Iteration:  40385, Training Accuracy:  78.1%, Loss: 0.5643\n",
      "Optimization Iteration:  40449, Training Accuracy:  76.6%, Loss: 0.4449\n",
      "Optimization Iteration:  40513, Training Accuracy:  73.4%, Loss: 0.4164\n",
      "Optimization Iteration:  40577, Training Accuracy:  76.6%, Loss: 0.3934\n",
      "Optimization Iteration:  40641, Training Accuracy:  73.4%, Loss: 0.4252\n",
      "Optimization Iteration:  40705, Training Accuracy:  73.4%, Loss: 0.4836\n",
      "Optimization Iteration:  40769, Training Accuracy:  76.6%, Loss: 0.3749\n",
      "Optimization Iteration:  40833, Training Accuracy:  81.2%, Loss: 0.3471\n",
      "Optimization Iteration:  40897, Training Accuracy:  75.0%, Loss: 0.4236\n",
      "Optimization Iteration:  40961, Training Accuracy:  79.7%, Loss: 0.3741\n",
      "Optimization Iteration:  41025, Training Accuracy:  79.7%, Loss: 0.3821\n",
      "Optimization Iteration:  41089, Training Accuracy:  82.8%, Loss: 0.3754\n",
      "Optimization Iteration:  41153, Training Accuracy:  84.4%, Loss: 0.4089\n",
      "Optimization Iteration:  41217, Training Accuracy:  84.4%, Loss: 0.3343\n",
      "Optimization Iteration:  41281, Training Accuracy:  71.9%, Loss: 0.4646\n",
      "Optimization Iteration:  41345, Training Accuracy:  73.4%, Loss: 0.4240\n",
      "Optimization Iteration:  41409, Training Accuracy:  76.6%, Loss: 0.4158\n",
      "Optimization Iteration:  41473, Training Accuracy:  70.3%, Loss: 0.4998\n",
      "Optimization Iteration:  41537, Training Accuracy:  79.7%, Loss: 0.4701\n",
      "Optimization Iteration:  41601, Training Accuracy:  71.9%, Loss: 0.4501\n",
      "Optimization Iteration:  41665, Training Accuracy:  78.1%, Loss: 0.3929\n",
      "Optimization Iteration:  41729, Training Accuracy:  71.9%, Loss: 0.4273\n",
      "Optimization Iteration:  41793, Training Accuracy:  79.7%, Loss: 0.4422\n",
      "Optimization Iteration:  41857, Training Accuracy:  70.3%, Loss: 0.4680\n",
      "Optimization Iteration:  41921, Training Accuracy:  75.0%, Loss: 0.4357\n",
      "Optimization Iteration:  41985, Training Accuracy:  67.2%, Loss: 0.4973\n",
      "Optimization Iteration:  42049, Training Accuracy:  70.3%, Loss: 0.5075\n",
      "Optimization Iteration:  42113, Training Accuracy:  64.1%, Loss: 0.5302\n",
      "Optimization Iteration:  42177, Training Accuracy:  71.9%, Loss: 0.4426\n",
      "Optimization Iteration:  42241, Training Accuracy:  70.3%, Loss: 0.4474\n",
      "Optimization Iteration:  42305, Training Accuracy:  81.2%, Loss: 0.4570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  42369, Training Accuracy:  76.6%, Loss: 0.4890\n",
      "Optimization Iteration:  42433, Training Accuracy:  62.5%, Loss: 0.4740\n",
      "Optimization Iteration:  42497, Training Accuracy:  70.3%, Loss: 0.4456\n",
      "Optimization Iteration:  42561, Training Accuracy:  79.7%, Loss: 0.3953\n",
      "Optimization Iteration:  42625, Training Accuracy:  78.1%, Loss: 0.3826\n",
      "Optimization Iteration:  42689, Training Accuracy:  60.9%, Loss: 0.4034\n",
      "Optimization Iteration:  42753, Training Accuracy:  73.4%, Loss: 0.4546\n",
      "Optimization Iteration:  42817, Training Accuracy:  81.2%, Loss: 0.3681\n",
      "Optimization Iteration:  42881, Training Accuracy:  64.1%, Loss: 0.5332\n",
      "Optimization Iteration:  42945, Training Accuracy:  73.4%, Loss: 0.4496\n",
      "Optimization Iteration:  43009, Training Accuracy:  68.8%, Loss: 0.5121\n",
      "Optimization Iteration:  43073, Training Accuracy:  73.4%, Loss: 0.4194\n",
      "Optimization Iteration:  43137, Training Accuracy:  75.0%, Loss: 0.4175\n",
      "Optimization Iteration:  43201, Training Accuracy:  68.8%, Loss: 0.5056\n",
      "Optimization Iteration:  43265, Training Accuracy:  68.8%, Loss: 0.4054\n",
      "Optimization Iteration:  43329, Training Accuracy:  78.1%, Loss: 0.5147\n",
      "Optimization Iteration:  43393, Training Accuracy:  73.4%, Loss: 0.4153\n",
      "Optimization Iteration:  43457, Training Accuracy:  81.2%, Loss: 0.4360\n",
      "Optimization Iteration:  43521, Training Accuracy:  79.7%, Loss: 0.4419\n",
      "Optimization Iteration:  43585, Training Accuracy:  78.1%, Loss: 0.4052\n",
      "Optimization Iteration:  43649, Training Accuracy:  70.3%, Loss: 0.4696\n",
      "Optimization Iteration:  43713, Training Accuracy:  73.4%, Loss: 0.4799\n",
      "Optimization Iteration:  43777, Training Accuracy:  81.2%, Loss: 0.3940\n",
      "Optimization Iteration:  43841, Training Accuracy:  67.2%, Loss: 0.5284\n",
      "Optimization Iteration:  43905, Training Accuracy:  78.1%, Loss: 0.4092\n",
      "Optimization Iteration:  43969, Training Accuracy:  75.0%, Loss: 0.4151\n",
      "Optimization Iteration:  44033, Training Accuracy:  75.0%, Loss: 0.4265\n",
      "Optimization Iteration:  44097, Training Accuracy:  78.1%, Loss: 0.3707\n",
      "Optimization Iteration:  44161, Training Accuracy:  84.4%, Loss: 0.3546\n",
      "Optimization Iteration:  44225, Training Accuracy:  68.8%, Loss: 0.5471\n",
      "Optimization Iteration:  44289, Training Accuracy:  78.1%, Loss: 0.5062\n",
      "Optimization Iteration:  44353, Training Accuracy:  79.7%, Loss: 0.4494\n",
      "Optimization Iteration:  44417, Training Accuracy:  76.6%, Loss: 0.4268\n",
      "Optimization Iteration:  44481, Training Accuracy:  68.8%, Loss: 0.4262\n",
      "Optimization Iteration:  44545, Training Accuracy:  68.8%, Loss: 0.3913\n",
      "Optimization Iteration:  44609, Training Accuracy:  70.3%, Loss: 0.3862\n",
      "Optimization Iteration:  44673, Training Accuracy:  78.1%, Loss: 0.4773\n",
      "Optimization Iteration:  44737, Training Accuracy:  67.2%, Loss: 0.4569\n",
      "Optimization Iteration:  44801, Training Accuracy:  73.4%, Loss: 0.5097\n",
      "Optimization Iteration:  44865, Training Accuracy:  67.2%, Loss: 0.4826\n",
      "Optimization Iteration:  44929, Training Accuracy:  71.9%, Loss: 0.4638\n",
      "Optimization Iteration:  44993, Training Accuracy:  73.4%, Loss: 0.3811\n",
      "Optimization Iteration:  45057, Training Accuracy:  73.4%, Loss: 0.4440\n",
      "Optimization Iteration:  45121, Training Accuracy:  78.1%, Loss: 0.4515\n",
      "Optimization Iteration:  45185, Training Accuracy:  84.4%, Loss: 0.3787\n",
      "Optimization Iteration:  45249, Training Accuracy:  71.9%, Loss: 0.4620\n",
      "Optimization Iteration:  45313, Training Accuracy:  73.4%, Loss: 0.4244\n",
      "Optimization Iteration:  45377, Training Accuracy:  73.4%, Loss: 0.5163\n",
      "Optimization Iteration:  45441, Training Accuracy:  82.8%, Loss: 0.3774\n",
      "Optimization Iteration:  45505, Training Accuracy:  71.9%, Loss: 0.4580\n",
      "Optimization Iteration:  45569, Training Accuracy:  68.8%, Loss: 0.4596\n",
      "Optimization Iteration:  45633, Training Accuracy:  75.0%, Loss: 0.4952\n",
      "Optimization Iteration:  45697, Training Accuracy:  82.8%, Loss: 0.3803\n",
      "Optimization Iteration:  45761, Training Accuracy:  78.1%, Loss: 0.4198\n",
      "Optimization Iteration:  45825, Training Accuracy:  76.6%, Loss: 0.4302\n",
      "Optimization Iteration:  45889, Training Accuracy:  75.0%, Loss: 0.4236\n",
      "Optimization Iteration:  45953, Training Accuracy:  78.1%, Loss: 0.4155\n",
      "Optimization Iteration:  46017, Training Accuracy:  75.0%, Loss: 0.4025\n",
      "Optimization Iteration:  46081, Training Accuracy:  68.8%, Loss: 0.4335\n",
      "Optimization Iteration:  46145, Training Accuracy:  71.9%, Loss: 0.4762\n",
      "Optimization Iteration:  46209, Training Accuracy:  75.0%, Loss: 0.3885\n",
      "Optimization Iteration:  46273, Training Accuracy:  68.8%, Loss: 0.4994\n",
      "Optimization Iteration:  46337, Training Accuracy:  73.4%, Loss: 0.4775\n",
      "Optimization Iteration:  46401, Training Accuracy:  89.1%, Loss: 0.3290\n",
      "Optimization Iteration:  46465, Training Accuracy:  73.4%, Loss: 0.4380\n",
      "Optimization Iteration:  46529, Training Accuracy:  78.1%, Loss: 0.3963\n",
      "Optimization Iteration:  46593, Training Accuracy:  78.1%, Loss: 0.4058\n",
      "Optimization Iteration:  46657, Training Accuracy:  68.8%, Loss: 0.4799\n",
      "Optimization Iteration:  46721, Training Accuracy:  71.9%, Loss: 0.4306\n",
      "Optimization Iteration:  46785, Training Accuracy:  64.1%, Loss: 0.5192\n",
      "Optimization Iteration:  46849, Training Accuracy:  75.0%, Loss: 0.3830\n",
      "Optimization Iteration:  46913, Training Accuracy:  75.0%, Loss: 0.4475\n",
      "Optimization Iteration:  46977, Training Accuracy:  71.9%, Loss: 0.4605\n",
      "Optimization Iteration:  47041, Training Accuracy:  76.6%, Loss: 0.4517\n",
      "Optimization Iteration:  47105, Training Accuracy:  70.3%, Loss: 0.4865\n",
      "Optimization Iteration:  47169, Training Accuracy:  73.4%, Loss: 0.4968\n",
      "Optimization Iteration:  47233, Training Accuracy:  71.9%, Loss: 0.4204\n",
      "Optimization Iteration:  47297, Training Accuracy:  71.9%, Loss: 0.4164\n",
      "Optimization Iteration:  47361, Training Accuracy:  81.2%, Loss: 0.3748\n",
      "Optimization Iteration:  47425, Training Accuracy:  71.9%, Loss: 0.4505\n",
      "Optimization Iteration:  47489, Training Accuracy:  81.2%, Loss: 0.3683\n",
      "Optimization Iteration:  47553, Training Accuracy:  70.3%, Loss: 0.4733\n",
      "Optimization Iteration:  47617, Training Accuracy:  71.9%, Loss: 0.5135\n",
      "Optimization Iteration:  47681, Training Accuracy:  76.6%, Loss: 0.3113\n",
      "Optimization Iteration:  47745, Training Accuracy:  75.0%, Loss: 0.4322\n",
      "Optimization Iteration:  47809, Training Accuracy:  73.4%, Loss: 0.4707\n",
      "Optimization Iteration:  47873, Training Accuracy:  78.1%, Loss: 0.3523\n",
      "Optimization Iteration:  47937, Training Accuracy:  65.6%, Loss: 0.4843\n",
      "Optimization Iteration:  48001, Training Accuracy:  73.4%, Loss: 0.4319\n",
      "Optimization Iteration:  48065, Training Accuracy:  76.6%, Loss: 0.4279\n",
      "Optimization Iteration:  48129, Training Accuracy:  70.3%, Loss: 0.5431\n",
      "Optimization Iteration:  48193, Training Accuracy:  62.5%, Loss: 0.4884\n",
      "Optimization Iteration:  48257, Training Accuracy:  70.3%, Loss: 0.4381\n",
      "Optimization Iteration:  48321, Training Accuracy:  78.1%, Loss: 0.3999\n",
      "Optimization Iteration:  48385, Training Accuracy:  75.0%, Loss: 0.4906\n",
      "Optimization Iteration:  48449, Training Accuracy:  76.6%, Loss: 0.4262\n",
      "Optimization Iteration:  48513, Training Accuracy:  73.4%, Loss: 0.4185\n",
      "Optimization Iteration:  48577, Training Accuracy:  68.8%, Loss: 0.5052\n",
      "Optimization Iteration:  48641, Training Accuracy:  78.1%, Loss: 0.3735\n",
      "Optimization Iteration:  48705, Training Accuracy:  79.7%, Loss: 0.3739\n",
      "Optimization Iteration:  48769, Training Accuracy:  79.7%, Loss: 0.3834\n",
      "Optimization Iteration:  48833, Training Accuracy:  76.6%, Loss: 0.4423\n",
      "Optimization Iteration:  48897, Training Accuracy:  70.3%, Loss: 0.5945\n",
      "Optimization Iteration:  48961, Training Accuracy:  75.0%, Loss: 0.4594\n",
      "Optimization Iteration:  49025, Training Accuracy:  71.9%, Loss: 0.4834\n",
      "Optimization Iteration:  49089, Training Accuracy:  76.6%, Loss: 0.3915\n",
      "Optimization Iteration:  49153, Training Accuracy:  73.4%, Loss: 0.3985\n",
      "Optimization Iteration:  49217, Training Accuracy:  78.1%, Loss: 0.3693\n",
      "Optimization Iteration:  49281, Training Accuracy:  64.1%, Loss: 0.4722\n",
      "Optimization Iteration:  49345, Training Accuracy:  73.4%, Loss: 0.5008\n",
      "Optimization Iteration:  49409, Training Accuracy:  75.0%, Loss: 0.4029\n",
      "Optimization Iteration:  49473, Training Accuracy:  71.9%, Loss: 0.4212\n",
      "Optimization Iteration:  49537, Training Accuracy:  76.6%, Loss: 0.3882\n",
      "Optimization Iteration:  49601, Training Accuracy:  71.9%, Loss: 0.4357\n",
      "Optimization Iteration:  49665, Training Accuracy:  79.7%, Loss: 0.3757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  49729, Training Accuracy:  79.7%, Loss: 0.4223\n",
      "Optimization Iteration:  49793, Training Accuracy:  64.1%, Loss: 0.4081\n",
      "Optimization Iteration:  49857, Training Accuracy:  60.9%, Loss: 0.5196\n",
      "Optimization Iteration:  49921, Training Accuracy:  81.2%, Loss: 0.3634\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 6\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  76.6%, Loss: 0.4732\n",
      "Optimization Iteration:    129, Training Accuracy:  73.4%, Loss: 0.5087\n",
      "Optimization Iteration:    193, Training Accuracy:  68.8%, Loss: 0.4671\n",
      "Optimization Iteration:    257, Training Accuracy:  71.9%, Loss: 0.3730\n",
      "Optimization Iteration:    321, Training Accuracy:  78.1%, Loss: 0.4083\n",
      "Optimization Iteration:    385, Training Accuracy:  78.1%, Loss: 0.4041\n",
      "Optimization Iteration:    449, Training Accuracy:  75.0%, Loss: 0.4062\n",
      "Optimization Iteration:    513, Training Accuracy:  75.0%, Loss: 0.3950\n",
      "Optimization Iteration:    577, Training Accuracy:  68.8%, Loss: 0.4407\n",
      "Optimization Iteration:    641, Training Accuracy:  81.2%, Loss: 0.4130\n",
      "Optimization Iteration:    705, Training Accuracy:  71.9%, Loss: 0.5140\n",
      "Optimization Iteration:    769, Training Accuracy:  75.0%, Loss: 0.4326\n",
      "Optimization Iteration:    833, Training Accuracy:  81.2%, Loss: 0.4219\n",
      "Optimization Iteration:    897, Training Accuracy:  79.7%, Loss: 0.3508\n",
      "Optimization Iteration:    961, Training Accuracy:  78.1%, Loss: 0.3703\n",
      "Optimization Iteration:   1025, Training Accuracy:  71.9%, Loss: 0.4378\n",
      "Optimization Iteration:   1089, Training Accuracy:  71.9%, Loss: 0.4788\n",
      "Optimization Iteration:   1153, Training Accuracy:  71.9%, Loss: 0.4450\n",
      "Optimization Iteration:   1217, Training Accuracy:  78.1%, Loss: 0.4091\n",
      "Optimization Iteration:   1281, Training Accuracy:  68.8%, Loss: 0.4189\n",
      "Optimization Iteration:   1345, Training Accuracy:  65.6%, Loss: 0.4353\n",
      "Optimization Iteration:   1409, Training Accuracy:  78.1%, Loss: 0.4187\n",
      "Optimization Iteration:   1473, Training Accuracy:  65.6%, Loss: 0.4437\n",
      "Optimization Iteration:   1537, Training Accuracy:  67.2%, Loss: 0.4407\n",
      "Optimization Iteration:   1601, Training Accuracy:  76.6%, Loss: 0.3812\n",
      "Optimization Iteration:   1665, Training Accuracy:  62.5%, Loss: 0.4013\n",
      "Optimization Iteration:   1729, Training Accuracy:  65.6%, Loss: 0.5127\n",
      "Optimization Iteration:   1793, Training Accuracy:  70.3%, Loss: 0.4481\n",
      "Optimization Iteration:   1857, Training Accuracy:  76.6%, Loss: 0.4215\n",
      "Optimization Iteration:   1921, Training Accuracy:  73.4%, Loss: 0.4535\n",
      "Optimization Iteration:   1985, Training Accuracy:  73.4%, Loss: 0.4647\n",
      "Optimization Iteration:   2049, Training Accuracy:  82.8%, Loss: 0.3325\n",
      "Optimization Iteration:   2113, Training Accuracy:  67.2%, Loss: 0.4700\n",
      "Optimization Iteration:   2177, Training Accuracy:  71.9%, Loss: 0.4048\n",
      "Optimization Iteration:   2241, Training Accuracy:  75.0%, Loss: 0.4149\n",
      "Optimization Iteration:   2305, Training Accuracy:  67.2%, Loss: 0.4522\n",
      "Optimization Iteration:   2369, Training Accuracy:  73.4%, Loss: 0.4938\n",
      "Optimization Iteration:   2433, Training Accuracy:  76.6%, Loss: 0.4465\n",
      "Optimization Iteration:   2497, Training Accuracy:  75.0%, Loss: 0.3711\n",
      "Optimization Iteration:   2561, Training Accuracy:  89.1%, Loss: 0.3228\n",
      "Optimization Iteration:   2625, Training Accuracy:  76.6%, Loss: 0.4496\n",
      "Optimization Iteration:   2689, Training Accuracy:  75.0%, Loss: 0.3841\n",
      "Optimization Iteration:   2753, Training Accuracy:  68.8%, Loss: 0.5071\n",
      "Optimization Iteration:   2817, Training Accuracy:  75.0%, Loss: 0.4143\n",
      "Optimization Iteration:   2881, Training Accuracy:  70.3%, Loss: 0.4824\n",
      "Optimization Iteration:   2945, Training Accuracy:  70.3%, Loss: 0.4257\n",
      "Optimization Iteration:   3009, Training Accuracy:  82.8%, Loss: 0.3953\n",
      "Optimization Iteration:   3073, Training Accuracy:  78.1%, Loss: 0.3536\n",
      "Optimization Iteration:   3137, Training Accuracy:  70.3%, Loss: 0.3968\n",
      "Optimization Iteration:   3201, Training Accuracy:  73.4%, Loss: 0.4249\n",
      "Optimization Iteration:   3265, Training Accuracy:  78.1%, Loss: 0.3947\n",
      "Optimization Iteration:   3329, Training Accuracy:  70.3%, Loss: 0.4316\n",
      "Optimization Iteration:   3393, Training Accuracy:  73.4%, Loss: 0.4158\n",
      "Optimization Iteration:   3457, Training Accuracy:  79.7%, Loss: 0.4187\n",
      "Optimization Iteration:   3521, Training Accuracy:  71.9%, Loss: 0.4336\n",
      "Optimization Iteration:   3585, Training Accuracy:  70.3%, Loss: 0.5644\n",
      "Optimization Iteration:   3649, Training Accuracy:  71.9%, Loss: 0.4263\n",
      "Optimization Iteration:   3713, Training Accuracy:  68.8%, Loss: 0.4153\n",
      "Optimization Iteration:   3777, Training Accuracy:  56.2%, Loss: 0.5084\n",
      "Optimization Iteration:   3841, Training Accuracy:  68.8%, Loss: 0.4750\n",
      "Optimization Iteration:   3905, Training Accuracy:  73.4%, Loss: 0.4381\n",
      "Optimization Iteration:   3969, Training Accuracy:  73.4%, Loss: 0.4416\n",
      "Optimization Iteration:   4033, Training Accuracy:  76.6%, Loss: 0.3591\n",
      "Optimization Iteration:   4097, Training Accuracy:  70.3%, Loss: 0.4145\n",
      "Optimization Iteration:   4161, Training Accuracy:  65.6%, Loss: 0.5096\n",
      "Optimization Iteration:   4225, Training Accuracy:  79.7%, Loss: 0.3772\n",
      "Optimization Iteration:   4289, Training Accuracy:  70.3%, Loss: 0.4075\n",
      "Optimization Iteration:   4353, Training Accuracy:  71.9%, Loss: 0.4107\n",
      "Optimization Iteration:   4417, Training Accuracy:  71.9%, Loss: 0.4786\n",
      "Optimization Iteration:   4481, Training Accuracy:  73.4%, Loss: 0.4190\n",
      "Optimization Iteration:   4545, Training Accuracy:  71.9%, Loss: 0.4444\n",
      "Optimization Iteration:   4609, Training Accuracy:  71.9%, Loss: 0.4250\n",
      "Optimization Iteration:   4673, Training Accuracy:  78.1%, Loss: 0.4668\n",
      "Optimization Iteration:   4737, Training Accuracy:  67.2%, Loss: 0.4888\n",
      "Optimization Iteration:   4801, Training Accuracy:  65.6%, Loss: 0.5725\n",
      "Optimization Iteration:   4865, Training Accuracy:  75.0%, Loss: 0.3851\n",
      "Optimization Iteration:   4929, Training Accuracy:  87.5%, Loss: 0.3790\n",
      "Optimization Iteration:   4993, Training Accuracy:  84.4%, Loss: 0.3770\n",
      "Optimization Iteration:   5057, Training Accuracy:  71.9%, Loss: 0.4441\n",
      "Optimization Iteration:   5121, Training Accuracy:  79.7%, Loss: 0.3612\n",
      "Optimization Iteration:   5185, Training Accuracy:  78.1%, Loss: 0.4334\n",
      "Optimization Iteration:   5249, Training Accuracy:  67.2%, Loss: 0.5097\n",
      "Optimization Iteration:   5313, Training Accuracy:  71.9%, Loss: 0.5368\n",
      "Optimization Iteration:   5377, Training Accuracy:  79.7%, Loss: 0.4125\n",
      "Optimization Iteration:   5441, Training Accuracy:  76.6%, Loss: 0.4118\n",
      "Optimization Iteration:   5505, Training Accuracy:  71.9%, Loss: 0.4087\n",
      "Optimization Iteration:   5569, Training Accuracy:  73.4%, Loss: 0.4345\n",
      "Optimization Iteration:   5633, Training Accuracy:  79.7%, Loss: 0.3677\n",
      "Optimization Iteration:   5697, Training Accuracy:  76.6%, Loss: 0.4560\n",
      "Optimization Iteration:   5761, Training Accuracy:  78.1%, Loss: 0.4078\n",
      "Optimization Iteration:   5825, Training Accuracy:  76.6%, Loss: 0.4586\n",
      "Optimization Iteration:   5889, Training Accuracy:  78.1%, Loss: 0.4625\n",
      "Optimization Iteration:   5953, Training Accuracy:  79.7%, Loss: 0.4157\n",
      "Optimization Iteration:   6017, Training Accuracy:  62.5%, Loss: 0.5276\n",
      "Optimization Iteration:   6081, Training Accuracy:  84.4%, Loss: 0.3920\n",
      "Optimization Iteration:   6145, Training Accuracy:  62.5%, Loss: 0.5926\n",
      "Optimization Iteration:   6209, Training Accuracy:  73.4%, Loss: 0.4519\n",
      "Optimization Iteration:   6273, Training Accuracy:  68.8%, Loss: 0.4213\n",
      "Optimization Iteration:   6337, Training Accuracy:  70.3%, Loss: 0.4876\n",
      "Optimization Iteration:   6401, Training Accuracy:  78.1%, Loss: 0.3705\n",
      "Optimization Iteration:   6465, Training Accuracy:  79.7%, Loss: 0.3973\n",
      "Optimization Iteration:   6529, Training Accuracy:  82.8%, Loss: 0.3382\n",
      "Optimization Iteration:   6593, Training Accuracy:  79.7%, Loss: 0.3520\n",
      "Optimization Iteration:   6657, Training Accuracy:  71.9%, Loss: 0.4644\n",
      "Optimization Iteration:   6721, Training Accuracy:  78.1%, Loss: 0.3453\n",
      "Optimization Iteration:   6785, Training Accuracy:  76.6%, Loss: 0.4373\n",
      "Optimization Iteration:   6849, Training Accuracy:  75.0%, Loss: 0.5922\n",
      "Optimization Iteration:   6913, Training Accuracy:  82.8%, Loss: 0.3522\n",
      "Optimization Iteration:   6977, Training Accuracy:  78.1%, Loss: 0.4195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7041, Training Accuracy:  73.4%, Loss: 0.4156\n",
      "Optimization Iteration:   7105, Training Accuracy:  84.4%, Loss: 0.4110\n",
      "Optimization Iteration:   7169, Training Accuracy:  78.1%, Loss: 0.3966\n",
      "Optimization Iteration:   7233, Training Accuracy:  65.6%, Loss: 0.5088\n",
      "Optimization Iteration:   7297, Training Accuracy:  73.4%, Loss: 0.4555\n",
      "Optimization Iteration:   7361, Training Accuracy:  78.1%, Loss: 0.3762\n",
      "Optimization Iteration:   7425, Training Accuracy:  76.6%, Loss: 0.3847\n",
      "Optimization Iteration:   7489, Training Accuracy:  73.4%, Loss: 0.4156\n",
      "Optimization Iteration:   7553, Training Accuracy:  73.4%, Loss: 0.4946\n",
      "Optimization Iteration:   7617, Training Accuracy:  75.0%, Loss: 0.4528\n",
      "Optimization Iteration:   7681, Training Accuracy:  78.1%, Loss: 0.4569\n",
      "Optimization Iteration:   7745, Training Accuracy:  70.3%, Loss: 0.5353\n",
      "Optimization Iteration:   7809, Training Accuracy:  70.3%, Loss: 0.5506\n",
      "Optimization Iteration:   7873, Training Accuracy:  65.6%, Loss: 0.4558\n",
      "Optimization Iteration:   7937, Training Accuracy:  73.4%, Loss: 0.4481\n",
      "Optimization Iteration:   8001, Training Accuracy:  68.8%, Loss: 0.5035\n",
      "Optimization Iteration:   8065, Training Accuracy:  78.1%, Loss: 0.4271\n",
      "Optimization Iteration:   8129, Training Accuracy:  68.8%, Loss: 0.4352\n",
      "Optimization Iteration:   8193, Training Accuracy:  75.0%, Loss: 0.4169\n",
      "Optimization Iteration:   8257, Training Accuracy:  75.0%, Loss: 0.5285\n",
      "Optimization Iteration:   8321, Training Accuracy:  71.9%, Loss: 0.4276\n",
      "Optimization Iteration:   8385, Training Accuracy:  73.4%, Loss: 0.4906\n",
      "Optimization Iteration:   8449, Training Accuracy:  73.4%, Loss: 0.4690\n",
      "Optimization Iteration:   8513, Training Accuracy:  84.4%, Loss: 0.3512\n",
      "Optimization Iteration:   8577, Training Accuracy:  76.6%, Loss: 0.4470\n",
      "Optimization Iteration:   8641, Training Accuracy:  68.8%, Loss: 0.4860\n",
      "Optimization Iteration:   8705, Training Accuracy:  78.1%, Loss: 0.4340\n",
      "Optimization Iteration:   8769, Training Accuracy:  70.3%, Loss: 0.4037\n",
      "Optimization Iteration:   8833, Training Accuracy:  65.6%, Loss: 0.5145\n",
      "Optimization Iteration:   8897, Training Accuracy:  59.4%, Loss: 0.4636\n",
      "Optimization Iteration:   8961, Training Accuracy:  79.7%, Loss: 0.4704\n",
      "Optimization Iteration:   9025, Training Accuracy:  73.4%, Loss: 0.5030\n",
      "Optimization Iteration:   9089, Training Accuracy:  56.2%, Loss: 0.5681\n",
      "Optimization Iteration:   9153, Training Accuracy:  70.3%, Loss: 0.4501\n",
      "Optimization Iteration:   9217, Training Accuracy:  68.8%, Loss: 0.4328\n",
      "Optimization Iteration:   9281, Training Accuracy:  68.8%, Loss: 0.4633\n",
      "Optimization Iteration:   9345, Training Accuracy:  76.6%, Loss: 0.4072\n",
      "Optimization Iteration:   9409, Training Accuracy:  79.7%, Loss: 0.4471\n",
      "Optimization Iteration:   9473, Training Accuracy:  70.3%, Loss: 0.4047\n",
      "Optimization Iteration:   9537, Training Accuracy:  71.9%, Loss: 0.4084\n",
      "Optimization Iteration:   9601, Training Accuracy:  84.4%, Loss: 0.3684\n",
      "Optimization Iteration:   9665, Training Accuracy:  60.9%, Loss: 0.5735\n",
      "Optimization Iteration:   9729, Training Accuracy:  67.2%, Loss: 0.4301\n",
      "Optimization Iteration:   9793, Training Accuracy:  84.4%, Loss: 0.3659\n",
      "Optimization Iteration:   9857, Training Accuracy:  68.8%, Loss: 0.4705\n",
      "Optimization Iteration:   9921, Training Accuracy:  70.3%, Loss: 0.4528\n",
      "Optimization Iteration:   9985, Training Accuracy:  68.8%, Loss: 0.4387\n",
      "Optimization Iteration:  10049, Training Accuracy:  68.8%, Loss: 0.4799\n",
      "Optimization Iteration:  10113, Training Accuracy:  65.6%, Loss: 0.4456\n",
      "Optimization Iteration:  10177, Training Accuracy:  64.1%, Loss: 0.5699\n",
      "Optimization Iteration:  10241, Training Accuracy:  65.6%, Loss: 0.4897\n",
      "Optimization Iteration:  10305, Training Accuracy:  85.9%, Loss: 0.3869\n",
      "Optimization Iteration:  10369, Training Accuracy:  71.9%, Loss: 0.4096\n",
      "Optimization Iteration:  10433, Training Accuracy:  75.0%, Loss: 0.4511\n",
      "Optimization Iteration:  10497, Training Accuracy:  84.4%, Loss: 0.4382\n",
      "Optimization Iteration:  10561, Training Accuracy:  78.1%, Loss: 0.4211\n",
      "Optimization Iteration:  10625, Training Accuracy:  82.8%, Loss: 0.3797\n",
      "Optimization Iteration:  10689, Training Accuracy:  85.9%, Loss: 0.4311\n",
      "Optimization Iteration:  10753, Training Accuracy:  70.3%, Loss: 0.4501\n",
      "Optimization Iteration:  10817, Training Accuracy:  76.6%, Loss: 0.4144\n",
      "Optimization Iteration:  10881, Training Accuracy:  67.2%, Loss: 0.4254\n",
      "Optimization Iteration:  10945, Training Accuracy:  73.4%, Loss: 0.4611\n",
      "Optimization Iteration:  11009, Training Accuracy:  75.0%, Loss: 0.4310\n",
      "Optimization Iteration:  11073, Training Accuracy:  79.7%, Loss: 0.3741\n",
      "Optimization Iteration:  11137, Training Accuracy:  76.6%, Loss: 0.3867\n",
      "Optimization Iteration:  11201, Training Accuracy:  82.8%, Loss: 0.3869\n",
      "Optimization Iteration:  11265, Training Accuracy:  78.1%, Loss: 0.4034\n",
      "Optimization Iteration:  11329, Training Accuracy:  71.9%, Loss: 0.5483\n",
      "Optimization Iteration:  11393, Training Accuracy:  68.8%, Loss: 0.4615\n",
      "Optimization Iteration:  11457, Training Accuracy:  78.1%, Loss: 0.3744\n",
      "Optimization Iteration:  11521, Training Accuracy:  84.4%, Loss: 0.3867\n",
      "Optimization Iteration:  11585, Training Accuracy:  73.4%, Loss: 0.4255\n",
      "Optimization Iteration:  11649, Training Accuracy:  73.4%, Loss: 0.5100\n",
      "Optimization Iteration:  11713, Training Accuracy:  70.3%, Loss: 0.3862\n",
      "Optimization Iteration:  11777, Training Accuracy:  68.8%, Loss: 0.4590\n",
      "Optimization Iteration:  11841, Training Accuracy:  73.4%, Loss: 0.4288\n",
      "Optimization Iteration:  11905, Training Accuracy:  79.7%, Loss: 0.3755\n",
      "Optimization Iteration:  11969, Training Accuracy:  76.6%, Loss: 0.3829\n",
      "Optimization Iteration:  12033, Training Accuracy:  73.4%, Loss: 0.4408\n",
      "Optimization Iteration:  12097, Training Accuracy:  81.2%, Loss: 0.3767\n",
      "Optimization Iteration:  12161, Training Accuracy:  73.4%, Loss: 0.5195\n",
      "Optimization Iteration:  12225, Training Accuracy:  73.4%, Loss: 0.4612\n",
      "Optimization Iteration:  12289, Training Accuracy:  76.6%, Loss: 0.4036\n",
      "Optimization Iteration:  12353, Training Accuracy:  82.8%, Loss: 0.3784\n",
      "Optimization Iteration:  12417, Training Accuracy:  71.9%, Loss: 0.4330\n",
      "Optimization Iteration:  12481, Training Accuracy:  78.1%, Loss: 0.4410\n",
      "Optimization Iteration:  12545, Training Accuracy:  67.2%, Loss: 0.5251\n",
      "Optimization Iteration:  12609, Training Accuracy:  73.4%, Loss: 0.4288\n",
      "Optimization Iteration:  12673, Training Accuracy:  68.8%, Loss: 0.4289\n",
      "Optimization Iteration:  12737, Training Accuracy:  64.1%, Loss: 0.6355\n",
      "Optimization Iteration:  12801, Training Accuracy:  75.0%, Loss: 0.4197\n",
      "Optimization Iteration:  12865, Training Accuracy:  70.3%, Loss: 0.5045\n",
      "Optimization Iteration:  12929, Training Accuracy:  68.8%, Loss: 0.4945\n",
      "Optimization Iteration:  12993, Training Accuracy:  64.1%, Loss: 0.4157\n",
      "Optimization Iteration:  13057, Training Accuracy:  71.9%, Loss: 0.4093\n",
      "Optimization Iteration:  13121, Training Accuracy:  81.2%, Loss: 0.4026\n",
      "Optimization Iteration:  13185, Training Accuracy:  76.6%, Loss: 0.4518\n",
      "Optimization Iteration:  13249, Training Accuracy:  67.2%, Loss: 0.5001\n",
      "Optimization Iteration:  13313, Training Accuracy:  75.0%, Loss: 0.5443\n",
      "Optimization Iteration:  13377, Training Accuracy:  70.3%, Loss: 0.4704\n",
      "Optimization Iteration:  13441, Training Accuracy:  81.2%, Loss: 0.4116\n",
      "Optimization Iteration:  13505, Training Accuracy:  73.4%, Loss: 0.4378\n",
      "Optimization Iteration:  13569, Training Accuracy:  85.9%, Loss: 0.2981\n",
      "Optimization Iteration:  13633, Training Accuracy:  81.2%, Loss: 0.3778\n",
      "Optimization Iteration:  13697, Training Accuracy:  79.7%, Loss: 0.3573\n",
      "Optimization Iteration:  13761, Training Accuracy:  81.2%, Loss: 0.3555\n",
      "Optimization Iteration:  13825, Training Accuracy:  78.1%, Loss: 0.4480\n",
      "Optimization Iteration:  13889, Training Accuracy:  75.0%, Loss: 0.6347\n",
      "Optimization Iteration:  13953, Training Accuracy:  81.2%, Loss: 0.3645\n",
      "Optimization Iteration:  14017, Training Accuracy:  76.6%, Loss: 0.4462\n",
      "Optimization Iteration:  14081, Training Accuracy:  81.2%, Loss: 0.3816\n",
      "Optimization Iteration:  14145, Training Accuracy:  82.8%, Loss: 0.4391\n",
      "Optimization Iteration:  14209, Training Accuracy:  78.1%, Loss: 0.3718\n",
      "Optimization Iteration:  14273, Training Accuracy:  71.9%, Loss: 0.4802\n",
      "Optimization Iteration:  14337, Training Accuracy:  76.6%, Loss: 0.3610\n",
      "Optimization Iteration:  14401, Training Accuracy:  70.3%, Loss: 0.4898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  14465, Training Accuracy:  71.9%, Loss: 0.5155\n",
      "Optimization Iteration:  14529, Training Accuracy:  73.4%, Loss: 0.4436\n",
      "Optimization Iteration:  14593, Training Accuracy:  85.9%, Loss: 0.3408\n",
      "Optimization Iteration:  14657, Training Accuracy:  73.4%, Loss: 0.4839\n",
      "Optimization Iteration:  14721, Training Accuracy:  75.0%, Loss: 0.4202\n",
      "Optimization Iteration:  14785, Training Accuracy:  68.8%, Loss: 0.5021\n",
      "Optimization Iteration:  14849, Training Accuracy:  71.9%, Loss: 0.4679\n",
      "Optimization Iteration:  14913, Training Accuracy:  79.7%, Loss: 0.3873\n",
      "Optimization Iteration:  14977, Training Accuracy:  70.3%, Loss: 0.4785\n",
      "Optimization Iteration:  15041, Training Accuracy:  70.3%, Loss: 0.5798\n",
      "Optimization Iteration:  15105, Training Accuracy:  78.1%, Loss: 0.3643\n",
      "Optimization Iteration:  15169, Training Accuracy:  70.3%, Loss: 0.4651\n",
      "Optimization Iteration:  15233, Training Accuracy:  65.6%, Loss: 0.4289\n",
      "Optimization Iteration:  15297, Training Accuracy:  76.6%, Loss: 0.4374\n",
      "Optimization Iteration:  15361, Training Accuracy:  78.1%, Loss: 0.3759\n",
      "Optimization Iteration:  15425, Training Accuracy:  75.0%, Loss: 0.3876\n",
      "Optimization Iteration:  15489, Training Accuracy:  62.5%, Loss: 0.5044\n",
      "Optimization Iteration:  15553, Training Accuracy:  78.1%, Loss: 0.4103\n",
      "Optimization Iteration:  15617, Training Accuracy:  81.2%, Loss: 0.4596\n",
      "Optimization Iteration:  15681, Training Accuracy:  78.1%, Loss: 0.4042\n",
      "Optimization Iteration:  15745, Training Accuracy:  78.1%, Loss: 0.3835\n",
      "Optimization Iteration:  15809, Training Accuracy:  75.0%, Loss: 0.4000\n",
      "Optimization Iteration:  15873, Training Accuracy:  81.2%, Loss: 0.4021\n",
      "Optimization Iteration:  15937, Training Accuracy:  67.2%, Loss: 0.4828\n",
      "Optimization Iteration:  16001, Training Accuracy:  65.6%, Loss: 0.4489\n",
      "Optimization Iteration:  16065, Training Accuracy:  67.2%, Loss: 0.4583\n",
      "Optimization Iteration:  16129, Training Accuracy:  67.2%, Loss: 0.4197\n",
      "Optimization Iteration:  16193, Training Accuracy:  73.4%, Loss: 0.4537\n",
      "Optimization Iteration:  16257, Training Accuracy:  79.7%, Loss: 0.4576\n",
      "Optimization Iteration:  16321, Training Accuracy:  75.0%, Loss: 0.4495\n",
      "Optimization Iteration:  16385, Training Accuracy:  78.1%, Loss: 0.4303\n",
      "Optimization Iteration:  16449, Training Accuracy:  75.0%, Loss: 0.4044\n",
      "Optimization Iteration:  16513, Training Accuracy:  68.8%, Loss: 0.5059\n",
      "Optimization Iteration:  16577, Training Accuracy:  62.5%, Loss: 0.4304\n",
      "Optimization Iteration:  16641, Training Accuracy:  68.8%, Loss: 0.5071\n",
      "Optimization Iteration:  16705, Training Accuracy:  73.4%, Loss: 0.4893\n",
      "Optimization Iteration:  16769, Training Accuracy:  75.0%, Loss: 0.4230\n",
      "Optimization Iteration:  16833, Training Accuracy:  62.5%, Loss: 0.4961\n",
      "Optimization Iteration:  16897, Training Accuracy:  75.0%, Loss: 0.4243\n",
      "Optimization Iteration:  16961, Training Accuracy:  76.6%, Loss: 0.4194\n",
      "Optimization Iteration:  17025, Training Accuracy:  62.5%, Loss: 0.4753\n",
      "Optimization Iteration:  17089, Training Accuracy:  67.2%, Loss: 0.4609\n",
      "Optimization Iteration:  17153, Training Accuracy:  70.3%, Loss: 0.4586\n",
      "Optimization Iteration:  17217, Training Accuracy:  73.4%, Loss: 0.5245\n",
      "Optimization Iteration:  17281, Training Accuracy:  71.9%, Loss: 0.4379\n",
      "Optimization Iteration:  17345, Training Accuracy:  73.4%, Loss: 0.3895\n",
      "Optimization Iteration:  17409, Training Accuracy:  62.5%, Loss: 0.5028\n",
      "Optimization Iteration:  17473, Training Accuracy:  64.1%, Loss: 0.6388\n",
      "Optimization Iteration:  17537, Training Accuracy:  75.0%, Loss: 0.4420\n",
      "Optimization Iteration:  17601, Training Accuracy:  78.1%, Loss: 0.4070\n",
      "Optimization Iteration:  17665, Training Accuracy:  81.2%, Loss: 0.5057\n",
      "Optimization Iteration:  17729, Training Accuracy:  70.3%, Loss: 0.4736\n",
      "Optimization Iteration:  17793, Training Accuracy:  81.2%, Loss: 0.4708\n",
      "Optimization Iteration:  17857, Training Accuracy:  71.9%, Loss: 0.4675\n",
      "Optimization Iteration:  17921, Training Accuracy:  75.0%, Loss: 0.4269\n",
      "Optimization Iteration:  17985, Training Accuracy:  78.1%, Loss: 0.4003\n",
      "Optimization Iteration:  18049, Training Accuracy:  75.0%, Loss: 0.4027\n",
      "Optimization Iteration:  18113, Training Accuracy:  75.0%, Loss: 0.4931\n",
      "Optimization Iteration:  18177, Training Accuracy:  70.3%, Loss: 0.5844\n",
      "Optimization Iteration:  18241, Training Accuracy:  70.3%, Loss: 0.4214\n",
      "Optimization Iteration:  18305, Training Accuracy:  65.6%, Loss: 0.4796\n",
      "Optimization Iteration:  18369, Training Accuracy:  73.4%, Loss: 0.3634\n",
      "Optimization Iteration:  18433, Training Accuracy:  67.2%, Loss: 0.4527\n",
      "Optimization Iteration:  18497, Training Accuracy:  75.0%, Loss: 0.3671\n",
      "Optimization Iteration:  18561, Training Accuracy:  70.3%, Loss: 0.4082\n",
      "Optimization Iteration:  18625, Training Accuracy:  65.6%, Loss: 0.5282\n",
      "Optimization Iteration:  18689, Training Accuracy:  78.1%, Loss: 0.3892\n",
      "Optimization Iteration:  18753, Training Accuracy:  67.2%, Loss: 0.4731\n",
      "Optimization Iteration:  18817, Training Accuracy:  73.4%, Loss: 0.4533\n",
      "Optimization Iteration:  18881, Training Accuracy:  67.2%, Loss: 0.4421\n",
      "Optimization Iteration:  18945, Training Accuracy:  73.4%, Loss: 0.4675\n",
      "Optimization Iteration:  19009, Training Accuracy:  73.4%, Loss: 0.3666\n",
      "Optimization Iteration:  19073, Training Accuracy:  76.6%, Loss: 0.4660\n",
      "Optimization Iteration:  19137, Training Accuracy:  71.9%, Loss: 0.4913\n",
      "Optimization Iteration:  19201, Training Accuracy:  73.4%, Loss: 0.4388\n",
      "Optimization Iteration:  19265, Training Accuracy:  78.1%, Loss: 0.4042\n",
      "Optimization Iteration:  19329, Training Accuracy:  71.9%, Loss: 0.3549\n",
      "Optimization Iteration:  19393, Training Accuracy:  68.8%, Loss: 0.5174\n",
      "Optimization Iteration:  19457, Training Accuracy:  71.9%, Loss: 0.4329\n",
      "Optimization Iteration:  19521, Training Accuracy:  68.8%, Loss: 0.4568\n",
      "Optimization Iteration:  19585, Training Accuracy:  71.9%, Loss: 0.4432\n",
      "Optimization Iteration:  19649, Training Accuracy:  71.9%, Loss: 0.4711\n",
      "Optimization Iteration:  19713, Training Accuracy:  70.3%, Loss: 0.3858\n",
      "Optimization Iteration:  19777, Training Accuracy:  76.6%, Loss: 0.4575\n",
      "Optimization Iteration:  19841, Training Accuracy:  68.8%, Loss: 0.4563\n",
      "Optimization Iteration:  19905, Training Accuracy:  71.9%, Loss: 0.4537\n",
      "Optimization Iteration:  19969, Training Accuracy:  75.0%, Loss: 0.4692\n",
      "Optimization Iteration:  20033, Training Accuracy:  70.3%, Loss: 0.4158\n",
      "Optimization Iteration:  20097, Training Accuracy:  78.1%, Loss: 0.4201\n",
      "Optimization Iteration:  20161, Training Accuracy:  75.0%, Loss: 0.3935\n",
      "Optimization Iteration:  20225, Training Accuracy:  59.4%, Loss: 0.4834\n",
      "Optimization Iteration:  20289, Training Accuracy:  76.6%, Loss: 0.4183\n",
      "Optimization Iteration:  20353, Training Accuracy:  79.7%, Loss: 0.4158\n",
      "Optimization Iteration:  20417, Training Accuracy:  71.9%, Loss: 0.4433\n",
      "Optimization Iteration:  20481, Training Accuracy:  68.8%, Loss: 0.5047\n",
      "Optimization Iteration:  20545, Training Accuracy:  71.9%, Loss: 0.5705\n",
      "Optimization Iteration:  20609, Training Accuracy:  64.1%, Loss: 0.4885\n",
      "Optimization Iteration:  20673, Training Accuracy:  76.6%, Loss: 0.4136\n",
      "Optimization Iteration:  20737, Training Accuracy:  81.2%, Loss: 0.4266\n",
      "Optimization Iteration:  20801, Training Accuracy:  70.3%, Loss: 0.4574\n",
      "Optimization Iteration:  20865, Training Accuracy:  81.2%, Loss: 0.3678\n",
      "Optimization Iteration:  20929, Training Accuracy:  76.6%, Loss: 0.4043\n",
      "Optimization Iteration:  20993, Training Accuracy:  79.7%, Loss: 0.4108\n",
      "Optimization Iteration:  21057, Training Accuracy:  81.2%, Loss: 0.3785\n",
      "Optimization Iteration:  21121, Training Accuracy:  71.9%, Loss: 0.4604\n",
      "Optimization Iteration:  21185, Training Accuracy:  78.1%, Loss: 0.4578\n",
      "Optimization Iteration:  21249, Training Accuracy:  71.9%, Loss: 0.5235\n",
      "Optimization Iteration:  21313, Training Accuracy:  73.4%, Loss: 0.4811\n",
      "Optimization Iteration:  21377, Training Accuracy:  75.0%, Loss: 0.4005\n",
      "Optimization Iteration:  21441, Training Accuracy:  70.3%, Loss: 0.4005\n",
      "Optimization Iteration:  21505, Training Accuracy:  79.7%, Loss: 0.4736\n",
      "Optimization Iteration:  21569, Training Accuracy:  68.8%, Loss: 0.4257\n",
      "Optimization Iteration:  21633, Training Accuracy:  89.1%, Loss: 0.3658\n",
      "Optimization Iteration:  21697, Training Accuracy:  67.2%, Loss: 0.4724\n",
      "Optimization Iteration:  21761, Training Accuracy:  67.2%, Loss: 0.4037\n",
      "Optimization Iteration:  21825, Training Accuracy:  76.6%, Loss: 0.4609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  21889, Training Accuracy:  76.6%, Loss: 0.4617\n",
      "Optimization Iteration:  21953, Training Accuracy:  59.4%, Loss: 0.5882\n",
      "Optimization Iteration:  22017, Training Accuracy:  87.5%, Loss: 0.3814\n",
      "Optimization Iteration:  22081, Training Accuracy:  76.6%, Loss: 0.4616\n",
      "Optimization Iteration:  22145, Training Accuracy:  76.6%, Loss: 0.3657\n",
      "Optimization Iteration:  22209, Training Accuracy:  71.9%, Loss: 0.4283\n",
      "Optimization Iteration:  22273, Training Accuracy:  71.9%, Loss: 0.4890\n",
      "Optimization Iteration:  22337, Training Accuracy:  76.6%, Loss: 0.4404\n",
      "Optimization Iteration:  22401, Training Accuracy:  68.8%, Loss: 0.4588\n",
      "Optimization Iteration:  22465, Training Accuracy:  78.1%, Loss: 0.4253\n",
      "Optimization Iteration:  22529, Training Accuracy:  71.9%, Loss: 0.4069\n",
      "Optimization Iteration:  22593, Training Accuracy:  79.7%, Loss: 0.4122\n",
      "Optimization Iteration:  22657, Training Accuracy:  78.1%, Loss: 0.4472\n",
      "Optimization Iteration:  22721, Training Accuracy:  64.1%, Loss: 0.5072\n",
      "Optimization Iteration:  22785, Training Accuracy:  65.6%, Loss: 0.4982\n",
      "Optimization Iteration:  22849, Training Accuracy:  67.2%, Loss: 0.4633\n",
      "Optimization Iteration:  22913, Training Accuracy:  78.1%, Loss: 0.4270\n",
      "Optimization Iteration:  22977, Training Accuracy:  70.3%, Loss: 0.4068\n",
      "Optimization Iteration:  23041, Training Accuracy:  73.4%, Loss: 0.4114\n",
      "Optimization Iteration:  23105, Training Accuracy:  78.1%, Loss: 0.4056\n",
      "Optimization Iteration:  23169, Training Accuracy:  78.1%, Loss: 0.4142\n",
      "Optimization Iteration:  23233, Training Accuracy:  62.5%, Loss: 0.6110\n",
      "Optimization Iteration:  23297, Training Accuracy:  76.6%, Loss: 0.4265\n",
      "Optimization Iteration:  23361, Training Accuracy:  75.0%, Loss: 0.4649\n",
      "Optimization Iteration:  23425, Training Accuracy:  76.6%, Loss: 0.4237\n",
      "Optimization Iteration:  23489, Training Accuracy:  75.0%, Loss: 0.4034\n",
      "Optimization Iteration:  23553, Training Accuracy:  75.0%, Loss: 0.4010\n",
      "Optimization Iteration:  23617, Training Accuracy:  68.8%, Loss: 0.4806\n",
      "Optimization Iteration:  23681, Training Accuracy:  67.2%, Loss: 0.5681\n",
      "Optimization Iteration:  23745, Training Accuracy:  75.0%, Loss: 0.4600\n",
      "Optimization Iteration:  23809, Training Accuracy:  73.4%, Loss: 0.4789\n",
      "Optimization Iteration:  23873, Training Accuracy:  65.6%, Loss: 0.4116\n",
      "Optimization Iteration:  23937, Training Accuracy:  70.3%, Loss: 0.4832\n",
      "Optimization Iteration:  24001, Training Accuracy:  79.7%, Loss: 0.3710\n",
      "Optimization Iteration:  24065, Training Accuracy:  75.0%, Loss: 0.4297\n",
      "Optimization Iteration:  24129, Training Accuracy:  85.9%, Loss: 0.3431\n",
      "Optimization Iteration:  24193, Training Accuracy:  76.6%, Loss: 0.3819\n",
      "Optimization Iteration:  24257, Training Accuracy:  68.8%, Loss: 0.3989\n",
      "Optimization Iteration:  24321, Training Accuracy:  62.5%, Loss: 0.4843\n",
      "Optimization Iteration:  24385, Training Accuracy:  71.9%, Loss: 0.4109\n",
      "Optimization Iteration:  24449, Training Accuracy:  84.4%, Loss: 0.3464\n",
      "Optimization Iteration:  24513, Training Accuracy:  73.4%, Loss: 0.3961\n",
      "Optimization Iteration:  24577, Training Accuracy:  70.3%, Loss: 0.5323\n",
      "Optimization Iteration:  24641, Training Accuracy:  75.0%, Loss: 0.4613\n",
      "Optimization Iteration:  24705, Training Accuracy:  79.7%, Loss: 0.3405\n",
      "Optimization Iteration:  24769, Training Accuracy:  70.3%, Loss: 0.4173\n",
      "Optimization Iteration:  24833, Training Accuracy:  79.7%, Loss: 0.3709\n",
      "Optimization Iteration:  24897, Training Accuracy:  68.8%, Loss: 0.4543\n",
      "Optimization Iteration:  24961, Training Accuracy:  76.6%, Loss: 0.3859\n",
      "Optimization Iteration:  25025, Training Accuracy:  79.7%, Loss: 0.4660\n",
      "Optimization Iteration:  25089, Training Accuracy:  67.2%, Loss: 0.3997\n",
      "Optimization Iteration:  25153, Training Accuracy:  65.6%, Loss: 0.4992\n",
      "Optimization Iteration:  25217, Training Accuracy:  75.0%, Loss: 0.4761\n",
      "Optimization Iteration:  25281, Training Accuracy:  70.3%, Loss: 0.3993\n",
      "Optimization Iteration:  25345, Training Accuracy:  76.6%, Loss: 0.4570\n",
      "Optimization Iteration:  25409, Training Accuracy:  76.6%, Loss: 0.4464\n",
      "Optimization Iteration:  25473, Training Accuracy:  71.9%, Loss: 0.4737\n",
      "Optimization Iteration:  25537, Training Accuracy:  70.3%, Loss: 0.3892\n",
      "Optimization Iteration:  25601, Training Accuracy:  62.5%, Loss: 0.5339\n",
      "Optimization Iteration:  25665, Training Accuracy:  76.6%, Loss: 0.4845\n",
      "Optimization Iteration:  25729, Training Accuracy:  79.7%, Loss: 0.3531\n",
      "Optimization Iteration:  25793, Training Accuracy:  79.7%, Loss: 0.3449\n",
      "Optimization Iteration:  25857, Training Accuracy:  73.4%, Loss: 0.4176\n",
      "Optimization Iteration:  25921, Training Accuracy:  79.7%, Loss: 0.4715\n",
      "Optimization Iteration:  25985, Training Accuracy:  81.2%, Loss: 0.4291\n",
      "Optimization Iteration:  26049, Training Accuracy:  78.1%, Loss: 0.3991\n",
      "Optimization Iteration:  26113, Training Accuracy:  76.6%, Loss: 0.4081\n",
      "Optimization Iteration:  26177, Training Accuracy:  78.1%, Loss: 0.3940\n",
      "Optimization Iteration:  26241, Training Accuracy:  84.4%, Loss: 0.3430\n",
      "Optimization Iteration:  26305, Training Accuracy:  79.7%, Loss: 0.4461\n",
      "Optimization Iteration:  26369, Training Accuracy:  75.0%, Loss: 0.4427\n",
      "Optimization Iteration:  26433, Training Accuracy:  60.9%, Loss: 0.4821\n",
      "Optimization Iteration:  26497, Training Accuracy:  68.8%, Loss: 0.4796\n",
      "Optimization Iteration:  26561, Training Accuracy:  82.8%, Loss: 0.3587\n",
      "Optimization Iteration:  26625, Training Accuracy:  75.0%, Loss: 0.4206\n",
      "Optimization Iteration:  26689, Training Accuracy:  71.9%, Loss: 0.4560\n",
      "Optimization Iteration:  26753, Training Accuracy:  67.2%, Loss: 0.5158\n",
      "Optimization Iteration:  26817, Training Accuracy:  71.9%, Loss: 0.4673\n",
      "Optimization Iteration:  26881, Training Accuracy:  78.1%, Loss: 0.4245\n",
      "Optimization Iteration:  26945, Training Accuracy:  73.4%, Loss: 0.4499\n",
      "Optimization Iteration:  27009, Training Accuracy:  79.7%, Loss: 0.4125\n",
      "Optimization Iteration:  27073, Training Accuracy:  81.2%, Loss: 0.5223\n",
      "Optimization Iteration:  27137, Training Accuracy:  76.6%, Loss: 0.4772\n",
      "Optimization Iteration:  27201, Training Accuracy:  84.4%, Loss: 0.3417\n",
      "Optimization Iteration:  27265, Training Accuracy:  76.6%, Loss: 0.4773\n",
      "Optimization Iteration:  27329, Training Accuracy:  73.4%, Loss: 0.3895\n",
      "Optimization Iteration:  27393, Training Accuracy:  75.0%, Loss: 0.4962\n",
      "Optimization Iteration:  27457, Training Accuracy:  78.1%, Loss: 0.3858\n",
      "Optimization Iteration:  27521, Training Accuracy:  68.8%, Loss: 0.5000\n",
      "Optimization Iteration:  27585, Training Accuracy:  78.1%, Loss: 0.3859\n",
      "Optimization Iteration:  27649, Training Accuracy:  71.9%, Loss: 0.4291\n",
      "Optimization Iteration:  27713, Training Accuracy:  76.6%, Loss: 0.4342\n",
      "Optimization Iteration:  27777, Training Accuracy:  76.6%, Loss: 0.3743\n",
      "Optimization Iteration:  27841, Training Accuracy:  75.0%, Loss: 0.4344\n",
      "Optimization Iteration:  27905, Training Accuracy:  70.3%, Loss: 0.3916\n",
      "Optimization Iteration:  27969, Training Accuracy:  71.9%, Loss: 0.4705\n",
      "Optimization Iteration:  28033, Training Accuracy:  76.6%, Loss: 0.4568\n",
      "Optimization Iteration:  28097, Training Accuracy:  78.1%, Loss: 0.4149\n",
      "Optimization Iteration:  28161, Training Accuracy:  84.4%, Loss: 0.3501\n",
      "Optimization Iteration:  28225, Training Accuracy:  73.4%, Loss: 0.4516\n",
      "Optimization Iteration:  28289, Training Accuracy:  73.4%, Loss: 0.4622\n",
      "Optimization Iteration:  28353, Training Accuracy:  78.1%, Loss: 0.3668\n",
      "Optimization Iteration:  28417, Training Accuracy:  73.4%, Loss: 0.4879\n",
      "Optimization Iteration:  28481, Training Accuracy:  71.9%, Loss: 0.4287\n",
      "Optimization Iteration:  28545, Training Accuracy:  76.6%, Loss: 0.4195\n",
      "Optimization Iteration:  28609, Training Accuracy:  85.9%, Loss: 0.3331\n",
      "Optimization Iteration:  28673, Training Accuracy:  70.3%, Loss: 0.4740\n",
      "Optimization Iteration:  28737, Training Accuracy:  78.1%, Loss: 0.4372\n",
      "Optimization Iteration:  28801, Training Accuracy:  75.0%, Loss: 0.4164\n",
      "Optimization Iteration:  28865, Training Accuracy:  78.1%, Loss: 0.4160\n",
      "Optimization Iteration:  28929, Training Accuracy:  81.2%, Loss: 0.3465\n",
      "Optimization Iteration:  28993, Training Accuracy:  71.9%, Loss: 0.4343\n",
      "Optimization Iteration:  29057, Training Accuracy:  76.6%, Loss: 0.4135\n",
      "Optimization Iteration:  29121, Training Accuracy:  75.0%, Loss: 0.5213\n",
      "Optimization Iteration:  29185, Training Accuracy:  73.4%, Loss: 0.3911\n",
      "Optimization Iteration:  29249, Training Accuracy:  68.8%, Loss: 0.4335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  29313, Training Accuracy:  71.9%, Loss: 0.4422\n",
      "Optimization Iteration:  29377, Training Accuracy:  78.1%, Loss: 0.4084\n",
      "Optimization Iteration:  29441, Training Accuracy:  79.7%, Loss: 0.5137\n",
      "Optimization Iteration:  29505, Training Accuracy:  75.0%, Loss: 0.4044\n",
      "Optimization Iteration:  29569, Training Accuracy:  76.6%, Loss: 0.4123\n",
      "Optimization Iteration:  29633, Training Accuracy:  64.1%, Loss: 0.4858\n",
      "Optimization Iteration:  29697, Training Accuracy:  73.4%, Loss: 0.4264\n",
      "Optimization Iteration:  29761, Training Accuracy:  75.0%, Loss: 0.4297\n",
      "Optimization Iteration:  29825, Training Accuracy:  68.8%, Loss: 0.4512\n",
      "Optimization Iteration:  29889, Training Accuracy:  75.0%, Loss: 0.4661\n",
      "Optimization Iteration:  29953, Training Accuracy:  68.8%, Loss: 0.4655\n",
      "Optimization Iteration:  30017, Training Accuracy:  85.9%, Loss: 0.3792\n",
      "Optimization Iteration:  30081, Training Accuracy:  76.6%, Loss: 0.3708\n",
      "Optimization Iteration:  30145, Training Accuracy:  81.2%, Loss: 0.4216\n",
      "Optimization Iteration:  30209, Training Accuracy:  68.8%, Loss: 0.5488\n",
      "Optimization Iteration:  30273, Training Accuracy:  76.6%, Loss: 0.4336\n",
      "Optimization Iteration:  30337, Training Accuracy:  81.2%, Loss: 0.4164\n",
      "Optimization Iteration:  30401, Training Accuracy:  73.4%, Loss: 0.4238\n",
      "Optimization Iteration:  30465, Training Accuracy:  78.1%, Loss: 0.4748\n",
      "Optimization Iteration:  30529, Training Accuracy:  68.8%, Loss: 0.4879\n",
      "Optimization Iteration:  30593, Training Accuracy:  82.8%, Loss: 0.4134\n",
      "Optimization Iteration:  30657, Training Accuracy:  75.0%, Loss: 0.3765\n",
      "Optimization Iteration:  30721, Training Accuracy:  79.7%, Loss: 0.4028\n",
      "Optimization Iteration:  30785, Training Accuracy:  73.4%, Loss: 0.4219\n",
      "Optimization Iteration:  30849, Training Accuracy:  78.1%, Loss: 0.4622\n",
      "Optimization Iteration:  30913, Training Accuracy:  76.6%, Loss: 0.3476\n",
      "Optimization Iteration:  30977, Training Accuracy:  84.4%, Loss: 0.3931\n",
      "Optimization Iteration:  31041, Training Accuracy:  73.4%, Loss: 0.4142\n",
      "Optimization Iteration:  31105, Training Accuracy:  65.6%, Loss: 0.4912\n",
      "Optimization Iteration:  31169, Training Accuracy:  79.7%, Loss: 0.3521\n",
      "Optimization Iteration:  31233, Training Accuracy:  81.2%, Loss: 0.3962\n",
      "Optimization Iteration:  31297, Training Accuracy:  75.0%, Loss: 0.4617\n",
      "Optimization Iteration:  31361, Training Accuracy:  68.8%, Loss: 0.4901\n",
      "Optimization Iteration:  31425, Training Accuracy:  81.2%, Loss: 0.3781\n",
      "Optimization Iteration:  31489, Training Accuracy:  78.1%, Loss: 0.4150\n",
      "Optimization Iteration:  31553, Training Accuracy:  76.6%, Loss: 0.4738\n",
      "Optimization Iteration:  31617, Training Accuracy:  68.8%, Loss: 0.4266\n",
      "Optimization Iteration:  31681, Training Accuracy:  70.3%, Loss: 0.5935\n",
      "Optimization Iteration:  31745, Training Accuracy:  75.0%, Loss: 0.4165\n",
      "Optimization Iteration:  31809, Training Accuracy:  75.0%, Loss: 0.4443\n",
      "Optimization Iteration:  31873, Training Accuracy:  78.1%, Loss: 0.3912\n",
      "Optimization Iteration:  31937, Training Accuracy:  75.0%, Loss: 0.4591\n",
      "Optimization Iteration:  32001, Training Accuracy:  70.3%, Loss: 0.5146\n",
      "Optimization Iteration:  32065, Training Accuracy:  68.8%, Loss: 0.4349\n",
      "Optimization Iteration:  32129, Training Accuracy:  65.6%, Loss: 0.4777\n",
      "Optimization Iteration:  32193, Training Accuracy:  79.7%, Loss: 0.4238\n",
      "Optimization Iteration:  32257, Training Accuracy:  67.2%, Loss: 0.4763\n",
      "Optimization Iteration:  32321, Training Accuracy:  73.4%, Loss: 0.4288\n",
      "Optimization Iteration:  32385, Training Accuracy:  84.4%, Loss: 0.3825\n",
      "Optimization Iteration:  32449, Training Accuracy:  76.6%, Loss: 0.4423\n",
      "Optimization Iteration:  32513, Training Accuracy:  76.6%, Loss: 0.4002\n",
      "Optimization Iteration:  32577, Training Accuracy:  85.9%, Loss: 0.4246\n",
      "Optimization Iteration:  32641, Training Accuracy:  75.0%, Loss: 0.4469\n",
      "Optimization Iteration:  32705, Training Accuracy:  79.7%, Loss: 0.4001\n",
      "Optimization Iteration:  32769, Training Accuracy:  70.3%, Loss: 0.4134\n",
      "Optimization Iteration:  32833, Training Accuracy:  62.5%, Loss: 0.5147\n",
      "Optimization Iteration:  32897, Training Accuracy:  73.4%, Loss: 0.4355\n",
      "Optimization Iteration:  32961, Training Accuracy:  65.6%, Loss: 0.5100\n",
      "Optimization Iteration:  33025, Training Accuracy:  67.2%, Loss: 0.4394\n",
      "Optimization Iteration:  33089, Training Accuracy:  73.4%, Loss: 0.4670\n",
      "Optimization Iteration:  33153, Training Accuracy:  73.4%, Loss: 0.5073\n",
      "Optimization Iteration:  33217, Training Accuracy:  75.0%, Loss: 0.3943\n",
      "Optimization Iteration:  33281, Training Accuracy:  75.0%, Loss: 0.4899\n",
      "Optimization Iteration:  33345, Training Accuracy:  70.3%, Loss: 0.4879\n",
      "Optimization Iteration:  33409, Training Accuracy:  79.7%, Loss: 0.4067\n",
      "Optimization Iteration:  33473, Training Accuracy:  75.0%, Loss: 0.4878\n",
      "Optimization Iteration:  33537, Training Accuracy:  75.0%, Loss: 0.4317\n",
      "Optimization Iteration:  33601, Training Accuracy:  75.0%, Loss: 0.4886\n",
      "Optimization Iteration:  33665, Training Accuracy:  84.4%, Loss: 0.3242\n",
      "Optimization Iteration:  33729, Training Accuracy:  68.8%, Loss: 0.5192\n",
      "Optimization Iteration:  33793, Training Accuracy:  65.6%, Loss: 0.5301\n",
      "Optimization Iteration:  33857, Training Accuracy:  70.3%, Loss: 0.4047\n",
      "Optimization Iteration:  33921, Training Accuracy:  73.4%, Loss: 0.4035\n",
      "Optimization Iteration:  33985, Training Accuracy:  79.7%, Loss: 0.4099\n",
      "Optimization Iteration:  34049, Training Accuracy:  70.3%, Loss: 0.4607\n",
      "Optimization Iteration:  34113, Training Accuracy:  65.6%, Loss: 0.4033\n",
      "Optimization Iteration:  34177, Training Accuracy:  62.5%, Loss: 0.4639\n",
      "Optimization Iteration:  34241, Training Accuracy:  76.6%, Loss: 0.4262\n",
      "Optimization Iteration:  34305, Training Accuracy:  68.8%, Loss: 0.4670\n",
      "Optimization Iteration:  34369, Training Accuracy:  81.2%, Loss: 0.3799\n",
      "Optimization Iteration:  34433, Training Accuracy:  78.1%, Loss: 0.4625\n",
      "Optimization Iteration:  34497, Training Accuracy:  78.1%, Loss: 0.3323\n",
      "Optimization Iteration:  34561, Training Accuracy:  75.0%, Loss: 0.4695\n",
      "Optimization Iteration:  34625, Training Accuracy:  71.9%, Loss: 0.5204\n",
      "Optimization Iteration:  34689, Training Accuracy:  65.6%, Loss: 0.4598\n",
      "Optimization Iteration:  34753, Training Accuracy:  81.2%, Loss: 0.4236\n",
      "Optimization Iteration:  34817, Training Accuracy:  76.6%, Loss: 0.4021\n",
      "Optimization Iteration:  34881, Training Accuracy:  71.9%, Loss: 0.3448\n",
      "Optimization Iteration:  34945, Training Accuracy:  84.4%, Loss: 0.3943\n",
      "Optimization Iteration:  35009, Training Accuracy:  79.7%, Loss: 0.4242\n",
      "Optimization Iteration:  35073, Training Accuracy:  71.9%, Loss: 0.4284\n",
      "Optimization Iteration:  35137, Training Accuracy:  75.0%, Loss: 0.4754\n",
      "Optimization Iteration:  35201, Training Accuracy:  79.7%, Loss: 0.4300\n",
      "Optimization Iteration:  35265, Training Accuracy:  73.4%, Loss: 0.4521\n",
      "Optimization Iteration:  35329, Training Accuracy:  62.5%, Loss: 0.5004\n",
      "Optimization Iteration:  35393, Training Accuracy:  79.7%, Loss: 0.3046\n",
      "Optimization Iteration:  35457, Training Accuracy:  82.8%, Loss: 0.3666\n",
      "Optimization Iteration:  35521, Training Accuracy:  68.8%, Loss: 0.4436\n",
      "Optimization Iteration:  35585, Training Accuracy:  89.1%, Loss: 0.3005\n",
      "Optimization Iteration:  35649, Training Accuracy:  67.2%, Loss: 0.5065\n",
      "Optimization Iteration:  35713, Training Accuracy:  79.7%, Loss: 0.3957\n",
      "Optimization Iteration:  35777, Training Accuracy:  76.6%, Loss: 0.3840\n",
      "Optimization Iteration:  35841, Training Accuracy:  78.1%, Loss: 0.4238\n",
      "Optimization Iteration:  35905, Training Accuracy:  76.6%, Loss: 0.4200\n",
      "Optimization Iteration:  35969, Training Accuracy:  65.6%, Loss: 0.4578\n",
      "Optimization Iteration:  36033, Training Accuracy:  78.1%, Loss: 0.3999\n",
      "Optimization Iteration:  36097, Training Accuracy:  68.8%, Loss: 0.4423\n",
      "Optimization Iteration:  36161, Training Accuracy:  78.1%, Loss: 0.3956\n",
      "Optimization Iteration:  36225, Training Accuracy:  82.8%, Loss: 0.3631\n",
      "Optimization Iteration:  36289, Training Accuracy:  79.7%, Loss: 0.3828\n",
      "Optimization Iteration:  36353, Training Accuracy:  60.9%, Loss: 0.4775\n",
      "Optimization Iteration:  36417, Training Accuracy:  75.0%, Loss: 0.5070\n",
      "Optimization Iteration:  36481, Training Accuracy:  73.4%, Loss: 0.3961\n",
      "Optimization Iteration:  36545, Training Accuracy:  73.4%, Loss: 0.4780\n",
      "Optimization Iteration:  36609, Training Accuracy:  75.0%, Loss: 0.4229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  36673, Training Accuracy:  82.8%, Loss: 0.4236\n",
      "Optimization Iteration:  36737, Training Accuracy:  81.2%, Loss: 0.3558\n",
      "Optimization Iteration:  36801, Training Accuracy:  75.0%, Loss: 0.3676\n",
      "Optimization Iteration:  36865, Training Accuracy:  68.8%, Loss: 0.4701\n",
      "Optimization Iteration:  36929, Training Accuracy:  67.2%, Loss: 0.4970\n",
      "Optimization Iteration:  36993, Training Accuracy:  64.1%, Loss: 0.4527\n",
      "Optimization Iteration:  37057, Training Accuracy:  76.6%, Loss: 0.4121\n",
      "Optimization Iteration:  37121, Training Accuracy:  75.0%, Loss: 0.4769\n",
      "Optimization Iteration:  37185, Training Accuracy:  79.7%, Loss: 0.3601\n",
      "Optimization Iteration:  37249, Training Accuracy:  76.6%, Loss: 0.4245\n",
      "Optimization Iteration:  37313, Training Accuracy:  78.1%, Loss: 0.4172\n",
      "Optimization Iteration:  37377, Training Accuracy:  64.1%, Loss: 0.6611\n",
      "Optimization Iteration:  37441, Training Accuracy:  67.2%, Loss: 0.4734\n",
      "Optimization Iteration:  37505, Training Accuracy:  75.0%, Loss: 0.4545\n",
      "Optimization Iteration:  37569, Training Accuracy:  73.4%, Loss: 0.4825\n",
      "Optimization Iteration:  37633, Training Accuracy:  73.4%, Loss: 0.4215\n",
      "Optimization Iteration:  37697, Training Accuracy:  84.4%, Loss: 0.3402\n",
      "Optimization Iteration:  37761, Training Accuracy:  78.1%, Loss: 0.3888\n",
      "Optimization Iteration:  37825, Training Accuracy:  76.6%, Loss: 0.3661\n",
      "Optimization Iteration:  37889, Training Accuracy:  78.1%, Loss: 0.4668\n",
      "Optimization Iteration:  37953, Training Accuracy:  84.4%, Loss: 0.3166\n",
      "Optimization Iteration:  38017, Training Accuracy:  78.1%, Loss: 0.3729\n",
      "Optimization Iteration:  38081, Training Accuracy:  71.9%, Loss: 0.4160\n",
      "Optimization Iteration:  38145, Training Accuracy:  81.2%, Loss: 0.3528\n",
      "Optimization Iteration:  38209, Training Accuracy:  85.9%, Loss: 0.3761\n",
      "Optimization Iteration:  38273, Training Accuracy:  67.2%, Loss: 0.4388\n",
      "Optimization Iteration:  38337, Training Accuracy:  95.3%, Loss: 0.2665\n",
      "Optimization Iteration:  38401, Training Accuracy:  79.7%, Loss: 0.4623\n",
      "Optimization Iteration:  38465, Training Accuracy:  65.6%, Loss: 0.4769\n",
      "Optimization Iteration:  38529, Training Accuracy:  78.1%, Loss: 0.4312\n",
      "Optimization Iteration:  38593, Training Accuracy:  78.1%, Loss: 0.4850\n",
      "Optimization Iteration:  38657, Training Accuracy:  68.8%, Loss: 0.4564\n",
      "Optimization Iteration:  38721, Training Accuracy:  70.3%, Loss: 0.4229\n",
      "Optimization Iteration:  38785, Training Accuracy:  70.3%, Loss: 0.4668\n",
      "Optimization Iteration:  38849, Training Accuracy:  76.6%, Loss: 0.3899\n",
      "Optimization Iteration:  38913, Training Accuracy:  75.0%, Loss: 0.4287\n",
      "Optimization Iteration:  38977, Training Accuracy:  84.4%, Loss: 0.3697\n",
      "Optimization Iteration:  39041, Training Accuracy:  75.0%, Loss: 0.3526\n",
      "Optimization Iteration:  39105, Training Accuracy:  70.3%, Loss: 0.4894\n",
      "Optimization Iteration:  39169, Training Accuracy:  73.4%, Loss: 0.3935\n",
      "Optimization Iteration:  39233, Training Accuracy:  78.1%, Loss: 0.4253\n",
      "Optimization Iteration:  39297, Training Accuracy:  78.1%, Loss: 0.4069\n",
      "Optimization Iteration:  39361, Training Accuracy:  76.6%, Loss: 0.3727\n",
      "Optimization Iteration:  39425, Training Accuracy:  65.6%, Loss: 0.5025\n",
      "Optimization Iteration:  39489, Training Accuracy:  78.1%, Loss: 0.3999\n",
      "Optimization Iteration:  39553, Training Accuracy:  73.4%, Loss: 0.3816\n",
      "Optimization Iteration:  39617, Training Accuracy:  76.6%, Loss: 0.4350\n",
      "Optimization Iteration:  39681, Training Accuracy:  73.4%, Loss: 0.3916\n",
      "Optimization Iteration:  39745, Training Accuracy:  73.4%, Loss: 0.4684\n",
      "Optimization Iteration:  39809, Training Accuracy:  79.7%, Loss: 0.4133\n",
      "Optimization Iteration:  39873, Training Accuracy:  68.8%, Loss: 0.5752\n",
      "Optimization Iteration:  39937, Training Accuracy:  78.1%, Loss: 0.4980\n",
      "Optimization Iteration:  40001, Training Accuracy:  67.2%, Loss: 0.4606\n",
      "Optimization Iteration:  40065, Training Accuracy:  78.1%, Loss: 0.3565\n",
      "Optimization Iteration:  40129, Training Accuracy:  67.2%, Loss: 0.5755\n",
      "Optimization Iteration:  40193, Training Accuracy:  84.4%, Loss: 0.4021\n",
      "Optimization Iteration:  40257, Training Accuracy:  68.8%, Loss: 0.4327\n",
      "Optimization Iteration:  40321, Training Accuracy:  73.4%, Loss: 0.4864\n",
      "Optimization Iteration:  40385, Training Accuracy:  85.9%, Loss: 0.3773\n",
      "Optimization Iteration:  40449, Training Accuracy:  73.4%, Loss: 0.4123\n",
      "Optimization Iteration:  40513, Training Accuracy:  73.4%, Loss: 0.4326\n",
      "Optimization Iteration:  40577, Training Accuracy:  81.2%, Loss: 0.3934\n",
      "Optimization Iteration:  40641, Training Accuracy:  73.4%, Loss: 0.3714\n",
      "Optimization Iteration:  40705, Training Accuracy:  78.1%, Loss: 0.4638\n",
      "Optimization Iteration:  40769, Training Accuracy:  84.4%, Loss: 0.3634\n",
      "Optimization Iteration:  40833, Training Accuracy:  75.0%, Loss: 0.4082\n",
      "Optimization Iteration:  40897, Training Accuracy:  71.9%, Loss: 0.4519\n",
      "Optimization Iteration:  40961, Training Accuracy:  81.2%, Loss: 0.3977\n",
      "Optimization Iteration:  41025, Training Accuracy:  78.1%, Loss: 0.3645\n",
      "Optimization Iteration:  41089, Training Accuracy:  71.9%, Loss: 0.4812\n",
      "Optimization Iteration:  41153, Training Accuracy:  76.6%, Loss: 0.4441\n",
      "Optimization Iteration:  41217, Training Accuracy:  78.1%, Loss: 0.4392\n",
      "Optimization Iteration:  41281, Training Accuracy:  68.8%, Loss: 0.4489\n",
      "Optimization Iteration:  41345, Training Accuracy:  62.5%, Loss: 0.4854\n",
      "Optimization Iteration:  41409, Training Accuracy:  67.2%, Loss: 0.4627\n",
      "Optimization Iteration:  41473, Training Accuracy:  70.3%, Loss: 0.4477\n",
      "Optimization Iteration:  41537, Training Accuracy:  71.9%, Loss: 0.4832\n",
      "Optimization Iteration:  41601, Training Accuracy:  73.4%, Loss: 0.3872\n",
      "Optimization Iteration:  41665, Training Accuracy:  73.4%, Loss: 0.4311\n",
      "Optimization Iteration:  41729, Training Accuracy:  75.0%, Loss: 0.3882\n",
      "Optimization Iteration:  41793, Training Accuracy:  79.7%, Loss: 0.4668\n",
      "Optimization Iteration:  41857, Training Accuracy:  68.8%, Loss: 0.5072\n",
      "Optimization Iteration:  41921, Training Accuracy:  73.4%, Loss: 0.3872\n",
      "Optimization Iteration:  41985, Training Accuracy:  70.3%, Loss: 0.4586\n",
      "Optimization Iteration:  42049, Training Accuracy:  71.9%, Loss: 0.4031\n",
      "Optimization Iteration:  42113, Training Accuracy:  68.8%, Loss: 0.4858\n",
      "Optimization Iteration:  42177, Training Accuracy:  76.6%, Loss: 0.4638\n",
      "Optimization Iteration:  42241, Training Accuracy:  78.1%, Loss: 0.4681\n",
      "Optimization Iteration:  42305, Training Accuracy:  73.4%, Loss: 0.5474\n",
      "Optimization Iteration:  42369, Training Accuracy:  76.6%, Loss: 0.4489\n",
      "Optimization Iteration:  42433, Training Accuracy:  71.9%, Loss: 0.4517\n",
      "Optimization Iteration:  42497, Training Accuracy:  67.2%, Loss: 0.4672\n",
      "Optimization Iteration:  42561, Training Accuracy:  79.7%, Loss: 0.3713\n",
      "Optimization Iteration:  42625, Training Accuracy:  78.1%, Loss: 0.4292\n",
      "Optimization Iteration:  42689, Training Accuracy:  73.4%, Loss: 0.4254\n",
      "Optimization Iteration:  42753, Training Accuracy:  71.9%, Loss: 0.4354\n",
      "Optimization Iteration:  42817, Training Accuracy:  79.7%, Loss: 0.3715\n",
      "Optimization Iteration:  42881, Training Accuracy:  70.3%, Loss: 0.4756\n",
      "Optimization Iteration:  42945, Training Accuracy:  76.6%, Loss: 0.4362\n",
      "Optimization Iteration:  43009, Training Accuracy:  75.0%, Loss: 0.4681\n",
      "Optimization Iteration:  43073, Training Accuracy:  67.2%, Loss: 0.4785\n",
      "Optimization Iteration:  43137, Training Accuracy:  71.9%, Loss: 0.4492\n",
      "Optimization Iteration:  43201, Training Accuracy:  71.9%, Loss: 0.4223\n",
      "Optimization Iteration:  43265, Training Accuracy:  71.9%, Loss: 0.4467\n",
      "Optimization Iteration:  43329, Training Accuracy:  75.0%, Loss: 0.4165\n",
      "Optimization Iteration:  43393, Training Accuracy:  79.7%, Loss: 0.4512\n",
      "Optimization Iteration:  43457, Training Accuracy:  75.0%, Loss: 0.4046\n",
      "Optimization Iteration:  43521, Training Accuracy:  81.2%, Loss: 0.4507\n",
      "Optimization Iteration:  43585, Training Accuracy:  71.9%, Loss: 0.4780\n",
      "Optimization Iteration:  43649, Training Accuracy:  78.1%, Loss: 0.4008\n",
      "Optimization Iteration:  43713, Training Accuracy:  75.0%, Loss: 0.4409\n",
      "Optimization Iteration:  43777, Training Accuracy:  79.7%, Loss: 0.3928\n",
      "Optimization Iteration:  43841, Training Accuracy:  67.2%, Loss: 0.4807\n",
      "Optimization Iteration:  43905, Training Accuracy:  76.6%, Loss: 0.4128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  43969, Training Accuracy:  73.4%, Loss: 0.4169\n",
      "Optimization Iteration:  44033, Training Accuracy:  59.4%, Loss: 0.5455\n",
      "Optimization Iteration:  44097, Training Accuracy:  82.8%, Loss: 0.3711\n",
      "Optimization Iteration:  44161, Training Accuracy:  81.2%, Loss: 0.3321\n",
      "Optimization Iteration:  44225, Training Accuracy:  75.0%, Loss: 0.4683\n",
      "Optimization Iteration:  44289, Training Accuracy:  78.1%, Loss: 0.4596\n",
      "Optimization Iteration:  44353, Training Accuracy:  76.6%, Loss: 0.3926\n",
      "Optimization Iteration:  44417, Training Accuracy:  78.1%, Loss: 0.3859\n",
      "Optimization Iteration:  44481, Training Accuracy:  78.1%, Loss: 0.4141\n",
      "Optimization Iteration:  44545, Training Accuracy:  71.9%, Loss: 0.3864\n",
      "Optimization Iteration:  44609, Training Accuracy:  78.1%, Loss: 0.4020\n",
      "Optimization Iteration:  44673, Training Accuracy:  73.4%, Loss: 0.6318\n",
      "Optimization Iteration:  44737, Training Accuracy:  78.1%, Loss: 0.4147\n",
      "Optimization Iteration:  44801, Training Accuracy:  75.0%, Loss: 0.4202\n",
      "Optimization Iteration:  44865, Training Accuracy:  79.7%, Loss: 0.3905\n",
      "Optimization Iteration:  44929, Training Accuracy:  82.8%, Loss: 0.3903\n",
      "Optimization Iteration:  44993, Training Accuracy:  67.2%, Loss: 0.5320\n",
      "Optimization Iteration:  45057, Training Accuracy:  73.4%, Loss: 0.4293\n",
      "Optimization Iteration:  45121, Training Accuracy:  81.2%, Loss: 0.3912\n",
      "Optimization Iteration:  45185, Training Accuracy:  81.2%, Loss: 0.3346\n",
      "Optimization Iteration:  45249, Training Accuracy:  70.3%, Loss: 0.4789\n",
      "Optimization Iteration:  45313, Training Accuracy:  79.7%, Loss: 0.4350\n",
      "Optimization Iteration:  45377, Training Accuracy:  79.7%, Loss: 0.4459\n",
      "Optimization Iteration:  45441, Training Accuracy:  76.6%, Loss: 0.4239\n",
      "Optimization Iteration:  45505, Training Accuracy:  75.0%, Loss: 0.4216\n",
      "Optimization Iteration:  45569, Training Accuracy:  82.8%, Loss: 0.3833\n",
      "Optimization Iteration:  45633, Training Accuracy:  78.1%, Loss: 0.4916\n",
      "Optimization Iteration:  45697, Training Accuracy:  71.9%, Loss: 0.3504\n",
      "Optimization Iteration:  45761, Training Accuracy:  84.4%, Loss: 0.3614\n",
      "Optimization Iteration:  45825, Training Accuracy:  71.9%, Loss: 0.4281\n",
      "Optimization Iteration:  45889, Training Accuracy:  82.8%, Loss: 0.4082\n",
      "Optimization Iteration:  45953, Training Accuracy:  78.1%, Loss: 0.3742\n",
      "Optimization Iteration:  46017, Training Accuracy:  76.6%, Loss: 0.4997\n",
      "Optimization Iteration:  46081, Training Accuracy:  82.8%, Loss: 0.3537\n",
      "Optimization Iteration:  46145, Training Accuracy:  64.1%, Loss: 0.4933\n",
      "Optimization Iteration:  46209, Training Accuracy:  81.2%, Loss: 0.3883\n",
      "Optimization Iteration:  46273, Training Accuracy:  68.8%, Loss: 0.5273\n",
      "Optimization Iteration:  46337, Training Accuracy:  76.6%, Loss: 0.4268\n",
      "Optimization Iteration:  46401, Training Accuracy:  79.7%, Loss: 0.3666\n",
      "Optimization Iteration:  46465, Training Accuracy:  71.9%, Loss: 0.4647\n",
      "Optimization Iteration:  46529, Training Accuracy:  71.9%, Loss: 0.4010\n",
      "Optimization Iteration:  46593, Training Accuracy:  78.1%, Loss: 0.4114\n",
      "Optimization Iteration:  46657, Training Accuracy:  76.6%, Loss: 0.5164\n",
      "Optimization Iteration:  46721, Training Accuracy:  75.0%, Loss: 0.5116\n",
      "Optimization Iteration:  46785, Training Accuracy:  60.9%, Loss: 0.5474\n",
      "Optimization Iteration:  46849, Training Accuracy:  71.9%, Loss: 0.3847\n",
      "Optimization Iteration:  46913, Training Accuracy:  79.7%, Loss: 0.4346\n",
      "Optimization Iteration:  46977, Training Accuracy:  70.3%, Loss: 0.4416\n",
      "Optimization Iteration:  47041, Training Accuracy:  79.7%, Loss: 0.3901\n",
      "Optimization Iteration:  47105, Training Accuracy:  68.8%, Loss: 0.4889\n",
      "Optimization Iteration:  47169, Training Accuracy:  71.9%, Loss: 0.4449\n",
      "Optimization Iteration:  47233, Training Accuracy:  73.4%, Loss: 0.4014\n",
      "Optimization Iteration:  47297, Training Accuracy:  62.5%, Loss: 0.4415\n",
      "Optimization Iteration:  47361, Training Accuracy:  79.7%, Loss: 0.4287\n",
      "Optimization Iteration:  47425, Training Accuracy:  75.0%, Loss: 0.4089\n",
      "Optimization Iteration:  47489, Training Accuracy:  75.0%, Loss: 0.4464\n",
      "Optimization Iteration:  47553, Training Accuracy:  82.8%, Loss: 0.4184\n",
      "Optimization Iteration:  47617, Training Accuracy:  75.0%, Loss: 0.4384\n",
      "Optimization Iteration:  47681, Training Accuracy:  79.7%, Loss: 0.3582\n",
      "Optimization Iteration:  47745, Training Accuracy:  75.0%, Loss: 0.4275\n",
      "Optimization Iteration:  47809, Training Accuracy:  62.5%, Loss: 0.5582\n",
      "Optimization Iteration:  47873, Training Accuracy:  85.9%, Loss: 0.3035\n",
      "Optimization Iteration:  47937, Training Accuracy:  71.9%, Loss: 0.4218\n",
      "Optimization Iteration:  48001, Training Accuracy:  73.4%, Loss: 0.4497\n",
      "Optimization Iteration:  48065, Training Accuracy:  70.3%, Loss: 0.4002\n",
      "Optimization Iteration:  48129, Training Accuracy:  71.9%, Loss: 0.4832\n",
      "Optimization Iteration:  48193, Training Accuracy:  65.6%, Loss: 0.5378\n",
      "Optimization Iteration:  48257, Training Accuracy:  78.1%, Loss: 0.3851\n",
      "Optimization Iteration:  48321, Training Accuracy:  76.6%, Loss: 0.4339\n",
      "Optimization Iteration:  48385, Training Accuracy:  73.4%, Loss: 0.5566\n",
      "Optimization Iteration:  48449, Training Accuracy:  70.3%, Loss: 0.5406\n",
      "Optimization Iteration:  48513, Training Accuracy:  68.8%, Loss: 0.3870\n",
      "Optimization Iteration:  48577, Training Accuracy:  57.8%, Loss: 0.5678\n",
      "Optimization Iteration:  48641, Training Accuracy:  79.7%, Loss: 0.3831\n",
      "Optimization Iteration:  48705, Training Accuracy:  70.3%, Loss: 0.4364\n",
      "Optimization Iteration:  48769, Training Accuracy:  78.1%, Loss: 0.3674\n",
      "Optimization Iteration:  48833, Training Accuracy:  78.1%, Loss: 0.3842\n",
      "Optimization Iteration:  48897, Training Accuracy:  75.0%, Loss: 0.4718\n",
      "Optimization Iteration:  48961, Training Accuracy:  79.7%, Loss: 0.4203\n",
      "Optimization Iteration:  49025, Training Accuracy:  75.0%, Loss: 0.4433\n",
      "Optimization Iteration:  49089, Training Accuracy:  76.6%, Loss: 0.3745\n",
      "Optimization Iteration:  49153, Training Accuracy:  75.0%, Loss: 0.4243\n",
      "Optimization Iteration:  49217, Training Accuracy:  68.8%, Loss: 0.4082\n",
      "Optimization Iteration:  49281, Training Accuracy:  65.6%, Loss: 0.4470\n",
      "Optimization Iteration:  49345, Training Accuracy:  75.0%, Loss: 0.4290\n",
      "Optimization Iteration:  49409, Training Accuracy:  73.4%, Loss: 0.4151\n",
      "Optimization Iteration:  49473, Training Accuracy:  59.4%, Loss: 0.4505\n",
      "Optimization Iteration:  49537, Training Accuracy:  73.4%, Loss: 0.3723\n",
      "Optimization Iteration:  49601, Training Accuracy:  79.7%, Loss: 0.4088\n",
      "Optimization Iteration:  49665, Training Accuracy:  79.7%, Loss: 0.3040\n",
      "Optimization Iteration:  49729, Training Accuracy:  71.9%, Loss: 0.5202\n",
      "Optimization Iteration:  49793, Training Accuracy:  71.9%, Loss: 0.3924\n",
      "Optimization Iteration:  49857, Training Accuracy:  76.6%, Loss: 0.4373\n",
      "Optimization Iteration:  49921, Training Accuracy:  73.4%, Loss: 0.4130\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 7\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  70.3%, Loss: 0.4941\n",
      "Optimization Iteration:    129, Training Accuracy:  76.6%, Loss: 0.5030\n",
      "Optimization Iteration:    193, Training Accuracy:  75.0%, Loss: 0.4609\n",
      "Optimization Iteration:    257, Training Accuracy:  70.3%, Loss: 0.3999\n",
      "Optimization Iteration:    321, Training Accuracy:  78.1%, Loss: 0.3770\n",
      "Optimization Iteration:    385, Training Accuracy:  73.4%, Loss: 0.4625\n",
      "Optimization Iteration:    449, Training Accuracy:  79.7%, Loss: 0.3933\n",
      "Optimization Iteration:    513, Training Accuracy:  75.0%, Loss: 0.4489\n",
      "Optimization Iteration:    577, Training Accuracy:  70.3%, Loss: 0.4199\n",
      "Optimization Iteration:    641, Training Accuracy:  73.4%, Loss: 0.4372\n",
      "Optimization Iteration:    705, Training Accuracy:  70.3%, Loss: 0.5356\n",
      "Optimization Iteration:    769, Training Accuracy:  73.4%, Loss: 0.4969\n",
      "Optimization Iteration:    833, Training Accuracy:  78.1%, Loss: 0.3944\n",
      "Optimization Iteration:    897, Training Accuracy:  85.9%, Loss: 0.2986\n",
      "Optimization Iteration:    961, Training Accuracy:  76.6%, Loss: 0.3325\n",
      "Optimization Iteration:   1025, Training Accuracy:  82.8%, Loss: 0.4388\n",
      "Optimization Iteration:   1089, Training Accuracy:  67.2%, Loss: 0.5226\n",
      "Optimization Iteration:   1153, Training Accuracy:  64.1%, Loss: 0.5380\n",
      "Optimization Iteration:   1217, Training Accuracy:  75.0%, Loss: 0.4461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   1281, Training Accuracy:  73.4%, Loss: 0.4117\n",
      "Optimization Iteration:   1345, Training Accuracy:  76.6%, Loss: 0.4449\n",
      "Optimization Iteration:   1409, Training Accuracy:  73.4%, Loss: 0.4414\n",
      "Optimization Iteration:   1473, Training Accuracy:  70.3%, Loss: 0.4107\n",
      "Optimization Iteration:   1537, Training Accuracy:  75.0%, Loss: 0.4273\n",
      "Optimization Iteration:   1601, Training Accuracy:  78.1%, Loss: 0.4250\n",
      "Optimization Iteration:   1665, Training Accuracy:  68.8%, Loss: 0.4276\n",
      "Optimization Iteration:   1729, Training Accuracy:  73.4%, Loss: 0.4486\n",
      "Optimization Iteration:   1793, Training Accuracy:  64.1%, Loss: 0.5637\n",
      "Optimization Iteration:   1857, Training Accuracy:  75.0%, Loss: 0.4104\n",
      "Optimization Iteration:   1921, Training Accuracy:  67.2%, Loss: 0.4920\n",
      "Optimization Iteration:   1985, Training Accuracy:  71.9%, Loss: 0.4598\n",
      "Optimization Iteration:   2049, Training Accuracy:  73.4%, Loss: 0.4012\n",
      "Optimization Iteration:   2113, Training Accuracy:  71.9%, Loss: 0.3785\n",
      "Optimization Iteration:   2177, Training Accuracy:  68.8%, Loss: 0.4076\n",
      "Optimization Iteration:   2241, Training Accuracy:  79.7%, Loss: 0.4157\n",
      "Optimization Iteration:   2305, Training Accuracy:  71.9%, Loss: 0.3694\n",
      "Optimization Iteration:   2369, Training Accuracy:  73.4%, Loss: 0.4541\n",
      "Optimization Iteration:   2433, Training Accuracy:  73.4%, Loss: 0.4702\n",
      "Optimization Iteration:   2497, Training Accuracy:  76.6%, Loss: 0.4170\n",
      "Optimization Iteration:   2561, Training Accuracy:  79.7%, Loss: 0.3708\n",
      "Optimization Iteration:   2625, Training Accuracy:  79.7%, Loss: 0.4370\n",
      "Optimization Iteration:   2689, Training Accuracy:  73.4%, Loss: 0.3970\n",
      "Optimization Iteration:   2753, Training Accuracy:  73.4%, Loss: 0.3680\n",
      "Optimization Iteration:   2817, Training Accuracy:  79.7%, Loss: 0.3770\n",
      "Optimization Iteration:   2881, Training Accuracy:  64.1%, Loss: 0.4822\n",
      "Optimization Iteration:   2945, Training Accuracy:  75.0%, Loss: 0.4912\n",
      "Optimization Iteration:   3009, Training Accuracy:  68.8%, Loss: 0.4339\n",
      "Optimization Iteration:   3073, Training Accuracy:  82.8%, Loss: 0.3115\n",
      "Optimization Iteration:   3137, Training Accuracy:  79.7%, Loss: 0.4158\n",
      "Optimization Iteration:   3201, Training Accuracy:  73.4%, Loss: 0.4300\n",
      "Optimization Iteration:   3265, Training Accuracy:  70.3%, Loss: 0.4120\n",
      "Optimization Iteration:   3329, Training Accuracy:  73.4%, Loss: 0.4343\n",
      "Optimization Iteration:   3393, Training Accuracy:  68.8%, Loss: 0.4417\n",
      "Optimization Iteration:   3457, Training Accuracy:  71.9%, Loss: 0.4576\n",
      "Optimization Iteration:   3521, Training Accuracy:  75.0%, Loss: 0.4807\n",
      "Optimization Iteration:   3585, Training Accuracy:  65.6%, Loss: 0.5438\n",
      "Optimization Iteration:   3649, Training Accuracy:  76.6%, Loss: 0.4240\n",
      "Optimization Iteration:   3713, Training Accuracy:  75.0%, Loss: 0.3460\n",
      "Optimization Iteration:   3777, Training Accuracy:  67.2%, Loss: 0.4949\n",
      "Optimization Iteration:   3841, Training Accuracy:  71.9%, Loss: 0.4159\n",
      "Optimization Iteration:   3905, Training Accuracy:  70.3%, Loss: 0.5596\n",
      "Optimization Iteration:   3969, Training Accuracy:  71.9%, Loss: 0.4136\n",
      "Optimization Iteration:   4033, Training Accuracy:  81.2%, Loss: 0.3765\n",
      "Optimization Iteration:   4097, Training Accuracy:  62.5%, Loss: 0.4694\n",
      "Optimization Iteration:   4161, Training Accuracy:  76.6%, Loss: 0.4133\n",
      "Optimization Iteration:   4225, Training Accuracy:  81.2%, Loss: 0.4148\n",
      "Optimization Iteration:   4289, Training Accuracy:  73.4%, Loss: 0.3793\n",
      "Optimization Iteration:   4353, Training Accuracy:  71.9%, Loss: 0.4649\n",
      "Optimization Iteration:   4417, Training Accuracy:  78.1%, Loss: 0.4026\n",
      "Optimization Iteration:   4481, Training Accuracy:  79.7%, Loss: 0.4552\n",
      "Optimization Iteration:   4545, Training Accuracy:  71.9%, Loss: 0.4812\n",
      "Optimization Iteration:   4609, Training Accuracy:  70.3%, Loss: 0.4291\n",
      "Optimization Iteration:   4673, Training Accuracy:  73.4%, Loss: 0.5108\n",
      "Optimization Iteration:   4737, Training Accuracy:  73.4%, Loss: 0.4017\n",
      "Optimization Iteration:   4801, Training Accuracy:  75.0%, Loss: 0.5002\n",
      "Optimization Iteration:   4865, Training Accuracy:  76.6%, Loss: 0.4130\n",
      "Optimization Iteration:   4929, Training Accuracy:  73.4%, Loss: 0.4454\n",
      "Optimization Iteration:   4993, Training Accuracy:  78.1%, Loss: 0.3543\n",
      "Optimization Iteration:   5057, Training Accuracy:  71.9%, Loss: 0.4627\n",
      "Optimization Iteration:   5121, Training Accuracy:  79.7%, Loss: 0.3472\n",
      "Optimization Iteration:   5185, Training Accuracy:  73.4%, Loss: 0.4329\n",
      "Optimization Iteration:   5249, Training Accuracy:  65.6%, Loss: 0.5047\n",
      "Optimization Iteration:   5313, Training Accuracy:  73.4%, Loss: 0.4427\n",
      "Optimization Iteration:   5377, Training Accuracy:  70.3%, Loss: 0.4576\n",
      "Optimization Iteration:   5441, Training Accuracy:  70.3%, Loss: 0.4622\n",
      "Optimization Iteration:   5505, Training Accuracy:  85.9%, Loss: 0.3637\n",
      "Optimization Iteration:   5569, Training Accuracy:  71.9%, Loss: 0.4052\n",
      "Optimization Iteration:   5633, Training Accuracy:  71.9%, Loss: 0.4625\n",
      "Optimization Iteration:   5697, Training Accuracy:  78.1%, Loss: 0.4579\n",
      "Optimization Iteration:   5761, Training Accuracy:  79.7%, Loss: 0.3861\n",
      "Optimization Iteration:   5825, Training Accuracy:  73.4%, Loss: 0.4596\n",
      "Optimization Iteration:   5889, Training Accuracy:  79.7%, Loss: 0.4240\n",
      "Optimization Iteration:   5953, Training Accuracy:  73.4%, Loss: 0.4426\n",
      "Optimization Iteration:   6017, Training Accuracy:  62.5%, Loss: 0.5457\n",
      "Optimization Iteration:   6081, Training Accuracy:  81.2%, Loss: 0.3475\n",
      "Optimization Iteration:   6145, Training Accuracy:  78.1%, Loss: 0.4327\n",
      "Optimization Iteration:   6209, Training Accuracy:  67.2%, Loss: 0.3957\n",
      "Optimization Iteration:   6273, Training Accuracy:  73.4%, Loss: 0.4306\n",
      "Optimization Iteration:   6337, Training Accuracy:  68.8%, Loss: 0.4698\n",
      "Optimization Iteration:   6401, Training Accuracy:  76.6%, Loss: 0.4175\n",
      "Optimization Iteration:   6465, Training Accuracy:  87.5%, Loss: 0.3279\n",
      "Optimization Iteration:   6529, Training Accuracy:  81.2%, Loss: 0.3888\n",
      "Optimization Iteration:   6593, Training Accuracy:  70.3%, Loss: 0.4602\n",
      "Optimization Iteration:   6657, Training Accuracy:  73.4%, Loss: 0.3951\n",
      "Optimization Iteration:   6721, Training Accuracy:  75.0%, Loss: 0.3345\n",
      "Optimization Iteration:   6785, Training Accuracy:  76.6%, Loss: 0.3908\n",
      "Optimization Iteration:   6849, Training Accuracy:  70.3%, Loss: 0.5071\n",
      "Optimization Iteration:   6913, Training Accuracy:  75.0%, Loss: 0.3993\n",
      "Optimization Iteration:   6977, Training Accuracy:  70.3%, Loss: 0.4963\n",
      "Optimization Iteration:   7041, Training Accuracy:  75.0%, Loss: 0.3528\n",
      "Optimization Iteration:   7105, Training Accuracy:  76.6%, Loss: 0.3708\n",
      "Optimization Iteration:   7169, Training Accuracy:  73.4%, Loss: 0.4303\n",
      "Optimization Iteration:   7233, Training Accuracy:  75.0%, Loss: 0.4898\n",
      "Optimization Iteration:   7297, Training Accuracy:  82.8%, Loss: 0.4403\n",
      "Optimization Iteration:   7361, Training Accuracy:  68.8%, Loss: 0.4735\n",
      "Optimization Iteration:   7425, Training Accuracy:  73.4%, Loss: 0.3956\n",
      "Optimization Iteration:   7489, Training Accuracy:  76.6%, Loss: 0.4925\n",
      "Optimization Iteration:   7553, Training Accuracy:  73.4%, Loss: 0.5054\n",
      "Optimization Iteration:   7617, Training Accuracy:  78.1%, Loss: 0.4049\n",
      "Optimization Iteration:   7681, Training Accuracy:  81.2%, Loss: 0.4426\n",
      "Optimization Iteration:   7745, Training Accuracy:  73.4%, Loss: 0.4668\n",
      "Optimization Iteration:   7809, Training Accuracy:  75.0%, Loss: 0.5306\n",
      "Optimization Iteration:   7873, Training Accuracy:  68.8%, Loss: 0.4245\n",
      "Optimization Iteration:   7937, Training Accuracy:  85.9%, Loss: 0.3515\n",
      "Optimization Iteration:   8001, Training Accuracy:  79.7%, Loss: 0.4001\n",
      "Optimization Iteration:   8065, Training Accuracy:  76.6%, Loss: 0.4710\n",
      "Optimization Iteration:   8129, Training Accuracy:  70.3%, Loss: 0.4497\n",
      "Optimization Iteration:   8193, Training Accuracy:  67.2%, Loss: 0.4563\n",
      "Optimization Iteration:   8257, Training Accuracy:  75.0%, Loss: 0.4589\n",
      "Optimization Iteration:   8321, Training Accuracy:  71.9%, Loss: 0.4715\n",
      "Optimization Iteration:   8385, Training Accuracy:  79.7%, Loss: 0.4730\n",
      "Optimization Iteration:   8449, Training Accuracy:  70.3%, Loss: 0.5335\n",
      "Optimization Iteration:   8513, Training Accuracy:  84.4%, Loss: 0.3745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   8577, Training Accuracy:  65.6%, Loss: 0.5119\n",
      "Optimization Iteration:   8641, Training Accuracy:  78.1%, Loss: 0.4458\n",
      "Optimization Iteration:   8705, Training Accuracy:  64.1%, Loss: 0.4768\n",
      "Optimization Iteration:   8769, Training Accuracy:  75.0%, Loss: 0.4083\n",
      "Optimization Iteration:   8833, Training Accuracy:  73.4%, Loss: 0.4519\n",
      "Optimization Iteration:   8897, Training Accuracy:  73.4%, Loss: 0.4614\n",
      "Optimization Iteration:   8961, Training Accuracy:  67.2%, Loss: 0.4517\n",
      "Optimization Iteration:   9025, Training Accuracy:  71.9%, Loss: 0.4953\n",
      "Optimization Iteration:   9089, Training Accuracy:  64.1%, Loss: 0.5526\n",
      "Optimization Iteration:   9153, Training Accuracy:  70.3%, Loss: 0.4407\n",
      "Optimization Iteration:   9217, Training Accuracy:  71.9%, Loss: 0.4437\n",
      "Optimization Iteration:   9281, Training Accuracy:  76.6%, Loss: 0.4303\n",
      "Optimization Iteration:   9345, Training Accuracy:  73.4%, Loss: 0.4917\n",
      "Optimization Iteration:   9409, Training Accuracy:  78.1%, Loss: 0.5382\n",
      "Optimization Iteration:   9473, Training Accuracy:  78.1%, Loss: 0.4108\n",
      "Optimization Iteration:   9537, Training Accuracy:  78.1%, Loss: 0.4416\n",
      "Optimization Iteration:   9601, Training Accuracy:  73.4%, Loss: 0.4423\n",
      "Optimization Iteration:   9665, Training Accuracy:  62.5%, Loss: 0.5096\n",
      "Optimization Iteration:   9729, Training Accuracy:  76.6%, Loss: 0.4801\n",
      "Optimization Iteration:   9793, Training Accuracy:  85.9%, Loss: 0.2823\n",
      "Optimization Iteration:   9857, Training Accuracy:  75.0%, Loss: 0.4238\n",
      "Optimization Iteration:   9921, Training Accuracy:  70.3%, Loss: 0.4048\n",
      "Optimization Iteration:   9985, Training Accuracy:  64.1%, Loss: 0.4843\n",
      "Optimization Iteration:  10049, Training Accuracy:  75.0%, Loss: 0.4584\n",
      "Optimization Iteration:  10113, Training Accuracy:  71.9%, Loss: 0.4370\n",
      "Optimization Iteration:  10177, Training Accuracy:  62.5%, Loss: 0.4974\n",
      "Optimization Iteration:  10241, Training Accuracy:  70.3%, Loss: 0.4637\n",
      "Optimization Iteration:  10305, Training Accuracy:  78.1%, Loss: 0.4236\n",
      "Optimization Iteration:  10369, Training Accuracy:  70.3%, Loss: 0.4359\n",
      "Optimization Iteration:  10433, Training Accuracy:  73.4%, Loss: 0.4597\n",
      "Optimization Iteration:  10497, Training Accuracy:  71.9%, Loss: 0.5146\n",
      "Optimization Iteration:  10561, Training Accuracy:  73.4%, Loss: 0.3996\n",
      "Optimization Iteration:  10625, Training Accuracy:  75.0%, Loss: 0.4187\n",
      "Optimization Iteration:  10689, Training Accuracy:  76.6%, Loss: 0.3914\n",
      "Optimization Iteration:  10753, Training Accuracy:  75.0%, Loss: 0.4361\n",
      "Optimization Iteration:  10817, Training Accuracy:  73.4%, Loss: 0.5103\n",
      "Optimization Iteration:  10881, Training Accuracy:  81.2%, Loss: 0.3430\n",
      "Optimization Iteration:  10945, Training Accuracy:  73.4%, Loss: 0.5249\n",
      "Optimization Iteration:  11009, Training Accuracy:  71.9%, Loss: 0.4071\n",
      "Optimization Iteration:  11073, Training Accuracy:  70.3%, Loss: 0.4181\n",
      "Optimization Iteration:  11137, Training Accuracy:  71.9%, Loss: 0.4317\n",
      "Optimization Iteration:  11201, Training Accuracy:  81.2%, Loss: 0.3796\n",
      "Optimization Iteration:  11265, Training Accuracy:  76.6%, Loss: 0.3977\n",
      "Optimization Iteration:  11329, Training Accuracy:  78.1%, Loss: 0.4719\n",
      "Optimization Iteration:  11393, Training Accuracy:  65.6%, Loss: 0.4710\n",
      "Optimization Iteration:  11457, Training Accuracy:  79.7%, Loss: 0.4020\n",
      "Optimization Iteration:  11521, Training Accuracy:  82.8%, Loss: 0.4024\n",
      "Optimization Iteration:  11585, Training Accuracy:  79.7%, Loss: 0.3320\n",
      "Optimization Iteration:  11649, Training Accuracy:  70.3%, Loss: 0.4639\n",
      "Optimization Iteration:  11713, Training Accuracy:  70.3%, Loss: 0.3595\n",
      "Optimization Iteration:  11777, Training Accuracy:  73.4%, Loss: 0.5003\n",
      "Optimization Iteration:  11841, Training Accuracy:  79.7%, Loss: 0.4104\n",
      "Optimization Iteration:  11905, Training Accuracy:  84.4%, Loss: 0.3788\n",
      "Optimization Iteration:  11969, Training Accuracy:  75.0%, Loss: 0.4028\n",
      "Optimization Iteration:  12033, Training Accuracy:  75.0%, Loss: 0.4191\n",
      "Optimization Iteration:  12097, Training Accuracy:  76.6%, Loss: 0.3600\n",
      "Optimization Iteration:  12161, Training Accuracy:  75.0%, Loss: 0.4418\n",
      "Optimization Iteration:  12225, Training Accuracy:  79.7%, Loss: 0.4129\n",
      "Optimization Iteration:  12289, Training Accuracy:  76.6%, Loss: 0.3703\n",
      "Optimization Iteration:  12353, Training Accuracy:  85.9%, Loss: 0.3634\n",
      "Optimization Iteration:  12417, Training Accuracy:  67.2%, Loss: 0.4133\n",
      "Optimization Iteration:  12481, Training Accuracy:  73.4%, Loss: 0.3756\n",
      "Optimization Iteration:  12545, Training Accuracy:  73.4%, Loss: 0.4656\n",
      "Optimization Iteration:  12609, Training Accuracy:  78.1%, Loss: 0.4066\n",
      "Optimization Iteration:  12673, Training Accuracy:  76.6%, Loss: 0.3599\n",
      "Optimization Iteration:  12737, Training Accuracy:  67.2%, Loss: 0.4992\n",
      "Optimization Iteration:  12801, Training Accuracy:  70.3%, Loss: 0.4924\n",
      "Optimization Iteration:  12865, Training Accuracy:  84.4%, Loss: 0.3535\n",
      "Optimization Iteration:  12929, Training Accuracy:  67.2%, Loss: 0.4520\n",
      "Optimization Iteration:  12993, Training Accuracy:  73.4%, Loss: 0.3962\n",
      "Optimization Iteration:  13057, Training Accuracy:  73.4%, Loss: 0.4428\n",
      "Optimization Iteration:  13121, Training Accuracy:  75.0%, Loss: 0.4147\n",
      "Optimization Iteration:  13185, Training Accuracy:  73.4%, Loss: 0.5438\n",
      "Optimization Iteration:  13249, Training Accuracy:  78.1%, Loss: 0.4173\n",
      "Optimization Iteration:  13313, Training Accuracy:  68.8%, Loss: 0.5442\n",
      "Optimization Iteration:  13377, Training Accuracy:  76.6%, Loss: 0.4184\n",
      "Optimization Iteration:  13441, Training Accuracy:  70.3%, Loss: 0.4477\n",
      "Optimization Iteration:  13505, Training Accuracy:  71.9%, Loss: 0.3861\n",
      "Optimization Iteration:  13569, Training Accuracy:  84.4%, Loss: 0.3003\n",
      "Optimization Iteration:  13633, Training Accuracy:  73.4%, Loss: 0.4138\n",
      "Optimization Iteration:  13697, Training Accuracy:  73.4%, Loss: 0.3677\n",
      "Optimization Iteration:  13761, Training Accuracy:  82.8%, Loss: 0.3414\n",
      "Optimization Iteration:  13825, Training Accuracy:  70.3%, Loss: 0.6183\n",
      "Optimization Iteration:  13889, Training Accuracy:  81.2%, Loss: 0.5281\n",
      "Optimization Iteration:  13953, Training Accuracy:  82.8%, Loss: 0.3600\n",
      "Optimization Iteration:  14017, Training Accuracy:  81.2%, Loss: 0.4314\n",
      "Optimization Iteration:  14081, Training Accuracy:  78.1%, Loss: 0.3715\n",
      "Optimization Iteration:  14145, Training Accuracy:  79.7%, Loss: 0.4024\n",
      "Optimization Iteration:  14209, Training Accuracy:  79.7%, Loss: 0.4616\n",
      "Optimization Iteration:  14273, Training Accuracy:  78.1%, Loss: 0.4302\n",
      "Optimization Iteration:  14337, Training Accuracy:  78.1%, Loss: 0.3510\n",
      "Optimization Iteration:  14401, Training Accuracy:  68.8%, Loss: 0.4457\n",
      "Optimization Iteration:  14465, Training Accuracy:  64.1%, Loss: 0.5503\n",
      "Optimization Iteration:  14529, Training Accuracy:  79.7%, Loss: 0.4975\n",
      "Optimization Iteration:  14593, Training Accuracy:  85.9%, Loss: 0.3615\n",
      "Optimization Iteration:  14657, Training Accuracy:  71.9%, Loss: 0.4320\n",
      "Optimization Iteration:  14721, Training Accuracy:  71.9%, Loss: 0.4064\n",
      "Optimization Iteration:  14785, Training Accuracy:  75.0%, Loss: 0.4776\n",
      "Optimization Iteration:  14849, Training Accuracy:  76.6%, Loss: 0.3967\n",
      "Optimization Iteration:  14913, Training Accuracy:  71.9%, Loss: 0.3846\n",
      "Optimization Iteration:  14977, Training Accuracy:  68.8%, Loss: 0.4375\n",
      "Optimization Iteration:  15041, Training Accuracy:  73.4%, Loss: 0.5171\n",
      "Optimization Iteration:  15105, Training Accuracy:  84.4%, Loss: 0.3950\n",
      "Optimization Iteration:  15169, Training Accuracy:  68.8%, Loss: 0.4384\n",
      "Optimization Iteration:  15233, Training Accuracy:  70.3%, Loss: 0.4169\n",
      "Optimization Iteration:  15297, Training Accuracy:  75.0%, Loss: 0.4797\n",
      "Optimization Iteration:  15361, Training Accuracy:  82.8%, Loss: 0.3774\n",
      "Optimization Iteration:  15425, Training Accuracy:  78.1%, Loss: 0.4018\n",
      "Optimization Iteration:  15489, Training Accuracy:  65.6%, Loss: 0.5602\n",
      "Optimization Iteration:  15553, Training Accuracy:  79.7%, Loss: 0.4055\n",
      "Optimization Iteration:  15617, Training Accuracy:  76.6%, Loss: 0.4497\n",
      "Optimization Iteration:  15681, Training Accuracy:  81.2%, Loss: 0.3255\n",
      "Optimization Iteration:  15745, Training Accuracy:  84.4%, Loss: 0.3672\n",
      "Optimization Iteration:  15809, Training Accuracy:  73.4%, Loss: 0.4658\n",
      "Optimization Iteration:  15873, Training Accuracy:  79.7%, Loss: 0.4145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  15937, Training Accuracy:  75.0%, Loss: 0.4194\n",
      "Optimization Iteration:  16001, Training Accuracy:  71.9%, Loss: 0.4619\n",
      "Optimization Iteration:  16065, Training Accuracy:  81.2%, Loss: 0.4275\n",
      "Optimization Iteration:  16129, Training Accuracy:  73.4%, Loss: 0.4316\n",
      "Optimization Iteration:  16193, Training Accuracy:  76.6%, Loss: 0.3849\n",
      "Optimization Iteration:  16257, Training Accuracy:  73.4%, Loss: 0.4691\n",
      "Optimization Iteration:  16321, Training Accuracy:  73.4%, Loss: 0.4889\n",
      "Optimization Iteration:  16385, Training Accuracy:  75.0%, Loss: 0.4504\n",
      "Optimization Iteration:  16449, Training Accuracy:  68.8%, Loss: 0.4070\n",
      "Optimization Iteration:  16513, Training Accuracy:  79.7%, Loss: 0.3534\n",
      "Optimization Iteration:  16577, Training Accuracy:  79.7%, Loss: 0.3878\n",
      "Optimization Iteration:  16641, Training Accuracy:  70.3%, Loss: 0.4989\n",
      "Optimization Iteration:  16705, Training Accuracy:  76.6%, Loss: 0.4551\n",
      "Optimization Iteration:  16769, Training Accuracy:  75.0%, Loss: 0.3586\n",
      "Optimization Iteration:  16833, Training Accuracy:  60.9%, Loss: 0.4701\n",
      "Optimization Iteration:  16897, Training Accuracy:  81.2%, Loss: 0.3824\n",
      "Optimization Iteration:  16961, Training Accuracy:  70.3%, Loss: 0.4152\n",
      "Optimization Iteration:  17025, Training Accuracy:  71.9%, Loss: 0.4277\n",
      "Optimization Iteration:  17089, Training Accuracy:  68.8%, Loss: 0.4711\n",
      "Optimization Iteration:  17153, Training Accuracy:  70.3%, Loss: 0.4095\n",
      "Optimization Iteration:  17217, Training Accuracy:  78.1%, Loss: 0.4686\n",
      "Optimization Iteration:  17281, Training Accuracy:  71.9%, Loss: 0.4653\n",
      "Optimization Iteration:  17345, Training Accuracy:  73.4%, Loss: 0.4618\n",
      "Optimization Iteration:  17409, Training Accuracy:  71.9%, Loss: 0.4109\n",
      "Optimization Iteration:  17473, Training Accuracy:  57.8%, Loss: 0.6117\n",
      "Optimization Iteration:  17537, Training Accuracy:  71.9%, Loss: 0.4048\n",
      "Optimization Iteration:  17601, Training Accuracy:  67.2%, Loss: 0.4681\n",
      "Optimization Iteration:  17665, Training Accuracy:  84.4%, Loss: 0.3712\n",
      "Optimization Iteration:  17729, Training Accuracy:  75.0%, Loss: 0.3980\n",
      "Optimization Iteration:  17793, Training Accuracy:  68.8%, Loss: 0.4840\n",
      "Optimization Iteration:  17857, Training Accuracy:  67.2%, Loss: 0.4896\n",
      "Optimization Iteration:  17921, Training Accuracy:  78.1%, Loss: 0.3574\n",
      "Optimization Iteration:  17985, Training Accuracy:  78.1%, Loss: 0.3683\n",
      "Optimization Iteration:  18049, Training Accuracy:  78.1%, Loss: 0.3467\n",
      "Optimization Iteration:  18113, Training Accuracy:  70.3%, Loss: 0.4996\n",
      "Optimization Iteration:  18177, Training Accuracy:  79.7%, Loss: 0.5357\n",
      "Optimization Iteration:  18241, Training Accuracy:  73.4%, Loss: 0.4400\n",
      "Optimization Iteration:  18305, Training Accuracy:  68.8%, Loss: 0.4878\n",
      "Optimization Iteration:  18369, Training Accuracy:  73.4%, Loss: 0.3836\n",
      "Optimization Iteration:  18433, Training Accuracy:  71.9%, Loss: 0.4576\n",
      "Optimization Iteration:  18497, Training Accuracy:  70.3%, Loss: 0.4246\n",
      "Optimization Iteration:  18561, Training Accuracy:  70.3%, Loss: 0.4685\n",
      "Optimization Iteration:  18625, Training Accuracy:  73.4%, Loss: 0.4814\n",
      "Optimization Iteration:  18689, Training Accuracy:  81.2%, Loss: 0.4246\n",
      "Optimization Iteration:  18753, Training Accuracy:  76.6%, Loss: 0.3897\n",
      "Optimization Iteration:  18817, Training Accuracy:  79.7%, Loss: 0.3956\n",
      "Optimization Iteration:  18881, Training Accuracy:  76.6%, Loss: 0.3369\n",
      "Optimization Iteration:  18945, Training Accuracy:  75.0%, Loss: 0.4495\n",
      "Optimization Iteration:  19009, Training Accuracy:  71.9%, Loss: 0.3933\n",
      "Optimization Iteration:  19073, Training Accuracy:  68.8%, Loss: 0.5270\n",
      "Optimization Iteration:  19137, Training Accuracy:  71.9%, Loss: 0.4863\n",
      "Optimization Iteration:  19201, Training Accuracy:  73.4%, Loss: 0.4421\n",
      "Optimization Iteration:  19265, Training Accuracy:  76.6%, Loss: 0.4348\n",
      "Optimization Iteration:  19329, Training Accuracy:  82.8%, Loss: 0.3630\n",
      "Optimization Iteration:  19393, Training Accuracy:  76.6%, Loss: 0.5802\n",
      "Optimization Iteration:  19457, Training Accuracy:  75.0%, Loss: 0.4129\n",
      "Optimization Iteration:  19521, Training Accuracy:  78.1%, Loss: 0.3890\n",
      "Optimization Iteration:  19585, Training Accuracy:  70.3%, Loss: 0.4308\n",
      "Optimization Iteration:  19649, Training Accuracy:  81.2%, Loss: 0.3808\n",
      "Optimization Iteration:  19713, Training Accuracy:  75.0%, Loss: 0.4447\n",
      "Optimization Iteration:  19777, Training Accuracy:  73.4%, Loss: 0.4683\n",
      "Optimization Iteration:  19841, Training Accuracy:  75.0%, Loss: 0.4997\n",
      "Optimization Iteration:  19905, Training Accuracy:  67.2%, Loss: 0.4362\n",
      "Optimization Iteration:  19969, Training Accuracy:  73.4%, Loss: 0.4588\n",
      "Optimization Iteration:  20033, Training Accuracy:  79.7%, Loss: 0.3666\n",
      "Optimization Iteration:  20097, Training Accuracy:  73.4%, Loss: 0.4088\n",
      "Optimization Iteration:  20161, Training Accuracy:  78.1%, Loss: 0.4364\n",
      "Optimization Iteration:  20225, Training Accuracy:  65.6%, Loss: 0.5171\n",
      "Optimization Iteration:  20289, Training Accuracy:  81.2%, Loss: 0.4107\n",
      "Optimization Iteration:  20353, Training Accuracy:  76.6%, Loss: 0.4294\n",
      "Optimization Iteration:  20417, Training Accuracy:  75.0%, Loss: 0.4160\n",
      "Optimization Iteration:  20481, Training Accuracy:  78.1%, Loss: 0.3957\n",
      "Optimization Iteration:  20545, Training Accuracy:  75.0%, Loss: 0.4958\n",
      "Optimization Iteration:  20609, Training Accuracy:  64.1%, Loss: 0.4761\n",
      "Optimization Iteration:  20673, Training Accuracy:  75.0%, Loss: 0.4075\n",
      "Optimization Iteration:  20737, Training Accuracy:  81.2%, Loss: 0.3667\n",
      "Optimization Iteration:  20801, Training Accuracy:  65.6%, Loss: 0.4788\n",
      "Optimization Iteration:  20865, Training Accuracy:  76.6%, Loss: 0.4029\n",
      "Optimization Iteration:  20929, Training Accuracy:  78.1%, Loss: 0.3706\n",
      "Optimization Iteration:  20993, Training Accuracy:  84.4%, Loss: 0.3629\n",
      "Optimization Iteration:  21057, Training Accuracy:  76.6%, Loss: 0.3802\n",
      "Optimization Iteration:  21121, Training Accuracy:  62.5%, Loss: 0.5289\n",
      "Optimization Iteration:  21185, Training Accuracy:  75.0%, Loss: 0.4134\n",
      "Optimization Iteration:  21249, Training Accuracy:  59.4%, Loss: 0.5189\n",
      "Optimization Iteration:  21313, Training Accuracy:  71.9%, Loss: 0.4350\n",
      "Optimization Iteration:  21377, Training Accuracy:  82.8%, Loss: 0.3590\n",
      "Optimization Iteration:  21441, Training Accuracy:  68.8%, Loss: 0.4392\n",
      "Optimization Iteration:  21505, Training Accuracy:  76.6%, Loss: 0.4290\n",
      "Optimization Iteration:  21569, Training Accuracy:  73.4%, Loss: 0.4333\n",
      "Optimization Iteration:  21633, Training Accuracy:  85.9%, Loss: 0.3307\n",
      "Optimization Iteration:  21697, Training Accuracy:  65.6%, Loss: 0.5300\n",
      "Optimization Iteration:  21761, Training Accuracy:  71.9%, Loss: 0.3792\n",
      "Optimization Iteration:  21825, Training Accuracy:  70.3%, Loss: 0.5077\n",
      "Optimization Iteration:  21889, Training Accuracy:  78.1%, Loss: 0.3935\n",
      "Optimization Iteration:  21953, Training Accuracy:  73.4%, Loss: 0.4862\n",
      "Optimization Iteration:  22017, Training Accuracy:  81.2%, Loss: 0.4126\n",
      "Optimization Iteration:  22081, Training Accuracy:  71.9%, Loss: 0.4023\n",
      "Optimization Iteration:  22145, Training Accuracy:  81.2%, Loss: 0.3486\n",
      "Optimization Iteration:  22209, Training Accuracy:  71.9%, Loss: 0.4875\n",
      "Optimization Iteration:  22273, Training Accuracy:  78.1%, Loss: 0.3616\n",
      "Optimization Iteration:  22337, Training Accuracy:  76.6%, Loss: 0.3834\n",
      "Optimization Iteration:  22401, Training Accuracy:  76.6%, Loss: 0.4030\n",
      "Optimization Iteration:  22465, Training Accuracy:  78.1%, Loss: 0.3928\n",
      "Optimization Iteration:  22529, Training Accuracy:  75.0%, Loss: 0.4493\n",
      "Optimization Iteration:  22593, Training Accuracy:  68.8%, Loss: 0.4782\n",
      "Optimization Iteration:  22657, Training Accuracy:  75.0%, Loss: 0.4348\n",
      "Optimization Iteration:  22721, Training Accuracy:  64.1%, Loss: 0.4664\n",
      "Optimization Iteration:  22785, Training Accuracy:  68.8%, Loss: 0.4896\n",
      "Optimization Iteration:  22849, Training Accuracy:  68.8%, Loss: 0.4217\n",
      "Optimization Iteration:  22913, Training Accuracy:  71.9%, Loss: 0.4324\n",
      "Optimization Iteration:  22977, Training Accuracy:  75.0%, Loss: 0.3929\n",
      "Optimization Iteration:  23041, Training Accuracy:  76.6%, Loss: 0.3268\n",
      "Optimization Iteration:  23105, Training Accuracy:  70.3%, Loss: 0.4780\n",
      "Optimization Iteration:  23169, Training Accuracy:  71.9%, Loss: 0.4523\n",
      "Optimization Iteration:  23233, Training Accuracy:  67.2%, Loss: 0.5428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  23297, Training Accuracy:  67.2%, Loss: 0.4996\n",
      "Optimization Iteration:  23361, Training Accuracy:  79.7%, Loss: 0.3932\n",
      "Optimization Iteration:  23425, Training Accuracy:  68.8%, Loss: 0.5196\n",
      "Optimization Iteration:  23489, Training Accuracy:  84.4%, Loss: 0.3844\n",
      "Optimization Iteration:  23553, Training Accuracy:  79.7%, Loss: 0.4011\n",
      "Optimization Iteration:  23617, Training Accuracy:  73.4%, Loss: 0.4626\n",
      "Optimization Iteration:  23681, Training Accuracy:  70.3%, Loss: 0.4045\n",
      "Optimization Iteration:  23745, Training Accuracy:  78.1%, Loss: 0.3655\n",
      "Optimization Iteration:  23809, Training Accuracy:  81.2%, Loss: 0.4611\n",
      "Optimization Iteration:  23873, Training Accuracy:  73.4%, Loss: 0.3625\n",
      "Optimization Iteration:  23937, Training Accuracy:  57.8%, Loss: 0.5933\n",
      "Optimization Iteration:  24001, Training Accuracy:  81.2%, Loss: 0.3593\n",
      "Optimization Iteration:  24065, Training Accuracy:  75.0%, Loss: 0.4100\n",
      "Optimization Iteration:  24129, Training Accuracy:  70.3%, Loss: 0.4333\n",
      "Optimization Iteration:  24193, Training Accuracy:  68.8%, Loss: 0.4419\n",
      "Optimization Iteration:  24257, Training Accuracy:  73.4%, Loss: 0.4281\n",
      "Optimization Iteration:  24321, Training Accuracy:  76.6%, Loss: 0.4224\n",
      "Optimization Iteration:  24385, Training Accuracy:  71.9%, Loss: 0.4319\n",
      "Optimization Iteration:  24449, Training Accuracy:  81.2%, Loss: 0.3451\n",
      "Optimization Iteration:  24513, Training Accuracy:  70.3%, Loss: 0.4853\n",
      "Optimization Iteration:  24577, Training Accuracy:  73.4%, Loss: 0.4491\n",
      "Optimization Iteration:  24641, Training Accuracy:  70.3%, Loss: 0.4801\n",
      "Optimization Iteration:  24705, Training Accuracy:  79.7%, Loss: 0.4238\n",
      "Optimization Iteration:  24769, Training Accuracy:  76.6%, Loss: 0.4288\n",
      "Optimization Iteration:  24833, Training Accuracy:  75.0%, Loss: 0.3399\n",
      "Optimization Iteration:  24897, Training Accuracy:  70.3%, Loss: 0.4170\n",
      "Optimization Iteration:  24961, Training Accuracy:  78.1%, Loss: 0.3736\n",
      "Optimization Iteration:  25025, Training Accuracy:  76.6%, Loss: 0.4623\n",
      "Optimization Iteration:  25089, Training Accuracy:  73.4%, Loss: 0.4854\n",
      "Optimization Iteration:  25153, Training Accuracy:  70.3%, Loss: 0.4392\n",
      "Optimization Iteration:  25217, Training Accuracy:  78.1%, Loss: 0.4417\n",
      "Optimization Iteration:  25281, Training Accuracy:  78.1%, Loss: 0.3871\n",
      "Optimization Iteration:  25345, Training Accuracy:  67.2%, Loss: 0.4792\n",
      "Optimization Iteration:  25409, Training Accuracy:  73.4%, Loss: 0.4152\n",
      "Optimization Iteration:  25473, Training Accuracy:  68.8%, Loss: 0.5053\n",
      "Optimization Iteration:  25537, Training Accuracy:  73.4%, Loss: 0.3625\n",
      "Optimization Iteration:  25601, Training Accuracy:  71.9%, Loss: 0.4277\n",
      "Optimization Iteration:  25665, Training Accuracy:  76.6%, Loss: 0.4045\n",
      "Optimization Iteration:  25729, Training Accuracy:  68.8%, Loss: 0.3861\n",
      "Optimization Iteration:  25793, Training Accuracy:  81.2%, Loss: 0.3710\n",
      "Optimization Iteration:  25857, Training Accuracy:  79.7%, Loss: 0.4439\n",
      "Optimization Iteration:  25921, Training Accuracy:  68.8%, Loss: 0.5496\n",
      "Optimization Iteration:  25985, Training Accuracy:  73.4%, Loss: 0.4530\n",
      "Optimization Iteration:  26049, Training Accuracy:  76.6%, Loss: 0.4477\n",
      "Optimization Iteration:  26113, Training Accuracy:  71.9%, Loss: 0.3689\n",
      "Optimization Iteration:  26177, Training Accuracy:  73.4%, Loss: 0.3883\n",
      "Optimization Iteration:  26241, Training Accuracy:  76.6%, Loss: 0.4337\n",
      "Optimization Iteration:  26305, Training Accuracy:  68.8%, Loss: 0.5222\n",
      "Optimization Iteration:  26369, Training Accuracy:  67.2%, Loss: 0.4986\n",
      "Optimization Iteration:  26433, Training Accuracy:  68.8%, Loss: 0.4970\n",
      "Optimization Iteration:  26497, Training Accuracy:  81.2%, Loss: 0.3931\n",
      "Optimization Iteration:  26561, Training Accuracy:  71.9%, Loss: 0.3837\n",
      "Optimization Iteration:  26625, Training Accuracy:  78.1%, Loss: 0.3984\n",
      "Optimization Iteration:  26689, Training Accuracy:  73.4%, Loss: 0.4421\n",
      "Optimization Iteration:  26753, Training Accuracy:  71.9%, Loss: 0.4619\n",
      "Optimization Iteration:  26817, Training Accuracy:  67.2%, Loss: 0.4891\n",
      "Optimization Iteration:  26881, Training Accuracy:  85.9%, Loss: 0.2899\n",
      "Optimization Iteration:  26945, Training Accuracy:  59.4%, Loss: 0.5099\n",
      "Optimization Iteration:  27009, Training Accuracy:  71.9%, Loss: 0.4182\n",
      "Optimization Iteration:  27073, Training Accuracy:  79.7%, Loss: 0.4529\n",
      "Optimization Iteration:  27137, Training Accuracy:  79.7%, Loss: 0.4335\n",
      "Optimization Iteration:  27201, Training Accuracy:  79.7%, Loss: 0.3426\n",
      "Optimization Iteration:  27265, Training Accuracy:  75.0%, Loss: 0.4322\n",
      "Optimization Iteration:  27329, Training Accuracy:  81.2%, Loss: 0.4176\n",
      "Optimization Iteration:  27393, Training Accuracy:  76.6%, Loss: 0.3984\n",
      "Optimization Iteration:  27457, Training Accuracy:  78.1%, Loss: 0.4045\n",
      "Optimization Iteration:  27521, Training Accuracy:  73.4%, Loss: 0.4402\n",
      "Optimization Iteration:  27585, Training Accuracy:  78.1%, Loss: 0.3817\n",
      "Optimization Iteration:  27649, Training Accuracy:  76.6%, Loss: 0.4376\n",
      "Optimization Iteration:  27713, Training Accuracy:  73.4%, Loss: 0.4244\n",
      "Optimization Iteration:  27777, Training Accuracy:  85.9%, Loss: 0.3220\n",
      "Optimization Iteration:  27841, Training Accuracy:  75.0%, Loss: 0.4265\n",
      "Optimization Iteration:  27905, Training Accuracy:  76.6%, Loss: 0.4759\n",
      "Optimization Iteration:  27969, Training Accuracy:  71.9%, Loss: 0.4868\n",
      "Optimization Iteration:  28033, Training Accuracy:  70.3%, Loss: 0.4632\n",
      "Optimization Iteration:  28097, Training Accuracy:  73.4%, Loss: 0.4397\n",
      "Optimization Iteration:  28161, Training Accuracy:  81.2%, Loss: 0.3945\n",
      "Optimization Iteration:  28225, Training Accuracy:  59.4%, Loss: 0.4553\n",
      "Optimization Iteration:  28289, Training Accuracy:  73.4%, Loss: 0.3438\n",
      "Optimization Iteration:  28353, Training Accuracy:  70.3%, Loss: 0.4547\n",
      "Optimization Iteration:  28417, Training Accuracy:  64.1%, Loss: 0.5105\n",
      "Optimization Iteration:  28481, Training Accuracy:  73.4%, Loss: 0.4128\n",
      "Optimization Iteration:  28545, Training Accuracy:  78.1%, Loss: 0.3722\n",
      "Optimization Iteration:  28609, Training Accuracy:  82.8%, Loss: 0.3843\n",
      "Optimization Iteration:  28673, Training Accuracy:  71.9%, Loss: 0.4892\n",
      "Optimization Iteration:  28737, Training Accuracy:  71.9%, Loss: 0.4431\n",
      "Optimization Iteration:  28801, Training Accuracy:  73.4%, Loss: 0.3697\n",
      "Optimization Iteration:  28865, Training Accuracy:  85.9%, Loss: 0.3092\n",
      "Optimization Iteration:  28929, Training Accuracy:  76.6%, Loss: 0.3456\n",
      "Optimization Iteration:  28993, Training Accuracy:  60.9%, Loss: 0.4696\n",
      "Optimization Iteration:  29057, Training Accuracy:  71.9%, Loss: 0.4254\n",
      "Optimization Iteration:  29121, Training Accuracy:  67.2%, Loss: 0.6042\n",
      "Optimization Iteration:  29185, Training Accuracy:  79.7%, Loss: 0.3398\n",
      "Optimization Iteration:  29249, Training Accuracy:  68.8%, Loss: 0.4596\n",
      "Optimization Iteration:  29313, Training Accuracy:  71.9%, Loss: 0.4798\n",
      "Optimization Iteration:  29377, Training Accuracy:  70.3%, Loss: 0.4237\n",
      "Optimization Iteration:  29441, Training Accuracy:  68.8%, Loss: 0.5236\n",
      "Optimization Iteration:  29505, Training Accuracy:  79.7%, Loss: 0.4103\n",
      "Optimization Iteration:  29569, Training Accuracy:  79.7%, Loss: 0.4105\n",
      "Optimization Iteration:  29633, Training Accuracy:  73.4%, Loss: 0.4404\n",
      "Optimization Iteration:  29697, Training Accuracy:  85.9%, Loss: 0.3702\n",
      "Optimization Iteration:  29761, Training Accuracy:  71.9%, Loss: 0.4316\n",
      "Optimization Iteration:  29825, Training Accuracy:  84.4%, Loss: 0.4129\n",
      "Optimization Iteration:  29889, Training Accuracy:  79.7%, Loss: 0.4185\n",
      "Optimization Iteration:  29953, Training Accuracy:  71.9%, Loss: 0.5202\n",
      "Optimization Iteration:  30017, Training Accuracy:  85.9%, Loss: 0.3160\n",
      "Optimization Iteration:  30081, Training Accuracy:  79.7%, Loss: 0.3576\n",
      "Optimization Iteration:  30145, Training Accuracy:  71.9%, Loss: 0.3901\n",
      "Optimization Iteration:  30209, Training Accuracy:  65.6%, Loss: 0.5195\n",
      "Optimization Iteration:  30273, Training Accuracy:  73.4%, Loss: 0.4055\n",
      "Optimization Iteration:  30337, Training Accuracy:  73.4%, Loss: 0.4068\n",
      "Optimization Iteration:  30401, Training Accuracy:  76.6%, Loss: 0.4450\n",
      "Optimization Iteration:  30465, Training Accuracy:  76.6%, Loss: 0.4444\n",
      "Optimization Iteration:  30529, Training Accuracy:  73.4%, Loss: 0.4067\n",
      "Optimization Iteration:  30593, Training Accuracy:  71.9%, Loss: 0.4249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  30657, Training Accuracy:  78.1%, Loss: 0.3818\n",
      "Optimization Iteration:  30721, Training Accuracy:  71.9%, Loss: 0.4633\n",
      "Optimization Iteration:  30785, Training Accuracy:  78.1%, Loss: 0.3824\n",
      "Optimization Iteration:  30849, Training Accuracy:  68.8%, Loss: 0.4618\n",
      "Optimization Iteration:  30913, Training Accuracy:  79.7%, Loss: 0.3861\n",
      "Optimization Iteration:  30977, Training Accuracy:  78.1%, Loss: 0.3811\n",
      "Optimization Iteration:  31041, Training Accuracy:  79.7%, Loss: 0.3930\n",
      "Optimization Iteration:  31105, Training Accuracy:  71.9%, Loss: 0.3854\n",
      "Optimization Iteration:  31169, Training Accuracy:  71.9%, Loss: 0.3928\n",
      "Optimization Iteration:  31233, Training Accuracy:  67.2%, Loss: 0.4595\n",
      "Optimization Iteration:  31297, Training Accuracy:  68.8%, Loss: 0.4046\n",
      "Optimization Iteration:  31361, Training Accuracy:  73.4%, Loss: 0.4318\n",
      "Optimization Iteration:  31425, Training Accuracy:  76.6%, Loss: 0.4284\n",
      "Optimization Iteration:  31489, Training Accuracy:  76.6%, Loss: 0.4105\n",
      "Optimization Iteration:  31553, Training Accuracy:  76.6%, Loss: 0.4505\n",
      "Optimization Iteration:  31617, Training Accuracy:  76.6%, Loss: 0.3820\n",
      "Optimization Iteration:  31681, Training Accuracy:  78.1%, Loss: 0.3933\n",
      "Optimization Iteration:  31745, Training Accuracy:  79.7%, Loss: 0.3667\n",
      "Optimization Iteration:  31809, Training Accuracy:  67.2%, Loss: 0.4305\n",
      "Optimization Iteration:  31873, Training Accuracy:  79.7%, Loss: 0.4031\n",
      "Optimization Iteration:  31937, Training Accuracy:  67.2%, Loss: 0.4981\n",
      "Optimization Iteration:  32001, Training Accuracy:  68.8%, Loss: 0.4948\n",
      "Optimization Iteration:  32065, Training Accuracy:  70.3%, Loss: 0.4211\n",
      "Optimization Iteration:  32129, Training Accuracy:  71.9%, Loss: 0.4520\n",
      "Optimization Iteration:  32193, Training Accuracy:  75.0%, Loss: 0.4891\n",
      "Optimization Iteration:  32257, Training Accuracy:  75.0%, Loss: 0.5104\n",
      "Optimization Iteration:  32321, Training Accuracy:  78.1%, Loss: 0.3770\n",
      "Optimization Iteration:  32385, Training Accuracy:  64.1%, Loss: 0.4828\n",
      "Optimization Iteration:  32449, Training Accuracy:  67.2%, Loss: 0.5028\n",
      "Optimization Iteration:  32513, Training Accuracy:  70.3%, Loss: 0.4496\n",
      "Optimization Iteration:  32577, Training Accuracy:  76.6%, Loss: 0.3691\n",
      "Optimization Iteration:  32641, Training Accuracy:  73.4%, Loss: 0.4037\n",
      "Optimization Iteration:  32705, Training Accuracy:  78.1%, Loss: 0.3784\n",
      "Optimization Iteration:  32769, Training Accuracy:  70.3%, Loss: 0.4149\n",
      "Optimization Iteration:  32833, Training Accuracy:  76.6%, Loss: 0.3485\n",
      "Optimization Iteration:  32897, Training Accuracy:  73.4%, Loss: 0.4861\n",
      "Optimization Iteration:  32961, Training Accuracy:  78.1%, Loss: 0.5774\n",
      "Optimization Iteration:  33025, Training Accuracy:  85.9%, Loss: 0.3167\n",
      "Optimization Iteration:  33089, Training Accuracy:  78.1%, Loss: 0.4796\n",
      "Optimization Iteration:  33153, Training Accuracy:  75.0%, Loss: 0.4939\n",
      "Optimization Iteration:  33217, Training Accuracy:  71.9%, Loss: 0.4254\n",
      "Optimization Iteration:  33281, Training Accuracy:  62.5%, Loss: 0.5340\n",
      "Optimization Iteration:  33345, Training Accuracy:  67.2%, Loss: 0.5014\n",
      "Optimization Iteration:  33409, Training Accuracy:  67.2%, Loss: 0.4729\n",
      "Optimization Iteration:  33473, Training Accuracy:  70.3%, Loss: 0.4309\n",
      "Optimization Iteration:  33537, Training Accuracy:  70.3%, Loss: 0.4631\n",
      "Optimization Iteration:  33601, Training Accuracy:  76.6%, Loss: 0.4523\n",
      "Optimization Iteration:  33665, Training Accuracy:  75.0%, Loss: 0.4317\n",
      "Optimization Iteration:  33729, Training Accuracy:  75.0%, Loss: 0.5737\n",
      "Optimization Iteration:  33793, Training Accuracy:  70.3%, Loss: 0.4975\n",
      "Optimization Iteration:  33857, Training Accuracy:  78.1%, Loss: 0.4165\n",
      "Optimization Iteration:  33921, Training Accuracy:  76.6%, Loss: 0.4596\n",
      "Optimization Iteration:  33985, Training Accuracy:  73.4%, Loss: 0.4249\n",
      "Optimization Iteration:  34049, Training Accuracy:  71.9%, Loss: 0.4717\n",
      "Optimization Iteration:  34113, Training Accuracy:  68.8%, Loss: 0.3933\n",
      "Optimization Iteration:  34177, Training Accuracy:  78.1%, Loss: 0.3446\n",
      "Optimization Iteration:  34241, Training Accuracy:  76.6%, Loss: 0.4368\n",
      "Optimization Iteration:  34305, Training Accuracy:  65.6%, Loss: 0.5134\n",
      "Optimization Iteration:  34369, Training Accuracy:  76.6%, Loss: 0.3359\n",
      "Optimization Iteration:  34433, Training Accuracy:  71.9%, Loss: 0.5709\n",
      "Optimization Iteration:  34497, Training Accuracy:  90.6%, Loss: 0.2653\n",
      "Optimization Iteration:  34561, Training Accuracy:  81.2%, Loss: 0.3820\n",
      "Optimization Iteration:  34625, Training Accuracy:  81.2%, Loss: 0.4961\n",
      "Optimization Iteration:  34689, Training Accuracy:  68.8%, Loss: 0.5059\n",
      "Optimization Iteration:  34753, Training Accuracy:  75.0%, Loss: 0.5574\n",
      "Optimization Iteration:  34817, Training Accuracy:  71.9%, Loss: 0.4917\n",
      "Optimization Iteration:  34881, Training Accuracy:  70.3%, Loss: 0.4254\n",
      "Optimization Iteration:  34945, Training Accuracy:  78.1%, Loss: 0.3888\n",
      "Optimization Iteration:  35009, Training Accuracy:  78.1%, Loss: 0.3890\n",
      "Optimization Iteration:  35073, Training Accuracy:  73.4%, Loss: 0.3678\n",
      "Optimization Iteration:  35137, Training Accuracy:  78.1%, Loss: 0.3428\n",
      "Optimization Iteration:  35201, Training Accuracy:  71.9%, Loss: 0.4371\n",
      "Optimization Iteration:  35265, Training Accuracy:  70.3%, Loss: 0.4536\n",
      "Optimization Iteration:  35329, Training Accuracy:  67.2%, Loss: 0.4965\n",
      "Optimization Iteration:  35393, Training Accuracy:  73.4%, Loss: 0.3571\n",
      "Optimization Iteration:  35457, Training Accuracy:  78.1%, Loss: 0.4056\n",
      "Optimization Iteration:  35521, Training Accuracy:  54.7%, Loss: 0.4892\n",
      "Optimization Iteration:  35585, Training Accuracy:  78.1%, Loss: 0.3595\n",
      "Optimization Iteration:  35649, Training Accuracy:  76.6%, Loss: 0.4621\n",
      "Optimization Iteration:  35713, Training Accuracy:  78.1%, Loss: 0.4251\n",
      "Optimization Iteration:  35777, Training Accuracy:  84.4%, Loss: 0.3280\n",
      "Optimization Iteration:  35841, Training Accuracy:  79.7%, Loss: 0.3831\n",
      "Optimization Iteration:  35905, Training Accuracy:  76.6%, Loss: 0.3871\n",
      "Optimization Iteration:  35969, Training Accuracy:  73.4%, Loss: 0.4481\n",
      "Optimization Iteration:  36033, Training Accuracy:  68.8%, Loss: 0.3907\n",
      "Optimization Iteration:  36097, Training Accuracy:  76.6%, Loss: 0.4388\n",
      "Optimization Iteration:  36161, Training Accuracy:  79.7%, Loss: 0.3750\n",
      "Optimization Iteration:  36225, Training Accuracy:  76.6%, Loss: 0.4163\n",
      "Optimization Iteration:  36289, Training Accuracy:  76.6%, Loss: 0.3809\n",
      "Optimization Iteration:  36353, Training Accuracy:  73.4%, Loss: 0.4202\n",
      "Optimization Iteration:  36417, Training Accuracy:  79.7%, Loss: 0.4217\n",
      "Optimization Iteration:  36481, Training Accuracy:  79.7%, Loss: 0.3342\n",
      "Optimization Iteration:  36545, Training Accuracy:  79.7%, Loss: 0.4222\n",
      "Optimization Iteration:  36609, Training Accuracy:  73.4%, Loss: 0.4924\n",
      "Optimization Iteration:  36673, Training Accuracy:  70.3%, Loss: 0.4155\n",
      "Optimization Iteration:  36737, Training Accuracy:  81.2%, Loss: 0.3856\n",
      "Optimization Iteration:  36801, Training Accuracy:  81.2%, Loss: 0.3630\n",
      "Optimization Iteration:  36865, Training Accuracy:  65.6%, Loss: 0.4771\n",
      "Optimization Iteration:  36929, Training Accuracy:  64.1%, Loss: 0.4448\n",
      "Optimization Iteration:  36993, Training Accuracy:  64.1%, Loss: 0.5168\n",
      "Optimization Iteration:  37057, Training Accuracy:  81.2%, Loss: 0.3947\n",
      "Optimization Iteration:  37121, Training Accuracy:  82.8%, Loss: 0.4296\n",
      "Optimization Iteration:  37185, Training Accuracy:  71.9%, Loss: 0.4181\n",
      "Optimization Iteration:  37249, Training Accuracy:  76.6%, Loss: 0.5554\n",
      "Optimization Iteration:  37313, Training Accuracy:  73.4%, Loss: 0.4376\n",
      "Optimization Iteration:  37377, Training Accuracy:  71.9%, Loss: 0.5961\n",
      "Optimization Iteration:  37441, Training Accuracy:  71.9%, Loss: 0.4129\n",
      "Optimization Iteration:  37505, Training Accuracy:  73.4%, Loss: 0.4898\n",
      "Optimization Iteration:  37569, Training Accuracy:  75.0%, Loss: 0.4998\n",
      "Optimization Iteration:  37633, Training Accuracy:  68.8%, Loss: 0.4278\n",
      "Optimization Iteration:  37697, Training Accuracy:  75.0%, Loss: 0.4081\n",
      "Optimization Iteration:  37761, Training Accuracy:  70.3%, Loss: 0.4090\n",
      "Optimization Iteration:  37825, Training Accuracy:  82.8%, Loss: 0.3116\n",
      "Optimization Iteration:  37889, Training Accuracy:  76.6%, Loss: 0.3877\n",
      "Optimization Iteration:  37953, Training Accuracy:  81.2%, Loss: 0.3661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  38017, Training Accuracy:  79.7%, Loss: 0.4078\n",
      "Optimization Iteration:  38081, Training Accuracy:  65.6%, Loss: 0.4192\n",
      "Optimization Iteration:  38145, Training Accuracy:  78.1%, Loss: 0.3938\n",
      "Optimization Iteration:  38209, Training Accuracy:  70.3%, Loss: 0.4018\n",
      "Optimization Iteration:  38273, Training Accuracy:  79.7%, Loss: 0.3498\n",
      "Optimization Iteration:  38337, Training Accuracy:  87.5%, Loss: 0.3014\n",
      "Optimization Iteration:  38401, Training Accuracy:  81.2%, Loss: 0.3856\n",
      "Optimization Iteration:  38465, Training Accuracy:  70.3%, Loss: 0.4799\n",
      "Optimization Iteration:  38529, Training Accuracy:  76.6%, Loss: 0.4648\n",
      "Optimization Iteration:  38593, Training Accuracy:  59.4%, Loss: 0.5515\n",
      "Optimization Iteration:  38657, Training Accuracy:  68.8%, Loss: 0.4561\n",
      "Optimization Iteration:  38721, Training Accuracy:  76.6%, Loss: 0.3404\n",
      "Optimization Iteration:  38785, Training Accuracy:  73.4%, Loss: 0.3981\n",
      "Optimization Iteration:  38849, Training Accuracy:  82.8%, Loss: 0.3973\n",
      "Optimization Iteration:  38913, Training Accuracy:  67.2%, Loss: 0.4780\n",
      "Optimization Iteration:  38977, Training Accuracy:  62.5%, Loss: 0.4664\n",
      "Optimization Iteration:  39041, Training Accuracy:  79.7%, Loss: 0.4570\n",
      "Optimization Iteration:  39105, Training Accuracy:  81.2%, Loss: 0.4085\n",
      "Optimization Iteration:  39169, Training Accuracy:  71.9%, Loss: 0.4361\n",
      "Optimization Iteration:  39233, Training Accuracy:  70.3%, Loss: 0.4605\n",
      "Optimization Iteration:  39297, Training Accuracy:  75.0%, Loss: 0.3542\n",
      "Optimization Iteration:  39361, Training Accuracy:  65.6%, Loss: 0.4262\n",
      "Optimization Iteration:  39425, Training Accuracy:  73.4%, Loss: 0.4708\n",
      "Optimization Iteration:  39489, Training Accuracy:  76.6%, Loss: 0.3651\n",
      "Optimization Iteration:  39553, Training Accuracy:  73.4%, Loss: 0.4242\n",
      "Optimization Iteration:  39617, Training Accuracy:  81.2%, Loss: 0.4369\n",
      "Optimization Iteration:  39681, Training Accuracy:  75.0%, Loss: 0.3640\n",
      "Optimization Iteration:  39745, Training Accuracy:  70.3%, Loss: 0.4587\n",
      "Optimization Iteration:  39809, Training Accuracy:  78.1%, Loss: 0.4500\n",
      "Optimization Iteration:  39873, Training Accuracy:  70.3%, Loss: 0.4530\n",
      "Optimization Iteration:  39937, Training Accuracy:  81.2%, Loss: 0.5441\n",
      "Optimization Iteration:  40001, Training Accuracy:  79.7%, Loss: 0.4111\n",
      "Optimization Iteration:  40065, Training Accuracy:  70.3%, Loss: 0.4691\n",
      "Optimization Iteration:  40129, Training Accuracy:  75.0%, Loss: 0.3807\n",
      "Optimization Iteration:  40193, Training Accuracy:  75.0%, Loss: 0.4808\n",
      "Optimization Iteration:  40257, Training Accuracy:  76.6%, Loss: 0.3927\n",
      "Optimization Iteration:  40321, Training Accuracy:  67.2%, Loss: 0.4886\n",
      "Optimization Iteration:  40385, Training Accuracy:  76.6%, Loss: 0.5002\n",
      "Optimization Iteration:  40449, Training Accuracy:  73.4%, Loss: 0.4097\n",
      "Optimization Iteration:  40513, Training Accuracy:  73.4%, Loss: 0.4194\n",
      "Optimization Iteration:  40577, Training Accuracy:  76.6%, Loss: 0.4207\n",
      "Optimization Iteration:  40641, Training Accuracy:  68.8%, Loss: 0.4242\n",
      "Optimization Iteration:  40705, Training Accuracy:  75.0%, Loss: 0.4427\n",
      "Optimization Iteration:  40769, Training Accuracy:  79.7%, Loss: 0.3615\n",
      "Optimization Iteration:  40833, Training Accuracy:  76.6%, Loss: 0.3793\n",
      "Optimization Iteration:  40897, Training Accuracy:  78.1%, Loss: 0.4249\n",
      "Optimization Iteration:  40961, Training Accuracy:  84.4%, Loss: 0.3558\n",
      "Optimization Iteration:  41025, Training Accuracy:  78.1%, Loss: 0.4101\n",
      "Optimization Iteration:  41089, Training Accuracy:  75.0%, Loss: 0.4018\n",
      "Optimization Iteration:  41153, Training Accuracy:  82.8%, Loss: 0.3824\n",
      "Optimization Iteration:  41217, Training Accuracy:  79.7%, Loss: 0.3707\n",
      "Optimization Iteration:  41281, Training Accuracy:  68.8%, Loss: 0.4514\n",
      "Optimization Iteration:  41345, Training Accuracy:  76.6%, Loss: 0.4443\n",
      "Optimization Iteration:  41409, Training Accuracy:  73.4%, Loss: 0.4224\n",
      "Optimization Iteration:  41473, Training Accuracy:  75.0%, Loss: 0.4006\n",
      "Optimization Iteration:  41537, Training Accuracy:  75.0%, Loss: 0.4529\n",
      "Optimization Iteration:  41601, Training Accuracy:  81.2%, Loss: 0.3799\n",
      "Optimization Iteration:  41665, Training Accuracy:  75.0%, Loss: 0.4380\n",
      "Optimization Iteration:  41729, Training Accuracy:  87.5%, Loss: 0.2814\n",
      "Optimization Iteration:  41793, Training Accuracy:  60.9%, Loss: 0.5870\n",
      "Optimization Iteration:  41857, Training Accuracy:  64.1%, Loss: 0.5440\n",
      "Optimization Iteration:  41921, Training Accuracy:  73.4%, Loss: 0.4191\n",
      "Optimization Iteration:  41985, Training Accuracy:  73.4%, Loss: 0.4719\n",
      "Optimization Iteration:  42049, Training Accuracy:  67.2%, Loss: 0.5030\n",
      "Optimization Iteration:  42113, Training Accuracy:  65.6%, Loss: 0.4924\n",
      "Optimization Iteration:  42177, Training Accuracy:  71.9%, Loss: 0.3987\n",
      "Optimization Iteration:  42241, Training Accuracy:  81.2%, Loss: 0.3852\n",
      "Optimization Iteration:  42305, Training Accuracy:  73.4%, Loss: 0.4540\n",
      "Optimization Iteration:  42369, Training Accuracy:  78.1%, Loss: 0.4230\n",
      "Optimization Iteration:  42433, Training Accuracy:  68.8%, Loss: 0.4837\n",
      "Optimization Iteration:  42497, Training Accuracy:  78.1%, Loss: 0.4116\n",
      "Optimization Iteration:  42561, Training Accuracy:  73.4%, Loss: 0.4370\n",
      "Optimization Iteration:  42625, Training Accuracy:  79.7%, Loss: 0.4117\n",
      "Optimization Iteration:  42689, Training Accuracy:  81.2%, Loss: 0.3752\n",
      "Optimization Iteration:  42753, Training Accuracy:  70.3%, Loss: 0.4524\n",
      "Optimization Iteration:  42817, Training Accuracy:  85.9%, Loss: 0.3493\n",
      "Optimization Iteration:  42881, Training Accuracy:  71.9%, Loss: 0.4863\n",
      "Optimization Iteration:  42945, Training Accuracy:  71.9%, Loss: 0.4438\n",
      "Optimization Iteration:  43009, Training Accuracy:  64.1%, Loss: 0.5310\n",
      "Optimization Iteration:  43073, Training Accuracy:  78.1%, Loss: 0.4104\n",
      "Optimization Iteration:  43137, Training Accuracy:  76.6%, Loss: 0.4399\n",
      "Optimization Iteration:  43201, Training Accuracy:  73.4%, Loss: 0.4567\n",
      "Optimization Iteration:  43265, Training Accuracy:  78.1%, Loss: 0.4280\n",
      "Optimization Iteration:  43329, Training Accuracy:  79.7%, Loss: 0.4351\n",
      "Optimization Iteration:  43393, Training Accuracy:  67.2%, Loss: 0.4391\n",
      "Optimization Iteration:  43457, Training Accuracy:  82.8%, Loss: 0.3250\n",
      "Optimization Iteration:  43521, Training Accuracy:  78.1%, Loss: 0.4670\n",
      "Optimization Iteration:  43585, Training Accuracy:  76.6%, Loss: 0.4574\n",
      "Optimization Iteration:  43649, Training Accuracy:  73.4%, Loss: 0.4472\n",
      "Optimization Iteration:  43713, Training Accuracy:  75.0%, Loss: 0.3819\n",
      "Optimization Iteration:  43777, Training Accuracy:  87.5%, Loss: 0.3166\n",
      "Optimization Iteration:  43841, Training Accuracy:  79.7%, Loss: 0.4001\n",
      "Optimization Iteration:  43905, Training Accuracy:  73.4%, Loss: 0.3812\n",
      "Optimization Iteration:  43969, Training Accuracy:  85.9%, Loss: 0.3857\n",
      "Optimization Iteration:  44033, Training Accuracy:  71.9%, Loss: 0.4500\n",
      "Optimization Iteration:  44097, Training Accuracy:  67.2%, Loss: 0.4222\n",
      "Optimization Iteration:  44161, Training Accuracy:  76.6%, Loss: 0.3455\n",
      "Optimization Iteration:  44225, Training Accuracy:  73.4%, Loss: 0.4390\n",
      "Optimization Iteration:  44289, Training Accuracy:  78.1%, Loss: 0.4673\n",
      "Optimization Iteration:  44353, Training Accuracy:  75.0%, Loss: 0.4380\n",
      "Optimization Iteration:  44417, Training Accuracy:  75.0%, Loss: 0.4393\n",
      "Optimization Iteration:  44481, Training Accuracy:  68.8%, Loss: 0.3917\n",
      "Optimization Iteration:  44545, Training Accuracy:  78.1%, Loss: 0.3689\n",
      "Optimization Iteration:  44609, Training Accuracy:  85.9%, Loss: 0.3807\n",
      "Optimization Iteration:  44673, Training Accuracy:  64.1%, Loss: 0.6456\n",
      "Optimization Iteration:  44737, Training Accuracy:  78.1%, Loss: 0.3925\n",
      "Optimization Iteration:  44801, Training Accuracy:  76.6%, Loss: 0.4385\n",
      "Optimization Iteration:  44865, Training Accuracy:  65.6%, Loss: 0.4934\n",
      "Optimization Iteration:  44929, Training Accuracy:  79.7%, Loss: 0.4173\n",
      "Optimization Iteration:  44993, Training Accuracy:  70.3%, Loss: 0.5358\n",
      "Optimization Iteration:  45057, Training Accuracy:  70.3%, Loss: 0.5117\n",
      "Optimization Iteration:  45121, Training Accuracy:  82.8%, Loss: 0.3871\n",
      "Optimization Iteration:  45185, Training Accuracy:  75.0%, Loss: 0.3313\n",
      "Optimization Iteration:  45249, Training Accuracy:  67.2%, Loss: 0.4618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  45313, Training Accuracy:  75.0%, Loss: 0.4624\n",
      "Optimization Iteration:  45377, Training Accuracy:  76.6%, Loss: 0.4068\n",
      "Optimization Iteration:  45441, Training Accuracy:  71.9%, Loss: 0.4768\n",
      "Optimization Iteration:  45505, Training Accuracy:  65.6%, Loss: 0.4532\n",
      "Optimization Iteration:  45569, Training Accuracy:  71.9%, Loss: 0.5107\n",
      "Optimization Iteration:  45633, Training Accuracy:  79.7%, Loss: 0.4088\n",
      "Optimization Iteration:  45697, Training Accuracy:  79.7%, Loss: 0.3898\n",
      "Optimization Iteration:  45761, Training Accuracy:  78.1%, Loss: 0.3539\n",
      "Optimization Iteration:  45825, Training Accuracy:  68.8%, Loss: 0.3982\n",
      "Optimization Iteration:  45889, Training Accuracy:  71.9%, Loss: 0.4322\n",
      "Optimization Iteration:  45953, Training Accuracy:  75.0%, Loss: 0.4065\n",
      "Optimization Iteration:  46017, Training Accuracy:  79.7%, Loss: 0.4294\n",
      "Optimization Iteration:  46081, Training Accuracy:  85.9%, Loss: 0.3155\n",
      "Optimization Iteration:  46145, Training Accuracy:  73.4%, Loss: 0.4394\n",
      "Optimization Iteration:  46209, Training Accuracy:  73.4%, Loss: 0.4069\n",
      "Optimization Iteration:  46273, Training Accuracy:  71.9%, Loss: 0.4849\n",
      "Optimization Iteration:  46337, Training Accuracy:  78.1%, Loss: 0.4055\n",
      "Optimization Iteration:  46401, Training Accuracy:  87.5%, Loss: 0.3254\n",
      "Optimization Iteration:  46465, Training Accuracy:  75.0%, Loss: 0.3971\n",
      "Optimization Iteration:  46529, Training Accuracy:  76.6%, Loss: 0.4071\n",
      "Optimization Iteration:  46593, Training Accuracy:  70.3%, Loss: 0.4316\n",
      "Optimization Iteration:  46657, Training Accuracy:  79.7%, Loss: 0.4376\n",
      "Optimization Iteration:  46721, Training Accuracy:  67.2%, Loss: 0.5473\n",
      "Optimization Iteration:  46785, Training Accuracy:  64.1%, Loss: 0.4657\n",
      "Optimization Iteration:  46849, Training Accuracy:  67.2%, Loss: 0.4573\n",
      "Optimization Iteration:  46913, Training Accuracy:  84.4%, Loss: 0.3487\n",
      "Optimization Iteration:  46977, Training Accuracy:  73.4%, Loss: 0.4139\n",
      "Optimization Iteration:  47041, Training Accuracy:  75.0%, Loss: 0.4096\n",
      "Optimization Iteration:  47105, Training Accuracy:  68.8%, Loss: 0.5309\n",
      "Optimization Iteration:  47169, Training Accuracy:  75.0%, Loss: 0.4334\n",
      "Optimization Iteration:  47233, Training Accuracy:  68.8%, Loss: 0.4768\n",
      "Optimization Iteration:  47297, Training Accuracy:  79.7%, Loss: 0.3642\n",
      "Optimization Iteration:  47361, Training Accuracy:  81.2%, Loss: 0.3166\n",
      "Optimization Iteration:  47425, Training Accuracy:  76.6%, Loss: 0.3910\n",
      "Optimization Iteration:  47489, Training Accuracy:  75.0%, Loss: 0.4090\n",
      "Optimization Iteration:  47553, Training Accuracy:  76.6%, Loss: 0.4562\n",
      "Optimization Iteration:  47617, Training Accuracy:  68.8%, Loss: 0.5262\n",
      "Optimization Iteration:  47681, Training Accuracy:  84.4%, Loss: 0.3119\n",
      "Optimization Iteration:  47745, Training Accuracy:  68.8%, Loss: 0.4962\n",
      "Optimization Iteration:  47809, Training Accuracy:  73.4%, Loss: 0.4619\n",
      "Optimization Iteration:  47873, Training Accuracy:  81.2%, Loss: 0.3371\n",
      "Optimization Iteration:  47937, Training Accuracy:  70.3%, Loss: 0.4372\n",
      "Optimization Iteration:  48001, Training Accuracy:  76.6%, Loss: 0.4177\n",
      "Optimization Iteration:  48065, Training Accuracy:  67.2%, Loss: 0.4385\n",
      "Optimization Iteration:  48129, Training Accuracy:  71.9%, Loss: 0.4671\n",
      "Optimization Iteration:  48193, Training Accuracy:  70.3%, Loss: 0.5268\n",
      "Optimization Iteration:  48257, Training Accuracy:  78.1%, Loss: 0.3825\n",
      "Optimization Iteration:  48321, Training Accuracy:  68.8%, Loss: 0.4933\n",
      "Optimization Iteration:  48385, Training Accuracy:  73.4%, Loss: 0.5661\n",
      "Optimization Iteration:  48449, Training Accuracy:  76.6%, Loss: 0.4510\n",
      "Optimization Iteration:  48513, Training Accuracy:  67.2%, Loss: 0.4769\n",
      "Optimization Iteration:  48577, Training Accuracy:  73.4%, Loss: 0.4571\n",
      "Optimization Iteration:  48641, Training Accuracy:  78.1%, Loss: 0.4207\n",
      "Optimization Iteration:  48705, Training Accuracy:  81.2%, Loss: 0.3747\n",
      "Optimization Iteration:  48769, Training Accuracy:  75.0%, Loss: 0.3817\n",
      "Optimization Iteration:  48833, Training Accuracy:  71.9%, Loss: 0.4518\n",
      "Optimization Iteration:  48897, Training Accuracy:  70.3%, Loss: 0.4014\n",
      "Optimization Iteration:  48961, Training Accuracy:  64.1%, Loss: 0.4506\n",
      "Optimization Iteration:  49025, Training Accuracy:  68.8%, Loss: 0.4692\n",
      "Optimization Iteration:  49089, Training Accuracy:  75.0%, Loss: 0.3765\n",
      "Optimization Iteration:  49153, Training Accuracy:  67.2%, Loss: 0.4353\n",
      "Optimization Iteration:  49217, Training Accuracy:  76.6%, Loss: 0.4032\n",
      "Optimization Iteration:  49281, Training Accuracy:  73.4%, Loss: 0.4016\n",
      "Optimization Iteration:  49345, Training Accuracy:  70.3%, Loss: 0.4257\n",
      "Optimization Iteration:  49409, Training Accuracy:  78.1%, Loss: 0.3688\n",
      "Optimization Iteration:  49473, Training Accuracy:  67.2%, Loss: 0.4142\n",
      "Optimization Iteration:  49537, Training Accuracy:  73.4%, Loss: 0.4189\n",
      "Optimization Iteration:  49601, Training Accuracy:  68.8%, Loss: 0.4975\n",
      "Optimization Iteration:  49665, Training Accuracy:  87.5%, Loss: 0.2958\n",
      "Optimization Iteration:  49729, Training Accuracy:  60.9%, Loss: 0.5397\n",
      "Optimization Iteration:  49793, Training Accuracy:  78.1%, Loss: 0.3613\n",
      "Optimization Iteration:  49857, Training Accuracy:  64.1%, Loss: 0.4693\n",
      "Optimization Iteration:  49921, Training Accuracy:  73.4%, Loss: 0.4781\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 8\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  71.9%, Loss: 0.4893\n",
      "Optimization Iteration:    129, Training Accuracy:  68.8%, Loss: 0.5044\n",
      "Optimization Iteration:    193, Training Accuracy:  65.6%, Loss: 0.4914\n",
      "Optimization Iteration:    257, Training Accuracy:  70.3%, Loss: 0.4037\n",
      "Optimization Iteration:    321, Training Accuracy:  78.1%, Loss: 0.3674\n",
      "Optimization Iteration:    385, Training Accuracy:  67.2%, Loss: 0.3860\n",
      "Optimization Iteration:    449, Training Accuracy:  81.2%, Loss: 0.3376\n",
      "Optimization Iteration:    513, Training Accuracy:  67.2%, Loss: 0.4735\n",
      "Optimization Iteration:    577, Training Accuracy:  67.2%, Loss: 0.4494\n",
      "Optimization Iteration:    641, Training Accuracy:  75.0%, Loss: 0.3972\n",
      "Optimization Iteration:    705, Training Accuracy:  71.9%, Loss: 0.4821\n",
      "Optimization Iteration:    769, Training Accuracy:  73.4%, Loss: 0.4198\n",
      "Optimization Iteration:    833, Training Accuracy:  81.2%, Loss: 0.3291\n",
      "Optimization Iteration:    897, Training Accuracy:  78.1%, Loss: 0.3232\n",
      "Optimization Iteration:    961, Training Accuracy:  76.6%, Loss: 0.3296\n",
      "Optimization Iteration:   1025, Training Accuracy:  76.6%, Loss: 0.4335\n",
      "Optimization Iteration:   1089, Training Accuracy:  70.3%, Loss: 0.4746\n",
      "Optimization Iteration:   1153, Training Accuracy:  76.6%, Loss: 0.4017\n",
      "Optimization Iteration:   1217, Training Accuracy:  73.4%, Loss: 0.4122\n",
      "Optimization Iteration:   1281, Training Accuracy:  68.8%, Loss: 0.4614\n",
      "Optimization Iteration:   1345, Training Accuracy:  75.0%, Loss: 0.3979\n",
      "Optimization Iteration:   1409, Training Accuracy:  76.6%, Loss: 0.3935\n",
      "Optimization Iteration:   1473, Training Accuracy:  70.3%, Loss: 0.4521\n",
      "Optimization Iteration:   1537, Training Accuracy:  71.9%, Loss: 0.4109\n",
      "Optimization Iteration:   1601, Training Accuracy:  76.6%, Loss: 0.3752\n",
      "Optimization Iteration:   1665, Training Accuracy:  75.0%, Loss: 0.3664\n",
      "Optimization Iteration:   1729, Training Accuracy:  67.2%, Loss: 0.4009\n",
      "Optimization Iteration:   1793, Training Accuracy:  67.2%, Loss: 0.4608\n",
      "Optimization Iteration:   1857, Training Accuracy:  78.1%, Loss: 0.3909\n",
      "Optimization Iteration:   1921, Training Accuracy:  70.3%, Loss: 0.4224\n",
      "Optimization Iteration:   1985, Training Accuracy:  76.6%, Loss: 0.3934\n",
      "Optimization Iteration:   2049, Training Accuracy:  70.3%, Loss: 0.3745\n",
      "Optimization Iteration:   2113, Training Accuracy:  76.6%, Loss: 0.3644\n",
      "Optimization Iteration:   2177, Training Accuracy:  81.2%, Loss: 0.3039\n",
      "Optimization Iteration:   2241, Training Accuracy:  70.3%, Loss: 0.4307\n",
      "Optimization Iteration:   2305, Training Accuracy:  75.0%, Loss: 0.4312\n",
      "Optimization Iteration:   2369, Training Accuracy:  85.9%, Loss: 0.3834\n",
      "Optimization Iteration:   2433, Training Accuracy:  70.3%, Loss: 0.4201\n",
      "Optimization Iteration:   2497, Training Accuracy:  78.1%, Loss: 0.4278\n",
      "Optimization Iteration:   2561, Training Accuracy:  82.8%, Loss: 0.3411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   2625, Training Accuracy:  79.7%, Loss: 0.4056\n",
      "Optimization Iteration:   2689, Training Accuracy:  75.0%, Loss: 0.3902\n",
      "Optimization Iteration:   2753, Training Accuracy:  81.2%, Loss: 0.3388\n",
      "Optimization Iteration:   2817, Training Accuracy:  70.3%, Loss: 0.3886\n",
      "Optimization Iteration:   2881, Training Accuracy:  71.9%, Loss: 0.4578\n",
      "Optimization Iteration:   2945, Training Accuracy:  73.4%, Loss: 0.4274\n",
      "Optimization Iteration:   3009, Training Accuracy:  84.4%, Loss: 0.3328\n",
      "Optimization Iteration:   3073, Training Accuracy:  81.2%, Loss: 0.4106\n",
      "Optimization Iteration:   3137, Training Accuracy:  70.3%, Loss: 0.3962\n",
      "Optimization Iteration:   3201, Training Accuracy:  79.7%, Loss: 0.3356\n",
      "Optimization Iteration:   3265, Training Accuracy:  73.4%, Loss: 0.4508\n",
      "Optimization Iteration:   3329, Training Accuracy:  75.0%, Loss: 0.4431\n",
      "Optimization Iteration:   3393, Training Accuracy:  71.9%, Loss: 0.3522\n",
      "Optimization Iteration:   3457, Training Accuracy:  76.6%, Loss: 0.5047\n",
      "Optimization Iteration:   3521, Training Accuracy:  75.0%, Loss: 0.3820\n",
      "Optimization Iteration:   3585, Training Accuracy:  68.8%, Loss: 0.5624\n",
      "Optimization Iteration:   3649, Training Accuracy:  71.9%, Loss: 0.5247\n",
      "Optimization Iteration:   3713, Training Accuracy:  75.0%, Loss: 0.3965\n",
      "Optimization Iteration:   3777, Training Accuracy:  75.0%, Loss: 0.4443\n",
      "Optimization Iteration:   3841, Training Accuracy:  68.8%, Loss: 0.4543\n",
      "Optimization Iteration:   3905, Training Accuracy:  73.4%, Loss: 0.4275\n",
      "Optimization Iteration:   3969, Training Accuracy:  71.9%, Loss: 0.3879\n",
      "Optimization Iteration:   4033, Training Accuracy:  73.4%, Loss: 0.3875\n",
      "Optimization Iteration:   4097, Training Accuracy:  67.2%, Loss: 0.4012\n",
      "Optimization Iteration:   4161, Training Accuracy:  68.8%, Loss: 0.4795\n",
      "Optimization Iteration:   4225, Training Accuracy:  84.4%, Loss: 0.3483\n",
      "Optimization Iteration:   4289, Training Accuracy:  73.4%, Loss: 0.3706\n",
      "Optimization Iteration:   4353, Training Accuracy:  73.4%, Loss: 0.3601\n",
      "Optimization Iteration:   4417, Training Accuracy:  73.4%, Loss: 0.4262\n",
      "Optimization Iteration:   4481, Training Accuracy:  73.4%, Loss: 0.4550\n",
      "Optimization Iteration:   4545, Training Accuracy:  67.2%, Loss: 0.4253\n",
      "Optimization Iteration:   4609, Training Accuracy:  73.4%, Loss: 0.3803\n",
      "Optimization Iteration:   4673, Training Accuracy:  78.1%, Loss: 0.4009\n",
      "Optimization Iteration:   4737, Training Accuracy:  67.2%, Loss: 0.4629\n",
      "Optimization Iteration:   4801, Training Accuracy:  68.8%, Loss: 0.5266\n",
      "Optimization Iteration:   4865, Training Accuracy:  68.8%, Loss: 0.4312\n",
      "Optimization Iteration:   4929, Training Accuracy:  71.9%, Loss: 0.5280\n",
      "Optimization Iteration:   4993, Training Accuracy:  84.4%, Loss: 0.3321\n",
      "Optimization Iteration:   5057, Training Accuracy:  68.8%, Loss: 0.4763\n",
      "Optimization Iteration:   5121, Training Accuracy:  70.3%, Loss: 0.3959\n",
      "Optimization Iteration:   5185, Training Accuracy:  73.4%, Loss: 0.5082\n",
      "Optimization Iteration:   5249, Training Accuracy:  59.4%, Loss: 0.5330\n",
      "Optimization Iteration:   5313, Training Accuracy:  78.1%, Loss: 0.4360\n",
      "Optimization Iteration:   5377, Training Accuracy:  79.7%, Loss: 0.3858\n",
      "Optimization Iteration:   5441, Training Accuracy:  71.9%, Loss: 0.3870\n",
      "Optimization Iteration:   5505, Training Accuracy:  75.0%, Loss: 0.3654\n",
      "Optimization Iteration:   5569, Training Accuracy:  68.8%, Loss: 0.4714\n",
      "Optimization Iteration:   5633, Training Accuracy:  73.4%, Loss: 0.4339\n",
      "Optimization Iteration:   5697, Training Accuracy:  71.9%, Loss: 0.4317\n",
      "Optimization Iteration:   5761, Training Accuracy:  78.1%, Loss: 0.3967\n",
      "Optimization Iteration:   5825, Training Accuracy:  67.2%, Loss: 0.4397\n",
      "Optimization Iteration:   5889, Training Accuracy:  81.2%, Loss: 0.4592\n",
      "Optimization Iteration:   5953, Training Accuracy:  81.2%, Loss: 0.4502\n",
      "Optimization Iteration:   6017, Training Accuracy:  68.8%, Loss: 0.5251\n",
      "Optimization Iteration:   6081, Training Accuracy:  76.6%, Loss: 0.3819\n",
      "Optimization Iteration:   6145, Training Accuracy:  68.8%, Loss: 0.5281\n",
      "Optimization Iteration:   6209, Training Accuracy:  71.9%, Loss: 0.4259\n",
      "Optimization Iteration:   6273, Training Accuracy:  78.1%, Loss: 0.3972\n",
      "Optimization Iteration:   6337, Training Accuracy:  67.2%, Loss: 0.5123\n",
      "Optimization Iteration:   6401, Training Accuracy:  84.4%, Loss: 0.4712\n",
      "Optimization Iteration:   6465, Training Accuracy:  82.8%, Loss: 0.3262\n",
      "Optimization Iteration:   6529, Training Accuracy:  78.1%, Loss: 0.4619\n",
      "Optimization Iteration:   6593, Training Accuracy:  73.4%, Loss: 0.4480\n",
      "Optimization Iteration:   6657, Training Accuracy:  68.8%, Loss: 0.4774\n",
      "Optimization Iteration:   6721, Training Accuracy:  75.0%, Loss: 0.3533\n",
      "Optimization Iteration:   6785, Training Accuracy:  75.0%, Loss: 0.4347\n",
      "Optimization Iteration:   6849, Training Accuracy:  76.6%, Loss: 0.3818\n",
      "Optimization Iteration:   6913, Training Accuracy:  70.3%, Loss: 0.3684\n",
      "Optimization Iteration:   6977, Training Accuracy:  70.3%, Loss: 0.4483\n",
      "Optimization Iteration:   7041, Training Accuracy:  79.7%, Loss: 0.3566\n",
      "Optimization Iteration:   7105, Training Accuracy:  81.2%, Loss: 0.3955\n",
      "Optimization Iteration:   7169, Training Accuracy:  73.4%, Loss: 0.4016\n",
      "Optimization Iteration:   7233, Training Accuracy:  81.2%, Loss: 0.4757\n",
      "Optimization Iteration:   7297, Training Accuracy:  70.3%, Loss: 0.5146\n",
      "Optimization Iteration:   7361, Training Accuracy:  67.2%, Loss: 0.4851\n",
      "Optimization Iteration:   7425, Training Accuracy:  79.7%, Loss: 0.3783\n",
      "Optimization Iteration:   7489, Training Accuracy:  71.9%, Loss: 0.4601\n",
      "Optimization Iteration:   7553, Training Accuracy:  75.0%, Loss: 0.3900\n",
      "Optimization Iteration:   7617, Training Accuracy:  71.9%, Loss: 0.4194\n",
      "Optimization Iteration:   7681, Training Accuracy:  79.7%, Loss: 0.4492\n",
      "Optimization Iteration:   7745, Training Accuracy:  65.6%, Loss: 0.4638\n",
      "Optimization Iteration:   7809, Training Accuracy:  67.2%, Loss: 0.5392\n",
      "Optimization Iteration:   7873, Training Accuracy:  75.0%, Loss: 0.3589\n",
      "Optimization Iteration:   7937, Training Accuracy:  82.8%, Loss: 0.3957\n",
      "Optimization Iteration:   8001, Training Accuracy:  73.4%, Loss: 0.4199\n",
      "Optimization Iteration:   8065, Training Accuracy:  75.0%, Loss: 0.4743\n",
      "Optimization Iteration:   8129, Training Accuracy:  71.9%, Loss: 0.4217\n",
      "Optimization Iteration:   8193, Training Accuracy:  73.4%, Loss: 0.4424\n",
      "Optimization Iteration:   8257, Training Accuracy:  68.8%, Loss: 0.5228\n",
      "Optimization Iteration:   8321, Training Accuracy:  78.1%, Loss: 0.4357\n",
      "Optimization Iteration:   8385, Training Accuracy:  76.6%, Loss: 0.4835\n",
      "Optimization Iteration:   8449, Training Accuracy:  71.9%, Loss: 0.5059\n",
      "Optimization Iteration:   8513, Training Accuracy:  79.7%, Loss: 0.3686\n",
      "Optimization Iteration:   8577, Training Accuracy:  60.9%, Loss: 0.5469\n",
      "Optimization Iteration:   8641, Training Accuracy:  76.6%, Loss: 0.4325\n",
      "Optimization Iteration:   8705, Training Accuracy:  81.2%, Loss: 0.3348\n",
      "Optimization Iteration:   8769, Training Accuracy:  76.6%, Loss: 0.4118\n",
      "Optimization Iteration:   8833, Training Accuracy:  67.2%, Loss: 0.4529\n",
      "Optimization Iteration:   8897, Training Accuracy:  73.4%, Loss: 0.4879\n",
      "Optimization Iteration:   8961, Training Accuracy:  67.2%, Loss: 0.4139\n",
      "Optimization Iteration:   9025, Training Accuracy:  65.6%, Loss: 0.4967\n",
      "Optimization Iteration:   9089, Training Accuracy:  60.9%, Loss: 0.5164\n",
      "Optimization Iteration:   9153, Training Accuracy:  65.6%, Loss: 0.4609\n",
      "Optimization Iteration:   9217, Training Accuracy:  81.2%, Loss: 0.4063\n",
      "Optimization Iteration:   9281, Training Accuracy:  70.3%, Loss: 0.4346\n",
      "Optimization Iteration:   9345, Training Accuracy:  81.2%, Loss: 0.3807\n",
      "Optimization Iteration:   9409, Training Accuracy:  79.7%, Loss: 0.4588\n",
      "Optimization Iteration:   9473, Training Accuracy:  73.4%, Loss: 0.4035\n",
      "Optimization Iteration:   9537, Training Accuracy:  71.9%, Loss: 0.4253\n",
      "Optimization Iteration:   9601, Training Accuracy:  68.8%, Loss: 0.4711\n",
      "Optimization Iteration:   9665, Training Accuracy:  64.1%, Loss: 0.5103\n",
      "Optimization Iteration:   9729, Training Accuracy:  68.8%, Loss: 0.4779\n",
      "Optimization Iteration:   9793, Training Accuracy:  79.7%, Loss: 0.3555\n",
      "Optimization Iteration:   9857, Training Accuracy:  71.9%, Loss: 0.4152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   9921, Training Accuracy:  67.2%, Loss: 0.4443\n",
      "Optimization Iteration:   9985, Training Accuracy:  79.7%, Loss: 0.4040\n",
      "Optimization Iteration:  10049, Training Accuracy:  68.8%, Loss: 0.4721\n",
      "Optimization Iteration:  10113, Training Accuracy:  68.8%, Loss: 0.4358\n",
      "Optimization Iteration:  10177, Training Accuracy:  71.9%, Loss: 0.5161\n",
      "Optimization Iteration:  10241, Training Accuracy:  68.8%, Loss: 0.4221\n",
      "Optimization Iteration:  10305, Training Accuracy:  78.1%, Loss: 0.3356\n",
      "Optimization Iteration:  10369, Training Accuracy:  68.8%, Loss: 0.4303\n",
      "Optimization Iteration:  10433, Training Accuracy:  73.4%, Loss: 0.3959\n",
      "Optimization Iteration:  10497, Training Accuracy:  71.9%, Loss: 0.4917\n",
      "Optimization Iteration:  10561, Training Accuracy:  79.7%, Loss: 0.3756\n",
      "Optimization Iteration:  10625, Training Accuracy:  75.0%, Loss: 0.4022\n",
      "Optimization Iteration:  10689, Training Accuracy:  76.6%, Loss: 0.4182\n",
      "Optimization Iteration:  10753, Training Accuracy:  71.9%, Loss: 0.4645\n",
      "Optimization Iteration:  10817, Training Accuracy:  76.6%, Loss: 0.4443\n",
      "Optimization Iteration:  10881, Training Accuracy:  78.1%, Loss: 0.3697\n",
      "Optimization Iteration:  10945, Training Accuracy:  76.6%, Loss: 0.4416\n",
      "Optimization Iteration:  11009, Training Accuracy:  82.8%, Loss: 0.3315\n",
      "Optimization Iteration:  11073, Training Accuracy:  76.6%, Loss: 0.4251\n",
      "Optimization Iteration:  11137, Training Accuracy:  78.1%, Loss: 0.3694\n",
      "Optimization Iteration:  11201, Training Accuracy:  73.4%, Loss: 0.4198\n",
      "Optimization Iteration:  11265, Training Accuracy:  76.6%, Loss: 0.3719\n",
      "Optimization Iteration:  11329, Training Accuracy:  73.4%, Loss: 0.5134\n",
      "Optimization Iteration:  11393, Training Accuracy:  79.7%, Loss: 0.3549\n",
      "Optimization Iteration:  11457, Training Accuracy:  73.4%, Loss: 0.4292\n",
      "Optimization Iteration:  11521, Training Accuracy:  71.9%, Loss: 0.4512\n",
      "Optimization Iteration:  11585, Training Accuracy:  70.3%, Loss: 0.4170\n",
      "Optimization Iteration:  11649, Training Accuracy:  64.1%, Loss: 0.5484\n",
      "Optimization Iteration:  11713, Training Accuracy:  75.0%, Loss: 0.3499\n",
      "Optimization Iteration:  11777, Training Accuracy:  73.4%, Loss: 0.4888\n",
      "Optimization Iteration:  11841, Training Accuracy:  71.9%, Loss: 0.4306\n",
      "Optimization Iteration:  11905, Training Accuracy:  81.2%, Loss: 0.3759\n",
      "Optimization Iteration:  11969, Training Accuracy:  82.8%, Loss: 0.3782\n",
      "Optimization Iteration:  12033, Training Accuracy:  79.7%, Loss: 0.3794\n",
      "Optimization Iteration:  12097, Training Accuracy:  79.7%, Loss: 0.3499\n",
      "Optimization Iteration:  12161, Training Accuracy:  73.4%, Loss: 0.4425\n",
      "Optimization Iteration:  12225, Training Accuracy:  81.2%, Loss: 0.4613\n",
      "Optimization Iteration:  12289, Training Accuracy:  71.9%, Loss: 0.3735\n",
      "Optimization Iteration:  12353, Training Accuracy:  75.0%, Loss: 0.3965\n",
      "Optimization Iteration:  12417, Training Accuracy:  71.9%, Loss: 0.4512\n",
      "Optimization Iteration:  12481, Training Accuracy:  73.4%, Loss: 0.3973\n",
      "Optimization Iteration:  12545, Training Accuracy:  73.4%, Loss: 0.5253\n",
      "Optimization Iteration:  12609, Training Accuracy:  81.2%, Loss: 0.3862\n",
      "Optimization Iteration:  12673, Training Accuracy:  75.0%, Loss: 0.4046\n",
      "Optimization Iteration:  12737, Training Accuracy:  73.4%, Loss: 0.5104\n",
      "Optimization Iteration:  12801, Training Accuracy:  68.8%, Loss: 0.4476\n",
      "Optimization Iteration:  12865, Training Accuracy:  62.5%, Loss: 0.5011\n",
      "Optimization Iteration:  12929, Training Accuracy:  70.3%, Loss: 0.4468\n",
      "Optimization Iteration:  12993, Training Accuracy:  76.6%, Loss: 0.3822\n",
      "Optimization Iteration:  13057, Training Accuracy:  68.8%, Loss: 0.4712\n",
      "Optimization Iteration:  13121, Training Accuracy:  62.5%, Loss: 0.5266\n",
      "Optimization Iteration:  13185, Training Accuracy:  70.3%, Loss: 0.5089\n",
      "Optimization Iteration:  13249, Training Accuracy:  70.3%, Loss: 0.4813\n",
      "Optimization Iteration:  13313, Training Accuracy:  71.9%, Loss: 0.5416\n",
      "Optimization Iteration:  13377, Training Accuracy:  73.4%, Loss: 0.4875\n",
      "Optimization Iteration:  13441, Training Accuracy:  75.0%, Loss: 0.4183\n",
      "Optimization Iteration:  13505, Training Accuracy:  75.0%, Loss: 0.3913\n",
      "Optimization Iteration:  13569, Training Accuracy:  84.4%, Loss: 0.3023\n",
      "Optimization Iteration:  13633, Training Accuracy:  75.0%, Loss: 0.3751\n",
      "Optimization Iteration:  13697, Training Accuracy:  71.9%, Loss: 0.4333\n",
      "Optimization Iteration:  13761, Training Accuracy:  78.1%, Loss: 0.3656\n",
      "Optimization Iteration:  13825, Training Accuracy:  75.0%, Loss: 0.4819\n",
      "Optimization Iteration:  13889, Training Accuracy:  78.1%, Loss: 0.4832\n",
      "Optimization Iteration:  13953, Training Accuracy:  78.1%, Loss: 0.4044\n",
      "Optimization Iteration:  14017, Training Accuracy:  70.3%, Loss: 0.5224\n",
      "Optimization Iteration:  14081, Training Accuracy:  68.8%, Loss: 0.4691\n",
      "Optimization Iteration:  14145, Training Accuracy:  81.2%, Loss: 0.4064\n",
      "Optimization Iteration:  14209, Training Accuracy:  78.1%, Loss: 0.4757\n",
      "Optimization Iteration:  14273, Training Accuracy:  68.8%, Loss: 0.5046\n",
      "Optimization Iteration:  14337, Training Accuracy:  85.9%, Loss: 0.3024\n",
      "Optimization Iteration:  14401, Training Accuracy:  73.4%, Loss: 0.3824\n",
      "Optimization Iteration:  14465, Training Accuracy:  65.6%, Loss: 0.4917\n",
      "Optimization Iteration:  14529, Training Accuracy:  76.6%, Loss: 0.4982\n",
      "Optimization Iteration:  14593, Training Accuracy:  78.1%, Loss: 0.4305\n",
      "Optimization Iteration:  14657, Training Accuracy:  68.8%, Loss: 0.4877\n",
      "Optimization Iteration:  14721, Training Accuracy:  75.0%, Loss: 0.4045\n",
      "Optimization Iteration:  14785, Training Accuracy:  75.0%, Loss: 0.5069\n",
      "Optimization Iteration:  14849, Training Accuracy:  76.6%, Loss: 0.3863\n",
      "Optimization Iteration:  14913, Training Accuracy:  81.2%, Loss: 0.3842\n",
      "Optimization Iteration:  14977, Training Accuracy:  76.6%, Loss: 0.4222\n",
      "Optimization Iteration:  15041, Training Accuracy:  67.2%, Loss: 0.4495\n",
      "Optimization Iteration:  15105, Training Accuracy:  78.1%, Loss: 0.4188\n",
      "Optimization Iteration:  15169, Training Accuracy:  71.9%, Loss: 0.4294\n",
      "Optimization Iteration:  15233, Training Accuracy:  67.2%, Loss: 0.4294\n",
      "Optimization Iteration:  15297, Training Accuracy:  73.4%, Loss: 0.4614\n",
      "Optimization Iteration:  15361, Training Accuracy:  84.4%, Loss: 0.3507\n",
      "Optimization Iteration:  15425, Training Accuracy:  67.2%, Loss: 0.3991\n",
      "Optimization Iteration:  15489, Training Accuracy:  64.1%, Loss: 0.4666\n",
      "Optimization Iteration:  15553, Training Accuracy:  81.2%, Loss: 0.3326\n",
      "Optimization Iteration:  15617, Training Accuracy:  76.6%, Loss: 0.4212\n",
      "Optimization Iteration:  15681, Training Accuracy:  73.4%, Loss: 0.4125\n",
      "Optimization Iteration:  15745, Training Accuracy:  70.3%, Loss: 0.4260\n",
      "Optimization Iteration:  15809, Training Accuracy:  70.3%, Loss: 0.4415\n",
      "Optimization Iteration:  15873, Training Accuracy:  67.2%, Loss: 0.4833\n",
      "Optimization Iteration:  15937, Training Accuracy:  76.6%, Loss: 0.3917\n",
      "Optimization Iteration:  16001, Training Accuracy:  64.1%, Loss: 0.5037\n",
      "Optimization Iteration:  16065, Training Accuracy:  68.8%, Loss: 0.4912\n",
      "Optimization Iteration:  16129, Training Accuracy:  73.4%, Loss: 0.4226\n",
      "Optimization Iteration:  16193, Training Accuracy:  78.1%, Loss: 0.4195\n",
      "Optimization Iteration:  16257, Training Accuracy:  78.1%, Loss: 0.4500\n",
      "Optimization Iteration:  16321, Training Accuracy:  73.4%, Loss: 0.4747\n",
      "Optimization Iteration:  16385, Training Accuracy:  71.9%, Loss: 0.4449\n",
      "Optimization Iteration:  16449, Training Accuracy:  73.4%, Loss: 0.3945\n",
      "Optimization Iteration:  16513, Training Accuracy:  73.4%, Loss: 0.5379\n",
      "Optimization Iteration:  16577, Training Accuracy:  78.1%, Loss: 0.3972\n",
      "Optimization Iteration:  16641, Training Accuracy:  71.9%, Loss: 0.4656\n",
      "Optimization Iteration:  16705, Training Accuracy:  75.0%, Loss: 0.4402\n",
      "Optimization Iteration:  16769, Training Accuracy:  78.1%, Loss: 0.3696\n",
      "Optimization Iteration:  16833, Training Accuracy:  75.0%, Loss: 0.4092\n",
      "Optimization Iteration:  16897, Training Accuracy:  82.8%, Loss: 0.3946\n",
      "Optimization Iteration:  16961, Training Accuracy:  73.4%, Loss: 0.4824\n",
      "Optimization Iteration:  17025, Training Accuracy:  73.4%, Loss: 0.4122\n",
      "Optimization Iteration:  17089, Training Accuracy:  75.0%, Loss: 0.4758\n",
      "Optimization Iteration:  17153, Training Accuracy:  73.4%, Loss: 0.4126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  17217, Training Accuracy:  73.4%, Loss: 0.4197\n",
      "Optimization Iteration:  17281, Training Accuracy:  70.3%, Loss: 0.4258\n",
      "Optimization Iteration:  17345, Training Accuracy:  76.6%, Loss: 0.4158\n",
      "Optimization Iteration:  17409, Training Accuracy:  79.7%, Loss: 0.4201\n",
      "Optimization Iteration:  17473, Training Accuracy:  62.5%, Loss: 0.5460\n",
      "Optimization Iteration:  17537, Training Accuracy:  79.7%, Loss: 0.3326\n",
      "Optimization Iteration:  17601, Training Accuracy:  73.4%, Loss: 0.4913\n",
      "Optimization Iteration:  17665, Training Accuracy:  78.1%, Loss: 0.4396\n",
      "Optimization Iteration:  17729, Training Accuracy:  67.2%, Loss: 0.4180\n",
      "Optimization Iteration:  17793, Training Accuracy:  78.1%, Loss: 0.4296\n",
      "Optimization Iteration:  17857, Training Accuracy:  67.2%, Loss: 0.4816\n",
      "Optimization Iteration:  17921, Training Accuracy:  79.7%, Loss: 0.3787\n",
      "Optimization Iteration:  17985, Training Accuracy:  79.7%, Loss: 0.3663\n",
      "Optimization Iteration:  18049, Training Accuracy:  76.6%, Loss: 0.3866\n",
      "Optimization Iteration:  18113, Training Accuracy:  70.3%, Loss: 0.5070\n",
      "Optimization Iteration:  18177, Training Accuracy:  68.8%, Loss: 0.6038\n",
      "Optimization Iteration:  18241, Training Accuracy:  71.9%, Loss: 0.3749\n",
      "Optimization Iteration:  18305, Training Accuracy:  76.6%, Loss: 0.3878\n",
      "Optimization Iteration:  18369, Training Accuracy:  71.9%, Loss: 0.3668\n",
      "Optimization Iteration:  18433, Training Accuracy:  64.1%, Loss: 0.5037\n",
      "Optimization Iteration:  18497, Training Accuracy:  81.2%, Loss: 0.3527\n",
      "Optimization Iteration:  18561, Training Accuracy:  79.7%, Loss: 0.4167\n",
      "Optimization Iteration:  18625, Training Accuracy:  73.4%, Loss: 0.4248\n",
      "Optimization Iteration:  18689, Training Accuracy:  76.6%, Loss: 0.4790\n",
      "Optimization Iteration:  18753, Training Accuracy:  79.7%, Loss: 0.3916\n",
      "Optimization Iteration:  18817, Training Accuracy:  76.6%, Loss: 0.3854\n",
      "Optimization Iteration:  18881, Training Accuracy:  81.2%, Loss: 0.4025\n",
      "Optimization Iteration:  18945, Training Accuracy:  79.7%, Loss: 0.4306\n",
      "Optimization Iteration:  19009, Training Accuracy:  73.4%, Loss: 0.3628\n",
      "Optimization Iteration:  19073, Training Accuracy:  73.4%, Loss: 0.4961\n",
      "Optimization Iteration:  19137, Training Accuracy:  65.6%, Loss: 0.4875\n",
      "Optimization Iteration:  19201, Training Accuracy:  82.8%, Loss: 0.4130\n",
      "Optimization Iteration:  19265, Training Accuracy:  84.4%, Loss: 0.4050\n",
      "Optimization Iteration:  19329, Training Accuracy:  84.4%, Loss: 0.3450\n",
      "Optimization Iteration:  19393, Training Accuracy:  68.8%, Loss: 0.5186\n",
      "Optimization Iteration:  19457, Training Accuracy:  73.4%, Loss: 0.4489\n",
      "Optimization Iteration:  19521, Training Accuracy:  79.7%, Loss: 0.4256\n",
      "Optimization Iteration:  19585, Training Accuracy:  60.9%, Loss: 0.4647\n",
      "Optimization Iteration:  19649, Training Accuracy:  73.4%, Loss: 0.4961\n",
      "Optimization Iteration:  19713, Training Accuracy:  73.4%, Loss: 0.3943\n",
      "Optimization Iteration:  19777, Training Accuracy:  65.6%, Loss: 0.4675\n",
      "Optimization Iteration:  19841, Training Accuracy:  78.1%, Loss: 0.4411\n",
      "Optimization Iteration:  19905, Training Accuracy:  79.7%, Loss: 0.4298\n",
      "Optimization Iteration:  19969, Training Accuracy:  81.2%, Loss: 0.4134\n",
      "Optimization Iteration:  20033, Training Accuracy:  81.2%, Loss: 0.4403\n",
      "Optimization Iteration:  20097, Training Accuracy:  71.9%, Loss: 0.4169\n",
      "Optimization Iteration:  20161, Training Accuracy:  70.3%, Loss: 0.4581\n",
      "Optimization Iteration:  20225, Training Accuracy:  68.8%, Loss: 0.4655\n",
      "Optimization Iteration:  20289, Training Accuracy:  70.3%, Loss: 0.4743\n",
      "Optimization Iteration:  20353, Training Accuracy:  79.7%, Loss: 0.4116\n",
      "Optimization Iteration:  20417, Training Accuracy:  73.4%, Loss: 0.4194\n",
      "Optimization Iteration:  20481, Training Accuracy:  79.7%, Loss: 0.4257\n",
      "Optimization Iteration:  20545, Training Accuracy:  73.4%, Loss: 0.4909\n",
      "Optimization Iteration:  20609, Training Accuracy:  62.5%, Loss: 0.5155\n",
      "Optimization Iteration:  20673, Training Accuracy:  78.1%, Loss: 0.3781\n",
      "Optimization Iteration:  20737, Training Accuracy:  78.1%, Loss: 0.4019\n",
      "Optimization Iteration:  20801, Training Accuracy:  76.6%, Loss: 0.4225\n",
      "Optimization Iteration:  20865, Training Accuracy:  76.6%, Loss: 0.3501\n",
      "Optimization Iteration:  20929, Training Accuracy:  73.4%, Loss: 0.4000\n",
      "Optimization Iteration:  20993, Training Accuracy:  79.7%, Loss: 0.4175\n",
      "Optimization Iteration:  21057, Training Accuracy:  78.1%, Loss: 0.3621\n",
      "Optimization Iteration:  21121, Training Accuracy:  57.8%, Loss: 0.5126\n",
      "Optimization Iteration:  21185, Training Accuracy:  67.2%, Loss: 0.4522\n",
      "Optimization Iteration:  21249, Training Accuracy:  71.9%, Loss: 0.5038\n",
      "Optimization Iteration:  21313, Training Accuracy:  73.4%, Loss: 0.4508\n",
      "Optimization Iteration:  21377, Training Accuracy:  73.4%, Loss: 0.3915\n",
      "Optimization Iteration:  21441, Training Accuracy:  75.0%, Loss: 0.3813\n",
      "Optimization Iteration:  21505, Training Accuracy:  78.1%, Loss: 0.3937\n",
      "Optimization Iteration:  21569, Training Accuracy:  73.4%, Loss: 0.3778\n",
      "Optimization Iteration:  21633, Training Accuracy:  79.7%, Loss: 0.3441\n",
      "Optimization Iteration:  21697, Training Accuracy:  68.8%, Loss: 0.5502\n",
      "Optimization Iteration:  21761, Training Accuracy:  70.3%, Loss: 0.3419\n",
      "Optimization Iteration:  21825, Training Accuracy:  73.4%, Loss: 0.5406\n",
      "Optimization Iteration:  21889, Training Accuracy:  79.7%, Loss: 0.3275\n",
      "Optimization Iteration:  21953, Training Accuracy:  65.6%, Loss: 0.5065\n",
      "Optimization Iteration:  22017, Training Accuracy:  79.7%, Loss: 0.3831\n",
      "Optimization Iteration:  22081, Training Accuracy:  82.8%, Loss: 0.4011\n",
      "Optimization Iteration:  22145, Training Accuracy:  73.4%, Loss: 0.4427\n",
      "Optimization Iteration:  22209, Training Accuracy:  70.3%, Loss: 0.5019\n",
      "Optimization Iteration:  22273, Training Accuracy:  81.2%, Loss: 0.3811\n",
      "Optimization Iteration:  22337, Training Accuracy:  79.7%, Loss: 0.3439\n",
      "Optimization Iteration:  22401, Training Accuracy:  67.2%, Loss: 0.4818\n",
      "Optimization Iteration:  22465, Training Accuracy:  59.4%, Loss: 0.5136\n",
      "Optimization Iteration:  22529, Training Accuracy:  78.1%, Loss: 0.3998\n",
      "Optimization Iteration:  22593, Training Accuracy:  70.3%, Loss: 0.4511\n",
      "Optimization Iteration:  22657, Training Accuracy:  78.1%, Loss: 0.4439\n",
      "Optimization Iteration:  22721, Training Accuracy:  70.3%, Loss: 0.4236\n",
      "Optimization Iteration:  22785, Training Accuracy:  75.0%, Loss: 0.4130\n",
      "Optimization Iteration:  22849, Training Accuracy:  71.9%, Loss: 0.4224\n",
      "Optimization Iteration:  22913, Training Accuracy:  76.6%, Loss: 0.4155\n",
      "Optimization Iteration:  22977, Training Accuracy:  78.1%, Loss: 0.3652\n",
      "Optimization Iteration:  23041, Training Accuracy:  78.1%, Loss: 0.3543\n",
      "Optimization Iteration:  23105, Training Accuracy:  76.6%, Loss: 0.3719\n",
      "Optimization Iteration:  23169, Training Accuracy:  75.0%, Loss: 0.3970\n",
      "Optimization Iteration:  23233, Training Accuracy:  68.8%, Loss: 0.5792\n",
      "Optimization Iteration:  23297, Training Accuracy:  75.0%, Loss: 0.5033\n",
      "Optimization Iteration:  23361, Training Accuracy:  67.2%, Loss: 0.5197\n",
      "Optimization Iteration:  23425, Training Accuracy:  75.0%, Loss: 0.4301\n",
      "Optimization Iteration:  23489, Training Accuracy:  70.3%, Loss: 0.4624\n",
      "Optimization Iteration:  23553, Training Accuracy:  79.7%, Loss: 0.3985\n",
      "Optimization Iteration:  23617, Training Accuracy:  65.6%, Loss: 0.4873\n",
      "Optimization Iteration:  23681, Training Accuracy:  73.4%, Loss: 0.4845\n",
      "Optimization Iteration:  23745, Training Accuracy:  71.9%, Loss: 0.3866\n",
      "Optimization Iteration:  23809, Training Accuracy:  71.9%, Loss: 0.4406\n",
      "Optimization Iteration:  23873, Training Accuracy:  67.2%, Loss: 0.4146\n",
      "Optimization Iteration:  23937, Training Accuracy:  67.2%, Loss: 0.4757\n",
      "Optimization Iteration:  24001, Training Accuracy:  78.1%, Loss: 0.4259\n",
      "Optimization Iteration:  24065, Training Accuracy:  78.1%, Loss: 0.3560\n",
      "Optimization Iteration:  24129, Training Accuracy:  81.2%, Loss: 0.3663\n",
      "Optimization Iteration:  24193, Training Accuracy:  73.4%, Loss: 0.4324\n",
      "Optimization Iteration:  24257, Training Accuracy:  73.4%, Loss: 0.4411\n",
      "Optimization Iteration:  24321, Training Accuracy:  70.3%, Loss: 0.4870\n",
      "Optimization Iteration:  24385, Training Accuracy:  65.6%, Loss: 0.4762\n",
      "Optimization Iteration:  24449, Training Accuracy:  81.2%, Loss: 0.3383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  24513, Training Accuracy:  70.3%, Loss: 0.4143\n",
      "Optimization Iteration:  24577, Training Accuracy:  67.2%, Loss: 0.5630\n",
      "Optimization Iteration:  24641, Training Accuracy:  65.6%, Loss: 0.5302\n",
      "Optimization Iteration:  24705, Training Accuracy:  71.9%, Loss: 0.4487\n",
      "Optimization Iteration:  24769, Training Accuracy:  76.6%, Loss: 0.3835\n",
      "Optimization Iteration:  24833, Training Accuracy:  75.0%, Loss: 0.4133\n",
      "Optimization Iteration:  24897, Training Accuracy:  68.8%, Loss: 0.4506\n",
      "Optimization Iteration:  24961, Training Accuracy:  87.5%, Loss: 0.2932\n",
      "Optimization Iteration:  25025, Training Accuracy:  62.5%, Loss: 0.5102\n",
      "Optimization Iteration:  25089, Training Accuracy:  70.3%, Loss: 0.3725\n",
      "Optimization Iteration:  25153, Training Accuracy:  70.3%, Loss: 0.4381\n",
      "Optimization Iteration:  25217, Training Accuracy:  68.8%, Loss: 0.5008\n",
      "Optimization Iteration:  25281, Training Accuracy:  78.1%, Loss: 0.3883\n",
      "Optimization Iteration:  25345, Training Accuracy:  67.2%, Loss: 0.4995\n",
      "Optimization Iteration:  25409, Training Accuracy:  68.8%, Loss: 0.4970\n",
      "Optimization Iteration:  25473, Training Accuracy:  76.6%, Loss: 0.3981\n",
      "Optimization Iteration:  25537, Training Accuracy:  75.0%, Loss: 0.3596\n",
      "Optimization Iteration:  25601, Training Accuracy:  70.3%, Loss: 0.4574\n",
      "Optimization Iteration:  25665, Training Accuracy:  65.6%, Loss: 0.4991\n",
      "Optimization Iteration:  25729, Training Accuracy:  75.0%, Loss: 0.3949\n",
      "Optimization Iteration:  25793, Training Accuracy:  76.6%, Loss: 0.4111\n",
      "Optimization Iteration:  25857, Training Accuracy:  76.6%, Loss: 0.4328\n",
      "Optimization Iteration:  25921, Training Accuracy:  78.1%, Loss: 0.4453\n",
      "Optimization Iteration:  25985, Training Accuracy:  73.4%, Loss: 0.5430\n",
      "Optimization Iteration:  26049, Training Accuracy:  73.4%, Loss: 0.4072\n",
      "Optimization Iteration:  26113, Training Accuracy:  75.0%, Loss: 0.3848\n",
      "Optimization Iteration:  26177, Training Accuracy:  68.8%, Loss: 0.4692\n",
      "Optimization Iteration:  26241, Training Accuracy:  75.0%, Loss: 0.4231\n",
      "Optimization Iteration:  26305, Training Accuracy:  71.9%, Loss: 0.4261\n",
      "Optimization Iteration:  26369, Training Accuracy:  84.4%, Loss: 0.4075\n",
      "Optimization Iteration:  26433, Training Accuracy:  68.8%, Loss: 0.4343\n",
      "Optimization Iteration:  26497, Training Accuracy:  71.9%, Loss: 0.4317\n",
      "Optimization Iteration:  26561, Training Accuracy:  76.6%, Loss: 0.3669\n",
      "Optimization Iteration:  26625, Training Accuracy:  64.1%, Loss: 0.4867\n",
      "Optimization Iteration:  26689, Training Accuracy:  75.0%, Loss: 0.4302\n",
      "Optimization Iteration:  26753, Training Accuracy:  71.9%, Loss: 0.4278\n",
      "Optimization Iteration:  26817, Training Accuracy:  70.3%, Loss: 0.4581\n",
      "Optimization Iteration:  26881, Training Accuracy:  81.2%, Loss: 0.4094\n",
      "Optimization Iteration:  26945, Training Accuracy:  68.8%, Loss: 0.4616\n",
      "Optimization Iteration:  27009, Training Accuracy:  70.3%, Loss: 0.4001\n",
      "Optimization Iteration:  27073, Training Accuracy:  81.2%, Loss: 0.5141\n",
      "Optimization Iteration:  27137, Training Accuracy:  79.7%, Loss: 0.4114\n",
      "Optimization Iteration:  27201, Training Accuracy:  81.2%, Loss: 0.3260\n",
      "Optimization Iteration:  27265, Training Accuracy:  76.6%, Loss: 0.3917\n",
      "Optimization Iteration:  27329, Training Accuracy:  68.8%, Loss: 0.4334\n",
      "Optimization Iteration:  27393, Training Accuracy:  75.0%, Loss: 0.4230\n",
      "Optimization Iteration:  27457, Training Accuracy:  82.8%, Loss: 0.3747\n",
      "Optimization Iteration:  27521, Training Accuracy:  73.4%, Loss: 0.4128\n",
      "Optimization Iteration:  27585, Training Accuracy:  81.2%, Loss: 0.4237\n",
      "Optimization Iteration:  27649, Training Accuracy:  78.1%, Loss: 0.4127\n",
      "Optimization Iteration:  27713, Training Accuracy:  73.4%, Loss: 0.4616\n",
      "Optimization Iteration:  27777, Training Accuracy:  84.4%, Loss: 0.3505\n",
      "Optimization Iteration:  27841, Training Accuracy:  70.3%, Loss: 0.4928\n",
      "Optimization Iteration:  27905, Training Accuracy:  70.3%, Loss: 0.5065\n",
      "Optimization Iteration:  27969, Training Accuracy:  70.3%, Loss: 0.4800\n",
      "Optimization Iteration:  28033, Training Accuracy:  84.4%, Loss: 0.3625\n",
      "Optimization Iteration:  28097, Training Accuracy:  85.9%, Loss: 0.3140\n",
      "Optimization Iteration:  28161, Training Accuracy:  90.6%, Loss: 0.3352\n",
      "Optimization Iteration:  28225, Training Accuracy:  73.4%, Loss: 0.4537\n",
      "Optimization Iteration:  28289, Training Accuracy:  75.0%, Loss: 0.4109\n",
      "Optimization Iteration:  28353, Training Accuracy:  73.4%, Loss: 0.3750\n",
      "Optimization Iteration:  28417, Training Accuracy:  71.9%, Loss: 0.4278\n",
      "Optimization Iteration:  28481, Training Accuracy:  70.3%, Loss: 0.4108\n",
      "Optimization Iteration:  28545, Training Accuracy:  79.7%, Loss: 0.3578\n",
      "Optimization Iteration:  28609, Training Accuracy:  73.4%, Loss: 0.4320\n",
      "Optimization Iteration:  28673, Training Accuracy:  73.4%, Loss: 0.5125\n",
      "Optimization Iteration:  28737, Training Accuracy:  65.6%, Loss: 0.4497\n",
      "Optimization Iteration:  28801, Training Accuracy:  70.3%, Loss: 0.3881\n",
      "Optimization Iteration:  28865, Training Accuracy:  84.4%, Loss: 0.2977\n",
      "Optimization Iteration:  28929, Training Accuracy:  75.0%, Loss: 0.3690\n",
      "Optimization Iteration:  28993, Training Accuracy:  73.4%, Loss: 0.4216\n",
      "Optimization Iteration:  29057, Training Accuracy:  68.8%, Loss: 0.4147\n",
      "Optimization Iteration:  29121, Training Accuracy:  65.6%, Loss: 0.5388\n",
      "Optimization Iteration:  29185, Training Accuracy:  78.1%, Loss: 0.3858\n",
      "Optimization Iteration:  29249, Training Accuracy:  76.6%, Loss: 0.4027\n",
      "Optimization Iteration:  29313, Training Accuracy:  75.0%, Loss: 0.4332\n",
      "Optimization Iteration:  29377, Training Accuracy:  76.6%, Loss: 0.3660\n",
      "Optimization Iteration:  29441, Training Accuracy:  73.4%, Loss: 0.4800\n",
      "Optimization Iteration:  29505, Training Accuracy:  75.0%, Loss: 0.4074\n",
      "Optimization Iteration:  29569, Training Accuracy:  73.4%, Loss: 0.4898\n",
      "Optimization Iteration:  29633, Training Accuracy:  78.1%, Loss: 0.4016\n",
      "Optimization Iteration:  29697, Training Accuracy:  81.2%, Loss: 0.3394\n",
      "Optimization Iteration:  29761, Training Accuracy:  71.9%, Loss: 0.4544\n",
      "Optimization Iteration:  29825, Training Accuracy:  76.6%, Loss: 0.4289\n",
      "Optimization Iteration:  29889, Training Accuracy:  76.6%, Loss: 0.4553\n",
      "Optimization Iteration:  29953, Training Accuracy:  62.5%, Loss: 0.5110\n",
      "Optimization Iteration:  30017, Training Accuracy:  78.1%, Loss: 0.3400\n",
      "Optimization Iteration:  30081, Training Accuracy:  78.1%, Loss: 0.3891\n",
      "Optimization Iteration:  30145, Training Accuracy:  73.4%, Loss: 0.4496\n",
      "Optimization Iteration:  30209, Training Accuracy:  73.4%, Loss: 0.4050\n",
      "Optimization Iteration:  30273, Training Accuracy:  78.1%, Loss: 0.3279\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.3517\n",
      "Optimization Iteration:  30401, Training Accuracy:  71.9%, Loss: 0.4599\n",
      "Optimization Iteration:  30465, Training Accuracy:  68.8%, Loss: 0.4810\n",
      "Optimization Iteration:  30529, Training Accuracy:  71.9%, Loss: 0.4505\n",
      "Optimization Iteration:  30593, Training Accuracy:  75.0%, Loss: 0.4441\n",
      "Optimization Iteration:  30657, Training Accuracy:  82.8%, Loss: 0.4077\n",
      "Optimization Iteration:  30721, Training Accuracy:  76.6%, Loss: 0.3711\n",
      "Optimization Iteration:  30785, Training Accuracy:  79.7%, Loss: 0.3724\n",
      "Optimization Iteration:  30849, Training Accuracy:  70.3%, Loss: 0.4148\n",
      "Optimization Iteration:  30913, Training Accuracy:  78.1%, Loss: 0.3636\n",
      "Optimization Iteration:  30977, Training Accuracy:  75.0%, Loss: 0.4283\n",
      "Optimization Iteration:  31041, Training Accuracy:  78.1%, Loss: 0.4217\n",
      "Optimization Iteration:  31105, Training Accuracy:  71.9%, Loss: 0.4531\n",
      "Optimization Iteration:  31169, Training Accuracy:  70.3%, Loss: 0.3868\n",
      "Optimization Iteration:  31233, Training Accuracy:  73.4%, Loss: 0.4183\n",
      "Optimization Iteration:  31297, Training Accuracy:  75.0%, Loss: 0.4350\n",
      "Optimization Iteration:  31361, Training Accuracy:  75.0%, Loss: 0.3920\n",
      "Optimization Iteration:  31425, Training Accuracy:  81.2%, Loss: 0.3695\n",
      "Optimization Iteration:  31489, Training Accuracy:  81.2%, Loss: 0.3528\n",
      "Optimization Iteration:  31553, Training Accuracy:  75.0%, Loss: 0.4657\n",
      "Optimization Iteration:  31617, Training Accuracy:  76.6%, Loss: 0.3266\n",
      "Optimization Iteration:  31681, Training Accuracy:  79.7%, Loss: 0.4103\n",
      "Optimization Iteration:  31745, Training Accuracy:  65.6%, Loss: 0.4785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  31809, Training Accuracy:  67.2%, Loss: 0.5192\n",
      "Optimization Iteration:  31873, Training Accuracy:  81.2%, Loss: 0.3557\n",
      "Optimization Iteration:  31937, Training Accuracy:  67.2%, Loss: 0.5523\n",
      "Optimization Iteration:  32001, Training Accuracy:  78.1%, Loss: 0.4248\n",
      "Optimization Iteration:  32065, Training Accuracy:  70.3%, Loss: 0.4340\n",
      "Optimization Iteration:  32129, Training Accuracy:  68.8%, Loss: 0.4626\n",
      "Optimization Iteration:  32193, Training Accuracy:  67.2%, Loss: 0.4436\n",
      "Optimization Iteration:  32257, Training Accuracy:  73.4%, Loss: 0.4947\n",
      "Optimization Iteration:  32321, Training Accuracy:  82.8%, Loss: 0.3877\n",
      "Optimization Iteration:  32385, Training Accuracy:  76.6%, Loss: 0.4293\n",
      "Optimization Iteration:  32449, Training Accuracy:  64.1%, Loss: 0.4906\n",
      "Optimization Iteration:  32513, Training Accuracy:  73.4%, Loss: 0.3826\n",
      "Optimization Iteration:  32577, Training Accuracy:  78.1%, Loss: 0.4101\n",
      "Optimization Iteration:  32641, Training Accuracy:  70.3%, Loss: 0.4594\n",
      "Optimization Iteration:  32705, Training Accuracy:  76.6%, Loss: 0.4049\n",
      "Optimization Iteration:  32769, Training Accuracy:  79.7%, Loss: 0.3957\n",
      "Optimization Iteration:  32833, Training Accuracy:  73.4%, Loss: 0.4126\n",
      "Optimization Iteration:  32897, Training Accuracy:  76.6%, Loss: 0.4347\n",
      "Optimization Iteration:  32961, Training Accuracy:  59.4%, Loss: 0.5349\n",
      "Optimization Iteration:  33025, Training Accuracy:  79.7%, Loss: 0.3595\n",
      "Optimization Iteration:  33089, Training Accuracy:  75.0%, Loss: 0.4658\n",
      "Optimization Iteration:  33153, Training Accuracy:  73.4%, Loss: 0.5198\n",
      "Optimization Iteration:  33217, Training Accuracy:  68.8%, Loss: 0.3807\n",
      "Optimization Iteration:  33281, Training Accuracy:  60.9%, Loss: 0.5379\n",
      "Optimization Iteration:  33345, Training Accuracy:  73.4%, Loss: 0.4982\n",
      "Optimization Iteration:  33409, Training Accuracy:  75.0%, Loss: 0.4400\n",
      "Optimization Iteration:  33473, Training Accuracy:  70.3%, Loss: 0.4915\n",
      "Optimization Iteration:  33537, Training Accuracy:  68.8%, Loss: 0.4159\n",
      "Optimization Iteration:  33601, Training Accuracy:  78.1%, Loss: 0.3993\n",
      "Optimization Iteration:  33665, Training Accuracy:  71.9%, Loss: 0.4280\n",
      "Optimization Iteration:  33729, Training Accuracy:  76.6%, Loss: 0.5360\n",
      "Optimization Iteration:  33793, Training Accuracy:  67.2%, Loss: 0.4776\n",
      "Optimization Iteration:  33857, Training Accuracy:  68.8%, Loss: 0.4493\n",
      "Optimization Iteration:  33921, Training Accuracy:  71.9%, Loss: 0.4345\n",
      "Optimization Iteration:  33985, Training Accuracy:  75.0%, Loss: 0.4536\n",
      "Optimization Iteration:  34049, Training Accuracy:  67.2%, Loss: 0.4855\n",
      "Optimization Iteration:  34113, Training Accuracy:  76.6%, Loss: 0.3822\n",
      "Optimization Iteration:  34177, Training Accuracy:  75.0%, Loss: 0.3730\n",
      "Optimization Iteration:  34241, Training Accuracy:  79.7%, Loss: 0.3333\n",
      "Optimization Iteration:  34305, Training Accuracy:  78.1%, Loss: 0.3720\n",
      "Optimization Iteration:  34369, Training Accuracy:  76.6%, Loss: 0.3733\n",
      "Optimization Iteration:  34433, Training Accuracy:  79.7%, Loss: 0.4099\n",
      "Optimization Iteration:  34497, Training Accuracy:  79.7%, Loss: 0.3539\n",
      "Optimization Iteration:  34561, Training Accuracy:  71.9%, Loss: 0.4095\n",
      "Optimization Iteration:  34625, Training Accuracy:  70.3%, Loss: 0.4524\n",
      "Optimization Iteration:  34689, Training Accuracy:  65.6%, Loss: 0.5493\n",
      "Optimization Iteration:  34753, Training Accuracy:  68.8%, Loss: 0.4230\n",
      "Optimization Iteration:  34817, Training Accuracy:  76.6%, Loss: 0.4182\n",
      "Optimization Iteration:  34881, Training Accuracy:  73.4%, Loss: 0.3847\n",
      "Optimization Iteration:  34945, Training Accuracy:  76.6%, Loss: 0.4354\n",
      "Optimization Iteration:  35009, Training Accuracy:  73.4%, Loss: 0.4640\n",
      "Optimization Iteration:  35073, Training Accuracy:  75.0%, Loss: 0.3872\n",
      "Optimization Iteration:  35137, Training Accuracy:  78.1%, Loss: 0.4245\n",
      "Optimization Iteration:  35201, Training Accuracy:  65.6%, Loss: 0.4173\n",
      "Optimization Iteration:  35265, Training Accuracy:  78.1%, Loss: 0.4025\n",
      "Optimization Iteration:  35329, Training Accuracy:  71.9%, Loss: 0.4458\n",
      "Optimization Iteration:  35393, Training Accuracy:  71.9%, Loss: 0.3907\n",
      "Optimization Iteration:  35457, Training Accuracy:  73.4%, Loss: 0.4330\n",
      "Optimization Iteration:  35521, Training Accuracy:  70.3%, Loss: 0.4132\n",
      "Optimization Iteration:  35585, Training Accuracy:  84.4%, Loss: 0.3746\n",
      "Optimization Iteration:  35649, Training Accuracy:  71.9%, Loss: 0.4534\n",
      "Optimization Iteration:  35713, Training Accuracy:  76.6%, Loss: 0.4496\n",
      "Optimization Iteration:  35777, Training Accuracy:  76.6%, Loss: 0.3474\n",
      "Optimization Iteration:  35841, Training Accuracy:  81.2%, Loss: 0.4037\n",
      "Optimization Iteration:  35905, Training Accuracy:  75.0%, Loss: 0.4043\n",
      "Optimization Iteration:  35969, Training Accuracy:  70.3%, Loss: 0.4148\n",
      "Optimization Iteration:  36033, Training Accuracy:  75.0%, Loss: 0.3926\n",
      "Optimization Iteration:  36097, Training Accuracy:  65.6%, Loss: 0.4730\n",
      "Optimization Iteration:  36161, Training Accuracy:  71.9%, Loss: 0.4046\n",
      "Optimization Iteration:  36225, Training Accuracy:  71.9%, Loss: 0.4313\n",
      "Optimization Iteration:  36289, Training Accuracy:  71.9%, Loss: 0.4290\n",
      "Optimization Iteration:  36353, Training Accuracy:  79.7%, Loss: 0.3236\n",
      "Optimization Iteration:  36417, Training Accuracy:  78.1%, Loss: 0.4364\n",
      "Optimization Iteration:  36481, Training Accuracy:  79.7%, Loss: 0.3830\n",
      "Optimization Iteration:  36545, Training Accuracy:  82.8%, Loss: 0.3453\n",
      "Optimization Iteration:  36609, Training Accuracy:  68.8%, Loss: 0.4138\n",
      "Optimization Iteration:  36673, Training Accuracy:  76.6%, Loss: 0.4121\n",
      "Optimization Iteration:  36737, Training Accuracy:  81.2%, Loss: 0.4050\n",
      "Optimization Iteration:  36801, Training Accuracy:  73.4%, Loss: 0.4100\n",
      "Optimization Iteration:  36865, Training Accuracy:  68.8%, Loss: 0.4597\n",
      "Optimization Iteration:  36929, Training Accuracy:  67.2%, Loss: 0.4741\n",
      "Optimization Iteration:  36993, Training Accuracy:  73.4%, Loss: 0.4450\n",
      "Optimization Iteration:  37057, Training Accuracy:  75.0%, Loss: 0.3979\n",
      "Optimization Iteration:  37121, Training Accuracy:  78.1%, Loss: 0.3734\n",
      "Optimization Iteration:  37185, Training Accuracy:  78.1%, Loss: 0.3765\n",
      "Optimization Iteration:  37249, Training Accuracy:  78.1%, Loss: 0.4786\n",
      "Optimization Iteration:  37313, Training Accuracy:  82.8%, Loss: 0.3535\n",
      "Optimization Iteration:  37377, Training Accuracy:  65.6%, Loss: 0.5931\n",
      "Optimization Iteration:  37441, Training Accuracy:  82.8%, Loss: 0.4150\n",
      "Optimization Iteration:  37505, Training Accuracy:  79.7%, Loss: 0.5219\n",
      "Optimization Iteration:  37569, Training Accuracy:  78.1%, Loss: 0.4859\n",
      "Optimization Iteration:  37633, Training Accuracy:  71.9%, Loss: 0.4816\n",
      "Optimization Iteration:  37697, Training Accuracy:  67.2%, Loss: 0.3744\n",
      "Optimization Iteration:  37761, Training Accuracy:  71.9%, Loss: 0.3807\n",
      "Optimization Iteration:  37825, Training Accuracy:  79.7%, Loss: 0.4037\n",
      "Optimization Iteration:  37889, Training Accuracy:  76.6%, Loss: 0.4019\n",
      "Optimization Iteration:  37953, Training Accuracy:  78.1%, Loss: 0.3771\n",
      "Optimization Iteration:  38017, Training Accuracy:  70.3%, Loss: 0.4271\n",
      "Optimization Iteration:  38081, Training Accuracy:  71.9%, Loss: 0.4013\n",
      "Optimization Iteration:  38145, Training Accuracy:  79.7%, Loss: 0.3292\n",
      "Optimization Iteration:  38209, Training Accuracy:  70.3%, Loss: 0.4512\n",
      "Optimization Iteration:  38273, Training Accuracy:  71.9%, Loss: 0.3744\n",
      "Optimization Iteration:  38337, Training Accuracy:  85.9%, Loss: 0.3161\n",
      "Optimization Iteration:  38401, Training Accuracy:  78.1%, Loss: 0.4126\n",
      "Optimization Iteration:  38465, Training Accuracy:  78.1%, Loss: 0.3740\n",
      "Optimization Iteration:  38529, Training Accuracy:  79.7%, Loss: 0.4709\n",
      "Optimization Iteration:  38593, Training Accuracy:  71.9%, Loss: 0.4393\n",
      "Optimization Iteration:  38657, Training Accuracy:  73.4%, Loss: 0.4345\n",
      "Optimization Iteration:  38721, Training Accuracy:  79.7%, Loss: 0.3867\n",
      "Optimization Iteration:  38785, Training Accuracy:  70.3%, Loss: 0.4509\n",
      "Optimization Iteration:  38849, Training Accuracy:  78.1%, Loss: 0.3852\n",
      "Optimization Iteration:  38913, Training Accuracy:  73.4%, Loss: 0.4198\n",
      "Optimization Iteration:  38977, Training Accuracy:  71.9%, Loss: 0.4957\n",
      "Optimization Iteration:  39041, Training Accuracy:  68.8%, Loss: 0.4597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  39105, Training Accuracy:  76.6%, Loss: 0.4831\n",
      "Optimization Iteration:  39169, Training Accuracy:  67.2%, Loss: 0.4260\n",
      "Optimization Iteration:  39233, Training Accuracy:  71.9%, Loss: 0.4559\n",
      "Optimization Iteration:  39297, Training Accuracy:  76.6%, Loss: 0.3825\n",
      "Optimization Iteration:  39361, Training Accuracy:  75.0%, Loss: 0.3573\n",
      "Optimization Iteration:  39425, Training Accuracy:  75.0%, Loss: 0.4722\n",
      "Optimization Iteration:  39489, Training Accuracy:  79.7%, Loss: 0.3592\n",
      "Optimization Iteration:  39553, Training Accuracy:  73.4%, Loss: 0.3637\n",
      "Optimization Iteration:  39617, Training Accuracy:  73.4%, Loss: 0.4214\n",
      "Optimization Iteration:  39681, Training Accuracy:  76.6%, Loss: 0.3586\n",
      "Optimization Iteration:  39745, Training Accuracy:  68.8%, Loss: 0.5411\n",
      "Optimization Iteration:  39809, Training Accuracy:  67.2%, Loss: 0.4965\n",
      "Optimization Iteration:  39873, Training Accuracy:  75.0%, Loss: 0.4525\n",
      "Optimization Iteration:  39937, Training Accuracy:  68.8%, Loss: 0.5445\n",
      "Optimization Iteration:  40001, Training Accuracy:  71.9%, Loss: 0.4243\n",
      "Optimization Iteration:  40065, Training Accuracy:  73.4%, Loss: 0.3342\n",
      "Optimization Iteration:  40129, Training Accuracy:  68.8%, Loss: 0.4416\n",
      "Optimization Iteration:  40193, Training Accuracy:  76.6%, Loss: 0.3802\n",
      "Optimization Iteration:  40257, Training Accuracy:  75.0%, Loss: 0.4293\n",
      "Optimization Iteration:  40321, Training Accuracy:  70.3%, Loss: 0.4479\n",
      "Optimization Iteration:  40385, Training Accuracy:  78.1%, Loss: 0.4367\n",
      "Optimization Iteration:  40449, Training Accuracy:  78.1%, Loss: 0.3804\n",
      "Optimization Iteration:  40513, Training Accuracy:  78.1%, Loss: 0.3755\n",
      "Optimization Iteration:  40577, Training Accuracy:  73.4%, Loss: 0.4245\n",
      "Optimization Iteration:  40641, Training Accuracy:  75.0%, Loss: 0.3522\n",
      "Optimization Iteration:  40705, Training Accuracy:  67.2%, Loss: 0.4355\n",
      "Optimization Iteration:  40769, Training Accuracy:  81.2%, Loss: 0.3628\n",
      "Optimization Iteration:  40833, Training Accuracy:  85.9%, Loss: 0.3238\n",
      "Optimization Iteration:  40897, Training Accuracy:  76.6%, Loss: 0.3631\n",
      "Optimization Iteration:  40961, Training Accuracy:  84.4%, Loss: 0.3542\n",
      "Optimization Iteration:  41025, Training Accuracy:  82.8%, Loss: 0.3942\n",
      "Optimization Iteration:  41089, Training Accuracy:  79.7%, Loss: 0.4075\n",
      "Optimization Iteration:  41153, Training Accuracy:  76.6%, Loss: 0.4132\n",
      "Optimization Iteration:  41217, Training Accuracy:  78.1%, Loss: 0.3539\n",
      "Optimization Iteration:  41281, Training Accuracy:  65.6%, Loss: 0.4602\n",
      "Optimization Iteration:  41345, Training Accuracy:  71.9%, Loss: 0.4124\n",
      "Optimization Iteration:  41409, Training Accuracy:  68.8%, Loss: 0.4570\n",
      "Optimization Iteration:  41473, Training Accuracy:  78.1%, Loss: 0.3847\n",
      "Optimization Iteration:  41537, Training Accuracy:  73.4%, Loss: 0.4500\n",
      "Optimization Iteration:  41601, Training Accuracy:  75.0%, Loss: 0.4153\n",
      "Optimization Iteration:  41665, Training Accuracy:  73.4%, Loss: 0.3950\n",
      "Optimization Iteration:  41729, Training Accuracy:  75.0%, Loss: 0.3646\n",
      "Optimization Iteration:  41793, Training Accuracy:  73.4%, Loss: 0.4608\n",
      "Optimization Iteration:  41857, Training Accuracy:  76.6%, Loss: 0.4987\n",
      "Optimization Iteration:  41921, Training Accuracy:  73.4%, Loss: 0.4133\n",
      "Optimization Iteration:  41985, Training Accuracy:  68.8%, Loss: 0.4792\n",
      "Optimization Iteration:  42049, Training Accuracy:  82.8%, Loss: 0.3883\n",
      "Optimization Iteration:  42113, Training Accuracy:  79.7%, Loss: 0.4102\n",
      "Optimization Iteration:  42177, Training Accuracy:  68.8%, Loss: 0.5255\n",
      "Optimization Iteration:  42241, Training Accuracy:  76.6%, Loss: 0.4631\n",
      "Optimization Iteration:  42305, Training Accuracy:  73.4%, Loss: 0.4252\n",
      "Optimization Iteration:  42369, Training Accuracy:  70.3%, Loss: 0.4818\n",
      "Optimization Iteration:  42433, Training Accuracy:  65.6%, Loss: 0.4742\n",
      "Optimization Iteration:  42497, Training Accuracy:  67.2%, Loss: 0.4984\n",
      "Optimization Iteration:  42561, Training Accuracy:  81.2%, Loss: 0.3532\n",
      "Optimization Iteration:  42625, Training Accuracy:  73.4%, Loss: 0.3710\n",
      "Optimization Iteration:  42689, Training Accuracy:  71.9%, Loss: 0.3661\n",
      "Optimization Iteration:  42753, Training Accuracy:  73.4%, Loss: 0.4015\n",
      "Optimization Iteration:  42817, Training Accuracy:  81.2%, Loss: 0.3481\n",
      "Optimization Iteration:  42881, Training Accuracy:  73.4%, Loss: 0.4712\n",
      "Optimization Iteration:  42945, Training Accuracy:  75.0%, Loss: 0.4009\n",
      "Optimization Iteration:  43009, Training Accuracy:  64.1%, Loss: 0.4689\n",
      "Optimization Iteration:  43073, Training Accuracy:  76.6%, Loss: 0.3945\n",
      "Optimization Iteration:  43137, Training Accuracy:  73.4%, Loss: 0.4612\n",
      "Optimization Iteration:  43201, Training Accuracy:  73.4%, Loss: 0.4076\n",
      "Optimization Iteration:  43265, Training Accuracy:  73.4%, Loss: 0.4206\n",
      "Optimization Iteration:  43329, Training Accuracy:  76.6%, Loss: 0.4690\n",
      "Optimization Iteration:  43393, Training Accuracy:  70.3%, Loss: 0.4076\n",
      "Optimization Iteration:  43457, Training Accuracy:  75.0%, Loss: 0.3777\n",
      "Optimization Iteration:  43521, Training Accuracy:  78.1%, Loss: 0.4386\n",
      "Optimization Iteration:  43585, Training Accuracy:  71.9%, Loss: 0.4601\n",
      "Optimization Iteration:  43649, Training Accuracy:  79.7%, Loss: 0.4618\n",
      "Optimization Iteration:  43713, Training Accuracy:  71.9%, Loss: 0.4111\n",
      "Optimization Iteration:  43777, Training Accuracy:  76.6%, Loss: 0.3599\n",
      "Optimization Iteration:  43841, Training Accuracy:  76.6%, Loss: 0.4562\n",
      "Optimization Iteration:  43905, Training Accuracy:  73.4%, Loss: 0.4026\n",
      "Optimization Iteration:  43969, Training Accuracy:  73.4%, Loss: 0.3591\n",
      "Optimization Iteration:  44033, Training Accuracy:  62.5%, Loss: 0.5178\n",
      "Optimization Iteration:  44097, Training Accuracy:  76.6%, Loss: 0.3470\n",
      "Optimization Iteration:  44161, Training Accuracy:  70.3%, Loss: 0.4515\n",
      "Optimization Iteration:  44225, Training Accuracy:  75.0%, Loss: 0.3990\n",
      "Optimization Iteration:  44289, Training Accuracy:  75.0%, Loss: 0.4385\n",
      "Optimization Iteration:  44353, Training Accuracy:  73.4%, Loss: 0.4662\n",
      "Optimization Iteration:  44417, Training Accuracy:  75.0%, Loss: 0.3681\n",
      "Optimization Iteration:  44481, Training Accuracy:  71.9%, Loss: 0.4601\n",
      "Optimization Iteration:  44545, Training Accuracy:  79.7%, Loss: 0.3606\n",
      "Optimization Iteration:  44609, Training Accuracy:  81.2%, Loss: 0.4035\n",
      "Optimization Iteration:  44673, Training Accuracy:  79.7%, Loss: 0.5850\n",
      "Optimization Iteration:  44737, Training Accuracy:  78.1%, Loss: 0.3727\n",
      "Optimization Iteration:  44801, Training Accuracy:  71.9%, Loss: 0.4667\n",
      "Optimization Iteration:  44865, Training Accuracy:  73.4%, Loss: 0.4171\n",
      "Optimization Iteration:  44929, Training Accuracy:  79.7%, Loss: 0.4091\n",
      "Optimization Iteration:  44993, Training Accuracy:  81.2%, Loss: 0.3414\n",
      "Optimization Iteration:  45057, Training Accuracy:  68.8%, Loss: 0.5177\n",
      "Optimization Iteration:  45121, Training Accuracy:  81.2%, Loss: 0.3520\n",
      "Optimization Iteration:  45185, Training Accuracy:  79.7%, Loss: 0.3653\n",
      "Optimization Iteration:  45249, Training Accuracy:  73.4%, Loss: 0.4491\n",
      "Optimization Iteration:  45313, Training Accuracy:  75.0%, Loss: 0.4009\n",
      "Optimization Iteration:  45377, Training Accuracy:  73.4%, Loss: 0.4224\n",
      "Optimization Iteration:  45441, Training Accuracy:  78.1%, Loss: 0.4106\n",
      "Optimization Iteration:  45505, Training Accuracy:  76.6%, Loss: 0.3881\n",
      "Optimization Iteration:  45569, Training Accuracy:  65.6%, Loss: 0.5154\n",
      "Optimization Iteration:  45633, Training Accuracy:  73.4%, Loss: 0.4412\n",
      "Optimization Iteration:  45697, Training Accuracy:  76.6%, Loss: 0.3606\n",
      "Optimization Iteration:  45761, Training Accuracy:  78.1%, Loss: 0.3568\n",
      "Optimization Iteration:  45825, Training Accuracy:  75.0%, Loss: 0.3810\n",
      "Optimization Iteration:  45889, Training Accuracy:  82.8%, Loss: 0.3683\n",
      "Optimization Iteration:  45953, Training Accuracy:  76.6%, Loss: 0.4142\n",
      "Optimization Iteration:  46017, Training Accuracy:  78.1%, Loss: 0.4558\n",
      "Optimization Iteration:  46081, Training Accuracy:  76.6%, Loss: 0.3916\n",
      "Optimization Iteration:  46145, Training Accuracy:  73.4%, Loss: 0.4450\n",
      "Optimization Iteration:  46209, Training Accuracy:  79.7%, Loss: 0.3140\n",
      "Optimization Iteration:  46273, Training Accuracy:  73.4%, Loss: 0.4895\n",
      "Optimization Iteration:  46337, Training Accuracy:  76.6%, Loss: 0.4567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  46401, Training Accuracy:  79.7%, Loss: 0.4040\n",
      "Optimization Iteration:  46465, Training Accuracy:  75.0%, Loss: 0.4210\n",
      "Optimization Iteration:  46529, Training Accuracy:  78.1%, Loss: 0.4132\n",
      "Optimization Iteration:  46593, Training Accuracy:  67.2%, Loss: 0.4635\n",
      "Optimization Iteration:  46657, Training Accuracy:  81.2%, Loss: 0.4057\n",
      "Optimization Iteration:  46721, Training Accuracy:  73.4%, Loss: 0.5469\n",
      "Optimization Iteration:  46785, Training Accuracy:  76.6%, Loss: 0.4302\n",
      "Optimization Iteration:  46849, Training Accuracy:  65.6%, Loss: 0.4485\n",
      "Optimization Iteration:  46913, Training Accuracy:  78.1%, Loss: 0.4136\n",
      "Optimization Iteration:  46977, Training Accuracy:  79.7%, Loss: 0.3682\n",
      "Optimization Iteration:  47041, Training Accuracy:  82.8%, Loss: 0.4033\n",
      "Optimization Iteration:  47105, Training Accuracy:  76.6%, Loss: 0.4710\n",
      "Optimization Iteration:  47169, Training Accuracy:  76.6%, Loss: 0.4097\n",
      "Optimization Iteration:  47233, Training Accuracy:  75.0%, Loss: 0.4422\n",
      "Optimization Iteration:  47297, Training Accuracy:  76.6%, Loss: 0.3447\n",
      "Optimization Iteration:  47361, Training Accuracy:  78.1%, Loss: 0.3958\n",
      "Optimization Iteration:  47425, Training Accuracy:  71.9%, Loss: 0.4009\n",
      "Optimization Iteration:  47489, Training Accuracy:  73.4%, Loss: 0.4196\n",
      "Optimization Iteration:  47553, Training Accuracy:  73.4%, Loss: 0.5311\n",
      "Optimization Iteration:  47617, Training Accuracy:  81.2%, Loss: 0.4385\n",
      "Optimization Iteration:  47681, Training Accuracy:  76.6%, Loss: 0.3534\n",
      "Optimization Iteration:  47745, Training Accuracy:  62.5%, Loss: 0.5017\n",
      "Optimization Iteration:  47809, Training Accuracy:  75.0%, Loss: 0.4337\n",
      "Optimization Iteration:  47873, Training Accuracy:  78.1%, Loss: 0.3347\n",
      "Optimization Iteration:  47937, Training Accuracy:  68.8%, Loss: 0.5004\n",
      "Optimization Iteration:  48001, Training Accuracy:  81.2%, Loss: 0.3229\n",
      "Optimization Iteration:  48065, Training Accuracy:  79.7%, Loss: 0.3744\n",
      "Optimization Iteration:  48129, Training Accuracy:  71.9%, Loss: 0.4536\n",
      "Optimization Iteration:  48193, Training Accuracy:  75.0%, Loss: 0.4549\n",
      "Optimization Iteration:  48257, Training Accuracy:  76.6%, Loss: 0.4125\n",
      "Optimization Iteration:  48321, Training Accuracy:  78.1%, Loss: 0.4038\n",
      "Optimization Iteration:  48385, Training Accuracy:  67.2%, Loss: 0.4606\n",
      "Optimization Iteration:  48449, Training Accuracy:  75.0%, Loss: 0.4589\n",
      "Optimization Iteration:  48513, Training Accuracy:  76.6%, Loss: 0.4147\n",
      "Optimization Iteration:  48577, Training Accuracy:  60.9%, Loss: 0.5417\n",
      "Optimization Iteration:  48641, Training Accuracy:  79.7%, Loss: 0.3392\n",
      "Optimization Iteration:  48705, Training Accuracy:  79.7%, Loss: 0.3768\n",
      "Optimization Iteration:  48769, Training Accuracy:  79.7%, Loss: 0.3717\n",
      "Optimization Iteration:  48833, Training Accuracy:  73.4%, Loss: 0.4127\n",
      "Optimization Iteration:  48897, Training Accuracy:  79.7%, Loss: 0.4616\n",
      "Optimization Iteration:  48961, Training Accuracy:  65.6%, Loss: 0.4906\n",
      "Optimization Iteration:  49025, Training Accuracy:  73.4%, Loss: 0.4457\n",
      "Optimization Iteration:  49089, Training Accuracy:  73.4%, Loss: 0.4304\n",
      "Optimization Iteration:  49153, Training Accuracy:  76.6%, Loss: 0.4041\n",
      "Optimization Iteration:  49217, Training Accuracy:  76.6%, Loss: 0.4320\n",
      "Optimization Iteration:  49281, Training Accuracy:  75.0%, Loss: 0.4031\n",
      "Optimization Iteration:  49345, Training Accuracy:  76.6%, Loss: 0.4091\n",
      "Optimization Iteration:  49409, Training Accuracy:  75.0%, Loss: 0.3902\n",
      "Optimization Iteration:  49473, Training Accuracy:  64.1%, Loss: 0.4913\n",
      "Optimization Iteration:  49537, Training Accuracy:  73.4%, Loss: 0.3896\n",
      "Optimization Iteration:  49601, Training Accuracy:  71.9%, Loss: 0.4403\n",
      "Optimization Iteration:  49665, Training Accuracy:  79.7%, Loss: 0.3281\n",
      "Optimization Iteration:  49729, Training Accuracy:  70.3%, Loss: 0.4663\n",
      "Optimization Iteration:  49793, Training Accuracy:  59.4%, Loss: 0.4190\n",
      "Optimization Iteration:  49857, Training Accuracy:  65.6%, Loss: 0.4779\n",
      "Optimization Iteration:  49921, Training Accuracy:  73.4%, Loss: 0.5345\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 9\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  71.9%, Loss: 0.5098\n",
      "Optimization Iteration:    129, Training Accuracy:  73.4%, Loss: 0.4511\n",
      "Optimization Iteration:    193, Training Accuracy:  79.7%, Loss: 0.4360\n",
      "Optimization Iteration:    257, Training Accuracy:  76.6%, Loss: 0.3729\n",
      "Optimization Iteration:    321, Training Accuracy:  70.3%, Loss: 0.4663\n",
      "Optimization Iteration:    385, Training Accuracy:  75.0%, Loss: 0.3436\n",
      "Optimization Iteration:    449, Training Accuracy:  79.7%, Loss: 0.3693\n",
      "Optimization Iteration:    513, Training Accuracy:  71.9%, Loss: 0.4859\n",
      "Optimization Iteration:    577, Training Accuracy:  73.4%, Loss: 0.4080\n",
      "Optimization Iteration:    641, Training Accuracy:  75.0%, Loss: 0.3945\n",
      "Optimization Iteration:    705, Training Accuracy:  60.9%, Loss: 0.4877\n",
      "Optimization Iteration:    769, Training Accuracy:  73.4%, Loss: 0.4155\n",
      "Optimization Iteration:    833, Training Accuracy:  84.4%, Loss: 0.4447\n",
      "Optimization Iteration:    897, Training Accuracy:  84.4%, Loss: 0.3505\n",
      "Optimization Iteration:    961, Training Accuracy:  73.4%, Loss: 0.4152\n",
      "Optimization Iteration:   1025, Training Accuracy:  73.4%, Loss: 0.4304\n",
      "Optimization Iteration:   1089, Training Accuracy:  73.4%, Loss: 0.4844\n",
      "Optimization Iteration:   1153, Training Accuracy:  76.6%, Loss: 0.4108\n",
      "Optimization Iteration:   1217, Training Accuracy:  75.0%, Loss: 0.4326\n",
      "Optimization Iteration:   1281, Training Accuracy:  73.4%, Loss: 0.4132\n",
      "Optimization Iteration:   1345, Training Accuracy:  62.5%, Loss: 0.5259\n",
      "Optimization Iteration:   1409, Training Accuracy:  73.4%, Loss: 0.4193\n",
      "Optimization Iteration:   1473, Training Accuracy:  75.0%, Loss: 0.4281\n",
      "Optimization Iteration:   1537, Training Accuracy:  79.7%, Loss: 0.3937\n",
      "Optimization Iteration:   1601, Training Accuracy:  79.7%, Loss: 0.4143\n",
      "Optimization Iteration:   1665, Training Accuracy:  76.6%, Loss: 0.3866\n",
      "Optimization Iteration:   1729, Training Accuracy:  78.1%, Loss: 0.3581\n",
      "Optimization Iteration:   1793, Training Accuracy:  68.8%, Loss: 0.4140\n",
      "Optimization Iteration:   1857, Training Accuracy:  76.6%, Loss: 0.4515\n",
      "Optimization Iteration:   1921, Training Accuracy:  73.4%, Loss: 0.4634\n",
      "Optimization Iteration:   1985, Training Accuracy:  67.2%, Loss: 0.4739\n",
      "Optimization Iteration:   2049, Training Accuracy:  76.6%, Loss: 0.3954\n",
      "Optimization Iteration:   2113, Training Accuracy:  76.6%, Loss: 0.4037\n",
      "Optimization Iteration:   2177, Training Accuracy:  85.9%, Loss: 0.3029\n",
      "Optimization Iteration:   2241, Training Accuracy:  79.7%, Loss: 0.3413\n",
      "Optimization Iteration:   2305, Training Accuracy:  71.9%, Loss: 0.3853\n",
      "Optimization Iteration:   2369, Training Accuracy:  81.2%, Loss: 0.4069\n",
      "Optimization Iteration:   2433, Training Accuracy:  78.1%, Loss: 0.4286\n",
      "Optimization Iteration:   2497, Training Accuracy:  79.7%, Loss: 0.3660\n",
      "Optimization Iteration:   2561, Training Accuracy:  75.0%, Loss: 0.3988\n",
      "Optimization Iteration:   2625, Training Accuracy:  79.7%, Loss: 0.4109\n",
      "Optimization Iteration:   2689, Training Accuracy:  81.2%, Loss: 0.3608\n",
      "Optimization Iteration:   2753, Training Accuracy:  68.8%, Loss: 0.4007\n",
      "Optimization Iteration:   2817, Training Accuracy:  75.0%, Loss: 0.4039\n",
      "Optimization Iteration:   2881, Training Accuracy:  73.4%, Loss: 0.4467\n",
      "Optimization Iteration:   2945, Training Accuracy:  70.3%, Loss: 0.5241\n",
      "Optimization Iteration:   3009, Training Accuracy:  75.0%, Loss: 0.4645\n",
      "Optimization Iteration:   3073, Training Accuracy:  82.8%, Loss: 0.4031\n",
      "Optimization Iteration:   3137, Training Accuracy:  76.6%, Loss: 0.3615\n",
      "Optimization Iteration:   3201, Training Accuracy:  84.4%, Loss: 0.3614\n",
      "Optimization Iteration:   3265, Training Accuracy:  81.2%, Loss: 0.3499\n",
      "Optimization Iteration:   3329, Training Accuracy:  76.6%, Loss: 0.4892\n",
      "Optimization Iteration:   3393, Training Accuracy:  76.6%, Loss: 0.3712\n",
      "Optimization Iteration:   3457, Training Accuracy:  85.9%, Loss: 0.3376\n",
      "Optimization Iteration:   3521, Training Accuracy:  67.2%, Loss: 0.4485\n",
      "Optimization Iteration:   3585, Training Accuracy:  68.8%, Loss: 0.4360\n",
      "Optimization Iteration:   3649, Training Accuracy:  75.0%, Loss: 0.4101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   3713, Training Accuracy:  68.8%, Loss: 0.4173\n",
      "Optimization Iteration:   3777, Training Accuracy:  67.2%, Loss: 0.5520\n",
      "Optimization Iteration:   3841, Training Accuracy:  65.6%, Loss: 0.4858\n",
      "Optimization Iteration:   3905, Training Accuracy:  81.2%, Loss: 0.4826\n",
      "Optimization Iteration:   3969, Training Accuracy:  73.4%, Loss: 0.4082\n",
      "Optimization Iteration:   4033, Training Accuracy:  81.2%, Loss: 0.2959\n",
      "Optimization Iteration:   4097, Training Accuracy:  71.9%, Loss: 0.4180\n",
      "Optimization Iteration:   4161, Training Accuracy:  71.9%, Loss: 0.5091\n",
      "Optimization Iteration:   4225, Training Accuracy:  79.7%, Loss: 0.3398\n",
      "Optimization Iteration:   4289, Training Accuracy:  68.8%, Loss: 0.4335\n",
      "Optimization Iteration:   4353, Training Accuracy:  78.1%, Loss: 0.4018\n",
      "Optimization Iteration:   4417, Training Accuracy:  75.0%, Loss: 0.4336\n",
      "Optimization Iteration:   4481, Training Accuracy:  73.4%, Loss: 0.4254\n",
      "Optimization Iteration:   4545, Training Accuracy:  73.4%, Loss: 0.3873\n",
      "Optimization Iteration:   4609, Training Accuracy:  78.1%, Loss: 0.3762\n",
      "Optimization Iteration:   4673, Training Accuracy:  70.3%, Loss: 0.4883\n",
      "Optimization Iteration:   4737, Training Accuracy:  71.9%, Loss: 0.4030\n",
      "Optimization Iteration:   4801, Training Accuracy:  65.6%, Loss: 0.4905\n",
      "Optimization Iteration:   4865, Training Accuracy:  67.2%, Loss: 0.4741\n",
      "Optimization Iteration:   4929, Training Accuracy:  81.2%, Loss: 0.4324\n",
      "Optimization Iteration:   4993, Training Accuracy:  76.6%, Loss: 0.3514\n",
      "Optimization Iteration:   5057, Training Accuracy:  67.2%, Loss: 0.4988\n",
      "Optimization Iteration:   5121, Training Accuracy:  81.2%, Loss: 0.3353\n",
      "Optimization Iteration:   5185, Training Accuracy:  79.7%, Loss: 0.4950\n",
      "Optimization Iteration:   5249, Training Accuracy:  59.4%, Loss: 0.5193\n",
      "Optimization Iteration:   5313, Training Accuracy:  79.7%, Loss: 0.4087\n",
      "Optimization Iteration:   5377, Training Accuracy:  70.3%, Loss: 0.4131\n",
      "Optimization Iteration:   5441, Training Accuracy:  71.9%, Loss: 0.4381\n",
      "Optimization Iteration:   5505, Training Accuracy:  79.7%, Loss: 0.3820\n",
      "Optimization Iteration:   5569, Training Accuracy:  73.4%, Loss: 0.3774\n",
      "Optimization Iteration:   5633, Training Accuracy:  65.6%, Loss: 0.4267\n",
      "Optimization Iteration:   5697, Training Accuracy:  73.4%, Loss: 0.4020\n",
      "Optimization Iteration:   5761, Training Accuracy:  79.7%, Loss: 0.3555\n",
      "Optimization Iteration:   5825, Training Accuracy:  65.6%, Loss: 0.5346\n",
      "Optimization Iteration:   5889, Training Accuracy:  79.7%, Loss: 0.4140\n",
      "Optimization Iteration:   5953, Training Accuracy:  79.7%, Loss: 0.4087\n",
      "Optimization Iteration:   6017, Training Accuracy:  56.2%, Loss: 0.6156\n",
      "Optimization Iteration:   6081, Training Accuracy:  81.2%, Loss: 0.3266\n",
      "Optimization Iteration:   6145, Training Accuracy:  60.9%, Loss: 0.5291\n",
      "Optimization Iteration:   6209, Training Accuracy:  75.0%, Loss: 0.4337\n",
      "Optimization Iteration:   6273, Training Accuracy:  89.1%, Loss: 0.3666\n",
      "Optimization Iteration:   6337, Training Accuracy:  73.4%, Loss: 0.4115\n",
      "Optimization Iteration:   6401, Training Accuracy:  85.9%, Loss: 0.4087\n",
      "Optimization Iteration:   6465, Training Accuracy:  84.4%, Loss: 0.3173\n",
      "Optimization Iteration:   6529, Training Accuracy:  79.7%, Loss: 0.3733\n",
      "Optimization Iteration:   6593, Training Accuracy:  81.2%, Loss: 0.4073\n",
      "Optimization Iteration:   6657, Training Accuracy:  70.3%, Loss: 0.4406\n",
      "Optimization Iteration:   6721, Training Accuracy:  78.1%, Loss: 0.3858\n",
      "Optimization Iteration:   6785, Training Accuracy:  71.9%, Loss: 0.4203\n",
      "Optimization Iteration:   6849, Training Accuracy:  76.6%, Loss: 0.4317\n",
      "Optimization Iteration:   6913, Training Accuracy:  82.8%, Loss: 0.3676\n",
      "Optimization Iteration:   6977, Training Accuracy:  82.8%, Loss: 0.4270\n",
      "Optimization Iteration:   7041, Training Accuracy:  79.7%, Loss: 0.3777\n",
      "Optimization Iteration:   7105, Training Accuracy:  75.0%, Loss: 0.3572\n",
      "Optimization Iteration:   7169, Training Accuracy:  73.4%, Loss: 0.4346\n",
      "Optimization Iteration:   7233, Training Accuracy:  70.3%, Loss: 0.4988\n",
      "Optimization Iteration:   7297, Training Accuracy:  70.3%, Loss: 0.4694\n",
      "Optimization Iteration:   7361, Training Accuracy:  75.0%, Loss: 0.3775\n",
      "Optimization Iteration:   7425, Training Accuracy:  73.4%, Loss: 0.4334\n",
      "Optimization Iteration:   7489, Training Accuracy:  68.8%, Loss: 0.4981\n",
      "Optimization Iteration:   7553, Training Accuracy:  76.6%, Loss: 0.5284\n",
      "Optimization Iteration:   7617, Training Accuracy:  70.3%, Loss: 0.4457\n",
      "Optimization Iteration:   7681, Training Accuracy:  79.7%, Loss: 0.4056\n",
      "Optimization Iteration:   7745, Training Accuracy:  81.2%, Loss: 0.3412\n",
      "Optimization Iteration:   7809, Training Accuracy:  76.6%, Loss: 0.4622\n",
      "Optimization Iteration:   7873, Training Accuracy:  78.1%, Loss: 0.3500\n",
      "Optimization Iteration:   7937, Training Accuracy:  79.7%, Loss: 0.4030\n",
      "Optimization Iteration:   8001, Training Accuracy:  78.1%, Loss: 0.4014\n",
      "Optimization Iteration:   8065, Training Accuracy:  75.0%, Loss: 0.3803\n",
      "Optimization Iteration:   8129, Training Accuracy:  79.7%, Loss: 0.4157\n",
      "Optimization Iteration:   8193, Training Accuracy:  70.3%, Loss: 0.4447\n",
      "Optimization Iteration:   8257, Training Accuracy:  73.4%, Loss: 0.4532\n",
      "Optimization Iteration:   8321, Training Accuracy:  73.4%, Loss: 0.4542\n",
      "Optimization Iteration:   8385, Training Accuracy:  64.1%, Loss: 0.5263\n",
      "Optimization Iteration:   8449, Training Accuracy:  70.3%, Loss: 0.5124\n",
      "Optimization Iteration:   8513, Training Accuracy:  84.4%, Loss: 0.3475\n",
      "Optimization Iteration:   8577, Training Accuracy:  70.3%, Loss: 0.5095\n",
      "Optimization Iteration:   8641, Training Accuracy:  78.1%, Loss: 0.3934\n",
      "Optimization Iteration:   8705, Training Accuracy:  79.7%, Loss: 0.3807\n",
      "Optimization Iteration:   8769, Training Accuracy:  65.6%, Loss: 0.4351\n",
      "Optimization Iteration:   8833, Training Accuracy:  70.3%, Loss: 0.5066\n",
      "Optimization Iteration:   8897, Training Accuracy:  76.6%, Loss: 0.4225\n",
      "Optimization Iteration:   8961, Training Accuracy:  68.8%, Loss: 0.4814\n",
      "Optimization Iteration:   9025, Training Accuracy:  68.8%, Loss: 0.4928\n",
      "Optimization Iteration:   9089, Training Accuracy:  64.1%, Loss: 0.5264\n",
      "Optimization Iteration:   9153, Training Accuracy:  78.1%, Loss: 0.3815\n",
      "Optimization Iteration:   9217, Training Accuracy:  71.9%, Loss: 0.4083\n",
      "Optimization Iteration:   9281, Training Accuracy:  75.0%, Loss: 0.3931\n",
      "Optimization Iteration:   9345, Training Accuracy:  79.7%, Loss: 0.4224\n",
      "Optimization Iteration:   9409, Training Accuracy:  75.0%, Loss: 0.4517\n",
      "Optimization Iteration:   9473, Training Accuracy:  81.2%, Loss: 0.4150\n",
      "Optimization Iteration:   9537, Training Accuracy:  71.9%, Loss: 0.4310\n",
      "Optimization Iteration:   9601, Training Accuracy:  81.2%, Loss: 0.3518\n",
      "Optimization Iteration:   9665, Training Accuracy:  62.5%, Loss: 0.4313\n",
      "Optimization Iteration:   9729, Training Accuracy:  76.6%, Loss: 0.3855\n",
      "Optimization Iteration:   9793, Training Accuracy:  75.0%, Loss: 0.4012\n",
      "Optimization Iteration:   9857, Training Accuracy:  78.1%, Loss: 0.4005\n",
      "Optimization Iteration:   9921, Training Accuracy:  79.7%, Loss: 0.3820\n",
      "Optimization Iteration:   9985, Training Accuracy:  78.1%, Loss: 0.4138\n",
      "Optimization Iteration:  10049, Training Accuracy:  73.4%, Loss: 0.4465\n",
      "Optimization Iteration:  10113, Training Accuracy:  68.8%, Loss: 0.4682\n",
      "Optimization Iteration:  10177, Training Accuracy:  78.1%, Loss: 0.5251\n",
      "Optimization Iteration:  10241, Training Accuracy:  73.4%, Loss: 0.4241\n",
      "Optimization Iteration:  10305, Training Accuracy:  89.1%, Loss: 0.3130\n",
      "Optimization Iteration:  10369, Training Accuracy:  78.1%, Loss: 0.3924\n",
      "Optimization Iteration:  10433, Training Accuracy:  76.6%, Loss: 0.4127\n",
      "Optimization Iteration:  10497, Training Accuracy:  71.9%, Loss: 0.4733\n",
      "Optimization Iteration:  10561, Training Accuracy:  84.4%, Loss: 0.3572\n",
      "Optimization Iteration:  10625, Training Accuracy:  81.2%, Loss: 0.3757\n",
      "Optimization Iteration:  10689, Training Accuracy:  71.9%, Loss: 0.4025\n",
      "Optimization Iteration:  10753, Training Accuracy:  68.8%, Loss: 0.4646\n",
      "Optimization Iteration:  10817, Training Accuracy:  73.4%, Loss: 0.4312\n",
      "Optimization Iteration:  10881, Training Accuracy:  76.6%, Loss: 0.3636\n",
      "Optimization Iteration:  10945, Training Accuracy:  71.9%, Loss: 0.4493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  11009, Training Accuracy:  82.8%, Loss: 0.3360\n",
      "Optimization Iteration:  11073, Training Accuracy:  84.4%, Loss: 0.3654\n",
      "Optimization Iteration:  11137, Training Accuracy:  73.4%, Loss: 0.3785\n",
      "Optimization Iteration:  11201, Training Accuracy:  78.1%, Loss: 0.4531\n",
      "Optimization Iteration:  11265, Training Accuracy:  75.0%, Loss: 0.3921\n",
      "Optimization Iteration:  11329, Training Accuracy:  75.0%, Loss: 0.5304\n",
      "Optimization Iteration:  11393, Training Accuracy:  81.2%, Loss: 0.3659\n",
      "Optimization Iteration:  11457, Training Accuracy:  75.0%, Loss: 0.4407\n",
      "Optimization Iteration:  11521, Training Accuracy:  75.0%, Loss: 0.4397\n",
      "Optimization Iteration:  11585, Training Accuracy:  70.3%, Loss: 0.4232\n",
      "Optimization Iteration:  11649, Training Accuracy:  60.9%, Loss: 0.5213\n",
      "Optimization Iteration:  11713, Training Accuracy:  79.7%, Loss: 0.3413\n",
      "Optimization Iteration:  11777, Training Accuracy:  73.4%, Loss: 0.5238\n",
      "Optimization Iteration:  11841, Training Accuracy:  78.1%, Loss: 0.4931\n",
      "Optimization Iteration:  11905, Training Accuracy:  73.4%, Loss: 0.3697\n",
      "Optimization Iteration:  11969, Training Accuracy:  78.1%, Loss: 0.3692\n",
      "Optimization Iteration:  12033, Training Accuracy:  76.6%, Loss: 0.4189\n",
      "Optimization Iteration:  12097, Training Accuracy:  75.0%, Loss: 0.4013\n",
      "Optimization Iteration:  12161, Training Accuracy:  73.4%, Loss: 0.5980\n",
      "Optimization Iteration:  12225, Training Accuracy:  82.8%, Loss: 0.3629\n",
      "Optimization Iteration:  12289, Training Accuracy:  73.4%, Loss: 0.3678\n",
      "Optimization Iteration:  12353, Training Accuracy:  89.1%, Loss: 0.3262\n",
      "Optimization Iteration:  12417, Training Accuracy:  78.1%, Loss: 0.4094\n",
      "Optimization Iteration:  12481, Training Accuracy:  78.1%, Loss: 0.3854\n",
      "Optimization Iteration:  12545, Training Accuracy:  71.9%, Loss: 0.4823\n",
      "Optimization Iteration:  12609, Training Accuracy:  76.6%, Loss: 0.3415\n",
      "Optimization Iteration:  12673, Training Accuracy:  70.3%, Loss: 0.3760\n",
      "Optimization Iteration:  12737, Training Accuracy:  68.8%, Loss: 0.4864\n",
      "Optimization Iteration:  12801, Training Accuracy:  68.8%, Loss: 0.4684\n",
      "Optimization Iteration:  12865, Training Accuracy:  73.4%, Loss: 0.4578\n",
      "Optimization Iteration:  12929, Training Accuracy:  71.9%, Loss: 0.4388\n",
      "Optimization Iteration:  12993, Training Accuracy:  78.1%, Loss: 0.3627\n",
      "Optimization Iteration:  13057, Training Accuracy:  64.1%, Loss: 0.4659\n",
      "Optimization Iteration:  13121, Training Accuracy:  67.2%, Loss: 0.4570\n",
      "Optimization Iteration:  13185, Training Accuracy:  76.6%, Loss: 0.3905\n",
      "Optimization Iteration:  13249, Training Accuracy:  71.9%, Loss: 0.4621\n",
      "Optimization Iteration:  13313, Training Accuracy:  70.3%, Loss: 0.5359\n",
      "Optimization Iteration:  13377, Training Accuracy:  81.2%, Loss: 0.4346\n",
      "Optimization Iteration:  13441, Training Accuracy:  73.4%, Loss: 0.4228\n",
      "Optimization Iteration:  13505, Training Accuracy:  76.6%, Loss: 0.3860\n",
      "Optimization Iteration:  13569, Training Accuracy:  76.6%, Loss: 0.3517\n",
      "Optimization Iteration:  13633, Training Accuracy:  75.0%, Loss: 0.3881\n",
      "Optimization Iteration:  13697, Training Accuracy:  84.4%, Loss: 0.3792\n",
      "Optimization Iteration:  13761, Training Accuracy:  76.6%, Loss: 0.4239\n",
      "Optimization Iteration:  13825, Training Accuracy:  71.9%, Loss: 0.5112\n",
      "Optimization Iteration:  13889, Training Accuracy:  75.0%, Loss: 0.5534\n",
      "Optimization Iteration:  13953, Training Accuracy:  84.4%, Loss: 0.3654\n",
      "Optimization Iteration:  14017, Training Accuracy:  75.0%, Loss: 0.3783\n",
      "Optimization Iteration:  14081, Training Accuracy:  68.8%, Loss: 0.3908\n",
      "Optimization Iteration:  14145, Training Accuracy:  82.8%, Loss: 0.3606\n",
      "Optimization Iteration:  14209, Training Accuracy:  68.8%, Loss: 0.4823\n",
      "Optimization Iteration:  14273, Training Accuracy:  76.6%, Loss: 0.5275\n",
      "Optimization Iteration:  14337, Training Accuracy:  75.0%, Loss: 0.4336\n",
      "Optimization Iteration:  14401, Training Accuracy:  73.4%, Loss: 0.4426\n",
      "Optimization Iteration:  14465, Training Accuracy:  71.9%, Loss: 0.4500\n",
      "Optimization Iteration:  14529, Training Accuracy:  71.9%, Loss: 0.5155\n",
      "Optimization Iteration:  14593, Training Accuracy:  81.2%, Loss: 0.3929\n",
      "Optimization Iteration:  14657, Training Accuracy:  73.4%, Loss: 0.4278\n",
      "Optimization Iteration:  14721, Training Accuracy:  79.7%, Loss: 0.3641\n",
      "Optimization Iteration:  14785, Training Accuracy:  71.9%, Loss: 0.4709\n",
      "Optimization Iteration:  14849, Training Accuracy:  71.9%, Loss: 0.4659\n",
      "Optimization Iteration:  14913, Training Accuracy:  82.8%, Loss: 0.3287\n",
      "Optimization Iteration:  14977, Training Accuracy:  70.3%, Loss: 0.4520\n",
      "Optimization Iteration:  15041, Training Accuracy:  75.0%, Loss: 0.4264\n",
      "Optimization Iteration:  15105, Training Accuracy:  75.0%, Loss: 0.4162\n",
      "Optimization Iteration:  15169, Training Accuracy:  64.1%, Loss: 0.4476\n",
      "Optimization Iteration:  15233, Training Accuracy:  84.4%, Loss: 0.3746\n",
      "Optimization Iteration:  15297, Training Accuracy:  75.0%, Loss: 0.4688\n",
      "Optimization Iteration:  15361, Training Accuracy:  78.1%, Loss: 0.4877\n",
      "Optimization Iteration:  15425, Training Accuracy:  75.0%, Loss: 0.4310\n",
      "Optimization Iteration:  15489, Training Accuracy:  68.8%, Loss: 0.4607\n",
      "Optimization Iteration:  15553, Training Accuracy:  78.1%, Loss: 0.3451\n",
      "Optimization Iteration:  15617, Training Accuracy:  71.9%, Loss: 0.3874\n",
      "Optimization Iteration:  15681, Training Accuracy:  73.4%, Loss: 0.3623\n",
      "Optimization Iteration:  15745, Training Accuracy:  79.7%, Loss: 0.3080\n",
      "Optimization Iteration:  15809, Training Accuracy:  70.3%, Loss: 0.4266\n",
      "Optimization Iteration:  15873, Training Accuracy:  64.1%, Loss: 0.4685\n",
      "Optimization Iteration:  15937, Training Accuracy:  78.1%, Loss: 0.3586\n",
      "Optimization Iteration:  16001, Training Accuracy:  62.5%, Loss: 0.5048\n",
      "Optimization Iteration:  16065, Training Accuracy:  62.5%, Loss: 0.5386\n",
      "Optimization Iteration:  16129, Training Accuracy:  71.9%, Loss: 0.4230\n",
      "Optimization Iteration:  16193, Training Accuracy:  68.8%, Loss: 0.4715\n",
      "Optimization Iteration:  16257, Training Accuracy:  82.8%, Loss: 0.4071\n",
      "Optimization Iteration:  16321, Training Accuracy:  71.9%, Loss: 0.4744\n",
      "Optimization Iteration:  16385, Training Accuracy:  79.7%, Loss: 0.4586\n",
      "Optimization Iteration:  16449, Training Accuracy:  67.2%, Loss: 0.4265\n",
      "Optimization Iteration:  16513, Training Accuracy:  71.9%, Loss: 0.4635\n",
      "Optimization Iteration:  16577, Training Accuracy:  75.0%, Loss: 0.3791\n",
      "Optimization Iteration:  16641, Training Accuracy:  67.2%, Loss: 0.5133\n",
      "Optimization Iteration:  16705, Training Accuracy:  75.0%, Loss: 0.4254\n",
      "Optimization Iteration:  16769, Training Accuracy:  81.2%, Loss: 0.3817\n",
      "Optimization Iteration:  16833, Training Accuracy:  65.6%, Loss: 0.4773\n",
      "Optimization Iteration:  16897, Training Accuracy:  75.0%, Loss: 0.3819\n",
      "Optimization Iteration:  16961, Training Accuracy:  71.9%, Loss: 0.4202\n",
      "Optimization Iteration:  17025, Training Accuracy:  73.4%, Loss: 0.4328\n",
      "Optimization Iteration:  17089, Training Accuracy:  75.0%, Loss: 0.4367\n",
      "Optimization Iteration:  17153, Training Accuracy:  68.8%, Loss: 0.4647\n",
      "Optimization Iteration:  17217, Training Accuracy:  67.2%, Loss: 0.5007\n",
      "Optimization Iteration:  17281, Training Accuracy:  71.9%, Loss: 0.4161\n",
      "Optimization Iteration:  17345, Training Accuracy:  76.6%, Loss: 0.3338\n",
      "Optimization Iteration:  17409, Training Accuracy:  78.1%, Loss: 0.3267\n",
      "Optimization Iteration:  17473, Training Accuracy:  64.1%, Loss: 0.4708\n",
      "Optimization Iteration:  17537, Training Accuracy:  78.1%, Loss: 0.3548\n",
      "Optimization Iteration:  17601, Training Accuracy:  65.6%, Loss: 0.4738\n",
      "Optimization Iteration:  17665, Training Accuracy:  76.6%, Loss: 0.4422\n",
      "Optimization Iteration:  17729, Training Accuracy:  73.4%, Loss: 0.3940\n",
      "Optimization Iteration:  17793, Training Accuracy:  73.4%, Loss: 0.4251\n",
      "Optimization Iteration:  17857, Training Accuracy:  62.5%, Loss: 0.5974\n",
      "Optimization Iteration:  17921, Training Accuracy:  76.6%, Loss: 0.3536\n",
      "Optimization Iteration:  17985, Training Accuracy:  75.0%, Loss: 0.3653\n",
      "Optimization Iteration:  18049, Training Accuracy:  78.1%, Loss: 0.3830\n",
      "Optimization Iteration:  18113, Training Accuracy:  70.3%, Loss: 0.4856\n",
      "Optimization Iteration:  18177, Training Accuracy:  78.1%, Loss: 0.4886\n",
      "Optimization Iteration:  18241, Training Accuracy:  78.1%, Loss: 0.4128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  18305, Training Accuracy:  68.8%, Loss: 0.4488\n",
      "Optimization Iteration:  18369, Training Accuracy:  84.4%, Loss: 0.3464\n",
      "Optimization Iteration:  18433, Training Accuracy:  62.5%, Loss: 0.4799\n",
      "Optimization Iteration:  18497, Training Accuracy:  76.6%, Loss: 0.3528\n",
      "Optimization Iteration:  18561, Training Accuracy:  76.6%, Loss: 0.3854\n",
      "Optimization Iteration:  18625, Training Accuracy:  67.2%, Loss: 0.4935\n",
      "Optimization Iteration:  18689, Training Accuracy:  70.3%, Loss: 0.4852\n",
      "Optimization Iteration:  18753, Training Accuracy:  78.1%, Loss: 0.3843\n",
      "Optimization Iteration:  18817, Training Accuracy:  82.8%, Loss: 0.3807\n",
      "Optimization Iteration:  18881, Training Accuracy:  68.8%, Loss: 0.4188\n",
      "Optimization Iteration:  18945, Training Accuracy:  73.4%, Loss: 0.4952\n",
      "Optimization Iteration:  19009, Training Accuracy:  84.4%, Loss: 0.3420\n",
      "Optimization Iteration:  19073, Training Accuracy:  73.4%, Loss: 0.4781\n",
      "Optimization Iteration:  19137, Training Accuracy:  68.8%, Loss: 0.5027\n",
      "Optimization Iteration:  19201, Training Accuracy:  78.1%, Loss: 0.3897\n",
      "Optimization Iteration:  19265, Training Accuracy:  82.8%, Loss: 0.4078\n",
      "Optimization Iteration:  19329, Training Accuracy:  81.2%, Loss: 0.3179\n",
      "Optimization Iteration:  19393, Training Accuracy:  67.2%, Loss: 0.4387\n",
      "Optimization Iteration:  19457, Training Accuracy:  76.6%, Loss: 0.4219\n",
      "Optimization Iteration:  19521, Training Accuracy:  82.8%, Loss: 0.3832\n",
      "Optimization Iteration:  19585, Training Accuracy:  73.4%, Loss: 0.4709\n",
      "Optimization Iteration:  19649, Training Accuracy:  75.0%, Loss: 0.4641\n",
      "Optimization Iteration:  19713, Training Accuracy:  76.6%, Loss: 0.3841\n",
      "Optimization Iteration:  19777, Training Accuracy:  67.2%, Loss: 0.4295\n",
      "Optimization Iteration:  19841, Training Accuracy:  73.4%, Loss: 0.4576\n",
      "Optimization Iteration:  19905, Training Accuracy:  68.8%, Loss: 0.4594\n",
      "Optimization Iteration:  19969, Training Accuracy:  73.4%, Loss: 0.3857\n",
      "Optimization Iteration:  20033, Training Accuracy:  76.6%, Loss: 0.4419\n",
      "Optimization Iteration:  20097, Training Accuracy:  71.9%, Loss: 0.4411\n",
      "Optimization Iteration:  20161, Training Accuracy:  70.3%, Loss: 0.4320\n",
      "Optimization Iteration:  20225, Training Accuracy:  70.3%, Loss: 0.5175\n",
      "Optimization Iteration:  20289, Training Accuracy:  71.9%, Loss: 0.4344\n",
      "Optimization Iteration:  20353, Training Accuracy:  76.6%, Loss: 0.4014\n",
      "Optimization Iteration:  20417, Training Accuracy:  75.0%, Loss: 0.4182\n",
      "Optimization Iteration:  20481, Training Accuracy:  76.6%, Loss: 0.3616\n",
      "Optimization Iteration:  20545, Training Accuracy:  71.9%, Loss: 0.4296\n",
      "Optimization Iteration:  20609, Training Accuracy:  71.9%, Loss: 0.4984\n",
      "Optimization Iteration:  20673, Training Accuracy:  76.6%, Loss: 0.4103\n",
      "Optimization Iteration:  20737, Training Accuracy:  79.7%, Loss: 0.3860\n",
      "Optimization Iteration:  20801, Training Accuracy:  75.0%, Loss: 0.4088\n",
      "Optimization Iteration:  20865, Training Accuracy:  79.7%, Loss: 0.3673\n",
      "Optimization Iteration:  20929, Training Accuracy:  84.4%, Loss: 0.4458\n",
      "Optimization Iteration:  20993, Training Accuracy:  79.7%, Loss: 0.3938\n",
      "Optimization Iteration:  21057, Training Accuracy:  68.8%, Loss: 0.4466\n",
      "Optimization Iteration:  21121, Training Accuracy:  67.2%, Loss: 0.4235\n",
      "Optimization Iteration:  21185, Training Accuracy:  73.4%, Loss: 0.4486\n",
      "Optimization Iteration:  21249, Training Accuracy:  68.8%, Loss: 0.6167\n",
      "Optimization Iteration:  21313, Training Accuracy:  78.1%, Loss: 0.4466\n",
      "Optimization Iteration:  21377, Training Accuracy:  81.2%, Loss: 0.3240\n",
      "Optimization Iteration:  21441, Training Accuracy:  71.9%, Loss: 0.4461\n",
      "Optimization Iteration:  21505, Training Accuracy:  75.0%, Loss: 0.4570\n",
      "Optimization Iteration:  21569, Training Accuracy:  75.0%, Loss: 0.3513\n",
      "Optimization Iteration:  21633, Training Accuracy:  87.5%, Loss: 0.2850\n",
      "Optimization Iteration:  21697, Training Accuracy:  70.3%, Loss: 0.5653\n",
      "Optimization Iteration:  21761, Training Accuracy:  79.7%, Loss: 0.3458\n",
      "Optimization Iteration:  21825, Training Accuracy:  73.4%, Loss: 0.4850\n",
      "Optimization Iteration:  21889, Training Accuracy:  78.1%, Loss: 0.4148\n",
      "Optimization Iteration:  21953, Training Accuracy:  81.2%, Loss: 0.5109\n",
      "Optimization Iteration:  22017, Training Accuracy:  81.2%, Loss: 0.3722\n",
      "Optimization Iteration:  22081, Training Accuracy:  79.7%, Loss: 0.3833\n",
      "Optimization Iteration:  22145, Training Accuracy:  79.7%, Loss: 0.4291\n",
      "Optimization Iteration:  22209, Training Accuracy:  62.5%, Loss: 0.5552\n",
      "Optimization Iteration:  22273, Training Accuracy:  73.4%, Loss: 0.4082\n",
      "Optimization Iteration:  22337, Training Accuracy:  76.6%, Loss: 0.3882\n",
      "Optimization Iteration:  22401, Training Accuracy:  78.1%, Loss: 0.3859\n",
      "Optimization Iteration:  22465, Training Accuracy:  73.4%, Loss: 0.4434\n",
      "Optimization Iteration:  22529, Training Accuracy:  71.9%, Loss: 0.3965\n",
      "Optimization Iteration:  22593, Training Accuracy:  62.5%, Loss: 0.5184\n",
      "Optimization Iteration:  22657, Training Accuracy:  82.8%, Loss: 0.3420\n",
      "Optimization Iteration:  22721, Training Accuracy:  65.6%, Loss: 0.4518\n",
      "Optimization Iteration:  22785, Training Accuracy:  70.3%, Loss: 0.4776\n",
      "Optimization Iteration:  22849, Training Accuracy:  73.4%, Loss: 0.3740\n",
      "Optimization Iteration:  22913, Training Accuracy:  71.9%, Loss: 0.4037\n",
      "Optimization Iteration:  22977, Training Accuracy:  75.0%, Loss: 0.3865\n",
      "Optimization Iteration:  23041, Training Accuracy:  71.9%, Loss: 0.3555\n",
      "Optimization Iteration:  23105, Training Accuracy:  62.5%, Loss: 0.4424\n",
      "Optimization Iteration:  23169, Training Accuracy:  79.7%, Loss: 0.3503\n",
      "Optimization Iteration:  23233, Training Accuracy:  71.9%, Loss: 0.4907\n",
      "Optimization Iteration:  23297, Training Accuracy:  75.0%, Loss: 0.4217\n",
      "Optimization Iteration:  23361, Training Accuracy:  73.4%, Loss: 0.4549\n",
      "Optimization Iteration:  23425, Training Accuracy:  82.8%, Loss: 0.4053\n",
      "Optimization Iteration:  23489, Training Accuracy:  76.6%, Loss: 0.4635\n",
      "Optimization Iteration:  23553, Training Accuracy:  76.6%, Loss: 0.3483\n",
      "Optimization Iteration:  23617, Training Accuracy:  76.6%, Loss: 0.4467\n",
      "Optimization Iteration:  23681, Training Accuracy:  71.9%, Loss: 0.4671\n",
      "Optimization Iteration:  23745, Training Accuracy:  73.4%, Loss: 0.3904\n",
      "Optimization Iteration:  23809, Training Accuracy:  67.2%, Loss: 0.4710\n",
      "Optimization Iteration:  23873, Training Accuracy:  73.4%, Loss: 0.4113\n",
      "Optimization Iteration:  23937, Training Accuracy:  70.3%, Loss: 0.4500\n",
      "Optimization Iteration:  24001, Training Accuracy:  75.0%, Loss: 0.3829\n",
      "Optimization Iteration:  24065, Training Accuracy:  71.9%, Loss: 0.4036\n",
      "Optimization Iteration:  24129, Training Accuracy:  70.3%, Loss: 0.3987\n",
      "Optimization Iteration:  24193, Training Accuracy:  76.6%, Loss: 0.4646\n",
      "Optimization Iteration:  24257, Training Accuracy:  68.8%, Loss: 0.4469\n",
      "Optimization Iteration:  24321, Training Accuracy:  67.2%, Loss: 0.4470\n",
      "Optimization Iteration:  24385, Training Accuracy:  79.7%, Loss: 0.4223\n",
      "Optimization Iteration:  24449, Training Accuracy:  79.7%, Loss: 0.4004\n",
      "Optimization Iteration:  24513, Training Accuracy:  81.2%, Loss: 0.4020\n",
      "Optimization Iteration:  24577, Training Accuracy:  65.6%, Loss: 0.5612\n",
      "Optimization Iteration:  24641, Training Accuracy:  64.1%, Loss: 0.5391\n",
      "Optimization Iteration:  24705, Training Accuracy:  76.6%, Loss: 0.3699\n",
      "Optimization Iteration:  24769, Training Accuracy:  68.8%, Loss: 0.4007\n",
      "Optimization Iteration:  24833, Training Accuracy:  76.6%, Loss: 0.3620\n",
      "Optimization Iteration:  24897, Training Accuracy:  73.4%, Loss: 0.3932\n",
      "Optimization Iteration:  24961, Training Accuracy:  81.2%, Loss: 0.3827\n",
      "Optimization Iteration:  25025, Training Accuracy:  76.6%, Loss: 0.4848\n",
      "Optimization Iteration:  25089, Training Accuracy:  78.1%, Loss: 0.4173\n",
      "Optimization Iteration:  25153, Training Accuracy:  71.9%, Loss: 0.4019\n",
      "Optimization Iteration:  25217, Training Accuracy:  62.5%, Loss: 0.5324\n",
      "Optimization Iteration:  25281, Training Accuracy:  81.2%, Loss: 0.3834\n",
      "Optimization Iteration:  25345, Training Accuracy:  70.3%, Loss: 0.4895\n",
      "Optimization Iteration:  25409, Training Accuracy:  71.9%, Loss: 0.4302\n",
      "Optimization Iteration:  25473, Training Accuracy:  68.8%, Loss: 0.4885\n",
      "Optimization Iteration:  25537, Training Accuracy:  67.2%, Loss: 0.4392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  25601, Training Accuracy:  65.6%, Loss: 0.4847\n",
      "Optimization Iteration:  25665, Training Accuracy:  84.4%, Loss: 0.3992\n",
      "Optimization Iteration:  25729, Training Accuracy:  81.2%, Loss: 0.3344\n",
      "Optimization Iteration:  25793, Training Accuracy:  76.6%, Loss: 0.4017\n",
      "Optimization Iteration:  25857, Training Accuracy:  67.2%, Loss: 0.4839\n",
      "Optimization Iteration:  25921, Training Accuracy:  73.4%, Loss: 0.4936\n",
      "Optimization Iteration:  25985, Training Accuracy:  68.8%, Loss: 0.4432\n",
      "Optimization Iteration:  26049, Training Accuracy:  79.7%, Loss: 0.3609\n",
      "Optimization Iteration:  26113, Training Accuracy:  76.6%, Loss: 0.4408\n",
      "Optimization Iteration:  26177, Training Accuracy:  73.4%, Loss: 0.4099\n",
      "Optimization Iteration:  26241, Training Accuracy:  75.0%, Loss: 0.4141\n",
      "Optimization Iteration:  26305, Training Accuracy:  68.8%, Loss: 0.4628\n",
      "Optimization Iteration:  26369, Training Accuracy:  79.7%, Loss: 0.3646\n",
      "Optimization Iteration:  26433, Training Accuracy:  67.2%, Loss: 0.4511\n",
      "Optimization Iteration:  26497, Training Accuracy:  76.6%, Loss: 0.4355\n",
      "Optimization Iteration:  26561, Training Accuracy:  79.7%, Loss: 0.3689\n",
      "Optimization Iteration:  26625, Training Accuracy:  75.0%, Loss: 0.4646\n",
      "Optimization Iteration:  26689, Training Accuracy:  79.7%, Loss: 0.4076\n",
      "Optimization Iteration:  26753, Training Accuracy:  71.9%, Loss: 0.5249\n",
      "Optimization Iteration:  26817, Training Accuracy:  75.0%, Loss: 0.4685\n",
      "Optimization Iteration:  26881, Training Accuracy:  81.2%, Loss: 0.3910\n",
      "Optimization Iteration:  26945, Training Accuracy:  70.3%, Loss: 0.4465\n",
      "Optimization Iteration:  27009, Training Accuracy:  76.6%, Loss: 0.3907\n",
      "Optimization Iteration:  27073, Training Accuracy:  70.3%, Loss: 0.4778\n",
      "Optimization Iteration:  27137, Training Accuracy:  82.8%, Loss: 0.3979\n",
      "Optimization Iteration:  27201, Training Accuracy:  79.7%, Loss: 0.3329\n",
      "Optimization Iteration:  27265, Training Accuracy:  84.4%, Loss: 0.3885\n",
      "Optimization Iteration:  27329, Training Accuracy:  71.9%, Loss: 0.4342\n",
      "Optimization Iteration:  27393, Training Accuracy:  71.9%, Loss: 0.4119\n",
      "Optimization Iteration:  27457, Training Accuracy:  76.6%, Loss: 0.4142\n",
      "Optimization Iteration:  27521, Training Accuracy:  81.2%, Loss: 0.4276\n",
      "Optimization Iteration:  27585, Training Accuracy:  78.1%, Loss: 0.4366\n",
      "Optimization Iteration:  27649, Training Accuracy:  81.2%, Loss: 0.3722\n",
      "Optimization Iteration:  27713, Training Accuracy:  81.2%, Loss: 0.3790\n",
      "Optimization Iteration:  27777, Training Accuracy:  79.7%, Loss: 0.3975\n",
      "Optimization Iteration:  27841, Training Accuracy:  78.1%, Loss: 0.4566\n",
      "Optimization Iteration:  27905, Training Accuracy:  73.4%, Loss: 0.4060\n",
      "Optimization Iteration:  27969, Training Accuracy:  73.4%, Loss: 0.4888\n",
      "Optimization Iteration:  28033, Training Accuracy:  78.1%, Loss: 0.4035\n",
      "Optimization Iteration:  28097, Training Accuracy:  64.1%, Loss: 0.4381\n",
      "Optimization Iteration:  28161, Training Accuracy:  78.1%, Loss: 0.3941\n",
      "Optimization Iteration:  28225, Training Accuracy:  67.2%, Loss: 0.4429\n",
      "Optimization Iteration:  28289, Training Accuracy:  73.4%, Loss: 0.4515\n",
      "Optimization Iteration:  28353, Training Accuracy:  78.1%, Loss: 0.4127\n",
      "Optimization Iteration:  28417, Training Accuracy:  71.9%, Loss: 0.4699\n",
      "Optimization Iteration:  28481, Training Accuracy:  78.1%, Loss: 0.3755\n",
      "Optimization Iteration:  28545, Training Accuracy:  68.8%, Loss: 0.4317\n",
      "Optimization Iteration:  28609, Training Accuracy:  79.7%, Loss: 0.4002\n",
      "Optimization Iteration:  28673, Training Accuracy:  73.4%, Loss: 0.4485\n",
      "Optimization Iteration:  28737, Training Accuracy:  75.0%, Loss: 0.4141\n",
      "Optimization Iteration:  28801, Training Accuracy:  75.0%, Loss: 0.3283\n",
      "Optimization Iteration:  28865, Training Accuracy:  84.4%, Loss: 0.3721\n",
      "Optimization Iteration:  28929, Training Accuracy:  85.9%, Loss: 0.2868\n",
      "Optimization Iteration:  28993, Training Accuracy:  70.3%, Loss: 0.4717\n",
      "Optimization Iteration:  29057, Training Accuracy:  70.3%, Loss: 0.4136\n",
      "Optimization Iteration:  29121, Training Accuracy:  64.1%, Loss: 0.5570\n",
      "Optimization Iteration:  29185, Training Accuracy:  75.0%, Loss: 0.4143\n",
      "Optimization Iteration:  29249, Training Accuracy:  73.4%, Loss: 0.4391\n",
      "Optimization Iteration:  29313, Training Accuracy:  75.0%, Loss: 0.4684\n",
      "Optimization Iteration:  29377, Training Accuracy:  75.0%, Loss: 0.3509\n",
      "Optimization Iteration:  29441, Training Accuracy:  68.8%, Loss: 0.4922\n",
      "Optimization Iteration:  29505, Training Accuracy:  81.2%, Loss: 0.3694\n",
      "Optimization Iteration:  29569, Training Accuracy:  84.4%, Loss: 0.3676\n",
      "Optimization Iteration:  29633, Training Accuracy:  75.0%, Loss: 0.3931\n",
      "Optimization Iteration:  29697, Training Accuracy:  79.7%, Loss: 0.3784\n",
      "Optimization Iteration:  29761, Training Accuracy:  71.9%, Loss: 0.4830\n",
      "Optimization Iteration:  29825, Training Accuracy:  67.2%, Loss: 0.4194\n",
      "Optimization Iteration:  29889, Training Accuracy:  75.0%, Loss: 0.4702\n",
      "Optimization Iteration:  29953, Training Accuracy:  68.8%, Loss: 0.4650\n",
      "Optimization Iteration:  30017, Training Accuracy:  87.5%, Loss: 0.2848\n",
      "Optimization Iteration:  30081, Training Accuracy:  78.1%, Loss: 0.3793\n",
      "Optimization Iteration:  30145, Training Accuracy:  73.4%, Loss: 0.4071\n",
      "Optimization Iteration:  30209, Training Accuracy:  75.0%, Loss: 0.4341\n",
      "Optimization Iteration:  30273, Training Accuracy:  81.2%, Loss: 0.4185\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.3757\n",
      "Optimization Iteration:  30401, Training Accuracy:  70.3%, Loss: 0.3924\n",
      "Optimization Iteration:  30465, Training Accuracy:  73.4%, Loss: 0.4301\n",
      "Optimization Iteration:  30529, Training Accuracy:  75.0%, Loss: 0.4305\n",
      "Optimization Iteration:  30593, Training Accuracy:  79.7%, Loss: 0.3562\n",
      "Optimization Iteration:  30657, Training Accuracy:  78.1%, Loss: 0.4158\n",
      "Optimization Iteration:  30721, Training Accuracy:  71.9%, Loss: 0.4435\n",
      "Optimization Iteration:  30785, Training Accuracy:  76.6%, Loss: 0.3758\n",
      "Optimization Iteration:  30849, Training Accuracy:  82.8%, Loss: 0.4496\n",
      "Optimization Iteration:  30913, Training Accuracy:  73.4%, Loss: 0.4135\n",
      "Optimization Iteration:  30977, Training Accuracy:  71.9%, Loss: 0.4175\n",
      "Optimization Iteration:  31041, Training Accuracy:  78.1%, Loss: 0.4324\n",
      "Optimization Iteration:  31105, Training Accuracy:  70.3%, Loss: 0.4500\n",
      "Optimization Iteration:  31169, Training Accuracy:  76.6%, Loss: 0.3611\n",
      "Optimization Iteration:  31233, Training Accuracy:  82.8%, Loss: 0.4099\n",
      "Optimization Iteration:  31297, Training Accuracy:  82.8%, Loss: 0.3408\n",
      "Optimization Iteration:  31361, Training Accuracy:  70.3%, Loss: 0.4567\n",
      "Optimization Iteration:  31425, Training Accuracy:  78.1%, Loss: 0.3604\n",
      "Optimization Iteration:  31489, Training Accuracy:  84.4%, Loss: 0.3842\n",
      "Optimization Iteration:  31553, Training Accuracy:  78.1%, Loss: 0.4778\n",
      "Optimization Iteration:  31617, Training Accuracy:  71.9%, Loss: 0.3966\n",
      "Optimization Iteration:  31681, Training Accuracy:  76.6%, Loss: 0.4788\n",
      "Optimization Iteration:  31745, Training Accuracy:  65.6%, Loss: 0.4462\n",
      "Optimization Iteration:  31809, Training Accuracy:  62.5%, Loss: 0.5153\n",
      "Optimization Iteration:  31873, Training Accuracy:  87.5%, Loss: 0.3375\n",
      "Optimization Iteration:  31937, Training Accuracy:  71.9%, Loss: 0.5280\n",
      "Optimization Iteration:  32001, Training Accuracy:  73.4%, Loss: 0.4192\n",
      "Optimization Iteration:  32065, Training Accuracy:  71.9%, Loss: 0.4186\n",
      "Optimization Iteration:  32129, Training Accuracy:  68.8%, Loss: 0.4624\n",
      "Optimization Iteration:  32193, Training Accuracy:  70.3%, Loss: 0.4371\n",
      "Optimization Iteration:  32257, Training Accuracy:  70.3%, Loss: 0.4219\n",
      "Optimization Iteration:  32321, Training Accuracy:  81.2%, Loss: 0.3410\n",
      "Optimization Iteration:  32385, Training Accuracy:  73.4%, Loss: 0.4357\n",
      "Optimization Iteration:  32449, Training Accuracy:  68.8%, Loss: 0.4516\n",
      "Optimization Iteration:  32513, Training Accuracy:  70.3%, Loss: 0.4098\n",
      "Optimization Iteration:  32577, Training Accuracy:  67.2%, Loss: 0.4408\n",
      "Optimization Iteration:  32641, Training Accuracy:  71.9%, Loss: 0.4784\n",
      "Optimization Iteration:  32705, Training Accuracy:  73.4%, Loss: 0.4186\n",
      "Optimization Iteration:  32769, Training Accuracy:  78.1%, Loss: 0.3824\n",
      "Optimization Iteration:  32833, Training Accuracy:  78.1%, Loss: 0.3967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  32897, Training Accuracy:  75.0%, Loss: 0.4578\n",
      "Optimization Iteration:  32961, Training Accuracy:  68.8%, Loss: 0.4904\n",
      "Optimization Iteration:  33025, Training Accuracy:  81.2%, Loss: 0.3717\n",
      "Optimization Iteration:  33089, Training Accuracy:  75.0%, Loss: 0.4663\n",
      "Optimization Iteration:  33153, Training Accuracy:  70.3%, Loss: 0.4520\n",
      "Optimization Iteration:  33217, Training Accuracy:  67.2%, Loss: 0.3927\n",
      "Optimization Iteration:  33281, Training Accuracy:  71.9%, Loss: 0.4552\n",
      "Optimization Iteration:  33345, Training Accuracy:  70.3%, Loss: 0.4376\n",
      "Optimization Iteration:  33409, Training Accuracy:  78.1%, Loss: 0.4088\n",
      "Optimization Iteration:  33473, Training Accuracy:  73.4%, Loss: 0.3829\n",
      "Optimization Iteration:  33537, Training Accuracy:  67.2%, Loss: 0.4665\n",
      "Optimization Iteration:  33601, Training Accuracy:  78.1%, Loss: 0.4535\n",
      "Optimization Iteration:  33665, Training Accuracy:  75.0%, Loss: 0.4513\n",
      "Optimization Iteration:  33729, Training Accuracy:  79.7%, Loss: 0.6830\n",
      "Optimization Iteration:  33793, Training Accuracy:  70.3%, Loss: 0.5087\n",
      "Optimization Iteration:  33857, Training Accuracy:  73.4%, Loss: 0.4554\n",
      "Optimization Iteration:  33921, Training Accuracy:  75.0%, Loss: 0.4689\n",
      "Optimization Iteration:  33985, Training Accuracy:  71.9%, Loss: 0.4455\n",
      "Optimization Iteration:  34049, Training Accuracy:  75.0%, Loss: 0.5211\n",
      "Optimization Iteration:  34113, Training Accuracy:  78.1%, Loss: 0.3871\n",
      "Optimization Iteration:  34177, Training Accuracy:  71.9%, Loss: 0.3713\n",
      "Optimization Iteration:  34241, Training Accuracy:  73.4%, Loss: 0.4023\n",
      "Optimization Iteration:  34305, Training Accuracy:  64.1%, Loss: 0.4725\n",
      "Optimization Iteration:  34369, Training Accuracy:  79.7%, Loss: 0.3623\n",
      "Optimization Iteration:  34433, Training Accuracy:  68.8%, Loss: 0.4882\n",
      "Optimization Iteration:  34497, Training Accuracy:  79.7%, Loss: 0.3869\n",
      "Optimization Iteration:  34561, Training Accuracy:  75.0%, Loss: 0.4269\n",
      "Optimization Iteration:  34625, Training Accuracy:  67.2%, Loss: 0.5589\n",
      "Optimization Iteration:  34689, Training Accuracy:  73.4%, Loss: 0.4613\n",
      "Optimization Iteration:  34753, Training Accuracy:  71.9%, Loss: 0.4692\n",
      "Optimization Iteration:  34817, Training Accuracy:  68.8%, Loss: 0.4054\n",
      "Optimization Iteration:  34881, Training Accuracy:  75.0%, Loss: 0.3791\n",
      "Optimization Iteration:  34945, Training Accuracy:  73.4%, Loss: 0.4013\n",
      "Optimization Iteration:  35009, Training Accuracy:  78.1%, Loss: 0.4310\n",
      "Optimization Iteration:  35073, Training Accuracy:  73.4%, Loss: 0.3948\n",
      "Optimization Iteration:  35137, Training Accuracy:  76.6%, Loss: 0.4181\n",
      "Optimization Iteration:  35201, Training Accuracy:  76.6%, Loss: 0.3949\n",
      "Optimization Iteration:  35265, Training Accuracy:  68.8%, Loss: 0.4078\n",
      "Optimization Iteration:  35329, Training Accuracy:  75.0%, Loss: 0.4691\n",
      "Optimization Iteration:  35393, Training Accuracy:  76.6%, Loss: 0.3739\n",
      "Optimization Iteration:  35457, Training Accuracy:  87.5%, Loss: 0.3167\n",
      "Optimization Iteration:  35521, Training Accuracy:  70.3%, Loss: 0.4388\n",
      "Optimization Iteration:  35585, Training Accuracy:  92.2%, Loss: 0.2581\n",
      "Optimization Iteration:  35649, Training Accuracy:  73.4%, Loss: 0.4656\n",
      "Optimization Iteration:  35713, Training Accuracy:  84.4%, Loss: 0.4283\n",
      "Optimization Iteration:  35777, Training Accuracy:  78.1%, Loss: 0.3713\n",
      "Optimization Iteration:  35841, Training Accuracy:  79.7%, Loss: 0.3927\n",
      "Optimization Iteration:  35905, Training Accuracy:  78.1%, Loss: 0.4240\n",
      "Optimization Iteration:  35969, Training Accuracy:  68.8%, Loss: 0.4276\n",
      "Optimization Iteration:  36033, Training Accuracy:  71.9%, Loss: 0.4247\n",
      "Optimization Iteration:  36097, Training Accuracy:  73.4%, Loss: 0.4522\n",
      "Optimization Iteration:  36161, Training Accuracy:  73.4%, Loss: 0.3800\n",
      "Optimization Iteration:  36225, Training Accuracy:  76.6%, Loss: 0.4098\n",
      "Optimization Iteration:  36289, Training Accuracy:  73.4%, Loss: 0.3609\n",
      "Optimization Iteration:  36353, Training Accuracy:  70.3%, Loss: 0.4353\n",
      "Optimization Iteration:  36417, Training Accuracy:  79.7%, Loss: 0.5011\n",
      "Optimization Iteration:  36481, Training Accuracy:  78.1%, Loss: 0.3118\n",
      "Optimization Iteration:  36545, Training Accuracy:  76.6%, Loss: 0.3994\n",
      "Optimization Iteration:  36609, Training Accuracy:  78.1%, Loss: 0.4296\n",
      "Optimization Iteration:  36673, Training Accuracy:  75.0%, Loss: 0.3862\n",
      "Optimization Iteration:  36737, Training Accuracy:  81.2%, Loss: 0.3648\n",
      "Optimization Iteration:  36801, Training Accuracy:  75.0%, Loss: 0.4217\n",
      "Optimization Iteration:  36865, Training Accuracy:  78.1%, Loss: 0.4393\n",
      "Optimization Iteration:  36929, Training Accuracy:  76.6%, Loss: 0.4301\n",
      "Optimization Iteration:  36993, Training Accuracy:  79.7%, Loss: 0.3847\n",
      "Optimization Iteration:  37057, Training Accuracy:  82.8%, Loss: 0.3244\n",
      "Optimization Iteration:  37121, Training Accuracy:  79.7%, Loss: 0.4108\n",
      "Optimization Iteration:  37185, Training Accuracy:  78.1%, Loss: 0.3531\n",
      "Optimization Iteration:  37249, Training Accuracy:  67.2%, Loss: 0.5061\n",
      "Optimization Iteration:  37313, Training Accuracy:  85.9%, Loss: 0.3210\n",
      "Optimization Iteration:  37377, Training Accuracy:  70.3%, Loss: 0.6440\n",
      "Optimization Iteration:  37441, Training Accuracy:  75.0%, Loss: 0.3789\n",
      "Optimization Iteration:  37505, Training Accuracy:  73.4%, Loss: 0.4277\n",
      "Optimization Iteration:  37569, Training Accuracy:  71.9%, Loss: 0.4633\n",
      "Optimization Iteration:  37633, Training Accuracy:  71.9%, Loss: 0.4296\n",
      "Optimization Iteration:  37697, Training Accuracy:  71.9%, Loss: 0.4246\n",
      "Optimization Iteration:  37761, Training Accuracy:  65.6%, Loss: 0.4251\n",
      "Optimization Iteration:  37825, Training Accuracy:  67.2%, Loss: 0.4764\n",
      "Optimization Iteration:  37889, Training Accuracy:  78.1%, Loss: 0.4005\n",
      "Optimization Iteration:  37953, Training Accuracy:  78.1%, Loss: 0.3714\n",
      "Optimization Iteration:  38017, Training Accuracy:  75.0%, Loss: 0.4173\n",
      "Optimization Iteration:  38081, Training Accuracy:  76.6%, Loss: 0.4018\n",
      "Optimization Iteration:  38145, Training Accuracy:  79.7%, Loss: 0.3592\n",
      "Optimization Iteration:  38209, Training Accuracy:  68.8%, Loss: 0.4546\n",
      "Optimization Iteration:  38273, Training Accuracy:  71.9%, Loss: 0.4408\n",
      "Optimization Iteration:  38337, Training Accuracy:  82.8%, Loss: 0.3435\n",
      "Optimization Iteration:  38401, Training Accuracy:  78.1%, Loss: 0.3571\n",
      "Optimization Iteration:  38465, Training Accuracy:  75.0%, Loss: 0.4375\n",
      "Optimization Iteration:  38529, Training Accuracy:  76.6%, Loss: 0.4486\n",
      "Optimization Iteration:  38593, Training Accuracy:  68.8%, Loss: 0.5246\n",
      "Optimization Iteration:  38657, Training Accuracy:  68.8%, Loss: 0.4859\n",
      "Optimization Iteration:  38721, Training Accuracy:  81.2%, Loss: 0.3369\n",
      "Optimization Iteration:  38785, Training Accuracy:  73.4%, Loss: 0.3958\n",
      "Optimization Iteration:  38849, Training Accuracy:  84.4%, Loss: 0.3226\n",
      "Optimization Iteration:  38913, Training Accuracy:  81.2%, Loss: 0.3576\n",
      "Optimization Iteration:  38977, Training Accuracy:  76.6%, Loss: 0.3809\n",
      "Optimization Iteration:  39041, Training Accuracy:  71.9%, Loss: 0.4700\n",
      "Optimization Iteration:  39105, Training Accuracy:  67.2%, Loss: 0.4535\n",
      "Optimization Iteration:  39169, Training Accuracy:  68.8%, Loss: 0.4541\n",
      "Optimization Iteration:  39233, Training Accuracy:  70.3%, Loss: 0.4359\n",
      "Optimization Iteration:  39297, Training Accuracy:  78.1%, Loss: 0.3658\n",
      "Optimization Iteration:  39361, Training Accuracy:  84.4%, Loss: 0.3165\n",
      "Optimization Iteration:  39425, Training Accuracy:  75.0%, Loss: 0.4527\n",
      "Optimization Iteration:  39489, Training Accuracy:  78.1%, Loss: 0.3788\n",
      "Optimization Iteration:  39553, Training Accuracy:  71.9%, Loss: 0.4137\n",
      "Optimization Iteration:  39617, Training Accuracy:  75.0%, Loss: 0.4208\n",
      "Optimization Iteration:  39681, Training Accuracy:  68.8%, Loss: 0.4148\n",
      "Optimization Iteration:  39745, Training Accuracy:  78.1%, Loss: 0.4536\n",
      "Optimization Iteration:  39809, Training Accuracy:  75.0%, Loss: 0.4903\n",
      "Optimization Iteration:  39873, Training Accuracy:  68.8%, Loss: 0.4890\n",
      "Optimization Iteration:  39937, Training Accuracy:  70.3%, Loss: 0.4724\n",
      "Optimization Iteration:  40001, Training Accuracy:  67.2%, Loss: 0.4110\n",
      "Optimization Iteration:  40065, Training Accuracy:  78.1%, Loss: 0.3817\n",
      "Optimization Iteration:  40129, Training Accuracy:  75.0%, Loss: 0.5248\n",
      "Optimization Iteration:  40193, Training Accuracy:  85.9%, Loss: 0.3173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  40257, Training Accuracy:  75.0%, Loss: 0.4515\n",
      "Optimization Iteration:  40321, Training Accuracy:  64.1%, Loss: 0.5096\n",
      "Optimization Iteration:  40385, Training Accuracy:  75.0%, Loss: 0.5049\n",
      "Optimization Iteration:  40449, Training Accuracy:  79.7%, Loss: 0.3820\n",
      "Optimization Iteration:  40513, Training Accuracy:  75.0%, Loss: 0.4035\n",
      "Optimization Iteration:  40577, Training Accuracy:  70.3%, Loss: 0.4123\n",
      "Optimization Iteration:  40641, Training Accuracy:  79.7%, Loss: 0.3646\n",
      "Optimization Iteration:  40705, Training Accuracy:  79.7%, Loss: 0.4205\n",
      "Optimization Iteration:  40769, Training Accuracy:  75.0%, Loss: 0.3591\n",
      "Optimization Iteration:  40833, Training Accuracy:  76.6%, Loss: 0.3521\n",
      "Optimization Iteration:  40897, Training Accuracy:  82.8%, Loss: 0.3779\n",
      "Optimization Iteration:  40961, Training Accuracy:  79.7%, Loss: 0.3668\n",
      "Optimization Iteration:  41025, Training Accuracy:  75.0%, Loss: 0.4372\n",
      "Optimization Iteration:  41089, Training Accuracy:  78.1%, Loss: 0.4020\n",
      "Optimization Iteration:  41153, Training Accuracy:  85.9%, Loss: 0.3921\n",
      "Optimization Iteration:  41217, Training Accuracy:  82.8%, Loss: 0.3339\n",
      "Optimization Iteration:  41281, Training Accuracy:  60.9%, Loss: 0.4867\n",
      "Optimization Iteration:  41345, Training Accuracy:  79.7%, Loss: 0.3754\n",
      "Optimization Iteration:  41409, Training Accuracy:  70.3%, Loss: 0.4378\n",
      "Optimization Iteration:  41473, Training Accuracy:  76.6%, Loss: 0.3845\n",
      "Optimization Iteration:  41537, Training Accuracy:  78.1%, Loss: 0.4767\n",
      "Optimization Iteration:  41601, Training Accuracy:  73.4%, Loss: 0.4063\n",
      "Optimization Iteration:  41665, Training Accuracy:  75.0%, Loss: 0.3937\n",
      "Optimization Iteration:  41729, Training Accuracy:  81.2%, Loss: 0.3709\n",
      "Optimization Iteration:  41793, Training Accuracy:  73.4%, Loss: 0.4645\n",
      "Optimization Iteration:  41857, Training Accuracy:  67.2%, Loss: 0.4968\n",
      "Optimization Iteration:  41921, Training Accuracy:  79.7%, Loss: 0.3910\n",
      "Optimization Iteration:  41985, Training Accuracy:  71.9%, Loss: 0.4617\n",
      "Optimization Iteration:  42049, Training Accuracy:  70.3%, Loss: 0.4659\n",
      "Optimization Iteration:  42113, Training Accuracy:  76.6%, Loss: 0.4384\n",
      "Optimization Iteration:  42177, Training Accuracy:  75.0%, Loss: 0.4931\n",
      "Optimization Iteration:  42241, Training Accuracy:  78.1%, Loss: 0.4299\n",
      "Optimization Iteration:  42305, Training Accuracy:  85.9%, Loss: 0.3714\n",
      "Optimization Iteration:  42369, Training Accuracy:  81.2%, Loss: 0.4044\n",
      "Optimization Iteration:  42433, Training Accuracy:  65.6%, Loss: 0.4830\n",
      "Optimization Iteration:  42497, Training Accuracy:  71.9%, Loss: 0.4093\n",
      "Optimization Iteration:  42561, Training Accuracy:  78.1%, Loss: 0.3953\n",
      "Optimization Iteration:  42625, Training Accuracy:  82.8%, Loss: 0.4042\n",
      "Optimization Iteration:  42689, Training Accuracy:  78.1%, Loss: 0.3458\n",
      "Optimization Iteration:  42753, Training Accuracy:  67.2%, Loss: 0.4755\n",
      "Optimization Iteration:  42817, Training Accuracy:  89.1%, Loss: 0.3118\n",
      "Optimization Iteration:  42881, Training Accuracy:  67.2%, Loss: 0.5627\n",
      "Optimization Iteration:  42945, Training Accuracy:  79.7%, Loss: 0.3945\n",
      "Optimization Iteration:  43009, Training Accuracy:  71.9%, Loss: 0.4171\n",
      "Optimization Iteration:  43073, Training Accuracy:  75.0%, Loss: 0.4359\n",
      "Optimization Iteration:  43137, Training Accuracy:  79.7%, Loss: 0.3764\n",
      "Optimization Iteration:  43201, Training Accuracy:  84.4%, Loss: 0.3833\n",
      "Optimization Iteration:  43265, Training Accuracy:  67.2%, Loss: 0.4025\n",
      "Optimization Iteration:  43329, Training Accuracy:  79.7%, Loss: 0.4797\n",
      "Optimization Iteration:  43393, Training Accuracy:  75.0%, Loss: 0.3773\n",
      "Optimization Iteration:  43457, Training Accuracy:  75.0%, Loss: 0.3414\n",
      "Optimization Iteration:  43521, Training Accuracy:  81.2%, Loss: 0.4064\n",
      "Optimization Iteration:  43585, Training Accuracy:  73.4%, Loss: 0.4755\n",
      "Optimization Iteration:  43649, Training Accuracy:  79.7%, Loss: 0.4374\n",
      "Optimization Iteration:  43713, Training Accuracy:  81.2%, Loss: 0.4054\n",
      "Optimization Iteration:  43777, Training Accuracy:  82.8%, Loss: 0.3442\n",
      "Optimization Iteration:  43841, Training Accuracy:  76.6%, Loss: 0.4343\n",
      "Optimization Iteration:  43905, Training Accuracy:  82.8%, Loss: 0.4142\n",
      "Optimization Iteration:  43969, Training Accuracy:  81.2%, Loss: 0.3415\n",
      "Optimization Iteration:  44033, Training Accuracy:  62.5%, Loss: 0.4177\n",
      "Optimization Iteration:  44097, Training Accuracy:  76.6%, Loss: 0.3575\n",
      "Optimization Iteration:  44161, Training Accuracy:  81.2%, Loss: 0.3517\n",
      "Optimization Iteration:  44225, Training Accuracy:  68.8%, Loss: 0.5583\n",
      "Optimization Iteration:  44289, Training Accuracy:  71.9%, Loss: 0.4679\n",
      "Optimization Iteration:  44353, Training Accuracy:  75.0%, Loss: 0.4692\n",
      "Optimization Iteration:  44417, Training Accuracy:  81.2%, Loss: 0.3784\n",
      "Optimization Iteration:  44481, Training Accuracy:  75.0%, Loss: 0.4233\n",
      "Optimization Iteration:  44545, Training Accuracy:  78.1%, Loss: 0.3477\n",
      "Optimization Iteration:  44609, Training Accuracy:  79.7%, Loss: 0.4073\n",
      "Optimization Iteration:  44673, Training Accuracy:  84.4%, Loss: 0.4348\n",
      "Optimization Iteration:  44737, Training Accuracy:  67.2%, Loss: 0.4204\n",
      "Optimization Iteration:  44801, Training Accuracy:  68.8%, Loss: 0.4694\n",
      "Optimization Iteration:  44865, Training Accuracy:  76.6%, Loss: 0.3983\n",
      "Optimization Iteration:  44929, Training Accuracy:  84.4%, Loss: 0.3841\n",
      "Optimization Iteration:  44993, Training Accuracy:  78.1%, Loss: 0.5523\n",
      "Optimization Iteration:  45057, Training Accuracy:  76.6%, Loss: 0.4034\n",
      "Optimization Iteration:  45121, Training Accuracy:  79.7%, Loss: 0.3779\n",
      "Optimization Iteration:  45185, Training Accuracy:  78.1%, Loss: 0.3307\n",
      "Optimization Iteration:  45249, Training Accuracy:  67.2%, Loss: 0.4657\n",
      "Optimization Iteration:  45313, Training Accuracy:  78.1%, Loss: 0.4690\n",
      "Optimization Iteration:  45377, Training Accuracy:  79.7%, Loss: 0.4782\n",
      "Optimization Iteration:  45441, Training Accuracy:  67.2%, Loss: 0.4393\n",
      "Optimization Iteration:  45505, Training Accuracy:  71.9%, Loss: 0.4393\n",
      "Optimization Iteration:  45569, Training Accuracy:  73.4%, Loss: 0.4585\n",
      "Optimization Iteration:  45633, Training Accuracy:  73.4%, Loss: 0.4992\n",
      "Optimization Iteration:  45697, Training Accuracy:  71.9%, Loss: 0.4172\n",
      "Optimization Iteration:  45761, Training Accuracy:  82.8%, Loss: 0.3314\n",
      "Optimization Iteration:  45825, Training Accuracy:  76.6%, Loss: 0.4114\n",
      "Optimization Iteration:  45889, Training Accuracy:  73.4%, Loss: 0.4265\n",
      "Optimization Iteration:  45953, Training Accuracy:  87.5%, Loss: 0.3582\n",
      "Optimization Iteration:  46017, Training Accuracy:  73.4%, Loss: 0.4357\n",
      "Optimization Iteration:  46081, Training Accuracy:  75.0%, Loss: 0.4429\n",
      "Optimization Iteration:  46145, Training Accuracy:  65.6%, Loss: 0.4362\n",
      "Optimization Iteration:  46209, Training Accuracy:  68.8%, Loss: 0.4442\n",
      "Optimization Iteration:  46273, Training Accuracy:  71.9%, Loss: 0.4714\n",
      "Optimization Iteration:  46337, Training Accuracy:  79.7%, Loss: 0.4245\n",
      "Optimization Iteration:  46401, Training Accuracy:  76.6%, Loss: 0.3469\n",
      "Optimization Iteration:  46465, Training Accuracy:  73.4%, Loss: 0.4688\n",
      "Optimization Iteration:  46529, Training Accuracy:  76.6%, Loss: 0.4516\n",
      "Optimization Iteration:  46593, Training Accuracy:  75.0%, Loss: 0.4162\n",
      "Optimization Iteration:  46657, Training Accuracy:  65.6%, Loss: 0.4787\n",
      "Optimization Iteration:  46721, Training Accuracy:  78.1%, Loss: 0.4053\n",
      "Optimization Iteration:  46785, Training Accuracy:  62.5%, Loss: 0.5180\n",
      "Optimization Iteration:  46849, Training Accuracy:  73.4%, Loss: 0.3916\n",
      "Optimization Iteration:  46913, Training Accuracy:  78.1%, Loss: 0.3195\n",
      "Optimization Iteration:  46977, Training Accuracy:  73.4%, Loss: 0.4261\n",
      "Optimization Iteration:  47041, Training Accuracy:  76.6%, Loss: 0.4435\n",
      "Optimization Iteration:  47105, Training Accuracy:  68.8%, Loss: 0.4843\n",
      "Optimization Iteration:  47169, Training Accuracy:  70.3%, Loss: 0.4599\n",
      "Optimization Iteration:  47233, Training Accuracy:  82.8%, Loss: 0.3953\n",
      "Optimization Iteration:  47297, Training Accuracy:  70.3%, Loss: 0.4133\n",
      "Optimization Iteration:  47361, Training Accuracy:  79.7%, Loss: 0.3490\n",
      "Optimization Iteration:  47425, Training Accuracy:  75.0%, Loss: 0.4020\n",
      "Optimization Iteration:  47489, Training Accuracy:  78.1%, Loss: 0.4173\n",
      "Optimization Iteration:  47553, Training Accuracy:  75.0%, Loss: 0.4643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  47617, Training Accuracy:  68.8%, Loss: 0.4518\n",
      "Optimization Iteration:  47681, Training Accuracy:  81.2%, Loss: 0.3413\n",
      "Optimization Iteration:  47745, Training Accuracy:  67.2%, Loss: 0.4532\n",
      "Optimization Iteration:  47809, Training Accuracy:  64.1%, Loss: 0.4859\n",
      "Optimization Iteration:  47873, Training Accuracy:  78.1%, Loss: 0.3138\n",
      "Optimization Iteration:  47937, Training Accuracy:  75.0%, Loss: 0.4463\n",
      "Optimization Iteration:  48001, Training Accuracy:  76.6%, Loss: 0.4718\n",
      "Optimization Iteration:  48065, Training Accuracy:  79.7%, Loss: 0.4493\n",
      "Optimization Iteration:  48129, Training Accuracy:  65.6%, Loss: 0.5317\n",
      "Optimization Iteration:  48193, Training Accuracy:  70.3%, Loss: 0.4183\n",
      "Optimization Iteration:  48257, Training Accuracy:  78.1%, Loss: 0.3461\n",
      "Optimization Iteration:  48321, Training Accuracy:  78.1%, Loss: 0.4275\n",
      "Optimization Iteration:  48385, Training Accuracy:  70.3%, Loss: 0.4725\n",
      "Optimization Iteration:  48449, Training Accuracy:  68.8%, Loss: 0.4704\n",
      "Optimization Iteration:  48513, Training Accuracy:  79.7%, Loss: 0.3727\n",
      "Optimization Iteration:  48577, Training Accuracy:  70.3%, Loss: 0.5399\n",
      "Optimization Iteration:  48641, Training Accuracy:  75.0%, Loss: 0.4127\n",
      "Optimization Iteration:  48705, Training Accuracy:  82.8%, Loss: 0.3785\n",
      "Optimization Iteration:  48769, Training Accuracy:  73.4%, Loss: 0.3996\n",
      "Optimization Iteration:  48833, Training Accuracy:  73.4%, Loss: 0.3821\n",
      "Optimization Iteration:  48897, Training Accuracy:  71.9%, Loss: 0.5265\n",
      "Optimization Iteration:  48961, Training Accuracy:  68.8%, Loss: 0.4851\n",
      "Optimization Iteration:  49025, Training Accuracy:  71.9%, Loss: 0.5113\n",
      "Optimization Iteration:  49089, Training Accuracy:  68.8%, Loss: 0.4075\n",
      "Optimization Iteration:  49153, Training Accuracy:  73.4%, Loss: 0.3784\n",
      "Optimization Iteration:  49217, Training Accuracy:  81.2%, Loss: 0.3829\n",
      "Optimization Iteration:  49281, Training Accuracy:  73.4%, Loss: 0.4172\n",
      "Optimization Iteration:  49345, Training Accuracy:  76.6%, Loss: 0.3520\n",
      "Optimization Iteration:  49409, Training Accuracy:  71.9%, Loss: 0.4691\n",
      "Optimization Iteration:  49473, Training Accuracy:  68.8%, Loss: 0.4105\n",
      "Optimization Iteration:  49537, Training Accuracy:  68.8%, Loss: 0.4171\n",
      "Optimization Iteration:  49601, Training Accuracy:  81.2%, Loss: 0.4273\n",
      "Optimization Iteration:  49665, Training Accuracy:  79.7%, Loss: 0.3973\n",
      "Optimization Iteration:  49729, Training Accuracy:  62.5%, Loss: 0.5372\n",
      "Optimization Iteration:  49793, Training Accuracy:  73.4%, Loss: 0.3511\n",
      "Optimization Iteration:  49857, Training Accuracy:  71.9%, Loss: 0.4501\n",
      "Optimization Iteration:  49921, Training Accuracy:  75.0%, Loss: 0.4258\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 10\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  65.6%, Loss: 0.4842\n",
      "Optimization Iteration:    129, Training Accuracy:  73.4%, Loss: 0.4588\n",
      "Optimization Iteration:    193, Training Accuracy:  84.4%, Loss: 0.3842\n",
      "Optimization Iteration:    257, Training Accuracy:  68.8%, Loss: 0.4753\n",
      "Optimization Iteration:    321, Training Accuracy:  81.2%, Loss: 0.4052\n",
      "Optimization Iteration:    385, Training Accuracy:  73.4%, Loss: 0.4475\n",
      "Optimization Iteration:    449, Training Accuracy:  71.9%, Loss: 0.3862\n",
      "Optimization Iteration:    513, Training Accuracy:  73.4%, Loss: 0.4876\n",
      "Optimization Iteration:    577, Training Accuracy:  70.3%, Loss: 0.4383\n",
      "Optimization Iteration:    641, Training Accuracy:  75.0%, Loss: 0.4948\n",
      "Optimization Iteration:    705, Training Accuracy:  64.1%, Loss: 0.4682\n",
      "Optimization Iteration:    769, Training Accuracy:  81.2%, Loss: 0.4309\n",
      "Optimization Iteration:    833, Training Accuracy:  82.8%, Loss: 0.4253\n",
      "Optimization Iteration:    897, Training Accuracy:  78.1%, Loss: 0.3206\n",
      "Optimization Iteration:    961, Training Accuracy:  79.7%, Loss: 0.3182\n",
      "Optimization Iteration:   1025, Training Accuracy:  84.4%, Loss: 0.3115\n",
      "Optimization Iteration:   1089, Training Accuracy:  67.2%, Loss: 0.4694\n",
      "Optimization Iteration:   1153, Training Accuracy:  67.2%, Loss: 0.4661\n",
      "Optimization Iteration:   1217, Training Accuracy:  78.1%, Loss: 0.3835\n",
      "Optimization Iteration:   1281, Training Accuracy:  67.2%, Loss: 0.4822\n",
      "Optimization Iteration:   1345, Training Accuracy:  76.6%, Loss: 0.4638\n",
      "Optimization Iteration:   1409, Training Accuracy:  75.0%, Loss: 0.4093\n",
      "Optimization Iteration:   1473, Training Accuracy:  79.7%, Loss: 0.3728\n",
      "Optimization Iteration:   1537, Training Accuracy:  78.1%, Loss: 0.3998\n",
      "Optimization Iteration:   1601, Training Accuracy:  81.2%, Loss: 0.3556\n",
      "Optimization Iteration:   1665, Training Accuracy:  70.3%, Loss: 0.3824\n",
      "Optimization Iteration:   1729, Training Accuracy:  81.2%, Loss: 0.3495\n",
      "Optimization Iteration:   1793, Training Accuracy:  70.3%, Loss: 0.5491\n",
      "Optimization Iteration:   1857, Training Accuracy:  79.7%, Loss: 0.3740\n",
      "Optimization Iteration:   1921, Training Accuracy:  73.4%, Loss: 0.4726\n",
      "Optimization Iteration:   1985, Training Accuracy:  73.4%, Loss: 0.3612\n",
      "Optimization Iteration:   2049, Training Accuracy:  73.4%, Loss: 0.3895\n",
      "Optimization Iteration:   2113, Training Accuracy:  75.0%, Loss: 0.3981\n",
      "Optimization Iteration:   2177, Training Accuracy:  82.8%, Loss: 0.3682\n",
      "Optimization Iteration:   2241, Training Accuracy:  78.1%, Loss: 0.3676\n",
      "Optimization Iteration:   2305, Training Accuracy:  71.9%, Loss: 0.4119\n",
      "Optimization Iteration:   2369, Training Accuracy:  79.7%, Loss: 0.4176\n",
      "Optimization Iteration:   2433, Training Accuracy:  70.3%, Loss: 0.4141\n",
      "Optimization Iteration:   2497, Training Accuracy:  71.9%, Loss: 0.3559\n",
      "Optimization Iteration:   2561, Training Accuracy:  71.9%, Loss: 0.3770\n",
      "Optimization Iteration:   2625, Training Accuracy:  70.3%, Loss: 0.4368\n",
      "Optimization Iteration:   2689, Training Accuracy:  84.4%, Loss: 0.3732\n",
      "Optimization Iteration:   2753, Training Accuracy:  70.3%, Loss: 0.4337\n",
      "Optimization Iteration:   2817, Training Accuracy:  82.8%, Loss: 0.3805\n",
      "Optimization Iteration:   2881, Training Accuracy:  67.2%, Loss: 0.4952\n",
      "Optimization Iteration:   2945, Training Accuracy:  75.0%, Loss: 0.3995\n",
      "Optimization Iteration:   3009, Training Accuracy:  82.8%, Loss: 0.4729\n",
      "Optimization Iteration:   3073, Training Accuracy:  81.2%, Loss: 0.3838\n",
      "Optimization Iteration:   3137, Training Accuracy:  84.4%, Loss: 0.3672\n",
      "Optimization Iteration:   3201, Training Accuracy:  81.2%, Loss: 0.3812\n",
      "Optimization Iteration:   3265, Training Accuracy:  75.0%, Loss: 0.3630\n",
      "Optimization Iteration:   3329, Training Accuracy:  78.1%, Loss: 0.4307\n",
      "Optimization Iteration:   3393, Training Accuracy:  75.0%, Loss: 0.3641\n",
      "Optimization Iteration:   3457, Training Accuracy:  84.4%, Loss: 0.3809\n",
      "Optimization Iteration:   3521, Training Accuracy:  70.3%, Loss: 0.4733\n",
      "Optimization Iteration:   3585, Training Accuracy:  68.8%, Loss: 0.4683\n",
      "Optimization Iteration:   3649, Training Accuracy:  78.1%, Loss: 0.4418\n",
      "Optimization Iteration:   3713, Training Accuracy:  65.6%, Loss: 0.4808\n",
      "Optimization Iteration:   3777, Training Accuracy:  67.2%, Loss: 0.5045\n",
      "Optimization Iteration:   3841, Training Accuracy:  76.6%, Loss: 0.4205\n",
      "Optimization Iteration:   3905, Training Accuracy:  68.8%, Loss: 0.4823\n",
      "Optimization Iteration:   3969, Training Accuracy:  75.0%, Loss: 0.4514\n",
      "Optimization Iteration:   4033, Training Accuracy:  75.0%, Loss: 0.3358\n",
      "Optimization Iteration:   4097, Training Accuracy:  75.0%, Loss: 0.3694\n",
      "Optimization Iteration:   4161, Training Accuracy:  73.4%, Loss: 0.4836\n",
      "Optimization Iteration:   4225, Training Accuracy:  76.6%, Loss: 0.3827\n",
      "Optimization Iteration:   4289, Training Accuracy:  82.8%, Loss: 0.3598\n",
      "Optimization Iteration:   4353, Training Accuracy:  76.6%, Loss: 0.3881\n",
      "Optimization Iteration:   4417, Training Accuracy:  67.2%, Loss: 0.4952\n",
      "Optimization Iteration:   4481, Training Accuracy:  78.1%, Loss: 0.4159\n",
      "Optimization Iteration:   4545, Training Accuracy:  75.0%, Loss: 0.4815\n",
      "Optimization Iteration:   4609, Training Accuracy:  82.8%, Loss: 0.3632\n",
      "Optimization Iteration:   4673, Training Accuracy:  67.2%, Loss: 0.4183\n",
      "Optimization Iteration:   4737, Training Accuracy:  76.6%, Loss: 0.4482\n",
      "Optimization Iteration:   4801, Training Accuracy:  73.4%, Loss: 0.4620\n",
      "Optimization Iteration:   4865, Training Accuracy:  71.9%, Loss: 0.4051\n",
      "Optimization Iteration:   4929, Training Accuracy:  82.8%, Loss: 0.3753\n",
      "Optimization Iteration:   4993, Training Accuracy:  79.7%, Loss: 0.3531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   5057, Training Accuracy:  67.2%, Loss: 0.5282\n",
      "Optimization Iteration:   5121, Training Accuracy:  75.0%, Loss: 0.3729\n",
      "Optimization Iteration:   5185, Training Accuracy:  75.0%, Loss: 0.4037\n",
      "Optimization Iteration:   5249, Training Accuracy:  59.4%, Loss: 0.5273\n",
      "Optimization Iteration:   5313, Training Accuracy:  79.7%, Loss: 0.4112\n",
      "Optimization Iteration:   5377, Training Accuracy:  78.1%, Loss: 0.3763\n",
      "Optimization Iteration:   5441, Training Accuracy:  64.1%, Loss: 0.4210\n",
      "Optimization Iteration:   5505, Training Accuracy:  87.5%, Loss: 0.3388\n",
      "Optimization Iteration:   5569, Training Accuracy:  75.0%, Loss: 0.3767\n",
      "Optimization Iteration:   5633, Training Accuracy:  79.7%, Loss: 0.3942\n",
      "Optimization Iteration:   5697, Training Accuracy:  75.0%, Loss: 0.4507\n",
      "Optimization Iteration:   5761, Training Accuracy:  79.7%, Loss: 0.3103\n",
      "Optimization Iteration:   5825, Training Accuracy:  73.4%, Loss: 0.4590\n",
      "Optimization Iteration:   5889, Training Accuracy:  75.0%, Loss: 0.4130\n",
      "Optimization Iteration:   5953, Training Accuracy:  78.1%, Loss: 0.4251\n",
      "Optimization Iteration:   6017, Training Accuracy:  73.4%, Loss: 0.5058\n",
      "Optimization Iteration:   6081, Training Accuracy:  76.6%, Loss: 0.4252\n",
      "Optimization Iteration:   6145, Training Accuracy:  73.4%, Loss: 0.5006\n",
      "Optimization Iteration:   6209, Training Accuracy:  68.8%, Loss: 0.4225\n",
      "Optimization Iteration:   6273, Training Accuracy:  89.1%, Loss: 0.3655\n",
      "Optimization Iteration:   6337, Training Accuracy:  65.6%, Loss: 0.4625\n",
      "Optimization Iteration:   6401, Training Accuracy:  73.4%, Loss: 0.4406\n",
      "Optimization Iteration:   6465, Training Accuracy:  84.4%, Loss: 0.3295\n",
      "Optimization Iteration:   6529, Training Accuracy:  82.8%, Loss: 0.3826\n",
      "Optimization Iteration:   6593, Training Accuracy:  68.8%, Loss: 0.4511\n",
      "Optimization Iteration:   6657, Training Accuracy:  78.1%, Loss: 0.4006\n",
      "Optimization Iteration:   6721, Training Accuracy:  73.4%, Loss: 0.4314\n",
      "Optimization Iteration:   6785, Training Accuracy:  57.8%, Loss: 0.4588\n",
      "Optimization Iteration:   6849, Training Accuracy:  71.9%, Loss: 0.4528\n",
      "Optimization Iteration:   6913, Training Accuracy:  76.6%, Loss: 0.4169\n",
      "Optimization Iteration:   6977, Training Accuracy:  73.4%, Loss: 0.4372\n",
      "Optimization Iteration:   7041, Training Accuracy:  78.1%, Loss: 0.3602\n",
      "Optimization Iteration:   7105, Training Accuracy:  89.1%, Loss: 0.2917\n",
      "Optimization Iteration:   7169, Training Accuracy:  81.2%, Loss: 0.3696\n",
      "Optimization Iteration:   7233, Training Accuracy:  71.9%, Loss: 0.4637\n",
      "Optimization Iteration:   7297, Training Accuracy:  65.6%, Loss: 0.4945\n",
      "Optimization Iteration:   7361, Training Accuracy:  79.7%, Loss: 0.3882\n",
      "Optimization Iteration:   7425, Training Accuracy:  75.0%, Loss: 0.4714\n",
      "Optimization Iteration:   7489, Training Accuracy:  79.7%, Loss: 0.4245\n",
      "Optimization Iteration:   7553, Training Accuracy:  78.1%, Loss: 0.4623\n",
      "Optimization Iteration:   7617, Training Accuracy:  75.0%, Loss: 0.3942\n",
      "Optimization Iteration:   7681, Training Accuracy:  76.6%, Loss: 0.3875\n",
      "Optimization Iteration:   7745, Training Accuracy:  70.3%, Loss: 0.3858\n",
      "Optimization Iteration:   7809, Training Accuracy:  68.8%, Loss: 0.5084\n",
      "Optimization Iteration:   7873, Training Accuracy:  71.9%, Loss: 0.3797\n",
      "Optimization Iteration:   7937, Training Accuracy:  76.6%, Loss: 0.3940\n",
      "Optimization Iteration:   8001, Training Accuracy:  73.4%, Loss: 0.4131\n",
      "Optimization Iteration:   8065, Training Accuracy:  68.8%, Loss: 0.4769\n",
      "Optimization Iteration:   8129, Training Accuracy:  68.8%, Loss: 0.4323\n",
      "Optimization Iteration:   8193, Training Accuracy:  75.0%, Loss: 0.4255\n",
      "Optimization Iteration:   8257, Training Accuracy:  71.9%, Loss: 0.4722\n",
      "Optimization Iteration:   8321, Training Accuracy:  64.1%, Loss: 0.4502\n",
      "Optimization Iteration:   8385, Training Accuracy:  71.9%, Loss: 0.4101\n",
      "Optimization Iteration:   8449, Training Accuracy:  68.8%, Loss: 0.5005\n",
      "Optimization Iteration:   8513, Training Accuracy:  73.4%, Loss: 0.4541\n",
      "Optimization Iteration:   8577, Training Accuracy:  68.8%, Loss: 0.4360\n",
      "Optimization Iteration:   8641, Training Accuracy:  78.1%, Loss: 0.4438\n",
      "Optimization Iteration:   8705, Training Accuracy:  79.7%, Loss: 0.4146\n",
      "Optimization Iteration:   8769, Training Accuracy:  70.3%, Loss: 0.4114\n",
      "Optimization Iteration:   8833, Training Accuracy:  67.2%, Loss: 0.4623\n",
      "Optimization Iteration:   8897, Training Accuracy:  75.0%, Loss: 0.4409\n",
      "Optimization Iteration:   8961, Training Accuracy:  75.0%, Loss: 0.3883\n",
      "Optimization Iteration:   9025, Training Accuracy:  64.1%, Loss: 0.5493\n",
      "Optimization Iteration:   9089, Training Accuracy:  68.8%, Loss: 0.5132\n",
      "Optimization Iteration:   9153, Training Accuracy:  65.6%, Loss: 0.4323\n",
      "Optimization Iteration:   9217, Training Accuracy:  73.4%, Loss: 0.3978\n",
      "Optimization Iteration:   9281, Training Accuracy:  75.0%, Loss: 0.4042\n",
      "Optimization Iteration:   9345, Training Accuracy:  76.6%, Loss: 0.4165\n",
      "Optimization Iteration:   9409, Training Accuracy:  85.9%, Loss: 0.4296\n",
      "Optimization Iteration:   9473, Training Accuracy:  76.6%, Loss: 0.3448\n",
      "Optimization Iteration:   9537, Training Accuracy:  70.3%, Loss: 0.4088\n",
      "Optimization Iteration:   9601, Training Accuracy:  75.0%, Loss: 0.4112\n",
      "Optimization Iteration:   9665, Training Accuracy:  65.6%, Loss: 0.4497\n",
      "Optimization Iteration:   9729, Training Accuracy:  71.9%, Loss: 0.4461\n",
      "Optimization Iteration:   9793, Training Accuracy:  76.6%, Loss: 0.3954\n",
      "Optimization Iteration:   9857, Training Accuracy:  71.9%, Loss: 0.4443\n",
      "Optimization Iteration:   9921, Training Accuracy:  73.4%, Loss: 0.3591\n",
      "Optimization Iteration:   9985, Training Accuracy:  73.4%, Loss: 0.4864\n",
      "Optimization Iteration:  10049, Training Accuracy:  75.0%, Loss: 0.4451\n",
      "Optimization Iteration:  10113, Training Accuracy:  64.1%, Loss: 0.4459\n",
      "Optimization Iteration:  10177, Training Accuracy:  70.3%, Loss: 0.5174\n",
      "Optimization Iteration:  10241, Training Accuracy:  78.1%, Loss: 0.3636\n",
      "Optimization Iteration:  10305, Training Accuracy:  87.5%, Loss: 0.3766\n",
      "Optimization Iteration:  10369, Training Accuracy:  73.4%, Loss: 0.4024\n",
      "Optimization Iteration:  10433, Training Accuracy:  76.6%, Loss: 0.3761\n",
      "Optimization Iteration:  10497, Training Accuracy:  64.1%, Loss: 0.5067\n",
      "Optimization Iteration:  10561, Training Accuracy:  79.7%, Loss: 0.3109\n",
      "Optimization Iteration:  10625, Training Accuracy:  79.7%, Loss: 0.3848\n",
      "Optimization Iteration:  10689, Training Accuracy:  68.8%, Loss: 0.4134\n",
      "Optimization Iteration:  10753, Training Accuracy:  67.2%, Loss: 0.5171\n",
      "Optimization Iteration:  10817, Training Accuracy:  70.3%, Loss: 0.4598\n",
      "Optimization Iteration:  10881, Training Accuracy:  84.4%, Loss: 0.3523\n",
      "Optimization Iteration:  10945, Training Accuracy:  75.0%, Loss: 0.4444\n",
      "Optimization Iteration:  11009, Training Accuracy:  82.8%, Loss: 0.3617\n",
      "Optimization Iteration:  11073, Training Accuracy:  70.3%, Loss: 0.4091\n",
      "Optimization Iteration:  11137, Training Accuracy:  71.9%, Loss: 0.4137\n",
      "Optimization Iteration:  11201, Training Accuracy:  81.2%, Loss: 0.3781\n",
      "Optimization Iteration:  11265, Training Accuracy:  75.0%, Loss: 0.3509\n",
      "Optimization Iteration:  11329, Training Accuracy:  70.3%, Loss: 0.5709\n",
      "Optimization Iteration:  11393, Training Accuracy:  76.6%, Loss: 0.4693\n",
      "Optimization Iteration:  11457, Training Accuracy:  82.8%, Loss: 0.3614\n",
      "Optimization Iteration:  11521, Training Accuracy:  67.2%, Loss: 0.4437\n",
      "Optimization Iteration:  11585, Training Accuracy:  71.9%, Loss: 0.3883\n",
      "Optimization Iteration:  11649, Training Accuracy:  73.4%, Loss: 0.4688\n",
      "Optimization Iteration:  11713, Training Accuracy:  75.0%, Loss: 0.4301\n",
      "Optimization Iteration:  11777, Training Accuracy:  70.3%, Loss: 0.4198\n",
      "Optimization Iteration:  11841, Training Accuracy:  73.4%, Loss: 0.4769\n",
      "Optimization Iteration:  11905, Training Accuracy:  79.7%, Loss: 0.3399\n",
      "Optimization Iteration:  11969, Training Accuracy:  78.1%, Loss: 0.3770\n",
      "Optimization Iteration:  12033, Training Accuracy:  81.2%, Loss: 0.4054\n",
      "Optimization Iteration:  12097, Training Accuracy:  75.0%, Loss: 0.4134\n",
      "Optimization Iteration:  12161, Training Accuracy:  73.4%, Loss: 0.4410\n",
      "Optimization Iteration:  12225, Training Accuracy:  78.1%, Loss: 0.3931\n",
      "Optimization Iteration:  12289, Training Accuracy:  75.0%, Loss: 0.4161\n",
      "Optimization Iteration:  12353, Training Accuracy:  89.1%, Loss: 0.3709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  12417, Training Accuracy:  81.2%, Loss: 0.3477\n",
      "Optimization Iteration:  12481, Training Accuracy:  71.9%, Loss: 0.4644\n",
      "Optimization Iteration:  12545, Training Accuracy:  70.3%, Loss: 0.4769\n",
      "Optimization Iteration:  12609, Training Accuracy:  75.0%, Loss: 0.3485\n",
      "Optimization Iteration:  12673, Training Accuracy:  79.7%, Loss: 0.3592\n",
      "Optimization Iteration:  12737, Training Accuracy:  59.4%, Loss: 0.5382\n",
      "Optimization Iteration:  12801, Training Accuracy:  73.4%, Loss: 0.4094\n",
      "Optimization Iteration:  12865, Training Accuracy:  75.0%, Loss: 0.4989\n",
      "Optimization Iteration:  12929, Training Accuracy:  79.7%, Loss: 0.5324\n",
      "Optimization Iteration:  12993, Training Accuracy:  81.2%, Loss: 0.3238\n",
      "Optimization Iteration:  13057, Training Accuracy:  71.9%, Loss: 0.4170\n",
      "Optimization Iteration:  13121, Training Accuracy:  75.0%, Loss: 0.4244\n",
      "Optimization Iteration:  13185, Training Accuracy:  67.2%, Loss: 0.4568\n",
      "Optimization Iteration:  13249, Training Accuracy:  70.3%, Loss: 0.4701\n",
      "Optimization Iteration:  13313, Training Accuracy:  68.8%, Loss: 0.5314\n",
      "Optimization Iteration:  13377, Training Accuracy:  67.2%, Loss: 0.4755\n",
      "Optimization Iteration:  13441, Training Accuracy:  75.0%, Loss: 0.4116\n",
      "Optimization Iteration:  13505, Training Accuracy:  71.9%, Loss: 0.4393\n",
      "Optimization Iteration:  13569, Training Accuracy:  79.7%, Loss: 0.3402\n",
      "Optimization Iteration:  13633, Training Accuracy:  73.4%, Loss: 0.3998\n",
      "Optimization Iteration:  13697, Training Accuracy:  79.7%, Loss: 0.3974\n",
      "Optimization Iteration:  13761, Training Accuracy:  82.8%, Loss: 0.3964\n",
      "Optimization Iteration:  13825, Training Accuracy:  79.7%, Loss: 0.4366\n",
      "Optimization Iteration:  13889, Training Accuracy:  81.2%, Loss: 0.4651\n",
      "Optimization Iteration:  13953, Training Accuracy:  85.9%, Loss: 0.3663\n",
      "Optimization Iteration:  14017, Training Accuracy:  68.8%, Loss: 0.4021\n",
      "Optimization Iteration:  14081, Training Accuracy:  79.7%, Loss: 0.3518\n",
      "Optimization Iteration:  14145, Training Accuracy:  78.1%, Loss: 0.3585\n",
      "Optimization Iteration:  14209, Training Accuracy:  76.6%, Loss: 0.4428\n",
      "Optimization Iteration:  14273, Training Accuracy:  71.9%, Loss: 0.4251\n",
      "Optimization Iteration:  14337, Training Accuracy:  78.1%, Loss: 0.3018\n",
      "Optimization Iteration:  14401, Training Accuracy:  79.7%, Loss: 0.4042\n",
      "Optimization Iteration:  14465, Training Accuracy:  67.2%, Loss: 0.5030\n",
      "Optimization Iteration:  14529, Training Accuracy:  68.8%, Loss: 0.5757\n",
      "Optimization Iteration:  14593, Training Accuracy:  76.6%, Loss: 0.4278\n",
      "Optimization Iteration:  14657, Training Accuracy:  76.6%, Loss: 0.4932\n",
      "Optimization Iteration:  14721, Training Accuracy:  71.9%, Loss: 0.4300\n",
      "Optimization Iteration:  14785, Training Accuracy:  73.4%, Loss: 0.4807\n",
      "Optimization Iteration:  14849, Training Accuracy:  67.2%, Loss: 0.4496\n",
      "Optimization Iteration:  14913, Training Accuracy:  85.9%, Loss: 0.3400\n",
      "Optimization Iteration:  14977, Training Accuracy:  65.6%, Loss: 0.5663\n",
      "Optimization Iteration:  15041, Training Accuracy:  76.6%, Loss: 0.4255\n",
      "Optimization Iteration:  15105, Training Accuracy:  76.6%, Loss: 0.4609\n",
      "Optimization Iteration:  15169, Training Accuracy:  68.8%, Loss: 0.3836\n",
      "Optimization Iteration:  15233, Training Accuracy:  68.8%, Loss: 0.4677\n",
      "Optimization Iteration:  15297, Training Accuracy:  76.6%, Loss: 0.4822\n",
      "Optimization Iteration:  15361, Training Accuracy:  82.8%, Loss: 0.3373\n",
      "Optimization Iteration:  15425, Training Accuracy:  71.9%, Loss: 0.4465\n",
      "Optimization Iteration:  15489, Training Accuracy:  70.3%, Loss: 0.4260\n",
      "Optimization Iteration:  15553, Training Accuracy:  82.8%, Loss: 0.3490\n",
      "Optimization Iteration:  15617, Training Accuracy:  79.7%, Loss: 0.3632\n",
      "Optimization Iteration:  15681, Training Accuracy:  78.1%, Loss: 0.3770\n",
      "Optimization Iteration:  15745, Training Accuracy:  82.8%, Loss: 0.3687\n",
      "Optimization Iteration:  15809, Training Accuracy:  68.8%, Loss: 0.4057\n",
      "Optimization Iteration:  15873, Training Accuracy:  71.9%, Loss: 0.5126\n",
      "Optimization Iteration:  15937, Training Accuracy:  70.3%, Loss: 0.3902\n",
      "Optimization Iteration:  16001, Training Accuracy:  67.2%, Loss: 0.4534\n",
      "Optimization Iteration:  16065, Training Accuracy:  81.2%, Loss: 0.4346\n",
      "Optimization Iteration:  16129, Training Accuracy:  82.8%, Loss: 0.3852\n",
      "Optimization Iteration:  16193, Training Accuracy:  67.2%, Loss: 0.4471\n",
      "Optimization Iteration:  16257, Training Accuracy:  75.0%, Loss: 0.4897\n",
      "Optimization Iteration:  16321, Training Accuracy:  76.6%, Loss: 0.4709\n",
      "Optimization Iteration:  16385, Training Accuracy:  79.7%, Loss: 0.4025\n",
      "Optimization Iteration:  16449, Training Accuracy:  71.9%, Loss: 0.4326\n",
      "Optimization Iteration:  16513, Training Accuracy:  76.6%, Loss: 0.4099\n",
      "Optimization Iteration:  16577, Training Accuracy:  73.4%, Loss: 0.4141\n",
      "Optimization Iteration:  16641, Training Accuracy:  65.6%, Loss: 0.5080\n",
      "Optimization Iteration:  16705, Training Accuracy:  73.4%, Loss: 0.4191\n",
      "Optimization Iteration:  16769, Training Accuracy:  79.7%, Loss: 0.3955\n",
      "Optimization Iteration:  16833, Training Accuracy:  71.9%, Loss: 0.3871\n",
      "Optimization Iteration:  16897, Training Accuracy:  70.3%, Loss: 0.3952\n",
      "Optimization Iteration:  16961, Training Accuracy:  73.4%, Loss: 0.3958\n",
      "Optimization Iteration:  17025, Training Accuracy:  70.3%, Loss: 0.4228\n",
      "Optimization Iteration:  17089, Training Accuracy:  76.6%, Loss: 0.4147\n",
      "Optimization Iteration:  17153, Training Accuracy:  68.8%, Loss: 0.4846\n",
      "Optimization Iteration:  17217, Training Accuracy:  68.8%, Loss: 0.5825\n",
      "Optimization Iteration:  17281, Training Accuracy:  62.5%, Loss: 0.4844\n",
      "Optimization Iteration:  17345, Training Accuracy:  75.0%, Loss: 0.3572\n",
      "Optimization Iteration:  17409, Training Accuracy:  76.6%, Loss: 0.4327\n",
      "Optimization Iteration:  17473, Training Accuracy:  65.6%, Loss: 0.5110\n",
      "Optimization Iteration:  17537, Training Accuracy:  81.2%, Loss: 0.3883\n",
      "Optimization Iteration:  17601, Training Accuracy:  71.9%, Loss: 0.4322\n",
      "Optimization Iteration:  17665, Training Accuracy:  71.9%, Loss: 0.4691\n",
      "Optimization Iteration:  17729, Training Accuracy:  71.9%, Loss: 0.3970\n",
      "Optimization Iteration:  17793, Training Accuracy:  75.0%, Loss: 0.4380\n",
      "Optimization Iteration:  17857, Training Accuracy:  76.6%, Loss: 0.4464\n",
      "Optimization Iteration:  17921, Training Accuracy:  81.2%, Loss: 0.3531\n",
      "Optimization Iteration:  17985, Training Accuracy:  73.4%, Loss: 0.3544\n",
      "Optimization Iteration:  18049, Training Accuracy:  73.4%, Loss: 0.3586\n",
      "Optimization Iteration:  18113, Training Accuracy:  73.4%, Loss: 0.4935\n",
      "Optimization Iteration:  18177, Training Accuracy:  71.9%, Loss: 0.4919\n",
      "Optimization Iteration:  18241, Training Accuracy:  75.0%, Loss: 0.4578\n",
      "Optimization Iteration:  18305, Training Accuracy:  71.9%, Loss: 0.4553\n",
      "Optimization Iteration:  18369, Training Accuracy:  76.6%, Loss: 0.3755\n",
      "Optimization Iteration:  18433, Training Accuracy:  60.9%, Loss: 0.4614\n",
      "Optimization Iteration:  18497, Training Accuracy:  82.8%, Loss: 0.3518\n",
      "Optimization Iteration:  18561, Training Accuracy:  79.7%, Loss: 0.3927\n",
      "Optimization Iteration:  18625, Training Accuracy:  79.7%, Loss: 0.4290\n",
      "Optimization Iteration:  18689, Training Accuracy:  78.1%, Loss: 0.4059\n",
      "Optimization Iteration:  18753, Training Accuracy:  85.9%, Loss: 0.3618\n",
      "Optimization Iteration:  18817, Training Accuracy:  78.1%, Loss: 0.3869\n",
      "Optimization Iteration:  18881, Training Accuracy:  76.6%, Loss: 0.3729\n",
      "Optimization Iteration:  18945, Training Accuracy:  71.9%, Loss: 0.4579\n",
      "Optimization Iteration:  19009, Training Accuracy:  75.0%, Loss: 0.3328\n",
      "Optimization Iteration:  19073, Training Accuracy:  76.6%, Loss: 0.4567\n",
      "Optimization Iteration:  19137, Training Accuracy:  70.3%, Loss: 0.5185\n",
      "Optimization Iteration:  19201, Training Accuracy:  75.0%, Loss: 0.4471\n",
      "Optimization Iteration:  19265, Training Accuracy:  71.9%, Loss: 0.5162\n",
      "Optimization Iteration:  19329, Training Accuracy:  79.7%, Loss: 0.3246\n",
      "Optimization Iteration:  19393, Training Accuracy:  71.9%, Loss: 0.5007\n",
      "Optimization Iteration:  19457, Training Accuracy:  84.4%, Loss: 0.3757\n",
      "Optimization Iteration:  19521, Training Accuracy:  71.9%, Loss: 0.4589\n",
      "Optimization Iteration:  19585, Training Accuracy:  64.1%, Loss: 0.4790\n",
      "Optimization Iteration:  19649, Training Accuracy:  84.4%, Loss: 0.4688\n",
      "Optimization Iteration:  19713, Training Accuracy:  89.1%, Loss: 0.3181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  19777, Training Accuracy:  73.4%, Loss: 0.4922\n",
      "Optimization Iteration:  19841, Training Accuracy:  70.3%, Loss: 0.4612\n",
      "Optimization Iteration:  19905, Training Accuracy:  73.4%, Loss: 0.4414\n",
      "Optimization Iteration:  19969, Training Accuracy:  71.9%, Loss: 0.4404\n",
      "Optimization Iteration:  20033, Training Accuracy:  75.0%, Loss: 0.3997\n",
      "Optimization Iteration:  20097, Training Accuracy:  75.0%, Loss: 0.4137\n",
      "Optimization Iteration:  20161, Training Accuracy:  71.9%, Loss: 0.3967\n",
      "Optimization Iteration:  20225, Training Accuracy:  71.9%, Loss: 0.4400\n",
      "Optimization Iteration:  20289, Training Accuracy:  70.3%, Loss: 0.4697\n",
      "Optimization Iteration:  20353, Training Accuracy:  81.2%, Loss: 0.3720\n",
      "Optimization Iteration:  20417, Training Accuracy:  79.7%, Loss: 0.3511\n",
      "Optimization Iteration:  20481, Training Accuracy:  79.7%, Loss: 0.3525\n",
      "Optimization Iteration:  20545, Training Accuracy:  78.1%, Loss: 0.4168\n",
      "Optimization Iteration:  20609, Training Accuracy:  65.6%, Loss: 0.5011\n",
      "Optimization Iteration:  20673, Training Accuracy:  73.4%, Loss: 0.4210\n",
      "Optimization Iteration:  20737, Training Accuracy:  90.6%, Loss: 0.3838\n",
      "Optimization Iteration:  20801, Training Accuracy:  79.7%, Loss: 0.3821\n",
      "Optimization Iteration:  20865, Training Accuracy:  75.0%, Loss: 0.3706\n",
      "Optimization Iteration:  20929, Training Accuracy:  89.1%, Loss: 0.3580\n",
      "Optimization Iteration:  20993, Training Accuracy:  79.7%, Loss: 0.3807\n",
      "Optimization Iteration:  21057, Training Accuracy:  78.1%, Loss: 0.3474\n",
      "Optimization Iteration:  21121, Training Accuracy:  70.3%, Loss: 0.4793\n",
      "Optimization Iteration:  21185, Training Accuracy:  75.0%, Loss: 0.4642\n",
      "Optimization Iteration:  21249, Training Accuracy:  68.8%, Loss: 0.5341\n",
      "Optimization Iteration:  21313, Training Accuracy:  76.6%, Loss: 0.4416\n",
      "Optimization Iteration:  21377, Training Accuracy:  79.7%, Loss: 0.3333\n",
      "Optimization Iteration:  21441, Training Accuracy:  70.3%, Loss: 0.4451\n",
      "Optimization Iteration:  21505, Training Accuracy:  78.1%, Loss: 0.3714\n",
      "Optimization Iteration:  21569, Training Accuracy:  73.4%, Loss: 0.4062\n",
      "Optimization Iteration:  21633, Training Accuracy:  87.5%, Loss: 0.2619\n",
      "Optimization Iteration:  21697, Training Accuracy:  68.8%, Loss: 0.5554\n",
      "Optimization Iteration:  21761, Training Accuracy:  76.6%, Loss: 0.3873\n",
      "Optimization Iteration:  21825, Training Accuracy:  70.3%, Loss: 0.5215\n",
      "Optimization Iteration:  21889, Training Accuracy:  75.0%, Loss: 0.4377\n",
      "Optimization Iteration:  21953, Training Accuracy:  71.9%, Loss: 0.5964\n",
      "Optimization Iteration:  22017, Training Accuracy:  67.2%, Loss: 0.4662\n",
      "Optimization Iteration:  22081, Training Accuracy:  76.6%, Loss: 0.3802\n",
      "Optimization Iteration:  22145, Training Accuracy:  78.1%, Loss: 0.4428\n",
      "Optimization Iteration:  22209, Training Accuracy:  75.0%, Loss: 0.5121\n",
      "Optimization Iteration:  22273, Training Accuracy:  62.5%, Loss: 0.4692\n",
      "Optimization Iteration:  22337, Training Accuracy:  78.1%, Loss: 0.3768\n",
      "Optimization Iteration:  22401, Training Accuracy:  76.6%, Loss: 0.4184\n",
      "Optimization Iteration:  22465, Training Accuracy:  62.5%, Loss: 0.4604\n",
      "Optimization Iteration:  22529, Training Accuracy:  76.6%, Loss: 0.3929\n",
      "Optimization Iteration:  22593, Training Accuracy:  62.5%, Loss: 0.5033\n",
      "Optimization Iteration:  22657, Training Accuracy:  82.8%, Loss: 0.3796\n",
      "Optimization Iteration:  22721, Training Accuracy:  70.3%, Loss: 0.4331\n",
      "Optimization Iteration:  22785, Training Accuracy:  76.6%, Loss: 0.4485\n",
      "Optimization Iteration:  22849, Training Accuracy:  70.3%, Loss: 0.4169\n",
      "Optimization Iteration:  22913, Training Accuracy:  67.2%, Loss: 0.4239\n",
      "Optimization Iteration:  22977, Training Accuracy:  76.6%, Loss: 0.3973\n",
      "Optimization Iteration:  23041, Training Accuracy:  78.1%, Loss: 0.4105\n",
      "Optimization Iteration:  23105, Training Accuracy:  73.4%, Loss: 0.4052\n",
      "Optimization Iteration:  23169, Training Accuracy:  76.6%, Loss: 0.3675\n",
      "Optimization Iteration:  23233, Training Accuracy:  79.7%, Loss: 0.4604\n",
      "Optimization Iteration:  23297, Training Accuracy:  64.1%, Loss: 0.5261\n",
      "Optimization Iteration:  23361, Training Accuracy:  75.0%, Loss: 0.4457\n",
      "Optimization Iteration:  23425, Training Accuracy:  73.4%, Loss: 0.4310\n",
      "Optimization Iteration:  23489, Training Accuracy:  85.9%, Loss: 0.4038\n",
      "Optimization Iteration:  23553, Training Accuracy:  78.1%, Loss: 0.3663\n",
      "Optimization Iteration:  23617, Training Accuracy:  68.8%, Loss: 0.5040\n",
      "Optimization Iteration:  23681, Training Accuracy:  68.8%, Loss: 0.5115\n",
      "Optimization Iteration:  23745, Training Accuracy:  75.0%, Loss: 0.4170\n",
      "Optimization Iteration:  23809, Training Accuracy:  67.2%, Loss: 0.5362\n",
      "Optimization Iteration:  23873, Training Accuracy:  78.1%, Loss: 0.3533\n",
      "Optimization Iteration:  23937, Training Accuracy:  62.5%, Loss: 0.4741\n",
      "Optimization Iteration:  24001, Training Accuracy:  76.6%, Loss: 0.3329\n",
      "Optimization Iteration:  24065, Training Accuracy:  75.0%, Loss: 0.3759\n",
      "Optimization Iteration:  24129, Training Accuracy:  81.2%, Loss: 0.3546\n",
      "Optimization Iteration:  24193, Training Accuracy:  70.3%, Loss: 0.4067\n",
      "Optimization Iteration:  24257, Training Accuracy:  73.4%, Loss: 0.4166\n",
      "Optimization Iteration:  24321, Training Accuracy:  62.5%, Loss: 0.4688\n",
      "Optimization Iteration:  24385, Training Accuracy:  67.2%, Loss: 0.4621\n",
      "Optimization Iteration:  24449, Training Accuracy:  79.7%, Loss: 0.3881\n",
      "Optimization Iteration:  24513, Training Accuracy:  82.8%, Loss: 0.3695\n",
      "Optimization Iteration:  24577, Training Accuracy:  56.2%, Loss: 0.6190\n",
      "Optimization Iteration:  24641, Training Accuracy:  73.4%, Loss: 0.4241\n",
      "Optimization Iteration:  24705, Training Accuracy:  81.2%, Loss: 0.3143\n",
      "Optimization Iteration:  24769, Training Accuracy:  76.6%, Loss: 0.3738\n",
      "Optimization Iteration:  24833, Training Accuracy:  70.3%, Loss: 0.4779\n",
      "Optimization Iteration:  24897, Training Accuracy:  76.6%, Loss: 0.4284\n",
      "Optimization Iteration:  24961, Training Accuracy:  79.7%, Loss: 0.3388\n",
      "Optimization Iteration:  25025, Training Accuracy:  75.0%, Loss: 0.3917\n",
      "Optimization Iteration:  25089, Training Accuracy:  71.9%, Loss: 0.4064\n",
      "Optimization Iteration:  25153, Training Accuracy:  68.8%, Loss: 0.4748\n",
      "Optimization Iteration:  25217, Training Accuracy:  67.2%, Loss: 0.5276\n",
      "Optimization Iteration:  25281, Training Accuracy:  70.3%, Loss: 0.4310\n",
      "Optimization Iteration:  25345, Training Accuracy:  70.3%, Loss: 0.4634\n",
      "Optimization Iteration:  25409, Training Accuracy:  76.6%, Loss: 0.4310\n",
      "Optimization Iteration:  25473, Training Accuracy:  70.3%, Loss: 0.4441\n",
      "Optimization Iteration:  25537, Training Accuracy:  71.9%, Loss: 0.3829\n",
      "Optimization Iteration:  25601, Training Accuracy:  73.4%, Loss: 0.4536\n",
      "Optimization Iteration:  25665, Training Accuracy:  78.1%, Loss: 0.5120\n",
      "Optimization Iteration:  25729, Training Accuracy:  85.9%, Loss: 0.3444\n",
      "Optimization Iteration:  25793, Training Accuracy:  75.0%, Loss: 0.4054\n",
      "Optimization Iteration:  25857, Training Accuracy:  64.1%, Loss: 0.4530\n",
      "Optimization Iteration:  25921, Training Accuracy:  79.7%, Loss: 0.4108\n",
      "Optimization Iteration:  25985, Training Accuracy:  70.3%, Loss: 0.4566\n",
      "Optimization Iteration:  26049, Training Accuracy:  67.2%, Loss: 0.4342\n",
      "Optimization Iteration:  26113, Training Accuracy:  78.1%, Loss: 0.4150\n",
      "Optimization Iteration:  26177, Training Accuracy:  67.2%, Loss: 0.5188\n",
      "Optimization Iteration:  26241, Training Accuracy:  73.4%, Loss: 0.3820\n",
      "Optimization Iteration:  26305, Training Accuracy:  70.3%, Loss: 0.5061\n",
      "Optimization Iteration:  26369, Training Accuracy:  78.1%, Loss: 0.4391\n",
      "Optimization Iteration:  26433, Training Accuracy:  79.7%, Loss: 0.3570\n",
      "Optimization Iteration:  26497, Training Accuracy:  78.1%, Loss: 0.4308\n",
      "Optimization Iteration:  26561, Training Accuracy:  85.9%, Loss: 0.3071\n",
      "Optimization Iteration:  26625, Training Accuracy:  82.8%, Loss: 0.3789\n",
      "Optimization Iteration:  26689, Training Accuracy:  81.2%, Loss: 0.3550\n",
      "Optimization Iteration:  26753, Training Accuracy:  65.6%, Loss: 0.4934\n",
      "Optimization Iteration:  26817, Training Accuracy:  71.9%, Loss: 0.4958\n",
      "Optimization Iteration:  26881, Training Accuracy:  79.7%, Loss: 0.3594\n",
      "Optimization Iteration:  26945, Training Accuracy:  60.9%, Loss: 0.4715\n",
      "Optimization Iteration:  27009, Training Accuracy:  73.4%, Loss: 0.4188\n",
      "Optimization Iteration:  27073, Training Accuracy:  82.8%, Loss: 0.4308\n",
      "Optimization Iteration:  27137, Training Accuracy:  75.0%, Loss: 0.4543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  27201, Training Accuracy:  68.8%, Loss: 0.3758\n",
      "Optimization Iteration:  27265, Training Accuracy:  70.3%, Loss: 0.4596\n",
      "Optimization Iteration:  27329, Training Accuracy:  70.3%, Loss: 0.4069\n",
      "Optimization Iteration:  27393, Training Accuracy:  78.1%, Loss: 0.4045\n",
      "Optimization Iteration:  27457, Training Accuracy:  78.1%, Loss: 0.3924\n",
      "Optimization Iteration:  27521, Training Accuracy:  71.9%, Loss: 0.4168\n",
      "Optimization Iteration:  27585, Training Accuracy:  76.6%, Loss: 0.4152\n",
      "Optimization Iteration:  27649, Training Accuracy:  76.6%, Loss: 0.3819\n",
      "Optimization Iteration:  27713, Training Accuracy:  73.4%, Loss: 0.4464\n",
      "Optimization Iteration:  27777, Training Accuracy:  78.1%, Loss: 0.3496\n",
      "Optimization Iteration:  27841, Training Accuracy:  67.2%, Loss: 0.5179\n",
      "Optimization Iteration:  27905, Training Accuracy:  78.1%, Loss: 0.3062\n",
      "Optimization Iteration:  27969, Training Accuracy:  70.3%, Loss: 0.4422\n",
      "Optimization Iteration:  28033, Training Accuracy:  76.6%, Loss: 0.3385\n",
      "Optimization Iteration:  28097, Training Accuracy:  76.6%, Loss: 0.3888\n",
      "Optimization Iteration:  28161, Training Accuracy:  84.4%, Loss: 0.3522\n",
      "Optimization Iteration:  28225, Training Accuracy:  73.4%, Loss: 0.3706\n",
      "Optimization Iteration:  28289, Training Accuracy:  73.4%, Loss: 0.4207\n",
      "Optimization Iteration:  28353, Training Accuracy:  75.0%, Loss: 0.3820\n",
      "Optimization Iteration:  28417, Training Accuracy:  70.3%, Loss: 0.4483\n",
      "Optimization Iteration:  28481, Training Accuracy:  75.0%, Loss: 0.4190\n",
      "Optimization Iteration:  28545, Training Accuracy:  81.2%, Loss: 0.3391\n",
      "Optimization Iteration:  28609, Training Accuracy:  78.1%, Loss: 0.3618\n",
      "Optimization Iteration:  28673, Training Accuracy:  70.3%, Loss: 0.4691\n",
      "Optimization Iteration:  28737, Training Accuracy:  76.6%, Loss: 0.3575\n",
      "Optimization Iteration:  28801, Training Accuracy:  68.8%, Loss: 0.4375\n",
      "Optimization Iteration:  28865, Training Accuracy:  85.9%, Loss: 0.3035\n",
      "Optimization Iteration:  28929, Training Accuracy:  79.7%, Loss: 0.3609\n",
      "Optimization Iteration:  28993, Training Accuracy:  70.3%, Loss: 0.4417\n",
      "Optimization Iteration:  29057, Training Accuracy:  70.3%, Loss: 0.4504\n",
      "Optimization Iteration:  29121, Training Accuracy:  71.9%, Loss: 0.5494\n",
      "Optimization Iteration:  29185, Training Accuracy:  70.3%, Loss: 0.3638\n",
      "Optimization Iteration:  29249, Training Accuracy:  79.7%, Loss: 0.4124\n",
      "Optimization Iteration:  29313, Training Accuracy:  81.2%, Loss: 0.3591\n",
      "Optimization Iteration:  29377, Training Accuracy:  81.2%, Loss: 0.3762\n",
      "Optimization Iteration:  29441, Training Accuracy:  70.3%, Loss: 0.4870\n",
      "Optimization Iteration:  29505, Training Accuracy:  76.6%, Loss: 0.4032\n",
      "Optimization Iteration:  29569, Training Accuracy:  73.4%, Loss: 0.4388\n",
      "Optimization Iteration:  29633, Training Accuracy:  73.4%, Loss: 0.4625\n",
      "Optimization Iteration:  29697, Training Accuracy:  81.2%, Loss: 0.3489\n",
      "Optimization Iteration:  29761, Training Accuracy:  75.0%, Loss: 0.4608\n",
      "Optimization Iteration:  29825, Training Accuracy:  75.0%, Loss: 0.3946\n",
      "Optimization Iteration:  29889, Training Accuracy:  76.6%, Loss: 0.4633\n",
      "Optimization Iteration:  29953, Training Accuracy:  70.3%, Loss: 0.4558\n",
      "Optimization Iteration:  30017, Training Accuracy:  87.5%, Loss: 0.2698\n",
      "Optimization Iteration:  30081, Training Accuracy:  78.1%, Loss: 0.3437\n",
      "Optimization Iteration:  30145, Training Accuracy:  81.2%, Loss: 0.4062\n",
      "Optimization Iteration:  30209, Training Accuracy:  67.2%, Loss: 0.4374\n",
      "Optimization Iteration:  30273, Training Accuracy:  79.7%, Loss: 0.3801\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.3667\n",
      "Optimization Iteration:  30401, Training Accuracy:  73.4%, Loss: 0.4544\n",
      "Optimization Iteration:  30465, Training Accuracy:  75.0%, Loss: 0.4140\n",
      "Optimization Iteration:  30529, Training Accuracy:  75.0%, Loss: 0.4168\n",
      "Optimization Iteration:  30593, Training Accuracy:  75.0%, Loss: 0.3884\n",
      "Optimization Iteration:  30657, Training Accuracy:  76.6%, Loss: 0.3435\n",
      "Optimization Iteration:  30721, Training Accuracy:  85.9%, Loss: 0.3521\n",
      "Optimization Iteration:  30785, Training Accuracy:  76.6%, Loss: 0.3427\n",
      "Optimization Iteration:  30849, Training Accuracy:  75.0%, Loss: 0.3853\n",
      "Optimization Iteration:  30913, Training Accuracy:  70.3%, Loss: 0.4589\n",
      "Optimization Iteration:  30977, Training Accuracy:  64.1%, Loss: 0.4644\n",
      "Optimization Iteration:  31041, Training Accuracy:  75.0%, Loss: 0.4181\n",
      "Optimization Iteration:  31105, Training Accuracy:  78.1%, Loss: 0.4050\n",
      "Optimization Iteration:  31169, Training Accuracy:  81.2%, Loss: 0.3643\n",
      "Optimization Iteration:  31233, Training Accuracy:  82.8%, Loss: 0.3845\n",
      "Optimization Iteration:  31297, Training Accuracy:  76.6%, Loss: 0.3915\n",
      "Optimization Iteration:  31361, Training Accuracy:  75.0%, Loss: 0.4502\n",
      "Optimization Iteration:  31425, Training Accuracy:  78.1%, Loss: 0.3233\n",
      "Optimization Iteration:  31489, Training Accuracy:  82.8%, Loss: 0.4345\n",
      "Optimization Iteration:  31553, Training Accuracy:  78.1%, Loss: 0.4036\n",
      "Optimization Iteration:  31617, Training Accuracy:  71.9%, Loss: 0.4080\n",
      "Optimization Iteration:  31681, Training Accuracy:  76.6%, Loss: 0.5566\n",
      "Optimization Iteration:  31745, Training Accuracy:  73.4%, Loss: 0.3372\n",
      "Optimization Iteration:  31809, Training Accuracy:  71.9%, Loss: 0.4655\n",
      "Optimization Iteration:  31873, Training Accuracy:  82.8%, Loss: 0.3532\n",
      "Optimization Iteration:  31937, Training Accuracy:  56.2%, Loss: 0.6994\n",
      "Optimization Iteration:  32001, Training Accuracy:  76.6%, Loss: 0.4773\n",
      "Optimization Iteration:  32065, Training Accuracy:  79.7%, Loss: 0.4051\n",
      "Optimization Iteration:  32129, Training Accuracy:  70.3%, Loss: 0.3985\n",
      "Optimization Iteration:  32193, Training Accuracy:  73.4%, Loss: 0.3874\n",
      "Optimization Iteration:  32257, Training Accuracy:  71.9%, Loss: 0.4368\n",
      "Optimization Iteration:  32321, Training Accuracy:  78.1%, Loss: 0.2986\n",
      "Optimization Iteration:  32385, Training Accuracy:  81.2%, Loss: 0.3808\n",
      "Optimization Iteration:  32449, Training Accuracy:  67.2%, Loss: 0.5181\n",
      "Optimization Iteration:  32513, Training Accuracy:  79.7%, Loss: 0.3503\n",
      "Optimization Iteration:  32577, Training Accuracy:  82.8%, Loss: 0.3338\n",
      "Optimization Iteration:  32641, Training Accuracy:  75.0%, Loss: 0.5013\n",
      "Optimization Iteration:  32705, Training Accuracy:  75.0%, Loss: 0.3990\n",
      "Optimization Iteration:  32769, Training Accuracy:  75.0%, Loss: 0.4153\n",
      "Optimization Iteration:  32833, Training Accuracy:  73.4%, Loss: 0.4012\n",
      "Optimization Iteration:  32897, Training Accuracy:  79.7%, Loss: 0.4272\n",
      "Optimization Iteration:  32961, Training Accuracy:  73.4%, Loss: 0.5413\n",
      "Optimization Iteration:  33025, Training Accuracy:  75.0%, Loss: 0.3967\n",
      "Optimization Iteration:  33089, Training Accuracy:  76.6%, Loss: 0.4842\n",
      "Optimization Iteration:  33153, Training Accuracy:  71.9%, Loss: 0.5019\n",
      "Optimization Iteration:  33217, Training Accuracy:  76.6%, Loss: 0.3556\n",
      "Optimization Iteration:  33281, Training Accuracy:  71.9%, Loss: 0.4865\n",
      "Optimization Iteration:  33345, Training Accuracy:  68.8%, Loss: 0.4809\n",
      "Optimization Iteration:  33409, Training Accuracy:  79.7%, Loss: 0.4055\n",
      "Optimization Iteration:  33473, Training Accuracy:  78.1%, Loss: 0.4662\n",
      "Optimization Iteration:  33537, Training Accuracy:  67.2%, Loss: 0.4711\n",
      "Optimization Iteration:  33601, Training Accuracy:  73.4%, Loss: 0.4273\n",
      "Optimization Iteration:  33665, Training Accuracy:  81.2%, Loss: 0.3718\n",
      "Optimization Iteration:  33729, Training Accuracy:  75.0%, Loss: 0.5683\n",
      "Optimization Iteration:  33793, Training Accuracy:  64.1%, Loss: 0.5146\n",
      "Optimization Iteration:  33857, Training Accuracy:  75.0%, Loss: 0.4065\n",
      "Optimization Iteration:  33921, Training Accuracy:  82.8%, Loss: 0.3515\n",
      "Optimization Iteration:  33985, Training Accuracy:  75.0%, Loss: 0.3736\n",
      "Optimization Iteration:  34049, Training Accuracy:  71.9%, Loss: 0.4811\n",
      "Optimization Iteration:  34113, Training Accuracy:  73.4%, Loss: 0.4134\n",
      "Optimization Iteration:  34177, Training Accuracy:  68.8%, Loss: 0.3845\n",
      "Optimization Iteration:  34241, Training Accuracy:  82.8%, Loss: 0.3425\n",
      "Optimization Iteration:  34305, Training Accuracy:  73.4%, Loss: 0.3929\n",
      "Optimization Iteration:  34369, Training Accuracy:  75.0%, Loss: 0.3545\n",
      "Optimization Iteration:  34433, Training Accuracy:  78.1%, Loss: 0.5527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  34497, Training Accuracy:  79.7%, Loss: 0.3581\n",
      "Optimization Iteration:  34561, Training Accuracy:  71.9%, Loss: 0.4070\n",
      "Optimization Iteration:  34625, Training Accuracy:  71.9%, Loss: 0.5320\n",
      "Optimization Iteration:  34689, Training Accuracy:  65.6%, Loss: 0.6018\n",
      "Optimization Iteration:  34753, Training Accuracy:  76.6%, Loss: 0.4293\n",
      "Optimization Iteration:  34817, Training Accuracy:  75.0%, Loss: 0.4093\n",
      "Optimization Iteration:  34881, Training Accuracy:  81.2%, Loss: 0.3384\n",
      "Optimization Iteration:  34945, Training Accuracy:  73.4%, Loss: 0.4519\n",
      "Optimization Iteration:  35009, Training Accuracy:  78.1%, Loss: 0.4381\n",
      "Optimization Iteration:  35073, Training Accuracy:  76.6%, Loss: 0.3734\n",
      "Optimization Iteration:  35137, Training Accuracy:  81.2%, Loss: 0.3852\n",
      "Optimization Iteration:  35201, Training Accuracy:  73.4%, Loss: 0.3688\n",
      "Optimization Iteration:  35265, Training Accuracy:  73.4%, Loss: 0.3792\n",
      "Optimization Iteration:  35329, Training Accuracy:  73.4%, Loss: 0.4617\n",
      "Optimization Iteration:  35393, Training Accuracy:  81.2%, Loss: 0.3482\n",
      "Optimization Iteration:  35457, Training Accuracy:  78.1%, Loss: 0.3259\n",
      "Optimization Iteration:  35521, Training Accuracy:  68.8%, Loss: 0.4236\n",
      "Optimization Iteration:  35585, Training Accuracy:  82.8%, Loss: 0.3690\n",
      "Optimization Iteration:  35649, Training Accuracy:  79.7%, Loss: 0.4075\n",
      "Optimization Iteration:  35713, Training Accuracy:  78.1%, Loss: 0.4329\n",
      "Optimization Iteration:  35777, Training Accuracy:  78.1%, Loss: 0.3358\n",
      "Optimization Iteration:  35841, Training Accuracy:  82.8%, Loss: 0.3437\n",
      "Optimization Iteration:  35905, Training Accuracy:  79.7%, Loss: 0.3934\n",
      "Optimization Iteration:  35969, Training Accuracy:  70.3%, Loss: 0.4364\n",
      "Optimization Iteration:  36033, Training Accuracy:  81.2%, Loss: 0.3557\n",
      "Optimization Iteration:  36097, Training Accuracy:  65.6%, Loss: 0.4680\n",
      "Optimization Iteration:  36161, Training Accuracy:  81.2%, Loss: 0.3612\n",
      "Optimization Iteration:  36225, Training Accuracy:  76.6%, Loss: 0.3967\n",
      "Optimization Iteration:  36289, Training Accuracy:  73.4%, Loss: 0.3398\n",
      "Optimization Iteration:  36353, Training Accuracy:  73.4%, Loss: 0.3931\n",
      "Optimization Iteration:  36417, Training Accuracy:  76.6%, Loss: 0.4750\n",
      "Optimization Iteration:  36481, Training Accuracy:  68.8%, Loss: 0.3935\n",
      "Optimization Iteration:  36545, Training Accuracy:  82.8%, Loss: 0.3872\n",
      "Optimization Iteration:  36609, Training Accuracy:  65.6%, Loss: 0.4431\n",
      "Optimization Iteration:  36673, Training Accuracy:  75.0%, Loss: 0.4261\n",
      "Optimization Iteration:  36737, Training Accuracy:  78.1%, Loss: 0.3856\n",
      "Optimization Iteration:  36801, Training Accuracy:  81.2%, Loss: 0.3895\n",
      "Optimization Iteration:  36865, Training Accuracy:  67.2%, Loss: 0.4379\n",
      "Optimization Iteration:  36929, Training Accuracy:  76.6%, Loss: 0.4471\n",
      "Optimization Iteration:  36993, Training Accuracy:  64.1%, Loss: 0.4272\n",
      "Optimization Iteration:  37057, Training Accuracy:  75.0%, Loss: 0.3916\n",
      "Optimization Iteration:  37121, Training Accuracy:  75.0%, Loss: 0.4389\n",
      "Optimization Iteration:  37185, Training Accuracy:  78.1%, Loss: 0.3911\n",
      "Optimization Iteration:  37249, Training Accuracy:  73.4%, Loss: 0.4674\n",
      "Optimization Iteration:  37313, Training Accuracy:  81.2%, Loss: 0.3410\n",
      "Optimization Iteration:  37377, Training Accuracy:  75.0%, Loss: 0.6420\n",
      "Optimization Iteration:  37441, Training Accuracy:  75.0%, Loss: 0.4177\n",
      "Optimization Iteration:  37505, Training Accuracy:  81.2%, Loss: 0.5093\n",
      "Optimization Iteration:  37569, Training Accuracy:  62.5%, Loss: 0.4951\n",
      "Optimization Iteration:  37633, Training Accuracy:  70.3%, Loss: 0.5425\n",
      "Optimization Iteration:  37697, Training Accuracy:  82.8%, Loss: 0.4004\n",
      "Optimization Iteration:  37761, Training Accuracy:  73.4%, Loss: 0.4256\n",
      "Optimization Iteration:  37825, Training Accuracy:  71.9%, Loss: 0.4887\n",
      "Optimization Iteration:  37889, Training Accuracy:  85.9%, Loss: 0.3654\n",
      "Optimization Iteration:  37953, Training Accuracy:  79.7%, Loss: 0.4035\n",
      "Optimization Iteration:  38017, Training Accuracy:  68.8%, Loss: 0.5327\n",
      "Optimization Iteration:  38081, Training Accuracy:  87.5%, Loss: 0.3431\n",
      "Optimization Iteration:  38145, Training Accuracy:  81.2%, Loss: 0.2925\n",
      "Optimization Iteration:  38209, Training Accuracy:  78.1%, Loss: 0.4697\n",
      "Optimization Iteration:  38273, Training Accuracy:  70.3%, Loss: 0.3622\n",
      "Optimization Iteration:  38337, Training Accuracy:  87.5%, Loss: 0.3317\n",
      "Optimization Iteration:  38401, Training Accuracy:  70.3%, Loss: 0.4418\n",
      "Optimization Iteration:  38465, Training Accuracy:  65.6%, Loss: 0.4346\n",
      "Optimization Iteration:  38529, Training Accuracy:  75.0%, Loss: 0.5163\n",
      "Optimization Iteration:  38593, Training Accuracy:  64.1%, Loss: 0.5921\n",
      "Optimization Iteration:  38657, Training Accuracy:  75.0%, Loss: 0.4414\n",
      "Optimization Iteration:  38721, Training Accuracy:  71.9%, Loss: 0.4083\n",
      "Optimization Iteration:  38785, Training Accuracy:  70.3%, Loss: 0.4089\n",
      "Optimization Iteration:  38849, Training Accuracy:  81.2%, Loss: 0.3719\n",
      "Optimization Iteration:  38913, Training Accuracy:  81.2%, Loss: 0.3807\n",
      "Optimization Iteration:  38977, Training Accuracy:  73.4%, Loss: 0.4779\n",
      "Optimization Iteration:  39041, Training Accuracy:  67.2%, Loss: 0.5449\n",
      "Optimization Iteration:  39105, Training Accuracy:  70.3%, Loss: 0.4391\n",
      "Optimization Iteration:  39169, Training Accuracy:  79.7%, Loss: 0.3590\n",
      "Optimization Iteration:  39233, Training Accuracy:  64.1%, Loss: 0.4813\n",
      "Optimization Iteration:  39297, Training Accuracy:  76.6%, Loss: 0.4322\n",
      "Optimization Iteration:  39361, Training Accuracy:  75.0%, Loss: 0.3627\n",
      "Optimization Iteration:  39425, Training Accuracy:  71.9%, Loss: 0.4558\n",
      "Optimization Iteration:  39489, Training Accuracy:  78.1%, Loss: 0.4087\n",
      "Optimization Iteration:  39553, Training Accuracy:  65.6%, Loss: 0.4431\n",
      "Optimization Iteration:  39617, Training Accuracy:  70.3%, Loss: 0.4371\n",
      "Optimization Iteration:  39681, Training Accuracy:  75.0%, Loss: 0.4015\n",
      "Optimization Iteration:  39745, Training Accuracy:  71.9%, Loss: 0.4282\n",
      "Optimization Iteration:  39809, Training Accuracy:  65.6%, Loss: 0.4591\n",
      "Optimization Iteration:  39873, Training Accuracy:  68.8%, Loss: 0.4714\n",
      "Optimization Iteration:  39937, Training Accuracy:  75.0%, Loss: 0.4635\n",
      "Optimization Iteration:  40001, Training Accuracy:  67.2%, Loss: 0.4258\n",
      "Optimization Iteration:  40065, Training Accuracy:  76.6%, Loss: 0.3850\n",
      "Optimization Iteration:  40129, Training Accuracy:  68.8%, Loss: 0.4838\n",
      "Optimization Iteration:  40193, Training Accuracy:  78.1%, Loss: 0.4261\n",
      "Optimization Iteration:  40257, Training Accuracy:  68.8%, Loss: 0.4830\n",
      "Optimization Iteration:  40321, Training Accuracy:  67.2%, Loss: 0.4666\n",
      "Optimization Iteration:  40385, Training Accuracy:  76.6%, Loss: 0.5001\n",
      "Optimization Iteration:  40449, Training Accuracy:  71.9%, Loss: 0.5067\n",
      "Optimization Iteration:  40513, Training Accuracy:  78.1%, Loss: 0.3606\n",
      "Optimization Iteration:  40577, Training Accuracy:  82.8%, Loss: 0.4250\n",
      "Optimization Iteration:  40641, Training Accuracy:  87.5%, Loss: 0.3025\n",
      "Optimization Iteration:  40705, Training Accuracy:  78.1%, Loss: 0.4540\n",
      "Optimization Iteration:  40769, Training Accuracy:  75.0%, Loss: 0.3234\n",
      "Optimization Iteration:  40833, Training Accuracy:  78.1%, Loss: 0.4065\n",
      "Optimization Iteration:  40897, Training Accuracy:  79.7%, Loss: 0.3936\n",
      "Optimization Iteration:  40961, Training Accuracy:  75.0%, Loss: 0.4040\n",
      "Optimization Iteration:  41025, Training Accuracy:  78.1%, Loss: 0.3901\n",
      "Optimization Iteration:  41089, Training Accuracy:  79.7%, Loss: 0.3605\n",
      "Optimization Iteration:  41153, Training Accuracy:  82.8%, Loss: 0.3442\n",
      "Optimization Iteration:  41217, Training Accuracy:  76.6%, Loss: 0.3506\n",
      "Optimization Iteration:  41281, Training Accuracy:  68.8%, Loss: 0.4322\n",
      "Optimization Iteration:  41345, Training Accuracy:  78.1%, Loss: 0.3588\n",
      "Optimization Iteration:  41409, Training Accuracy:  73.4%, Loss: 0.4496\n",
      "Optimization Iteration:  41473, Training Accuracy:  76.6%, Loss: 0.4629\n",
      "Optimization Iteration:  41537, Training Accuracy:  78.1%, Loss: 0.4052\n",
      "Optimization Iteration:  41601, Training Accuracy:  75.0%, Loss: 0.3704\n",
      "Optimization Iteration:  41665, Training Accuracy:  73.4%, Loss: 0.4026\n",
      "Optimization Iteration:  41729, Training Accuracy:  75.0%, Loss: 0.3744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  41793, Training Accuracy:  81.2%, Loss: 0.4150\n",
      "Optimization Iteration:  41857, Training Accuracy:  75.0%, Loss: 0.4434\n",
      "Optimization Iteration:  41921, Training Accuracy:  71.9%, Loss: 0.4175\n",
      "Optimization Iteration:  41985, Training Accuracy:  70.3%, Loss: 0.4779\n",
      "Optimization Iteration:  42049, Training Accuracy:  75.0%, Loss: 0.4207\n",
      "Optimization Iteration:  42113, Training Accuracy:  71.9%, Loss: 0.4773\n",
      "Optimization Iteration:  42177, Training Accuracy:  76.6%, Loss: 0.4191\n",
      "Optimization Iteration:  42241, Training Accuracy:  70.3%, Loss: 0.4508\n",
      "Optimization Iteration:  42305, Training Accuracy:  82.8%, Loss: 0.4057\n",
      "Optimization Iteration:  42369, Training Accuracy:  71.9%, Loss: 0.4362\n",
      "Optimization Iteration:  42433, Training Accuracy:  70.3%, Loss: 0.4581\n",
      "Optimization Iteration:  42497, Training Accuracy:  71.9%, Loss: 0.4777\n",
      "Optimization Iteration:  42561, Training Accuracy:  79.7%, Loss: 0.3462\n",
      "Optimization Iteration:  42625, Training Accuracy:  76.6%, Loss: 0.4256\n",
      "Optimization Iteration:  42689, Training Accuracy:  73.4%, Loss: 0.4436\n",
      "Optimization Iteration:  42753, Training Accuracy:  75.0%, Loss: 0.4078\n",
      "Optimization Iteration:  42817, Training Accuracy:  87.5%, Loss: 0.3326\n",
      "Optimization Iteration:  42881, Training Accuracy:  71.9%, Loss: 0.4916\n",
      "Optimization Iteration:  42945, Training Accuracy:  73.4%, Loss: 0.4632\n",
      "Optimization Iteration:  43009, Training Accuracy:  68.8%, Loss: 0.4180\n",
      "Optimization Iteration:  43073, Training Accuracy:  75.0%, Loss: 0.4027\n",
      "Optimization Iteration:  43137, Training Accuracy:  82.8%, Loss: 0.3283\n",
      "Optimization Iteration:  43201, Training Accuracy:  73.4%, Loss: 0.3838\n",
      "Optimization Iteration:  43265, Training Accuracy:  75.0%, Loss: 0.4092\n",
      "Optimization Iteration:  43329, Training Accuracy:  81.2%, Loss: 0.3992\n",
      "Optimization Iteration:  43393, Training Accuracy:  73.4%, Loss: 0.4127\n",
      "Optimization Iteration:  43457, Training Accuracy:  81.2%, Loss: 0.3391\n",
      "Optimization Iteration:  43521, Training Accuracy:  75.0%, Loss: 0.4529\n",
      "Optimization Iteration:  43585, Training Accuracy:  79.7%, Loss: 0.3872\n",
      "Optimization Iteration:  43649, Training Accuracy:  78.1%, Loss: 0.4800\n",
      "Optimization Iteration:  43713, Training Accuracy:  82.8%, Loss: 0.3457\n",
      "Optimization Iteration:  43777, Training Accuracy:  78.1%, Loss: 0.3453\n",
      "Optimization Iteration:  43841, Training Accuracy:  71.9%, Loss: 0.5116\n",
      "Optimization Iteration:  43905, Training Accuracy:  79.7%, Loss: 0.4602\n",
      "Optimization Iteration:  43969, Training Accuracy:  68.8%, Loss: 0.4117\n",
      "Optimization Iteration:  44033, Training Accuracy:  71.9%, Loss: 0.4606\n",
      "Optimization Iteration:  44097, Training Accuracy:  79.7%, Loss: 0.3032\n",
      "Optimization Iteration:  44161, Training Accuracy:  81.2%, Loss: 0.3773\n",
      "Optimization Iteration:  44225, Training Accuracy:  68.8%, Loss: 0.5739\n",
      "Optimization Iteration:  44289, Training Accuracy:  78.1%, Loss: 0.4121\n",
      "Optimization Iteration:  44353, Training Accuracy:  76.6%, Loss: 0.4285\n",
      "Optimization Iteration:  44417, Training Accuracy:  73.4%, Loss: 0.3805\n",
      "Optimization Iteration:  44481, Training Accuracy:  73.4%, Loss: 0.4198\n",
      "Optimization Iteration:  44545, Training Accuracy:  75.0%, Loss: 0.4071\n",
      "Optimization Iteration:  44609, Training Accuracy:  89.1%, Loss: 0.3697\n",
      "Optimization Iteration:  44673, Training Accuracy:  70.3%, Loss: 0.5380\n",
      "Optimization Iteration:  44737, Training Accuracy:  78.1%, Loss: 0.4766\n",
      "Optimization Iteration:  44801, Training Accuracy:  70.3%, Loss: 0.4450\n",
      "Optimization Iteration:  44865, Training Accuracy:  82.8%, Loss: 0.4282\n",
      "Optimization Iteration:  44929, Training Accuracy:  81.2%, Loss: 0.4461\n",
      "Optimization Iteration:  44993, Training Accuracy:  73.4%, Loss: 0.5039\n",
      "Optimization Iteration:  45057, Training Accuracy:  76.6%, Loss: 0.5014\n",
      "Optimization Iteration:  45121, Training Accuracy:  76.6%, Loss: 0.3585\n",
      "Optimization Iteration:  45185, Training Accuracy:  85.9%, Loss: 0.3530\n",
      "Optimization Iteration:  45249, Training Accuracy:  70.3%, Loss: 0.4701\n",
      "Optimization Iteration:  45313, Training Accuracy:  78.1%, Loss: 0.3703\n",
      "Optimization Iteration:  45377, Training Accuracy:  76.6%, Loss: 0.3623\n",
      "Optimization Iteration:  45441, Training Accuracy:  78.1%, Loss: 0.3836\n",
      "Optimization Iteration:  45505, Training Accuracy:  79.7%, Loss: 0.4611\n",
      "Optimization Iteration:  45569, Training Accuracy:  70.3%, Loss: 0.5672\n",
      "Optimization Iteration:  45633, Training Accuracy:  73.4%, Loss: 0.4789\n",
      "Optimization Iteration:  45697, Training Accuracy:  78.1%, Loss: 0.3914\n",
      "Optimization Iteration:  45761, Training Accuracy:  79.7%, Loss: 0.3863\n",
      "Optimization Iteration:  45825, Training Accuracy:  73.4%, Loss: 0.4077\n",
      "Optimization Iteration:  45889, Training Accuracy:  75.0%, Loss: 0.3417\n",
      "Optimization Iteration:  45953, Training Accuracy:  73.4%, Loss: 0.4276\n",
      "Optimization Iteration:  46017, Training Accuracy:  67.2%, Loss: 0.5056\n",
      "Optimization Iteration:  46081, Training Accuracy:  82.8%, Loss: 0.3619\n",
      "Optimization Iteration:  46145, Training Accuracy:  75.0%, Loss: 0.4138\n",
      "Optimization Iteration:  46209, Training Accuracy:  79.7%, Loss: 0.3520\n",
      "Optimization Iteration:  46273, Training Accuracy:  70.3%, Loss: 0.5005\n",
      "Optimization Iteration:  46337, Training Accuracy:  81.2%, Loss: 0.4340\n",
      "Optimization Iteration:  46401, Training Accuracy:  82.8%, Loss: 0.3000\n",
      "Optimization Iteration:  46465, Training Accuracy:  76.6%, Loss: 0.4098\n",
      "Optimization Iteration:  46529, Training Accuracy:  70.3%, Loss: 0.4086\n",
      "Optimization Iteration:  46593, Training Accuracy:  78.1%, Loss: 0.4359\n",
      "Optimization Iteration:  46657, Training Accuracy:  82.8%, Loss: 0.4322\n",
      "Optimization Iteration:  46721, Training Accuracy:  75.0%, Loss: 0.4304\n",
      "Optimization Iteration:  46785, Training Accuracy:  68.8%, Loss: 0.4968\n",
      "Optimization Iteration:  46849, Training Accuracy:  67.2%, Loss: 0.4078\n",
      "Optimization Iteration:  46913, Training Accuracy:  76.6%, Loss: 0.3934\n",
      "Optimization Iteration:  46977, Training Accuracy:  75.0%, Loss: 0.4350\n",
      "Optimization Iteration:  47041, Training Accuracy:  79.7%, Loss: 0.3457\n",
      "Optimization Iteration:  47105, Training Accuracy:  71.9%, Loss: 0.4856\n",
      "Optimization Iteration:  47169, Training Accuracy:  65.6%, Loss: 0.4243\n",
      "Optimization Iteration:  47233, Training Accuracy:  75.0%, Loss: 0.3800\n",
      "Optimization Iteration:  47297, Training Accuracy:  75.0%, Loss: 0.3420\n",
      "Optimization Iteration:  47361, Training Accuracy:  75.0%, Loss: 0.3655\n",
      "Optimization Iteration:  47425, Training Accuracy:  76.6%, Loss: 0.3601\n",
      "Optimization Iteration:  47489, Training Accuracy:  73.4%, Loss: 0.4496\n",
      "Optimization Iteration:  47553, Training Accuracy:  79.7%, Loss: 0.4489\n",
      "Optimization Iteration:  47617, Training Accuracy:  73.4%, Loss: 0.4594\n",
      "Optimization Iteration:  47681, Training Accuracy:  85.9%, Loss: 0.3241\n",
      "Optimization Iteration:  47745, Training Accuracy:  70.3%, Loss: 0.4639\n",
      "Optimization Iteration:  47809, Training Accuracy:  71.9%, Loss: 0.4340\n",
      "Optimization Iteration:  47873, Training Accuracy:  87.5%, Loss: 0.2803\n",
      "Optimization Iteration:  47937, Training Accuracy:  73.4%, Loss: 0.4305\n",
      "Optimization Iteration:  48001, Training Accuracy:  81.2%, Loss: 0.3821\n",
      "Optimization Iteration:  48065, Training Accuracy:  78.1%, Loss: 0.4071\n",
      "Optimization Iteration:  48129, Training Accuracy:  81.2%, Loss: 0.3777\n",
      "Optimization Iteration:  48193, Training Accuracy:  75.0%, Loss: 0.4552\n",
      "Optimization Iteration:  48257, Training Accuracy:  73.4%, Loss: 0.4114\n",
      "Optimization Iteration:  48321, Training Accuracy:  79.7%, Loss: 0.3882\n",
      "Optimization Iteration:  48385, Training Accuracy:  70.3%, Loss: 0.4381\n",
      "Optimization Iteration:  48449, Training Accuracy:  68.8%, Loss: 0.4617\n",
      "Optimization Iteration:  48513, Training Accuracy:  79.7%, Loss: 0.3632\n",
      "Optimization Iteration:  48577, Training Accuracy:  67.2%, Loss: 0.5973\n",
      "Optimization Iteration:  48641, Training Accuracy:  82.8%, Loss: 0.3317\n",
      "Optimization Iteration:  48705, Training Accuracy:  84.4%, Loss: 0.3441\n",
      "Optimization Iteration:  48769, Training Accuracy:  82.8%, Loss: 0.3341\n",
      "Optimization Iteration:  48833, Training Accuracy:  81.2%, Loss: 0.3693\n",
      "Optimization Iteration:  48897, Training Accuracy:  71.9%, Loss: 0.4299\n",
      "Optimization Iteration:  48961, Training Accuracy:  76.6%, Loss: 0.4507\n",
      "Optimization Iteration:  49025, Training Accuracy:  70.3%, Loss: 0.4890\n",
      "Optimization Iteration:  49089, Training Accuracy:  71.9%, Loss: 0.3669\n",
      "Optimization Iteration:  49153, Training Accuracy:  87.5%, Loss: 0.3833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  49217, Training Accuracy:  71.9%, Loss: 0.3619\n",
      "Optimization Iteration:  49281, Training Accuracy:  68.8%, Loss: 0.4182\n",
      "Optimization Iteration:  49345, Training Accuracy:  85.9%, Loss: 0.3618\n",
      "Optimization Iteration:  49409, Training Accuracy:  73.4%, Loss: 0.3775\n",
      "Optimization Iteration:  49473, Training Accuracy:  75.0%, Loss: 0.3499\n",
      "Optimization Iteration:  49537, Training Accuracy:  73.4%, Loss: 0.4014\n",
      "Optimization Iteration:  49601, Training Accuracy:  73.4%, Loss: 0.4827\n",
      "Optimization Iteration:  49665, Training Accuracy:  78.1%, Loss: 0.3731\n",
      "Optimization Iteration:  49729, Training Accuracy:  76.6%, Loss: 0.4097\n",
      "Optimization Iteration:  49793, Training Accuracy:  70.3%, Loss: 0.3964\n",
      "Optimization Iteration:  49857, Training Accuracy:  68.8%, Loss: 0.4315\n",
      "Optimization Iteration:  49921, Training Accuracy:  75.0%, Loss: 0.4171\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 11\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  60.9%, Loss: 0.5123\n",
      "Optimization Iteration:    129, Training Accuracy:  75.0%, Loss: 0.4573\n",
      "Optimization Iteration:    193, Training Accuracy:  70.3%, Loss: 0.4632\n",
      "Optimization Iteration:    257, Training Accuracy:  75.0%, Loss: 0.3762\n",
      "Optimization Iteration:    321, Training Accuracy:  76.6%, Loss: 0.3800\n",
      "Optimization Iteration:    385, Training Accuracy:  84.4%, Loss: 0.3781\n",
      "Optimization Iteration:    449, Training Accuracy:  82.8%, Loss: 0.3695\n",
      "Optimization Iteration:    513, Training Accuracy:  64.1%, Loss: 0.4429\n",
      "Optimization Iteration:    577, Training Accuracy:  65.6%, Loss: 0.4725\n",
      "Optimization Iteration:    641, Training Accuracy:  79.7%, Loss: 0.3587\n",
      "Optimization Iteration:    705, Training Accuracy:  68.8%, Loss: 0.5460\n",
      "Optimization Iteration:    769, Training Accuracy:  75.0%, Loss: 0.4413\n",
      "Optimization Iteration:    833, Training Accuracy:  78.1%, Loss: 0.3946\n",
      "Optimization Iteration:    897, Training Accuracy:  73.4%, Loss: 0.3699\n",
      "Optimization Iteration:    961, Training Accuracy:  75.0%, Loss: 0.3493\n",
      "Optimization Iteration:   1025, Training Accuracy:  76.6%, Loss: 0.3974\n",
      "Optimization Iteration:   1089, Training Accuracy:  75.0%, Loss: 0.4598\n",
      "Optimization Iteration:   1153, Training Accuracy:  75.0%, Loss: 0.4466\n",
      "Optimization Iteration:   1217, Training Accuracy:  76.6%, Loss: 0.4152\n",
      "Optimization Iteration:   1281, Training Accuracy:  75.0%, Loss: 0.4037\n",
      "Optimization Iteration:   1345, Training Accuracy:  76.6%, Loss: 0.4082\n",
      "Optimization Iteration:   1409, Training Accuracy:  78.1%, Loss: 0.4268\n",
      "Optimization Iteration:   1473, Training Accuracy:  73.4%, Loss: 0.4490\n",
      "Optimization Iteration:   1537, Training Accuracy:  73.4%, Loss: 0.3968\n",
      "Optimization Iteration:   1601, Training Accuracy:  76.6%, Loss: 0.4023\n",
      "Optimization Iteration:   1665, Training Accuracy:  75.0%, Loss: 0.3297\n",
      "Optimization Iteration:   1729, Training Accuracy:  68.8%, Loss: 0.3873\n",
      "Optimization Iteration:   1793, Training Accuracy:  78.1%, Loss: 0.3836\n",
      "Optimization Iteration:   1857, Training Accuracy:  79.7%, Loss: 0.3847\n",
      "Optimization Iteration:   1921, Training Accuracy:  79.7%, Loss: 0.4109\n",
      "Optimization Iteration:   1985, Training Accuracy:  71.9%, Loss: 0.4362\n",
      "Optimization Iteration:   2049, Training Accuracy:  81.2%, Loss: 0.3087\n",
      "Optimization Iteration:   2113, Training Accuracy:  79.7%, Loss: 0.3440\n",
      "Optimization Iteration:   2177, Training Accuracy:  84.4%, Loss: 0.3373\n",
      "Optimization Iteration:   2241, Training Accuracy:  67.2%, Loss: 0.4443\n",
      "Optimization Iteration:   2305, Training Accuracy:  75.0%, Loss: 0.3830\n",
      "Optimization Iteration:   2369, Training Accuracy:  70.3%, Loss: 0.4337\n",
      "Optimization Iteration:   2433, Training Accuracy:  70.3%, Loss: 0.4680\n",
      "Optimization Iteration:   2497, Training Accuracy:  75.0%, Loss: 0.3799\n",
      "Optimization Iteration:   2561, Training Accuracy:  75.0%, Loss: 0.3457\n",
      "Optimization Iteration:   2625, Training Accuracy:  81.2%, Loss: 0.3892\n",
      "Optimization Iteration:   2689, Training Accuracy:  68.8%, Loss: 0.4036\n",
      "Optimization Iteration:   2753, Training Accuracy:  65.6%, Loss: 0.4070\n",
      "Optimization Iteration:   2817, Training Accuracy:  78.1%, Loss: 0.4152\n",
      "Optimization Iteration:   2881, Training Accuracy:  76.6%, Loss: 0.4483\n",
      "Optimization Iteration:   2945, Training Accuracy:  71.9%, Loss: 0.4958\n",
      "Optimization Iteration:   3009, Training Accuracy:  75.0%, Loss: 0.4342\n",
      "Optimization Iteration:   3073, Training Accuracy:  76.6%, Loss: 0.3580\n",
      "Optimization Iteration:   3137, Training Accuracy:  75.0%, Loss: 0.3873\n",
      "Optimization Iteration:   3201, Training Accuracy:  81.2%, Loss: 0.3977\n",
      "Optimization Iteration:   3265, Training Accuracy:  79.7%, Loss: 0.3918\n",
      "Optimization Iteration:   3329, Training Accuracy:  79.7%, Loss: 0.4400\n",
      "Optimization Iteration:   3393, Training Accuracy:  76.6%, Loss: 0.3708\n",
      "Optimization Iteration:   3457, Training Accuracy:  79.7%, Loss: 0.4233\n",
      "Optimization Iteration:   3521, Training Accuracy:  75.0%, Loss: 0.3893\n",
      "Optimization Iteration:   3585, Training Accuracy:  79.7%, Loss: 0.3667\n",
      "Optimization Iteration:   3649, Training Accuracy:  81.2%, Loss: 0.3442\n",
      "Optimization Iteration:   3713, Training Accuracy:  65.6%, Loss: 0.4291\n",
      "Optimization Iteration:   3777, Training Accuracy:  73.4%, Loss: 0.4392\n",
      "Optimization Iteration:   3841, Training Accuracy:  73.4%, Loss: 0.4367\n",
      "Optimization Iteration:   3905, Training Accuracy:  75.0%, Loss: 0.3781\n",
      "Optimization Iteration:   3969, Training Accuracy:  75.0%, Loss: 0.4485\n",
      "Optimization Iteration:   4033, Training Accuracy:  78.1%, Loss: 0.3160\n",
      "Optimization Iteration:   4097, Training Accuracy:  73.4%, Loss: 0.4083\n",
      "Optimization Iteration:   4161, Training Accuracy:  76.6%, Loss: 0.4276\n",
      "Optimization Iteration:   4225, Training Accuracy:  78.1%, Loss: 0.3762\n",
      "Optimization Iteration:   4289, Training Accuracy:  75.0%, Loss: 0.3519\n",
      "Optimization Iteration:   4353, Training Accuracy:  76.6%, Loss: 0.4001\n",
      "Optimization Iteration:   4417, Training Accuracy:  71.9%, Loss: 0.4694\n",
      "Optimization Iteration:   4481, Training Accuracy:  78.1%, Loss: 0.4292\n",
      "Optimization Iteration:   4545, Training Accuracy:  81.2%, Loss: 0.4187\n",
      "Optimization Iteration:   4609, Training Accuracy:  71.9%, Loss: 0.4154\n",
      "Optimization Iteration:   4673, Training Accuracy:  73.4%, Loss: 0.4388\n",
      "Optimization Iteration:   4737, Training Accuracy:  68.8%, Loss: 0.4658\n",
      "Optimization Iteration:   4801, Training Accuracy:  75.0%, Loss: 0.4015\n",
      "Optimization Iteration:   4865, Training Accuracy:  73.4%, Loss: 0.4349\n",
      "Optimization Iteration:   4929, Training Accuracy:  78.1%, Loss: 0.3505\n",
      "Optimization Iteration:   4993, Training Accuracy:  79.7%, Loss: 0.3524\n",
      "Optimization Iteration:   5057, Training Accuracy:  70.3%, Loss: 0.4597\n",
      "Optimization Iteration:   5121, Training Accuracy:  81.2%, Loss: 0.3307\n",
      "Optimization Iteration:   5185, Training Accuracy:  73.4%, Loss: 0.3988\n",
      "Optimization Iteration:   5249, Training Accuracy:  71.9%, Loss: 0.4723\n",
      "Optimization Iteration:   5313, Training Accuracy:  71.9%, Loss: 0.4692\n",
      "Optimization Iteration:   5377, Training Accuracy:  76.6%, Loss: 0.4050\n",
      "Optimization Iteration:   5441, Training Accuracy:  71.9%, Loss: 0.4310\n",
      "Optimization Iteration:   5505, Training Accuracy:  82.8%, Loss: 0.3341\n",
      "Optimization Iteration:   5569, Training Accuracy:  84.4%, Loss: 0.3639\n",
      "Optimization Iteration:   5633, Training Accuracy:  70.3%, Loss: 0.4169\n",
      "Optimization Iteration:   5697, Training Accuracy:  76.6%, Loss: 0.4456\n",
      "Optimization Iteration:   5761, Training Accuracy:  84.4%, Loss: 0.3359\n",
      "Optimization Iteration:   5825, Training Accuracy:  75.0%, Loss: 0.4556\n",
      "Optimization Iteration:   5889, Training Accuracy:  76.6%, Loss: 0.4079\n",
      "Optimization Iteration:   5953, Training Accuracy:  75.0%, Loss: 0.4440\n",
      "Optimization Iteration:   6017, Training Accuracy:  62.5%, Loss: 0.5258\n",
      "Optimization Iteration:   6081, Training Accuracy:  79.7%, Loss: 0.3539\n",
      "Optimization Iteration:   6145, Training Accuracy:  68.8%, Loss: 0.4699\n",
      "Optimization Iteration:   6209, Training Accuracy:  70.3%, Loss: 0.3742\n",
      "Optimization Iteration:   6273, Training Accuracy:  81.2%, Loss: 0.3654\n",
      "Optimization Iteration:   6337, Training Accuracy:  79.7%, Loss: 0.4249\n",
      "Optimization Iteration:   6401, Training Accuracy:  84.4%, Loss: 0.3882\n",
      "Optimization Iteration:   6465, Training Accuracy:  81.2%, Loss: 0.2936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   6529, Training Accuracy:  78.1%, Loss: 0.4186\n",
      "Optimization Iteration:   6593, Training Accuracy:  78.1%, Loss: 0.3741\n",
      "Optimization Iteration:   6657, Training Accuracy:  68.8%, Loss: 0.4282\n",
      "Optimization Iteration:   6721, Training Accuracy:  76.6%, Loss: 0.3355\n",
      "Optimization Iteration:   6785, Training Accuracy:  79.7%, Loss: 0.3448\n",
      "Optimization Iteration:   6849, Training Accuracy:  81.2%, Loss: 0.3773\n",
      "Optimization Iteration:   6913, Training Accuracy:  84.4%, Loss: 0.2889\n",
      "Optimization Iteration:   6977, Training Accuracy:  78.1%, Loss: 0.3640\n",
      "Optimization Iteration:   7041, Training Accuracy:  76.6%, Loss: 0.3398\n",
      "Optimization Iteration:   7105, Training Accuracy:  76.6%, Loss: 0.3357\n",
      "Optimization Iteration:   7169, Training Accuracy:  70.3%, Loss: 0.4113\n",
      "Optimization Iteration:   7233, Training Accuracy:  75.0%, Loss: 0.4735\n",
      "Optimization Iteration:   7297, Training Accuracy:  62.5%, Loss: 0.6250\n",
      "Optimization Iteration:   7361, Training Accuracy:  73.4%, Loss: 0.3727\n",
      "Optimization Iteration:   7425, Training Accuracy:  78.1%, Loss: 0.4305\n",
      "Optimization Iteration:   7489, Training Accuracy:  76.6%, Loss: 0.4180\n",
      "Optimization Iteration:   7553, Training Accuracy:  75.0%, Loss: 0.4539\n",
      "Optimization Iteration:   7617, Training Accuracy:  68.8%, Loss: 0.4754\n",
      "Optimization Iteration:   7681, Training Accuracy:  75.0%, Loss: 0.4353\n",
      "Optimization Iteration:   7745, Training Accuracy:  75.0%, Loss: 0.3632\n",
      "Optimization Iteration:   7809, Training Accuracy:  78.1%, Loss: 0.4354\n",
      "Optimization Iteration:   7873, Training Accuracy:  73.4%, Loss: 0.3933\n",
      "Optimization Iteration:   7937, Training Accuracy:  78.1%, Loss: 0.4459\n",
      "Optimization Iteration:   8001, Training Accuracy:  73.4%, Loss: 0.4528\n",
      "Optimization Iteration:   8065, Training Accuracy:  73.4%, Loss: 0.3861\n",
      "Optimization Iteration:   8129, Training Accuracy:  78.1%, Loss: 0.3991\n",
      "Optimization Iteration:   8193, Training Accuracy:  71.9%, Loss: 0.4131\n",
      "Optimization Iteration:   8257, Training Accuracy:  70.3%, Loss: 0.4657\n",
      "Optimization Iteration:   8321, Training Accuracy:  64.1%, Loss: 0.4636\n",
      "Optimization Iteration:   8385, Training Accuracy:  65.6%, Loss: 0.4933\n",
      "Optimization Iteration:   8449, Training Accuracy:  68.8%, Loss: 0.4932\n",
      "Optimization Iteration:   8513, Training Accuracy:  84.4%, Loss: 0.3724\n",
      "Optimization Iteration:   8577, Training Accuracy:  73.4%, Loss: 0.3912\n",
      "Optimization Iteration:   8641, Training Accuracy:  78.1%, Loss: 0.3851\n",
      "Optimization Iteration:   8705, Training Accuracy:  78.1%, Loss: 0.3727\n",
      "Optimization Iteration:   8769, Training Accuracy:  70.3%, Loss: 0.4628\n",
      "Optimization Iteration:   8833, Training Accuracy:  70.3%, Loss: 0.4157\n",
      "Optimization Iteration:   8897, Training Accuracy:  78.1%, Loss: 0.5087\n",
      "Optimization Iteration:   8961, Training Accuracy:  70.3%, Loss: 0.4726\n",
      "Optimization Iteration:   9025, Training Accuracy:  70.3%, Loss: 0.5100\n",
      "Optimization Iteration:   9089, Training Accuracy:  60.9%, Loss: 0.5000\n",
      "Optimization Iteration:   9153, Training Accuracy:  67.2%, Loss: 0.4507\n",
      "Optimization Iteration:   9217, Training Accuracy:  82.8%, Loss: 0.4035\n",
      "Optimization Iteration:   9281, Training Accuracy:  70.3%, Loss: 0.4091\n",
      "Optimization Iteration:   9345, Training Accuracy:  79.7%, Loss: 0.3878\n",
      "Optimization Iteration:   9409, Training Accuracy:  79.7%, Loss: 0.3923\n",
      "Optimization Iteration:   9473, Training Accuracy:  78.1%, Loss: 0.3124\n",
      "Optimization Iteration:   9537, Training Accuracy:  81.2%, Loss: 0.3586\n",
      "Optimization Iteration:   9601, Training Accuracy:  75.0%, Loss: 0.4050\n",
      "Optimization Iteration:   9665, Training Accuracy:  75.0%, Loss: 0.3854\n",
      "Optimization Iteration:   9729, Training Accuracy:  68.8%, Loss: 0.4943\n",
      "Optimization Iteration:   9793, Training Accuracy:  70.3%, Loss: 0.3889\n",
      "Optimization Iteration:   9857, Training Accuracy:  79.7%, Loss: 0.3637\n",
      "Optimization Iteration:   9921, Training Accuracy:  73.4%, Loss: 0.3888\n",
      "Optimization Iteration:   9985, Training Accuracy:  82.8%, Loss: 0.3735\n",
      "Optimization Iteration:  10049, Training Accuracy:  76.6%, Loss: 0.4191\n",
      "Optimization Iteration:  10113, Training Accuracy:  67.2%, Loss: 0.4736\n",
      "Optimization Iteration:  10177, Training Accuracy:  70.3%, Loss: 0.5386\n",
      "Optimization Iteration:  10241, Training Accuracy:  73.4%, Loss: 0.4293\n",
      "Optimization Iteration:  10305, Training Accuracy:  75.0%, Loss: 0.4469\n",
      "Optimization Iteration:  10369, Training Accuracy:  73.4%, Loss: 0.4378\n",
      "Optimization Iteration:  10433, Training Accuracy:  82.8%, Loss: 0.3462\n",
      "Optimization Iteration:  10497, Training Accuracy:  68.8%, Loss: 0.5375\n",
      "Optimization Iteration:  10561, Training Accuracy:  79.7%, Loss: 0.4008\n",
      "Optimization Iteration:  10625, Training Accuracy:  76.6%, Loss: 0.3906\n",
      "Optimization Iteration:  10689, Training Accuracy:  76.6%, Loss: 0.4130\n",
      "Optimization Iteration:  10753, Training Accuracy:  71.9%, Loss: 0.4778\n",
      "Optimization Iteration:  10817, Training Accuracy:  71.9%, Loss: 0.3971\n",
      "Optimization Iteration:  10881, Training Accuracy:  82.8%, Loss: 0.3660\n",
      "Optimization Iteration:  10945, Training Accuracy:  75.0%, Loss: 0.3938\n",
      "Optimization Iteration:  11009, Training Accuracy:  78.1%, Loss: 0.3327\n",
      "Optimization Iteration:  11073, Training Accuracy:  76.6%, Loss: 0.3858\n",
      "Optimization Iteration:  11137, Training Accuracy:  81.2%, Loss: 0.4393\n",
      "Optimization Iteration:  11201, Training Accuracy:  76.6%, Loss: 0.3865\n",
      "Optimization Iteration:  11265, Training Accuracy:  79.7%, Loss: 0.3331\n",
      "Optimization Iteration:  11329, Training Accuracy:  78.1%, Loss: 0.5087\n",
      "Optimization Iteration:  11393, Training Accuracy:  82.8%, Loss: 0.3446\n",
      "Optimization Iteration:  11457, Training Accuracy:  81.2%, Loss: 0.3663\n",
      "Optimization Iteration:  11521, Training Accuracy:  73.4%, Loss: 0.4188\n",
      "Optimization Iteration:  11585, Training Accuracy:  79.7%, Loss: 0.3850\n",
      "Optimization Iteration:  11649, Training Accuracy:  76.6%, Loss: 0.4109\n",
      "Optimization Iteration:  11713, Training Accuracy:  70.3%, Loss: 0.4360\n",
      "Optimization Iteration:  11777, Training Accuracy:  76.6%, Loss: 0.4991\n",
      "Optimization Iteration:  11841, Training Accuracy:  82.8%, Loss: 0.3865\n",
      "Optimization Iteration:  11905, Training Accuracy:  79.7%, Loss: 0.4201\n",
      "Optimization Iteration:  11969, Training Accuracy:  79.7%, Loss: 0.4055\n",
      "Optimization Iteration:  12033, Training Accuracy:  70.3%, Loss: 0.4291\n",
      "Optimization Iteration:  12097, Training Accuracy:  79.7%, Loss: 0.4198\n",
      "Optimization Iteration:  12161, Training Accuracy:  70.3%, Loss: 0.4516\n",
      "Optimization Iteration:  12225, Training Accuracy:  82.8%, Loss: 0.3976\n",
      "Optimization Iteration:  12289, Training Accuracy:  76.6%, Loss: 0.3802\n",
      "Optimization Iteration:  12353, Training Accuracy:  81.2%, Loss: 0.4169\n",
      "Optimization Iteration:  12417, Training Accuracy:  87.5%, Loss: 0.3494\n",
      "Optimization Iteration:  12481, Training Accuracy:  71.9%, Loss: 0.3985\n",
      "Optimization Iteration:  12545, Training Accuracy:  71.9%, Loss: 0.4027\n",
      "Optimization Iteration:  12609, Training Accuracy:  78.1%, Loss: 0.3742\n",
      "Optimization Iteration:  12673, Training Accuracy:  76.6%, Loss: 0.3419\n",
      "Optimization Iteration:  12737, Training Accuracy:  71.9%, Loss: 0.4509\n",
      "Optimization Iteration:  12801, Training Accuracy:  79.7%, Loss: 0.3868\n",
      "Optimization Iteration:  12865, Training Accuracy:  70.3%, Loss: 0.4652\n",
      "Optimization Iteration:  12929, Training Accuracy:  65.6%, Loss: 0.4710\n",
      "Optimization Iteration:  12993, Training Accuracy:  68.8%, Loss: 0.4192\n",
      "Optimization Iteration:  13057, Training Accuracy:  70.3%, Loss: 0.4455\n",
      "Optimization Iteration:  13121, Training Accuracy:  75.0%, Loss: 0.4123\n",
      "Optimization Iteration:  13185, Training Accuracy:  73.4%, Loss: 0.4717\n",
      "Optimization Iteration:  13249, Training Accuracy:  79.7%, Loss: 0.4104\n",
      "Optimization Iteration:  13313, Training Accuracy:  73.4%, Loss: 0.5388\n",
      "Optimization Iteration:  13377, Training Accuracy:  65.6%, Loss: 0.5271\n",
      "Optimization Iteration:  13441, Training Accuracy:  64.1%, Loss: 0.4269\n",
      "Optimization Iteration:  13505, Training Accuracy:  82.8%, Loss: 0.4080\n",
      "Optimization Iteration:  13569, Training Accuracy:  82.8%, Loss: 0.3167\n",
      "Optimization Iteration:  13633, Training Accuracy:  70.3%, Loss: 0.4157\n",
      "Optimization Iteration:  13697, Training Accuracy:  79.7%, Loss: 0.4216\n",
      "Optimization Iteration:  13761, Training Accuracy:  71.9%, Loss: 0.4037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  13825, Training Accuracy:  76.6%, Loss: 0.4174\n",
      "Optimization Iteration:  13889, Training Accuracy:  75.0%, Loss: 0.6270\n",
      "Optimization Iteration:  13953, Training Accuracy:  76.6%, Loss: 0.3716\n",
      "Optimization Iteration:  14017, Training Accuracy:  78.1%, Loss: 0.4817\n",
      "Optimization Iteration:  14081, Training Accuracy:  70.3%, Loss: 0.4144\n",
      "Optimization Iteration:  14145, Training Accuracy:  76.6%, Loss: 0.3787\n",
      "Optimization Iteration:  14209, Training Accuracy:  73.4%, Loss: 0.4764\n",
      "Optimization Iteration:  14273, Training Accuracy:  70.3%, Loss: 0.4311\n",
      "Optimization Iteration:  14337, Training Accuracy:  79.7%, Loss: 0.3193\n",
      "Optimization Iteration:  14401, Training Accuracy:  73.4%, Loss: 0.4279\n",
      "Optimization Iteration:  14465, Training Accuracy:  78.1%, Loss: 0.3880\n",
      "Optimization Iteration:  14529, Training Accuracy:  78.1%, Loss: 0.4774\n",
      "Optimization Iteration:  14593, Training Accuracy:  73.4%, Loss: 0.3740\n",
      "Optimization Iteration:  14657, Training Accuracy:  70.3%, Loss: 0.4909\n",
      "Optimization Iteration:  14721, Training Accuracy:  78.1%, Loss: 0.3699\n",
      "Optimization Iteration:  14785, Training Accuracy:  73.4%, Loss: 0.4846\n",
      "Optimization Iteration:  14849, Training Accuracy:  70.3%, Loss: 0.4403\n",
      "Optimization Iteration:  14913, Training Accuracy:  81.2%, Loss: 0.2949\n",
      "Optimization Iteration:  14977, Training Accuracy:  65.6%, Loss: 0.4907\n",
      "Optimization Iteration:  15041, Training Accuracy:  75.0%, Loss: 0.4104\n",
      "Optimization Iteration:  15105, Training Accuracy:  76.6%, Loss: 0.4186\n",
      "Optimization Iteration:  15169, Training Accuracy:  82.8%, Loss: 0.3671\n",
      "Optimization Iteration:  15233, Training Accuracy:  75.0%, Loss: 0.3936\n",
      "Optimization Iteration:  15297, Training Accuracy:  82.8%, Loss: 0.4045\n",
      "Optimization Iteration:  15361, Training Accuracy:  82.8%, Loss: 0.4440\n",
      "Optimization Iteration:  15425, Training Accuracy:  71.9%, Loss: 0.4575\n",
      "Optimization Iteration:  15489, Training Accuracy:  75.0%, Loss: 0.4746\n",
      "Optimization Iteration:  15553, Training Accuracy:  73.4%, Loss: 0.4140\n",
      "Optimization Iteration:  15617, Training Accuracy:  81.2%, Loss: 0.3659\n",
      "Optimization Iteration:  15681, Training Accuracy:  79.7%, Loss: 0.4204\n",
      "Optimization Iteration:  15745, Training Accuracy:  79.7%, Loss: 0.3595\n",
      "Optimization Iteration:  15809, Training Accuracy:  79.7%, Loss: 0.3668\n",
      "Optimization Iteration:  15873, Training Accuracy:  70.3%, Loss: 0.4628\n",
      "Optimization Iteration:  15937, Training Accuracy:  75.0%, Loss: 0.3839\n",
      "Optimization Iteration:  16001, Training Accuracy:  78.1%, Loss: 0.4541\n",
      "Optimization Iteration:  16065, Training Accuracy:  68.8%, Loss: 0.4564\n",
      "Optimization Iteration:  16129, Training Accuracy:  79.7%, Loss: 0.3895\n",
      "Optimization Iteration:  16193, Training Accuracy:  70.3%, Loss: 0.3881\n",
      "Optimization Iteration:  16257, Training Accuracy:  79.7%, Loss: 0.4264\n",
      "Optimization Iteration:  16321, Training Accuracy:  73.4%, Loss: 0.4292\n",
      "Optimization Iteration:  16385, Training Accuracy:  79.7%, Loss: 0.3959\n",
      "Optimization Iteration:  16449, Training Accuracy:  79.7%, Loss: 0.3683\n",
      "Optimization Iteration:  16513, Training Accuracy:  75.0%, Loss: 0.3631\n",
      "Optimization Iteration:  16577, Training Accuracy:  76.6%, Loss: 0.3964\n",
      "Optimization Iteration:  16641, Training Accuracy:  76.6%, Loss: 0.5305\n",
      "Optimization Iteration:  16705, Training Accuracy:  81.2%, Loss: 0.4153\n",
      "Optimization Iteration:  16769, Training Accuracy:  76.6%, Loss: 0.3867\n",
      "Optimization Iteration:  16833, Training Accuracy:  73.4%, Loss: 0.3998\n",
      "Optimization Iteration:  16897, Training Accuracy:  84.4%, Loss: 0.3387\n",
      "Optimization Iteration:  16961, Training Accuracy:  75.0%, Loss: 0.3888\n",
      "Optimization Iteration:  17025, Training Accuracy:  62.5%, Loss: 0.4779\n",
      "Optimization Iteration:  17089, Training Accuracy:  73.4%, Loss: 0.3856\n",
      "Optimization Iteration:  17153, Training Accuracy:  70.3%, Loss: 0.4298\n",
      "Optimization Iteration:  17217, Training Accuracy:  73.4%, Loss: 0.5142\n",
      "Optimization Iteration:  17281, Training Accuracy:  65.6%, Loss: 0.4691\n",
      "Optimization Iteration:  17345, Training Accuracy:  78.1%, Loss: 0.3423\n",
      "Optimization Iteration:  17409, Training Accuracy:  75.0%, Loss: 0.3764\n",
      "Optimization Iteration:  17473, Training Accuracy:  64.1%, Loss: 0.6015\n",
      "Optimization Iteration:  17537, Training Accuracy:  79.7%, Loss: 0.3592\n",
      "Optimization Iteration:  17601, Training Accuracy:  73.4%, Loss: 0.4298\n",
      "Optimization Iteration:  17665, Training Accuracy:  81.2%, Loss: 0.3655\n",
      "Optimization Iteration:  17729, Training Accuracy:  79.7%, Loss: 0.3452\n",
      "Optimization Iteration:  17793, Training Accuracy:  75.0%, Loss: 0.4067\n",
      "Optimization Iteration:  17857, Training Accuracy:  76.6%, Loss: 0.3970\n",
      "Optimization Iteration:  17921, Training Accuracy:  78.1%, Loss: 0.3795\n",
      "Optimization Iteration:  17985, Training Accuracy:  75.0%, Loss: 0.3744\n",
      "Optimization Iteration:  18049, Training Accuracy:  79.7%, Loss: 0.3695\n",
      "Optimization Iteration:  18113, Training Accuracy:  65.6%, Loss: 0.4698\n",
      "Optimization Iteration:  18177, Training Accuracy:  75.0%, Loss: 0.4929\n",
      "Optimization Iteration:  18241, Training Accuracy:  78.1%, Loss: 0.4434\n",
      "Optimization Iteration:  18305, Training Accuracy:  75.0%, Loss: 0.4043\n",
      "Optimization Iteration:  18369, Training Accuracy:  84.4%, Loss: 0.3581\n",
      "Optimization Iteration:  18433, Training Accuracy:  70.3%, Loss: 0.4120\n",
      "Optimization Iteration:  18497, Training Accuracy:  81.2%, Loss: 0.3184\n",
      "Optimization Iteration:  18561, Training Accuracy:  75.0%, Loss: 0.3893\n",
      "Optimization Iteration:  18625, Training Accuracy:  65.6%, Loss: 0.5019\n",
      "Optimization Iteration:  18689, Training Accuracy:  73.4%, Loss: 0.4105\n",
      "Optimization Iteration:  18753, Training Accuracy:  75.0%, Loss: 0.4328\n",
      "Optimization Iteration:  18817, Training Accuracy:  81.2%, Loss: 0.3522\n",
      "Optimization Iteration:  18881, Training Accuracy:  75.0%, Loss: 0.3676\n",
      "Optimization Iteration:  18945, Training Accuracy:  68.8%, Loss: 0.4712\n",
      "Optimization Iteration:  19009, Training Accuracy:  76.6%, Loss: 0.3831\n",
      "Optimization Iteration:  19073, Training Accuracy:  76.6%, Loss: 0.5046\n",
      "Optimization Iteration:  19137, Training Accuracy:  73.4%, Loss: 0.4210\n",
      "Optimization Iteration:  19201, Training Accuracy:  84.4%, Loss: 0.3362\n",
      "Optimization Iteration:  19265, Training Accuracy:  76.6%, Loss: 0.4338\n",
      "Optimization Iteration:  19329, Training Accuracy:  82.8%, Loss: 0.3401\n",
      "Optimization Iteration:  19393, Training Accuracy:  75.0%, Loss: 0.5372\n",
      "Optimization Iteration:  19457, Training Accuracy:  78.1%, Loss: 0.3454\n",
      "Optimization Iteration:  19521, Training Accuracy:  78.1%, Loss: 0.5061\n",
      "Optimization Iteration:  19585, Training Accuracy:  64.1%, Loss: 0.4518\n",
      "Optimization Iteration:  19649, Training Accuracy:  75.0%, Loss: 0.4070\n",
      "Optimization Iteration:  19713, Training Accuracy:  67.2%, Loss: 0.4182\n",
      "Optimization Iteration:  19777, Training Accuracy:  76.6%, Loss: 0.3749\n",
      "Optimization Iteration:  19841, Training Accuracy:  67.2%, Loss: 0.5117\n",
      "Optimization Iteration:  19905, Training Accuracy:  59.4%, Loss: 0.4680\n",
      "Optimization Iteration:  19969, Training Accuracy:  70.3%, Loss: 0.5144\n",
      "Optimization Iteration:  20033, Training Accuracy:  76.6%, Loss: 0.3800\n",
      "Optimization Iteration:  20097, Training Accuracy:  71.9%, Loss: 0.4277\n",
      "Optimization Iteration:  20161, Training Accuracy:  70.3%, Loss: 0.4339\n",
      "Optimization Iteration:  20225, Training Accuracy:  76.6%, Loss: 0.4819\n",
      "Optimization Iteration:  20289, Training Accuracy:  76.6%, Loss: 0.4369\n",
      "Optimization Iteration:  20353, Training Accuracy:  70.3%, Loss: 0.4185\n",
      "Optimization Iteration:  20417, Training Accuracy:  73.4%, Loss: 0.4895\n",
      "Optimization Iteration:  20481, Training Accuracy:  81.2%, Loss: 0.4030\n",
      "Optimization Iteration:  20545, Training Accuracy:  82.8%, Loss: 0.4049\n",
      "Optimization Iteration:  20609, Training Accuracy:  70.3%, Loss: 0.4963\n",
      "Optimization Iteration:  20673, Training Accuracy:  67.2%, Loss: 0.5095\n",
      "Optimization Iteration:  20737, Training Accuracy:  81.2%, Loss: 0.3510\n",
      "Optimization Iteration:  20801, Training Accuracy:  78.1%, Loss: 0.4394\n",
      "Optimization Iteration:  20865, Training Accuracy:  78.1%, Loss: 0.3283\n",
      "Optimization Iteration:  20929, Training Accuracy:  82.8%, Loss: 0.3863\n",
      "Optimization Iteration:  20993, Training Accuracy:  78.1%, Loss: 0.4594\n",
      "Optimization Iteration:  21057, Training Accuracy:  65.6%, Loss: 0.4534\n",
      "Optimization Iteration:  21121, Training Accuracy:  67.2%, Loss: 0.4453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  21185, Training Accuracy:  65.6%, Loss: 0.4858\n",
      "Optimization Iteration:  21249, Training Accuracy:  73.4%, Loss: 0.4641\n",
      "Optimization Iteration:  21313, Training Accuracy:  78.1%, Loss: 0.4302\n",
      "Optimization Iteration:  21377, Training Accuracy:  75.0%, Loss: 0.3299\n",
      "Optimization Iteration:  21441, Training Accuracy:  73.4%, Loss: 0.3696\n",
      "Optimization Iteration:  21505, Training Accuracy:  78.1%, Loss: 0.4207\n",
      "Optimization Iteration:  21569, Training Accuracy:  76.6%, Loss: 0.3816\n",
      "Optimization Iteration:  21633, Training Accuracy:  81.2%, Loss: 0.3256\n",
      "Optimization Iteration:  21697, Training Accuracy:  75.0%, Loss: 0.4726\n",
      "Optimization Iteration:  21761, Training Accuracy:  81.2%, Loss: 0.3565\n",
      "Optimization Iteration:  21825, Training Accuracy:  78.1%, Loss: 0.4268\n",
      "Optimization Iteration:  21889, Training Accuracy:  84.4%, Loss: 0.3807\n",
      "Optimization Iteration:  21953, Training Accuracy:  81.2%, Loss: 0.4858\n",
      "Optimization Iteration:  22017, Training Accuracy:  71.9%, Loss: 0.4343\n",
      "Optimization Iteration:  22081, Training Accuracy:  75.0%, Loss: 0.4358\n",
      "Optimization Iteration:  22145, Training Accuracy:  79.7%, Loss: 0.3812\n",
      "Optimization Iteration:  22209, Training Accuracy:  62.5%, Loss: 0.5228\n",
      "Optimization Iteration:  22273, Training Accuracy:  67.2%, Loss: 0.5105\n",
      "Optimization Iteration:  22337, Training Accuracy:  73.4%, Loss: 0.3691\n",
      "Optimization Iteration:  22401, Training Accuracy:  68.8%, Loss: 0.4603\n",
      "Optimization Iteration:  22465, Training Accuracy:  75.0%, Loss: 0.4411\n",
      "Optimization Iteration:  22529, Training Accuracy:  78.1%, Loss: 0.4171\n",
      "Optimization Iteration:  22593, Training Accuracy:  73.4%, Loss: 0.4132\n",
      "Optimization Iteration:  22657, Training Accuracy:  79.7%, Loss: 0.4323\n",
      "Optimization Iteration:  22721, Training Accuracy:  70.3%, Loss: 0.4696\n",
      "Optimization Iteration:  22785, Training Accuracy:  71.9%, Loss: 0.4644\n",
      "Optimization Iteration:  22849, Training Accuracy:  71.9%, Loss: 0.4287\n",
      "Optimization Iteration:  22913, Training Accuracy:  81.2%, Loss: 0.3544\n",
      "Optimization Iteration:  22977, Training Accuracy:  76.6%, Loss: 0.3435\n",
      "Optimization Iteration:  23041, Training Accuracy:  75.0%, Loss: 0.4037\n",
      "Optimization Iteration:  23105, Training Accuracy:  71.9%, Loss: 0.3394\n",
      "Optimization Iteration:  23169, Training Accuracy:  81.2%, Loss: 0.2686\n",
      "Optimization Iteration:  23233, Training Accuracy:  67.2%, Loss: 0.6052\n",
      "Optimization Iteration:  23297, Training Accuracy:  73.4%, Loss: 0.4635\n",
      "Optimization Iteration:  23361, Training Accuracy:  73.4%, Loss: 0.4428\n",
      "Optimization Iteration:  23425, Training Accuracy:  76.6%, Loss: 0.3905\n",
      "Optimization Iteration:  23489, Training Accuracy:  76.6%, Loss: 0.4621\n",
      "Optimization Iteration:  23553, Training Accuracy:  85.9%, Loss: 0.3077\n",
      "Optimization Iteration:  23617, Training Accuracy:  79.7%, Loss: 0.4505\n",
      "Optimization Iteration:  23681, Training Accuracy:  65.6%, Loss: 0.4868\n",
      "Optimization Iteration:  23745, Training Accuracy:  78.1%, Loss: 0.4108\n",
      "Optimization Iteration:  23809, Training Accuracy:  68.8%, Loss: 0.4153\n",
      "Optimization Iteration:  23873, Training Accuracy:  60.9%, Loss: 0.4269\n",
      "Optimization Iteration:  23937, Training Accuracy:  79.7%, Loss: 0.4221\n",
      "Optimization Iteration:  24001, Training Accuracy:  79.7%, Loss: 0.3381\n",
      "Optimization Iteration:  24065, Training Accuracy:  68.8%, Loss: 0.4443\n",
      "Optimization Iteration:  24129, Training Accuracy:  79.7%, Loss: 0.3700\n",
      "Optimization Iteration:  24193, Training Accuracy:  78.1%, Loss: 0.4243\n",
      "Optimization Iteration:  24257, Training Accuracy:  68.8%, Loss: 0.4144\n",
      "Optimization Iteration:  24321, Training Accuracy:  71.9%, Loss: 0.4633\n",
      "Optimization Iteration:  24385, Training Accuracy:  73.4%, Loss: 0.4006\n",
      "Optimization Iteration:  24449, Training Accuracy:  79.7%, Loss: 0.3368\n",
      "Optimization Iteration:  24513, Training Accuracy:  71.9%, Loss: 0.3895\n",
      "Optimization Iteration:  24577, Training Accuracy:  68.8%, Loss: 0.4916\n",
      "Optimization Iteration:  24641, Training Accuracy:  81.2%, Loss: 0.4452\n",
      "Optimization Iteration:  24705, Training Accuracy:  85.9%, Loss: 0.3453\n",
      "Optimization Iteration:  24769, Training Accuracy:  70.3%, Loss: 0.3584\n",
      "Optimization Iteration:  24833, Training Accuracy:  82.8%, Loss: 0.3461\n",
      "Optimization Iteration:  24897, Training Accuracy:  68.8%, Loss: 0.3953\n",
      "Optimization Iteration:  24961, Training Accuracy:  75.0%, Loss: 0.3560\n",
      "Optimization Iteration:  25025, Training Accuracy:  71.9%, Loss: 0.4300\n",
      "Optimization Iteration:  25089, Training Accuracy:  68.8%, Loss: 0.4316\n",
      "Optimization Iteration:  25153, Training Accuracy:  75.0%, Loss: 0.4151\n",
      "Optimization Iteration:  25217, Training Accuracy:  75.0%, Loss: 0.4748\n",
      "Optimization Iteration:  25281, Training Accuracy:  71.9%, Loss: 0.4637\n",
      "Optimization Iteration:  25345, Training Accuracy:  75.0%, Loss: 0.5461\n",
      "Optimization Iteration:  25409, Training Accuracy:  76.6%, Loss: 0.4075\n",
      "Optimization Iteration:  25473, Training Accuracy:  70.3%, Loss: 0.4640\n",
      "Optimization Iteration:  25537, Training Accuracy:  65.6%, Loss: 0.4840\n",
      "Optimization Iteration:  25601, Training Accuracy:  60.9%, Loss: 0.5489\n",
      "Optimization Iteration:  25665, Training Accuracy:  70.3%, Loss: 0.5107\n",
      "Optimization Iteration:  25729, Training Accuracy:  75.0%, Loss: 0.3424\n",
      "Optimization Iteration:  25793, Training Accuracy:  78.1%, Loss: 0.3482\n",
      "Optimization Iteration:  25857, Training Accuracy:  73.4%, Loss: 0.4583\n",
      "Optimization Iteration:  25921, Training Accuracy:  87.5%, Loss: 0.3501\n",
      "Optimization Iteration:  25985, Training Accuracy:  70.3%, Loss: 0.4910\n",
      "Optimization Iteration:  26049, Training Accuracy:  78.1%, Loss: 0.4163\n",
      "Optimization Iteration:  26113, Training Accuracy:  78.1%, Loss: 0.3855\n",
      "Optimization Iteration:  26177, Training Accuracy:  76.6%, Loss: 0.3940\n",
      "Optimization Iteration:  26241, Training Accuracy:  76.6%, Loss: 0.3955\n",
      "Optimization Iteration:  26305, Training Accuracy:  68.8%, Loss: 0.4711\n",
      "Optimization Iteration:  26369, Training Accuracy:  76.6%, Loss: 0.4120\n",
      "Optimization Iteration:  26433, Training Accuracy:  81.2%, Loss: 0.3802\n",
      "Optimization Iteration:  26497, Training Accuracy:  76.6%, Loss: 0.4401\n",
      "Optimization Iteration:  26561, Training Accuracy:  76.6%, Loss: 0.3556\n",
      "Optimization Iteration:  26625, Training Accuracy:  79.7%, Loss: 0.3721\n",
      "Optimization Iteration:  26689, Training Accuracy:  85.9%, Loss: 0.3545\n",
      "Optimization Iteration:  26753, Training Accuracy:  71.9%, Loss: 0.4584\n",
      "Optimization Iteration:  26817, Training Accuracy:  76.6%, Loss: 0.4166\n",
      "Optimization Iteration:  26881, Training Accuracy:  87.5%, Loss: 0.3096\n",
      "Optimization Iteration:  26945, Training Accuracy:  67.2%, Loss: 0.4725\n",
      "Optimization Iteration:  27009, Training Accuracy:  75.0%, Loss: 0.3447\n",
      "Optimization Iteration:  27073, Training Accuracy:  75.0%, Loss: 0.4367\n",
      "Optimization Iteration:  27137, Training Accuracy:  79.7%, Loss: 0.5275\n",
      "Optimization Iteration:  27201, Training Accuracy:  73.4%, Loss: 0.3659\n",
      "Optimization Iteration:  27265, Training Accuracy:  75.0%, Loss: 0.4291\n",
      "Optimization Iteration:  27329, Training Accuracy:  78.1%, Loss: 0.3677\n",
      "Optimization Iteration:  27393, Training Accuracy:  79.7%, Loss: 0.4376\n",
      "Optimization Iteration:  27457, Training Accuracy:  79.7%, Loss: 0.3682\n",
      "Optimization Iteration:  27521, Training Accuracy:  76.6%, Loss: 0.4205\n",
      "Optimization Iteration:  27585, Training Accuracy:  78.1%, Loss: 0.3428\n",
      "Optimization Iteration:  27649, Training Accuracy:  79.7%, Loss: 0.3942\n",
      "Optimization Iteration:  27713, Training Accuracy:  68.8%, Loss: 0.4352\n",
      "Optimization Iteration:  27777, Training Accuracy:  79.7%, Loss: 0.3415\n",
      "Optimization Iteration:  27841, Training Accuracy:  70.3%, Loss: 0.4849\n",
      "Optimization Iteration:  27905, Training Accuracy:  73.4%, Loss: 0.4642\n",
      "Optimization Iteration:  27969, Training Accuracy:  78.1%, Loss: 0.4699\n",
      "Optimization Iteration:  28033, Training Accuracy:  65.6%, Loss: 0.4410\n",
      "Optimization Iteration:  28097, Training Accuracy:  78.1%, Loss: 0.4007\n",
      "Optimization Iteration:  28161, Training Accuracy:  85.9%, Loss: 0.3384\n",
      "Optimization Iteration:  28225, Training Accuracy:  70.3%, Loss: 0.3939\n",
      "Optimization Iteration:  28289, Training Accuracy:  71.9%, Loss: 0.4103\n",
      "Optimization Iteration:  28353, Training Accuracy:  70.3%, Loss: 0.4286\n",
      "Optimization Iteration:  28417, Training Accuracy:  76.6%, Loss: 0.4173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  28481, Training Accuracy:  84.4%, Loss: 0.3202\n",
      "Optimization Iteration:  28545, Training Accuracy:  73.4%, Loss: 0.3910\n",
      "Optimization Iteration:  28609, Training Accuracy:  84.4%, Loss: 0.3817\n",
      "Optimization Iteration:  28673, Training Accuracy:  73.4%, Loss: 0.3838\n",
      "Optimization Iteration:  28737, Training Accuracy:  73.4%, Loss: 0.3988\n",
      "Optimization Iteration:  28801, Training Accuracy:  75.0%, Loss: 0.3867\n",
      "Optimization Iteration:  28865, Training Accuracy:  85.9%, Loss: 0.2542\n",
      "Optimization Iteration:  28929, Training Accuracy:  75.0%, Loss: 0.3383\n",
      "Optimization Iteration:  28993, Training Accuracy:  65.6%, Loss: 0.4640\n",
      "Optimization Iteration:  29057, Training Accuracy:  67.2%, Loss: 0.4545\n",
      "Optimization Iteration:  29121, Training Accuracy:  60.9%, Loss: 0.6173\n",
      "Optimization Iteration:  29185, Training Accuracy:  76.6%, Loss: 0.3380\n",
      "Optimization Iteration:  29249, Training Accuracy:  78.1%, Loss: 0.4312\n",
      "Optimization Iteration:  29313, Training Accuracy:  75.0%, Loss: 0.4381\n",
      "Optimization Iteration:  29377, Training Accuracy:  73.4%, Loss: 0.3825\n",
      "Optimization Iteration:  29441, Training Accuracy:  76.6%, Loss: 0.4608\n",
      "Optimization Iteration:  29505, Training Accuracy:  81.2%, Loss: 0.3540\n",
      "Optimization Iteration:  29569, Training Accuracy:  73.4%, Loss: 0.4528\n",
      "Optimization Iteration:  29633, Training Accuracy:  75.0%, Loss: 0.4212\n",
      "Optimization Iteration:  29697, Training Accuracy:  71.9%, Loss: 0.4267\n",
      "Optimization Iteration:  29761, Training Accuracy:  81.2%, Loss: 0.3602\n",
      "Optimization Iteration:  29825, Training Accuracy:  68.8%, Loss: 0.4736\n",
      "Optimization Iteration:  29889, Training Accuracy:  82.8%, Loss: 0.4374\n",
      "Optimization Iteration:  29953, Training Accuracy:  64.1%, Loss: 0.4667\n",
      "Optimization Iteration:  30017, Training Accuracy:  78.1%, Loss: 0.3157\n",
      "Optimization Iteration:  30081, Training Accuracy:  82.8%, Loss: 0.4029\n",
      "Optimization Iteration:  30145, Training Accuracy:  75.0%, Loss: 0.4458\n",
      "Optimization Iteration:  30209, Training Accuracy:  68.8%, Loss: 0.4446\n",
      "Optimization Iteration:  30273, Training Accuracy:  76.6%, Loss: 0.3830\n",
      "Optimization Iteration:  30337, Training Accuracy:  75.0%, Loss: 0.3949\n",
      "Optimization Iteration:  30401, Training Accuracy:  82.8%, Loss: 0.4223\n",
      "Optimization Iteration:  30465, Training Accuracy:  71.9%, Loss: 0.4950\n",
      "Optimization Iteration:  30529, Training Accuracy:  81.2%, Loss: 0.4057\n",
      "Optimization Iteration:  30593, Training Accuracy:  78.1%, Loss: 0.4129\n",
      "Optimization Iteration:  30657, Training Accuracy:  81.2%, Loss: 0.3489\n",
      "Optimization Iteration:  30721, Training Accuracy:  70.3%, Loss: 0.4288\n",
      "Optimization Iteration:  30785, Training Accuracy:  68.8%, Loss: 0.4007\n",
      "Optimization Iteration:  30849, Training Accuracy:  73.4%, Loss: 0.4187\n",
      "Optimization Iteration:  30913, Training Accuracy:  76.6%, Loss: 0.4127\n",
      "Optimization Iteration:  30977, Training Accuracy:  75.0%, Loss: 0.4279\n",
      "Optimization Iteration:  31041, Training Accuracy:  71.9%, Loss: 0.4107\n",
      "Optimization Iteration:  31105, Training Accuracy:  71.9%, Loss: 0.4162\n",
      "Optimization Iteration:  31169, Training Accuracy:  78.1%, Loss: 0.3496\n",
      "Optimization Iteration:  31233, Training Accuracy:  75.0%, Loss: 0.4303\n",
      "Optimization Iteration:  31297, Training Accuracy:  73.4%, Loss: 0.3680\n",
      "Optimization Iteration:  31361, Training Accuracy:  75.0%, Loss: 0.4305\n",
      "Optimization Iteration:  31425, Training Accuracy:  87.5%, Loss: 0.3275\n",
      "Optimization Iteration:  31489, Training Accuracy:  78.1%, Loss: 0.3913\n",
      "Optimization Iteration:  31553, Training Accuracy:  84.4%, Loss: 0.3358\n",
      "Optimization Iteration:  31617, Training Accuracy:  82.8%, Loss: 0.3319\n",
      "Optimization Iteration:  31681, Training Accuracy:  85.9%, Loss: 0.3919\n",
      "Optimization Iteration:  31745, Training Accuracy:  73.4%, Loss: 0.4400\n",
      "Optimization Iteration:  31809, Training Accuracy:  75.0%, Loss: 0.4620\n",
      "Optimization Iteration:  31873, Training Accuracy:  85.9%, Loss: 0.2989\n",
      "Optimization Iteration:  31937, Training Accuracy:  70.3%, Loss: 0.5492\n",
      "Optimization Iteration:  32001, Training Accuracy:  68.8%, Loss: 0.4464\n",
      "Optimization Iteration:  32065, Training Accuracy:  70.3%, Loss: 0.4050\n",
      "Optimization Iteration:  32129, Training Accuracy:  71.9%, Loss: 0.4317\n",
      "Optimization Iteration:  32193, Training Accuracy:  75.0%, Loss: 0.4541\n",
      "Optimization Iteration:  32257, Training Accuracy:  73.4%, Loss: 0.4157\n",
      "Optimization Iteration:  32321, Training Accuracy:  78.1%, Loss: 0.3743\n",
      "Optimization Iteration:  32385, Training Accuracy:  79.7%, Loss: 0.4473\n",
      "Optimization Iteration:  32449, Training Accuracy:  70.3%, Loss: 0.4551\n",
      "Optimization Iteration:  32513, Training Accuracy:  73.4%, Loss: 0.4129\n",
      "Optimization Iteration:  32577, Training Accuracy:  70.3%, Loss: 0.4250\n",
      "Optimization Iteration:  32641, Training Accuracy:  70.3%, Loss: 0.4742\n",
      "Optimization Iteration:  32705, Training Accuracy:  78.1%, Loss: 0.4048\n",
      "Optimization Iteration:  32769, Training Accuracy:  76.6%, Loss: 0.3577\n",
      "Optimization Iteration:  32833, Training Accuracy:  75.0%, Loss: 0.3914\n",
      "Optimization Iteration:  32897, Training Accuracy:  68.8%, Loss: 0.4574\n",
      "Optimization Iteration:  32961, Training Accuracy:  79.7%, Loss: 0.3970\n",
      "Optimization Iteration:  33025, Training Accuracy:  81.2%, Loss: 0.4076\n",
      "Optimization Iteration:  33089, Training Accuracy:  65.6%, Loss: 0.4855\n",
      "Optimization Iteration:  33153, Training Accuracy:  68.8%, Loss: 0.4333\n",
      "Optimization Iteration:  33217, Training Accuracy:  71.9%, Loss: 0.4160\n",
      "Optimization Iteration:  33281, Training Accuracy:  71.9%, Loss: 0.5670\n",
      "Optimization Iteration:  33345, Training Accuracy:  71.9%, Loss: 0.4634\n",
      "Optimization Iteration:  33409, Training Accuracy:  76.6%, Loss: 0.4110\n",
      "Optimization Iteration:  33473, Training Accuracy:  75.0%, Loss: 0.4399\n",
      "Optimization Iteration:  33537, Training Accuracy:  68.8%, Loss: 0.4415\n",
      "Optimization Iteration:  33601, Training Accuracy:  79.7%, Loss: 0.4816\n",
      "Optimization Iteration:  33665, Training Accuracy:  81.2%, Loss: 0.4082\n",
      "Optimization Iteration:  33729, Training Accuracy:  71.9%, Loss: 0.4250\n",
      "Optimization Iteration:  33793, Training Accuracy:  64.1%, Loss: 0.4594\n",
      "Optimization Iteration:  33857, Training Accuracy:  81.2%, Loss: 0.3898\n",
      "Optimization Iteration:  33921, Training Accuracy:  79.7%, Loss: 0.3431\n",
      "Optimization Iteration:  33985, Training Accuracy:  79.7%, Loss: 0.3753\n",
      "Optimization Iteration:  34049, Training Accuracy:  73.4%, Loss: 0.4550\n",
      "Optimization Iteration:  34113, Training Accuracy:  78.1%, Loss: 0.3659\n",
      "Optimization Iteration:  34177, Training Accuracy:  68.8%, Loss: 0.4019\n",
      "Optimization Iteration:  34241, Training Accuracy:  82.8%, Loss: 0.3608\n",
      "Optimization Iteration:  34305, Training Accuracy:  62.5%, Loss: 0.4592\n",
      "Optimization Iteration:  34369, Training Accuracy:  78.1%, Loss: 0.3064\n",
      "Optimization Iteration:  34433, Training Accuracy:  73.4%, Loss: 0.5081\n",
      "Optimization Iteration:  34497, Training Accuracy:  79.7%, Loss: 0.3385\n",
      "Optimization Iteration:  34561, Training Accuracy:  82.8%, Loss: 0.3860\n",
      "Optimization Iteration:  34625, Training Accuracy:  70.3%, Loss: 0.4997\n",
      "Optimization Iteration:  34689, Training Accuracy:  68.8%, Loss: 0.5017\n",
      "Optimization Iteration:  34753, Training Accuracy:  82.8%, Loss: 0.4125\n",
      "Optimization Iteration:  34817, Training Accuracy:  70.3%, Loss: 0.4711\n",
      "Optimization Iteration:  34881, Training Accuracy:  70.3%, Loss: 0.3564\n",
      "Optimization Iteration:  34945, Training Accuracy:  75.0%, Loss: 0.4523\n",
      "Optimization Iteration:  35009, Training Accuracy:  84.4%, Loss: 0.3478\n",
      "Optimization Iteration:  35073, Training Accuracy:  75.0%, Loss: 0.3737\n",
      "Optimization Iteration:  35137, Training Accuracy:  81.2%, Loss: 0.3698\n",
      "Optimization Iteration:  35201, Training Accuracy:  78.1%, Loss: 0.3341\n",
      "Optimization Iteration:  35265, Training Accuracy:  81.2%, Loss: 0.3598\n",
      "Optimization Iteration:  35329, Training Accuracy:  84.4%, Loss: 0.3838\n",
      "Optimization Iteration:  35393, Training Accuracy:  65.6%, Loss: 0.3922\n",
      "Optimization Iteration:  35457, Training Accuracy:  73.4%, Loss: 0.3676\n",
      "Optimization Iteration:  35521, Training Accuracy:  70.3%, Loss: 0.4369\n",
      "Optimization Iteration:  35585, Training Accuracy:  79.7%, Loss: 0.3305\n",
      "Optimization Iteration:  35649, Training Accuracy:  85.9%, Loss: 0.3746\n",
      "Optimization Iteration:  35713, Training Accuracy:  81.2%, Loss: 0.4082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  35777, Training Accuracy:  85.9%, Loss: 0.3455\n",
      "Optimization Iteration:  35841, Training Accuracy:  68.8%, Loss: 0.4586\n",
      "Optimization Iteration:  35905, Training Accuracy:  79.7%, Loss: 0.3829\n",
      "Optimization Iteration:  35969, Training Accuracy:  73.4%, Loss: 0.4473\n",
      "Optimization Iteration:  36033, Training Accuracy:  79.7%, Loss: 0.3436\n",
      "Optimization Iteration:  36097, Training Accuracy:  67.2%, Loss: 0.4616\n",
      "Optimization Iteration:  36161, Training Accuracy:  79.7%, Loss: 0.3362\n",
      "Optimization Iteration:  36225, Training Accuracy:  73.4%, Loss: 0.3656\n",
      "Optimization Iteration:  36289, Training Accuracy:  70.3%, Loss: 0.3840\n",
      "Optimization Iteration:  36353, Training Accuracy:  75.0%, Loss: 0.3591\n",
      "Optimization Iteration:  36417, Training Accuracy:  73.4%, Loss: 0.4804\n",
      "Optimization Iteration:  36481, Training Accuracy:  70.3%, Loss: 0.3590\n",
      "Optimization Iteration:  36545, Training Accuracy:  79.7%, Loss: 0.3603\n",
      "Optimization Iteration:  36609, Training Accuracy:  81.2%, Loss: 0.3723\n",
      "Optimization Iteration:  36673, Training Accuracy:  73.4%, Loss: 0.4396\n",
      "Optimization Iteration:  36737, Training Accuracy:  81.2%, Loss: 0.4000\n",
      "Optimization Iteration:  36801, Training Accuracy:  75.0%, Loss: 0.4157\n",
      "Optimization Iteration:  36865, Training Accuracy:  73.4%, Loss: 0.4088\n",
      "Optimization Iteration:  36929, Training Accuracy:  75.0%, Loss: 0.4314\n",
      "Optimization Iteration:  36993, Training Accuracy:  78.1%, Loss: 0.3937\n",
      "Optimization Iteration:  37057, Training Accuracy:  78.1%, Loss: 0.3580\n",
      "Optimization Iteration:  37121, Training Accuracy:  76.6%, Loss: 0.3609\n",
      "Optimization Iteration:  37185, Training Accuracy:  78.1%, Loss: 0.3757\n",
      "Optimization Iteration:  37249, Training Accuracy:  75.0%, Loss: 0.4339\n",
      "Optimization Iteration:  37313, Training Accuracy:  85.9%, Loss: 0.2769\n",
      "Optimization Iteration:  37377, Training Accuracy:  70.3%, Loss: 0.7014\n",
      "Optimization Iteration:  37441, Training Accuracy:  76.6%, Loss: 0.3907\n",
      "Optimization Iteration:  37505, Training Accuracy:  73.4%, Loss: 0.4308\n",
      "Optimization Iteration:  37569, Training Accuracy:  78.1%, Loss: 0.4437\n",
      "Optimization Iteration:  37633, Training Accuracy:  70.3%, Loss: 0.4676\n",
      "Optimization Iteration:  37697, Training Accuracy:  73.4%, Loss: 0.4547\n",
      "Optimization Iteration:  37761, Training Accuracy:  78.1%, Loss: 0.3795\n",
      "Optimization Iteration:  37825, Training Accuracy:  78.1%, Loss: 0.3990\n",
      "Optimization Iteration:  37889, Training Accuracy:  73.4%, Loss: 0.3813\n",
      "Optimization Iteration:  37953, Training Accuracy:  73.4%, Loss: 0.3952\n",
      "Optimization Iteration:  38017, Training Accuracy:  73.4%, Loss: 0.4069\n",
      "Optimization Iteration:  38081, Training Accuracy:  75.0%, Loss: 0.4205\n",
      "Optimization Iteration:  38145, Training Accuracy:  71.9%, Loss: 0.3959\n",
      "Optimization Iteration:  38209, Training Accuracy:  76.6%, Loss: 0.4314\n",
      "Optimization Iteration:  38273, Training Accuracy:  73.4%, Loss: 0.3828\n",
      "Optimization Iteration:  38337, Training Accuracy:  84.4%, Loss: 0.3124\n",
      "Optimization Iteration:  38401, Training Accuracy:  81.2%, Loss: 0.3672\n",
      "Optimization Iteration:  38465, Training Accuracy:  75.0%, Loss: 0.4636\n",
      "Optimization Iteration:  38529, Training Accuracy:  75.0%, Loss: 0.4287\n",
      "Optimization Iteration:  38593, Training Accuracy:  71.9%, Loss: 0.4674\n",
      "Optimization Iteration:  38657, Training Accuracy:  71.9%, Loss: 0.4697\n",
      "Optimization Iteration:  38721, Training Accuracy:  81.2%, Loss: 0.3733\n",
      "Optimization Iteration:  38785, Training Accuracy:  67.2%, Loss: 0.4683\n",
      "Optimization Iteration:  38849, Training Accuracy:  76.6%, Loss: 0.3453\n",
      "Optimization Iteration:  38913, Training Accuracy:  71.9%, Loss: 0.4003\n",
      "Optimization Iteration:  38977, Training Accuracy:  68.8%, Loss: 0.4306\n",
      "Optimization Iteration:  39041, Training Accuracy:  75.0%, Loss: 0.3679\n",
      "Optimization Iteration:  39105, Training Accuracy:  65.6%, Loss: 0.5207\n",
      "Optimization Iteration:  39169, Training Accuracy:  70.3%, Loss: 0.4121\n",
      "Optimization Iteration:  39233, Training Accuracy:  75.0%, Loss: 0.4099\n",
      "Optimization Iteration:  39297, Training Accuracy:  73.4%, Loss: 0.3778\n",
      "Optimization Iteration:  39361, Training Accuracy:  75.0%, Loss: 0.4220\n",
      "Optimization Iteration:  39425, Training Accuracy:  75.0%, Loss: 0.4170\n",
      "Optimization Iteration:  39489, Training Accuracy:  78.1%, Loss: 0.3259\n",
      "Optimization Iteration:  39553, Training Accuracy:  71.9%, Loss: 0.4095\n",
      "Optimization Iteration:  39617, Training Accuracy:  70.3%, Loss: 0.4663\n",
      "Optimization Iteration:  39681, Training Accuracy:  59.4%, Loss: 0.4485\n",
      "Optimization Iteration:  39745, Training Accuracy:  68.8%, Loss: 0.4734\n",
      "Optimization Iteration:  39809, Training Accuracy:  71.9%, Loss: 0.5736\n",
      "Optimization Iteration:  39873, Training Accuracy:  71.9%, Loss: 0.4502\n",
      "Optimization Iteration:  39937, Training Accuracy:  75.0%, Loss: 0.4872\n",
      "Optimization Iteration:  40001, Training Accuracy:  70.3%, Loss: 0.4913\n",
      "Optimization Iteration:  40065, Training Accuracy:  68.8%, Loss: 0.3967\n",
      "Optimization Iteration:  40129, Training Accuracy:  67.2%, Loss: 0.4846\n",
      "Optimization Iteration:  40193, Training Accuracy:  79.7%, Loss: 0.3930\n",
      "Optimization Iteration:  40257, Training Accuracy:  71.9%, Loss: 0.4289\n",
      "Optimization Iteration:  40321, Training Accuracy:  70.3%, Loss: 0.4569\n",
      "Optimization Iteration:  40385, Training Accuracy:  73.4%, Loss: 0.5186\n",
      "Optimization Iteration:  40449, Training Accuracy:  73.4%, Loss: 0.4168\n",
      "Optimization Iteration:  40513, Training Accuracy:  76.6%, Loss: 0.4043\n",
      "Optimization Iteration:  40577, Training Accuracy:  73.4%, Loss: 0.4036\n",
      "Optimization Iteration:  40641, Training Accuracy:  79.7%, Loss: 0.3687\n",
      "Optimization Iteration:  40705, Training Accuracy:  82.8%, Loss: 0.3808\n",
      "Optimization Iteration:  40769, Training Accuracy:  76.6%, Loss: 0.4002\n",
      "Optimization Iteration:  40833, Training Accuracy:  84.4%, Loss: 0.3813\n",
      "Optimization Iteration:  40897, Training Accuracy:  78.1%, Loss: 0.3591\n",
      "Optimization Iteration:  40961, Training Accuracy:  79.7%, Loss: 0.3832\n",
      "Optimization Iteration:  41025, Training Accuracy:  79.7%, Loss: 0.4550\n",
      "Optimization Iteration:  41089, Training Accuracy:  79.7%, Loss: 0.4112\n",
      "Optimization Iteration:  41153, Training Accuracy:  82.8%, Loss: 0.3616\n",
      "Optimization Iteration:  41217, Training Accuracy:  78.1%, Loss: 0.3571\n",
      "Optimization Iteration:  41281, Training Accuracy:  65.6%, Loss: 0.4652\n",
      "Optimization Iteration:  41345, Training Accuracy:  68.8%, Loss: 0.4242\n",
      "Optimization Iteration:  41409, Training Accuracy:  81.2%, Loss: 0.3607\n",
      "Optimization Iteration:  41473, Training Accuracy:  71.9%, Loss: 0.4635\n",
      "Optimization Iteration:  41537, Training Accuracy:  75.0%, Loss: 0.4342\n",
      "Optimization Iteration:  41601, Training Accuracy:  73.4%, Loss: 0.4666\n",
      "Optimization Iteration:  41665, Training Accuracy:  68.8%, Loss: 0.4006\n",
      "Optimization Iteration:  41729, Training Accuracy:  84.4%, Loss: 0.3301\n",
      "Optimization Iteration:  41793, Training Accuracy:  79.7%, Loss: 0.4130\n",
      "Optimization Iteration:  41857, Training Accuracy:  70.3%, Loss: 0.4423\n",
      "Optimization Iteration:  41921, Training Accuracy:  71.9%, Loss: 0.4048\n",
      "Optimization Iteration:  41985, Training Accuracy:  67.2%, Loss: 0.5307\n",
      "Optimization Iteration:  42049, Training Accuracy:  70.3%, Loss: 0.4231\n",
      "Optimization Iteration:  42113, Training Accuracy:  67.2%, Loss: 0.4428\n",
      "Optimization Iteration:  42177, Training Accuracy:  71.9%, Loss: 0.4399\n",
      "Optimization Iteration:  42241, Training Accuracy:  81.2%, Loss: 0.3854\n",
      "Optimization Iteration:  42305, Training Accuracy:  76.6%, Loss: 0.4463\n",
      "Optimization Iteration:  42369, Training Accuracy:  75.0%, Loss: 0.4199\n",
      "Optimization Iteration:  42433, Training Accuracy:  70.3%, Loss: 0.4498\n",
      "Optimization Iteration:  42497, Training Accuracy:  70.3%, Loss: 0.4044\n",
      "Optimization Iteration:  42561, Training Accuracy:  78.1%, Loss: 0.3921\n",
      "Optimization Iteration:  42625, Training Accuracy:  75.0%, Loss: 0.4313\n",
      "Optimization Iteration:  42689, Training Accuracy:  87.5%, Loss: 0.3615\n",
      "Optimization Iteration:  42753, Training Accuracy:  67.2%, Loss: 0.4452\n",
      "Optimization Iteration:  42817, Training Accuracy:  85.9%, Loss: 0.3123\n",
      "Optimization Iteration:  42881, Training Accuracy:  65.6%, Loss: 0.5213\n",
      "Optimization Iteration:  42945, Training Accuracy:  68.8%, Loss: 0.4451\n",
      "Optimization Iteration:  43009, Training Accuracy:  73.4%, Loss: 0.4239\n",
      "Optimization Iteration:  43073, Training Accuracy:  70.3%, Loss: 0.4084\n",
      "Optimization Iteration:  43137, Training Accuracy:  75.0%, Loss: 0.4119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  43201, Training Accuracy:  81.2%, Loss: 0.3736\n",
      "Optimization Iteration:  43265, Training Accuracy:  84.4%, Loss: 0.3972\n",
      "Optimization Iteration:  43329, Training Accuracy:  78.1%, Loss: 0.4548\n",
      "Optimization Iteration:  43393, Training Accuracy:  76.6%, Loss: 0.3755\n",
      "Optimization Iteration:  43457, Training Accuracy:  81.2%, Loss: 0.3405\n",
      "Optimization Iteration:  43521, Training Accuracy:  81.2%, Loss: 0.3676\n",
      "Optimization Iteration:  43585, Training Accuracy:  79.7%, Loss: 0.3848\n",
      "Optimization Iteration:  43649, Training Accuracy:  73.4%, Loss: 0.4861\n",
      "Optimization Iteration:  43713, Training Accuracy:  79.7%, Loss: 0.3307\n",
      "Optimization Iteration:  43777, Training Accuracy:  82.8%, Loss: 0.2934\n",
      "Optimization Iteration:  43841, Training Accuracy:  65.6%, Loss: 0.4492\n",
      "Optimization Iteration:  43905, Training Accuracy:  81.2%, Loss: 0.3830\n",
      "Optimization Iteration:  43969, Training Accuracy:  78.1%, Loss: 0.3903\n",
      "Optimization Iteration:  44033, Training Accuracy:  78.1%, Loss: 0.4018\n",
      "Optimization Iteration:  44097, Training Accuracy:  78.1%, Loss: 0.4263\n",
      "Optimization Iteration:  44161, Training Accuracy:  78.1%, Loss: 0.3612\n",
      "Optimization Iteration:  44225, Training Accuracy:  76.6%, Loss: 0.4125\n",
      "Optimization Iteration:  44289, Training Accuracy:  75.0%, Loss: 0.4110\n",
      "Optimization Iteration:  44353, Training Accuracy:  78.1%, Loss: 0.3939\n",
      "Optimization Iteration:  44417, Training Accuracy:  71.9%, Loss: 0.3937\n",
      "Optimization Iteration:  44481, Training Accuracy:  71.9%, Loss: 0.4385\n",
      "Optimization Iteration:  44545, Training Accuracy:  79.7%, Loss: 0.3190\n",
      "Optimization Iteration:  44609, Training Accuracy:  85.9%, Loss: 0.3167\n",
      "Optimization Iteration:  44673, Training Accuracy:  78.1%, Loss: 0.4736\n",
      "Optimization Iteration:  44737, Training Accuracy:  79.7%, Loss: 0.4060\n",
      "Optimization Iteration:  44801, Training Accuracy:  65.6%, Loss: 0.4113\n",
      "Optimization Iteration:  44865, Training Accuracy:  73.4%, Loss: 0.4016\n",
      "Optimization Iteration:  44929, Training Accuracy:  79.7%, Loss: 0.4031\n",
      "Optimization Iteration:  44993, Training Accuracy:  73.4%, Loss: 0.4980\n",
      "Optimization Iteration:  45057, Training Accuracy:  71.9%, Loss: 0.4454\n",
      "Optimization Iteration:  45121, Training Accuracy:  76.6%, Loss: 0.3815\n",
      "Optimization Iteration:  45185, Training Accuracy:  75.0%, Loss: 0.3839\n",
      "Optimization Iteration:  45249, Training Accuracy:  75.0%, Loss: 0.4440\n",
      "Optimization Iteration:  45313, Training Accuracy:  82.8%, Loss: 0.3519\n",
      "Optimization Iteration:  45377, Training Accuracy:  67.2%, Loss: 0.4954\n",
      "Optimization Iteration:  45441, Training Accuracy:  78.1%, Loss: 0.4099\n",
      "Optimization Iteration:  45505, Training Accuracy:  71.9%, Loss: 0.3733\n",
      "Optimization Iteration:  45569, Training Accuracy:  68.8%, Loss: 0.4371\n",
      "Optimization Iteration:  45633, Training Accuracy:  73.4%, Loss: 0.4522\n",
      "Optimization Iteration:  45697, Training Accuracy:  78.1%, Loss: 0.3319\n",
      "Optimization Iteration:  45761, Training Accuracy:  81.2%, Loss: 0.3702\n",
      "Optimization Iteration:  45825, Training Accuracy:  71.9%, Loss: 0.4005\n",
      "Optimization Iteration:  45889, Training Accuracy:  78.1%, Loss: 0.3877\n",
      "Optimization Iteration:  45953, Training Accuracy:  79.7%, Loss: 0.3682\n",
      "Optimization Iteration:  46017, Training Accuracy:  73.4%, Loss: 0.4088\n",
      "Optimization Iteration:  46081, Training Accuracy:  68.8%, Loss: 0.4138\n",
      "Optimization Iteration:  46145, Training Accuracy:  76.6%, Loss: 0.3825\n",
      "Optimization Iteration:  46209, Training Accuracy:  76.6%, Loss: 0.3901\n",
      "Optimization Iteration:  46273, Training Accuracy:  73.4%, Loss: 0.4884\n",
      "Optimization Iteration:  46337, Training Accuracy:  73.4%, Loss: 0.4758\n",
      "Optimization Iteration:  46401, Training Accuracy:  76.6%, Loss: 0.3723\n",
      "Optimization Iteration:  46465, Training Accuracy:  76.6%, Loss: 0.4069\n",
      "Optimization Iteration:  46529, Training Accuracy:  71.9%, Loss: 0.4480\n",
      "Optimization Iteration:  46593, Training Accuracy:  73.4%, Loss: 0.4480\n",
      "Optimization Iteration:  46657, Training Accuracy:  76.6%, Loss: 0.4156\n",
      "Optimization Iteration:  46721, Training Accuracy:  71.9%, Loss: 0.4114\n",
      "Optimization Iteration:  46785, Training Accuracy:  68.8%, Loss: 0.4980\n",
      "Optimization Iteration:  46849, Training Accuracy:  71.9%, Loss: 0.4087\n",
      "Optimization Iteration:  46913, Training Accuracy:  89.1%, Loss: 0.3341\n",
      "Optimization Iteration:  46977, Training Accuracy:  73.4%, Loss: 0.4134\n",
      "Optimization Iteration:  47041, Training Accuracy:  81.2%, Loss: 0.3647\n",
      "Optimization Iteration:  47105, Training Accuracy:  68.8%, Loss: 0.4719\n",
      "Optimization Iteration:  47169, Training Accuracy:  73.4%, Loss: 0.4232\n",
      "Optimization Iteration:  47233, Training Accuracy:  70.3%, Loss: 0.4426\n",
      "Optimization Iteration:  47297, Training Accuracy:  78.1%, Loss: 0.3768\n",
      "Optimization Iteration:  47361, Training Accuracy:  68.8%, Loss: 0.4212\n",
      "Optimization Iteration:  47425, Training Accuracy:  82.8%, Loss: 0.3443\n",
      "Optimization Iteration:  47489, Training Accuracy:  64.1%, Loss: 0.4388\n",
      "Optimization Iteration:  47553, Training Accuracy:  78.1%, Loss: 0.4501\n",
      "Optimization Iteration:  47617, Training Accuracy:  78.1%, Loss: 0.3769\n",
      "Optimization Iteration:  47681, Training Accuracy:  84.4%, Loss: 0.4006\n",
      "Optimization Iteration:  47745, Training Accuracy:  70.3%, Loss: 0.4548\n",
      "Optimization Iteration:  47809, Training Accuracy:  75.0%, Loss: 0.4923\n",
      "Optimization Iteration:  47873, Training Accuracy:  85.9%, Loss: 0.2534\n",
      "Optimization Iteration:  47937, Training Accuracy:  78.1%, Loss: 0.3665\n",
      "Optimization Iteration:  48001, Training Accuracy:  79.7%, Loss: 0.4452\n",
      "Optimization Iteration:  48065, Training Accuracy:  78.1%, Loss: 0.3698\n",
      "Optimization Iteration:  48129, Training Accuracy:  71.9%, Loss: 0.4749\n",
      "Optimization Iteration:  48193, Training Accuracy:  64.1%, Loss: 0.5191\n",
      "Optimization Iteration:  48257, Training Accuracy:  78.1%, Loss: 0.3447\n",
      "Optimization Iteration:  48321, Training Accuracy:  70.3%, Loss: 0.4279\n",
      "Optimization Iteration:  48385, Training Accuracy:  70.3%, Loss: 0.4134\n",
      "Optimization Iteration:  48449, Training Accuracy:  70.3%, Loss: 0.4165\n",
      "Optimization Iteration:  48513, Training Accuracy:  75.0%, Loss: 0.3857\n",
      "Optimization Iteration:  48577, Training Accuracy:  73.4%, Loss: 0.4417\n",
      "Optimization Iteration:  48641, Training Accuracy:  73.4%, Loss: 0.3937\n",
      "Optimization Iteration:  48705, Training Accuracy:  84.4%, Loss: 0.3686\n",
      "Optimization Iteration:  48769, Training Accuracy:  71.9%, Loss: 0.3927\n",
      "Optimization Iteration:  48833, Training Accuracy:  84.4%, Loss: 0.3679\n",
      "Optimization Iteration:  48897, Training Accuracy:  78.1%, Loss: 0.4277\n",
      "Optimization Iteration:  48961, Training Accuracy:  79.7%, Loss: 0.4144\n",
      "Optimization Iteration:  49025, Training Accuracy:  71.9%, Loss: 0.4024\n",
      "Optimization Iteration:  49089, Training Accuracy:  75.0%, Loss: 0.3989\n",
      "Optimization Iteration:  49153, Training Accuracy:  84.4%, Loss: 0.3363\n",
      "Optimization Iteration:  49217, Training Accuracy:  79.7%, Loss: 0.4052\n",
      "Optimization Iteration:  49281, Training Accuracy:  75.0%, Loss: 0.4085\n",
      "Optimization Iteration:  49345, Training Accuracy:  75.0%, Loss: 0.3667\n",
      "Optimization Iteration:  49409, Training Accuracy:  76.6%, Loss: 0.4052\n",
      "Optimization Iteration:  49473, Training Accuracy:  75.0%, Loss: 0.4035\n",
      "Optimization Iteration:  49537, Training Accuracy:  71.9%, Loss: 0.3810\n",
      "Optimization Iteration:  49601, Training Accuracy:  75.0%, Loss: 0.3942\n",
      "Optimization Iteration:  49665, Training Accuracy:  78.1%, Loss: 0.3723\n",
      "Optimization Iteration:  49729, Training Accuracy:  71.9%, Loss: 0.4822\n",
      "Optimization Iteration:  49793, Training Accuracy:  60.9%, Loss: 0.4402\n",
      "Optimization Iteration:  49857, Training Accuracy:  71.9%, Loss: 0.4945\n",
      "Optimization Iteration:  49921, Training Accuracy:  75.0%, Loss: 0.4486\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 12\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  71.9%, Loss: 0.4894\n",
      "Optimization Iteration:    129, Training Accuracy:  76.6%, Loss: 0.4631\n",
      "Optimization Iteration:    193, Training Accuracy:  78.1%, Loss: 0.4535\n",
      "Optimization Iteration:    257, Training Accuracy:  67.2%, Loss: 0.4594\n",
      "Optimization Iteration:    321, Training Accuracy:  78.1%, Loss: 0.4100\n",
      "Optimization Iteration:    385, Training Accuracy:  73.4%, Loss: 0.4199\n",
      "Optimization Iteration:    449, Training Accuracy:  84.4%, Loss: 0.3456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    513, Training Accuracy:  65.6%, Loss: 0.5642\n",
      "Optimization Iteration:    577, Training Accuracy:  65.6%, Loss: 0.4920\n",
      "Optimization Iteration:    641, Training Accuracy:  81.2%, Loss: 0.3563\n",
      "Optimization Iteration:    705, Training Accuracy:  82.8%, Loss: 0.4400\n",
      "Optimization Iteration:    769, Training Accuracy:  75.0%, Loss: 0.3961\n",
      "Optimization Iteration:    833, Training Accuracy:  81.2%, Loss: 0.3864\n",
      "Optimization Iteration:    897, Training Accuracy:  81.2%, Loss: 0.3203\n",
      "Optimization Iteration:    961, Training Accuracy:  78.1%, Loss: 0.3581\n",
      "Optimization Iteration:   1025, Training Accuracy:  78.1%, Loss: 0.3330\n",
      "Optimization Iteration:   1089, Training Accuracy:  78.1%, Loss: 0.3773\n",
      "Optimization Iteration:   1153, Training Accuracy:  76.6%, Loss: 0.4187\n",
      "Optimization Iteration:   1217, Training Accuracy:  81.2%, Loss: 0.3981\n",
      "Optimization Iteration:   1281, Training Accuracy:  79.7%, Loss: 0.3643\n",
      "Optimization Iteration:   1345, Training Accuracy:  76.6%, Loss: 0.4358\n",
      "Optimization Iteration:   1409, Training Accuracy:  67.2%, Loss: 0.4490\n",
      "Optimization Iteration:   1473, Training Accuracy:  67.2%, Loss: 0.4055\n",
      "Optimization Iteration:   1537, Training Accuracy:  79.7%, Loss: 0.3866\n",
      "Optimization Iteration:   1601, Training Accuracy:  75.0%, Loss: 0.4342\n",
      "Optimization Iteration:   1665, Training Accuracy:  65.6%, Loss: 0.4251\n",
      "Optimization Iteration:   1729, Training Accuracy:  82.8%, Loss: 0.3300\n",
      "Optimization Iteration:   1793, Training Accuracy:  75.0%, Loss: 0.3771\n",
      "Optimization Iteration:   1857, Training Accuracy:  79.7%, Loss: 0.3333\n",
      "Optimization Iteration:   1921, Training Accuracy:  71.9%, Loss: 0.4513\n",
      "Optimization Iteration:   1985, Training Accuracy:  76.6%, Loss: 0.4272\n",
      "Optimization Iteration:   2049, Training Accuracy:  81.2%, Loss: 0.3619\n",
      "Optimization Iteration:   2113, Training Accuracy:  76.6%, Loss: 0.3710\n",
      "Optimization Iteration:   2177, Training Accuracy:  75.0%, Loss: 0.4005\n",
      "Optimization Iteration:   2241, Training Accuracy:  79.7%, Loss: 0.3906\n",
      "Optimization Iteration:   2305, Training Accuracy:  68.8%, Loss: 0.4016\n",
      "Optimization Iteration:   2369, Training Accuracy:  81.2%, Loss: 0.3658\n",
      "Optimization Iteration:   2433, Training Accuracy:  78.1%, Loss: 0.4293\n",
      "Optimization Iteration:   2497, Training Accuracy:  76.6%, Loss: 0.3685\n",
      "Optimization Iteration:   2561, Training Accuracy:  78.1%, Loss: 0.3409\n",
      "Optimization Iteration:   2625, Training Accuracy:  81.2%, Loss: 0.3705\n",
      "Optimization Iteration:   2689, Training Accuracy:  79.7%, Loss: 0.3914\n",
      "Optimization Iteration:   2753, Training Accuracy:  75.0%, Loss: 0.3283\n",
      "Optimization Iteration:   2817, Training Accuracy:  78.1%, Loss: 0.3910\n",
      "Optimization Iteration:   2881, Training Accuracy:  78.1%, Loss: 0.3947\n",
      "Optimization Iteration:   2945, Training Accuracy:  78.1%, Loss: 0.4830\n",
      "Optimization Iteration:   3009, Training Accuracy:  78.1%, Loss: 0.3792\n",
      "Optimization Iteration:   3073, Training Accuracy:  81.2%, Loss: 0.3182\n",
      "Optimization Iteration:   3137, Training Accuracy:  78.1%, Loss: 0.3820\n",
      "Optimization Iteration:   3201, Training Accuracy:  79.7%, Loss: 0.3877\n",
      "Optimization Iteration:   3265, Training Accuracy:  73.4%, Loss: 0.3614\n",
      "Optimization Iteration:   3329, Training Accuracy:  76.6%, Loss: 0.3944\n",
      "Optimization Iteration:   3393, Training Accuracy:  75.0%, Loss: 0.3758\n",
      "Optimization Iteration:   3457, Training Accuracy:  75.0%, Loss: 0.4433\n",
      "Optimization Iteration:   3521, Training Accuracy:  76.6%, Loss: 0.4090\n",
      "Optimization Iteration:   3585, Training Accuracy:  67.2%, Loss: 0.5070\n",
      "Optimization Iteration:   3649, Training Accuracy:  71.9%, Loss: 0.4350\n",
      "Optimization Iteration:   3713, Training Accuracy:  71.9%, Loss: 0.4162\n",
      "Optimization Iteration:   3777, Training Accuracy:  71.9%, Loss: 0.4872\n",
      "Optimization Iteration:   3841, Training Accuracy:  70.3%, Loss: 0.4293\n",
      "Optimization Iteration:   3905, Training Accuracy:  79.7%, Loss: 0.3876\n",
      "Optimization Iteration:   3969, Training Accuracy:  76.6%, Loss: 0.3849\n",
      "Optimization Iteration:   4033, Training Accuracy:  75.0%, Loss: 0.3586\n",
      "Optimization Iteration:   4097, Training Accuracy:  78.1%, Loss: 0.4126\n",
      "Optimization Iteration:   4161, Training Accuracy:  65.6%, Loss: 0.5524\n",
      "Optimization Iteration:   4225, Training Accuracy:  75.0%, Loss: 0.3778\n",
      "Optimization Iteration:   4289, Training Accuracy:  67.2%, Loss: 0.3752\n",
      "Optimization Iteration:   4353, Training Accuracy:  78.1%, Loss: 0.3676\n",
      "Optimization Iteration:   4417, Training Accuracy:  68.8%, Loss: 0.4557\n",
      "Optimization Iteration:   4481, Training Accuracy:  75.0%, Loss: 0.4129\n",
      "Optimization Iteration:   4545, Training Accuracy:  73.4%, Loss: 0.4356\n",
      "Optimization Iteration:   4609, Training Accuracy:  82.8%, Loss: 0.3411\n",
      "Optimization Iteration:   4673, Training Accuracy:  85.9%, Loss: 0.3168\n",
      "Optimization Iteration:   4737, Training Accuracy:  75.0%, Loss: 0.4164\n",
      "Optimization Iteration:   4801, Training Accuracy:  75.0%, Loss: 0.4735\n",
      "Optimization Iteration:   4865, Training Accuracy:  76.6%, Loss: 0.3632\n",
      "Optimization Iteration:   4929, Training Accuracy:  76.6%, Loss: 0.3886\n",
      "Optimization Iteration:   4993, Training Accuracy:  76.6%, Loss: 0.3730\n",
      "Optimization Iteration:   5057, Training Accuracy:  70.3%, Loss: 0.4710\n",
      "Optimization Iteration:   5121, Training Accuracy:  85.9%, Loss: 0.3240\n",
      "Optimization Iteration:   5185, Training Accuracy:  68.8%, Loss: 0.4290\n",
      "Optimization Iteration:   5249, Training Accuracy:  71.9%, Loss: 0.4696\n",
      "Optimization Iteration:   5313, Training Accuracy:  70.3%, Loss: 0.4736\n",
      "Optimization Iteration:   5377, Training Accuracy:  87.5%, Loss: 0.3613\n",
      "Optimization Iteration:   5441, Training Accuracy:  71.9%, Loss: 0.4315\n",
      "Optimization Iteration:   5505, Training Accuracy:  78.1%, Loss: 0.3237\n",
      "Optimization Iteration:   5569, Training Accuracy:  82.8%, Loss: 0.3303\n",
      "Optimization Iteration:   5633, Training Accuracy:  73.4%, Loss: 0.3846\n",
      "Optimization Iteration:   5697, Training Accuracy:  81.2%, Loss: 0.4117\n",
      "Optimization Iteration:   5761, Training Accuracy:  84.4%, Loss: 0.3137\n",
      "Optimization Iteration:   5825, Training Accuracy:  59.4%, Loss: 0.4647\n",
      "Optimization Iteration:   5889, Training Accuracy:  76.6%, Loss: 0.3788\n",
      "Optimization Iteration:   5953, Training Accuracy:  78.1%, Loss: 0.4014\n",
      "Optimization Iteration:   6017, Training Accuracy:  60.9%, Loss: 0.5609\n",
      "Optimization Iteration:   6081, Training Accuracy:  79.7%, Loss: 0.3783\n",
      "Optimization Iteration:   6145, Training Accuracy:  64.1%, Loss: 0.5068\n",
      "Optimization Iteration:   6209, Training Accuracy:  73.4%, Loss: 0.3873\n",
      "Optimization Iteration:   6273, Training Accuracy:  78.1%, Loss: 0.3716\n",
      "Optimization Iteration:   6337, Training Accuracy:  65.6%, Loss: 0.4391\n",
      "Optimization Iteration:   6401, Training Accuracy:  82.8%, Loss: 0.3904\n",
      "Optimization Iteration:   6465, Training Accuracy:  73.4%, Loss: 0.3691\n",
      "Optimization Iteration:   6529, Training Accuracy:  73.4%, Loss: 0.4299\n",
      "Optimization Iteration:   6593, Training Accuracy:  73.4%, Loss: 0.4376\n",
      "Optimization Iteration:   6657, Training Accuracy:  71.9%, Loss: 0.4409\n",
      "Optimization Iteration:   6721, Training Accuracy:  78.1%, Loss: 0.3455\n",
      "Optimization Iteration:   6785, Training Accuracy:  73.4%, Loss: 0.4231\n",
      "Optimization Iteration:   6849, Training Accuracy:  76.6%, Loss: 0.4634\n",
      "Optimization Iteration:   6913, Training Accuracy:  78.1%, Loss: 0.3747\n",
      "Optimization Iteration:   6977, Training Accuracy:  73.4%, Loss: 0.4229\n",
      "Optimization Iteration:   7041, Training Accuracy:  81.2%, Loss: 0.3537\n",
      "Optimization Iteration:   7105, Training Accuracy:  76.6%, Loss: 0.3499\n",
      "Optimization Iteration:   7169, Training Accuracy:  79.7%, Loss: 0.3868\n",
      "Optimization Iteration:   7233, Training Accuracy:  78.1%, Loss: 0.4338\n",
      "Optimization Iteration:   7297, Training Accuracy:  78.1%, Loss: 0.4915\n",
      "Optimization Iteration:   7361, Training Accuracy:  71.9%, Loss: 0.3784\n",
      "Optimization Iteration:   7425, Training Accuracy:  78.1%, Loss: 0.3935\n",
      "Optimization Iteration:   7489, Training Accuracy:  71.9%, Loss: 0.4452\n",
      "Optimization Iteration:   7553, Training Accuracy:  78.1%, Loss: 0.4128\n",
      "Optimization Iteration:   7617, Training Accuracy:  78.1%, Loss: 0.4066\n",
      "Optimization Iteration:   7681, Training Accuracy:  76.6%, Loss: 0.4725\n",
      "Optimization Iteration:   7745, Training Accuracy:  73.4%, Loss: 0.4181\n",
      "Optimization Iteration:   7809, Training Accuracy:  71.9%, Loss: 0.4406\n",
      "Optimization Iteration:   7873, Training Accuracy:  71.9%, Loss: 0.3967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7937, Training Accuracy:  73.4%, Loss: 0.3857\n",
      "Optimization Iteration:   8001, Training Accuracy:  75.0%, Loss: 0.4174\n",
      "Optimization Iteration:   8065, Training Accuracy:  62.5%, Loss: 0.4681\n",
      "Optimization Iteration:   8129, Training Accuracy:  67.2%, Loss: 0.4503\n",
      "Optimization Iteration:   8193, Training Accuracy:  70.3%, Loss: 0.4385\n",
      "Optimization Iteration:   8257, Training Accuracy:  79.7%, Loss: 0.4180\n",
      "Optimization Iteration:   8321, Training Accuracy:  70.3%, Loss: 0.4920\n",
      "Optimization Iteration:   8385, Training Accuracy:  73.4%, Loss: 0.4442\n",
      "Optimization Iteration:   8449, Training Accuracy:  71.9%, Loss: 0.4502\n",
      "Optimization Iteration:   8513, Training Accuracy:  76.6%, Loss: 0.3664\n",
      "Optimization Iteration:   8577, Training Accuracy:  75.0%, Loss: 0.5072\n",
      "Optimization Iteration:   8641, Training Accuracy:  75.0%, Loss: 0.4043\n",
      "Optimization Iteration:   8705, Training Accuracy:  78.1%, Loss: 0.4020\n",
      "Optimization Iteration:   8769, Training Accuracy:  75.0%, Loss: 0.4100\n",
      "Optimization Iteration:   8833, Training Accuracy:  68.8%, Loss: 0.5132\n",
      "Optimization Iteration:   8897, Training Accuracy:  73.4%, Loss: 0.4515\n",
      "Optimization Iteration:   8961, Training Accuracy:  71.9%, Loss: 0.4059\n",
      "Optimization Iteration:   9025, Training Accuracy:  67.2%, Loss: 0.5062\n",
      "Optimization Iteration:   9089, Training Accuracy:  71.9%, Loss: 0.4507\n",
      "Optimization Iteration:   9153, Training Accuracy:  82.8%, Loss: 0.3195\n",
      "Optimization Iteration:   9217, Training Accuracy:  75.0%, Loss: 0.3996\n",
      "Optimization Iteration:   9281, Training Accuracy:  73.4%, Loss: 0.4113\n",
      "Optimization Iteration:   9345, Training Accuracy:  76.6%, Loss: 0.4402\n",
      "Optimization Iteration:   9409, Training Accuracy:  76.6%, Loss: 0.5071\n",
      "Optimization Iteration:   9473, Training Accuracy:  76.6%, Loss: 0.4029\n",
      "Optimization Iteration:   9537, Training Accuracy:  75.0%, Loss: 0.4244\n",
      "Optimization Iteration:   9601, Training Accuracy:  76.6%, Loss: 0.3968\n",
      "Optimization Iteration:   9665, Training Accuracy:  65.6%, Loss: 0.5006\n",
      "Optimization Iteration:   9729, Training Accuracy:  64.1%, Loss: 0.4897\n",
      "Optimization Iteration:   9793, Training Accuracy:  85.9%, Loss: 0.3051\n",
      "Optimization Iteration:   9857, Training Accuracy:  70.3%, Loss: 0.4416\n",
      "Optimization Iteration:   9921, Training Accuracy:  76.6%, Loss: 0.3828\n",
      "Optimization Iteration:   9985, Training Accuracy:  68.8%, Loss: 0.4429\n",
      "Optimization Iteration:  10049, Training Accuracy:  79.7%, Loss: 0.4510\n",
      "Optimization Iteration:  10113, Training Accuracy:  71.9%, Loss: 0.4150\n",
      "Optimization Iteration:  10177, Training Accuracy:  62.5%, Loss: 0.5542\n",
      "Optimization Iteration:  10241, Training Accuracy:  71.9%, Loss: 0.4705\n",
      "Optimization Iteration:  10305, Training Accuracy:  84.4%, Loss: 0.3487\n",
      "Optimization Iteration:  10369, Training Accuracy:  73.4%, Loss: 0.4199\n",
      "Optimization Iteration:  10433, Training Accuracy:  79.7%, Loss: 0.3475\n",
      "Optimization Iteration:  10497, Training Accuracy:  73.4%, Loss: 0.5226\n",
      "Optimization Iteration:  10561, Training Accuracy:  81.2%, Loss: 0.3479\n",
      "Optimization Iteration:  10625, Training Accuracy:  68.8%, Loss: 0.4518\n",
      "Optimization Iteration:  10689, Training Accuracy:  81.2%, Loss: 0.3724\n",
      "Optimization Iteration:  10753, Training Accuracy:  75.0%, Loss: 0.4054\n",
      "Optimization Iteration:  10817, Training Accuracy:  75.0%, Loss: 0.4615\n",
      "Optimization Iteration:  10881, Training Accuracy:  82.8%, Loss: 0.3349\n",
      "Optimization Iteration:  10945, Training Accuracy:  75.0%, Loss: 0.3961\n",
      "Optimization Iteration:  11009, Training Accuracy:  81.2%, Loss: 0.3404\n",
      "Optimization Iteration:  11073, Training Accuracy:  75.0%, Loss: 0.3456\n",
      "Optimization Iteration:  11137, Training Accuracy:  71.9%, Loss: 0.4280\n",
      "Optimization Iteration:  11201, Training Accuracy:  79.7%, Loss: 0.3740\n",
      "Optimization Iteration:  11265, Training Accuracy:  81.2%, Loss: 0.3468\n",
      "Optimization Iteration:  11329, Training Accuracy:  68.8%, Loss: 0.4691\n",
      "Optimization Iteration:  11393, Training Accuracy:  87.5%, Loss: 0.3611\n",
      "Optimization Iteration:  11457, Training Accuracy:  79.7%, Loss: 0.3895\n",
      "Optimization Iteration:  11521, Training Accuracy:  65.6%, Loss: 0.4267\n",
      "Optimization Iteration:  11585, Training Accuracy:  73.4%, Loss: 0.3625\n",
      "Optimization Iteration:  11649, Training Accuracy:  71.9%, Loss: 0.4646\n",
      "Optimization Iteration:  11713, Training Accuracy:  79.7%, Loss: 0.4019\n",
      "Optimization Iteration:  11777, Training Accuracy:  67.2%, Loss: 0.5006\n",
      "Optimization Iteration:  11841, Training Accuracy:  78.1%, Loss: 0.3666\n",
      "Optimization Iteration:  11905, Training Accuracy:  84.4%, Loss: 0.4056\n",
      "Optimization Iteration:  11969, Training Accuracy:  68.8%, Loss: 0.4343\n",
      "Optimization Iteration:  12033, Training Accuracy:  70.3%, Loss: 0.4228\n",
      "Optimization Iteration:  12097, Training Accuracy:  78.1%, Loss: 0.4267\n",
      "Optimization Iteration:  12161, Training Accuracy:  76.6%, Loss: 0.4401\n",
      "Optimization Iteration:  12225, Training Accuracy:  76.6%, Loss: 0.4078\n",
      "Optimization Iteration:  12289, Training Accuracy:  78.1%, Loss: 0.3612\n",
      "Optimization Iteration:  12353, Training Accuracy:  82.8%, Loss: 0.4254\n",
      "Optimization Iteration:  12417, Training Accuracy:  81.2%, Loss: 0.3567\n",
      "Optimization Iteration:  12481, Training Accuracy:  78.1%, Loss: 0.3712\n",
      "Optimization Iteration:  12545, Training Accuracy:  71.9%, Loss: 0.3839\n",
      "Optimization Iteration:  12609, Training Accuracy:  76.6%, Loss: 0.3631\n",
      "Optimization Iteration:  12673, Training Accuracy:  84.4%, Loss: 0.3659\n",
      "Optimization Iteration:  12737, Training Accuracy:  67.2%, Loss: 0.4747\n",
      "Optimization Iteration:  12801, Training Accuracy:  70.3%, Loss: 0.4555\n",
      "Optimization Iteration:  12865, Training Accuracy:  67.2%, Loss: 0.4407\n",
      "Optimization Iteration:  12929, Training Accuracy:  71.9%, Loss: 0.4189\n",
      "Optimization Iteration:  12993, Training Accuracy:  76.6%, Loss: 0.4018\n",
      "Optimization Iteration:  13057, Training Accuracy:  62.5%, Loss: 0.5267\n",
      "Optimization Iteration:  13121, Training Accuracy:  79.7%, Loss: 0.3907\n",
      "Optimization Iteration:  13185, Training Accuracy:  76.6%, Loss: 0.4779\n",
      "Optimization Iteration:  13249, Training Accuracy:  79.7%, Loss: 0.4674\n",
      "Optimization Iteration:  13313, Training Accuracy:  62.5%, Loss: 0.5320\n",
      "Optimization Iteration:  13377, Training Accuracy:  67.2%, Loss: 0.4698\n",
      "Optimization Iteration:  13441, Training Accuracy:  79.7%, Loss: 0.3596\n",
      "Optimization Iteration:  13505, Training Accuracy:  78.1%, Loss: 0.3906\n",
      "Optimization Iteration:  13569, Training Accuracy:  81.2%, Loss: 0.3192\n",
      "Optimization Iteration:  13633, Training Accuracy:  73.4%, Loss: 0.4102\n",
      "Optimization Iteration:  13697, Training Accuracy:  78.1%, Loss: 0.3675\n",
      "Optimization Iteration:  13761, Training Accuracy:  79.7%, Loss: 0.3775\n",
      "Optimization Iteration:  13825, Training Accuracy:  76.6%, Loss: 0.4940\n",
      "Optimization Iteration:  13889, Training Accuracy:  76.6%, Loss: 0.4056\n",
      "Optimization Iteration:  13953, Training Accuracy:  82.8%, Loss: 0.3674\n",
      "Optimization Iteration:  14017, Training Accuracy:  78.1%, Loss: 0.3940\n",
      "Optimization Iteration:  14081, Training Accuracy:  76.6%, Loss: 0.3827\n",
      "Optimization Iteration:  14145, Training Accuracy:  79.7%, Loss: 0.3566\n",
      "Optimization Iteration:  14209, Training Accuracy:  75.0%, Loss: 0.4099\n",
      "Optimization Iteration:  14273, Training Accuracy:  76.6%, Loss: 0.5321\n",
      "Optimization Iteration:  14337, Training Accuracy:  84.4%, Loss: 0.2946\n",
      "Optimization Iteration:  14401, Training Accuracy:  78.1%, Loss: 0.3738\n",
      "Optimization Iteration:  14465, Training Accuracy:  71.9%, Loss: 0.4706\n",
      "Optimization Iteration:  14529, Training Accuracy:  81.2%, Loss: 0.4635\n",
      "Optimization Iteration:  14593, Training Accuracy:  82.8%, Loss: 0.2889\n",
      "Optimization Iteration:  14657, Training Accuracy:  81.2%, Loss: 0.4130\n",
      "Optimization Iteration:  14721, Training Accuracy:  73.4%, Loss: 0.3787\n",
      "Optimization Iteration:  14785, Training Accuracy:  75.0%, Loss: 0.4351\n",
      "Optimization Iteration:  14849, Training Accuracy:  73.4%, Loss: 0.4445\n",
      "Optimization Iteration:  14913, Training Accuracy:  79.7%, Loss: 0.3204\n",
      "Optimization Iteration:  14977, Training Accuracy:  75.0%, Loss: 0.4336\n",
      "Optimization Iteration:  15041, Training Accuracy:  73.4%, Loss: 0.4941\n",
      "Optimization Iteration:  15105, Training Accuracy:  81.2%, Loss: 0.3299\n",
      "Optimization Iteration:  15169, Training Accuracy:  73.4%, Loss: 0.4578\n",
      "Optimization Iteration:  15233, Training Accuracy:  70.3%, Loss: 0.4222\n",
      "Optimization Iteration:  15297, Training Accuracy:  76.6%, Loss: 0.4603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  15361, Training Accuracy:  78.1%, Loss: 0.3700\n",
      "Optimization Iteration:  15425, Training Accuracy:  71.9%, Loss: 0.4572\n",
      "Optimization Iteration:  15489, Training Accuracy:  67.2%, Loss: 0.4664\n",
      "Optimization Iteration:  15553, Training Accuracy:  73.4%, Loss: 0.3645\n",
      "Optimization Iteration:  15617, Training Accuracy:  71.9%, Loss: 0.4321\n",
      "Optimization Iteration:  15681, Training Accuracy:  76.6%, Loss: 0.3603\n",
      "Optimization Iteration:  15745, Training Accuracy:  73.4%, Loss: 0.4231\n",
      "Optimization Iteration:  15809, Training Accuracy:  73.4%, Loss: 0.4122\n",
      "Optimization Iteration:  15873, Training Accuracy:  70.3%, Loss: 0.4351\n",
      "Optimization Iteration:  15937, Training Accuracy:  76.6%, Loss: 0.3882\n",
      "Optimization Iteration:  16001, Training Accuracy:  73.4%, Loss: 0.4373\n",
      "Optimization Iteration:  16065, Training Accuracy:  73.4%, Loss: 0.3913\n",
      "Optimization Iteration:  16129, Training Accuracy:  73.4%, Loss: 0.3802\n",
      "Optimization Iteration:  16193, Training Accuracy:  75.0%, Loss: 0.4031\n",
      "Optimization Iteration:  16257, Training Accuracy:  70.3%, Loss: 0.4083\n",
      "Optimization Iteration:  16321, Training Accuracy:  76.6%, Loss: 0.4262\n",
      "Optimization Iteration:  16385, Training Accuracy:  78.1%, Loss: 0.3982\n",
      "Optimization Iteration:  16449, Training Accuracy:  71.9%, Loss: 0.4043\n",
      "Optimization Iteration:  16513, Training Accuracy:  78.1%, Loss: 0.4169\n",
      "Optimization Iteration:  16577, Training Accuracy:  65.6%, Loss: 0.5090\n",
      "Optimization Iteration:  16641, Training Accuracy:  68.8%, Loss: 0.4937\n",
      "Optimization Iteration:  16705, Training Accuracy:  81.2%, Loss: 0.3924\n",
      "Optimization Iteration:  16769, Training Accuracy:  70.3%, Loss: 0.4062\n",
      "Optimization Iteration:  16833, Training Accuracy:  68.8%, Loss: 0.3990\n",
      "Optimization Iteration:  16897, Training Accuracy:  76.6%, Loss: 0.3852\n",
      "Optimization Iteration:  16961, Training Accuracy:  70.3%, Loss: 0.4052\n",
      "Optimization Iteration:  17025, Training Accuracy:  70.3%, Loss: 0.4082\n",
      "Optimization Iteration:  17089, Training Accuracy:  73.4%, Loss: 0.4619\n",
      "Optimization Iteration:  17153, Training Accuracy:  73.4%, Loss: 0.4191\n",
      "Optimization Iteration:  17217, Training Accuracy:  81.2%, Loss: 0.5059\n",
      "Optimization Iteration:  17281, Training Accuracy:  75.0%, Loss: 0.4517\n",
      "Optimization Iteration:  17345, Training Accuracy:  79.7%, Loss: 0.3602\n",
      "Optimization Iteration:  17409, Training Accuracy:  76.6%, Loss: 0.3751\n",
      "Optimization Iteration:  17473, Training Accuracy:  68.8%, Loss: 0.5829\n",
      "Optimization Iteration:  17537, Training Accuracy:  73.4%, Loss: 0.3793\n",
      "Optimization Iteration:  17601, Training Accuracy:  71.9%, Loss: 0.4616\n",
      "Optimization Iteration:  17665, Training Accuracy:  75.0%, Loss: 0.4847\n",
      "Optimization Iteration:  17729, Training Accuracy:  78.1%, Loss: 0.3713\n",
      "Optimization Iteration:  17793, Training Accuracy:  75.0%, Loss: 0.4310\n",
      "Optimization Iteration:  17857, Training Accuracy:  76.6%, Loss: 0.4308\n",
      "Optimization Iteration:  17921, Training Accuracy:  71.9%, Loss: 0.3799\n",
      "Optimization Iteration:  17985, Training Accuracy:  75.0%, Loss: 0.3622\n",
      "Optimization Iteration:  18049, Training Accuracy:  78.1%, Loss: 0.3715\n",
      "Optimization Iteration:  18113, Training Accuracy:  71.9%, Loss: 0.4444\n",
      "Optimization Iteration:  18177, Training Accuracy:  75.0%, Loss: 0.5602\n",
      "Optimization Iteration:  18241, Training Accuracy:  78.1%, Loss: 0.4084\n",
      "Optimization Iteration:  18305, Training Accuracy:  70.3%, Loss: 0.4008\n",
      "Optimization Iteration:  18369, Training Accuracy:  68.8%, Loss: 0.3908\n",
      "Optimization Iteration:  18433, Training Accuracy:  73.4%, Loss: 0.4263\n",
      "Optimization Iteration:  18497, Training Accuracy:  76.6%, Loss: 0.3260\n",
      "Optimization Iteration:  18561, Training Accuracy:  71.9%, Loss: 0.3983\n",
      "Optimization Iteration:  18625, Training Accuracy:  64.1%, Loss: 0.4551\n",
      "Optimization Iteration:  18689, Training Accuracy:  75.0%, Loss: 0.4369\n",
      "Optimization Iteration:  18753, Training Accuracy:  68.8%, Loss: 0.4356\n",
      "Optimization Iteration:  18817, Training Accuracy:  73.4%, Loss: 0.4633\n",
      "Optimization Iteration:  18881, Training Accuracy:  68.8%, Loss: 0.4608\n",
      "Optimization Iteration:  18945, Training Accuracy:  79.7%, Loss: 0.3911\n",
      "Optimization Iteration:  19009, Training Accuracy:  79.7%, Loss: 0.3292\n",
      "Optimization Iteration:  19073, Training Accuracy:  76.6%, Loss: 0.4705\n",
      "Optimization Iteration:  19137, Training Accuracy:  65.6%, Loss: 0.5388\n",
      "Optimization Iteration:  19201, Training Accuracy:  75.0%, Loss: 0.3905\n",
      "Optimization Iteration:  19265, Training Accuracy:  75.0%, Loss: 0.4163\n",
      "Optimization Iteration:  19329, Training Accuracy:  79.7%, Loss: 0.3600\n",
      "Optimization Iteration:  19393, Training Accuracy:  68.8%, Loss: 0.4120\n",
      "Optimization Iteration:  19457, Training Accuracy:  81.2%, Loss: 0.3900\n",
      "Optimization Iteration:  19521, Training Accuracy:  68.8%, Loss: 0.4109\n",
      "Optimization Iteration:  19585, Training Accuracy:  75.0%, Loss: 0.4586\n",
      "Optimization Iteration:  19649, Training Accuracy:  76.6%, Loss: 0.5944\n",
      "Optimization Iteration:  19713, Training Accuracy:  73.4%, Loss: 0.3467\n",
      "Optimization Iteration:  19777, Training Accuracy:  76.6%, Loss: 0.4647\n",
      "Optimization Iteration:  19841, Training Accuracy:  71.9%, Loss: 0.3950\n",
      "Optimization Iteration:  19905, Training Accuracy:  75.0%, Loss: 0.4055\n",
      "Optimization Iteration:  19969, Training Accuracy:  78.1%, Loss: 0.4375\n",
      "Optimization Iteration:  20033, Training Accuracy:  84.4%, Loss: 0.3691\n",
      "Optimization Iteration:  20097, Training Accuracy:  71.9%, Loss: 0.4106\n",
      "Optimization Iteration:  20161, Training Accuracy:  70.3%, Loss: 0.4276\n",
      "Optimization Iteration:  20225, Training Accuracy:  73.4%, Loss: 0.4381\n",
      "Optimization Iteration:  20289, Training Accuracy:  76.6%, Loss: 0.4375\n",
      "Optimization Iteration:  20353, Training Accuracy:  75.0%, Loss: 0.4282\n",
      "Optimization Iteration:  20417, Training Accuracy:  73.4%, Loss: 0.4004\n",
      "Optimization Iteration:  20481, Training Accuracy:  75.0%, Loss: 0.4067\n",
      "Optimization Iteration:  20545, Training Accuracy:  75.0%, Loss: 0.4454\n",
      "Optimization Iteration:  20609, Training Accuracy:  68.8%, Loss: 0.4820\n",
      "Optimization Iteration:  20673, Training Accuracy:  73.4%, Loss: 0.4136\n",
      "Optimization Iteration:  20737, Training Accuracy:  84.4%, Loss: 0.3662\n",
      "Optimization Iteration:  20801, Training Accuracy:  70.3%, Loss: 0.4491\n",
      "Optimization Iteration:  20865, Training Accuracy:  76.6%, Loss: 0.4174\n",
      "Optimization Iteration:  20929, Training Accuracy:  79.7%, Loss: 0.3081\n",
      "Optimization Iteration:  20993, Training Accuracy:  78.1%, Loss: 0.3678\n",
      "Optimization Iteration:  21057, Training Accuracy:  79.7%, Loss: 0.4696\n",
      "Optimization Iteration:  21121, Training Accuracy:  64.1%, Loss: 0.4486\n",
      "Optimization Iteration:  21185, Training Accuracy:  76.6%, Loss: 0.4534\n",
      "Optimization Iteration:  21249, Training Accuracy:  71.9%, Loss: 0.4564\n",
      "Optimization Iteration:  21313, Training Accuracy:  78.1%, Loss: 0.4799\n",
      "Optimization Iteration:  21377, Training Accuracy:  78.1%, Loss: 0.3450\n",
      "Optimization Iteration:  21441, Training Accuracy:  73.4%, Loss: 0.3504\n",
      "Optimization Iteration:  21505, Training Accuracy:  81.2%, Loss: 0.3766\n",
      "Optimization Iteration:  21569, Training Accuracy:  76.6%, Loss: 0.3801\n",
      "Optimization Iteration:  21633, Training Accuracy:  82.8%, Loss: 0.3241\n",
      "Optimization Iteration:  21697, Training Accuracy:  71.9%, Loss: 0.5389\n",
      "Optimization Iteration:  21761, Training Accuracy:  81.2%, Loss: 0.2913\n",
      "Optimization Iteration:  21825, Training Accuracy:  79.7%, Loss: 0.4444\n",
      "Optimization Iteration:  21889, Training Accuracy:  71.9%, Loss: 0.3734\n",
      "Optimization Iteration:  21953, Training Accuracy:  65.6%, Loss: 0.5124\n",
      "Optimization Iteration:  22017, Training Accuracy:  76.6%, Loss: 0.3781\n",
      "Optimization Iteration:  22081, Training Accuracy:  76.6%, Loss: 0.3851\n",
      "Optimization Iteration:  22145, Training Accuracy:  78.1%, Loss: 0.4288\n",
      "Optimization Iteration:  22209, Training Accuracy:  75.0%, Loss: 0.4081\n",
      "Optimization Iteration:  22273, Training Accuracy:  71.9%, Loss: 0.4358\n",
      "Optimization Iteration:  22337, Training Accuracy:  75.0%, Loss: 0.3422\n",
      "Optimization Iteration:  22401, Training Accuracy:  73.4%, Loss: 0.4464\n",
      "Optimization Iteration:  22465, Training Accuracy:  71.9%, Loss: 0.4443\n",
      "Optimization Iteration:  22529, Training Accuracy:  79.7%, Loss: 0.3911\n",
      "Optimization Iteration:  22593, Training Accuracy:  81.2%, Loss: 0.4495\n",
      "Optimization Iteration:  22657, Training Accuracy:  81.2%, Loss: 0.3605\n",
      "Optimization Iteration:  22721, Training Accuracy:  65.6%, Loss: 0.4729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  22785, Training Accuracy:  71.9%, Loss: 0.4609\n",
      "Optimization Iteration:  22849, Training Accuracy:  71.9%, Loss: 0.4337\n",
      "Optimization Iteration:  22913, Training Accuracy:  78.1%, Loss: 0.3886\n",
      "Optimization Iteration:  22977, Training Accuracy:  85.9%, Loss: 0.3461\n",
      "Optimization Iteration:  23041, Training Accuracy:  71.9%, Loss: 0.3761\n",
      "Optimization Iteration:  23105, Training Accuracy:  71.9%, Loss: 0.4074\n",
      "Optimization Iteration:  23169, Training Accuracy:  76.6%, Loss: 0.3659\n",
      "Optimization Iteration:  23233, Training Accuracy:  70.3%, Loss: 0.5680\n",
      "Optimization Iteration:  23297, Training Accuracy:  73.4%, Loss: 0.5019\n",
      "Optimization Iteration:  23361, Training Accuracy:  76.6%, Loss: 0.4214\n",
      "Optimization Iteration:  23425, Training Accuracy:  68.8%, Loss: 0.4455\n",
      "Optimization Iteration:  23489, Training Accuracy:  76.6%, Loss: 0.4235\n",
      "Optimization Iteration:  23553, Training Accuracy:  76.6%, Loss: 0.3575\n",
      "Optimization Iteration:  23617, Training Accuracy:  70.3%, Loss: 0.5367\n",
      "Optimization Iteration:  23681, Training Accuracy:  78.1%, Loss: 0.4383\n",
      "Optimization Iteration:  23745, Training Accuracy:  73.4%, Loss: 0.3789\n",
      "Optimization Iteration:  23809, Training Accuracy:  81.2%, Loss: 0.4313\n",
      "Optimization Iteration:  23873, Training Accuracy:  73.4%, Loss: 0.3562\n",
      "Optimization Iteration:  23937, Training Accuracy:  70.3%, Loss: 0.4537\n",
      "Optimization Iteration:  24001, Training Accuracy:  78.1%, Loss: 0.3767\n",
      "Optimization Iteration:  24065, Training Accuracy:  73.4%, Loss: 0.4108\n",
      "Optimization Iteration:  24129, Training Accuracy:  71.9%, Loss: 0.3891\n",
      "Optimization Iteration:  24193, Training Accuracy:  65.6%, Loss: 0.4560\n",
      "Optimization Iteration:  24257, Training Accuracy:  75.0%, Loss: 0.4138\n",
      "Optimization Iteration:  24321, Training Accuracy:  68.8%, Loss: 0.4656\n",
      "Optimization Iteration:  24385, Training Accuracy:  79.7%, Loss: 0.4273\n",
      "Optimization Iteration:  24449, Training Accuracy:  68.8%, Loss: 0.4077\n",
      "Optimization Iteration:  24513, Training Accuracy:  76.6%, Loss: 0.3901\n",
      "Optimization Iteration:  24577, Training Accuracy:  64.1%, Loss: 0.5171\n",
      "Optimization Iteration:  24641, Training Accuracy:  73.4%, Loss: 0.4481\n",
      "Optimization Iteration:  24705, Training Accuracy:  82.8%, Loss: 0.3359\n",
      "Optimization Iteration:  24769, Training Accuracy:  71.9%, Loss: 0.3554\n",
      "Optimization Iteration:  24833, Training Accuracy:  85.9%, Loss: 0.3913\n",
      "Optimization Iteration:  24897, Training Accuracy:  81.2%, Loss: 0.3390\n",
      "Optimization Iteration:  24961, Training Accuracy:  82.8%, Loss: 0.3337\n",
      "Optimization Iteration:  25025, Training Accuracy:  68.8%, Loss: 0.4786\n",
      "Optimization Iteration:  25089, Training Accuracy:  75.0%, Loss: 0.4243\n",
      "Optimization Iteration:  25153, Training Accuracy:  71.9%, Loss: 0.4650\n",
      "Optimization Iteration:  25217, Training Accuracy:  65.6%, Loss: 0.4839\n",
      "Optimization Iteration:  25281, Training Accuracy:  90.6%, Loss: 0.3699\n",
      "Optimization Iteration:  25345, Training Accuracy:  79.7%, Loss: 0.4431\n",
      "Optimization Iteration:  25409, Training Accuracy:  75.0%, Loss: 0.3931\n",
      "Optimization Iteration:  25473, Training Accuracy:  70.3%, Loss: 0.4996\n",
      "Optimization Iteration:  25537, Training Accuracy:  76.6%, Loss: 0.3597\n",
      "Optimization Iteration:  25601, Training Accuracy:  62.5%, Loss: 0.4958\n",
      "Optimization Iteration:  25665, Training Accuracy:  76.6%, Loss: 0.5123\n",
      "Optimization Iteration:  25729, Training Accuracy:  76.6%, Loss: 0.3639\n",
      "Optimization Iteration:  25793, Training Accuracy:  73.4%, Loss: 0.4263\n",
      "Optimization Iteration:  25857, Training Accuracy:  70.3%, Loss: 0.4615\n",
      "Optimization Iteration:  25921, Training Accuracy:  79.7%, Loss: 0.3446\n",
      "Optimization Iteration:  25985, Training Accuracy:  70.3%, Loss: 0.5457\n",
      "Optimization Iteration:  26049, Training Accuracy:  73.4%, Loss: 0.4386\n",
      "Optimization Iteration:  26113, Training Accuracy:  76.6%, Loss: 0.3605\n",
      "Optimization Iteration:  26177, Training Accuracy:  79.7%, Loss: 0.4165\n",
      "Optimization Iteration:  26241, Training Accuracy:  68.8%, Loss: 0.4016\n",
      "Optimization Iteration:  26305, Training Accuracy:  81.2%, Loss: 0.3998\n",
      "Optimization Iteration:  26369, Training Accuracy:  82.8%, Loss: 0.3373\n",
      "Optimization Iteration:  26433, Training Accuracy:  70.3%, Loss: 0.4642\n",
      "Optimization Iteration:  26497, Training Accuracy:  75.0%, Loss: 0.4402\n",
      "Optimization Iteration:  26561, Training Accuracy:  81.2%, Loss: 0.3535\n",
      "Optimization Iteration:  26625, Training Accuracy:  73.4%, Loss: 0.4378\n",
      "Optimization Iteration:  26689, Training Accuracy:  81.2%, Loss: 0.4350\n",
      "Optimization Iteration:  26753, Training Accuracy:  71.9%, Loss: 0.4371\n",
      "Optimization Iteration:  26817, Training Accuracy:  67.2%, Loss: 0.4450\n",
      "Optimization Iteration:  26881, Training Accuracy:  79.7%, Loss: 0.3652\n",
      "Optimization Iteration:  26945, Training Accuracy:  70.3%, Loss: 0.4228\n",
      "Optimization Iteration:  27009, Training Accuracy:  71.9%, Loss: 0.4515\n",
      "Optimization Iteration:  27073, Training Accuracy:  82.8%, Loss: 0.4108\n",
      "Optimization Iteration:  27137, Training Accuracy:  78.1%, Loss: 0.4367\n",
      "Optimization Iteration:  27201, Training Accuracy:  75.0%, Loss: 0.3513\n",
      "Optimization Iteration:  27265, Training Accuracy:  81.2%, Loss: 0.4472\n",
      "Optimization Iteration:  27329, Training Accuracy:  70.3%, Loss: 0.4407\n",
      "Optimization Iteration:  27393, Training Accuracy:  65.6%, Loss: 0.4319\n",
      "Optimization Iteration:  27457, Training Accuracy:  82.8%, Loss: 0.3311\n",
      "Optimization Iteration:  27521, Training Accuracy:  78.1%, Loss: 0.4322\n",
      "Optimization Iteration:  27585, Training Accuracy:  73.4%, Loss: 0.4102\n",
      "Optimization Iteration:  27649, Training Accuracy:  85.9%, Loss: 0.3194\n",
      "Optimization Iteration:  27713, Training Accuracy:  71.9%, Loss: 0.4748\n",
      "Optimization Iteration:  27777, Training Accuracy:  78.1%, Loss: 0.3436\n",
      "Optimization Iteration:  27841, Training Accuracy:  71.9%, Loss: 0.4589\n",
      "Optimization Iteration:  27905, Training Accuracy:  75.0%, Loss: 0.4127\n",
      "Optimization Iteration:  27969, Training Accuracy:  73.4%, Loss: 0.4628\n",
      "Optimization Iteration:  28033, Training Accuracy:  82.8%, Loss: 0.3665\n",
      "Optimization Iteration:  28097, Training Accuracy:  76.6%, Loss: 0.4051\n",
      "Optimization Iteration:  28161, Training Accuracy:  81.2%, Loss: 0.3896\n",
      "Optimization Iteration:  28225, Training Accuracy:  78.1%, Loss: 0.3211\n",
      "Optimization Iteration:  28289, Training Accuracy:  76.6%, Loss: 0.3684\n",
      "Optimization Iteration:  28353, Training Accuracy:  76.6%, Loss: 0.4089\n",
      "Optimization Iteration:  28417, Training Accuracy:  65.6%, Loss: 0.5110\n",
      "Optimization Iteration:  28481, Training Accuracy:  79.7%, Loss: 0.3484\n",
      "Optimization Iteration:  28545, Training Accuracy:  78.1%, Loss: 0.3479\n",
      "Optimization Iteration:  28609, Training Accuracy:  90.6%, Loss: 0.3215\n",
      "Optimization Iteration:  28673, Training Accuracy:  79.7%, Loss: 0.4024\n",
      "Optimization Iteration:  28737, Training Accuracy:  75.0%, Loss: 0.4004\n",
      "Optimization Iteration:  28801, Training Accuracy:  79.7%, Loss: 0.3584\n",
      "Optimization Iteration:  28865, Training Accuracy:  90.6%, Loss: 0.2660\n",
      "Optimization Iteration:  28929, Training Accuracy:  76.6%, Loss: 0.3544\n",
      "Optimization Iteration:  28993, Training Accuracy:  70.3%, Loss: 0.4000\n",
      "Optimization Iteration:  29057, Training Accuracy:  67.2%, Loss: 0.4320\n",
      "Optimization Iteration:  29121, Training Accuracy:  68.8%, Loss: 0.5485\n",
      "Optimization Iteration:  29185, Training Accuracy:  70.3%, Loss: 0.4266\n",
      "Optimization Iteration:  29249, Training Accuracy:  81.2%, Loss: 0.3990\n",
      "Optimization Iteration:  29313, Training Accuracy:  79.7%, Loss: 0.3879\n",
      "Optimization Iteration:  29377, Training Accuracy:  79.7%, Loss: 0.3172\n",
      "Optimization Iteration:  29441, Training Accuracy:  71.9%, Loss: 0.3940\n",
      "Optimization Iteration:  29505, Training Accuracy:  79.7%, Loss: 0.3914\n",
      "Optimization Iteration:  29569, Training Accuracy:  71.9%, Loss: 0.4660\n",
      "Optimization Iteration:  29633, Training Accuracy:  70.3%, Loss: 0.4562\n",
      "Optimization Iteration:  29697, Training Accuracy:  84.4%, Loss: 0.2936\n",
      "Optimization Iteration:  29761, Training Accuracy:  76.6%, Loss: 0.4099\n",
      "Optimization Iteration:  29825, Training Accuracy:  76.6%, Loss: 0.3913\n",
      "Optimization Iteration:  29889, Training Accuracy:  85.9%, Loss: 0.4049\n",
      "Optimization Iteration:  29953, Training Accuracy:  68.8%, Loss: 0.4656\n",
      "Optimization Iteration:  30017, Training Accuracy:  81.2%, Loss: 0.3333\n",
      "Optimization Iteration:  30081, Training Accuracy:  71.9%, Loss: 0.4114\n",
      "Optimization Iteration:  30145, Training Accuracy:  67.2%, Loss: 0.4676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  30209, Training Accuracy:  76.6%, Loss: 0.3958\n",
      "Optimization Iteration:  30273, Training Accuracy:  81.2%, Loss: 0.3602\n",
      "Optimization Iteration:  30337, Training Accuracy:  70.3%, Loss: 0.4268\n",
      "Optimization Iteration:  30401, Training Accuracy:  75.0%, Loss: 0.4618\n",
      "Optimization Iteration:  30465, Training Accuracy:  82.8%, Loss: 0.3923\n",
      "Optimization Iteration:  30529, Training Accuracy:  79.7%, Loss: 0.3928\n",
      "Optimization Iteration:  30593, Training Accuracy:  78.1%, Loss: 0.3368\n",
      "Optimization Iteration:  30657, Training Accuracy:  81.2%, Loss: 0.3350\n",
      "Optimization Iteration:  30721, Training Accuracy:  73.4%, Loss: 0.4251\n",
      "Optimization Iteration:  30785, Training Accuracy:  71.9%, Loss: 0.3689\n",
      "Optimization Iteration:  30849, Training Accuracy:  71.9%, Loss: 0.4746\n",
      "Optimization Iteration:  30913, Training Accuracy:  76.6%, Loss: 0.3917\n",
      "Optimization Iteration:  30977, Training Accuracy:  78.1%, Loss: 0.4400\n",
      "Optimization Iteration:  31041, Training Accuracy:  78.1%, Loss: 0.4476\n",
      "Optimization Iteration:  31105, Training Accuracy:  81.2%, Loss: 0.3589\n",
      "Optimization Iteration:  31169, Training Accuracy:  79.7%, Loss: 0.4156\n",
      "Optimization Iteration:  31233, Training Accuracy:  64.1%, Loss: 0.4892\n",
      "Optimization Iteration:  31297, Training Accuracy:  81.2%, Loss: 0.3357\n",
      "Optimization Iteration:  31361, Training Accuracy:  70.3%, Loss: 0.4393\n",
      "Optimization Iteration:  31425, Training Accuracy:  78.1%, Loss: 0.3006\n",
      "Optimization Iteration:  31489, Training Accuracy:  76.6%, Loss: 0.4716\n",
      "Optimization Iteration:  31553, Training Accuracy:  75.0%, Loss: 0.3831\n",
      "Optimization Iteration:  31617, Training Accuracy:  75.0%, Loss: 0.3328\n",
      "Optimization Iteration:  31681, Training Accuracy:  85.9%, Loss: 0.3205\n",
      "Optimization Iteration:  31745, Training Accuracy:  79.7%, Loss: 0.4091\n",
      "Optimization Iteration:  31809, Training Accuracy:  67.2%, Loss: 0.5162\n",
      "Optimization Iteration:  31873, Training Accuracy:  76.6%, Loss: 0.3369\n",
      "Optimization Iteration:  31937, Training Accuracy:  68.8%, Loss: 0.4438\n",
      "Optimization Iteration:  32001, Training Accuracy:  70.3%, Loss: 0.4346\n",
      "Optimization Iteration:  32065, Training Accuracy:  71.9%, Loss: 0.4231\n",
      "Optimization Iteration:  32129, Training Accuracy:  75.0%, Loss: 0.3964\n",
      "Optimization Iteration:  32193, Training Accuracy:  71.9%, Loss: 0.5081\n",
      "Optimization Iteration:  32257, Training Accuracy:  70.3%, Loss: 0.4176\n",
      "Optimization Iteration:  32321, Training Accuracy:  81.2%, Loss: 0.3306\n",
      "Optimization Iteration:  32385, Training Accuracy:  76.6%, Loss: 0.4419\n",
      "Optimization Iteration:  32449, Training Accuracy:  67.2%, Loss: 0.4797\n",
      "Optimization Iteration:  32513, Training Accuracy:  73.4%, Loss: 0.4068\n",
      "Optimization Iteration:  32577, Training Accuracy:  71.9%, Loss: 0.4211\n",
      "Optimization Iteration:  32641, Training Accuracy:  70.3%, Loss: 0.4052\n",
      "Optimization Iteration:  32705, Training Accuracy:  71.9%, Loss: 0.3885\n",
      "Optimization Iteration:  32769, Training Accuracy:  67.2%, Loss: 0.4518\n",
      "Optimization Iteration:  32833, Training Accuracy:  75.0%, Loss: 0.4032\n",
      "Optimization Iteration:  32897, Training Accuracy:  78.1%, Loss: 0.3839\n",
      "Optimization Iteration:  32961, Training Accuracy:  73.4%, Loss: 0.4265\n",
      "Optimization Iteration:  33025, Training Accuracy:  82.8%, Loss: 0.3638\n",
      "Optimization Iteration:  33089, Training Accuracy:  65.6%, Loss: 0.5180\n",
      "Optimization Iteration:  33153, Training Accuracy:  76.6%, Loss: 0.4353\n",
      "Optimization Iteration:  33217, Training Accuracy:  75.0%, Loss: 0.3900\n",
      "Optimization Iteration:  33281, Training Accuracy:  68.8%, Loss: 0.4880\n",
      "Optimization Iteration:  33345, Training Accuracy:  67.2%, Loss: 0.4581\n",
      "Optimization Iteration:  33409, Training Accuracy:  79.7%, Loss: 0.4010\n",
      "Optimization Iteration:  33473, Training Accuracy:  79.7%, Loss: 0.4464\n",
      "Optimization Iteration:  33537, Training Accuracy:  71.9%, Loss: 0.4408\n",
      "Optimization Iteration:  33601, Training Accuracy:  76.6%, Loss: 0.4642\n",
      "Optimization Iteration:  33665, Training Accuracy:  78.1%, Loss: 0.3998\n",
      "Optimization Iteration:  33729, Training Accuracy:  75.0%, Loss: 0.4952\n",
      "Optimization Iteration:  33793, Training Accuracy:  67.2%, Loss: 0.4807\n",
      "Optimization Iteration:  33857, Training Accuracy:  73.4%, Loss: 0.4314\n",
      "Optimization Iteration:  33921, Training Accuracy:  73.4%, Loss: 0.4836\n",
      "Optimization Iteration:  33985, Training Accuracy:  68.8%, Loss: 0.3808\n",
      "Optimization Iteration:  34049, Training Accuracy:  71.9%, Loss: 0.4623\n",
      "Optimization Iteration:  34113, Training Accuracy:  81.2%, Loss: 0.3829\n",
      "Optimization Iteration:  34177, Training Accuracy:  76.6%, Loss: 0.3360\n",
      "Optimization Iteration:  34241, Training Accuracy:  76.6%, Loss: 0.4062\n",
      "Optimization Iteration:  34305, Training Accuracy:  79.7%, Loss: 0.3910\n",
      "Optimization Iteration:  34369, Training Accuracy:  87.5%, Loss: 0.2840\n",
      "Optimization Iteration:  34433, Training Accuracy:  78.1%, Loss: 0.5317\n",
      "Optimization Iteration:  34497, Training Accuracy:  79.7%, Loss: 0.3742\n",
      "Optimization Iteration:  34561, Training Accuracy:  71.9%, Loss: 0.4523\n",
      "Optimization Iteration:  34625, Training Accuracy:  70.3%, Loss: 0.5207\n",
      "Optimization Iteration:  34689, Training Accuracy:  64.1%, Loss: 0.5044\n",
      "Optimization Iteration:  34753, Training Accuracy:  75.0%, Loss: 0.4640\n",
      "Optimization Iteration:  34817, Training Accuracy:  78.1%, Loss: 0.3936\n",
      "Optimization Iteration:  34881, Training Accuracy:  71.9%, Loss: 0.3973\n",
      "Optimization Iteration:  34945, Training Accuracy:  84.4%, Loss: 0.4304\n",
      "Optimization Iteration:  35009, Training Accuracy:  78.1%, Loss: 0.3942\n",
      "Optimization Iteration:  35073, Training Accuracy:  71.9%, Loss: 0.4010\n",
      "Optimization Iteration:  35137, Training Accuracy:  71.9%, Loss: 0.3915\n",
      "Optimization Iteration:  35201, Training Accuracy:  78.1%, Loss: 0.3647\n",
      "Optimization Iteration:  35265, Training Accuracy:  76.6%, Loss: 0.3680\n",
      "Optimization Iteration:  35329, Training Accuracy:  78.1%, Loss: 0.4138\n",
      "Optimization Iteration:  35393, Training Accuracy:  76.6%, Loss: 0.3931\n",
      "Optimization Iteration:  35457, Training Accuracy:  76.6%, Loss: 0.4255\n",
      "Optimization Iteration:  35521, Training Accuracy:  65.6%, Loss: 0.4464\n",
      "Optimization Iteration:  35585, Training Accuracy:  82.8%, Loss: 0.3551\n",
      "Optimization Iteration:  35649, Training Accuracy:  68.8%, Loss: 0.5153\n",
      "Optimization Iteration:  35713, Training Accuracy:  73.4%, Loss: 0.4541\n",
      "Optimization Iteration:  35777, Training Accuracy:  81.2%, Loss: 0.3397\n",
      "Optimization Iteration:  35841, Training Accuracy:  76.6%, Loss: 0.4231\n",
      "Optimization Iteration:  35905, Training Accuracy:  78.1%, Loss: 0.3572\n",
      "Optimization Iteration:  35969, Training Accuracy:  79.7%, Loss: 0.4191\n",
      "Optimization Iteration:  36033, Training Accuracy:  67.2%, Loss: 0.4669\n",
      "Optimization Iteration:  36097, Training Accuracy:  67.2%, Loss: 0.5014\n",
      "Optimization Iteration:  36161, Training Accuracy:  75.0%, Loss: 0.3447\n",
      "Optimization Iteration:  36225, Training Accuracy:  81.2%, Loss: 0.3536\n",
      "Optimization Iteration:  36289, Training Accuracy:  79.7%, Loss: 0.3346\n",
      "Optimization Iteration:  36353, Training Accuracy:  79.7%, Loss: 0.3905\n",
      "Optimization Iteration:  36417, Training Accuracy:  84.4%, Loss: 0.4037\n",
      "Optimization Iteration:  36481, Training Accuracy:  76.6%, Loss: 0.3757\n",
      "Optimization Iteration:  36545, Training Accuracy:  79.7%, Loss: 0.4586\n",
      "Optimization Iteration:  36609, Training Accuracy:  81.2%, Loss: 0.3759\n",
      "Optimization Iteration:  36673, Training Accuracy:  78.1%, Loss: 0.4108\n",
      "Optimization Iteration:  36737, Training Accuracy:  78.1%, Loss: 0.3938\n",
      "Optimization Iteration:  36801, Training Accuracy:  82.8%, Loss: 0.3155\n",
      "Optimization Iteration:  36865, Training Accuracy:  71.9%, Loss: 0.3941\n",
      "Optimization Iteration:  36929, Training Accuracy:  70.3%, Loss: 0.4452\n",
      "Optimization Iteration:  36993, Training Accuracy:  67.2%, Loss: 0.4363\n",
      "Optimization Iteration:  37057, Training Accuracy:  73.4%, Loss: 0.3777\n",
      "Optimization Iteration:  37121, Training Accuracy:  79.7%, Loss: 0.2867\n",
      "Optimization Iteration:  37185, Training Accuracy:  75.0%, Loss: 0.4860\n",
      "Optimization Iteration:  37249, Training Accuracy:  64.1%, Loss: 0.5585\n",
      "Optimization Iteration:  37313, Training Accuracy:  75.0%, Loss: 0.3248\n",
      "Optimization Iteration:  37377, Training Accuracy:  70.3%, Loss: 0.5203\n",
      "Optimization Iteration:  37441, Training Accuracy:  78.1%, Loss: 0.3448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  37505, Training Accuracy:  70.3%, Loss: 0.4805\n",
      "Optimization Iteration:  37569, Training Accuracy:  67.2%, Loss: 0.4801\n",
      "Optimization Iteration:  37633, Training Accuracy:  76.6%, Loss: 0.3939\n",
      "Optimization Iteration:  37697, Training Accuracy:  79.7%, Loss: 0.3427\n",
      "Optimization Iteration:  37761, Training Accuracy:  67.2%, Loss: 0.4071\n",
      "Optimization Iteration:  37825, Training Accuracy:  76.6%, Loss: 0.3945\n",
      "Optimization Iteration:  37889, Training Accuracy:  73.4%, Loss: 0.4243\n",
      "Optimization Iteration:  37953, Training Accuracy:  87.5%, Loss: 0.3415\n",
      "Optimization Iteration:  38017, Training Accuracy:  75.0%, Loss: 0.4737\n",
      "Optimization Iteration:  38081, Training Accuracy:  68.8%, Loss: 0.4573\n",
      "Optimization Iteration:  38145, Training Accuracy:  78.1%, Loss: 0.3536\n",
      "Optimization Iteration:  38209, Training Accuracy:  73.4%, Loss: 0.4830\n",
      "Optimization Iteration:  38273, Training Accuracy:  81.2%, Loss: 0.3885\n",
      "Optimization Iteration:  38337, Training Accuracy:  81.2%, Loss: 0.3148\n",
      "Optimization Iteration:  38401, Training Accuracy:  76.6%, Loss: 0.4387\n",
      "Optimization Iteration:  38465, Training Accuracy:  75.0%, Loss: 0.4299\n",
      "Optimization Iteration:  38529, Training Accuracy:  84.4%, Loss: 0.4775\n",
      "Optimization Iteration:  38593, Training Accuracy:  67.2%, Loss: 0.5817\n",
      "Optimization Iteration:  38657, Training Accuracy:  75.0%, Loss: 0.4745\n",
      "Optimization Iteration:  38721, Training Accuracy:  76.6%, Loss: 0.3799\n",
      "Optimization Iteration:  38785, Training Accuracy:  75.0%, Loss: 0.4245\n",
      "Optimization Iteration:  38849, Training Accuracy:  84.4%, Loss: 0.3330\n",
      "Optimization Iteration:  38913, Training Accuracy:  78.1%, Loss: 0.4100\n",
      "Optimization Iteration:  38977, Training Accuracy:  78.1%, Loss: 0.3966\n",
      "Optimization Iteration:  39041, Training Accuracy:  75.0%, Loss: 0.3776\n",
      "Optimization Iteration:  39105, Training Accuracy:  73.4%, Loss: 0.4672\n",
      "Optimization Iteration:  39169, Training Accuracy:  73.4%, Loss: 0.4215\n",
      "Optimization Iteration:  39233, Training Accuracy:  73.4%, Loss: 0.4617\n",
      "Optimization Iteration:  39297, Training Accuracy:  73.4%, Loss: 0.3633\n",
      "Optimization Iteration:  39361, Training Accuracy:  78.1%, Loss: 0.3730\n",
      "Optimization Iteration:  39425, Training Accuracy:  75.0%, Loss: 0.3765\n",
      "Optimization Iteration:  39489, Training Accuracy:  79.7%, Loss: 0.3712\n",
      "Optimization Iteration:  39553, Training Accuracy:  79.7%, Loss: 0.3852\n",
      "Optimization Iteration:  39617, Training Accuracy:  73.4%, Loss: 0.4863\n",
      "Optimization Iteration:  39681, Training Accuracy:  62.5%, Loss: 0.4689\n",
      "Optimization Iteration:  39745, Training Accuracy:  75.0%, Loss: 0.4357\n",
      "Optimization Iteration:  39809, Training Accuracy:  70.3%, Loss: 0.4678\n",
      "Optimization Iteration:  39873, Training Accuracy:  65.6%, Loss: 0.4615\n",
      "Optimization Iteration:  39937, Training Accuracy:  73.4%, Loss: 0.5534\n",
      "Optimization Iteration:  40001, Training Accuracy:  68.8%, Loss: 0.4406\n",
      "Optimization Iteration:  40065, Training Accuracy:  70.3%, Loss: 0.4111\n",
      "Optimization Iteration:  40129, Training Accuracy:  64.1%, Loss: 0.5261\n",
      "Optimization Iteration:  40193, Training Accuracy:  89.1%, Loss: 0.2779\n",
      "Optimization Iteration:  40257, Training Accuracy:  71.9%, Loss: 0.3698\n",
      "Optimization Iteration:  40321, Training Accuracy:  75.0%, Loss: 0.3863\n",
      "Optimization Iteration:  40385, Training Accuracy:  76.6%, Loss: 0.4405\n",
      "Optimization Iteration:  40449, Training Accuracy:  71.9%, Loss: 0.3912\n",
      "Optimization Iteration:  40513, Training Accuracy:  75.0%, Loss: 0.3603\n",
      "Optimization Iteration:  40577, Training Accuracy:  75.0%, Loss: 0.4175\n",
      "Optimization Iteration:  40641, Training Accuracy:  75.0%, Loss: 0.4401\n",
      "Optimization Iteration:  40705, Training Accuracy:  75.0%, Loss: 0.3731\n",
      "Optimization Iteration:  40769, Training Accuracy:  68.8%, Loss: 0.3958\n",
      "Optimization Iteration:  40833, Training Accuracy:  79.7%, Loss: 0.3774\n",
      "Optimization Iteration:  40897, Training Accuracy:  78.1%, Loss: 0.4262\n",
      "Optimization Iteration:  40961, Training Accuracy:  84.4%, Loss: 0.3601\n",
      "Optimization Iteration:  41025, Training Accuracy:  87.5%, Loss: 0.3822\n",
      "Optimization Iteration:  41089, Training Accuracy:  81.2%, Loss: 0.3579\n",
      "Optimization Iteration:  41153, Training Accuracy:  76.6%, Loss: 0.4103\n",
      "Optimization Iteration:  41217, Training Accuracy:  79.7%, Loss: 0.4024\n",
      "Optimization Iteration:  41281, Training Accuracy:  68.8%, Loss: 0.4534\n",
      "Optimization Iteration:  41345, Training Accuracy:  76.6%, Loss: 0.4168\n",
      "Optimization Iteration:  41409, Training Accuracy:  71.9%, Loss: 0.4310\n",
      "Optimization Iteration:  41473, Training Accuracy:  76.6%, Loss: 0.4149\n",
      "Optimization Iteration:  41537, Training Accuracy:  76.6%, Loss: 0.4345\n",
      "Optimization Iteration:  41601, Training Accuracy:  70.3%, Loss: 0.3804\n",
      "Optimization Iteration:  41665, Training Accuracy:  78.1%, Loss: 0.3615\n",
      "Optimization Iteration:  41729, Training Accuracy:  78.1%, Loss: 0.3691\n",
      "Optimization Iteration:  41793, Training Accuracy:  68.8%, Loss: 0.4530\n",
      "Optimization Iteration:  41857, Training Accuracy:  73.4%, Loss: 0.4363\n",
      "Optimization Iteration:  41921, Training Accuracy:  73.4%, Loss: 0.4201\n",
      "Optimization Iteration:  41985, Training Accuracy:  76.6%, Loss: 0.4751\n",
      "Optimization Iteration:  42049, Training Accuracy:  81.2%, Loss: 0.3491\n",
      "Optimization Iteration:  42113, Training Accuracy:  84.4%, Loss: 0.3823\n",
      "Optimization Iteration:  42177, Training Accuracy:  62.5%, Loss: 0.4902\n",
      "Optimization Iteration:  42241, Training Accuracy:  73.4%, Loss: 0.4300\n",
      "Optimization Iteration:  42305, Training Accuracy:  78.1%, Loss: 0.5355\n",
      "Optimization Iteration:  42369, Training Accuracy:  68.8%, Loss: 0.3981\n",
      "Optimization Iteration:  42433, Training Accuracy:  70.3%, Loss: 0.4557\n",
      "Optimization Iteration:  42497, Training Accuracy:  64.1%, Loss: 0.4248\n",
      "Optimization Iteration:  42561, Training Accuracy:  81.2%, Loss: 0.4066\n",
      "Optimization Iteration:  42625, Training Accuracy:  81.2%, Loss: 0.3799\n",
      "Optimization Iteration:  42689, Training Accuracy:  79.7%, Loss: 0.3393\n",
      "Optimization Iteration:  42753, Training Accuracy:  78.1%, Loss: 0.4400\n",
      "Optimization Iteration:  42817, Training Accuracy:  81.2%, Loss: 0.3806\n",
      "Optimization Iteration:  42881, Training Accuracy:  71.9%, Loss: 0.4376\n",
      "Optimization Iteration:  42945, Training Accuracy:  73.4%, Loss: 0.3896\n",
      "Optimization Iteration:  43009, Training Accuracy:  75.0%, Loss: 0.4552\n",
      "Optimization Iteration:  43073, Training Accuracy:  79.7%, Loss: 0.4063\n",
      "Optimization Iteration:  43137, Training Accuracy:  81.2%, Loss: 0.3581\n",
      "Optimization Iteration:  43201, Training Accuracy:  67.2%, Loss: 0.4263\n",
      "Optimization Iteration:  43265, Training Accuracy:  79.7%, Loss: 0.3428\n",
      "Optimization Iteration:  43329, Training Accuracy:  75.0%, Loss: 0.4931\n",
      "Optimization Iteration:  43393, Training Accuracy:  70.3%, Loss: 0.3832\n",
      "Optimization Iteration:  43457, Training Accuracy:  82.8%, Loss: 0.3333\n",
      "Optimization Iteration:  43521, Training Accuracy:  78.1%, Loss: 0.4878\n",
      "Optimization Iteration:  43585, Training Accuracy:  79.7%, Loss: 0.3732\n",
      "Optimization Iteration:  43649, Training Accuracy:  75.0%, Loss: 0.4293\n",
      "Optimization Iteration:  43713, Training Accuracy:  71.9%, Loss: 0.3578\n",
      "Optimization Iteration:  43777, Training Accuracy:  75.0%, Loss: 0.3643\n",
      "Optimization Iteration:  43841, Training Accuracy:  70.3%, Loss: 0.4598\n",
      "Optimization Iteration:  43905, Training Accuracy:  75.0%, Loss: 0.4252\n",
      "Optimization Iteration:  43969, Training Accuracy:  76.6%, Loss: 0.3357\n",
      "Optimization Iteration:  44033, Training Accuracy:  79.7%, Loss: 0.4194\n",
      "Optimization Iteration:  44097, Training Accuracy:  73.4%, Loss: 0.3978\n",
      "Optimization Iteration:  44161, Training Accuracy:  76.6%, Loss: 0.3164\n",
      "Optimization Iteration:  44225, Training Accuracy:  78.1%, Loss: 0.3929\n",
      "Optimization Iteration:  44289, Training Accuracy:  76.6%, Loss: 0.3645\n",
      "Optimization Iteration:  44353, Training Accuracy:  75.0%, Loss: 0.4484\n",
      "Optimization Iteration:  44417, Training Accuracy:  71.9%, Loss: 0.4249\n",
      "Optimization Iteration:  44481, Training Accuracy:  65.6%, Loss: 0.4359\n",
      "Optimization Iteration:  44545, Training Accuracy:  75.0%, Loss: 0.3350\n",
      "Optimization Iteration:  44609, Training Accuracy:  81.2%, Loss: 0.3784\n",
      "Optimization Iteration:  44673, Training Accuracy:  76.6%, Loss: 0.4250\n",
      "Optimization Iteration:  44737, Training Accuracy:  73.4%, Loss: 0.4023\n",
      "Optimization Iteration:  44801, Training Accuracy:  78.1%, Loss: 0.3702\n",
      "Optimization Iteration:  44865, Training Accuracy:  70.3%, Loss: 0.4212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  44929, Training Accuracy:  82.8%, Loss: 0.3703\n",
      "Optimization Iteration:  44993, Training Accuracy:  73.4%, Loss: 0.4582\n",
      "Optimization Iteration:  45057, Training Accuracy:  76.6%, Loss: 0.4683\n",
      "Optimization Iteration:  45121, Training Accuracy:  81.2%, Loss: 0.3387\n",
      "Optimization Iteration:  45185, Training Accuracy:  78.1%, Loss: 0.3969\n",
      "Optimization Iteration:  45249, Training Accuracy:  70.3%, Loss: 0.4307\n",
      "Optimization Iteration:  45313, Training Accuracy:  76.6%, Loss: 0.4039\n",
      "Optimization Iteration:  45377, Training Accuracy:  75.0%, Loss: 0.4530\n",
      "Optimization Iteration:  45441, Training Accuracy:  75.0%, Loss: 0.4187\n",
      "Optimization Iteration:  45505, Training Accuracy:  75.0%, Loss: 0.4553\n",
      "Optimization Iteration:  45569, Training Accuracy:  67.2%, Loss: 0.4825\n",
      "Optimization Iteration:  45633, Training Accuracy:  79.7%, Loss: 0.4454\n",
      "Optimization Iteration:  45697, Training Accuracy:  76.6%, Loss: 0.4093\n",
      "Optimization Iteration:  45761, Training Accuracy:  89.1%, Loss: 0.2948\n",
      "Optimization Iteration:  45825, Training Accuracy:  73.4%, Loss: 0.3743\n",
      "Optimization Iteration:  45889, Training Accuracy:  78.1%, Loss: 0.3727\n",
      "Optimization Iteration:  45953, Training Accuracy:  76.6%, Loss: 0.3947\n",
      "Optimization Iteration:  46017, Training Accuracy:  73.4%, Loss: 0.4467\n",
      "Optimization Iteration:  46081, Training Accuracy:  79.7%, Loss: 0.3476\n",
      "Optimization Iteration:  46145, Training Accuracy:  78.1%, Loss: 0.3994\n",
      "Optimization Iteration:  46209, Training Accuracy:  71.9%, Loss: 0.4357\n",
      "Optimization Iteration:  46273, Training Accuracy:  64.1%, Loss: 0.4402\n",
      "Optimization Iteration:  46337, Training Accuracy:  76.6%, Loss: 0.4581\n",
      "Optimization Iteration:  46401, Training Accuracy:  78.1%, Loss: 0.3954\n",
      "Optimization Iteration:  46465, Training Accuracy:  75.0%, Loss: 0.4197\n",
      "Optimization Iteration:  46529, Training Accuracy:  68.8%, Loss: 0.4736\n",
      "Optimization Iteration:  46593, Training Accuracy:  70.3%, Loss: 0.4336\n",
      "Optimization Iteration:  46657, Training Accuracy:  79.7%, Loss: 0.4324\n",
      "Optimization Iteration:  46721, Training Accuracy:  73.4%, Loss: 0.4323\n",
      "Optimization Iteration:  46785, Training Accuracy:  70.3%, Loss: 0.4686\n",
      "Optimization Iteration:  46849, Training Accuracy:  70.3%, Loss: 0.4347\n",
      "Optimization Iteration:  46913, Training Accuracy:  76.6%, Loss: 0.3879\n",
      "Optimization Iteration:  46977, Training Accuracy:  68.8%, Loss: 0.4499\n",
      "Optimization Iteration:  47041, Training Accuracy:  78.1%, Loss: 0.3802\n",
      "Optimization Iteration:  47105, Training Accuracy:  76.6%, Loss: 0.4663\n",
      "Optimization Iteration:  47169, Training Accuracy:  67.2%, Loss: 0.4716\n",
      "Optimization Iteration:  47233, Training Accuracy:  71.9%, Loss: 0.4402\n",
      "Optimization Iteration:  47297, Training Accuracy:  75.0%, Loss: 0.4177\n",
      "Optimization Iteration:  47361, Training Accuracy:  81.2%, Loss: 0.3592\n",
      "Optimization Iteration:  47425, Training Accuracy:  75.0%, Loss: 0.4428\n",
      "Optimization Iteration:  47489, Training Accuracy:  71.9%, Loss: 0.3608\n",
      "Optimization Iteration:  47553, Training Accuracy:  76.6%, Loss: 0.4144\n",
      "Optimization Iteration:  47617, Training Accuracy:  71.9%, Loss: 0.4527\n",
      "Optimization Iteration:  47681, Training Accuracy:  75.0%, Loss: 0.3752\n",
      "Optimization Iteration:  47745, Training Accuracy:  75.0%, Loss: 0.4366\n",
      "Optimization Iteration:  47809, Training Accuracy:  73.4%, Loss: 0.4416\n",
      "Optimization Iteration:  47873, Training Accuracy:  79.7%, Loss: 0.3338\n",
      "Optimization Iteration:  47937, Training Accuracy:  75.0%, Loss: 0.4001\n",
      "Optimization Iteration:  48001, Training Accuracy:  76.6%, Loss: 0.4261\n",
      "Optimization Iteration:  48065, Training Accuracy:  76.6%, Loss: 0.3820\n",
      "Optimization Iteration:  48129, Training Accuracy:  70.3%, Loss: 0.4611\n",
      "Optimization Iteration:  48193, Training Accuracy:  70.3%, Loss: 0.4440\n",
      "Optimization Iteration:  48257, Training Accuracy:  78.1%, Loss: 0.3591\n",
      "Optimization Iteration:  48321, Training Accuracy:  79.7%, Loss: 0.3503\n",
      "Optimization Iteration:  48385, Training Accuracy:  78.1%, Loss: 0.3532\n",
      "Optimization Iteration:  48449, Training Accuracy:  79.7%, Loss: 0.3650\n",
      "Optimization Iteration:  48513, Training Accuracy:  75.0%, Loss: 0.4187\n",
      "Optimization Iteration:  48577, Training Accuracy:  65.6%, Loss: 0.5515\n",
      "Optimization Iteration:  48641, Training Accuracy:  76.6%, Loss: 0.4394\n",
      "Optimization Iteration:  48705, Training Accuracy:  73.4%, Loss: 0.4079\n",
      "Optimization Iteration:  48769, Training Accuracy:  73.4%, Loss: 0.3966\n",
      "Optimization Iteration:  48833, Training Accuracy:  82.8%, Loss: 0.3284\n",
      "Optimization Iteration:  48897, Training Accuracy:  79.7%, Loss: 0.4306\n",
      "Optimization Iteration:  48961, Training Accuracy:  73.4%, Loss: 0.4699\n",
      "Optimization Iteration:  49025, Training Accuracy:  70.3%, Loss: 0.4597\n",
      "Optimization Iteration:  49089, Training Accuracy:  76.6%, Loss: 0.3459\n",
      "Optimization Iteration:  49153, Training Accuracy:  76.6%, Loss: 0.4153\n",
      "Optimization Iteration:  49217, Training Accuracy:  81.2%, Loss: 0.3942\n",
      "Optimization Iteration:  49281, Training Accuracy:  71.9%, Loss: 0.3987\n",
      "Optimization Iteration:  49345, Training Accuracy:  79.7%, Loss: 0.4284\n",
      "Optimization Iteration:  49409, Training Accuracy:  73.4%, Loss: 0.5091\n",
      "Optimization Iteration:  49473, Training Accuracy:  70.3%, Loss: 0.4147\n",
      "Optimization Iteration:  49537, Training Accuracy:  67.2%, Loss: 0.4498\n",
      "Optimization Iteration:  49601, Training Accuracy:  79.7%, Loss: 0.3938\n",
      "Optimization Iteration:  49665, Training Accuracy:  82.8%, Loss: 0.3869\n",
      "Optimization Iteration:  49729, Training Accuracy:  65.6%, Loss: 0.5042\n",
      "Optimization Iteration:  49793, Training Accuracy:  70.3%, Loss: 0.4149\n",
      "Optimization Iteration:  49857, Training Accuracy:  73.4%, Loss: 0.4402\n",
      "Optimization Iteration:  49921, Training Accuracy:  79.7%, Loss: 0.4424\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 13\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  75.0%, Loss: 0.4309\n",
      "Optimization Iteration:    129, Training Accuracy:  75.0%, Loss: 0.4875\n",
      "Optimization Iteration:    193, Training Accuracy:  76.6%, Loss: 0.4388\n",
      "Optimization Iteration:    257, Training Accuracy:  71.9%, Loss: 0.4019\n",
      "Optimization Iteration:    321, Training Accuracy:  82.8%, Loss: 0.3723\n",
      "Optimization Iteration:    385, Training Accuracy:  75.0%, Loss: 0.3484\n",
      "Optimization Iteration:    449, Training Accuracy:  79.7%, Loss: 0.3957\n",
      "Optimization Iteration:    513, Training Accuracy:  75.0%, Loss: 0.4279\n",
      "Optimization Iteration:    577, Training Accuracy:  64.1%, Loss: 0.5228\n",
      "Optimization Iteration:    641, Training Accuracy:  76.6%, Loss: 0.3703\n",
      "Optimization Iteration:    705, Training Accuracy:  75.0%, Loss: 0.4265\n",
      "Optimization Iteration:    769, Training Accuracy:  73.4%, Loss: 0.4737\n",
      "Optimization Iteration:    833, Training Accuracy:  78.1%, Loss: 0.3921\n",
      "Optimization Iteration:    897, Training Accuracy:  68.8%, Loss: 0.3907\n",
      "Optimization Iteration:    961, Training Accuracy:  78.1%, Loss: 0.3799\n",
      "Optimization Iteration:   1025, Training Accuracy:  78.1%, Loss: 0.4000\n",
      "Optimization Iteration:   1089, Training Accuracy:  75.0%, Loss: 0.3254\n",
      "Optimization Iteration:   1153, Training Accuracy:  76.6%, Loss: 0.3814\n",
      "Optimization Iteration:   1217, Training Accuracy:  75.0%, Loss: 0.4181\n",
      "Optimization Iteration:   1281, Training Accuracy:  76.6%, Loss: 0.4286\n",
      "Optimization Iteration:   1345, Training Accuracy:  67.2%, Loss: 0.4337\n",
      "Optimization Iteration:   1409, Training Accuracy:  76.6%, Loss: 0.4178\n",
      "Optimization Iteration:   1473, Training Accuracy:  75.0%, Loss: 0.4178\n",
      "Optimization Iteration:   1537, Training Accuracy:  82.8%, Loss: 0.3214\n",
      "Optimization Iteration:   1601, Training Accuracy:  78.1%, Loss: 0.3721\n",
      "Optimization Iteration:   1665, Training Accuracy:  76.6%, Loss: 0.3556\n",
      "Optimization Iteration:   1729, Training Accuracy:  79.7%, Loss: 0.3791\n",
      "Optimization Iteration:   1793, Training Accuracy:  70.3%, Loss: 0.4847\n",
      "Optimization Iteration:   1857, Training Accuracy:  82.8%, Loss: 0.3315\n",
      "Optimization Iteration:   1921, Training Accuracy:  68.8%, Loss: 0.5082\n",
      "Optimization Iteration:   1985, Training Accuracy:  75.0%, Loss: 0.3983\n",
      "Optimization Iteration:   2049, Training Accuracy:  79.7%, Loss: 0.3193\n",
      "Optimization Iteration:   2113, Training Accuracy:  79.7%, Loss: 0.3451\n",
      "Optimization Iteration:   2177, Training Accuracy:  76.6%, Loss: 0.3772\n",
      "Optimization Iteration:   2241, Training Accuracy:  75.0%, Loss: 0.4284\n",
      "Optimization Iteration:   2305, Training Accuracy:  71.9%, Loss: 0.4126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   2369, Training Accuracy:  75.0%, Loss: 0.4525\n",
      "Optimization Iteration:   2433, Training Accuracy:  78.1%, Loss: 0.4180\n",
      "Optimization Iteration:   2497, Training Accuracy:  84.4%, Loss: 0.3216\n",
      "Optimization Iteration:   2561, Training Accuracy:  75.0%, Loss: 0.3368\n",
      "Optimization Iteration:   2625, Training Accuracy:  75.0%, Loss: 0.3827\n",
      "Optimization Iteration:   2689, Training Accuracy:  71.9%, Loss: 0.3953\n",
      "Optimization Iteration:   2753, Training Accuracy:  64.1%, Loss: 0.4930\n",
      "Optimization Iteration:   2817, Training Accuracy:  79.7%, Loss: 0.3644\n",
      "Optimization Iteration:   2881, Training Accuracy:  75.0%, Loss: 0.3809\n",
      "Optimization Iteration:   2945, Training Accuracy:  75.0%, Loss: 0.4922\n",
      "Optimization Iteration:   3009, Training Accuracy:  75.0%, Loss: 0.3868\n",
      "Optimization Iteration:   3073, Training Accuracy:  75.0%, Loss: 0.4023\n",
      "Optimization Iteration:   3137, Training Accuracy:  76.6%, Loss: 0.3681\n",
      "Optimization Iteration:   3201, Training Accuracy:  73.4%, Loss: 0.3877\n",
      "Optimization Iteration:   3265, Training Accuracy:  73.4%, Loss: 0.4405\n",
      "Optimization Iteration:   3329, Training Accuracy:  81.2%, Loss: 0.4173\n",
      "Optimization Iteration:   3393, Training Accuracy:  68.8%, Loss: 0.3907\n",
      "Optimization Iteration:   3457, Training Accuracy:  82.8%, Loss: 0.3926\n",
      "Optimization Iteration:   3521, Training Accuracy:  70.3%, Loss: 0.4100\n",
      "Optimization Iteration:   3585, Training Accuracy:  65.6%, Loss: 0.5108\n",
      "Optimization Iteration:   3649, Training Accuracy:  76.6%, Loss: 0.4061\n",
      "Optimization Iteration:   3713, Training Accuracy:  75.0%, Loss: 0.4281\n",
      "Optimization Iteration:   3777, Training Accuracy:  59.4%, Loss: 0.5487\n",
      "Optimization Iteration:   3841, Training Accuracy:  71.9%, Loss: 0.4029\n",
      "Optimization Iteration:   3905, Training Accuracy:  73.4%, Loss: 0.4901\n",
      "Optimization Iteration:   3969, Training Accuracy:  68.8%, Loss: 0.4458\n",
      "Optimization Iteration:   4033, Training Accuracy:  81.2%, Loss: 0.3320\n",
      "Optimization Iteration:   4097, Training Accuracy:  81.2%, Loss: 0.3880\n",
      "Optimization Iteration:   4161, Training Accuracy:  68.8%, Loss: 0.4552\n",
      "Optimization Iteration:   4225, Training Accuracy:  78.1%, Loss: 0.3794\n",
      "Optimization Iteration:   4289, Training Accuracy:  79.7%, Loss: 0.3514\n",
      "Optimization Iteration:   4353, Training Accuracy:  79.7%, Loss: 0.4277\n",
      "Optimization Iteration:   4417, Training Accuracy:  76.6%, Loss: 0.4008\n",
      "Optimization Iteration:   4481, Training Accuracy:  76.6%, Loss: 0.3717\n",
      "Optimization Iteration:   4545, Training Accuracy:  79.7%, Loss: 0.3789\n",
      "Optimization Iteration:   4609, Training Accuracy:  81.2%, Loss: 0.3411\n",
      "Optimization Iteration:   4673, Training Accuracy:  76.6%, Loss: 0.4247\n",
      "Optimization Iteration:   4737, Training Accuracy:  71.9%, Loss: 0.4124\n",
      "Optimization Iteration:   4801, Training Accuracy:  79.7%, Loss: 0.4362\n",
      "Optimization Iteration:   4865, Training Accuracy:  81.2%, Loss: 0.3899\n",
      "Optimization Iteration:   4929, Training Accuracy:  76.6%, Loss: 0.3869\n",
      "Optimization Iteration:   4993, Training Accuracy:  78.1%, Loss: 0.3672\n",
      "Optimization Iteration:   5057, Training Accuracy:  84.4%, Loss: 0.3752\n",
      "Optimization Iteration:   5121, Training Accuracy:  84.4%, Loss: 0.3083\n",
      "Optimization Iteration:   5185, Training Accuracy:  71.9%, Loss: 0.4013\n",
      "Optimization Iteration:   5249, Training Accuracy:  62.5%, Loss: 0.5178\n",
      "Optimization Iteration:   5313, Training Accuracy:  71.9%, Loss: 0.3968\n",
      "Optimization Iteration:   5377, Training Accuracy:  81.2%, Loss: 0.3652\n",
      "Optimization Iteration:   5441, Training Accuracy:  70.3%, Loss: 0.3900\n",
      "Optimization Iteration:   5505, Training Accuracy:  71.9%, Loss: 0.3495\n",
      "Optimization Iteration:   5569, Training Accuracy:  71.9%, Loss: 0.4400\n",
      "Optimization Iteration:   5633, Training Accuracy:  78.1%, Loss: 0.3347\n",
      "Optimization Iteration:   5697, Training Accuracy:  76.6%, Loss: 0.4075\n",
      "Optimization Iteration:   5761, Training Accuracy:  82.8%, Loss: 0.3704\n",
      "Optimization Iteration:   5825, Training Accuracy:  78.1%, Loss: 0.4719\n",
      "Optimization Iteration:   5889, Training Accuracy:  82.8%, Loss: 0.3904\n",
      "Optimization Iteration:   5953, Training Accuracy:  73.4%, Loss: 0.3603\n",
      "Optimization Iteration:   6017, Training Accuracy:  70.3%, Loss: 0.5133\n",
      "Optimization Iteration:   6081, Training Accuracy:  81.2%, Loss: 0.3570\n",
      "Optimization Iteration:   6145, Training Accuracy:  68.8%, Loss: 0.6268\n",
      "Optimization Iteration:   6209, Training Accuracy:  75.0%, Loss: 0.3880\n",
      "Optimization Iteration:   6273, Training Accuracy:  81.2%, Loss: 0.4483\n",
      "Optimization Iteration:   6337, Training Accuracy:  76.6%, Loss: 0.3984\n",
      "Optimization Iteration:   6401, Training Accuracy:  75.0%, Loss: 0.4231\n",
      "Optimization Iteration:   6465, Training Accuracy:  89.1%, Loss: 0.2584\n",
      "Optimization Iteration:   6529, Training Accuracy:  82.8%, Loss: 0.3772\n",
      "Optimization Iteration:   6593, Training Accuracy:  79.7%, Loss: 0.4110\n",
      "Optimization Iteration:   6657, Training Accuracy:  76.6%, Loss: 0.3649\n",
      "Optimization Iteration:   6721, Training Accuracy:  81.2%, Loss: 0.2965\n",
      "Optimization Iteration:   6785, Training Accuracy:  71.9%, Loss: 0.3772\n",
      "Optimization Iteration:   6849, Training Accuracy:  78.1%, Loss: 0.3934\n",
      "Optimization Iteration:   6913, Training Accuracy:  84.4%, Loss: 0.3181\n",
      "Optimization Iteration:   6977, Training Accuracy:  76.6%, Loss: 0.4063\n",
      "Optimization Iteration:   7041, Training Accuracy:  81.2%, Loss: 0.2877\n",
      "Optimization Iteration:   7105, Training Accuracy:  71.9%, Loss: 0.3914\n",
      "Optimization Iteration:   7169, Training Accuracy:  78.1%, Loss: 0.4201\n",
      "Optimization Iteration:   7233, Training Accuracy:  78.1%, Loss: 0.4649\n",
      "Optimization Iteration:   7297, Training Accuracy:  65.6%, Loss: 0.5839\n",
      "Optimization Iteration:   7361, Training Accuracy:  73.4%, Loss: 0.4393\n",
      "Optimization Iteration:   7425, Training Accuracy:  70.3%, Loss: 0.4145\n",
      "Optimization Iteration:   7489, Training Accuracy:  78.1%, Loss: 0.4144\n",
      "Optimization Iteration:   7553, Training Accuracy:  71.9%, Loss: 0.4997\n",
      "Optimization Iteration:   7617, Training Accuracy:  76.6%, Loss: 0.3955\n",
      "Optimization Iteration:   7681, Training Accuracy:  79.7%, Loss: 0.3561\n",
      "Optimization Iteration:   7745, Training Accuracy:  71.9%, Loss: 0.3890\n",
      "Optimization Iteration:   7809, Training Accuracy:  75.0%, Loss: 0.5157\n",
      "Optimization Iteration:   7873, Training Accuracy:  75.0%, Loss: 0.3558\n",
      "Optimization Iteration:   7937, Training Accuracy:  82.8%, Loss: 0.3133\n",
      "Optimization Iteration:   8001, Training Accuracy:  67.2%, Loss: 0.4719\n",
      "Optimization Iteration:   8065, Training Accuracy:  64.1%, Loss: 0.4420\n",
      "Optimization Iteration:   8129, Training Accuracy:  71.9%, Loss: 0.3764\n",
      "Optimization Iteration:   8193, Training Accuracy:  73.4%, Loss: 0.4653\n",
      "Optimization Iteration:   8257, Training Accuracy:  65.6%, Loss: 0.4315\n",
      "Optimization Iteration:   8321, Training Accuracy:  73.4%, Loss: 0.4338\n",
      "Optimization Iteration:   8385, Training Accuracy:  76.6%, Loss: 0.4459\n",
      "Optimization Iteration:   8449, Training Accuracy:  65.6%, Loss: 0.5344\n",
      "Optimization Iteration:   8513, Training Accuracy:  82.8%, Loss: 0.3443\n",
      "Optimization Iteration:   8577, Training Accuracy:  65.6%, Loss: 0.5706\n",
      "Optimization Iteration:   8641, Training Accuracy:  75.0%, Loss: 0.4210\n",
      "Optimization Iteration:   8705, Training Accuracy:  81.2%, Loss: 0.4344\n",
      "Optimization Iteration:   8769, Training Accuracy:  70.3%, Loss: 0.4546\n",
      "Optimization Iteration:   8833, Training Accuracy:  70.3%, Loss: 0.4971\n",
      "Optimization Iteration:   8897, Training Accuracy:  75.0%, Loss: 0.4304\n",
      "Optimization Iteration:   8961, Training Accuracy:  65.6%, Loss: 0.4498\n",
      "Optimization Iteration:   9025, Training Accuracy:  71.9%, Loss: 0.4863\n",
      "Optimization Iteration:   9089, Training Accuracy:  62.5%, Loss: 0.5231\n",
      "Optimization Iteration:   9153, Training Accuracy:  73.4%, Loss: 0.4072\n",
      "Optimization Iteration:   9217, Training Accuracy:  79.7%, Loss: 0.4081\n",
      "Optimization Iteration:   9281, Training Accuracy:  73.4%, Loss: 0.4118\n",
      "Optimization Iteration:   9345, Training Accuracy:  84.4%, Loss: 0.3303\n",
      "Optimization Iteration:   9409, Training Accuracy:  75.0%, Loss: 0.5406\n",
      "Optimization Iteration:   9473, Training Accuracy:  75.0%, Loss: 0.3785\n",
      "Optimization Iteration:   9537, Training Accuracy:  78.1%, Loss: 0.3519\n",
      "Optimization Iteration:   9601, Training Accuracy:  71.9%, Loss: 0.4372\n",
      "Optimization Iteration:   9665, Training Accuracy:  70.3%, Loss: 0.3896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   9729, Training Accuracy:  73.4%, Loss: 0.4298\n",
      "Optimization Iteration:   9793, Training Accuracy:  73.4%, Loss: 0.3904\n",
      "Optimization Iteration:   9857, Training Accuracy:  70.3%, Loss: 0.4557\n",
      "Optimization Iteration:   9921, Training Accuracy:  81.2%, Loss: 0.3623\n",
      "Optimization Iteration:   9985, Training Accuracy:  73.4%, Loss: 0.4495\n",
      "Optimization Iteration:  10049, Training Accuracy:  82.8%, Loss: 0.3607\n",
      "Optimization Iteration:  10113, Training Accuracy:  73.4%, Loss: 0.3981\n",
      "Optimization Iteration:  10177, Training Accuracy:  65.6%, Loss: 0.5462\n",
      "Optimization Iteration:  10241, Training Accuracy:  81.2%, Loss: 0.3879\n",
      "Optimization Iteration:  10305, Training Accuracy:  85.9%, Loss: 0.4176\n",
      "Optimization Iteration:  10369, Training Accuracy:  73.4%, Loss: 0.4002\n",
      "Optimization Iteration:  10433, Training Accuracy:  76.6%, Loss: 0.3500\n",
      "Optimization Iteration:  10497, Training Accuracy:  70.3%, Loss: 0.4951\n",
      "Optimization Iteration:  10561, Training Accuracy:  82.8%, Loss: 0.2989\n",
      "Optimization Iteration:  10625, Training Accuracy:  78.1%, Loss: 0.3763\n",
      "Optimization Iteration:  10689, Training Accuracy:  82.8%, Loss: 0.3262\n",
      "Optimization Iteration:  10753, Training Accuracy:  76.6%, Loss: 0.4270\n",
      "Optimization Iteration:  10817, Training Accuracy:  75.0%, Loss: 0.4502\n",
      "Optimization Iteration:  10881, Training Accuracy:  79.7%, Loss: 0.3156\n",
      "Optimization Iteration:  10945, Training Accuracy:  81.2%, Loss: 0.3593\n",
      "Optimization Iteration:  11009, Training Accuracy:  78.1%, Loss: 0.3285\n",
      "Optimization Iteration:  11073, Training Accuracy:  85.9%, Loss: 0.3292\n",
      "Optimization Iteration:  11137, Training Accuracy:  79.7%, Loss: 0.3983\n",
      "Optimization Iteration:  11201, Training Accuracy:  76.6%, Loss: 0.3816\n",
      "Optimization Iteration:  11265, Training Accuracy:  76.6%, Loss: 0.3264\n",
      "Optimization Iteration:  11329, Training Accuracy:  73.4%, Loss: 0.5207\n",
      "Optimization Iteration:  11393, Training Accuracy:  78.1%, Loss: 0.4090\n",
      "Optimization Iteration:  11457, Training Accuracy:  82.8%, Loss: 0.3960\n",
      "Optimization Iteration:  11521, Training Accuracy:  76.6%, Loss: 0.3684\n",
      "Optimization Iteration:  11585, Training Accuracy:  81.2%, Loss: 0.3628\n",
      "Optimization Iteration:  11649, Training Accuracy:  68.8%, Loss: 0.4845\n",
      "Optimization Iteration:  11713, Training Accuracy:  73.4%, Loss: 0.3622\n",
      "Optimization Iteration:  11777, Training Accuracy:  81.2%, Loss: 0.4243\n",
      "Optimization Iteration:  11841, Training Accuracy:  73.4%, Loss: 0.3775\n",
      "Optimization Iteration:  11905, Training Accuracy:  84.4%, Loss: 0.3470\n",
      "Optimization Iteration:  11969, Training Accuracy:  78.1%, Loss: 0.3541\n",
      "Optimization Iteration:  12033, Training Accuracy:  78.1%, Loss: 0.4210\n",
      "Optimization Iteration:  12097, Training Accuracy:  79.7%, Loss: 0.3698\n",
      "Optimization Iteration:  12161, Training Accuracy:  76.6%, Loss: 0.4503\n",
      "Optimization Iteration:  12225, Training Accuracy:  78.1%, Loss: 0.3318\n",
      "Optimization Iteration:  12289, Training Accuracy:  79.7%, Loss: 0.3580\n",
      "Optimization Iteration:  12353, Training Accuracy:  79.7%, Loss: 0.3787\n",
      "Optimization Iteration:  12417, Training Accuracy:  76.6%, Loss: 0.3806\n",
      "Optimization Iteration:  12481, Training Accuracy:  73.4%, Loss: 0.4215\n",
      "Optimization Iteration:  12545, Training Accuracy:  73.4%, Loss: 0.4116\n",
      "Optimization Iteration:  12609, Training Accuracy:  82.8%, Loss: 0.3152\n",
      "Optimization Iteration:  12673, Training Accuracy:  78.1%, Loss: 0.3822\n",
      "Optimization Iteration:  12737, Training Accuracy:  65.6%, Loss: 0.4900\n",
      "Optimization Iteration:  12801, Training Accuracy:  78.1%, Loss: 0.4161\n",
      "Optimization Iteration:  12865, Training Accuracy:  73.4%, Loss: 0.4997\n",
      "Optimization Iteration:  12929, Training Accuracy:  75.0%, Loss: 0.4302\n",
      "Optimization Iteration:  12993, Training Accuracy:  73.4%, Loss: 0.3652\n",
      "Optimization Iteration:  13057, Training Accuracy:  76.6%, Loss: 0.4077\n",
      "Optimization Iteration:  13121, Training Accuracy:  85.9%, Loss: 0.3363\n",
      "Optimization Iteration:  13185, Training Accuracy:  78.1%, Loss: 0.4441\n",
      "Optimization Iteration:  13249, Training Accuracy:  75.0%, Loss: 0.4727\n",
      "Optimization Iteration:  13313, Training Accuracy:  76.6%, Loss: 0.4904\n",
      "Optimization Iteration:  13377, Training Accuracy:  71.9%, Loss: 0.4418\n",
      "Optimization Iteration:  13441, Training Accuracy:  73.4%, Loss: 0.3809\n",
      "Optimization Iteration:  13505, Training Accuracy:  76.6%, Loss: 0.4206\n",
      "Optimization Iteration:  13569, Training Accuracy:  84.4%, Loss: 0.3412\n",
      "Optimization Iteration:  13633, Training Accuracy:  78.1%, Loss: 0.3693\n",
      "Optimization Iteration:  13697, Training Accuracy:  75.0%, Loss: 0.3767\n",
      "Optimization Iteration:  13761, Training Accuracy:  84.4%, Loss: 0.3687\n",
      "Optimization Iteration:  13825, Training Accuracy:  76.6%, Loss: 0.3788\n",
      "Optimization Iteration:  13889, Training Accuracy:  75.0%, Loss: 0.5949\n",
      "Optimization Iteration:  13953, Training Accuracy:  87.5%, Loss: 0.3177\n",
      "Optimization Iteration:  14017, Training Accuracy:  73.4%, Loss: 0.3896\n",
      "Optimization Iteration:  14081, Training Accuracy:  73.4%, Loss: 0.3722\n",
      "Optimization Iteration:  14145, Training Accuracy:  81.2%, Loss: 0.3821\n",
      "Optimization Iteration:  14209, Training Accuracy:  81.2%, Loss: 0.4825\n",
      "Optimization Iteration:  14273, Training Accuracy:  62.5%, Loss: 0.5717\n",
      "Optimization Iteration:  14337, Training Accuracy:  78.1%, Loss: 0.3411\n",
      "Optimization Iteration:  14401, Training Accuracy:  85.9%, Loss: 0.3666\n",
      "Optimization Iteration:  14465, Training Accuracy:  68.8%, Loss: 0.5068\n",
      "Optimization Iteration:  14529, Training Accuracy:  75.0%, Loss: 0.5639\n",
      "Optimization Iteration:  14593, Training Accuracy:  85.9%, Loss: 0.3339\n",
      "Optimization Iteration:  14657, Training Accuracy:  71.9%, Loss: 0.4270\n",
      "Optimization Iteration:  14721, Training Accuracy:  79.7%, Loss: 0.3718\n",
      "Optimization Iteration:  14785, Training Accuracy:  79.7%, Loss: 0.4148\n",
      "Optimization Iteration:  14849, Training Accuracy:  67.2%, Loss: 0.4188\n",
      "Optimization Iteration:  14913, Training Accuracy:  84.4%, Loss: 0.2871\n",
      "Optimization Iteration:  14977, Training Accuracy:  73.4%, Loss: 0.4573\n",
      "Optimization Iteration:  15041, Training Accuracy:  67.2%, Loss: 0.4347\n",
      "Optimization Iteration:  15105, Training Accuracy:  68.8%, Loss: 0.4730\n",
      "Optimization Iteration:  15169, Training Accuracy:  67.2%, Loss: 0.4271\n",
      "Optimization Iteration:  15233, Training Accuracy:  73.4%, Loss: 0.3885\n",
      "Optimization Iteration:  15297, Training Accuracy:  78.1%, Loss: 0.3676\n",
      "Optimization Iteration:  15361, Training Accuracy:  81.2%, Loss: 0.4035\n",
      "Optimization Iteration:  15425, Training Accuracy:  71.9%, Loss: 0.4515\n",
      "Optimization Iteration:  15489, Training Accuracy:  65.6%, Loss: 0.4409\n",
      "Optimization Iteration:  15553, Training Accuracy:  67.2%, Loss: 0.3583\n",
      "Optimization Iteration:  15617, Training Accuracy:  76.6%, Loss: 0.4169\n",
      "Optimization Iteration:  15681, Training Accuracy:  85.9%, Loss: 0.3545\n",
      "Optimization Iteration:  15745, Training Accuracy:  78.1%, Loss: 0.3175\n",
      "Optimization Iteration:  15809, Training Accuracy:  71.9%, Loss: 0.4577\n",
      "Optimization Iteration:  15873, Training Accuracy:  70.3%, Loss: 0.4724\n",
      "Optimization Iteration:  15937, Training Accuracy:  70.3%, Loss: 0.4309\n",
      "Optimization Iteration:  16001, Training Accuracy:  65.6%, Loss: 0.4853\n",
      "Optimization Iteration:  16065, Training Accuracy:  68.8%, Loss: 0.4009\n",
      "Optimization Iteration:  16129, Training Accuracy:  71.9%, Loss: 0.3581\n",
      "Optimization Iteration:  16193, Training Accuracy:  73.4%, Loss: 0.3874\n",
      "Optimization Iteration:  16257, Training Accuracy:  70.3%, Loss: 0.4243\n",
      "Optimization Iteration:  16321, Training Accuracy:  79.7%, Loss: 0.3951\n",
      "Optimization Iteration:  16385, Training Accuracy:  78.1%, Loss: 0.4260\n",
      "Optimization Iteration:  16449, Training Accuracy:  78.1%, Loss: 0.3815\n",
      "Optimization Iteration:  16513, Training Accuracy:  70.3%, Loss: 0.4773\n",
      "Optimization Iteration:  16577, Training Accuracy:  79.7%, Loss: 0.3694\n",
      "Optimization Iteration:  16641, Training Accuracy:  70.3%, Loss: 0.4593\n",
      "Optimization Iteration:  16705, Training Accuracy:  76.6%, Loss: 0.3989\n",
      "Optimization Iteration:  16769, Training Accuracy:  82.8%, Loss: 0.3376\n",
      "Optimization Iteration:  16833, Training Accuracy:  75.0%, Loss: 0.3565\n",
      "Optimization Iteration:  16897, Training Accuracy:  73.4%, Loss: 0.3737\n",
      "Optimization Iteration:  16961, Training Accuracy:  67.2%, Loss: 0.4523\n",
      "Optimization Iteration:  17025, Training Accuracy:  67.2%, Loss: 0.4973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  17089, Training Accuracy:  84.4%, Loss: 0.4356\n",
      "Optimization Iteration:  17153, Training Accuracy:  73.4%, Loss: 0.4367\n",
      "Optimization Iteration:  17217, Training Accuracy:  64.1%, Loss: 0.4486\n",
      "Optimization Iteration:  17281, Training Accuracy:  67.2%, Loss: 0.4510\n",
      "Optimization Iteration:  17345, Training Accuracy:  79.7%, Loss: 0.3263\n",
      "Optimization Iteration:  17409, Training Accuracy:  73.4%, Loss: 0.4115\n",
      "Optimization Iteration:  17473, Training Accuracy:  64.1%, Loss: 0.6149\n",
      "Optimization Iteration:  17537, Training Accuracy:  82.8%, Loss: 0.3293\n",
      "Optimization Iteration:  17601, Training Accuracy:  78.1%, Loss: 0.3984\n",
      "Optimization Iteration:  17665, Training Accuracy:  70.3%, Loss: 0.4429\n",
      "Optimization Iteration:  17729, Training Accuracy:  70.3%, Loss: 0.4316\n",
      "Optimization Iteration:  17793, Training Accuracy:  73.4%, Loss: 0.4883\n",
      "Optimization Iteration:  17857, Training Accuracy:  81.2%, Loss: 0.4287\n",
      "Optimization Iteration:  17921, Training Accuracy:  79.7%, Loss: 0.3379\n",
      "Optimization Iteration:  17985, Training Accuracy:  82.8%, Loss: 0.3132\n",
      "Optimization Iteration:  18049, Training Accuracy:  76.6%, Loss: 0.3369\n",
      "Optimization Iteration:  18113, Training Accuracy:  67.2%, Loss: 0.4932\n",
      "Optimization Iteration:  18177, Training Accuracy:  76.6%, Loss: 0.4758\n",
      "Optimization Iteration:  18241, Training Accuracy:  73.4%, Loss: 0.4204\n",
      "Optimization Iteration:  18305, Training Accuracy:  71.9%, Loss: 0.3945\n",
      "Optimization Iteration:  18369, Training Accuracy:  76.6%, Loss: 0.3728\n",
      "Optimization Iteration:  18433, Training Accuracy:  68.8%, Loss: 0.4683\n",
      "Optimization Iteration:  18497, Training Accuracy:  82.8%, Loss: 0.4008\n",
      "Optimization Iteration:  18561, Training Accuracy:  71.9%, Loss: 0.4588\n",
      "Optimization Iteration:  18625, Training Accuracy:  73.4%, Loss: 0.4375\n",
      "Optimization Iteration:  18689, Training Accuracy:  62.5%, Loss: 0.4421\n",
      "Optimization Iteration:  18753, Training Accuracy:  76.6%, Loss: 0.3437\n",
      "Optimization Iteration:  18817, Training Accuracy:  78.1%, Loss: 0.3196\n",
      "Optimization Iteration:  18881, Training Accuracy:  73.4%, Loss: 0.3986\n",
      "Optimization Iteration:  18945, Training Accuracy:  78.1%, Loss: 0.4327\n",
      "Optimization Iteration:  19009, Training Accuracy:  75.0%, Loss: 0.3781\n",
      "Optimization Iteration:  19073, Training Accuracy:  79.7%, Loss: 0.4009\n",
      "Optimization Iteration:  19137, Training Accuracy:  70.3%, Loss: 0.5011\n",
      "Optimization Iteration:  19201, Training Accuracy:  79.7%, Loss: 0.4101\n",
      "Optimization Iteration:  19265, Training Accuracy:  85.9%, Loss: 0.4092\n",
      "Optimization Iteration:  19329, Training Accuracy:  78.1%, Loss: 0.3372\n",
      "Optimization Iteration:  19393, Training Accuracy:  59.4%, Loss: 0.4908\n",
      "Optimization Iteration:  19457, Training Accuracy:  70.3%, Loss: 0.4413\n",
      "Optimization Iteration:  19521, Training Accuracy:  78.1%, Loss: 0.4079\n",
      "Optimization Iteration:  19585, Training Accuracy:  68.8%, Loss: 0.4427\n",
      "Optimization Iteration:  19649, Training Accuracy:  78.1%, Loss: 0.4843\n",
      "Optimization Iteration:  19713, Training Accuracy:  82.8%, Loss: 0.2952\n",
      "Optimization Iteration:  19777, Training Accuracy:  79.7%, Loss: 0.3883\n",
      "Optimization Iteration:  19841, Training Accuracy:  75.0%, Loss: 0.4260\n",
      "Optimization Iteration:  19905, Training Accuracy:  71.9%, Loss: 0.4027\n",
      "Optimization Iteration:  19969, Training Accuracy:  79.7%, Loss: 0.3686\n",
      "Optimization Iteration:  20033, Training Accuracy:  78.1%, Loss: 0.4064\n",
      "Optimization Iteration:  20097, Training Accuracy:  70.3%, Loss: 0.4292\n",
      "Optimization Iteration:  20161, Training Accuracy:  67.2%, Loss: 0.4440\n",
      "Optimization Iteration:  20225, Training Accuracy:  64.1%, Loss: 0.4744\n",
      "Optimization Iteration:  20289, Training Accuracy:  70.3%, Loss: 0.4036\n",
      "Optimization Iteration:  20353, Training Accuracy:  81.2%, Loss: 0.3764\n",
      "Optimization Iteration:  20417, Training Accuracy:  67.2%, Loss: 0.4245\n",
      "Optimization Iteration:  20481, Training Accuracy:  78.1%, Loss: 0.3932\n",
      "Optimization Iteration:  20545, Training Accuracy:  73.4%, Loss: 0.4106\n",
      "Optimization Iteration:  20609, Training Accuracy:  70.3%, Loss: 0.4616\n",
      "Optimization Iteration:  20673, Training Accuracy:  70.3%, Loss: 0.4438\n",
      "Optimization Iteration:  20737, Training Accuracy:  81.2%, Loss: 0.3831\n",
      "Optimization Iteration:  20801, Training Accuracy:  71.9%, Loss: 0.4222\n",
      "Optimization Iteration:  20865, Training Accuracy:  79.7%, Loss: 0.4042\n",
      "Optimization Iteration:  20929, Training Accuracy:  78.1%, Loss: 0.3509\n",
      "Optimization Iteration:  20993, Training Accuracy:  78.1%, Loss: 0.3601\n",
      "Optimization Iteration:  21057, Training Accuracy:  71.9%, Loss: 0.3896\n",
      "Optimization Iteration:  21121, Training Accuracy:  70.3%, Loss: 0.4099\n",
      "Optimization Iteration:  21185, Training Accuracy:  71.9%, Loss: 0.4274\n",
      "Optimization Iteration:  21249, Training Accuracy:  73.4%, Loss: 0.4557\n",
      "Optimization Iteration:  21313, Training Accuracy:  82.8%, Loss: 0.4479\n",
      "Optimization Iteration:  21377, Training Accuracy:  78.1%, Loss: 0.3294\n",
      "Optimization Iteration:  21441, Training Accuracy:  68.8%, Loss: 0.4419\n",
      "Optimization Iteration:  21505, Training Accuracy:  76.6%, Loss: 0.4019\n",
      "Optimization Iteration:  21569, Training Accuracy:  78.1%, Loss: 0.3558\n",
      "Optimization Iteration:  21633, Training Accuracy:  81.2%, Loss: 0.3178\n",
      "Optimization Iteration:  21697, Training Accuracy:  65.6%, Loss: 0.5996\n",
      "Optimization Iteration:  21761, Training Accuracy:  76.6%, Loss: 0.3281\n",
      "Optimization Iteration:  21825, Training Accuracy:  78.1%, Loss: 0.4329\n",
      "Optimization Iteration:  21889, Training Accuracy:  68.8%, Loss: 0.3755\n",
      "Optimization Iteration:  21953, Training Accuracy:  68.8%, Loss: 0.5516\n",
      "Optimization Iteration:  22017, Training Accuracy:  82.8%, Loss: 0.4123\n",
      "Optimization Iteration:  22081, Training Accuracy:  84.4%, Loss: 0.3862\n",
      "Optimization Iteration:  22145, Training Accuracy:  81.2%, Loss: 0.3652\n",
      "Optimization Iteration:  22209, Training Accuracy:  81.2%, Loss: 0.3677\n",
      "Optimization Iteration:  22273, Training Accuracy:  79.7%, Loss: 0.3967\n",
      "Optimization Iteration:  22337, Training Accuracy:  70.3%, Loss: 0.3760\n",
      "Optimization Iteration:  22401, Training Accuracy:  73.4%, Loss: 0.4100\n",
      "Optimization Iteration:  22465, Training Accuracy:  73.4%, Loss: 0.4711\n",
      "Optimization Iteration:  22529, Training Accuracy:  79.7%, Loss: 0.4059\n",
      "Optimization Iteration:  22593, Training Accuracy:  76.6%, Loss: 0.4229\n",
      "Optimization Iteration:  22657, Training Accuracy:  76.6%, Loss: 0.3755\n",
      "Optimization Iteration:  22721, Training Accuracy:  76.6%, Loss: 0.4450\n",
      "Optimization Iteration:  22785, Training Accuracy:  76.6%, Loss: 0.4586\n",
      "Optimization Iteration:  22849, Training Accuracy:  76.6%, Loss: 0.3761\n",
      "Optimization Iteration:  22913, Training Accuracy:  78.1%, Loss: 0.4225\n",
      "Optimization Iteration:  22977, Training Accuracy:  81.2%, Loss: 0.3697\n",
      "Optimization Iteration:  23041, Training Accuracy:  81.2%, Loss: 0.3079\n",
      "Optimization Iteration:  23105, Training Accuracy:  68.8%, Loss: 0.3714\n",
      "Optimization Iteration:  23169, Training Accuracy:  82.8%, Loss: 0.3314\n",
      "Optimization Iteration:  23233, Training Accuracy:  71.9%, Loss: 0.5677\n",
      "Optimization Iteration:  23297, Training Accuracy:  70.3%, Loss: 0.4842\n",
      "Optimization Iteration:  23361, Training Accuracy:  59.4%, Loss: 0.4906\n",
      "Optimization Iteration:  23425, Training Accuracy:  79.7%, Loss: 0.4082\n",
      "Optimization Iteration:  23489, Training Accuracy:  67.2%, Loss: 0.5400\n",
      "Optimization Iteration:  23553, Training Accuracy:  78.1%, Loss: 0.3669\n",
      "Optimization Iteration:  23617, Training Accuracy:  67.2%, Loss: 0.4940\n",
      "Optimization Iteration:  23681, Training Accuracy:  78.1%, Loss: 0.4559\n",
      "Optimization Iteration:  23745, Training Accuracy:  73.4%, Loss: 0.4192\n",
      "Optimization Iteration:  23809, Training Accuracy:  70.3%, Loss: 0.5070\n",
      "Optimization Iteration:  23873, Training Accuracy:  70.3%, Loss: 0.3968\n",
      "Optimization Iteration:  23937, Training Accuracy:  60.9%, Loss: 0.4728\n",
      "Optimization Iteration:  24001, Training Accuracy:  76.6%, Loss: 0.3211\n",
      "Optimization Iteration:  24065, Training Accuracy:  70.3%, Loss: 0.4042\n",
      "Optimization Iteration:  24129, Training Accuracy:  82.8%, Loss: 0.3325\n",
      "Optimization Iteration:  24193, Training Accuracy:  76.6%, Loss: 0.4109\n",
      "Optimization Iteration:  24257, Training Accuracy:  75.0%, Loss: 0.3807\n",
      "Optimization Iteration:  24321, Training Accuracy:  76.6%, Loss: 0.4669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  24385, Training Accuracy:  75.0%, Loss: 0.3844\n",
      "Optimization Iteration:  24449, Training Accuracy:  79.7%, Loss: 0.3362\n",
      "Optimization Iteration:  24513, Training Accuracy:  78.1%, Loss: 0.4020\n",
      "Optimization Iteration:  24577, Training Accuracy:  68.8%, Loss: 0.5093\n",
      "Optimization Iteration:  24641, Training Accuracy:  73.4%, Loss: 0.3945\n",
      "Optimization Iteration:  24705, Training Accuracy:  76.6%, Loss: 0.3436\n",
      "Optimization Iteration:  24769, Training Accuracy:  79.7%, Loss: 0.3910\n",
      "Optimization Iteration:  24833, Training Accuracy:  75.0%, Loss: 0.4762\n",
      "Optimization Iteration:  24897, Training Accuracy:  68.8%, Loss: 0.3989\n",
      "Optimization Iteration:  24961, Training Accuracy:  84.4%, Loss: 0.3154\n",
      "Optimization Iteration:  25025, Training Accuracy:  70.3%, Loss: 0.3948\n",
      "Optimization Iteration:  25089, Training Accuracy:  70.3%, Loss: 0.3960\n",
      "Optimization Iteration:  25153, Training Accuracy:  76.6%, Loss: 0.4141\n",
      "Optimization Iteration:  25217, Training Accuracy:  70.3%, Loss: 0.4972\n",
      "Optimization Iteration:  25281, Training Accuracy:  76.6%, Loss: 0.4007\n",
      "Optimization Iteration:  25345, Training Accuracy:  76.6%, Loss: 0.3626\n",
      "Optimization Iteration:  25409, Training Accuracy:  75.0%, Loss: 0.4269\n",
      "Optimization Iteration:  25473, Training Accuracy:  76.6%, Loss: 0.4822\n",
      "Optimization Iteration:  25537, Training Accuracy:  75.0%, Loss: 0.3479\n",
      "Optimization Iteration:  25601, Training Accuracy:  67.2%, Loss: 0.5348\n",
      "Optimization Iteration:  25665, Training Accuracy:  71.9%, Loss: 0.5271\n",
      "Optimization Iteration:  25729, Training Accuracy:  82.8%, Loss: 0.3367\n",
      "Optimization Iteration:  25793, Training Accuracy:  79.7%, Loss: 0.3401\n",
      "Optimization Iteration:  25857, Training Accuracy:  71.9%, Loss: 0.4211\n",
      "Optimization Iteration:  25921, Training Accuracy:  82.8%, Loss: 0.3669\n",
      "Optimization Iteration:  25985, Training Accuracy:  68.8%, Loss: 0.5396\n",
      "Optimization Iteration:  26049, Training Accuracy:  82.8%, Loss: 0.3702\n",
      "Optimization Iteration:  26113, Training Accuracy:  75.0%, Loss: 0.4160\n",
      "Optimization Iteration:  26177, Training Accuracy:  76.6%, Loss: 0.4065\n",
      "Optimization Iteration:  26241, Training Accuracy:  73.4%, Loss: 0.4052\n",
      "Optimization Iteration:  26305, Training Accuracy:  79.7%, Loss: 0.4079\n",
      "Optimization Iteration:  26369, Training Accuracy:  84.4%, Loss: 0.3514\n",
      "Optimization Iteration:  26433, Training Accuracy:  73.4%, Loss: 0.3974\n",
      "Optimization Iteration:  26497, Training Accuracy:  60.9%, Loss: 0.4686\n",
      "Optimization Iteration:  26561, Training Accuracy:  79.7%, Loss: 0.3542\n",
      "Optimization Iteration:  26625, Training Accuracy:  79.7%, Loss: 0.3654\n",
      "Optimization Iteration:  26689, Training Accuracy:  79.7%, Loss: 0.3613\n",
      "Optimization Iteration:  26753, Training Accuracy:  73.4%, Loss: 0.4434\n",
      "Optimization Iteration:  26817, Training Accuracy:  75.0%, Loss: 0.4751\n",
      "Optimization Iteration:  26881, Training Accuracy:  90.6%, Loss: 0.3024\n",
      "Optimization Iteration:  26945, Training Accuracy:  75.0%, Loss: 0.4447\n",
      "Optimization Iteration:  27009, Training Accuracy:  75.0%, Loss: 0.4194\n",
      "Optimization Iteration:  27073, Training Accuracy:  78.1%, Loss: 0.3900\n",
      "Optimization Iteration:  27137, Training Accuracy:  79.7%, Loss: 0.4180\n",
      "Optimization Iteration:  27201, Training Accuracy:  84.4%, Loss: 0.2898\n",
      "Optimization Iteration:  27265, Training Accuracy:  73.4%, Loss: 0.4326\n",
      "Optimization Iteration:  27329, Training Accuracy:  82.8%, Loss: 0.3233\n",
      "Optimization Iteration:  27393, Training Accuracy:  76.6%, Loss: 0.4220\n",
      "Optimization Iteration:  27457, Training Accuracy:  78.1%, Loss: 0.3968\n",
      "Optimization Iteration:  27521, Training Accuracy:  71.9%, Loss: 0.4255\n",
      "Optimization Iteration:  27585, Training Accuracy:  82.8%, Loss: 0.4199\n",
      "Optimization Iteration:  27649, Training Accuracy:  76.6%, Loss: 0.4063\n",
      "Optimization Iteration:  27713, Training Accuracy:  78.1%, Loss: 0.4064\n",
      "Optimization Iteration:  27777, Training Accuracy:  81.2%, Loss: 0.3513\n",
      "Optimization Iteration:  27841, Training Accuracy:  73.4%, Loss: 0.4338\n",
      "Optimization Iteration:  27905, Training Accuracy:  75.0%, Loss: 0.4441\n",
      "Optimization Iteration:  27969, Training Accuracy:  65.6%, Loss: 0.4841\n",
      "Optimization Iteration:  28033, Training Accuracy:  78.1%, Loss: 0.4246\n",
      "Optimization Iteration:  28097, Training Accuracy:  79.7%, Loss: 0.4009\n",
      "Optimization Iteration:  28161, Training Accuracy:  87.5%, Loss: 0.2757\n",
      "Optimization Iteration:  28225, Training Accuracy:  73.4%, Loss: 0.3808\n",
      "Optimization Iteration:  28289, Training Accuracy:  67.2%, Loss: 0.4569\n",
      "Optimization Iteration:  28353, Training Accuracy:  76.6%, Loss: 0.3728\n",
      "Optimization Iteration:  28417, Training Accuracy:  67.2%, Loss: 0.5137\n",
      "Optimization Iteration:  28481, Training Accuracy:  78.1%, Loss: 0.3924\n",
      "Optimization Iteration:  28545, Training Accuracy:  71.9%, Loss: 0.4063\n",
      "Optimization Iteration:  28609, Training Accuracy:  81.2%, Loss: 0.4202\n",
      "Optimization Iteration:  28673, Training Accuracy:  75.0%, Loss: 0.3737\n",
      "Optimization Iteration:  28737, Training Accuracy:  71.9%, Loss: 0.4225\n",
      "Optimization Iteration:  28801, Training Accuracy:  73.4%, Loss: 0.3560\n",
      "Optimization Iteration:  28865, Training Accuracy:  84.4%, Loss: 0.3549\n",
      "Optimization Iteration:  28929, Training Accuracy:  82.8%, Loss: 0.3679\n",
      "Optimization Iteration:  28993, Training Accuracy:  70.3%, Loss: 0.4239\n",
      "Optimization Iteration:  29057, Training Accuracy:  78.1%, Loss: 0.3621\n",
      "Optimization Iteration:  29121, Training Accuracy:  68.8%, Loss: 0.5536\n",
      "Optimization Iteration:  29185, Training Accuracy:  78.1%, Loss: 0.3065\n",
      "Optimization Iteration:  29249, Training Accuracy:  76.6%, Loss: 0.4481\n",
      "Optimization Iteration:  29313, Training Accuracy:  68.8%, Loss: 0.4457\n",
      "Optimization Iteration:  29377, Training Accuracy:  79.7%, Loss: 0.3621\n",
      "Optimization Iteration:  29441, Training Accuracy:  79.7%, Loss: 0.4215\n",
      "Optimization Iteration:  29505, Training Accuracy:  76.6%, Loss: 0.3726\n",
      "Optimization Iteration:  29569, Training Accuracy:  85.9%, Loss: 0.3197\n",
      "Optimization Iteration:  29633, Training Accuracy:  73.4%, Loss: 0.4489\n",
      "Optimization Iteration:  29697, Training Accuracy:  84.4%, Loss: 0.3802\n",
      "Optimization Iteration:  29761, Training Accuracy:  73.4%, Loss: 0.3701\n",
      "Optimization Iteration:  29825, Training Accuracy:  76.6%, Loss: 0.4072\n",
      "Optimization Iteration:  29889, Training Accuracy:  79.7%, Loss: 0.4504\n",
      "Optimization Iteration:  29953, Training Accuracy:  65.6%, Loss: 0.4789\n",
      "Optimization Iteration:  30017, Training Accuracy:  85.9%, Loss: 0.3213\n",
      "Optimization Iteration:  30081, Training Accuracy:  79.7%, Loss: 0.3646\n",
      "Optimization Iteration:  30145, Training Accuracy:  73.4%, Loss: 0.4256\n",
      "Optimization Iteration:  30209, Training Accuracy:  78.1%, Loss: 0.3868\n",
      "Optimization Iteration:  30273, Training Accuracy:  73.4%, Loss: 0.4589\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.3843\n",
      "Optimization Iteration:  30401, Training Accuracy:  70.3%, Loss: 0.4652\n",
      "Optimization Iteration:  30465, Training Accuracy:  78.1%, Loss: 0.4169\n",
      "Optimization Iteration:  30529, Training Accuracy:  75.0%, Loss: 0.4358\n",
      "Optimization Iteration:  30593, Training Accuracy:  79.7%, Loss: 0.4424\n",
      "Optimization Iteration:  30657, Training Accuracy:  79.7%, Loss: 0.3297\n",
      "Optimization Iteration:  30721, Training Accuracy:  70.3%, Loss: 0.4197\n",
      "Optimization Iteration:  30785, Training Accuracy:  65.6%, Loss: 0.3987\n",
      "Optimization Iteration:  30849, Training Accuracy:  64.1%, Loss: 0.4412\n",
      "Optimization Iteration:  30913, Training Accuracy:  82.8%, Loss: 0.3951\n",
      "Optimization Iteration:  30977, Training Accuracy:  78.1%, Loss: 0.3470\n",
      "Optimization Iteration:  31041, Training Accuracy:  79.7%, Loss: 0.3862\n",
      "Optimization Iteration:  31105, Training Accuracy:  78.1%, Loss: 0.3455\n",
      "Optimization Iteration:  31169, Training Accuracy:  68.8%, Loss: 0.3974\n",
      "Optimization Iteration:  31233, Training Accuracy:  67.2%, Loss: 0.4370\n",
      "Optimization Iteration:  31297, Training Accuracy:  71.9%, Loss: 0.3894\n",
      "Optimization Iteration:  31361, Training Accuracy:  67.2%, Loss: 0.4029\n",
      "Optimization Iteration:  31425, Training Accuracy:  81.2%, Loss: 0.3260\n",
      "Optimization Iteration:  31489, Training Accuracy:  79.7%, Loss: 0.3679\n",
      "Optimization Iteration:  31553, Training Accuracy:  79.7%, Loss: 0.3193\n",
      "Optimization Iteration:  31617, Training Accuracy:  73.4%, Loss: 0.3752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  31681, Training Accuracy:  75.0%, Loss: 0.4398\n",
      "Optimization Iteration:  31745, Training Accuracy:  75.0%, Loss: 0.3627\n",
      "Optimization Iteration:  31809, Training Accuracy:  67.2%, Loss: 0.4474\n",
      "Optimization Iteration:  31873, Training Accuracy:  82.8%, Loss: 0.3771\n",
      "Optimization Iteration:  31937, Training Accuracy:  76.6%, Loss: 0.5181\n",
      "Optimization Iteration:  32001, Training Accuracy:  75.0%, Loss: 0.4203\n",
      "Optimization Iteration:  32065, Training Accuracy:  76.6%, Loss: 0.3985\n",
      "Optimization Iteration:  32129, Training Accuracy:  65.6%, Loss: 0.4797\n",
      "Optimization Iteration:  32193, Training Accuracy:  76.6%, Loss: 0.4251\n",
      "Optimization Iteration:  32257, Training Accuracy:  71.9%, Loss: 0.4997\n",
      "Optimization Iteration:  32321, Training Accuracy:  76.6%, Loss: 0.3061\n",
      "Optimization Iteration:  32385, Training Accuracy:  71.9%, Loss: 0.4306\n",
      "Optimization Iteration:  32449, Training Accuracy:  75.0%, Loss: 0.4334\n",
      "Optimization Iteration:  32513, Training Accuracy:  71.9%, Loss: 0.3472\n",
      "Optimization Iteration:  32577, Training Accuracy:  84.4%, Loss: 0.3587\n",
      "Optimization Iteration:  32641, Training Accuracy:  64.1%, Loss: 0.5374\n",
      "Optimization Iteration:  32705, Training Accuracy:  79.7%, Loss: 0.3972\n",
      "Optimization Iteration:  32769, Training Accuracy:  78.1%, Loss: 0.4129\n",
      "Optimization Iteration:  32833, Training Accuracy:  73.4%, Loss: 0.4204\n",
      "Optimization Iteration:  32897, Training Accuracy:  71.9%, Loss: 0.5401\n",
      "Optimization Iteration:  32961, Training Accuracy:  71.9%, Loss: 0.4514\n",
      "Optimization Iteration:  33025, Training Accuracy:  68.8%, Loss: 0.4719\n",
      "Optimization Iteration:  33089, Training Accuracy:  70.3%, Loss: 0.5155\n",
      "Optimization Iteration:  33153, Training Accuracy:  70.3%, Loss: 0.4514\n",
      "Optimization Iteration:  33217, Training Accuracy:  78.1%, Loss: 0.3411\n",
      "Optimization Iteration:  33281, Training Accuracy:  65.6%, Loss: 0.4682\n",
      "Optimization Iteration:  33345, Training Accuracy:  67.2%, Loss: 0.4978\n",
      "Optimization Iteration:  33409, Training Accuracy:  76.6%, Loss: 0.4027\n",
      "Optimization Iteration:  33473, Training Accuracy:  70.3%, Loss: 0.5207\n",
      "Optimization Iteration:  33537, Training Accuracy:  78.1%, Loss: 0.4335\n",
      "Optimization Iteration:  33601, Training Accuracy:  75.0%, Loss: 0.4157\n",
      "Optimization Iteration:  33665, Training Accuracy:  71.9%, Loss: 0.3973\n",
      "Optimization Iteration:  33729, Training Accuracy:  68.8%, Loss: 0.4427\n",
      "Optimization Iteration:  33793, Training Accuracy:  65.6%, Loss: 0.4273\n",
      "Optimization Iteration:  33857, Training Accuracy:  70.3%, Loss: 0.4475\n",
      "Optimization Iteration:  33921, Training Accuracy:  76.6%, Loss: 0.4491\n",
      "Optimization Iteration:  33985, Training Accuracy:  75.0%, Loss: 0.3679\n",
      "Optimization Iteration:  34049, Training Accuracy:  75.0%, Loss: 0.4368\n",
      "Optimization Iteration:  34113, Training Accuracy:  75.0%, Loss: 0.4059\n",
      "Optimization Iteration:  34177, Training Accuracy:  81.2%, Loss: 0.3468\n",
      "Optimization Iteration:  34241, Training Accuracy:  76.6%, Loss: 0.3850\n",
      "Optimization Iteration:  34305, Training Accuracy:  78.1%, Loss: 0.4284\n",
      "Optimization Iteration:  34369, Training Accuracy:  81.2%, Loss: 0.3571\n",
      "Optimization Iteration:  34433, Training Accuracy:  73.4%, Loss: 0.3857\n",
      "Optimization Iteration:  34497, Training Accuracy:  82.8%, Loss: 0.3031\n",
      "Optimization Iteration:  34561, Training Accuracy:  75.0%, Loss: 0.4284\n",
      "Optimization Iteration:  34625, Training Accuracy:  76.6%, Loss: 0.5160\n",
      "Optimization Iteration:  34689, Training Accuracy:  71.9%, Loss: 0.4978\n",
      "Optimization Iteration:  34753, Training Accuracy:  76.6%, Loss: 0.4483\n",
      "Optimization Iteration:  34817, Training Accuracy:  64.1%, Loss: 0.4517\n",
      "Optimization Iteration:  34881, Training Accuracy:  71.9%, Loss: 0.3761\n",
      "Optimization Iteration:  34945, Training Accuracy:  70.3%, Loss: 0.3971\n",
      "Optimization Iteration:  35009, Training Accuracy:  75.0%, Loss: 0.3646\n",
      "Optimization Iteration:  35073, Training Accuracy:  68.8%, Loss: 0.3938\n",
      "Optimization Iteration:  35137, Training Accuracy:  81.2%, Loss: 0.3294\n",
      "Optimization Iteration:  35201, Training Accuracy:  75.0%, Loss: 0.4042\n",
      "Optimization Iteration:  35265, Training Accuracy:  76.6%, Loss: 0.3858\n",
      "Optimization Iteration:  35329, Training Accuracy:  67.2%, Loss: 0.5184\n",
      "Optimization Iteration:  35393, Training Accuracy:  75.0%, Loss: 0.3491\n",
      "Optimization Iteration:  35457, Training Accuracy:  79.7%, Loss: 0.4009\n",
      "Optimization Iteration:  35521, Training Accuracy:  68.8%, Loss: 0.4622\n",
      "Optimization Iteration:  35585, Training Accuracy:  87.5%, Loss: 0.3409\n",
      "Optimization Iteration:  35649, Training Accuracy:  76.6%, Loss: 0.4082\n",
      "Optimization Iteration:  35713, Training Accuracy:  81.2%, Loss: 0.4032\n",
      "Optimization Iteration:  35777, Training Accuracy:  81.2%, Loss: 0.4027\n",
      "Optimization Iteration:  35841, Training Accuracy:  71.9%, Loss: 0.4226\n",
      "Optimization Iteration:  35905, Training Accuracy:  81.2%, Loss: 0.3849\n",
      "Optimization Iteration:  35969, Training Accuracy:  67.2%, Loss: 0.4578\n",
      "Optimization Iteration:  36033, Training Accuracy:  65.6%, Loss: 0.4261\n",
      "Optimization Iteration:  36097, Training Accuracy:  73.4%, Loss: 0.4522\n",
      "Optimization Iteration:  36161, Training Accuracy:  81.2%, Loss: 0.3171\n",
      "Optimization Iteration:  36225, Training Accuracy:  76.6%, Loss: 0.3950\n",
      "Optimization Iteration:  36289, Training Accuracy:  78.1%, Loss: 0.3787\n",
      "Optimization Iteration:  36353, Training Accuracy:  75.0%, Loss: 0.3889\n",
      "Optimization Iteration:  36417, Training Accuracy:  75.0%, Loss: 0.4915\n",
      "Optimization Iteration:  36481, Training Accuracy:  78.1%, Loss: 0.3233\n",
      "Optimization Iteration:  36545, Training Accuracy:  78.1%, Loss: 0.4270\n",
      "Optimization Iteration:  36609, Training Accuracy:  68.8%, Loss: 0.4259\n",
      "Optimization Iteration:  36673, Training Accuracy:  68.8%, Loss: 0.4643\n",
      "Optimization Iteration:  36737, Training Accuracy:  84.4%, Loss: 0.3546\n",
      "Optimization Iteration:  36801, Training Accuracy:  75.0%, Loss: 0.4025\n",
      "Optimization Iteration:  36865, Training Accuracy:  78.1%, Loss: 0.3733\n",
      "Optimization Iteration:  36929, Training Accuracy:  76.6%, Loss: 0.5014\n",
      "Optimization Iteration:  36993, Training Accuracy:  70.3%, Loss: 0.4104\n",
      "Optimization Iteration:  37057, Training Accuracy:  78.1%, Loss: 0.3756\n",
      "Optimization Iteration:  37121, Training Accuracy:  76.6%, Loss: 0.4229\n",
      "Optimization Iteration:  37185, Training Accuracy:  79.7%, Loss: 0.3627\n",
      "Optimization Iteration:  37249, Training Accuracy:  76.6%, Loss: 0.5122\n",
      "Optimization Iteration:  37313, Training Accuracy:  76.6%, Loss: 0.3362\n",
      "Optimization Iteration:  37377, Training Accuracy:  75.0%, Loss: 0.5955\n",
      "Optimization Iteration:  37441, Training Accuracy:  76.6%, Loss: 0.4442\n",
      "Optimization Iteration:  37505, Training Accuracy:  73.4%, Loss: 0.5141\n",
      "Optimization Iteration:  37569, Training Accuracy:  76.6%, Loss: 0.4563\n",
      "Optimization Iteration:  37633, Training Accuracy:  70.3%, Loss: 0.4642\n",
      "Optimization Iteration:  37697, Training Accuracy:  79.7%, Loss: 0.4201\n",
      "Optimization Iteration:  37761, Training Accuracy:  81.2%, Loss: 0.4139\n",
      "Optimization Iteration:  37825, Training Accuracy:  76.6%, Loss: 0.4327\n",
      "Optimization Iteration:  37889, Training Accuracy:  76.6%, Loss: 0.4142\n",
      "Optimization Iteration:  37953, Training Accuracy:  76.6%, Loss: 0.3215\n",
      "Optimization Iteration:  38017, Training Accuracy:  71.9%, Loss: 0.4639\n",
      "Optimization Iteration:  38081, Training Accuracy:  76.6%, Loss: 0.3599\n",
      "Optimization Iteration:  38145, Training Accuracy:  78.1%, Loss: 0.3713\n",
      "Optimization Iteration:  38209, Training Accuracy:  79.7%, Loss: 0.3878\n",
      "Optimization Iteration:  38273, Training Accuracy:  78.1%, Loss: 0.3567\n",
      "Optimization Iteration:  38337, Training Accuracy:  82.8%, Loss: 0.3014\n",
      "Optimization Iteration:  38401, Training Accuracy:  67.2%, Loss: 0.4915\n",
      "Optimization Iteration:  38465, Training Accuracy:  79.7%, Loss: 0.3914\n",
      "Optimization Iteration:  38529, Training Accuracy:  73.4%, Loss: 0.4245\n",
      "Optimization Iteration:  38593, Training Accuracy:  73.4%, Loss: 0.5433\n",
      "Optimization Iteration:  38657, Training Accuracy:  64.1%, Loss: 0.4804\n",
      "Optimization Iteration:  38721, Training Accuracy:  67.2%, Loss: 0.4205\n",
      "Optimization Iteration:  38785, Training Accuracy:  76.6%, Loss: 0.4248\n",
      "Optimization Iteration:  38849, Training Accuracy:  79.7%, Loss: 0.2877\n",
      "Optimization Iteration:  38913, Training Accuracy:  76.6%, Loss: 0.4037\n",
      "Optimization Iteration:  38977, Training Accuracy:  75.0%, Loss: 0.4342\n",
      "Optimization Iteration:  39041, Training Accuracy:  78.1%, Loss: 0.3853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  39105, Training Accuracy:  64.1%, Loss: 0.4737\n",
      "Optimization Iteration:  39169, Training Accuracy:  70.3%, Loss: 0.4087\n",
      "Optimization Iteration:  39233, Training Accuracy:  68.8%, Loss: 0.4910\n",
      "Optimization Iteration:  39297, Training Accuracy:  68.8%, Loss: 0.4360\n",
      "Optimization Iteration:  39361, Training Accuracy:  71.9%, Loss: 0.3728\n",
      "Optimization Iteration:  39425, Training Accuracy:  68.8%, Loss: 0.4125\n",
      "Optimization Iteration:  39489, Training Accuracy:  68.8%, Loss: 0.4675\n",
      "Optimization Iteration:  39553, Training Accuracy:  68.8%, Loss: 0.4292\n",
      "Optimization Iteration:  39617, Training Accuracy:  71.9%, Loss: 0.4235\n",
      "Optimization Iteration:  39681, Training Accuracy:  78.1%, Loss: 0.3823\n",
      "Optimization Iteration:  39745, Training Accuracy:  68.8%, Loss: 0.4526\n",
      "Optimization Iteration:  39809, Training Accuracy:  68.8%, Loss: 0.4326\n",
      "Optimization Iteration:  39873, Training Accuracy:  67.2%, Loss: 0.4843\n",
      "Optimization Iteration:  39937, Training Accuracy:  64.1%, Loss: 0.5411\n",
      "Optimization Iteration:  40001, Training Accuracy:  71.9%, Loss: 0.4153\n",
      "Optimization Iteration:  40065, Training Accuracy:  65.6%, Loss: 0.3737\n",
      "Optimization Iteration:  40129, Training Accuracy:  70.3%, Loss: 0.4134\n",
      "Optimization Iteration:  40193, Training Accuracy:  81.2%, Loss: 0.4975\n",
      "Optimization Iteration:  40257, Training Accuracy:  67.2%, Loss: 0.4761\n",
      "Optimization Iteration:  40321, Training Accuracy:  73.4%, Loss: 0.4226\n",
      "Optimization Iteration:  40385, Training Accuracy:  81.2%, Loss: 0.4427\n",
      "Optimization Iteration:  40449, Training Accuracy:  67.2%, Loss: 0.4234\n",
      "Optimization Iteration:  40513, Training Accuracy:  79.7%, Loss: 0.3986\n",
      "Optimization Iteration:  40577, Training Accuracy:  76.6%, Loss: 0.4023\n",
      "Optimization Iteration:  40641, Training Accuracy:  76.6%, Loss: 0.3450\n",
      "Optimization Iteration:  40705, Training Accuracy:  78.1%, Loss: 0.3313\n",
      "Optimization Iteration:  40769, Training Accuracy:  81.2%, Loss: 0.3422\n",
      "Optimization Iteration:  40833, Training Accuracy:  79.7%, Loss: 0.3395\n",
      "Optimization Iteration:  40897, Training Accuracy:  79.7%, Loss: 0.4193\n",
      "Optimization Iteration:  40961, Training Accuracy:  78.1%, Loss: 0.3746\n",
      "Optimization Iteration:  41025, Training Accuracy:  71.9%, Loss: 0.4360\n",
      "Optimization Iteration:  41089, Training Accuracy:  73.4%, Loss: 0.4395\n",
      "Optimization Iteration:  41153, Training Accuracy:  81.2%, Loss: 0.3849\n",
      "Optimization Iteration:  41217, Training Accuracy:  89.1%, Loss: 0.3357\n",
      "Optimization Iteration:  41281, Training Accuracy:  68.8%, Loss: 0.4658\n",
      "Optimization Iteration:  41345, Training Accuracy:  78.1%, Loss: 0.4173\n",
      "Optimization Iteration:  41409, Training Accuracy:  70.3%, Loss: 0.4087\n",
      "Optimization Iteration:  41473, Training Accuracy:  73.4%, Loss: 0.4359\n",
      "Optimization Iteration:  41537, Training Accuracy:  78.1%, Loss: 0.4509\n",
      "Optimization Iteration:  41601, Training Accuracy:  70.3%, Loss: 0.4114\n",
      "Optimization Iteration:  41665, Training Accuracy:  73.4%, Loss: 0.4500\n",
      "Optimization Iteration:  41729, Training Accuracy:  81.2%, Loss: 0.3228\n",
      "Optimization Iteration:  41793, Training Accuracy:  73.4%, Loss: 0.5073\n",
      "Optimization Iteration:  41857, Training Accuracy:  79.7%, Loss: 0.4104\n",
      "Optimization Iteration:  41921, Training Accuracy:  73.4%, Loss: 0.3878\n",
      "Optimization Iteration:  41985, Training Accuracy:  73.4%, Loss: 0.4693\n",
      "Optimization Iteration:  42049, Training Accuracy:  75.0%, Loss: 0.4021\n",
      "Optimization Iteration:  42113, Training Accuracy:  79.7%, Loss: 0.4315\n",
      "Optimization Iteration:  42177, Training Accuracy:  75.0%, Loss: 0.4313\n",
      "Optimization Iteration:  42241, Training Accuracy:  73.4%, Loss: 0.4235\n",
      "Optimization Iteration:  42305, Training Accuracy:  79.7%, Loss: 0.4797\n",
      "Optimization Iteration:  42369, Training Accuracy:  78.1%, Loss: 0.3876\n",
      "Optimization Iteration:  42433, Training Accuracy:  76.6%, Loss: 0.4347\n",
      "Optimization Iteration:  42497, Training Accuracy:  68.8%, Loss: 0.4479\n",
      "Optimization Iteration:  42561, Training Accuracy:  84.4%, Loss: 0.3487\n",
      "Optimization Iteration:  42625, Training Accuracy:  81.2%, Loss: 0.3692\n",
      "Optimization Iteration:  42689, Training Accuracy:  70.3%, Loss: 0.4065\n",
      "Optimization Iteration:  42753, Training Accuracy:  79.7%, Loss: 0.3898\n",
      "Optimization Iteration:  42817, Training Accuracy:  81.2%, Loss: 0.3557\n",
      "Optimization Iteration:  42881, Training Accuracy:  67.2%, Loss: 0.4634\n",
      "Optimization Iteration:  42945, Training Accuracy:  73.4%, Loss: 0.3780\n",
      "Optimization Iteration:  43009, Training Accuracy:  70.3%, Loss: 0.4413\n",
      "Optimization Iteration:  43073, Training Accuracy:  79.7%, Loss: 0.3634\n",
      "Optimization Iteration:  43137, Training Accuracy:  79.7%, Loss: 0.3782\n",
      "Optimization Iteration:  43201, Training Accuracy:  81.2%, Loss: 0.3909\n",
      "Optimization Iteration:  43265, Training Accuracy:  79.7%, Loss: 0.3923\n",
      "Optimization Iteration:  43329, Training Accuracy:  78.1%, Loss: 0.3975\n",
      "Optimization Iteration:  43393, Training Accuracy:  79.7%, Loss: 0.3632\n",
      "Optimization Iteration:  43457, Training Accuracy:  81.2%, Loss: 0.3471\n",
      "Optimization Iteration:  43521, Training Accuracy:  78.1%, Loss: 0.4543\n",
      "Optimization Iteration:  43585, Training Accuracy:  78.1%, Loss: 0.3850\n",
      "Optimization Iteration:  43649, Training Accuracy:  78.1%, Loss: 0.4968\n",
      "Optimization Iteration:  43713, Training Accuracy:  76.6%, Loss: 0.3840\n",
      "Optimization Iteration:  43777, Training Accuracy:  76.6%, Loss: 0.3213\n",
      "Optimization Iteration:  43841, Training Accuracy:  73.4%, Loss: 0.4413\n",
      "Optimization Iteration:  43905, Training Accuracy:  73.4%, Loss: 0.4836\n",
      "Optimization Iteration:  43969, Training Accuracy:  70.3%, Loss: 0.3965\n",
      "Optimization Iteration:  44033, Training Accuracy:  76.6%, Loss: 0.3343\n",
      "Optimization Iteration:  44097, Training Accuracy:  79.7%, Loss: 0.3595\n",
      "Optimization Iteration:  44161, Training Accuracy:  81.2%, Loss: 0.3626\n",
      "Optimization Iteration:  44225, Training Accuracy:  78.1%, Loss: 0.3988\n",
      "Optimization Iteration:  44289, Training Accuracy:  87.5%, Loss: 0.3175\n",
      "Optimization Iteration:  44353, Training Accuracy:  73.4%, Loss: 0.4732\n",
      "Optimization Iteration:  44417, Training Accuracy:  70.3%, Loss: 0.4022\n",
      "Optimization Iteration:  44481, Training Accuracy:  68.8%, Loss: 0.3922\n",
      "Optimization Iteration:  44545, Training Accuracy:  84.4%, Loss: 0.3164\n",
      "Optimization Iteration:  44609, Training Accuracy:  82.8%, Loss: 0.3676\n",
      "Optimization Iteration:  44673, Training Accuracy:  68.8%, Loss: 0.5618\n",
      "Optimization Iteration:  44737, Training Accuracy:  82.8%, Loss: 0.3811\n",
      "Optimization Iteration:  44801, Training Accuracy:  75.0%, Loss: 0.4069\n",
      "Optimization Iteration:  44865, Training Accuracy:  78.1%, Loss: 0.3393\n",
      "Optimization Iteration:  44929, Training Accuracy:  85.9%, Loss: 0.3381\n",
      "Optimization Iteration:  44993, Training Accuracy:  70.3%, Loss: 0.4364\n",
      "Optimization Iteration:  45057, Training Accuracy:  78.1%, Loss: 0.4716\n",
      "Optimization Iteration:  45121, Training Accuracy:  78.1%, Loss: 0.3705\n",
      "Optimization Iteration:  45185, Training Accuracy:  76.6%, Loss: 0.4032\n",
      "Optimization Iteration:  45249, Training Accuracy:  67.2%, Loss: 0.4661\n",
      "Optimization Iteration:  45313, Training Accuracy:  79.7%, Loss: 0.4110\n",
      "Optimization Iteration:  45377, Training Accuracy:  75.0%, Loss: 0.4270\n",
      "Optimization Iteration:  45441, Training Accuracy:  78.1%, Loss: 0.3820\n",
      "Optimization Iteration:  45505, Training Accuracy:  71.9%, Loss: 0.4265\n",
      "Optimization Iteration:  45569, Training Accuracy:  68.8%, Loss: 0.4683\n",
      "Optimization Iteration:  45633, Training Accuracy:  84.4%, Loss: 0.3828\n",
      "Optimization Iteration:  45697, Training Accuracy:  79.7%, Loss: 0.3401\n",
      "Optimization Iteration:  45761, Training Accuracy:  82.8%, Loss: 0.3797\n",
      "Optimization Iteration:  45825, Training Accuracy:  70.3%, Loss: 0.4591\n",
      "Optimization Iteration:  45889, Training Accuracy:  81.2%, Loss: 0.4058\n",
      "Optimization Iteration:  45953, Training Accuracy:  79.7%, Loss: 0.3113\n",
      "Optimization Iteration:  46017, Training Accuracy:  67.2%, Loss: 0.4348\n",
      "Optimization Iteration:  46081, Training Accuracy:  79.7%, Loss: 0.3707\n",
      "Optimization Iteration:  46145, Training Accuracy:  73.4%, Loss: 0.4465\n",
      "Optimization Iteration:  46209, Training Accuracy:  71.9%, Loss: 0.3297\n",
      "Optimization Iteration:  46273, Training Accuracy:  68.8%, Loss: 0.4691\n",
      "Optimization Iteration:  46337, Training Accuracy:  78.1%, Loss: 0.4240\n",
      "Optimization Iteration:  46401, Training Accuracy:  81.2%, Loss: 0.3176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  46465, Training Accuracy:  76.6%, Loss: 0.4079\n",
      "Optimization Iteration:  46529, Training Accuracy:  76.6%, Loss: 0.3893\n",
      "Optimization Iteration:  46593, Training Accuracy:  73.4%, Loss: 0.3837\n",
      "Optimization Iteration:  46657, Training Accuracy:  70.3%, Loss: 0.4605\n",
      "Optimization Iteration:  46721, Training Accuracy:  65.6%, Loss: 0.4324\n",
      "Optimization Iteration:  46785, Training Accuracy:  70.3%, Loss: 0.4965\n",
      "Optimization Iteration:  46849, Training Accuracy:  70.3%, Loss: 0.3684\n",
      "Optimization Iteration:  46913, Training Accuracy:  75.0%, Loss: 0.3597\n",
      "Optimization Iteration:  46977, Training Accuracy:  79.7%, Loss: 0.4045\n",
      "Optimization Iteration:  47041, Training Accuracy:  76.6%, Loss: 0.4019\n",
      "Optimization Iteration:  47105, Training Accuracy:  75.0%, Loss: 0.4753\n",
      "Optimization Iteration:  47169, Training Accuracy:  68.8%, Loss: 0.4119\n",
      "Optimization Iteration:  47233, Training Accuracy:  76.6%, Loss: 0.3843\n",
      "Optimization Iteration:  47297, Training Accuracy:  76.6%, Loss: 0.3650\n",
      "Optimization Iteration:  47361, Training Accuracy:  76.6%, Loss: 0.3721\n",
      "Optimization Iteration:  47425, Training Accuracy:  79.7%, Loss: 0.4071\n",
      "Optimization Iteration:  47489, Training Accuracy:  76.6%, Loss: 0.3954\n",
      "Optimization Iteration:  47553, Training Accuracy:  71.9%, Loss: 0.4603\n",
      "Optimization Iteration:  47617, Training Accuracy:  75.0%, Loss: 0.4227\n",
      "Optimization Iteration:  47681, Training Accuracy:  82.8%, Loss: 0.3237\n",
      "Optimization Iteration:  47745, Training Accuracy:  73.4%, Loss: 0.4804\n",
      "Optimization Iteration:  47809, Training Accuracy:  78.1%, Loss: 0.4085\n",
      "Optimization Iteration:  47873, Training Accuracy:  82.8%, Loss: 0.3290\n",
      "Optimization Iteration:  47937, Training Accuracy:  70.3%, Loss: 0.4998\n",
      "Optimization Iteration:  48001, Training Accuracy:  73.4%, Loss: 0.4503\n",
      "Optimization Iteration:  48065, Training Accuracy:  75.0%, Loss: 0.4232\n",
      "Optimization Iteration:  48129, Training Accuracy:  75.0%, Loss: 0.4693\n",
      "Optimization Iteration:  48193, Training Accuracy:  70.3%, Loss: 0.4983\n",
      "Optimization Iteration:  48257, Training Accuracy:  76.6%, Loss: 0.3833\n",
      "Optimization Iteration:  48321, Training Accuracy:  79.7%, Loss: 0.3709\n",
      "Optimization Iteration:  48385, Training Accuracy:  78.1%, Loss: 0.3893\n",
      "Optimization Iteration:  48449, Training Accuracy:  71.9%, Loss: 0.3937\n",
      "Optimization Iteration:  48513, Training Accuracy:  78.1%, Loss: 0.4251\n",
      "Optimization Iteration:  48577, Training Accuracy:  68.8%, Loss: 0.4641\n",
      "Optimization Iteration:  48641, Training Accuracy:  79.7%, Loss: 0.3439\n",
      "Optimization Iteration:  48705, Training Accuracy:  76.6%, Loss: 0.4130\n",
      "Optimization Iteration:  48769, Training Accuracy:  85.9%, Loss: 0.2910\n",
      "Optimization Iteration:  48833, Training Accuracy:  81.2%, Loss: 0.3135\n",
      "Optimization Iteration:  48897, Training Accuracy:  70.3%, Loss: 0.4045\n",
      "Optimization Iteration:  48961, Training Accuracy:  70.3%, Loss: 0.4340\n",
      "Optimization Iteration:  49025, Training Accuracy:  67.2%, Loss: 0.4127\n",
      "Optimization Iteration:  49089, Training Accuracy:  79.7%, Loss: 0.3426\n",
      "Optimization Iteration:  49153, Training Accuracy:  81.2%, Loss: 0.3991\n",
      "Optimization Iteration:  49217, Training Accuracy:  73.4%, Loss: 0.3581\n",
      "Optimization Iteration:  49281, Training Accuracy:  79.7%, Loss: 0.4159\n",
      "Optimization Iteration:  49345, Training Accuracy:  71.9%, Loss: 0.4081\n",
      "Optimization Iteration:  49409, Training Accuracy:  70.3%, Loss: 0.5384\n",
      "Optimization Iteration:  49473, Training Accuracy:  67.2%, Loss: 0.4154\n",
      "Optimization Iteration:  49537, Training Accuracy:  79.7%, Loss: 0.3575\n",
      "Optimization Iteration:  49601, Training Accuracy:  67.2%, Loss: 0.4483\n",
      "Optimization Iteration:  49665, Training Accuracy:  78.1%, Loss: 0.3526\n",
      "Optimization Iteration:  49729, Training Accuracy:  65.6%, Loss: 0.5262\n",
      "Optimization Iteration:  49793, Training Accuracy:  70.3%, Loss: 0.3786\n",
      "Optimization Iteration:  49857, Training Accuracy:  71.9%, Loss: 0.4740\n",
      "Optimization Iteration:  49921, Training Accuracy:  73.4%, Loss: 0.4259\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 14\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  75.0%, Loss: 0.4280\n",
      "Optimization Iteration:    129, Training Accuracy:  70.3%, Loss: 0.4695\n",
      "Optimization Iteration:    193, Training Accuracy:  73.4%, Loss: 0.4902\n",
      "Optimization Iteration:    257, Training Accuracy:  70.3%, Loss: 0.3768\n",
      "Optimization Iteration:    321, Training Accuracy:  79.7%, Loss: 0.3851\n",
      "Optimization Iteration:    385, Training Accuracy:  75.0%, Loss: 0.3591\n",
      "Optimization Iteration:    449, Training Accuracy:  82.8%, Loss: 0.3054\n",
      "Optimization Iteration:    513, Training Accuracy:  68.8%, Loss: 0.5025\n",
      "Optimization Iteration:    577, Training Accuracy:  67.2%, Loss: 0.4884\n",
      "Optimization Iteration:    641, Training Accuracy:  81.2%, Loss: 0.3454\n",
      "Optimization Iteration:    705, Training Accuracy:  78.1%, Loss: 0.3906\n",
      "Optimization Iteration:    769, Training Accuracy:  73.4%, Loss: 0.4302\n",
      "Optimization Iteration:    833, Training Accuracy:  79.7%, Loss: 0.3844\n",
      "Optimization Iteration:    897, Training Accuracy:  73.4%, Loss: 0.3686\n",
      "Optimization Iteration:    961, Training Accuracy:  82.8%, Loss: 0.3132\n",
      "Optimization Iteration:   1025, Training Accuracy:  76.6%, Loss: 0.4078\n",
      "Optimization Iteration:   1089, Training Accuracy:  75.0%, Loss: 0.4044\n",
      "Optimization Iteration:   1153, Training Accuracy:  64.1%, Loss: 0.4640\n",
      "Optimization Iteration:   1217, Training Accuracy:  73.4%, Loss: 0.3878\n",
      "Optimization Iteration:   1281, Training Accuracy:  75.0%, Loss: 0.4841\n",
      "Optimization Iteration:   1345, Training Accuracy:  71.9%, Loss: 0.4636\n",
      "Optimization Iteration:   1409, Training Accuracy:  79.7%, Loss: 0.4291\n",
      "Optimization Iteration:   1473, Training Accuracy:  71.9%, Loss: 0.4256\n",
      "Optimization Iteration:   1537, Training Accuracy:  78.1%, Loss: 0.3542\n",
      "Optimization Iteration:   1601, Training Accuracy:  84.4%, Loss: 0.3514\n",
      "Optimization Iteration:   1665, Training Accuracy:  78.1%, Loss: 0.3246\n",
      "Optimization Iteration:   1729, Training Accuracy:  82.8%, Loss: 0.3570\n",
      "Optimization Iteration:   1793, Training Accuracy:  68.8%, Loss: 0.4551\n",
      "Optimization Iteration:   1857, Training Accuracy:  76.6%, Loss: 0.4595\n",
      "Optimization Iteration:   1921, Training Accuracy:  75.0%, Loss: 0.4450\n",
      "Optimization Iteration:   1985, Training Accuracy:  71.9%, Loss: 0.3666\n",
      "Optimization Iteration:   2049, Training Accuracy:  78.1%, Loss: 0.3959\n",
      "Optimization Iteration:   2113, Training Accuracy:  78.1%, Loss: 0.3392\n",
      "Optimization Iteration:   2177, Training Accuracy:  75.0%, Loss: 0.3607\n",
      "Optimization Iteration:   2241, Training Accuracy:  68.8%, Loss: 0.4014\n",
      "Optimization Iteration:   2305, Training Accuracy:  73.4%, Loss: 0.4181\n",
      "Optimization Iteration:   2369, Training Accuracy:  75.0%, Loss: 0.4806\n",
      "Optimization Iteration:   2433, Training Accuracy:  81.2%, Loss: 0.3650\n",
      "Optimization Iteration:   2497, Training Accuracy:  78.1%, Loss: 0.3402\n",
      "Optimization Iteration:   2561, Training Accuracy:  81.2%, Loss: 0.3490\n",
      "Optimization Iteration:   2625, Training Accuracy:  67.2%, Loss: 0.4248\n",
      "Optimization Iteration:   2689, Training Accuracy:  76.6%, Loss: 0.3944\n",
      "Optimization Iteration:   2753, Training Accuracy:  79.7%, Loss: 0.3920\n",
      "Optimization Iteration:   2817, Training Accuracy:  78.1%, Loss: 0.4315\n",
      "Optimization Iteration:   2881, Training Accuracy:  75.0%, Loss: 0.3935\n",
      "Optimization Iteration:   2945, Training Accuracy:  76.6%, Loss: 0.4545\n",
      "Optimization Iteration:   3009, Training Accuracy:  76.6%, Loss: 0.4160\n",
      "Optimization Iteration:   3073, Training Accuracy:  79.7%, Loss: 0.3485\n",
      "Optimization Iteration:   3137, Training Accuracy:  84.4%, Loss: 0.2981\n",
      "Optimization Iteration:   3201, Training Accuracy:  79.7%, Loss: 0.3247\n",
      "Optimization Iteration:   3265, Training Accuracy:  81.2%, Loss: 0.3298\n",
      "Optimization Iteration:   3329, Training Accuracy:  78.1%, Loss: 0.4019\n",
      "Optimization Iteration:   3393, Training Accuracy:  68.8%, Loss: 0.4635\n",
      "Optimization Iteration:   3457, Training Accuracy:  75.0%, Loss: 0.4587\n",
      "Optimization Iteration:   3521, Training Accuracy:  76.6%, Loss: 0.3978\n",
      "Optimization Iteration:   3585, Training Accuracy:  67.2%, Loss: 0.4986\n",
      "Optimization Iteration:   3649, Training Accuracy:  73.4%, Loss: 0.4685\n",
      "Optimization Iteration:   3713, Training Accuracy:  73.4%, Loss: 0.4040\n",
      "Optimization Iteration:   3777, Training Accuracy:  62.5%, Loss: 0.5670\n",
      "Optimization Iteration:   3841, Training Accuracy:  67.2%, Loss: 0.4787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   3905, Training Accuracy:  76.6%, Loss: 0.3946\n",
      "Optimization Iteration:   3969, Training Accuracy:  78.1%, Loss: 0.4176\n",
      "Optimization Iteration:   4033, Training Accuracy:  71.9%, Loss: 0.3478\n",
      "Optimization Iteration:   4097, Training Accuracy:  75.0%, Loss: 0.3652\n",
      "Optimization Iteration:   4161, Training Accuracy:  71.9%, Loss: 0.3988\n",
      "Optimization Iteration:   4225, Training Accuracy:  81.2%, Loss: 0.3560\n",
      "Optimization Iteration:   4289, Training Accuracy:  78.1%, Loss: 0.4262\n",
      "Optimization Iteration:   4353, Training Accuracy:  76.6%, Loss: 0.3946\n",
      "Optimization Iteration:   4417, Training Accuracy:  79.7%, Loss: 0.3696\n",
      "Optimization Iteration:   4481, Training Accuracy:  68.8%, Loss: 0.4044\n",
      "Optimization Iteration:   4545, Training Accuracy:  70.3%, Loss: 0.4469\n",
      "Optimization Iteration:   4609, Training Accuracy:  81.2%, Loss: 0.3403\n",
      "Optimization Iteration:   4673, Training Accuracy:  79.7%, Loss: 0.4443\n",
      "Optimization Iteration:   4737, Training Accuracy:  73.4%, Loss: 0.4081\n",
      "Optimization Iteration:   4801, Training Accuracy:  68.8%, Loss: 0.4572\n",
      "Optimization Iteration:   4865, Training Accuracy:  71.9%, Loss: 0.4215\n",
      "Optimization Iteration:   4929, Training Accuracy:  76.6%, Loss: 0.4207\n",
      "Optimization Iteration:   4993, Training Accuracy:  64.1%, Loss: 0.3820\n",
      "Optimization Iteration:   5057, Training Accuracy:  82.8%, Loss: 0.4328\n",
      "Optimization Iteration:   5121, Training Accuracy:  75.0%, Loss: 0.3500\n",
      "Optimization Iteration:   5185, Training Accuracy:  71.9%, Loss: 0.4592\n",
      "Optimization Iteration:   5249, Training Accuracy:  67.2%, Loss: 0.4979\n",
      "Optimization Iteration:   5313, Training Accuracy:  78.1%, Loss: 0.3476\n",
      "Optimization Iteration:   5377, Training Accuracy:  81.2%, Loss: 0.3505\n",
      "Optimization Iteration:   5441, Training Accuracy:  73.4%, Loss: 0.3966\n",
      "Optimization Iteration:   5505, Training Accuracy:  75.0%, Loss: 0.3338\n",
      "Optimization Iteration:   5569, Training Accuracy:  73.4%, Loss: 0.4319\n",
      "Optimization Iteration:   5633, Training Accuracy:  76.6%, Loss: 0.4389\n",
      "Optimization Iteration:   5697, Training Accuracy:  75.0%, Loss: 0.4452\n",
      "Optimization Iteration:   5761, Training Accuracy:  90.6%, Loss: 0.2735\n",
      "Optimization Iteration:   5825, Training Accuracy:  71.9%, Loss: 0.4126\n",
      "Optimization Iteration:   5889, Training Accuracy:  82.8%, Loss: 0.3329\n",
      "Optimization Iteration:   5953, Training Accuracy:  85.9%, Loss: 0.3750\n",
      "Optimization Iteration:   6017, Training Accuracy:  70.3%, Loss: 0.4794\n",
      "Optimization Iteration:   6081, Training Accuracy:  75.0%, Loss: 0.3394\n",
      "Optimization Iteration:   6145, Training Accuracy:  73.4%, Loss: 0.5060\n",
      "Optimization Iteration:   6209, Training Accuracy:  76.6%, Loss: 0.3943\n",
      "Optimization Iteration:   6273, Training Accuracy:  76.6%, Loss: 0.3991\n",
      "Optimization Iteration:   6337, Training Accuracy:  73.4%, Loss: 0.4624\n",
      "Optimization Iteration:   6401, Training Accuracy:  73.4%, Loss: 0.4507\n",
      "Optimization Iteration:   6465, Training Accuracy:  82.8%, Loss: 0.3720\n",
      "Optimization Iteration:   6529, Training Accuracy:  78.1%, Loss: 0.4305\n",
      "Optimization Iteration:   6593, Training Accuracy:  70.3%, Loss: 0.4882\n",
      "Optimization Iteration:   6657, Training Accuracy:  70.3%, Loss: 0.4170\n",
      "Optimization Iteration:   6721, Training Accuracy:  75.0%, Loss: 0.3453\n",
      "Optimization Iteration:   6785, Training Accuracy:  67.2%, Loss: 0.4372\n",
      "Optimization Iteration:   6849, Training Accuracy:  79.7%, Loss: 0.3384\n",
      "Optimization Iteration:   6913, Training Accuracy:  68.8%, Loss: 0.3756\n",
      "Optimization Iteration:   6977, Training Accuracy:  71.9%, Loss: 0.4773\n",
      "Optimization Iteration:   7041, Training Accuracy:  84.4%, Loss: 0.3038\n",
      "Optimization Iteration:   7105, Training Accuracy:  73.4%, Loss: 0.3675\n",
      "Optimization Iteration:   7169, Training Accuracy:  78.1%, Loss: 0.3648\n",
      "Optimization Iteration:   7233, Training Accuracy:  76.6%, Loss: 0.4265\n",
      "Optimization Iteration:   7297, Training Accuracy:  64.1%, Loss: 0.4997\n",
      "Optimization Iteration:   7361, Training Accuracy:  81.2%, Loss: 0.3404\n",
      "Optimization Iteration:   7425, Training Accuracy:  71.9%, Loss: 0.4426\n",
      "Optimization Iteration:   7489, Training Accuracy:  75.0%, Loss: 0.4716\n",
      "Optimization Iteration:   7553, Training Accuracy:  76.6%, Loss: 0.4984\n",
      "Optimization Iteration:   7617, Training Accuracy:  71.9%, Loss: 0.3964\n",
      "Optimization Iteration:   7681, Training Accuracy:  73.4%, Loss: 0.4370\n",
      "Optimization Iteration:   7745, Training Accuracy:  78.1%, Loss: 0.3718\n",
      "Optimization Iteration:   7809, Training Accuracy:  82.8%, Loss: 0.4473\n",
      "Optimization Iteration:   7873, Training Accuracy:  67.2%, Loss: 0.4191\n",
      "Optimization Iteration:   7937, Training Accuracy:  89.1%, Loss: 0.3571\n",
      "Optimization Iteration:   8001, Training Accuracy:  75.0%, Loss: 0.3725\n",
      "Optimization Iteration:   8065, Training Accuracy:  68.8%, Loss: 0.4615\n",
      "Optimization Iteration:   8129, Training Accuracy:  68.8%, Loss: 0.3977\n",
      "Optimization Iteration:   8193, Training Accuracy:  70.3%, Loss: 0.3987\n",
      "Optimization Iteration:   8257, Training Accuracy:  78.1%, Loss: 0.4564\n",
      "Optimization Iteration:   8321, Training Accuracy:  62.5%, Loss: 0.4750\n",
      "Optimization Iteration:   8385, Training Accuracy:  65.6%, Loss: 0.4781\n",
      "Optimization Iteration:   8449, Training Accuracy:  78.1%, Loss: 0.4317\n",
      "Optimization Iteration:   8513, Training Accuracy:  84.4%, Loss: 0.3484\n",
      "Optimization Iteration:   8577, Training Accuracy:  70.3%, Loss: 0.4855\n",
      "Optimization Iteration:   8641, Training Accuracy:  67.2%, Loss: 0.4446\n",
      "Optimization Iteration:   8705, Training Accuracy:  78.1%, Loss: 0.3578\n",
      "Optimization Iteration:   8769, Training Accuracy:  76.6%, Loss: 0.3668\n",
      "Optimization Iteration:   8833, Training Accuracy:  70.3%, Loss: 0.5676\n",
      "Optimization Iteration:   8897, Training Accuracy:  68.8%, Loss: 0.4899\n",
      "Optimization Iteration:   8961, Training Accuracy:  73.4%, Loss: 0.3765\n",
      "Optimization Iteration:   9025, Training Accuracy:  67.2%, Loss: 0.5363\n",
      "Optimization Iteration:   9089, Training Accuracy:  62.5%, Loss: 0.5033\n",
      "Optimization Iteration:   9153, Training Accuracy:  75.0%, Loss: 0.3694\n",
      "Optimization Iteration:   9217, Training Accuracy:  79.7%, Loss: 0.4082\n",
      "Optimization Iteration:   9281, Training Accuracy:  70.3%, Loss: 0.4386\n",
      "Optimization Iteration:   9345, Training Accuracy:  84.4%, Loss: 0.4045\n",
      "Optimization Iteration:   9409, Training Accuracy:  81.2%, Loss: 0.3914\n",
      "Optimization Iteration:   9473, Training Accuracy:  78.1%, Loss: 0.3840\n",
      "Optimization Iteration:   9537, Training Accuracy:  79.7%, Loss: 0.3676\n",
      "Optimization Iteration:   9601, Training Accuracy:  73.4%, Loss: 0.4187\n",
      "Optimization Iteration:   9665, Training Accuracy:  64.1%, Loss: 0.5152\n",
      "Optimization Iteration:   9729, Training Accuracy:  67.2%, Loss: 0.4755\n",
      "Optimization Iteration:   9793, Training Accuracy:  78.1%, Loss: 0.3730\n",
      "Optimization Iteration:   9857, Training Accuracy:  79.7%, Loss: 0.4247\n",
      "Optimization Iteration:   9921, Training Accuracy:  79.7%, Loss: 0.3598\n",
      "Optimization Iteration:   9985, Training Accuracy:  60.9%, Loss: 0.5092\n",
      "Optimization Iteration:  10049, Training Accuracy:  70.3%, Loss: 0.4153\n",
      "Optimization Iteration:  10113, Training Accuracy:  76.6%, Loss: 0.4319\n",
      "Optimization Iteration:  10177, Training Accuracy:  73.4%, Loss: 0.4816\n",
      "Optimization Iteration:  10241, Training Accuracy:  75.0%, Loss: 0.4255\n",
      "Optimization Iteration:  10305, Training Accuracy:  81.2%, Loss: 0.3826\n",
      "Optimization Iteration:  10369, Training Accuracy:  75.0%, Loss: 0.4111\n",
      "Optimization Iteration:  10433, Training Accuracy:  73.4%, Loss: 0.3918\n",
      "Optimization Iteration:  10497, Training Accuracy:  68.8%, Loss: 0.4580\n",
      "Optimization Iteration:  10561, Training Accuracy:  76.6%, Loss: 0.3977\n",
      "Optimization Iteration:  10625, Training Accuracy:  71.9%, Loss: 0.4171\n",
      "Optimization Iteration:  10689, Training Accuracy:  65.6%, Loss: 0.4947\n",
      "Optimization Iteration:  10753, Training Accuracy:  75.0%, Loss: 0.4446\n",
      "Optimization Iteration:  10817, Training Accuracy:  76.6%, Loss: 0.4216\n",
      "Optimization Iteration:  10881, Training Accuracy:  78.1%, Loss: 0.3708\n",
      "Optimization Iteration:  10945, Training Accuracy:  75.0%, Loss: 0.4402\n",
      "Optimization Iteration:  11009, Training Accuracy:  70.3%, Loss: 0.4048\n",
      "Optimization Iteration:  11073, Training Accuracy:  78.1%, Loss: 0.3857\n",
      "Optimization Iteration:  11137, Training Accuracy:  78.1%, Loss: 0.3976\n",
      "Optimization Iteration:  11201, Training Accuracy:  76.6%, Loss: 0.3855\n",
      "Optimization Iteration:  11265, Training Accuracy:  79.7%, Loss: 0.3421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  11329, Training Accuracy:  75.0%, Loss: 0.4827\n",
      "Optimization Iteration:  11393, Training Accuracy:  75.0%, Loss: 0.4372\n",
      "Optimization Iteration:  11457, Training Accuracy:  85.9%, Loss: 0.3801\n",
      "Optimization Iteration:  11521, Training Accuracy:  70.3%, Loss: 0.4920\n",
      "Optimization Iteration:  11585, Training Accuracy:  73.4%, Loss: 0.4129\n",
      "Optimization Iteration:  11649, Training Accuracy:  71.9%, Loss: 0.4605\n",
      "Optimization Iteration:  11713, Training Accuracy:  68.8%, Loss: 0.3887\n",
      "Optimization Iteration:  11777, Training Accuracy:  75.0%, Loss: 0.4164\n",
      "Optimization Iteration:  11841, Training Accuracy:  73.4%, Loss: 0.3477\n",
      "Optimization Iteration:  11905, Training Accuracy:  81.2%, Loss: 0.4002\n",
      "Optimization Iteration:  11969, Training Accuracy:  70.3%, Loss: 0.4483\n",
      "Optimization Iteration:  12033, Training Accuracy:  76.6%, Loss: 0.3519\n",
      "Optimization Iteration:  12097, Training Accuracy:  79.7%, Loss: 0.3526\n",
      "Optimization Iteration:  12161, Training Accuracy:  71.9%, Loss: 0.4843\n",
      "Optimization Iteration:  12225, Training Accuracy:  82.8%, Loss: 0.3599\n",
      "Optimization Iteration:  12289, Training Accuracy:  81.2%, Loss: 0.3734\n",
      "Optimization Iteration:  12353, Training Accuracy:  81.2%, Loss: 0.3674\n",
      "Optimization Iteration:  12417, Training Accuracy:  78.1%, Loss: 0.3785\n",
      "Optimization Iteration:  12481, Training Accuracy:  79.7%, Loss: 0.4058\n",
      "Optimization Iteration:  12545, Training Accuracy:  79.7%, Loss: 0.4694\n",
      "Optimization Iteration:  12609, Training Accuracy:  71.9%, Loss: 0.4228\n",
      "Optimization Iteration:  12673, Training Accuracy:  81.2%, Loss: 0.3260\n",
      "Optimization Iteration:  12737, Training Accuracy:  70.3%, Loss: 0.4606\n",
      "Optimization Iteration:  12801, Training Accuracy:  81.2%, Loss: 0.3820\n",
      "Optimization Iteration:  12865, Training Accuracy:  70.3%, Loss: 0.5092\n",
      "Optimization Iteration:  12929, Training Accuracy:  65.6%, Loss: 0.4577\n",
      "Optimization Iteration:  12993, Training Accuracy:  78.1%, Loss: 0.3576\n",
      "Optimization Iteration:  13057, Training Accuracy:  71.9%, Loss: 0.4453\n",
      "Optimization Iteration:  13121, Training Accuracy:  76.6%, Loss: 0.3812\n",
      "Optimization Iteration:  13185, Training Accuracy:  76.6%, Loss: 0.3821\n",
      "Optimization Iteration:  13249, Training Accuracy:  71.9%, Loss: 0.5037\n",
      "Optimization Iteration:  13313, Training Accuracy:  68.8%, Loss: 0.5240\n",
      "Optimization Iteration:  13377, Training Accuracy:  78.1%, Loss: 0.4839\n",
      "Optimization Iteration:  13441, Training Accuracy:  78.1%, Loss: 0.4378\n",
      "Optimization Iteration:  13505, Training Accuracy:  76.6%, Loss: 0.3858\n",
      "Optimization Iteration:  13569, Training Accuracy:  81.2%, Loss: 0.3096\n",
      "Optimization Iteration:  13633, Training Accuracy:  70.3%, Loss: 0.4098\n",
      "Optimization Iteration:  13697, Training Accuracy:  73.4%, Loss: 0.3771\n",
      "Optimization Iteration:  13761, Training Accuracy:  76.6%, Loss: 0.3889\n",
      "Optimization Iteration:  13825, Training Accuracy:  82.8%, Loss: 0.3790\n",
      "Optimization Iteration:  13889, Training Accuracy:  79.7%, Loss: 0.5477\n",
      "Optimization Iteration:  13953, Training Accuracy:  81.2%, Loss: 0.3521\n",
      "Optimization Iteration:  14017, Training Accuracy:  76.6%, Loss: 0.3717\n",
      "Optimization Iteration:  14081, Training Accuracy:  81.2%, Loss: 0.4106\n",
      "Optimization Iteration:  14145, Training Accuracy:  76.6%, Loss: 0.3690\n",
      "Optimization Iteration:  14209, Training Accuracy:  79.7%, Loss: 0.4332\n",
      "Optimization Iteration:  14273, Training Accuracy:  65.6%, Loss: 0.4820\n",
      "Optimization Iteration:  14337, Training Accuracy:  84.4%, Loss: 0.3027\n",
      "Optimization Iteration:  14401, Training Accuracy:  73.4%, Loss: 0.3389\n",
      "Optimization Iteration:  14465, Training Accuracy:  68.8%, Loss: 0.4521\n",
      "Optimization Iteration:  14529, Training Accuracy:  79.7%, Loss: 0.4505\n",
      "Optimization Iteration:  14593, Training Accuracy:  75.0%, Loss: 0.3851\n",
      "Optimization Iteration:  14657, Training Accuracy:  71.9%, Loss: 0.4219\n",
      "Optimization Iteration:  14721, Training Accuracy:  81.2%, Loss: 0.3481\n",
      "Optimization Iteration:  14785, Training Accuracy:  75.0%, Loss: 0.4534\n",
      "Optimization Iteration:  14849, Training Accuracy:  79.7%, Loss: 0.3952\n",
      "Optimization Iteration:  14913, Training Accuracy:  84.4%, Loss: 0.3659\n",
      "Optimization Iteration:  14977, Training Accuracy:  71.9%, Loss: 0.4354\n",
      "Optimization Iteration:  15041, Training Accuracy:  78.1%, Loss: 0.3862\n",
      "Optimization Iteration:  15105, Training Accuracy:  79.7%, Loss: 0.3667\n",
      "Optimization Iteration:  15169, Training Accuracy:  79.7%, Loss: 0.3673\n",
      "Optimization Iteration:  15233, Training Accuracy:  75.0%, Loss: 0.4107\n",
      "Optimization Iteration:  15297, Training Accuracy:  82.8%, Loss: 0.3717\n",
      "Optimization Iteration:  15361, Training Accuracy:  87.5%, Loss: 0.3154\n",
      "Optimization Iteration:  15425, Training Accuracy:  73.4%, Loss: 0.4315\n",
      "Optimization Iteration:  15489, Training Accuracy:  62.5%, Loss: 0.5378\n",
      "Optimization Iteration:  15553, Training Accuracy:  76.6%, Loss: 0.3399\n",
      "Optimization Iteration:  15617, Training Accuracy:  73.4%, Loss: 0.4161\n",
      "Optimization Iteration:  15681, Training Accuracy:  81.2%, Loss: 0.3723\n",
      "Optimization Iteration:  15745, Training Accuracy:  78.1%, Loss: 0.3470\n",
      "Optimization Iteration:  15809, Training Accuracy:  71.9%, Loss: 0.4119\n",
      "Optimization Iteration:  15873, Training Accuracy:  78.1%, Loss: 0.4093\n",
      "Optimization Iteration:  15937, Training Accuracy:  73.4%, Loss: 0.3852\n",
      "Optimization Iteration:  16001, Training Accuracy:  68.8%, Loss: 0.4330\n",
      "Optimization Iteration:  16065, Training Accuracy:  67.2%, Loss: 0.4392\n",
      "Optimization Iteration:  16129, Training Accuracy:  81.2%, Loss: 0.4078\n",
      "Optimization Iteration:  16193, Training Accuracy:  79.7%, Loss: 0.4183\n",
      "Optimization Iteration:  16257, Training Accuracy:  68.8%, Loss: 0.4597\n",
      "Optimization Iteration:  16321, Training Accuracy:  75.0%, Loss: 0.4362\n",
      "Optimization Iteration:  16385, Training Accuracy:  70.3%, Loss: 0.4327\n",
      "Optimization Iteration:  16449, Training Accuracy:  76.6%, Loss: 0.4095\n",
      "Optimization Iteration:  16513, Training Accuracy:  70.3%, Loss: 0.3957\n",
      "Optimization Iteration:  16577, Training Accuracy:  76.6%, Loss: 0.3943\n",
      "Optimization Iteration:  16641, Training Accuracy:  78.1%, Loss: 0.5328\n",
      "Optimization Iteration:  16705, Training Accuracy:  78.1%, Loss: 0.4218\n",
      "Optimization Iteration:  16769, Training Accuracy:  76.6%, Loss: 0.3513\n",
      "Optimization Iteration:  16833, Training Accuracy:  71.9%, Loss: 0.3936\n",
      "Optimization Iteration:  16897, Training Accuracy:  75.0%, Loss: 0.3915\n",
      "Optimization Iteration:  16961, Training Accuracy:  71.9%, Loss: 0.3719\n",
      "Optimization Iteration:  17025, Training Accuracy:  68.8%, Loss: 0.4257\n",
      "Optimization Iteration:  17089, Training Accuracy:  81.2%, Loss: 0.3985\n",
      "Optimization Iteration:  17153, Training Accuracy:  79.7%, Loss: 0.4216\n",
      "Optimization Iteration:  17217, Training Accuracy:  76.6%, Loss: 0.4748\n",
      "Optimization Iteration:  17281, Training Accuracy:  75.0%, Loss: 0.3828\n",
      "Optimization Iteration:  17345, Training Accuracy:  71.9%, Loss: 0.3876\n",
      "Optimization Iteration:  17409, Training Accuracy:  81.2%, Loss: 0.3337\n",
      "Optimization Iteration:  17473, Training Accuracy:  70.3%, Loss: 0.5801\n",
      "Optimization Iteration:  17537, Training Accuracy:  78.1%, Loss: 0.3796\n",
      "Optimization Iteration:  17601, Training Accuracy:  67.2%, Loss: 0.4734\n",
      "Optimization Iteration:  17665, Training Accuracy:  85.9%, Loss: 0.3340\n",
      "Optimization Iteration:  17729, Training Accuracy:  76.6%, Loss: 0.3938\n",
      "Optimization Iteration:  17793, Training Accuracy:  71.9%, Loss: 0.4488\n",
      "Optimization Iteration:  17857, Training Accuracy:  73.4%, Loss: 0.4283\n",
      "Optimization Iteration:  17921, Training Accuracy:  81.2%, Loss: 0.3397\n",
      "Optimization Iteration:  17985, Training Accuracy:  71.9%, Loss: 0.3633\n",
      "Optimization Iteration:  18049, Training Accuracy:  78.1%, Loss: 0.4179\n",
      "Optimization Iteration:  18113, Training Accuracy:  70.3%, Loss: 0.4606\n",
      "Optimization Iteration:  18177, Training Accuracy:  70.3%, Loss: 0.5142\n",
      "Optimization Iteration:  18241, Training Accuracy:  70.3%, Loss: 0.4467\n",
      "Optimization Iteration:  18305, Training Accuracy:  65.6%, Loss: 0.4655\n",
      "Optimization Iteration:  18369, Training Accuracy:  73.4%, Loss: 0.3855\n",
      "Optimization Iteration:  18433, Training Accuracy:  64.1%, Loss: 0.4382\n",
      "Optimization Iteration:  18497, Training Accuracy:  79.7%, Loss: 0.3878\n",
      "Optimization Iteration:  18561, Training Accuracy:  73.4%, Loss: 0.3901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  18625, Training Accuracy:  71.9%, Loss: 0.4743\n",
      "Optimization Iteration:  18689, Training Accuracy:  73.4%, Loss: 0.4303\n",
      "Optimization Iteration:  18753, Training Accuracy:  84.4%, Loss: 0.3422\n",
      "Optimization Iteration:  18817, Training Accuracy:  76.6%, Loss: 0.4099\n",
      "Optimization Iteration:  18881, Training Accuracy:  73.4%, Loss: 0.4096\n",
      "Optimization Iteration:  18945, Training Accuracy:  76.6%, Loss: 0.4554\n",
      "Optimization Iteration:  19009, Training Accuracy:  78.1%, Loss: 0.3252\n",
      "Optimization Iteration:  19073, Training Accuracy:  71.9%, Loss: 0.5388\n",
      "Optimization Iteration:  19137, Training Accuracy:  75.0%, Loss: 0.4391\n",
      "Optimization Iteration:  19201, Training Accuracy:  75.0%, Loss: 0.3834\n",
      "Optimization Iteration:  19265, Training Accuracy:  84.4%, Loss: 0.3954\n",
      "Optimization Iteration:  19329, Training Accuracy:  75.0%, Loss: 0.4125\n",
      "Optimization Iteration:  19393, Training Accuracy:  76.6%, Loss: 0.4492\n",
      "Optimization Iteration:  19457, Training Accuracy:  76.6%, Loss: 0.3904\n",
      "Optimization Iteration:  19521, Training Accuracy:  64.1%, Loss: 0.4868\n",
      "Optimization Iteration:  19585, Training Accuracy:  75.0%, Loss: 0.4215\n",
      "Optimization Iteration:  19649, Training Accuracy:  78.1%, Loss: 0.5337\n",
      "Optimization Iteration:  19713, Training Accuracy:  84.4%, Loss: 0.3163\n",
      "Optimization Iteration:  19777, Training Accuracy:  79.7%, Loss: 0.4252\n",
      "Optimization Iteration:  19841, Training Accuracy:  73.4%, Loss: 0.4035\n",
      "Optimization Iteration:  19905, Training Accuracy:  76.6%, Loss: 0.4054\n",
      "Optimization Iteration:  19969, Training Accuracy:  81.2%, Loss: 0.3624\n",
      "Optimization Iteration:  20033, Training Accuracy:  81.2%, Loss: 0.3839\n",
      "Optimization Iteration:  20097, Training Accuracy:  68.8%, Loss: 0.4802\n",
      "Optimization Iteration:  20161, Training Accuracy:  70.3%, Loss: 0.4399\n",
      "Optimization Iteration:  20225, Training Accuracy:  70.3%, Loss: 0.4100\n",
      "Optimization Iteration:  20289, Training Accuracy:  71.9%, Loss: 0.4339\n",
      "Optimization Iteration:  20353, Training Accuracy:  87.5%, Loss: 0.3392\n",
      "Optimization Iteration:  20417, Training Accuracy:  73.4%, Loss: 0.4500\n",
      "Optimization Iteration:  20481, Training Accuracy:  70.3%, Loss: 0.4230\n",
      "Optimization Iteration:  20545, Training Accuracy:  78.1%, Loss: 0.4444\n",
      "Optimization Iteration:  20609, Training Accuracy:  73.4%, Loss: 0.4777\n",
      "Optimization Iteration:  20673, Training Accuracy:  79.7%, Loss: 0.3914\n",
      "Optimization Iteration:  20737, Training Accuracy:  76.6%, Loss: 0.4265\n",
      "Optimization Iteration:  20801, Training Accuracy:  75.0%, Loss: 0.4267\n",
      "Optimization Iteration:  20865, Training Accuracy:  76.6%, Loss: 0.3522\n",
      "Optimization Iteration:  20929, Training Accuracy:  73.4%, Loss: 0.3962\n",
      "Optimization Iteration:  20993, Training Accuracy:  76.6%, Loss: 0.4123\n",
      "Optimization Iteration:  21057, Training Accuracy:  78.1%, Loss: 0.3866\n",
      "Optimization Iteration:  21121, Training Accuracy:  75.0%, Loss: 0.3962\n",
      "Optimization Iteration:  21185, Training Accuracy:  65.6%, Loss: 0.5491\n",
      "Optimization Iteration:  21249, Training Accuracy:  70.3%, Loss: 0.5276\n",
      "Optimization Iteration:  21313, Training Accuracy:  78.1%, Loss: 0.4708\n",
      "Optimization Iteration:  21377, Training Accuracy:  81.2%, Loss: 0.3496\n",
      "Optimization Iteration:  21441, Training Accuracy:  67.2%, Loss: 0.4679\n",
      "Optimization Iteration:  21505, Training Accuracy:  81.2%, Loss: 0.4124\n",
      "Optimization Iteration:  21569, Training Accuracy:  85.9%, Loss: 0.3331\n",
      "Optimization Iteration:  21633, Training Accuracy:  78.1%, Loss: 0.3110\n",
      "Optimization Iteration:  21697, Training Accuracy:  75.0%, Loss: 0.4563\n",
      "Optimization Iteration:  21761, Training Accuracy:  87.5%, Loss: 0.3081\n",
      "Optimization Iteration:  21825, Training Accuracy:  71.9%, Loss: 0.4794\n",
      "Optimization Iteration:  21889, Training Accuracy:  79.7%, Loss: 0.3961\n",
      "Optimization Iteration:  21953, Training Accuracy:  71.9%, Loss: 0.5265\n",
      "Optimization Iteration:  22017, Training Accuracy:  78.1%, Loss: 0.4007\n",
      "Optimization Iteration:  22081, Training Accuracy:  76.6%, Loss: 0.4141\n",
      "Optimization Iteration:  22145, Training Accuracy:  79.7%, Loss: 0.3754\n",
      "Optimization Iteration:  22209, Training Accuracy:  78.1%, Loss: 0.3936\n",
      "Optimization Iteration:  22273, Training Accuracy:  78.1%, Loss: 0.4043\n",
      "Optimization Iteration:  22337, Training Accuracy:  75.0%, Loss: 0.4015\n",
      "Optimization Iteration:  22401, Training Accuracy:  73.4%, Loss: 0.3841\n",
      "Optimization Iteration:  22465, Training Accuracy:  68.8%, Loss: 0.4687\n",
      "Optimization Iteration:  22529, Training Accuracy:  78.1%, Loss: 0.3865\n",
      "Optimization Iteration:  22593, Training Accuracy:  70.3%, Loss: 0.4503\n",
      "Optimization Iteration:  22657, Training Accuracy:  70.3%, Loss: 0.4046\n",
      "Optimization Iteration:  22721, Training Accuracy:  68.8%, Loss: 0.4125\n",
      "Optimization Iteration:  22785, Training Accuracy:  70.3%, Loss: 0.4083\n",
      "Optimization Iteration:  22849, Training Accuracy:  68.8%, Loss: 0.4166\n",
      "Optimization Iteration:  22913, Training Accuracy:  84.4%, Loss: 0.4092\n",
      "Optimization Iteration:  22977, Training Accuracy:  73.4%, Loss: 0.3951\n",
      "Optimization Iteration:  23041, Training Accuracy:  67.2%, Loss: 0.3919\n",
      "Optimization Iteration:  23105, Training Accuracy:  65.6%, Loss: 0.3910\n",
      "Optimization Iteration:  23169, Training Accuracy:  85.9%, Loss: 0.3289\n",
      "Optimization Iteration:  23233, Training Accuracy:  70.3%, Loss: 0.5152\n",
      "Optimization Iteration:  23297, Training Accuracy:  78.1%, Loss: 0.4300\n",
      "Optimization Iteration:  23361, Training Accuracy:  78.1%, Loss: 0.4635\n",
      "Optimization Iteration:  23425, Training Accuracy:  81.2%, Loss: 0.3512\n",
      "Optimization Iteration:  23489, Training Accuracy:  70.3%, Loss: 0.4545\n",
      "Optimization Iteration:  23553, Training Accuracy:  78.1%, Loss: 0.3913\n",
      "Optimization Iteration:  23617, Training Accuracy:  62.5%, Loss: 0.4695\n",
      "Optimization Iteration:  23681, Training Accuracy:  79.7%, Loss: 0.3603\n",
      "Optimization Iteration:  23745, Training Accuracy:  81.2%, Loss: 0.3510\n",
      "Optimization Iteration:  23809, Training Accuracy:  76.6%, Loss: 0.4274\n",
      "Optimization Iteration:  23873, Training Accuracy:  75.0%, Loss: 0.3678\n",
      "Optimization Iteration:  23937, Training Accuracy:  78.1%, Loss: 0.4327\n",
      "Optimization Iteration:  24001, Training Accuracy:  76.6%, Loss: 0.3649\n",
      "Optimization Iteration:  24065, Training Accuracy:  70.3%, Loss: 0.4545\n",
      "Optimization Iteration:  24129, Training Accuracy:  71.9%, Loss: 0.4150\n",
      "Optimization Iteration:  24193, Training Accuracy:  71.9%, Loss: 0.4754\n",
      "Optimization Iteration:  24257, Training Accuracy:  76.6%, Loss: 0.3639\n",
      "Optimization Iteration:  24321, Training Accuracy:  76.6%, Loss: 0.4421\n",
      "Optimization Iteration:  24385, Training Accuracy:  85.9%, Loss: 0.3634\n",
      "Optimization Iteration:  24449, Training Accuracy:  81.2%, Loss: 0.3533\n",
      "Optimization Iteration:  24513, Training Accuracy:  68.8%, Loss: 0.4371\n",
      "Optimization Iteration:  24577, Training Accuracy:  73.4%, Loss: 0.4565\n",
      "Optimization Iteration:  24641, Training Accuracy:  78.1%, Loss: 0.4155\n",
      "Optimization Iteration:  24705, Training Accuracy:  82.8%, Loss: 0.3323\n",
      "Optimization Iteration:  24769, Training Accuracy:  75.0%, Loss: 0.3837\n",
      "Optimization Iteration:  24833, Training Accuracy:  75.0%, Loss: 0.3679\n",
      "Optimization Iteration:  24897, Training Accuracy:  82.8%, Loss: 0.3564\n",
      "Optimization Iteration:  24961, Training Accuracy:  81.2%, Loss: 0.2503\n",
      "Optimization Iteration:  25025, Training Accuracy:  76.6%, Loss: 0.4049\n",
      "Optimization Iteration:  25089, Training Accuracy:  71.9%, Loss: 0.4170\n",
      "Optimization Iteration:  25153, Training Accuracy:  67.2%, Loss: 0.4385\n",
      "Optimization Iteration:  25217, Training Accuracy:  67.2%, Loss: 0.4779\n",
      "Optimization Iteration:  25281, Training Accuracy:  84.4%, Loss: 0.4447\n",
      "Optimization Iteration:  25345, Training Accuracy:  68.8%, Loss: 0.4366\n",
      "Optimization Iteration:  25409, Training Accuracy:  75.0%, Loss: 0.3907\n",
      "Optimization Iteration:  25473, Training Accuracy:  73.4%, Loss: 0.4550\n",
      "Optimization Iteration:  25537, Training Accuracy:  75.0%, Loss: 0.3704\n",
      "Optimization Iteration:  25601, Training Accuracy:  65.6%, Loss: 0.4939\n",
      "Optimization Iteration:  25665, Training Accuracy:  70.3%, Loss: 0.5482\n",
      "Optimization Iteration:  25729, Training Accuracy:  78.1%, Loss: 0.3384\n",
      "Optimization Iteration:  25793, Training Accuracy:  87.5%, Loss: 0.3023\n",
      "Optimization Iteration:  25857, Training Accuracy:  68.8%, Loss: 0.4676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  25921, Training Accuracy:  78.1%, Loss: 0.4570\n",
      "Optimization Iteration:  25985, Training Accuracy:  71.9%, Loss: 0.4128\n",
      "Optimization Iteration:  26049, Training Accuracy:  75.0%, Loss: 0.3836\n",
      "Optimization Iteration:  26113, Training Accuracy:  76.6%, Loss: 0.3728\n",
      "Optimization Iteration:  26177, Training Accuracy:  82.8%, Loss: 0.4209\n",
      "Optimization Iteration:  26241, Training Accuracy:  79.7%, Loss: 0.3880\n",
      "Optimization Iteration:  26305, Training Accuracy:  75.0%, Loss: 0.4266\n",
      "Optimization Iteration:  26369, Training Accuracy:  78.1%, Loss: 0.3626\n",
      "Optimization Iteration:  26433, Training Accuracy:  64.1%, Loss: 0.4526\n",
      "Optimization Iteration:  26497, Training Accuracy:  76.6%, Loss: 0.4438\n",
      "Optimization Iteration:  26561, Training Accuracy:  79.7%, Loss: 0.3612\n",
      "Optimization Iteration:  26625, Training Accuracy:  71.9%, Loss: 0.3856\n",
      "Optimization Iteration:  26689, Training Accuracy:  75.0%, Loss: 0.4501\n",
      "Optimization Iteration:  26753, Training Accuracy:  73.4%, Loss: 0.4252\n",
      "Optimization Iteration:  26817, Training Accuracy:  71.9%, Loss: 0.4251\n",
      "Optimization Iteration:  26881, Training Accuracy:  79.7%, Loss: 0.3808\n",
      "Optimization Iteration:  26945, Training Accuracy:  78.1%, Loss: 0.4596\n",
      "Optimization Iteration:  27009, Training Accuracy:  76.6%, Loss: 0.3967\n",
      "Optimization Iteration:  27073, Training Accuracy:  75.0%, Loss: 0.3897\n",
      "Optimization Iteration:  27137, Training Accuracy:  76.6%, Loss: 0.4062\n",
      "Optimization Iteration:  27201, Training Accuracy:  79.7%, Loss: 0.3955\n",
      "Optimization Iteration:  27265, Training Accuracy:  71.9%, Loss: 0.4520\n",
      "Optimization Iteration:  27329, Training Accuracy:  73.4%, Loss: 0.4187\n",
      "Optimization Iteration:  27393, Training Accuracy:  71.9%, Loss: 0.4637\n",
      "Optimization Iteration:  27457, Training Accuracy:  79.7%, Loss: 0.4327\n",
      "Optimization Iteration:  27521, Training Accuracy:  87.5%, Loss: 0.3731\n",
      "Optimization Iteration:  27585, Training Accuracy:  81.2%, Loss: 0.4043\n",
      "Optimization Iteration:  27649, Training Accuracy:  82.8%, Loss: 0.3873\n",
      "Optimization Iteration:  27713, Training Accuracy:  75.0%, Loss: 0.4275\n",
      "Optimization Iteration:  27777, Training Accuracy:  78.1%, Loss: 0.3705\n",
      "Optimization Iteration:  27841, Training Accuracy:  64.1%, Loss: 0.4917\n",
      "Optimization Iteration:  27905, Training Accuracy:  79.7%, Loss: 0.3727\n",
      "Optimization Iteration:  27969, Training Accuracy:  70.3%, Loss: 0.4740\n",
      "Optimization Iteration:  28033, Training Accuracy:  79.7%, Loss: 0.4044\n",
      "Optimization Iteration:  28097, Training Accuracy:  79.7%, Loss: 0.3783\n",
      "Optimization Iteration:  28161, Training Accuracy:  85.9%, Loss: 0.3233\n",
      "Optimization Iteration:  28225, Training Accuracy:  73.4%, Loss: 0.3821\n",
      "Optimization Iteration:  28289, Training Accuracy:  71.9%, Loss: 0.3790\n",
      "Optimization Iteration:  28353, Training Accuracy:  79.7%, Loss: 0.3903\n",
      "Optimization Iteration:  28417, Training Accuracy:  73.4%, Loss: 0.4161\n",
      "Optimization Iteration:  28481, Training Accuracy:  71.9%, Loss: 0.3666\n",
      "Optimization Iteration:  28545, Training Accuracy:  82.8%, Loss: 0.3545\n",
      "Optimization Iteration:  28609, Training Accuracy:  84.4%, Loss: 0.3429\n",
      "Optimization Iteration:  28673, Training Accuracy:  75.0%, Loss: 0.4465\n",
      "Optimization Iteration:  28737, Training Accuracy:  78.1%, Loss: 0.3726\n",
      "Optimization Iteration:  28801, Training Accuracy:  81.2%, Loss: 0.2719\n",
      "Optimization Iteration:  28865, Training Accuracy:  75.0%, Loss: 0.3897\n",
      "Optimization Iteration:  28929, Training Accuracy:  82.8%, Loss: 0.3430\n",
      "Optimization Iteration:  28993, Training Accuracy:  67.2%, Loss: 0.4190\n",
      "Optimization Iteration:  29057, Training Accuracy:  79.7%, Loss: 0.3843\n",
      "Optimization Iteration:  29121, Training Accuracy:  64.1%, Loss: 0.5158\n",
      "Optimization Iteration:  29185, Training Accuracy:  70.3%, Loss: 0.3655\n",
      "Optimization Iteration:  29249, Training Accuracy:  81.2%, Loss: 0.4232\n",
      "Optimization Iteration:  29313, Training Accuracy:  70.3%, Loss: 0.4349\n",
      "Optimization Iteration:  29377, Training Accuracy:  76.6%, Loss: 0.3794\n",
      "Optimization Iteration:  29441, Training Accuracy:  73.4%, Loss: 0.4222\n",
      "Optimization Iteration:  29505, Training Accuracy:  76.6%, Loss: 0.3897\n",
      "Optimization Iteration:  29569, Training Accuracy:  71.9%, Loss: 0.4450\n",
      "Optimization Iteration:  29633, Training Accuracy:  70.3%, Loss: 0.4583\n",
      "Optimization Iteration:  29697, Training Accuracy:  79.7%, Loss: 0.3642\n",
      "Optimization Iteration:  29761, Training Accuracy:  71.9%, Loss: 0.4967\n",
      "Optimization Iteration:  29825, Training Accuracy:  73.4%, Loss: 0.3973\n",
      "Optimization Iteration:  29889, Training Accuracy:  75.0%, Loss: 0.4230\n",
      "Optimization Iteration:  29953, Training Accuracy:  73.4%, Loss: 0.4437\n",
      "Optimization Iteration:  30017, Training Accuracy:  89.1%, Loss: 0.2563\n",
      "Optimization Iteration:  30081, Training Accuracy:  81.2%, Loss: 0.3583\n",
      "Optimization Iteration:  30145, Training Accuracy:  76.6%, Loss: 0.3960\n",
      "Optimization Iteration:  30209, Training Accuracy:  73.4%, Loss: 0.4097\n",
      "Optimization Iteration:  30273, Training Accuracy:  78.1%, Loss: 0.4156\n",
      "Optimization Iteration:  30337, Training Accuracy:  71.9%, Loss: 0.4073\n",
      "Optimization Iteration:  30401, Training Accuracy:  68.8%, Loss: 0.4514\n",
      "Optimization Iteration:  30465, Training Accuracy:  79.7%, Loss: 0.4052\n",
      "Optimization Iteration:  30529, Training Accuracy:  81.2%, Loss: 0.4036\n",
      "Optimization Iteration:  30593, Training Accuracy:  78.1%, Loss: 0.3230\n",
      "Optimization Iteration:  30657, Training Accuracy:  84.4%, Loss: 0.3237\n",
      "Optimization Iteration:  30721, Training Accuracy:  81.2%, Loss: 0.3805\n",
      "Optimization Iteration:  30785, Training Accuracy:  75.0%, Loss: 0.3490\n",
      "Optimization Iteration:  30849, Training Accuracy:  76.6%, Loss: 0.4251\n",
      "Optimization Iteration:  30913, Training Accuracy:  73.4%, Loss: 0.4334\n",
      "Optimization Iteration:  30977, Training Accuracy:  78.1%, Loss: 0.4382\n",
      "Optimization Iteration:  31041, Training Accuracy:  79.7%, Loss: 0.4145\n",
      "Optimization Iteration:  31105, Training Accuracy:  76.6%, Loss: 0.3845\n",
      "Optimization Iteration:  31169, Training Accuracy:  75.0%, Loss: 0.3511\n",
      "Optimization Iteration:  31233, Training Accuracy:  76.6%, Loss: 0.3812\n",
      "Optimization Iteration:  31297, Training Accuracy:  84.4%, Loss: 0.3033\n",
      "Optimization Iteration:  31361, Training Accuracy:  70.3%, Loss: 0.3884\n",
      "Optimization Iteration:  31425, Training Accuracy:  82.8%, Loss: 0.2987\n",
      "Optimization Iteration:  31489, Training Accuracy:  84.4%, Loss: 0.3350\n",
      "Optimization Iteration:  31553, Training Accuracy:  78.1%, Loss: 0.3825\n",
      "Optimization Iteration:  31617, Training Accuracy:  71.9%, Loss: 0.4209\n",
      "Optimization Iteration:  31681, Training Accuracy:  78.1%, Loss: 0.4264\n",
      "Optimization Iteration:  31745, Training Accuracy:  73.4%, Loss: 0.4089\n",
      "Optimization Iteration:  31809, Training Accuracy:  68.8%, Loss: 0.4955\n",
      "Optimization Iteration:  31873, Training Accuracy:  84.4%, Loss: 0.3262\n",
      "Optimization Iteration:  31937, Training Accuracy:  65.6%, Loss: 0.5627\n",
      "Optimization Iteration:  32001, Training Accuracy:  76.6%, Loss: 0.4380\n",
      "Optimization Iteration:  32065, Training Accuracy:  68.8%, Loss: 0.4166\n",
      "Optimization Iteration:  32129, Training Accuracy:  75.0%, Loss: 0.3766\n",
      "Optimization Iteration:  32193, Training Accuracy:  76.6%, Loss: 0.3915\n",
      "Optimization Iteration:  32257, Training Accuracy:  73.4%, Loss: 0.4427\n",
      "Optimization Iteration:  32321, Training Accuracy:  84.4%, Loss: 0.3517\n",
      "Optimization Iteration:  32385, Training Accuracy:  81.2%, Loss: 0.3803\n",
      "Optimization Iteration:  32449, Training Accuracy:  71.9%, Loss: 0.4410\n",
      "Optimization Iteration:  32513, Training Accuracy:  78.1%, Loss: 0.3612\n",
      "Optimization Iteration:  32577, Training Accuracy:  82.8%, Loss: 0.3666\n",
      "Optimization Iteration:  32641, Training Accuracy:  68.8%, Loss: 0.4724\n",
      "Optimization Iteration:  32705, Training Accuracy:  70.3%, Loss: 0.4794\n",
      "Optimization Iteration:  32769, Training Accuracy:  79.7%, Loss: 0.4140\n",
      "Optimization Iteration:  32833, Training Accuracy:  73.4%, Loss: 0.4097\n",
      "Optimization Iteration:  32897, Training Accuracy:  73.4%, Loss: 0.4179\n",
      "Optimization Iteration:  32961, Training Accuracy:  68.8%, Loss: 0.5080\n",
      "Optimization Iteration:  33025, Training Accuracy:  79.7%, Loss: 0.3424\n",
      "Optimization Iteration:  33089, Training Accuracy:  67.2%, Loss: 0.4701\n",
      "Optimization Iteration:  33153, Training Accuracy:  76.6%, Loss: 0.4295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  33217, Training Accuracy:  70.3%, Loss: 0.4287\n",
      "Optimization Iteration:  33281, Training Accuracy:  73.4%, Loss: 0.4627\n",
      "Optimization Iteration:  33345, Training Accuracy:  76.6%, Loss: 0.4178\n",
      "Optimization Iteration:  33409, Training Accuracy:  73.4%, Loss: 0.4012\n",
      "Optimization Iteration:  33473, Training Accuracy:  68.8%, Loss: 0.4382\n",
      "Optimization Iteration:  33537, Training Accuracy:  71.9%, Loss: 0.4607\n",
      "Optimization Iteration:  33601, Training Accuracy:  79.7%, Loss: 0.4052\n",
      "Optimization Iteration:  33665, Training Accuracy:  75.0%, Loss: 0.3899\n",
      "Optimization Iteration:  33729, Training Accuracy:  79.7%, Loss: 0.3870\n",
      "Optimization Iteration:  33793, Training Accuracy:  68.8%, Loss: 0.5149\n",
      "Optimization Iteration:  33857, Training Accuracy:  76.6%, Loss: 0.3680\n",
      "Optimization Iteration:  33921, Training Accuracy:  82.8%, Loss: 0.3641\n",
      "Optimization Iteration:  33985, Training Accuracy:  76.6%, Loss: 0.3854\n",
      "Optimization Iteration:  34049, Training Accuracy:  73.4%, Loss: 0.4835\n",
      "Optimization Iteration:  34113, Training Accuracy:  75.0%, Loss: 0.4303\n",
      "Optimization Iteration:  34177, Training Accuracy:  75.0%, Loss: 0.3584\n",
      "Optimization Iteration:  34241, Training Accuracy:  75.0%, Loss: 0.4242\n",
      "Optimization Iteration:  34305, Training Accuracy:  65.6%, Loss: 0.4581\n",
      "Optimization Iteration:  34369, Training Accuracy:  78.1%, Loss: 0.3509\n",
      "Optimization Iteration:  34433, Training Accuracy:  68.8%, Loss: 0.4904\n",
      "Optimization Iteration:  34497, Training Accuracy:  76.6%, Loss: 0.3758\n",
      "Optimization Iteration:  34561, Training Accuracy:  82.8%, Loss: 0.3649\n",
      "Optimization Iteration:  34625, Training Accuracy:  71.9%, Loss: 0.4549\n",
      "Optimization Iteration:  34689, Training Accuracy:  68.8%, Loss: 0.4642\n",
      "Optimization Iteration:  34753, Training Accuracy:  75.0%, Loss: 0.5392\n",
      "Optimization Iteration:  34817, Training Accuracy:  76.6%, Loss: 0.3940\n",
      "Optimization Iteration:  34881, Training Accuracy:  70.3%, Loss: 0.3734\n",
      "Optimization Iteration:  34945, Training Accuracy:  81.2%, Loss: 0.3799\n",
      "Optimization Iteration:  35009, Training Accuracy:  84.4%, Loss: 0.3752\n",
      "Optimization Iteration:  35073, Training Accuracy:  79.7%, Loss: 0.3421\n",
      "Optimization Iteration:  35137, Training Accuracy:  81.2%, Loss: 0.3365\n",
      "Optimization Iteration:  35201, Training Accuracy:  75.0%, Loss: 0.3777\n",
      "Optimization Iteration:  35265, Training Accuracy:  68.8%, Loss: 0.4373\n",
      "Optimization Iteration:  35329, Training Accuracy:  68.8%, Loss: 0.4044\n",
      "Optimization Iteration:  35393, Training Accuracy:  73.4%, Loss: 0.3780\n",
      "Optimization Iteration:  35457, Training Accuracy:  76.6%, Loss: 0.3513\n",
      "Optimization Iteration:  35521, Training Accuracy:  67.2%, Loss: 0.4537\n",
      "Optimization Iteration:  35585, Training Accuracy:  78.1%, Loss: 0.3679\n",
      "Optimization Iteration:  35649, Training Accuracy:  70.3%, Loss: 0.4823\n",
      "Optimization Iteration:  35713, Training Accuracy:  81.2%, Loss: 0.4349\n",
      "Optimization Iteration:  35777, Training Accuracy:  75.0%, Loss: 0.3275\n",
      "Optimization Iteration:  35841, Training Accuracy:  79.7%, Loss: 0.3701\n",
      "Optimization Iteration:  35905, Training Accuracy:  81.2%, Loss: 0.4321\n",
      "Optimization Iteration:  35969, Training Accuracy:  75.0%, Loss: 0.4097\n",
      "Optimization Iteration:  36033, Training Accuracy:  73.4%, Loss: 0.4106\n",
      "Optimization Iteration:  36097, Training Accuracy:  75.0%, Loss: 0.4336\n",
      "Optimization Iteration:  36161, Training Accuracy:  75.0%, Loss: 0.4042\n",
      "Optimization Iteration:  36225, Training Accuracy:  81.2%, Loss: 0.3530\n",
      "Optimization Iteration:  36289, Training Accuracy:  75.0%, Loss: 0.3902\n",
      "Optimization Iteration:  36353, Training Accuracy:  78.1%, Loss: 0.3760\n",
      "Optimization Iteration:  36417, Training Accuracy:  71.9%, Loss: 0.4885\n",
      "Optimization Iteration:  36481, Training Accuracy:  78.1%, Loss: 0.3659\n",
      "Optimization Iteration:  36545, Training Accuracy:  85.9%, Loss: 0.3346\n",
      "Optimization Iteration:  36609, Training Accuracy:  82.8%, Loss: 0.3313\n",
      "Optimization Iteration:  36673, Training Accuracy:  70.3%, Loss: 0.4436\n",
      "Optimization Iteration:  36737, Training Accuracy:  79.7%, Loss: 0.3729\n",
      "Optimization Iteration:  36801, Training Accuracy:  79.7%, Loss: 0.3312\n",
      "Optimization Iteration:  36865, Training Accuracy:  68.8%, Loss: 0.4041\n",
      "Optimization Iteration:  36929, Training Accuracy:  71.9%, Loss: 0.4076\n",
      "Optimization Iteration:  36993, Training Accuracy:  68.8%, Loss: 0.4105\n",
      "Optimization Iteration:  37057, Training Accuracy:  70.3%, Loss: 0.3823\n",
      "Optimization Iteration:  37121, Training Accuracy:  81.2%, Loss: 0.4000\n",
      "Optimization Iteration:  37185, Training Accuracy:  84.4%, Loss: 0.3299\n",
      "Optimization Iteration:  37249, Training Accuracy:  70.3%, Loss: 0.5279\n",
      "Optimization Iteration:  37313, Training Accuracy:  82.8%, Loss: 0.3120\n",
      "Optimization Iteration:  37377, Training Accuracy:  78.1%, Loss: 0.5598\n",
      "Optimization Iteration:  37441, Training Accuracy:  68.8%, Loss: 0.3804\n",
      "Optimization Iteration:  37505, Training Accuracy:  76.6%, Loss: 0.4007\n",
      "Optimization Iteration:  37569, Training Accuracy:  76.6%, Loss: 0.4381\n",
      "Optimization Iteration:  37633, Training Accuracy:  67.2%, Loss: 0.4685\n",
      "Optimization Iteration:  37697, Training Accuracy:  76.6%, Loss: 0.3796\n",
      "Optimization Iteration:  37761, Training Accuracy:  79.7%, Loss: 0.3912\n",
      "Optimization Iteration:  37825, Training Accuracy:  76.6%, Loss: 0.4235\n",
      "Optimization Iteration:  37889, Training Accuracy:  78.1%, Loss: 0.4131\n",
      "Optimization Iteration:  37953, Training Accuracy:  79.7%, Loss: 0.3930\n",
      "Optimization Iteration:  38017, Training Accuracy:  79.7%, Loss: 0.4140\n",
      "Optimization Iteration:  38081, Training Accuracy:  79.7%, Loss: 0.3651\n",
      "Optimization Iteration:  38145, Training Accuracy:  81.2%, Loss: 0.3724\n",
      "Optimization Iteration:  38209, Training Accuracy:  73.4%, Loss: 0.4313\n",
      "Optimization Iteration:  38273, Training Accuracy:  75.0%, Loss: 0.3736\n",
      "Optimization Iteration:  38337, Training Accuracy:  81.2%, Loss: 0.3327\n",
      "Optimization Iteration:  38401, Training Accuracy:  81.2%, Loss: 0.4233\n",
      "Optimization Iteration:  38465, Training Accuracy:  79.7%, Loss: 0.4235\n",
      "Optimization Iteration:  38529, Training Accuracy:  79.7%, Loss: 0.4152\n",
      "Optimization Iteration:  38593, Training Accuracy:  62.5%, Loss: 0.5680\n",
      "Optimization Iteration:  38657, Training Accuracy:  73.4%, Loss: 0.3767\n",
      "Optimization Iteration:  38721, Training Accuracy:  73.4%, Loss: 0.3773\n",
      "Optimization Iteration:  38785, Training Accuracy:  65.6%, Loss: 0.4518\n",
      "Optimization Iteration:  38849, Training Accuracy:  81.2%, Loss: 0.3513\n",
      "Optimization Iteration:  38913, Training Accuracy:  75.0%, Loss: 0.4272\n",
      "Optimization Iteration:  38977, Training Accuracy:  71.9%, Loss: 0.4587\n",
      "Optimization Iteration:  39041, Training Accuracy:  78.1%, Loss: 0.3989\n",
      "Optimization Iteration:  39105, Training Accuracy:  68.8%, Loss: 0.5518\n",
      "Optimization Iteration:  39169, Training Accuracy:  67.2%, Loss: 0.4998\n",
      "Optimization Iteration:  39233, Training Accuracy:  71.9%, Loss: 0.3970\n",
      "Optimization Iteration:  39297, Training Accuracy:  71.9%, Loss: 0.3565\n",
      "Optimization Iteration:  39361, Training Accuracy:  70.3%, Loss: 0.4052\n",
      "Optimization Iteration:  39425, Training Accuracy:  73.4%, Loss: 0.4409\n",
      "Optimization Iteration:  39489, Training Accuracy:  81.2%, Loss: 0.3715\n",
      "Optimization Iteration:  39553, Training Accuracy:  78.1%, Loss: 0.3805\n",
      "Optimization Iteration:  39617, Training Accuracy:  76.6%, Loss: 0.4557\n",
      "Optimization Iteration:  39681, Training Accuracy:  68.8%, Loss: 0.3899\n",
      "Optimization Iteration:  39745, Training Accuracy:  78.1%, Loss: 0.4295\n",
      "Optimization Iteration:  39809, Training Accuracy:  76.6%, Loss: 0.3942\n",
      "Optimization Iteration:  39873, Training Accuracy:  73.4%, Loss: 0.4352\n",
      "Optimization Iteration:  39937, Training Accuracy:  73.4%, Loss: 0.4378\n",
      "Optimization Iteration:  40001, Training Accuracy:  75.0%, Loss: 0.3510\n",
      "Optimization Iteration:  40065, Training Accuracy:  73.4%, Loss: 0.3302\n",
      "Optimization Iteration:  40129, Training Accuracy:  70.3%, Loss: 0.4402\n",
      "Optimization Iteration:  40193, Training Accuracy:  73.4%, Loss: 0.4866\n",
      "Optimization Iteration:  40257, Training Accuracy:  71.9%, Loss: 0.3990\n",
      "Optimization Iteration:  40321, Training Accuracy:  75.0%, Loss: 0.3987\n",
      "Optimization Iteration:  40385, Training Accuracy:  70.3%, Loss: 0.4401\n",
      "Optimization Iteration:  40449, Training Accuracy:  75.0%, Loss: 0.3717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  40513, Training Accuracy:  76.6%, Loss: 0.3601\n",
      "Optimization Iteration:  40577, Training Accuracy:  84.4%, Loss: 0.3582\n",
      "Optimization Iteration:  40641, Training Accuracy:  75.0%, Loss: 0.4161\n",
      "Optimization Iteration:  40705, Training Accuracy:  76.6%, Loss: 0.4465\n",
      "Optimization Iteration:  40769, Training Accuracy:  76.6%, Loss: 0.4063\n",
      "Optimization Iteration:  40833, Training Accuracy:  78.1%, Loss: 0.3437\n",
      "Optimization Iteration:  40897, Training Accuracy:  76.6%, Loss: 0.4295\n",
      "Optimization Iteration:  40961, Training Accuracy:  84.4%, Loss: 0.2910\n",
      "Optimization Iteration:  41025, Training Accuracy:  79.7%, Loss: 0.3776\n",
      "Optimization Iteration:  41089, Training Accuracy:  82.8%, Loss: 0.3683\n",
      "Optimization Iteration:  41153, Training Accuracy:  76.6%, Loss: 0.4154\n",
      "Optimization Iteration:  41217, Training Accuracy:  81.2%, Loss: 0.3370\n",
      "Optimization Iteration:  41281, Training Accuracy:  68.8%, Loss: 0.4613\n",
      "Optimization Iteration:  41345, Training Accuracy:  78.1%, Loss: 0.4093\n",
      "Optimization Iteration:  41409, Training Accuracy:  79.7%, Loss: 0.3630\n",
      "Optimization Iteration:  41473, Training Accuracy:  81.2%, Loss: 0.4136\n",
      "Optimization Iteration:  41537, Training Accuracy:  71.9%, Loss: 0.4461\n",
      "Optimization Iteration:  41601, Training Accuracy:  78.1%, Loss: 0.4014\n",
      "Optimization Iteration:  41665, Training Accuracy:  78.1%, Loss: 0.3457\n",
      "Optimization Iteration:  41729, Training Accuracy:  78.1%, Loss: 0.3522\n",
      "Optimization Iteration:  41793, Training Accuracy:  79.7%, Loss: 0.4170\n",
      "Optimization Iteration:  41857, Training Accuracy:  73.4%, Loss: 0.4538\n",
      "Optimization Iteration:  41921, Training Accuracy:  71.9%, Loss: 0.3445\n",
      "Optimization Iteration:  41985, Training Accuracy:  71.9%, Loss: 0.4540\n",
      "Optimization Iteration:  42049, Training Accuracy:  73.4%, Loss: 0.4113\n",
      "Optimization Iteration:  42113, Training Accuracy:  76.6%, Loss: 0.3568\n",
      "Optimization Iteration:  42177, Training Accuracy:  76.6%, Loss: 0.3969\n",
      "Optimization Iteration:  42241, Training Accuracy:  76.6%, Loss: 0.4218\n",
      "Optimization Iteration:  42305, Training Accuracy:  82.8%, Loss: 0.4338\n",
      "Optimization Iteration:  42369, Training Accuracy:  76.6%, Loss: 0.3572\n",
      "Optimization Iteration:  42433, Training Accuracy:  76.6%, Loss: 0.3718\n",
      "Optimization Iteration:  42497, Training Accuracy:  68.8%, Loss: 0.4235\n",
      "Optimization Iteration:  42561, Training Accuracy:  79.7%, Loss: 0.3888\n",
      "Optimization Iteration:  42625, Training Accuracy:  81.2%, Loss: 0.3649\n",
      "Optimization Iteration:  42689, Training Accuracy:  70.3%, Loss: 0.4679\n",
      "Optimization Iteration:  42753, Training Accuracy:  79.7%, Loss: 0.3839\n",
      "Optimization Iteration:  42817, Training Accuracy:  75.0%, Loss: 0.3484\n",
      "Optimization Iteration:  42881, Training Accuracy:  65.6%, Loss: 0.4826\n",
      "Optimization Iteration:  42945, Training Accuracy:  79.7%, Loss: 0.4133\n",
      "Optimization Iteration:  43009, Training Accuracy:  65.6%, Loss: 0.4213\n",
      "Optimization Iteration:  43073, Training Accuracy:  82.8%, Loss: 0.3875\n",
      "Optimization Iteration:  43137, Training Accuracy:  79.7%, Loss: 0.4046\n",
      "Optimization Iteration:  43201, Training Accuracy:  68.8%, Loss: 0.4090\n",
      "Optimization Iteration:  43265, Training Accuracy:  71.9%, Loss: 0.3784\n",
      "Optimization Iteration:  43329, Training Accuracy:  68.8%, Loss: 0.4781\n",
      "Optimization Iteration:  43393, Training Accuracy:  71.9%, Loss: 0.4155\n",
      "Optimization Iteration:  43457, Training Accuracy:  73.4%, Loss: 0.4043\n",
      "Optimization Iteration:  43521, Training Accuracy:  81.2%, Loss: 0.3658\n",
      "Optimization Iteration:  43585, Training Accuracy:  76.6%, Loss: 0.3781\n",
      "Optimization Iteration:  43649, Training Accuracy:  81.2%, Loss: 0.4297\n",
      "Optimization Iteration:  43713, Training Accuracy:  75.0%, Loss: 0.3837\n",
      "Optimization Iteration:  43777, Training Accuracy:  78.1%, Loss: 0.3842\n",
      "Optimization Iteration:  43841, Training Accuracy:  73.4%, Loss: 0.4348\n",
      "Optimization Iteration:  43905, Training Accuracy:  73.4%, Loss: 0.4161\n",
      "Optimization Iteration:  43969, Training Accuracy:  76.6%, Loss: 0.3673\n",
      "Optimization Iteration:  44033, Training Accuracy:  85.9%, Loss: 0.2842\n",
      "Optimization Iteration:  44097, Training Accuracy:  84.4%, Loss: 0.2998\n",
      "Optimization Iteration:  44161, Training Accuracy:  75.0%, Loss: 0.3730\n",
      "Optimization Iteration:  44225, Training Accuracy:  84.4%, Loss: 0.3261\n",
      "Optimization Iteration:  44289, Training Accuracy:  81.2%, Loss: 0.3745\n",
      "Optimization Iteration:  44353, Training Accuracy:  75.0%, Loss: 0.4446\n",
      "Optimization Iteration:  44417, Training Accuracy:  73.4%, Loss: 0.3784\n",
      "Optimization Iteration:  44481, Training Accuracy:  73.4%, Loss: 0.4409\n",
      "Optimization Iteration:  44545, Training Accuracy:  76.6%, Loss: 0.3898\n",
      "Optimization Iteration:  44609, Training Accuracy:  79.7%, Loss: 0.3801\n",
      "Optimization Iteration:  44673, Training Accuracy:  64.1%, Loss: 0.5942\n",
      "Optimization Iteration:  44737, Training Accuracy:  65.6%, Loss: 0.4988\n",
      "Optimization Iteration:  44801, Training Accuracy:  67.2%, Loss: 0.3729\n",
      "Optimization Iteration:  44865, Training Accuracy:  73.4%, Loss: 0.4179\n",
      "Optimization Iteration:  44929, Training Accuracy:  82.8%, Loss: 0.3703\n",
      "Optimization Iteration:  44993, Training Accuracy:  71.9%, Loss: 0.4525\n",
      "Optimization Iteration:  45057, Training Accuracy:  73.4%, Loss: 0.4286\n",
      "Optimization Iteration:  45121, Training Accuracy:  76.6%, Loss: 0.3281\n",
      "Optimization Iteration:  45185, Training Accuracy:  81.2%, Loss: 0.2736\n",
      "Optimization Iteration:  45249, Training Accuracy:  75.0%, Loss: 0.4038\n",
      "Optimization Iteration:  45313, Training Accuracy:  75.0%, Loss: 0.4456\n",
      "Optimization Iteration:  45377, Training Accuracy:  75.0%, Loss: 0.4142\n",
      "Optimization Iteration:  45441, Training Accuracy:  75.0%, Loss: 0.3659\n",
      "Optimization Iteration:  45505, Training Accuracy:  78.1%, Loss: 0.4061\n",
      "Optimization Iteration:  45569, Training Accuracy:  68.8%, Loss: 0.4489\n",
      "Optimization Iteration:  45633, Training Accuracy:  79.7%, Loss: 0.4407\n",
      "Optimization Iteration:  45697, Training Accuracy:  82.8%, Loss: 0.3688\n",
      "Optimization Iteration:  45761, Training Accuracy:  79.7%, Loss: 0.3678\n",
      "Optimization Iteration:  45825, Training Accuracy:  81.2%, Loss: 0.3838\n",
      "Optimization Iteration:  45889, Training Accuracy:  84.4%, Loss: 0.3490\n",
      "Optimization Iteration:  45953, Training Accuracy:  81.2%, Loss: 0.3399\n",
      "Optimization Iteration:  46017, Training Accuracy:  82.8%, Loss: 0.3908\n",
      "Optimization Iteration:  46081, Training Accuracy:  75.0%, Loss: 0.3405\n",
      "Optimization Iteration:  46145, Training Accuracy:  71.9%, Loss: 0.4221\n",
      "Optimization Iteration:  46209, Training Accuracy:  73.4%, Loss: 0.3975\n",
      "Optimization Iteration:  46273, Training Accuracy:  62.5%, Loss: 0.5078\n",
      "Optimization Iteration:  46337, Training Accuracy:  78.1%, Loss: 0.4310\n",
      "Optimization Iteration:  46401, Training Accuracy:  82.8%, Loss: 0.3069\n",
      "Optimization Iteration:  46465, Training Accuracy:  84.4%, Loss: 0.3777\n",
      "Optimization Iteration:  46529, Training Accuracy:  78.1%, Loss: 0.3855\n",
      "Optimization Iteration:  46593, Training Accuracy:  81.2%, Loss: 0.4117\n",
      "Optimization Iteration:  46657, Training Accuracy:  75.0%, Loss: 0.4397\n",
      "Optimization Iteration:  46721, Training Accuracy:  76.6%, Loss: 0.3807\n",
      "Optimization Iteration:  46785, Training Accuracy:  73.4%, Loss: 0.4474\n",
      "Optimization Iteration:  46849, Training Accuracy:  70.3%, Loss: 0.3856\n",
      "Optimization Iteration:  46913, Training Accuracy:  78.1%, Loss: 0.3381\n",
      "Optimization Iteration:  46977, Training Accuracy:  79.7%, Loss: 0.3535\n",
      "Optimization Iteration:  47041, Training Accuracy:  78.1%, Loss: 0.3968\n",
      "Optimization Iteration:  47105, Training Accuracy:  62.5%, Loss: 0.5078\n",
      "Optimization Iteration:  47169, Training Accuracy:  71.9%, Loss: 0.4474\n",
      "Optimization Iteration:  47233, Training Accuracy:  78.1%, Loss: 0.3407\n",
      "Optimization Iteration:  47297, Training Accuracy:  70.3%, Loss: 0.4092\n",
      "Optimization Iteration:  47361, Training Accuracy:  76.6%, Loss: 0.3732\n",
      "Optimization Iteration:  47425, Training Accuracy:  78.1%, Loss: 0.3788\n",
      "Optimization Iteration:  47489, Training Accuracy:  75.0%, Loss: 0.4396\n",
      "Optimization Iteration:  47553, Training Accuracy:  73.4%, Loss: 0.4578\n",
      "Optimization Iteration:  47617, Training Accuracy:  71.9%, Loss: 0.4485\n",
      "Optimization Iteration:  47681, Training Accuracy:  79.7%, Loss: 0.3641\n",
      "Optimization Iteration:  47745, Training Accuracy:  64.1%, Loss: 0.4306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  47809, Training Accuracy:  71.9%, Loss: 0.4177\n",
      "Optimization Iteration:  47873, Training Accuracy:  82.8%, Loss: 0.3773\n",
      "Optimization Iteration:  47937, Training Accuracy:  68.8%, Loss: 0.4602\n",
      "Optimization Iteration:  48001, Training Accuracy:  78.1%, Loss: 0.3857\n",
      "Optimization Iteration:  48065, Training Accuracy:  81.2%, Loss: 0.3704\n",
      "Optimization Iteration:  48129, Training Accuracy:  65.6%, Loss: 0.4823\n",
      "Optimization Iteration:  48193, Training Accuracy:  75.0%, Loss: 0.4670\n",
      "Optimization Iteration:  48257, Training Accuracy:  73.4%, Loss: 0.4459\n",
      "Optimization Iteration:  48321, Training Accuracy:  81.2%, Loss: 0.3514\n",
      "Optimization Iteration:  48385, Training Accuracy:  76.6%, Loss: 0.4601\n",
      "Optimization Iteration:  48449, Training Accuracy:  70.3%, Loss: 0.4259\n",
      "Optimization Iteration:  48513, Training Accuracy:  71.9%, Loss: 0.4730\n",
      "Optimization Iteration:  48577, Training Accuracy:  68.8%, Loss: 0.4710\n",
      "Optimization Iteration:  48641, Training Accuracy:  75.0%, Loss: 0.4063\n",
      "Optimization Iteration:  48705, Training Accuracy:  70.3%, Loss: 0.4151\n",
      "Optimization Iteration:  48769, Training Accuracy:  87.5%, Loss: 0.3562\n",
      "Optimization Iteration:  48833, Training Accuracy:  78.1%, Loss: 0.3400\n",
      "Optimization Iteration:  48897, Training Accuracy:  68.8%, Loss: 0.4582\n",
      "Optimization Iteration:  48961, Training Accuracy:  78.1%, Loss: 0.4204\n",
      "Optimization Iteration:  49025, Training Accuracy:  68.8%, Loss: 0.4425\n",
      "Optimization Iteration:  49089, Training Accuracy:  79.7%, Loss: 0.3441\n",
      "Optimization Iteration:  49153, Training Accuracy:  85.9%, Loss: 0.3504\n",
      "Optimization Iteration:  49217, Training Accuracy:  79.7%, Loss: 0.3763\n",
      "Optimization Iteration:  49281, Training Accuracy:  81.2%, Loss: 0.3702\n",
      "Optimization Iteration:  49345, Training Accuracy:  65.6%, Loss: 0.4127\n",
      "Optimization Iteration:  49409, Training Accuracy:  73.4%, Loss: 0.4674\n",
      "Optimization Iteration:  49473, Training Accuracy:  71.9%, Loss: 0.4258\n",
      "Optimization Iteration:  49537, Training Accuracy:  73.4%, Loss: 0.4058\n",
      "Optimization Iteration:  49601, Training Accuracy:  78.1%, Loss: 0.3709\n",
      "Optimization Iteration:  49665, Training Accuracy:  79.7%, Loss: 0.3277\n",
      "Optimization Iteration:  49729, Training Accuracy:  68.8%, Loss: 0.4291\n",
      "Optimization Iteration:  49793, Training Accuracy:  65.6%, Loss: 0.4336\n",
      "Optimization Iteration:  49857, Training Accuracy:  70.3%, Loss: 0.4254\n",
      "Optimization Iteration:  49921, Training Accuracy:  73.4%, Loss: 0.4959\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 15\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  71.9%, Loss: 0.4805\n",
      "Optimization Iteration:    129, Training Accuracy:  71.9%, Loss: 0.5110\n",
      "Optimization Iteration:    193, Training Accuracy:  82.8%, Loss: 0.3754\n",
      "Optimization Iteration:    257, Training Accuracy:  82.8%, Loss: 0.3355\n",
      "Optimization Iteration:    321, Training Accuracy:  79.7%, Loss: 0.3411\n",
      "Optimization Iteration:    385, Training Accuracy:  82.8%, Loss: 0.3233\n",
      "Optimization Iteration:    449, Training Accuracy:  87.5%, Loss: 0.3010\n",
      "Optimization Iteration:    513, Training Accuracy:  71.9%, Loss: 0.4335\n",
      "Optimization Iteration:    577, Training Accuracy:  65.6%, Loss: 0.5057\n",
      "Optimization Iteration:    641, Training Accuracy:  75.0%, Loss: 0.4243\n",
      "Optimization Iteration:    705, Training Accuracy:  75.0%, Loss: 0.4376\n",
      "Optimization Iteration:    769, Training Accuracy:  75.0%, Loss: 0.4190\n",
      "Optimization Iteration:    833, Training Accuracy:  82.8%, Loss: 0.3749\n",
      "Optimization Iteration:    897, Training Accuracy:  73.4%, Loss: 0.3131\n",
      "Optimization Iteration:    961, Training Accuracy:  82.8%, Loss: 0.3024\n",
      "Optimization Iteration:   1025, Training Accuracy:  65.6%, Loss: 0.4855\n",
      "Optimization Iteration:   1089, Training Accuracy:  71.9%, Loss: 0.4203\n",
      "Optimization Iteration:   1153, Training Accuracy:  79.7%, Loss: 0.3582\n",
      "Optimization Iteration:   1217, Training Accuracy:  76.6%, Loss: 0.3934\n",
      "Optimization Iteration:   1281, Training Accuracy:  78.1%, Loss: 0.4648\n",
      "Optimization Iteration:   1345, Training Accuracy:  70.3%, Loss: 0.3936\n",
      "Optimization Iteration:   1409, Training Accuracy:  76.6%, Loss: 0.4424\n",
      "Optimization Iteration:   1473, Training Accuracy:  71.9%, Loss: 0.4329\n",
      "Optimization Iteration:   1537, Training Accuracy:  84.4%, Loss: 0.3466\n",
      "Optimization Iteration:   1601, Training Accuracy:  82.8%, Loss: 0.3435\n",
      "Optimization Iteration:   1665, Training Accuracy:  81.2%, Loss: 0.3290\n",
      "Optimization Iteration:   1729, Training Accuracy:  76.6%, Loss: 0.3779\n",
      "Optimization Iteration:   1793, Training Accuracy:  70.3%, Loss: 0.4607\n",
      "Optimization Iteration:   1857, Training Accuracy:  76.6%, Loss: 0.4076\n",
      "Optimization Iteration:   1921, Training Accuracy:  71.9%, Loss: 0.4845\n",
      "Optimization Iteration:   1985, Training Accuracy:  71.9%, Loss: 0.4201\n",
      "Optimization Iteration:   2049, Training Accuracy:  84.4%, Loss: 0.3561\n",
      "Optimization Iteration:   2113, Training Accuracy:  81.2%, Loss: 0.3695\n",
      "Optimization Iteration:   2177, Training Accuracy:  81.2%, Loss: 0.3688\n",
      "Optimization Iteration:   2241, Training Accuracy:  78.1%, Loss: 0.3696\n",
      "Optimization Iteration:   2305, Training Accuracy:  79.7%, Loss: 0.3652\n",
      "Optimization Iteration:   2369, Training Accuracy:  78.1%, Loss: 0.3895\n",
      "Optimization Iteration:   2433, Training Accuracy:  76.6%, Loss: 0.3834\n",
      "Optimization Iteration:   2497, Training Accuracy:  75.0%, Loss: 0.3896\n",
      "Optimization Iteration:   2561, Training Accuracy:  73.4%, Loss: 0.4277\n",
      "Optimization Iteration:   2625, Training Accuracy:  75.0%, Loss: 0.4709\n",
      "Optimization Iteration:   2689, Training Accuracy:  76.6%, Loss: 0.3892\n",
      "Optimization Iteration:   2753, Training Accuracy:  70.3%, Loss: 0.4078\n",
      "Optimization Iteration:   2817, Training Accuracy:  81.2%, Loss: 0.3613\n",
      "Optimization Iteration:   2881, Training Accuracy:  79.7%, Loss: 0.4022\n",
      "Optimization Iteration:   2945, Training Accuracy:  76.6%, Loss: 0.5895\n",
      "Optimization Iteration:   3009, Training Accuracy:  73.4%, Loss: 0.4187\n",
      "Optimization Iteration:   3073, Training Accuracy:  75.0%, Loss: 0.4059\n",
      "Optimization Iteration:   3137, Training Accuracy:  79.7%, Loss: 0.3798\n",
      "Optimization Iteration:   3201, Training Accuracy:  82.8%, Loss: 0.3499\n",
      "Optimization Iteration:   3265, Training Accuracy:  76.6%, Loss: 0.3794\n",
      "Optimization Iteration:   3329, Training Accuracy:  89.1%, Loss: 0.3213\n",
      "Optimization Iteration:   3393, Training Accuracy:  71.9%, Loss: 0.3993\n",
      "Optimization Iteration:   3457, Training Accuracy:  76.6%, Loss: 0.4603\n",
      "Optimization Iteration:   3521, Training Accuracy:  87.5%, Loss: 0.3094\n",
      "Optimization Iteration:   3585, Training Accuracy:  75.0%, Loss: 0.4625\n",
      "Optimization Iteration:   3649, Training Accuracy:  71.9%, Loss: 0.5419\n",
      "Optimization Iteration:   3713, Training Accuracy:  68.8%, Loss: 0.4638\n",
      "Optimization Iteration:   3777, Training Accuracy:  64.1%, Loss: 0.4750\n",
      "Optimization Iteration:   3841, Training Accuracy:  67.2%, Loss: 0.4450\n",
      "Optimization Iteration:   3905, Training Accuracy:  85.9%, Loss: 0.3693\n",
      "Optimization Iteration:   3969, Training Accuracy:  73.4%, Loss: 0.4348\n",
      "Optimization Iteration:   4033, Training Accuracy:  81.2%, Loss: 0.3003\n",
      "Optimization Iteration:   4097, Training Accuracy:  76.6%, Loss: 0.3691\n",
      "Optimization Iteration:   4161, Training Accuracy:  68.8%, Loss: 0.4649\n",
      "Optimization Iteration:   4225, Training Accuracy:  79.7%, Loss: 0.3929\n",
      "Optimization Iteration:   4289, Training Accuracy:  75.0%, Loss: 0.3758\n",
      "Optimization Iteration:   4353, Training Accuracy:  84.4%, Loss: 0.3707\n",
      "Optimization Iteration:   4417, Training Accuracy:  75.0%, Loss: 0.4098\n",
      "Optimization Iteration:   4481, Training Accuracy:  68.8%, Loss: 0.4371\n",
      "Optimization Iteration:   4545, Training Accuracy:  73.4%, Loss: 0.3770\n",
      "Optimization Iteration:   4609, Training Accuracy:  76.6%, Loss: 0.3476\n",
      "Optimization Iteration:   4673, Training Accuracy:  79.7%, Loss: 0.4338\n",
      "Optimization Iteration:   4737, Training Accuracy:  79.7%, Loss: 0.3700\n",
      "Optimization Iteration:   4801, Training Accuracy:  70.3%, Loss: 0.4572\n",
      "Optimization Iteration:   4865, Training Accuracy:  68.8%, Loss: 0.4585\n",
      "Optimization Iteration:   4929, Training Accuracy:  79.7%, Loss: 0.4004\n",
      "Optimization Iteration:   4993, Training Accuracy:  75.0%, Loss: 0.3837\n",
      "Optimization Iteration:   5057, Training Accuracy:  75.0%, Loss: 0.3968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   5121, Training Accuracy:  79.7%, Loss: 0.3638\n",
      "Optimization Iteration:   5185, Training Accuracy:  71.9%, Loss: 0.3895\n",
      "Optimization Iteration:   5249, Training Accuracy:  67.2%, Loss: 0.4356\n",
      "Optimization Iteration:   5313, Training Accuracy:  78.1%, Loss: 0.3825\n",
      "Optimization Iteration:   5377, Training Accuracy:  78.1%, Loss: 0.3469\n",
      "Optimization Iteration:   5441, Training Accuracy:  73.4%, Loss: 0.3748\n",
      "Optimization Iteration:   5505, Training Accuracy:  79.7%, Loss: 0.3605\n",
      "Optimization Iteration:   5569, Training Accuracy:  79.7%, Loss: 0.3205\n",
      "Optimization Iteration:   5633, Training Accuracy:  79.7%, Loss: 0.3399\n",
      "Optimization Iteration:   5697, Training Accuracy:  67.2%, Loss: 0.4323\n",
      "Optimization Iteration:   5761, Training Accuracy:  82.8%, Loss: 0.3011\n",
      "Optimization Iteration:   5825, Training Accuracy:  78.1%, Loss: 0.4231\n",
      "Optimization Iteration:   5889, Training Accuracy:  76.6%, Loss: 0.4049\n",
      "Optimization Iteration:   5953, Training Accuracy:  65.6%, Loss: 0.4190\n",
      "Optimization Iteration:   6017, Training Accuracy:  53.1%, Loss: 0.5679\n",
      "Optimization Iteration:   6081, Training Accuracy:  75.0%, Loss: 0.4420\n",
      "Optimization Iteration:   6145, Training Accuracy:  76.6%, Loss: 0.4324\n",
      "Optimization Iteration:   6209, Training Accuracy:  78.1%, Loss: 0.3476\n",
      "Optimization Iteration:   6273, Training Accuracy:  81.2%, Loss: 0.4137\n",
      "Optimization Iteration:   6337, Training Accuracy:  67.2%, Loss: 0.4991\n",
      "Optimization Iteration:   6401, Training Accuracy:  81.2%, Loss: 0.3739\n",
      "Optimization Iteration:   6465, Training Accuracy:  85.9%, Loss: 0.3104\n",
      "Optimization Iteration:   6529, Training Accuracy:  76.6%, Loss: 0.4340\n",
      "Optimization Iteration:   6593, Training Accuracy:  73.4%, Loss: 0.4221\n",
      "Optimization Iteration:   6657, Training Accuracy:  78.1%, Loss: 0.3942\n",
      "Optimization Iteration:   6721, Training Accuracy:  73.4%, Loss: 0.4008\n",
      "Optimization Iteration:   6785, Training Accuracy:  67.2%, Loss: 0.4278\n",
      "Optimization Iteration:   6849, Training Accuracy:  71.9%, Loss: 0.3952\n",
      "Optimization Iteration:   6913, Training Accuracy:  82.8%, Loss: 0.3189\n",
      "Optimization Iteration:   6977, Training Accuracy:  70.3%, Loss: 0.4344\n",
      "Optimization Iteration:   7041, Training Accuracy:  82.8%, Loss: 0.3632\n",
      "Optimization Iteration:   7105, Training Accuracy:  78.1%, Loss: 0.3526\n",
      "Optimization Iteration:   7169, Training Accuracy:  78.1%, Loss: 0.3851\n",
      "Optimization Iteration:   7233, Training Accuracy:  71.9%, Loss: 0.4630\n",
      "Optimization Iteration:   7297, Training Accuracy:  73.4%, Loss: 0.4714\n",
      "Optimization Iteration:   7361, Training Accuracy:  76.6%, Loss: 0.3838\n",
      "Optimization Iteration:   7425, Training Accuracy:  71.9%, Loss: 0.4858\n",
      "Optimization Iteration:   7489, Training Accuracy:  78.1%, Loss: 0.4009\n",
      "Optimization Iteration:   7553, Training Accuracy:  71.9%, Loss: 0.4135\n",
      "Optimization Iteration:   7617, Training Accuracy:  75.0%, Loss: 0.4491\n",
      "Optimization Iteration:   7681, Training Accuracy:  75.0%, Loss: 0.4494\n",
      "Optimization Iteration:   7745, Training Accuracy:  73.4%, Loss: 0.3495\n",
      "Optimization Iteration:   7809, Training Accuracy:  75.0%, Loss: 0.4288\n",
      "Optimization Iteration:   7873, Training Accuracy:  78.1%, Loss: 0.3666\n",
      "Optimization Iteration:   7937, Training Accuracy:  84.4%, Loss: 0.3775\n",
      "Optimization Iteration:   8001, Training Accuracy:  73.4%, Loss: 0.3885\n",
      "Optimization Iteration:   8065, Training Accuracy:  67.2%, Loss: 0.4247\n",
      "Optimization Iteration:   8129, Training Accuracy:  65.6%, Loss: 0.5118\n",
      "Optimization Iteration:   8193, Training Accuracy:  65.6%, Loss: 0.4573\n",
      "Optimization Iteration:   8257, Training Accuracy:  73.4%, Loss: 0.4331\n",
      "Optimization Iteration:   8321, Training Accuracy:  71.9%, Loss: 0.4516\n",
      "Optimization Iteration:   8385, Training Accuracy:  71.9%, Loss: 0.4196\n",
      "Optimization Iteration:   8449, Training Accuracy:  81.2%, Loss: 0.4182\n",
      "Optimization Iteration:   8513, Training Accuracy:  87.5%, Loss: 0.3408\n",
      "Optimization Iteration:   8577, Training Accuracy:  79.7%, Loss: 0.4446\n",
      "Optimization Iteration:   8641, Training Accuracy:  82.8%, Loss: 0.3533\n",
      "Optimization Iteration:   8705, Training Accuracy:  76.6%, Loss: 0.3492\n",
      "Optimization Iteration:   8769, Training Accuracy:  75.0%, Loss: 0.3741\n",
      "Optimization Iteration:   8833, Training Accuracy:  67.2%, Loss: 0.4760\n",
      "Optimization Iteration:   8897, Training Accuracy:  84.4%, Loss: 0.3573\n",
      "Optimization Iteration:   8961, Training Accuracy:  71.9%, Loss: 0.4338\n",
      "Optimization Iteration:   9025, Training Accuracy:  71.9%, Loss: 0.4953\n",
      "Optimization Iteration:   9089, Training Accuracy:  60.9%, Loss: 0.5092\n",
      "Optimization Iteration:   9153, Training Accuracy:  75.0%, Loss: 0.3966\n",
      "Optimization Iteration:   9217, Training Accuracy:  78.1%, Loss: 0.4604\n",
      "Optimization Iteration:   9281, Training Accuracy:  71.9%, Loss: 0.4773\n",
      "Optimization Iteration:   9345, Training Accuracy:  81.2%, Loss: 0.4120\n",
      "Optimization Iteration:   9409, Training Accuracy:  85.9%, Loss: 0.4161\n",
      "Optimization Iteration:   9473, Training Accuracy:  78.1%, Loss: 0.3910\n",
      "Optimization Iteration:   9537, Training Accuracy:  81.2%, Loss: 0.3516\n",
      "Optimization Iteration:   9601, Training Accuracy:  75.0%, Loss: 0.4071\n",
      "Optimization Iteration:   9665, Training Accuracy:  59.4%, Loss: 0.5222\n",
      "Optimization Iteration:   9729, Training Accuracy:  62.5%, Loss: 0.4506\n",
      "Optimization Iteration:   9793, Training Accuracy:  76.6%, Loss: 0.3418\n",
      "Optimization Iteration:   9857, Training Accuracy:  65.6%, Loss: 0.4453\n",
      "Optimization Iteration:   9921, Training Accuracy:  67.2%, Loss: 0.4214\n",
      "Optimization Iteration:   9985, Training Accuracy:  75.0%, Loss: 0.4194\n",
      "Optimization Iteration:  10049, Training Accuracy:  73.4%, Loss: 0.4539\n",
      "Optimization Iteration:  10113, Training Accuracy:  75.0%, Loss: 0.3875\n",
      "Optimization Iteration:  10177, Training Accuracy:  70.3%, Loss: 0.4733\n",
      "Optimization Iteration:  10241, Training Accuracy:  81.2%, Loss: 0.4438\n",
      "Optimization Iteration:  10305, Training Accuracy:  82.8%, Loss: 0.3865\n",
      "Optimization Iteration:  10369, Training Accuracy:  71.9%, Loss: 0.4477\n",
      "Optimization Iteration:  10433, Training Accuracy:  68.8%, Loss: 0.4346\n",
      "Optimization Iteration:  10497, Training Accuracy:  75.0%, Loss: 0.4436\n",
      "Optimization Iteration:  10561, Training Accuracy:  73.4%, Loss: 0.3605\n",
      "Optimization Iteration:  10625, Training Accuracy:  68.8%, Loss: 0.4350\n",
      "Optimization Iteration:  10689, Training Accuracy:  73.4%, Loss: 0.3807\n",
      "Optimization Iteration:  10753, Training Accuracy:  78.1%, Loss: 0.4275\n",
      "Optimization Iteration:  10817, Training Accuracy:  71.9%, Loss: 0.4770\n",
      "Optimization Iteration:  10881, Training Accuracy:  82.8%, Loss: 0.3351\n",
      "Optimization Iteration:  10945, Training Accuracy:  75.0%, Loss: 0.4677\n",
      "Optimization Iteration:  11009, Training Accuracy:  76.6%, Loss: 0.3765\n",
      "Optimization Iteration:  11073, Training Accuracy:  76.6%, Loss: 0.3644\n",
      "Optimization Iteration:  11137, Training Accuracy:  75.0%, Loss: 0.4610\n",
      "Optimization Iteration:  11201, Training Accuracy:  84.4%, Loss: 0.2915\n",
      "Optimization Iteration:  11265, Training Accuracy:  90.6%, Loss: 0.2986\n",
      "Optimization Iteration:  11329, Training Accuracy:  78.1%, Loss: 0.4289\n",
      "Optimization Iteration:  11393, Training Accuracy:  65.6%, Loss: 0.4382\n",
      "Optimization Iteration:  11457, Training Accuracy:  73.4%, Loss: 0.4047\n",
      "Optimization Iteration:  11521, Training Accuracy:  68.8%, Loss: 0.4428\n",
      "Optimization Iteration:  11585, Training Accuracy:  79.7%, Loss: 0.3668\n",
      "Optimization Iteration:  11649, Training Accuracy:  76.6%, Loss: 0.4440\n",
      "Optimization Iteration:  11713, Training Accuracy:  75.0%, Loss: 0.4307\n",
      "Optimization Iteration:  11777, Training Accuracy:  68.8%, Loss: 0.4780\n",
      "Optimization Iteration:  11841, Training Accuracy:  76.6%, Loss: 0.4188\n",
      "Optimization Iteration:  11905, Training Accuracy:  76.6%, Loss: 0.3669\n",
      "Optimization Iteration:  11969, Training Accuracy:  87.5%, Loss: 0.3765\n",
      "Optimization Iteration:  12033, Training Accuracy:  78.1%, Loss: 0.3744\n",
      "Optimization Iteration:  12097, Training Accuracy:  81.2%, Loss: 0.3690\n",
      "Optimization Iteration:  12161, Training Accuracy:  68.8%, Loss: 0.5071\n",
      "Optimization Iteration:  12225, Training Accuracy:  73.4%, Loss: 0.4150\n",
      "Optimization Iteration:  12289, Training Accuracy:  82.8%, Loss: 0.3479\n",
      "Optimization Iteration:  12353, Training Accuracy:  78.1%, Loss: 0.3671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  12417, Training Accuracy:  82.8%, Loss: 0.3476\n",
      "Optimization Iteration:  12481, Training Accuracy:  75.0%, Loss: 0.3240\n",
      "Optimization Iteration:  12545, Training Accuracy:  71.9%, Loss: 0.4017\n",
      "Optimization Iteration:  12609, Training Accuracy:  79.7%, Loss: 0.3945\n",
      "Optimization Iteration:  12673, Training Accuracy:  78.1%, Loss: 0.3573\n",
      "Optimization Iteration:  12737, Training Accuracy:  62.5%, Loss: 0.5557\n",
      "Optimization Iteration:  12801, Training Accuracy:  76.6%, Loss: 0.4219\n",
      "Optimization Iteration:  12865, Training Accuracy:  70.3%, Loss: 0.4496\n",
      "Optimization Iteration:  12929, Training Accuracy:  65.6%, Loss: 0.4341\n",
      "Optimization Iteration:  12993, Training Accuracy:  76.6%, Loss: 0.3594\n",
      "Optimization Iteration:  13057, Training Accuracy:  71.9%, Loss: 0.4804\n",
      "Optimization Iteration:  13121, Training Accuracy:  84.4%, Loss: 0.3562\n",
      "Optimization Iteration:  13185, Training Accuracy:  71.9%, Loss: 0.4495\n",
      "Optimization Iteration:  13249, Training Accuracy:  70.3%, Loss: 0.4839\n",
      "Optimization Iteration:  13313, Training Accuracy:  71.9%, Loss: 0.4937\n",
      "Optimization Iteration:  13377, Training Accuracy:  68.8%, Loss: 0.4583\n",
      "Optimization Iteration:  13441, Training Accuracy:  82.8%, Loss: 0.3315\n",
      "Optimization Iteration:  13505, Training Accuracy:  76.6%, Loss: 0.3604\n",
      "Optimization Iteration:  13569, Training Accuracy:  82.8%, Loss: 0.3722\n",
      "Optimization Iteration:  13633, Training Accuracy:  70.3%, Loss: 0.4300\n",
      "Optimization Iteration:  13697, Training Accuracy:  75.0%, Loss: 0.3773\n",
      "Optimization Iteration:  13761, Training Accuracy:  85.9%, Loss: 0.3106\n",
      "Optimization Iteration:  13825, Training Accuracy:  84.4%, Loss: 0.5178\n",
      "Optimization Iteration:  13889, Training Accuracy:  62.5%, Loss: 0.4777\n",
      "Optimization Iteration:  13953, Training Accuracy:  78.1%, Loss: 0.4148\n",
      "Optimization Iteration:  14017, Training Accuracy:  82.8%, Loss: 0.3340\n",
      "Optimization Iteration:  14081, Training Accuracy:  68.8%, Loss: 0.4353\n",
      "Optimization Iteration:  14145, Training Accuracy:  73.4%, Loss: 0.4222\n",
      "Optimization Iteration:  14209, Training Accuracy:  71.9%, Loss: 0.4625\n",
      "Optimization Iteration:  14273, Training Accuracy:  71.9%, Loss: 0.4431\n",
      "Optimization Iteration:  14337, Training Accuracy:  85.9%, Loss: 0.2534\n",
      "Optimization Iteration:  14401, Training Accuracy:  73.4%, Loss: 0.3940\n",
      "Optimization Iteration:  14465, Training Accuracy:  64.1%, Loss: 0.4939\n",
      "Optimization Iteration:  14529, Training Accuracy:  84.4%, Loss: 0.3876\n",
      "Optimization Iteration:  14593, Training Accuracy:  81.2%, Loss: 0.3641\n",
      "Optimization Iteration:  14657, Training Accuracy:  79.7%, Loss: 0.4275\n",
      "Optimization Iteration:  14721, Training Accuracy:  68.8%, Loss: 0.4028\n",
      "Optimization Iteration:  14785, Training Accuracy:  76.6%, Loss: 0.3660\n",
      "Optimization Iteration:  14849, Training Accuracy:  73.4%, Loss: 0.4406\n",
      "Optimization Iteration:  14913, Training Accuracy:  79.7%, Loss: 0.3238\n",
      "Optimization Iteration:  14977, Training Accuracy:  79.7%, Loss: 0.4034\n",
      "Optimization Iteration:  15041, Training Accuracy:  75.0%, Loss: 0.3303\n",
      "Optimization Iteration:  15105, Training Accuracy:  73.4%, Loss: 0.4121\n",
      "Optimization Iteration:  15169, Training Accuracy:  79.7%, Loss: 0.3580\n",
      "Optimization Iteration:  15233, Training Accuracy:  75.0%, Loss: 0.3966\n",
      "Optimization Iteration:  15297, Training Accuracy:  81.2%, Loss: 0.4192\n",
      "Optimization Iteration:  15361, Training Accuracy:  82.8%, Loss: 0.3265\n",
      "Optimization Iteration:  15425, Training Accuracy:  68.8%, Loss: 0.3884\n",
      "Optimization Iteration:  15489, Training Accuracy:  65.6%, Loss: 0.4500\n",
      "Optimization Iteration:  15553, Training Accuracy:  73.4%, Loss: 0.4151\n",
      "Optimization Iteration:  15617, Training Accuracy:  75.0%, Loss: 0.4281\n",
      "Optimization Iteration:  15681, Training Accuracy:  73.4%, Loss: 0.3463\n",
      "Optimization Iteration:  15745, Training Accuracy:  82.8%, Loss: 0.3426\n",
      "Optimization Iteration:  15809, Training Accuracy:  76.6%, Loss: 0.4216\n",
      "Optimization Iteration:  15873, Training Accuracy:  76.6%, Loss: 0.4293\n",
      "Optimization Iteration:  15937, Training Accuracy:  82.8%, Loss: 0.3571\n",
      "Optimization Iteration:  16001, Training Accuracy:  75.0%, Loss: 0.4620\n",
      "Optimization Iteration:  16065, Training Accuracy:  73.4%, Loss: 0.3869\n",
      "Optimization Iteration:  16129, Training Accuracy:  76.6%, Loss: 0.3644\n",
      "Optimization Iteration:  16193, Training Accuracy:  76.6%, Loss: 0.3907\n",
      "Optimization Iteration:  16257, Training Accuracy:  81.2%, Loss: 0.4087\n",
      "Optimization Iteration:  16321, Training Accuracy:  71.9%, Loss: 0.5013\n",
      "Optimization Iteration:  16385, Training Accuracy:  73.4%, Loss: 0.3823\n",
      "Optimization Iteration:  16449, Training Accuracy:  76.6%, Loss: 0.3980\n",
      "Optimization Iteration:  16513, Training Accuracy:  76.6%, Loss: 0.3984\n",
      "Optimization Iteration:  16577, Training Accuracy:  78.1%, Loss: 0.3706\n",
      "Optimization Iteration:  16641, Training Accuracy:  75.0%, Loss: 0.3957\n",
      "Optimization Iteration:  16705, Training Accuracy:  78.1%, Loss: 0.3538\n",
      "Optimization Iteration:  16769, Training Accuracy:  79.7%, Loss: 0.3833\n",
      "Optimization Iteration:  16833, Training Accuracy:  76.6%, Loss: 0.3781\n",
      "Optimization Iteration:  16897, Training Accuracy:  78.1%, Loss: 0.3852\n",
      "Optimization Iteration:  16961, Training Accuracy:  75.0%, Loss: 0.4233\n",
      "Optimization Iteration:  17025, Training Accuracy:  79.7%, Loss: 0.4120\n",
      "Optimization Iteration:  17089, Training Accuracy:  81.2%, Loss: 0.3840\n",
      "Optimization Iteration:  17153, Training Accuracy:  76.6%, Loss: 0.4526\n",
      "Optimization Iteration:  17217, Training Accuracy:  71.9%, Loss: 0.4812\n",
      "Optimization Iteration:  17281, Training Accuracy:  71.9%, Loss: 0.4630\n",
      "Optimization Iteration:  17345, Training Accuracy:  75.0%, Loss: 0.3884\n",
      "Optimization Iteration:  17409, Training Accuracy:  76.6%, Loss: 0.3587\n",
      "Optimization Iteration:  17473, Training Accuracy:  65.6%, Loss: 0.6558\n",
      "Optimization Iteration:  17537, Training Accuracy:  71.9%, Loss: 0.4161\n",
      "Optimization Iteration:  17601, Training Accuracy:  76.6%, Loss: 0.4356\n",
      "Optimization Iteration:  17665, Training Accuracy:  73.4%, Loss: 0.4165\n",
      "Optimization Iteration:  17729, Training Accuracy:  75.0%, Loss: 0.3628\n",
      "Optimization Iteration:  17793, Training Accuracy:  78.1%, Loss: 0.4065\n",
      "Optimization Iteration:  17857, Training Accuracy:  67.2%, Loss: 0.5039\n",
      "Optimization Iteration:  17921, Training Accuracy:  82.8%, Loss: 0.3405\n",
      "Optimization Iteration:  17985, Training Accuracy:  71.9%, Loss: 0.3561\n",
      "Optimization Iteration:  18049, Training Accuracy:  78.1%, Loss: 0.4006\n",
      "Optimization Iteration:  18113, Training Accuracy:  73.4%, Loss: 0.4704\n",
      "Optimization Iteration:  18177, Training Accuracy:  75.0%, Loss: 0.4903\n",
      "Optimization Iteration:  18241, Training Accuracy:  76.6%, Loss: 0.4125\n",
      "Optimization Iteration:  18305, Training Accuracy:  73.4%, Loss: 0.4585\n",
      "Optimization Iteration:  18369, Training Accuracy:  75.0%, Loss: 0.3563\n",
      "Optimization Iteration:  18433, Training Accuracy:  68.8%, Loss: 0.4348\n",
      "Optimization Iteration:  18497, Training Accuracy:  79.7%, Loss: 0.3391\n",
      "Optimization Iteration:  18561, Training Accuracy:  76.6%, Loss: 0.3958\n",
      "Optimization Iteration:  18625, Training Accuracy:  67.2%, Loss: 0.4386\n",
      "Optimization Iteration:  18689, Training Accuracy:  67.2%, Loss: 0.4655\n",
      "Optimization Iteration:  18753, Training Accuracy:  81.2%, Loss: 0.3611\n",
      "Optimization Iteration:  18817, Training Accuracy:  75.0%, Loss: 0.3460\n",
      "Optimization Iteration:  18881, Training Accuracy:  71.9%, Loss: 0.3887\n",
      "Optimization Iteration:  18945, Training Accuracy:  71.9%, Loss: 0.4281\n",
      "Optimization Iteration:  19009, Training Accuracy:  70.3%, Loss: 0.4354\n",
      "Optimization Iteration:  19073, Training Accuracy:  76.6%, Loss: 0.4199\n",
      "Optimization Iteration:  19137, Training Accuracy:  68.8%, Loss: 0.4773\n",
      "Optimization Iteration:  19201, Training Accuracy:  75.0%, Loss: 0.3940\n",
      "Optimization Iteration:  19265, Training Accuracy:  62.5%, Loss: 0.4757\n",
      "Optimization Iteration:  19329, Training Accuracy:  85.9%, Loss: 0.3121\n",
      "Optimization Iteration:  19393, Training Accuracy:  71.9%, Loss: 0.4517\n",
      "Optimization Iteration:  19457, Training Accuracy:  67.2%, Loss: 0.4413\n",
      "Optimization Iteration:  19521, Training Accuracy:  76.6%, Loss: 0.3725\n",
      "Optimization Iteration:  19585, Training Accuracy:  73.4%, Loss: 0.4351\n",
      "Optimization Iteration:  19649, Training Accuracy:  81.2%, Loss: 0.3911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  19713, Training Accuracy:  76.6%, Loss: 0.3269\n",
      "Optimization Iteration:  19777, Training Accuracy:  79.7%, Loss: 0.4069\n",
      "Optimization Iteration:  19841, Training Accuracy:  68.8%, Loss: 0.4562\n",
      "Optimization Iteration:  19905, Training Accuracy:  64.1%, Loss: 0.5171\n",
      "Optimization Iteration:  19969, Training Accuracy:  73.4%, Loss: 0.4610\n",
      "Optimization Iteration:  20033, Training Accuracy:  81.2%, Loss: 0.3422\n",
      "Optimization Iteration:  20097, Training Accuracy:  67.2%, Loss: 0.5000\n",
      "Optimization Iteration:  20161, Training Accuracy:  67.2%, Loss: 0.4237\n",
      "Optimization Iteration:  20225, Training Accuracy:  65.6%, Loss: 0.4854\n",
      "Optimization Iteration:  20289, Training Accuracy:  73.4%, Loss: 0.4172\n",
      "Optimization Iteration:  20353, Training Accuracy:  78.1%, Loss: 0.3800\n",
      "Optimization Iteration:  20417, Training Accuracy:  70.3%, Loss: 0.4711\n",
      "Optimization Iteration:  20481, Training Accuracy:  75.0%, Loss: 0.3792\n",
      "Optimization Iteration:  20545, Training Accuracy:  73.4%, Loss: 0.4192\n",
      "Optimization Iteration:  20609, Training Accuracy:  70.3%, Loss: 0.4020\n",
      "Optimization Iteration:  20673, Training Accuracy:  73.4%, Loss: 0.4277\n",
      "Optimization Iteration:  20737, Training Accuracy:  85.9%, Loss: 0.3818\n",
      "Optimization Iteration:  20801, Training Accuracy:  78.1%, Loss: 0.4199\n",
      "Optimization Iteration:  20865, Training Accuracy:  75.0%, Loss: 0.4194\n",
      "Optimization Iteration:  20929, Training Accuracy:  85.9%, Loss: 0.3226\n",
      "Optimization Iteration:  20993, Training Accuracy:  76.6%, Loss: 0.4353\n",
      "Optimization Iteration:  21057, Training Accuracy:  73.4%, Loss: 0.4214\n",
      "Optimization Iteration:  21121, Training Accuracy:  65.6%, Loss: 0.4594\n",
      "Optimization Iteration:  21185, Training Accuracy:  84.4%, Loss: 0.4095\n",
      "Optimization Iteration:  21249, Training Accuracy:  64.1%, Loss: 0.5235\n",
      "Optimization Iteration:  21313, Training Accuracy:  81.2%, Loss: 0.4201\n",
      "Optimization Iteration:  21377, Training Accuracy:  82.8%, Loss: 0.3511\n",
      "Optimization Iteration:  21441, Training Accuracy:  68.8%, Loss: 0.4554\n",
      "Optimization Iteration:  21505, Training Accuracy:  78.1%, Loss: 0.4120\n",
      "Optimization Iteration:  21569, Training Accuracy:  81.2%, Loss: 0.3627\n",
      "Optimization Iteration:  21633, Training Accuracy:  79.7%, Loss: 0.3684\n",
      "Optimization Iteration:  21697, Training Accuracy:  70.3%, Loss: 0.4623\n",
      "Optimization Iteration:  21761, Training Accuracy:  82.8%, Loss: 0.3026\n",
      "Optimization Iteration:  21825, Training Accuracy:  70.3%, Loss: 0.4311\n",
      "Optimization Iteration:  21889, Training Accuracy:  78.1%, Loss: 0.4175\n",
      "Optimization Iteration:  21953, Training Accuracy:  71.9%, Loss: 0.5543\n",
      "Optimization Iteration:  22017, Training Accuracy:  78.1%, Loss: 0.4017\n",
      "Optimization Iteration:  22081, Training Accuracy:  82.8%, Loss: 0.3956\n",
      "Optimization Iteration:  22145, Training Accuracy:  79.7%, Loss: 0.3984\n",
      "Optimization Iteration:  22209, Training Accuracy:  75.0%, Loss: 0.4331\n",
      "Optimization Iteration:  22273, Training Accuracy:  71.9%, Loss: 0.4118\n",
      "Optimization Iteration:  22337, Training Accuracy:  67.2%, Loss: 0.4507\n",
      "Optimization Iteration:  22401, Training Accuracy:  76.6%, Loss: 0.4449\n",
      "Optimization Iteration:  22465, Training Accuracy:  73.4%, Loss: 0.4429\n",
      "Optimization Iteration:  22529, Training Accuracy:  71.9%, Loss: 0.3994\n",
      "Optimization Iteration:  22593, Training Accuracy:  75.0%, Loss: 0.4250\n",
      "Optimization Iteration:  22657, Training Accuracy:  76.6%, Loss: 0.4174\n",
      "Optimization Iteration:  22721, Training Accuracy:  70.3%, Loss: 0.4526\n",
      "Optimization Iteration:  22785, Training Accuracy:  84.4%, Loss: 0.4299\n",
      "Optimization Iteration:  22849, Training Accuracy:  62.5%, Loss: 0.5462\n",
      "Optimization Iteration:  22913, Training Accuracy:  76.6%, Loss: 0.3909\n",
      "Optimization Iteration:  22977, Training Accuracy:  79.7%, Loss: 0.3792\n",
      "Optimization Iteration:  23041, Training Accuracy:  76.6%, Loss: 0.3595\n",
      "Optimization Iteration:  23105, Training Accuracy:  62.5%, Loss: 0.4182\n",
      "Optimization Iteration:  23169, Training Accuracy:  82.8%, Loss: 0.3626\n",
      "Optimization Iteration:  23233, Training Accuracy:  71.9%, Loss: 0.4877\n",
      "Optimization Iteration:  23297, Training Accuracy:  70.3%, Loss: 0.5325\n",
      "Optimization Iteration:  23361, Training Accuracy:  65.6%, Loss: 0.4449\n",
      "Optimization Iteration:  23425, Training Accuracy:  78.1%, Loss: 0.4818\n",
      "Optimization Iteration:  23489, Training Accuracy:  73.4%, Loss: 0.4387\n",
      "Optimization Iteration:  23553, Training Accuracy:  76.6%, Loss: 0.3359\n",
      "Optimization Iteration:  23617, Training Accuracy:  78.1%, Loss: 0.4226\n",
      "Optimization Iteration:  23681, Training Accuracy:  68.8%, Loss: 0.5045\n",
      "Optimization Iteration:  23745, Training Accuracy:  75.0%, Loss: 0.4045\n",
      "Optimization Iteration:  23809, Training Accuracy:  79.7%, Loss: 0.4223\n",
      "Optimization Iteration:  23873, Training Accuracy:  68.8%, Loss: 0.3723\n",
      "Optimization Iteration:  23937, Training Accuracy:  65.6%, Loss: 0.4634\n",
      "Optimization Iteration:  24001, Training Accuracy:  79.7%, Loss: 0.3909\n",
      "Optimization Iteration:  24065, Training Accuracy:  76.6%, Loss: 0.3921\n",
      "Optimization Iteration:  24129, Training Accuracy:  78.1%, Loss: 0.3691\n",
      "Optimization Iteration:  24193, Training Accuracy:  68.8%, Loss: 0.4640\n",
      "Optimization Iteration:  24257, Training Accuracy:  75.0%, Loss: 0.3744\n",
      "Optimization Iteration:  24321, Training Accuracy:  67.2%, Loss: 0.4830\n",
      "Optimization Iteration:  24385, Training Accuracy:  76.6%, Loss: 0.4297\n",
      "Optimization Iteration:  24449, Training Accuracy:  71.9%, Loss: 0.3445\n",
      "Optimization Iteration:  24513, Training Accuracy:  81.2%, Loss: 0.3961\n",
      "Optimization Iteration:  24577, Training Accuracy:  73.4%, Loss: 0.4542\n",
      "Optimization Iteration:  24641, Training Accuracy:  79.7%, Loss: 0.4562\n",
      "Optimization Iteration:  24705, Training Accuracy:  85.9%, Loss: 0.3387\n",
      "Optimization Iteration:  24769, Training Accuracy:  76.6%, Loss: 0.3756\n",
      "Optimization Iteration:  24833, Training Accuracy:  82.8%, Loss: 0.3443\n",
      "Optimization Iteration:  24897, Training Accuracy:  68.8%, Loss: 0.4241\n",
      "Optimization Iteration:  24961, Training Accuracy:  84.4%, Loss: 0.2643\n",
      "Optimization Iteration:  25025, Training Accuracy:  75.0%, Loss: 0.3906\n",
      "Optimization Iteration:  25089, Training Accuracy:  75.0%, Loss: 0.3997\n",
      "Optimization Iteration:  25153, Training Accuracy:  71.9%, Loss: 0.3861\n",
      "Optimization Iteration:  25217, Training Accuracy:  64.1%, Loss: 0.4871\n",
      "Optimization Iteration:  25281, Training Accuracy:  78.1%, Loss: 0.3553\n",
      "Optimization Iteration:  25345, Training Accuracy:  70.3%, Loss: 0.4341\n",
      "Optimization Iteration:  25409, Training Accuracy:  75.0%, Loss: 0.4139\n",
      "Optimization Iteration:  25473, Training Accuracy:  73.4%, Loss: 0.4553\n",
      "Optimization Iteration:  25537, Training Accuracy:  70.3%, Loss: 0.4283\n",
      "Optimization Iteration:  25601, Training Accuracy:  64.1%, Loss: 0.5175\n",
      "Optimization Iteration:  25665, Training Accuracy:  73.4%, Loss: 0.4892\n",
      "Optimization Iteration:  25729, Training Accuracy:  76.6%, Loss: 0.3228\n",
      "Optimization Iteration:  25793, Training Accuracy:  71.9%, Loss: 0.3742\n",
      "Optimization Iteration:  25857, Training Accuracy:  70.3%, Loss: 0.4460\n",
      "Optimization Iteration:  25921, Training Accuracy:  78.1%, Loss: 0.3590\n",
      "Optimization Iteration:  25985, Training Accuracy:  68.8%, Loss: 0.5651\n",
      "Optimization Iteration:  26049, Training Accuracy:  79.7%, Loss: 0.3658\n",
      "Optimization Iteration:  26113, Training Accuracy:  78.1%, Loss: 0.3670\n",
      "Optimization Iteration:  26177, Training Accuracy:  76.6%, Loss: 0.4210\n",
      "Optimization Iteration:  26241, Training Accuracy:  73.4%, Loss: 0.4342\n",
      "Optimization Iteration:  26305, Training Accuracy:  76.6%, Loss: 0.4160\n",
      "Optimization Iteration:  26369, Training Accuracy:  78.1%, Loss: 0.3710\n",
      "Optimization Iteration:  26433, Training Accuracy:  64.1%, Loss: 0.4769\n",
      "Optimization Iteration:  26497, Training Accuracy:  81.2%, Loss: 0.3865\n",
      "Optimization Iteration:  26561, Training Accuracy:  75.0%, Loss: 0.3679\n",
      "Optimization Iteration:  26625, Training Accuracy:  73.4%, Loss: 0.4164\n",
      "Optimization Iteration:  26689, Training Accuracy:  79.7%, Loss: 0.4083\n",
      "Optimization Iteration:  26753, Training Accuracy:  73.4%, Loss: 0.4718\n",
      "Optimization Iteration:  26817, Training Accuracy:  67.2%, Loss: 0.4459\n",
      "Optimization Iteration:  26881, Training Accuracy:  79.7%, Loss: 0.3086\n",
      "Optimization Iteration:  26945, Training Accuracy:  68.8%, Loss: 0.3783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  27009, Training Accuracy:  75.0%, Loss: 0.4094\n",
      "Optimization Iteration:  27073, Training Accuracy:  82.8%, Loss: 0.3636\n",
      "Optimization Iteration:  27137, Training Accuracy:  76.6%, Loss: 0.3429\n",
      "Optimization Iteration:  27201, Training Accuracy:  71.9%, Loss: 0.3358\n",
      "Optimization Iteration:  27265, Training Accuracy:  81.2%, Loss: 0.3878\n",
      "Optimization Iteration:  27329, Training Accuracy:  73.4%, Loss: 0.3779\n",
      "Optimization Iteration:  27393, Training Accuracy:  78.1%, Loss: 0.3705\n",
      "Optimization Iteration:  27457, Training Accuracy:  71.9%, Loss: 0.3926\n",
      "Optimization Iteration:  27521, Training Accuracy:  78.1%, Loss: 0.4142\n",
      "Optimization Iteration:  27585, Training Accuracy:  79.7%, Loss: 0.4030\n",
      "Optimization Iteration:  27649, Training Accuracy:  75.0%, Loss: 0.3489\n",
      "Optimization Iteration:  27713, Training Accuracy:  75.0%, Loss: 0.4270\n",
      "Optimization Iteration:  27777, Training Accuracy:  79.7%, Loss: 0.3645\n",
      "Optimization Iteration:  27841, Training Accuracy:  73.4%, Loss: 0.3780\n",
      "Optimization Iteration:  27905, Training Accuracy:  75.0%, Loss: 0.3788\n",
      "Optimization Iteration:  27969, Training Accuracy:  64.1%, Loss: 0.5044\n",
      "Optimization Iteration:  28033, Training Accuracy:  82.8%, Loss: 0.3925\n",
      "Optimization Iteration:  28097, Training Accuracy:  82.8%, Loss: 0.3372\n",
      "Optimization Iteration:  28161, Training Accuracy:  90.6%, Loss: 0.3457\n",
      "Optimization Iteration:  28225, Training Accuracy:  76.6%, Loss: 0.3653\n",
      "Optimization Iteration:  28289, Training Accuracy:  73.4%, Loss: 0.4038\n",
      "Optimization Iteration:  28353, Training Accuracy:  76.6%, Loss: 0.4098\n",
      "Optimization Iteration:  28417, Training Accuracy:  73.4%, Loss: 0.4310\n",
      "Optimization Iteration:  28481, Training Accuracy:  75.0%, Loss: 0.3909\n",
      "Optimization Iteration:  28545, Training Accuracy:  78.1%, Loss: 0.3415\n",
      "Optimization Iteration:  28609, Training Accuracy:  79.7%, Loss: 0.3566\n",
      "Optimization Iteration:  28673, Training Accuracy:  81.2%, Loss: 0.4254\n",
      "Optimization Iteration:  28737, Training Accuracy:  67.2%, Loss: 0.4598\n",
      "Optimization Iteration:  28801, Training Accuracy:  84.4%, Loss: 0.3098\n",
      "Optimization Iteration:  28865, Training Accuracy:  85.9%, Loss: 0.2836\n",
      "Optimization Iteration:  28929, Training Accuracy:  82.8%, Loss: 0.3524\n",
      "Optimization Iteration:  28993, Training Accuracy:  79.7%, Loss: 0.3608\n",
      "Optimization Iteration:  29057, Training Accuracy:  75.0%, Loss: 0.4139\n",
      "Optimization Iteration:  29121, Training Accuracy:  71.9%, Loss: 0.4633\n",
      "Optimization Iteration:  29185, Training Accuracy:  70.3%, Loss: 0.4098\n",
      "Optimization Iteration:  29249, Training Accuracy:  78.1%, Loss: 0.3787\n",
      "Optimization Iteration:  29313, Training Accuracy:  73.4%, Loss: 0.4167\n",
      "Optimization Iteration:  29377, Training Accuracy:  78.1%, Loss: 0.3502\n",
      "Optimization Iteration:  29441, Training Accuracy:  73.4%, Loss: 0.4411\n",
      "Optimization Iteration:  29505, Training Accuracy:  76.6%, Loss: 0.4226\n",
      "Optimization Iteration:  29569, Training Accuracy:  73.4%, Loss: 0.4714\n",
      "Optimization Iteration:  29633, Training Accuracy:  64.1%, Loss: 0.4580\n",
      "Optimization Iteration:  29697, Training Accuracy:  71.9%, Loss: 0.3883\n",
      "Optimization Iteration:  29761, Training Accuracy:  84.4%, Loss: 0.4184\n",
      "Optimization Iteration:  29825, Training Accuracy:  75.0%, Loss: 0.4378\n",
      "Optimization Iteration:  29889, Training Accuracy:  71.9%, Loss: 0.4590\n",
      "Optimization Iteration:  29953, Training Accuracy:  68.8%, Loss: 0.4251\n",
      "Optimization Iteration:  30017, Training Accuracy:  79.7%, Loss: 0.3343\n",
      "Optimization Iteration:  30081, Training Accuracy:  79.7%, Loss: 0.3641\n",
      "Optimization Iteration:  30145, Training Accuracy:  75.0%, Loss: 0.4306\n",
      "Optimization Iteration:  30209, Training Accuracy:  70.3%, Loss: 0.4069\n",
      "Optimization Iteration:  30273, Training Accuracy:  73.4%, Loss: 0.3692\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.3364\n",
      "Optimization Iteration:  30401, Training Accuracy:  75.0%, Loss: 0.4388\n",
      "Optimization Iteration:  30465, Training Accuracy:  71.9%, Loss: 0.4538\n",
      "Optimization Iteration:  30529, Training Accuracy:  78.1%, Loss: 0.3688\n",
      "Optimization Iteration:  30593, Training Accuracy:  75.0%, Loss: 0.3815\n",
      "Optimization Iteration:  30657, Training Accuracy:  76.6%, Loss: 0.4324\n",
      "Optimization Iteration:  30721, Training Accuracy:  75.0%, Loss: 0.4099\n",
      "Optimization Iteration:  30785, Training Accuracy:  71.9%, Loss: 0.4039\n",
      "Optimization Iteration:  30849, Training Accuracy:  76.6%, Loss: 0.4408\n",
      "Optimization Iteration:  30913, Training Accuracy:  71.9%, Loss: 0.4081\n",
      "Optimization Iteration:  30977, Training Accuracy:  70.3%, Loss: 0.4314\n",
      "Optimization Iteration:  31041, Training Accuracy:  75.0%, Loss: 0.3809\n",
      "Optimization Iteration:  31105, Training Accuracy:  79.7%, Loss: 0.3865\n",
      "Optimization Iteration:  31169, Training Accuracy:  76.6%, Loss: 0.3817\n",
      "Optimization Iteration:  31233, Training Accuracy:  78.1%, Loss: 0.3954\n",
      "Optimization Iteration:  31297, Training Accuracy:  75.0%, Loss: 0.3777\n",
      "Optimization Iteration:  31361, Training Accuracy:  68.8%, Loss: 0.4401\n",
      "Optimization Iteration:  31425, Training Accuracy:  79.7%, Loss: 0.3344\n",
      "Optimization Iteration:  31489, Training Accuracy:  82.8%, Loss: 0.3727\n",
      "Optimization Iteration:  31553, Training Accuracy:  76.6%, Loss: 0.3679\n",
      "Optimization Iteration:  31617, Training Accuracy:  75.0%, Loss: 0.3636\n",
      "Optimization Iteration:  31681, Training Accuracy:  76.6%, Loss: 0.4023\n",
      "Optimization Iteration:  31745, Training Accuracy:  75.0%, Loss: 0.3665\n",
      "Optimization Iteration:  31809, Training Accuracy:  70.3%, Loss: 0.4947\n",
      "Optimization Iteration:  31873, Training Accuracy:  82.8%, Loss: 0.3111\n",
      "Optimization Iteration:  31937, Training Accuracy:  67.2%, Loss: 0.5395\n",
      "Optimization Iteration:  32001, Training Accuracy:  79.7%, Loss: 0.4031\n",
      "Optimization Iteration:  32065, Training Accuracy:  76.6%, Loss: 0.3992\n",
      "Optimization Iteration:  32129, Training Accuracy:  81.2%, Loss: 0.4203\n",
      "Optimization Iteration:  32193, Training Accuracy:  70.3%, Loss: 0.4784\n",
      "Optimization Iteration:  32257, Training Accuracy:  68.8%, Loss: 0.4221\n",
      "Optimization Iteration:  32321, Training Accuracy:  75.0%, Loss: 0.3670\n",
      "Optimization Iteration:  32385, Training Accuracy:  79.7%, Loss: 0.3860\n",
      "Optimization Iteration:  32449, Training Accuracy:  68.8%, Loss: 0.4586\n",
      "Optimization Iteration:  32513, Training Accuracy:  75.0%, Loss: 0.3646\n",
      "Optimization Iteration:  32577, Training Accuracy:  76.6%, Loss: 0.3983\n",
      "Optimization Iteration:  32641, Training Accuracy:  73.4%, Loss: 0.4761\n",
      "Optimization Iteration:  32705, Training Accuracy:  78.1%, Loss: 0.4225\n",
      "Optimization Iteration:  32769, Training Accuracy:  76.6%, Loss: 0.4695\n",
      "Optimization Iteration:  32833, Training Accuracy:  70.3%, Loss: 0.4548\n",
      "Optimization Iteration:  32897, Training Accuracy:  75.0%, Loss: 0.4453\n",
      "Optimization Iteration:  32961, Training Accuracy:  75.0%, Loss: 0.5197\n",
      "Optimization Iteration:  33025, Training Accuracy:  76.6%, Loss: 0.4422\n",
      "Optimization Iteration:  33089, Training Accuracy:  71.9%, Loss: 0.4442\n",
      "Optimization Iteration:  33153, Training Accuracy:  62.5%, Loss: 0.5345\n",
      "Optimization Iteration:  33217, Training Accuracy:  68.8%, Loss: 0.3809\n",
      "Optimization Iteration:  33281, Training Accuracy:  67.2%, Loss: 0.5310\n",
      "Optimization Iteration:  33345, Training Accuracy:  68.8%, Loss: 0.4630\n",
      "Optimization Iteration:  33409, Training Accuracy:  76.6%, Loss: 0.4210\n",
      "Optimization Iteration:  33473, Training Accuracy:  73.4%, Loss: 0.4571\n",
      "Optimization Iteration:  33537, Training Accuracy:  78.1%, Loss: 0.3950\n",
      "Optimization Iteration:  33601, Training Accuracy:  71.9%, Loss: 0.4467\n",
      "Optimization Iteration:  33665, Training Accuracy:  73.4%, Loss: 0.4383\n",
      "Optimization Iteration:  33729, Training Accuracy:  75.0%, Loss: 0.4591\n",
      "Optimization Iteration:  33793, Training Accuracy:  68.8%, Loss: 0.5496\n",
      "Optimization Iteration:  33857, Training Accuracy:  76.6%, Loss: 0.4378\n",
      "Optimization Iteration:  33921, Training Accuracy:  78.1%, Loss: 0.3829\n",
      "Optimization Iteration:  33985, Training Accuracy:  73.4%, Loss: 0.3717\n",
      "Optimization Iteration:  34049, Training Accuracy:  73.4%, Loss: 0.4288\n",
      "Optimization Iteration:  34113, Training Accuracy:  76.6%, Loss: 0.3755\n",
      "Optimization Iteration:  34177, Training Accuracy:  68.8%, Loss: 0.3880\n",
      "Optimization Iteration:  34241, Training Accuracy:  70.3%, Loss: 0.4064\n",
      "Optimization Iteration:  34305, Training Accuracy:  73.4%, Loss: 0.4036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  34369, Training Accuracy:  73.4%, Loss: 0.3220\n",
      "Optimization Iteration:  34433, Training Accuracy:  73.4%, Loss: 0.5193\n",
      "Optimization Iteration:  34497, Training Accuracy:  82.8%, Loss: 0.2951\n",
      "Optimization Iteration:  34561, Training Accuracy:  75.0%, Loss: 0.3854\n",
      "Optimization Iteration:  34625, Training Accuracy:  68.8%, Loss: 0.4770\n",
      "Optimization Iteration:  34689, Training Accuracy:  70.3%, Loss: 0.4910\n",
      "Optimization Iteration:  34753, Training Accuracy:  75.0%, Loss: 0.4539\n",
      "Optimization Iteration:  34817, Training Accuracy:  75.0%, Loss: 0.4431\n",
      "Optimization Iteration:  34881, Training Accuracy:  79.7%, Loss: 0.3454\n",
      "Optimization Iteration:  34945, Training Accuracy:  73.4%, Loss: 0.3960\n",
      "Optimization Iteration:  35009, Training Accuracy:  81.2%, Loss: 0.4175\n",
      "Optimization Iteration:  35073, Training Accuracy:  79.7%, Loss: 0.3650\n",
      "Optimization Iteration:  35137, Training Accuracy:  84.4%, Loss: 0.3217\n",
      "Optimization Iteration:  35201, Training Accuracy:  71.9%, Loss: 0.4433\n",
      "Optimization Iteration:  35265, Training Accuracy:  70.3%, Loss: 0.4107\n",
      "Optimization Iteration:  35329, Training Accuracy:  73.4%, Loss: 0.4583\n",
      "Optimization Iteration:  35393, Training Accuracy:  79.7%, Loss: 0.3220\n",
      "Optimization Iteration:  35457, Training Accuracy:  82.8%, Loss: 0.3916\n",
      "Optimization Iteration:  35521, Training Accuracy:  78.1%, Loss: 0.3775\n",
      "Optimization Iteration:  35585, Training Accuracy:  87.5%, Loss: 0.3414\n",
      "Optimization Iteration:  35649, Training Accuracy:  73.4%, Loss: 0.4839\n",
      "Optimization Iteration:  35713, Training Accuracy:  76.6%, Loss: 0.4481\n",
      "Optimization Iteration:  35777, Training Accuracy:  82.8%, Loss: 0.3151\n",
      "Optimization Iteration:  35841, Training Accuracy:  73.4%, Loss: 0.3567\n",
      "Optimization Iteration:  35905, Training Accuracy:  82.8%, Loss: 0.3656\n",
      "Optimization Iteration:  35969, Training Accuracy:  75.0%, Loss: 0.4422\n",
      "Optimization Iteration:  36033, Training Accuracy:  75.0%, Loss: 0.3609\n",
      "Optimization Iteration:  36097, Training Accuracy:  73.4%, Loss: 0.4218\n",
      "Optimization Iteration:  36161, Training Accuracy:  76.6%, Loss: 0.4443\n",
      "Optimization Iteration:  36225, Training Accuracy:  70.3%, Loss: 0.4192\n",
      "Optimization Iteration:  36289, Training Accuracy:  82.8%, Loss: 0.2970\n",
      "Optimization Iteration:  36353, Training Accuracy:  79.7%, Loss: 0.3508\n",
      "Optimization Iteration:  36417, Training Accuracy:  78.1%, Loss: 0.4349\n",
      "Optimization Iteration:  36481, Training Accuracy:  73.4%, Loss: 0.4201\n",
      "Optimization Iteration:  36545, Training Accuracy:  81.2%, Loss: 0.4419\n",
      "Optimization Iteration:  36609, Training Accuracy:  73.4%, Loss: 0.3854\n",
      "Optimization Iteration:  36673, Training Accuracy:  70.3%, Loss: 0.4428\n",
      "Optimization Iteration:  36737, Training Accuracy:  81.2%, Loss: 0.3590\n",
      "Optimization Iteration:  36801, Training Accuracy:  81.2%, Loss: 0.3975\n",
      "Optimization Iteration:  36865, Training Accuracy:  73.4%, Loss: 0.3744\n",
      "Optimization Iteration:  36929, Training Accuracy:  78.1%, Loss: 0.4718\n",
      "Optimization Iteration:  36993, Training Accuracy:  78.1%, Loss: 0.3692\n",
      "Optimization Iteration:  37057, Training Accuracy:  82.8%, Loss: 0.3188\n",
      "Optimization Iteration:  37121, Training Accuracy:  79.7%, Loss: 0.3189\n",
      "Optimization Iteration:  37185, Training Accuracy:  79.7%, Loss: 0.3906\n",
      "Optimization Iteration:  37249, Training Accuracy:  62.5%, Loss: 0.4879\n",
      "Optimization Iteration:  37313, Training Accuracy:  73.4%, Loss: 0.3609\n",
      "Optimization Iteration:  37377, Training Accuracy:  73.4%, Loss: 0.5661\n",
      "Optimization Iteration:  37441, Training Accuracy:  68.8%, Loss: 0.3922\n",
      "Optimization Iteration:  37505, Training Accuracy:  67.2%, Loss: 0.4851\n",
      "Optimization Iteration:  37569, Training Accuracy:  76.6%, Loss: 0.4015\n",
      "Optimization Iteration:  37633, Training Accuracy:  67.2%, Loss: 0.5221\n",
      "Optimization Iteration:  37697, Training Accuracy:  75.0%, Loss: 0.3912\n",
      "Optimization Iteration:  37761, Training Accuracy:  79.7%, Loss: 0.4170\n",
      "Optimization Iteration:  37825, Training Accuracy:  76.6%, Loss: 0.3717\n",
      "Optimization Iteration:  37889, Training Accuracy:  79.7%, Loss: 0.3990\n",
      "Optimization Iteration:  37953, Training Accuracy:  78.1%, Loss: 0.3285\n",
      "Optimization Iteration:  38017, Training Accuracy:  78.1%, Loss: 0.3781\n",
      "Optimization Iteration:  38081, Training Accuracy:  70.3%, Loss: 0.4092\n",
      "Optimization Iteration:  38145, Training Accuracy:  73.4%, Loss: 0.3398\n",
      "Optimization Iteration:  38209, Training Accuracy:  70.3%, Loss: 0.4394\n",
      "Optimization Iteration:  38273, Training Accuracy:  78.1%, Loss: 0.4185\n",
      "Optimization Iteration:  38337, Training Accuracy:  85.9%, Loss: 0.3108\n",
      "Optimization Iteration:  38401, Training Accuracy:  81.2%, Loss: 0.4375\n",
      "Optimization Iteration:  38465, Training Accuracy:  79.7%, Loss: 0.4120\n",
      "Optimization Iteration:  38529, Training Accuracy:  79.7%, Loss: 0.4516\n",
      "Optimization Iteration:  38593, Training Accuracy:  75.0%, Loss: 0.4851\n",
      "Optimization Iteration:  38657, Training Accuracy:  65.6%, Loss: 0.4553\n",
      "Optimization Iteration:  38721, Training Accuracy:  78.1%, Loss: 0.3141\n",
      "Optimization Iteration:  38785, Training Accuracy:  75.0%, Loss: 0.4475\n",
      "Optimization Iteration:  38849, Training Accuracy:  79.7%, Loss: 0.3380\n",
      "Optimization Iteration:  38913, Training Accuracy:  81.2%, Loss: 0.4146\n",
      "Optimization Iteration:  38977, Training Accuracy:  68.8%, Loss: 0.4049\n",
      "Optimization Iteration:  39041, Training Accuracy:  82.8%, Loss: 0.3737\n",
      "Optimization Iteration:  39105, Training Accuracy:  70.3%, Loss: 0.5086\n",
      "Optimization Iteration:  39169, Training Accuracy:  78.1%, Loss: 0.4060\n",
      "Optimization Iteration:  39233, Training Accuracy:  71.9%, Loss: 0.4217\n",
      "Optimization Iteration:  39297, Training Accuracy:  76.6%, Loss: 0.4351\n",
      "Optimization Iteration:  39361, Training Accuracy:  70.3%, Loss: 0.3648\n",
      "Optimization Iteration:  39425, Training Accuracy:  76.6%, Loss: 0.4359\n",
      "Optimization Iteration:  39489, Training Accuracy:  71.9%, Loss: 0.4011\n",
      "Optimization Iteration:  39553, Training Accuracy:  75.0%, Loss: 0.4018\n",
      "Optimization Iteration:  39617, Training Accuracy:  73.4%, Loss: 0.5079\n",
      "Optimization Iteration:  39681, Training Accuracy:  67.2%, Loss: 0.4331\n",
      "Optimization Iteration:  39745, Training Accuracy:  75.0%, Loss: 0.4717\n",
      "Optimization Iteration:  39809, Training Accuracy:  78.1%, Loss: 0.4285\n",
      "Optimization Iteration:  39873, Training Accuracy:  70.3%, Loss: 0.4549\n",
      "Optimization Iteration:  39937, Training Accuracy:  76.6%, Loss: 0.4552\n",
      "Optimization Iteration:  40001, Training Accuracy:  79.7%, Loss: 0.4071\n",
      "Optimization Iteration:  40065, Training Accuracy:  67.2%, Loss: 0.3672\n",
      "Optimization Iteration:  40129, Training Accuracy:  62.5%, Loss: 0.4705\n",
      "Optimization Iteration:  40193, Training Accuracy:  81.2%, Loss: 0.3529\n",
      "Optimization Iteration:  40257, Training Accuracy:  71.9%, Loss: 0.4812\n",
      "Optimization Iteration:  40321, Training Accuracy:  70.3%, Loss: 0.4472\n",
      "Optimization Iteration:  40385, Training Accuracy:  70.3%, Loss: 0.4317\n",
      "Optimization Iteration:  40449, Training Accuracy:  70.3%, Loss: 0.4141\n",
      "Optimization Iteration:  40513, Training Accuracy:  85.9%, Loss: 0.3230\n",
      "Optimization Iteration:  40577, Training Accuracy:  68.8%, Loss: 0.4494\n",
      "Optimization Iteration:  40641, Training Accuracy:  81.2%, Loss: 0.3362\n",
      "Optimization Iteration:  40705, Training Accuracy:  87.5%, Loss: 0.3488\n",
      "Optimization Iteration:  40769, Training Accuracy:  81.2%, Loss: 0.3168\n",
      "Optimization Iteration:  40833, Training Accuracy:  82.8%, Loss: 0.3228\n",
      "Optimization Iteration:  40897, Training Accuracy:  79.7%, Loss: 0.3661\n",
      "Optimization Iteration:  40961, Training Accuracy:  81.2%, Loss: 0.3389\n",
      "Optimization Iteration:  41025, Training Accuracy:  78.1%, Loss: 0.4409\n",
      "Optimization Iteration:  41089, Training Accuracy:  78.1%, Loss: 0.4164\n",
      "Optimization Iteration:  41153, Training Accuracy:  78.1%, Loss: 0.4601\n",
      "Optimization Iteration:  41217, Training Accuracy:  78.1%, Loss: 0.3476\n",
      "Optimization Iteration:  41281, Training Accuracy:  68.8%, Loss: 0.5133\n",
      "Optimization Iteration:  41345, Training Accuracy:  75.0%, Loss: 0.4512\n",
      "Optimization Iteration:  41409, Training Accuracy:  76.6%, Loss: 0.3803\n",
      "Optimization Iteration:  41473, Training Accuracy:  79.7%, Loss: 0.4059\n",
      "Optimization Iteration:  41537, Training Accuracy:  71.9%, Loss: 0.4612\n",
      "Optimization Iteration:  41601, Training Accuracy:  81.2%, Loss: 0.3709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  41665, Training Accuracy:  84.4%, Loss: 0.3657\n",
      "Optimization Iteration:  41729, Training Accuracy:  89.1%, Loss: 0.3518\n",
      "Optimization Iteration:  41793, Training Accuracy:  76.6%, Loss: 0.3700\n",
      "Optimization Iteration:  41857, Training Accuracy:  75.0%, Loss: 0.4102\n",
      "Optimization Iteration:  41921, Training Accuracy:  76.6%, Loss: 0.3727\n",
      "Optimization Iteration:  41985, Training Accuracy:  70.3%, Loss: 0.4093\n",
      "Optimization Iteration:  42049, Training Accuracy:  67.2%, Loss: 0.4384\n",
      "Optimization Iteration:  42113, Training Accuracy:  75.0%, Loss: 0.3700\n",
      "Optimization Iteration:  42177, Training Accuracy:  62.5%, Loss: 0.4450\n",
      "Optimization Iteration:  42241, Training Accuracy:  76.6%, Loss: 0.4117\n",
      "Optimization Iteration:  42305, Training Accuracy:  76.6%, Loss: 0.4840\n",
      "Optimization Iteration:  42369, Training Accuracy:  65.6%, Loss: 0.4500\n",
      "Optimization Iteration:  42433, Training Accuracy:  75.0%, Loss: 0.4212\n",
      "Optimization Iteration:  42497, Training Accuracy:  76.6%, Loss: 0.3660\n",
      "Optimization Iteration:  42561, Training Accuracy:  78.1%, Loss: 0.3957\n",
      "Optimization Iteration:  42625, Training Accuracy:  87.5%, Loss: 0.3527\n",
      "Optimization Iteration:  42689, Training Accuracy:  75.0%, Loss: 0.3553\n",
      "Optimization Iteration:  42753, Training Accuracy:  73.4%, Loss: 0.4666\n",
      "Optimization Iteration:  42817, Training Accuracy:  84.4%, Loss: 0.3371\n",
      "Optimization Iteration:  42881, Training Accuracy:  65.6%, Loss: 0.4213\n",
      "Optimization Iteration:  42945, Training Accuracy:  70.3%, Loss: 0.4122\n",
      "Optimization Iteration:  43009, Training Accuracy:  71.9%, Loss: 0.4468\n",
      "Optimization Iteration:  43073, Training Accuracy:  70.3%, Loss: 0.4460\n",
      "Optimization Iteration:  43137, Training Accuracy:  78.1%, Loss: 0.3699\n",
      "Optimization Iteration:  43201, Training Accuracy:  78.1%, Loss: 0.3468\n",
      "Optimization Iteration:  43265, Training Accuracy:  75.0%, Loss: 0.3743\n",
      "Optimization Iteration:  43329, Training Accuracy:  73.4%, Loss: 0.5239\n",
      "Optimization Iteration:  43393, Training Accuracy:  68.8%, Loss: 0.4109\n",
      "Optimization Iteration:  43457, Training Accuracy:  73.4%, Loss: 0.3191\n",
      "Optimization Iteration:  43521, Training Accuracy:  76.6%, Loss: 0.4657\n",
      "Optimization Iteration:  43585, Training Accuracy:  73.4%, Loss: 0.3918\n",
      "Optimization Iteration:  43649, Training Accuracy:  81.2%, Loss: 0.4547\n",
      "Optimization Iteration:  43713, Training Accuracy:  73.4%, Loss: 0.4026\n",
      "Optimization Iteration:  43777, Training Accuracy:  82.8%, Loss: 0.3195\n",
      "Optimization Iteration:  43841, Training Accuracy:  79.7%, Loss: 0.3919\n",
      "Optimization Iteration:  43905, Training Accuracy:  76.6%, Loss: 0.3883\n",
      "Optimization Iteration:  43969, Training Accuracy:  76.6%, Loss: 0.3610\n",
      "Optimization Iteration:  44033, Training Accuracy:  71.9%, Loss: 0.4848\n",
      "Optimization Iteration:  44097, Training Accuracy:  75.0%, Loss: 0.3691\n",
      "Optimization Iteration:  44161, Training Accuracy:  76.6%, Loss: 0.3483\n",
      "Optimization Iteration:  44225, Training Accuracy:  75.0%, Loss: 0.3857\n",
      "Optimization Iteration:  44289, Training Accuracy:  70.3%, Loss: 0.4643\n",
      "Optimization Iteration:  44353, Training Accuracy:  78.1%, Loss: 0.4342\n",
      "Optimization Iteration:  44417, Training Accuracy:  71.9%, Loss: 0.3812\n",
      "Optimization Iteration:  44481, Training Accuracy:  67.2%, Loss: 0.4590\n",
      "Optimization Iteration:  44545, Training Accuracy:  73.4%, Loss: 0.4299\n",
      "Optimization Iteration:  44609, Training Accuracy:  82.8%, Loss: 0.3412\n",
      "Optimization Iteration:  44673, Training Accuracy:  75.0%, Loss: 0.5618\n",
      "Optimization Iteration:  44737, Training Accuracy:  79.7%, Loss: 0.3894\n",
      "Optimization Iteration:  44801, Training Accuracy:  73.4%, Loss: 0.4362\n",
      "Optimization Iteration:  44865, Training Accuracy:  75.0%, Loss: 0.3882\n",
      "Optimization Iteration:  44929, Training Accuracy:  78.1%, Loss: 0.3636\n",
      "Optimization Iteration:  44993, Training Accuracy:  71.9%, Loss: 0.4748\n",
      "Optimization Iteration:  45057, Training Accuracy:  73.4%, Loss: 0.4347\n",
      "Optimization Iteration:  45121, Training Accuracy:  76.6%, Loss: 0.4520\n",
      "Optimization Iteration:  45185, Training Accuracy:  79.7%, Loss: 0.3627\n",
      "Optimization Iteration:  45249, Training Accuracy:  73.4%, Loss: 0.4279\n",
      "Optimization Iteration:  45313, Training Accuracy:  76.6%, Loss: 0.3826\n",
      "Optimization Iteration:  45377, Training Accuracy:  78.1%, Loss: 0.4758\n",
      "Optimization Iteration:  45441, Training Accuracy:  81.2%, Loss: 0.3133\n",
      "Optimization Iteration:  45505, Training Accuracy:  75.0%, Loss: 0.4876\n",
      "Optimization Iteration:  45569, Training Accuracy:  70.3%, Loss: 0.4549\n",
      "Optimization Iteration:  45633, Training Accuracy:  75.0%, Loss: 0.4972\n",
      "Optimization Iteration:  45697, Training Accuracy:  73.4%, Loss: 0.3926\n",
      "Optimization Iteration:  45761, Training Accuracy:  89.1%, Loss: 0.3047\n",
      "Optimization Iteration:  45825, Training Accuracy:  76.6%, Loss: 0.3568\n",
      "Optimization Iteration:  45889, Training Accuracy:  79.7%, Loss: 0.3752\n",
      "Optimization Iteration:  45953, Training Accuracy:  82.8%, Loss: 0.3238\n",
      "Optimization Iteration:  46017, Training Accuracy:  73.4%, Loss: 0.4176\n",
      "Optimization Iteration:  46081, Training Accuracy:  79.7%, Loss: 0.2877\n",
      "Optimization Iteration:  46145, Training Accuracy:  76.6%, Loss: 0.4066\n",
      "Optimization Iteration:  46209, Training Accuracy:  78.1%, Loss: 0.3741\n",
      "Optimization Iteration:  46273, Training Accuracy:  65.6%, Loss: 0.5273\n",
      "Optimization Iteration:  46337, Training Accuracy:  76.6%, Loss: 0.3864\n",
      "Optimization Iteration:  46401, Training Accuracy:  82.8%, Loss: 0.3195\n",
      "Optimization Iteration:  46465, Training Accuracy:  70.3%, Loss: 0.4555\n",
      "Optimization Iteration:  46529, Training Accuracy:  79.7%, Loss: 0.4266\n",
      "Optimization Iteration:  46593, Training Accuracy:  79.7%, Loss: 0.4191\n",
      "Optimization Iteration:  46657, Training Accuracy:  71.9%, Loss: 0.4586\n",
      "Optimization Iteration:  46721, Training Accuracy:  75.0%, Loss: 0.3977\n",
      "Optimization Iteration:  46785, Training Accuracy:  68.8%, Loss: 0.4836\n",
      "Optimization Iteration:  46849, Training Accuracy:  73.4%, Loss: 0.3559\n",
      "Optimization Iteration:  46913, Training Accuracy:  70.3%, Loss: 0.3897\n",
      "Optimization Iteration:  46977, Training Accuracy:  65.6%, Loss: 0.4354\n",
      "Optimization Iteration:  47041, Training Accuracy:  76.6%, Loss: 0.4071\n",
      "Optimization Iteration:  47105, Training Accuracy:  76.6%, Loss: 0.4691\n",
      "Optimization Iteration:  47169, Training Accuracy:  75.0%, Loss: 0.3980\n",
      "Optimization Iteration:  47233, Training Accuracy:  76.6%, Loss: 0.4024\n",
      "Optimization Iteration:  47297, Training Accuracy:  76.6%, Loss: 0.3700\n",
      "Optimization Iteration:  47361, Training Accuracy:  73.4%, Loss: 0.3855\n",
      "Optimization Iteration:  47425, Training Accuracy:  81.2%, Loss: 0.3299\n",
      "Optimization Iteration:  47489, Training Accuracy:  79.7%, Loss: 0.3612\n",
      "Optimization Iteration:  47553, Training Accuracy:  82.8%, Loss: 0.4195\n",
      "Optimization Iteration:  47617, Training Accuracy:  78.1%, Loss: 0.4215\n",
      "Optimization Iteration:  47681, Training Accuracy:  78.1%, Loss: 0.3927\n",
      "Optimization Iteration:  47745, Training Accuracy:  70.3%, Loss: 0.5186\n",
      "Optimization Iteration:  47809, Training Accuracy:  75.0%, Loss: 0.3962\n",
      "Optimization Iteration:  47873, Training Accuracy:  79.7%, Loss: 0.3126\n",
      "Optimization Iteration:  47937, Training Accuracy:  71.9%, Loss: 0.4456\n",
      "Optimization Iteration:  48001, Training Accuracy:  79.7%, Loss: 0.4206\n",
      "Optimization Iteration:  48065, Training Accuracy:  85.9%, Loss: 0.3564\n",
      "Optimization Iteration:  48129, Training Accuracy:  79.7%, Loss: 0.3617\n",
      "Optimization Iteration:  48193, Training Accuracy:  73.4%, Loss: 0.4732\n",
      "Optimization Iteration:  48257, Training Accuracy:  84.4%, Loss: 0.3539\n",
      "Optimization Iteration:  48321, Training Accuracy:  73.4%, Loss: 0.3951\n",
      "Optimization Iteration:  48385, Training Accuracy:  79.7%, Loss: 0.4228\n",
      "Optimization Iteration:  48449, Training Accuracy:  78.1%, Loss: 0.4098\n",
      "Optimization Iteration:  48513, Training Accuracy:  71.9%, Loss: 0.3650\n",
      "Optimization Iteration:  48577, Training Accuracy:  64.1%, Loss: 0.5626\n",
      "Optimization Iteration:  48641, Training Accuracy:  81.2%, Loss: 0.3786\n",
      "Optimization Iteration:  48705, Training Accuracy:  75.0%, Loss: 0.4031\n",
      "Optimization Iteration:  48769, Training Accuracy:  87.5%, Loss: 0.3482\n",
      "Optimization Iteration:  48833, Training Accuracy:  79.7%, Loss: 0.3633\n",
      "Optimization Iteration:  48897, Training Accuracy:  81.2%, Loss: 0.3776\n",
      "Optimization Iteration:  48961, Training Accuracy:  78.1%, Loss: 0.4423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  49025, Training Accuracy:  70.3%, Loss: 0.4030\n",
      "Optimization Iteration:  49089, Training Accuracy:  78.1%, Loss: 0.3929\n",
      "Optimization Iteration:  49153, Training Accuracy:  78.1%, Loss: 0.3756\n",
      "Optimization Iteration:  49217, Training Accuracy:  79.7%, Loss: 0.3920\n",
      "Optimization Iteration:  49281, Training Accuracy:  68.8%, Loss: 0.4389\n",
      "Optimization Iteration:  49345, Training Accuracy:  75.0%, Loss: 0.3658\n",
      "Optimization Iteration:  49409, Training Accuracy:  76.6%, Loss: 0.3549\n",
      "Optimization Iteration:  49473, Training Accuracy:  75.0%, Loss: 0.4288\n",
      "Optimization Iteration:  49537, Training Accuracy:  75.0%, Loss: 0.3991\n",
      "Optimization Iteration:  49601, Training Accuracy:  73.4%, Loss: 0.4371\n",
      "Optimization Iteration:  49665, Training Accuracy:  85.9%, Loss: 0.2983\n",
      "Optimization Iteration:  49729, Training Accuracy:  73.4%, Loss: 0.5010\n",
      "Optimization Iteration:  49793, Training Accuracy:  64.1%, Loss: 0.4041\n",
      "Optimization Iteration:  49857, Training Accuracy:  82.8%, Loss: 0.4211\n",
      "Optimization Iteration:  49921, Training Accuracy:  81.2%, Loss: 0.4848\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 16\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  68.8%, Loss: 0.4560\n",
      "Optimization Iteration:    129, Training Accuracy:  70.3%, Loss: 0.4862\n",
      "Optimization Iteration:    193, Training Accuracy:  81.2%, Loss: 0.3846\n",
      "Optimization Iteration:    257, Training Accuracy:  75.0%, Loss: 0.3586\n",
      "Optimization Iteration:    321, Training Accuracy:  73.4%, Loss: 0.3951\n",
      "Optimization Iteration:    385, Training Accuracy:  82.8%, Loss: 0.3436\n",
      "Optimization Iteration:    449, Training Accuracy:  89.1%, Loss: 0.3504\n",
      "Optimization Iteration:    513, Training Accuracy:  65.6%, Loss: 0.4557\n",
      "Optimization Iteration:    577, Training Accuracy:  62.5%, Loss: 0.4905\n",
      "Optimization Iteration:    641, Training Accuracy:  78.1%, Loss: 0.3917\n",
      "Optimization Iteration:    705, Training Accuracy:  76.6%, Loss: 0.4760\n",
      "Optimization Iteration:    769, Training Accuracy:  75.0%, Loss: 0.4651\n",
      "Optimization Iteration:    833, Training Accuracy:  78.1%, Loss: 0.3901\n",
      "Optimization Iteration:    897, Training Accuracy:  79.7%, Loss: 0.3395\n",
      "Optimization Iteration:    961, Training Accuracy:  79.7%, Loss: 0.3862\n",
      "Optimization Iteration:   1025, Training Accuracy:  78.1%, Loss: 0.3483\n",
      "Optimization Iteration:   1089, Training Accuracy:  65.6%, Loss: 0.4383\n",
      "Optimization Iteration:   1153, Training Accuracy:  62.5%, Loss: 0.4657\n",
      "Optimization Iteration:   1217, Training Accuracy:  71.9%, Loss: 0.4101\n",
      "Optimization Iteration:   1281, Training Accuracy:  67.2%, Loss: 0.5029\n",
      "Optimization Iteration:   1345, Training Accuracy:  78.1%, Loss: 0.4135\n",
      "Optimization Iteration:   1409, Training Accuracy:  79.7%, Loss: 0.3794\n",
      "Optimization Iteration:   1473, Training Accuracy:  73.4%, Loss: 0.3909\n",
      "Optimization Iteration:   1537, Training Accuracy:  78.1%, Loss: 0.4179\n",
      "Optimization Iteration:   1601, Training Accuracy:  81.2%, Loss: 0.3841\n",
      "Optimization Iteration:   1665, Training Accuracy:  82.8%, Loss: 0.2940\n",
      "Optimization Iteration:   1729, Training Accuracy:  78.1%, Loss: 0.3441\n",
      "Optimization Iteration:   1793, Training Accuracy:  76.6%, Loss: 0.4303\n",
      "Optimization Iteration:   1857, Training Accuracy:  70.3%, Loss: 0.4988\n",
      "Optimization Iteration:   1921, Training Accuracy:  62.5%, Loss: 0.5030\n",
      "Optimization Iteration:   1985, Training Accuracy:  68.8%, Loss: 0.4095\n",
      "Optimization Iteration:   2049, Training Accuracy:  81.2%, Loss: 0.3149\n",
      "Optimization Iteration:   2113, Training Accuracy:  73.4%, Loss: 0.4256\n",
      "Optimization Iteration:   2177, Training Accuracy:  78.1%, Loss: 0.3819\n",
      "Optimization Iteration:   2241, Training Accuracy:  76.6%, Loss: 0.4674\n",
      "Optimization Iteration:   2305, Training Accuracy:  75.0%, Loss: 0.3730\n",
      "Optimization Iteration:   2369, Training Accuracy:  82.8%, Loss: 0.3752\n",
      "Optimization Iteration:   2433, Training Accuracy:  79.7%, Loss: 0.4242\n",
      "Optimization Iteration:   2497, Training Accuracy:  78.1%, Loss: 0.3356\n",
      "Optimization Iteration:   2561, Training Accuracy:  79.7%, Loss: 0.3709\n",
      "Optimization Iteration:   2625, Training Accuracy:  81.2%, Loss: 0.3887\n",
      "Optimization Iteration:   2689, Training Accuracy:  75.0%, Loss: 0.3599\n",
      "Optimization Iteration:   2753, Training Accuracy:  78.1%, Loss: 0.3748\n",
      "Optimization Iteration:   2817, Training Accuracy:  76.6%, Loss: 0.4124\n",
      "Optimization Iteration:   2881, Training Accuracy:  79.7%, Loss: 0.3862\n",
      "Optimization Iteration:   2945, Training Accuracy:  75.0%, Loss: 0.4046\n",
      "Optimization Iteration:   3009, Training Accuracy:  75.0%, Loss: 0.4290\n",
      "Optimization Iteration:   3073, Training Accuracy:  75.0%, Loss: 0.4058\n",
      "Optimization Iteration:   3137, Training Accuracy:  78.1%, Loss: 0.3704\n",
      "Optimization Iteration:   3201, Training Accuracy:  82.8%, Loss: 0.3011\n",
      "Optimization Iteration:   3265, Training Accuracy:  71.9%, Loss: 0.4525\n",
      "Optimization Iteration:   3329, Training Accuracy:  84.4%, Loss: 0.3523\n",
      "Optimization Iteration:   3393, Training Accuracy:  73.4%, Loss: 0.3949\n",
      "Optimization Iteration:   3457, Training Accuracy:  73.4%, Loss: 0.4584\n",
      "Optimization Iteration:   3521, Training Accuracy:  70.3%, Loss: 0.4452\n",
      "Optimization Iteration:   3585, Training Accuracy:  70.3%, Loss: 0.5044\n",
      "Optimization Iteration:   3649, Training Accuracy:  79.7%, Loss: 0.4278\n",
      "Optimization Iteration:   3713, Training Accuracy:  73.4%, Loss: 0.3915\n",
      "Optimization Iteration:   3777, Training Accuracy:  75.0%, Loss: 0.3998\n",
      "Optimization Iteration:   3841, Training Accuracy:  73.4%, Loss: 0.4568\n",
      "Optimization Iteration:   3905, Training Accuracy:  78.1%, Loss: 0.3915\n",
      "Optimization Iteration:   3969, Training Accuracy:  68.8%, Loss: 0.4219\n",
      "Optimization Iteration:   4033, Training Accuracy:  75.0%, Loss: 0.3743\n",
      "Optimization Iteration:   4097, Training Accuracy:  73.4%, Loss: 0.4163\n",
      "Optimization Iteration:   4161, Training Accuracy:  70.3%, Loss: 0.4217\n",
      "Optimization Iteration:   4225, Training Accuracy:  81.2%, Loss: 0.3684\n",
      "Optimization Iteration:   4289, Training Accuracy:  84.4%, Loss: 0.3188\n",
      "Optimization Iteration:   4353, Training Accuracy:  82.8%, Loss: 0.3966\n",
      "Optimization Iteration:   4417, Training Accuracy:  67.2%, Loss: 0.4617\n",
      "Optimization Iteration:   4481, Training Accuracy:  71.9%, Loss: 0.4291\n",
      "Optimization Iteration:   4545, Training Accuracy:  76.6%, Loss: 0.3927\n",
      "Optimization Iteration:   4609, Training Accuracy:  79.7%, Loss: 0.3994\n",
      "Optimization Iteration:   4673, Training Accuracy:  73.4%, Loss: 0.4379\n",
      "Optimization Iteration:   4737, Training Accuracy:  81.2%, Loss: 0.4733\n",
      "Optimization Iteration:   4801, Training Accuracy:  71.9%, Loss: 0.4736\n",
      "Optimization Iteration:   4865, Training Accuracy:  79.7%, Loss: 0.3690\n",
      "Optimization Iteration:   4929, Training Accuracy:  81.2%, Loss: 0.4096\n",
      "Optimization Iteration:   4993, Training Accuracy:  76.6%, Loss: 0.3631\n",
      "Optimization Iteration:   5057, Training Accuracy:  73.4%, Loss: 0.4535\n",
      "Optimization Iteration:   5121, Training Accuracy:  76.6%, Loss: 0.3647\n",
      "Optimization Iteration:   5185, Training Accuracy:  68.8%, Loss: 0.4515\n",
      "Optimization Iteration:   5249, Training Accuracy:  68.8%, Loss: 0.4561\n",
      "Optimization Iteration:   5313, Training Accuracy:  79.7%, Loss: 0.4068\n",
      "Optimization Iteration:   5377, Training Accuracy:  84.4%, Loss: 0.3893\n",
      "Optimization Iteration:   5441, Training Accuracy:  70.3%, Loss: 0.3794\n",
      "Optimization Iteration:   5505, Training Accuracy:  78.1%, Loss: 0.3324\n",
      "Optimization Iteration:   5569, Training Accuracy:  79.7%, Loss: 0.3618\n",
      "Optimization Iteration:   5633, Training Accuracy:  79.7%, Loss: 0.4364\n",
      "Optimization Iteration:   5697, Training Accuracy:  73.4%, Loss: 0.4588\n",
      "Optimization Iteration:   5761, Training Accuracy:  81.2%, Loss: 0.3719\n",
      "Optimization Iteration:   5825, Training Accuracy:  71.9%, Loss: 0.4391\n",
      "Optimization Iteration:   5889, Training Accuracy:  76.6%, Loss: 0.4457\n",
      "Optimization Iteration:   5953, Training Accuracy:  64.1%, Loss: 0.4197\n",
      "Optimization Iteration:   6017, Training Accuracy:  65.6%, Loss: 0.4549\n",
      "Optimization Iteration:   6081, Training Accuracy:  71.9%, Loss: 0.4107\n",
      "Optimization Iteration:   6145, Training Accuracy:  67.2%, Loss: 0.5301\n",
      "Optimization Iteration:   6209, Training Accuracy:  75.0%, Loss: 0.4283\n",
      "Optimization Iteration:   6273, Training Accuracy:  81.2%, Loss: 0.3771\n",
      "Optimization Iteration:   6337, Training Accuracy:  68.8%, Loss: 0.4365\n",
      "Optimization Iteration:   6401, Training Accuracy:  81.2%, Loss: 0.3937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   6465, Training Accuracy:  76.6%, Loss: 0.3485\n",
      "Optimization Iteration:   6529, Training Accuracy:  85.9%, Loss: 0.3614\n",
      "Optimization Iteration:   6593, Training Accuracy:  76.6%, Loss: 0.3527\n",
      "Optimization Iteration:   6657, Training Accuracy:  73.4%, Loss: 0.3974\n",
      "Optimization Iteration:   6721, Training Accuracy:  76.6%, Loss: 0.3320\n",
      "Optimization Iteration:   6785, Training Accuracy:  68.8%, Loss: 0.4358\n",
      "Optimization Iteration:   6849, Training Accuracy:  81.2%, Loss: 0.3934\n",
      "Optimization Iteration:   6913, Training Accuracy:  78.1%, Loss: 0.3809\n",
      "Optimization Iteration:   6977, Training Accuracy:  75.0%, Loss: 0.4296\n",
      "Optimization Iteration:   7041, Training Accuracy:  82.8%, Loss: 0.3523\n",
      "Optimization Iteration:   7105, Training Accuracy:  75.0%, Loss: 0.3505\n",
      "Optimization Iteration:   7169, Training Accuracy:  79.7%, Loss: 0.4103\n",
      "Optimization Iteration:   7233, Training Accuracy:  71.9%, Loss: 0.4856\n",
      "Optimization Iteration:   7297, Training Accuracy:  60.9%, Loss: 0.5141\n",
      "Optimization Iteration:   7361, Training Accuracy:  82.8%, Loss: 0.3170\n",
      "Optimization Iteration:   7425, Training Accuracy:  73.4%, Loss: 0.4817\n",
      "Optimization Iteration:   7489, Training Accuracy:  70.3%, Loss: 0.4897\n",
      "Optimization Iteration:   7553, Training Accuracy:  73.4%, Loss: 0.4173\n",
      "Optimization Iteration:   7617, Training Accuracy:  70.3%, Loss: 0.4204\n",
      "Optimization Iteration:   7681, Training Accuracy:  67.2%, Loss: 0.4448\n",
      "Optimization Iteration:   7745, Training Accuracy:  84.4%, Loss: 0.3476\n",
      "Optimization Iteration:   7809, Training Accuracy:  75.0%, Loss: 0.5340\n",
      "Optimization Iteration:   7873, Training Accuracy:  78.1%, Loss: 0.3988\n",
      "Optimization Iteration:   7937, Training Accuracy:  75.0%, Loss: 0.4352\n",
      "Optimization Iteration:   8001, Training Accuracy:  71.9%, Loss: 0.4094\n",
      "Optimization Iteration:   8065, Training Accuracy:  68.8%, Loss: 0.4478\n",
      "Optimization Iteration:   8129, Training Accuracy:  79.7%, Loss: 0.3409\n",
      "Optimization Iteration:   8193, Training Accuracy:  71.9%, Loss: 0.3813\n",
      "Optimization Iteration:   8257, Training Accuracy:  78.1%, Loss: 0.4558\n",
      "Optimization Iteration:   8321, Training Accuracy:  67.2%, Loss: 0.4202\n",
      "Optimization Iteration:   8385, Training Accuracy:  60.9%, Loss: 0.5350\n",
      "Optimization Iteration:   8449, Training Accuracy:  78.1%, Loss: 0.4569\n",
      "Optimization Iteration:   8513, Training Accuracy:  82.8%, Loss: 0.3560\n",
      "Optimization Iteration:   8577, Training Accuracy:  75.0%, Loss: 0.4688\n",
      "Optimization Iteration:   8641, Training Accuracy:  67.2%, Loss: 0.4187\n",
      "Optimization Iteration:   8705, Training Accuracy:  81.2%, Loss: 0.3599\n",
      "Optimization Iteration:   8769, Training Accuracy:  82.8%, Loss: 0.3808\n",
      "Optimization Iteration:   8833, Training Accuracy:  70.3%, Loss: 0.4085\n",
      "Optimization Iteration:   8897, Training Accuracy:  68.8%, Loss: 0.4985\n",
      "Optimization Iteration:   8961, Training Accuracy:  67.2%, Loss: 0.3986\n",
      "Optimization Iteration:   9025, Training Accuracy:  73.4%, Loss: 0.5193\n",
      "Optimization Iteration:   9089, Training Accuracy:  68.8%, Loss: 0.4542\n",
      "Optimization Iteration:   9153, Training Accuracy:  71.9%, Loss: 0.3845\n",
      "Optimization Iteration:   9217, Training Accuracy:  81.2%, Loss: 0.3339\n",
      "Optimization Iteration:   9281, Training Accuracy:  75.0%, Loss: 0.4110\n",
      "Optimization Iteration:   9345, Training Accuracy:  81.2%, Loss: 0.3768\n",
      "Optimization Iteration:   9409, Training Accuracy:  76.6%, Loss: 0.4439\n",
      "Optimization Iteration:   9473, Training Accuracy:  71.9%, Loss: 0.3504\n",
      "Optimization Iteration:   9537, Training Accuracy:  76.6%, Loss: 0.3227\n",
      "Optimization Iteration:   9601, Training Accuracy:  75.0%, Loss: 0.4279\n",
      "Optimization Iteration:   9665, Training Accuracy:  60.9%, Loss: 0.4858\n",
      "Optimization Iteration:   9729, Training Accuracy:  70.3%, Loss: 0.4611\n",
      "Optimization Iteration:   9793, Training Accuracy:  71.9%, Loss: 0.3968\n",
      "Optimization Iteration:   9857, Training Accuracy:  73.4%, Loss: 0.4033\n",
      "Optimization Iteration:   9921, Training Accuracy:  79.7%, Loss: 0.3945\n",
      "Optimization Iteration:   9985, Training Accuracy:  71.9%, Loss: 0.4526\n",
      "Optimization Iteration:  10049, Training Accuracy:  73.4%, Loss: 0.4068\n",
      "Optimization Iteration:  10113, Training Accuracy:  76.6%, Loss: 0.3789\n",
      "Optimization Iteration:  10177, Training Accuracy:  73.4%, Loss: 0.4629\n",
      "Optimization Iteration:  10241, Training Accuracy:  79.7%, Loss: 0.4785\n",
      "Optimization Iteration:  10305, Training Accuracy:  78.1%, Loss: 0.3588\n",
      "Optimization Iteration:  10369, Training Accuracy:  71.9%, Loss: 0.3889\n",
      "Optimization Iteration:  10433, Training Accuracy:  71.9%, Loss: 0.3959\n",
      "Optimization Iteration:  10497, Training Accuracy:  70.3%, Loss: 0.4693\n",
      "Optimization Iteration:  10561, Training Accuracy:  76.6%, Loss: 0.3552\n",
      "Optimization Iteration:  10625, Training Accuracy:  79.7%, Loss: 0.3796\n",
      "Optimization Iteration:  10689, Training Accuracy:  73.4%, Loss: 0.3988\n",
      "Optimization Iteration:  10753, Training Accuracy:  70.3%, Loss: 0.4701\n",
      "Optimization Iteration:  10817, Training Accuracy:  70.3%, Loss: 0.4612\n",
      "Optimization Iteration:  10881, Training Accuracy:  78.1%, Loss: 0.3654\n",
      "Optimization Iteration:  10945, Training Accuracy:  76.6%, Loss: 0.3839\n",
      "Optimization Iteration:  11009, Training Accuracy:  84.4%, Loss: 0.3607\n",
      "Optimization Iteration:  11073, Training Accuracy:  81.2%, Loss: 0.3381\n",
      "Optimization Iteration:  11137, Training Accuracy:  78.1%, Loss: 0.4260\n",
      "Optimization Iteration:  11201, Training Accuracy:  75.0%, Loss: 0.4001\n",
      "Optimization Iteration:  11265, Training Accuracy:  71.9%, Loss: 0.4067\n",
      "Optimization Iteration:  11329, Training Accuracy:  82.8%, Loss: 0.5308\n",
      "Optimization Iteration:  11393, Training Accuracy:  79.7%, Loss: 0.4330\n",
      "Optimization Iteration:  11457, Training Accuracy:  82.8%, Loss: 0.3437\n",
      "Optimization Iteration:  11521, Training Accuracy:  75.0%, Loss: 0.4258\n",
      "Optimization Iteration:  11585, Training Accuracy:  76.6%, Loss: 0.3392\n",
      "Optimization Iteration:  11649, Training Accuracy:  67.2%, Loss: 0.4565\n",
      "Optimization Iteration:  11713, Training Accuracy:  78.1%, Loss: 0.3972\n",
      "Optimization Iteration:  11777, Training Accuracy:  68.8%, Loss: 0.4555\n",
      "Optimization Iteration:  11841, Training Accuracy:  70.3%, Loss: 0.4054\n",
      "Optimization Iteration:  11905, Training Accuracy:  76.6%, Loss: 0.3824\n",
      "Optimization Iteration:  11969, Training Accuracy:  84.4%, Loss: 0.3188\n",
      "Optimization Iteration:  12033, Training Accuracy:  78.1%, Loss: 0.3875\n",
      "Optimization Iteration:  12097, Training Accuracy:  79.7%, Loss: 0.3515\n",
      "Optimization Iteration:  12161, Training Accuracy:  87.5%, Loss: 0.4164\n",
      "Optimization Iteration:  12225, Training Accuracy:  81.2%, Loss: 0.3539\n",
      "Optimization Iteration:  12289, Training Accuracy:  78.1%, Loss: 0.3685\n",
      "Optimization Iteration:  12353, Training Accuracy:  81.2%, Loss: 0.3800\n",
      "Optimization Iteration:  12417, Training Accuracy:  81.2%, Loss: 0.3690\n",
      "Optimization Iteration:  12481, Training Accuracy:  71.9%, Loss: 0.4189\n",
      "Optimization Iteration:  12545, Training Accuracy:  76.6%, Loss: 0.3675\n",
      "Optimization Iteration:  12609, Training Accuracy:  76.6%, Loss: 0.3748\n",
      "Optimization Iteration:  12673, Training Accuracy:  79.7%, Loss: 0.4121\n",
      "Optimization Iteration:  12737, Training Accuracy:  76.6%, Loss: 0.4482\n",
      "Optimization Iteration:  12801, Training Accuracy:  84.4%, Loss: 0.4001\n",
      "Optimization Iteration:  12865, Training Accuracy:  76.6%, Loss: 0.4290\n",
      "Optimization Iteration:  12929, Training Accuracy:  73.4%, Loss: 0.4212\n",
      "Optimization Iteration:  12993, Training Accuracy:  82.8%, Loss: 0.3156\n",
      "Optimization Iteration:  13057, Training Accuracy:  73.4%, Loss: 0.4093\n",
      "Optimization Iteration:  13121, Training Accuracy:  78.1%, Loss: 0.3404\n",
      "Optimization Iteration:  13185, Training Accuracy:  78.1%, Loss: 0.3988\n",
      "Optimization Iteration:  13249, Training Accuracy:  70.3%, Loss: 0.5116\n",
      "Optimization Iteration:  13313, Training Accuracy:  68.8%, Loss: 0.5402\n",
      "Optimization Iteration:  13377, Training Accuracy:  81.2%, Loss: 0.4279\n",
      "Optimization Iteration:  13441, Training Accuracy:  73.4%, Loss: 0.3993\n",
      "Optimization Iteration:  13505, Training Accuracy:  76.6%, Loss: 0.3825\n",
      "Optimization Iteration:  13569, Training Accuracy:  79.7%, Loss: 0.3252\n",
      "Optimization Iteration:  13633, Training Accuracy:  75.0%, Loss: 0.3996\n",
      "Optimization Iteration:  13697, Training Accuracy:  81.2%, Loss: 0.3624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  13761, Training Accuracy:  79.7%, Loss: 0.3462\n",
      "Optimization Iteration:  13825, Training Accuracy:  76.6%, Loss: 0.4715\n",
      "Optimization Iteration:  13889, Training Accuracy:  76.6%, Loss: 0.5207\n",
      "Optimization Iteration:  13953, Training Accuracy:  76.6%, Loss: 0.4318\n",
      "Optimization Iteration:  14017, Training Accuracy:  75.0%, Loss: 0.3758\n",
      "Optimization Iteration:  14081, Training Accuracy:  76.6%, Loss: 0.3557\n",
      "Optimization Iteration:  14145, Training Accuracy:  75.0%, Loss: 0.3777\n",
      "Optimization Iteration:  14209, Training Accuracy:  78.1%, Loss: 0.3984\n",
      "Optimization Iteration:  14273, Training Accuracy:  75.0%, Loss: 0.4722\n",
      "Optimization Iteration:  14337, Training Accuracy:  90.6%, Loss: 0.2517\n",
      "Optimization Iteration:  14401, Training Accuracy:  79.7%, Loss: 0.3518\n",
      "Optimization Iteration:  14465, Training Accuracy:  76.6%, Loss: 0.4211\n",
      "Optimization Iteration:  14529, Training Accuracy:  84.4%, Loss: 0.3104\n",
      "Optimization Iteration:  14593, Training Accuracy:  71.9%, Loss: 0.4298\n",
      "Optimization Iteration:  14657, Training Accuracy:  65.6%, Loss: 0.4881\n",
      "Optimization Iteration:  14721, Training Accuracy:  79.7%, Loss: 0.3866\n",
      "Optimization Iteration:  14785, Training Accuracy:  71.9%, Loss: 0.4724\n",
      "Optimization Iteration:  14849, Training Accuracy:  73.4%, Loss: 0.3786\n",
      "Optimization Iteration:  14913, Training Accuracy:  78.1%, Loss: 0.2982\n",
      "Optimization Iteration:  14977, Training Accuracy:  81.2%, Loss: 0.3771\n",
      "Optimization Iteration:  15041, Training Accuracy:  76.6%, Loss: 0.4079\n",
      "Optimization Iteration:  15105, Training Accuracy:  85.9%, Loss: 0.3423\n",
      "Optimization Iteration:  15169, Training Accuracy:  81.2%, Loss: 0.3137\n",
      "Optimization Iteration:  15233, Training Accuracy:  71.9%, Loss: 0.4206\n",
      "Optimization Iteration:  15297, Training Accuracy:  76.6%, Loss: 0.4023\n",
      "Optimization Iteration:  15361, Training Accuracy:  82.8%, Loss: 0.3738\n",
      "Optimization Iteration:  15425, Training Accuracy:  68.8%, Loss: 0.4672\n",
      "Optimization Iteration:  15489, Training Accuracy:  67.2%, Loss: 0.4895\n",
      "Optimization Iteration:  15553, Training Accuracy:  75.0%, Loss: 0.3577\n",
      "Optimization Iteration:  15617, Training Accuracy:  75.0%, Loss: 0.4158\n",
      "Optimization Iteration:  15681, Training Accuracy:  84.4%, Loss: 0.3265\n",
      "Optimization Iteration:  15745, Training Accuracy:  81.2%, Loss: 0.3161\n",
      "Optimization Iteration:  15809, Training Accuracy:  73.4%, Loss: 0.4405\n",
      "Optimization Iteration:  15873, Training Accuracy:  65.6%, Loss: 0.4255\n",
      "Optimization Iteration:  15937, Training Accuracy:  76.6%, Loss: 0.4251\n",
      "Optimization Iteration:  16001, Training Accuracy:  67.2%, Loss: 0.3961\n",
      "Optimization Iteration:  16065, Training Accuracy:  68.8%, Loss: 0.4715\n",
      "Optimization Iteration:  16129, Training Accuracy:  68.8%, Loss: 0.3765\n",
      "Optimization Iteration:  16193, Training Accuracy:  78.1%, Loss: 0.4119\n",
      "Optimization Iteration:  16257, Training Accuracy:  81.2%, Loss: 0.3906\n",
      "Optimization Iteration:  16321, Training Accuracy:  71.9%, Loss: 0.4505\n",
      "Optimization Iteration:  16385, Training Accuracy:  81.2%, Loss: 0.3831\n",
      "Optimization Iteration:  16449, Training Accuracy:  71.9%, Loss: 0.4478\n",
      "Optimization Iteration:  16513, Training Accuracy:  76.6%, Loss: 0.4033\n",
      "Optimization Iteration:  16577, Training Accuracy:  73.4%, Loss: 0.3901\n",
      "Optimization Iteration:  16641, Training Accuracy:  73.4%, Loss: 0.4310\n",
      "Optimization Iteration:  16705, Training Accuracy:  78.1%, Loss: 0.4130\n",
      "Optimization Iteration:  16769, Training Accuracy:  70.3%, Loss: 0.4763\n",
      "Optimization Iteration:  16833, Training Accuracy:  81.2%, Loss: 0.3648\n",
      "Optimization Iteration:  16897, Training Accuracy:  73.4%, Loss: 0.4604\n",
      "Optimization Iteration:  16961, Training Accuracy:  70.3%, Loss: 0.4054\n",
      "Optimization Iteration:  17025, Training Accuracy:  70.3%, Loss: 0.4157\n",
      "Optimization Iteration:  17089, Training Accuracy:  81.2%, Loss: 0.3907\n",
      "Optimization Iteration:  17153, Training Accuracy:  71.9%, Loss: 0.4669\n",
      "Optimization Iteration:  17217, Training Accuracy:  78.1%, Loss: 0.4621\n",
      "Optimization Iteration:  17281, Training Accuracy:  64.1%, Loss: 0.4128\n",
      "Optimization Iteration:  17345, Training Accuracy:  81.2%, Loss: 0.2802\n",
      "Optimization Iteration:  17409, Training Accuracy:  81.2%, Loss: 0.3245\n",
      "Optimization Iteration:  17473, Training Accuracy:  68.8%, Loss: 0.5231\n",
      "Optimization Iteration:  17537, Training Accuracy:  71.9%, Loss: 0.3589\n",
      "Optimization Iteration:  17601, Training Accuracy:  71.9%, Loss: 0.3834\n",
      "Optimization Iteration:  17665, Training Accuracy:  82.8%, Loss: 0.3883\n",
      "Optimization Iteration:  17729, Training Accuracy:  73.4%, Loss: 0.4138\n",
      "Optimization Iteration:  17793, Training Accuracy:  67.2%, Loss: 0.3927\n",
      "Optimization Iteration:  17857, Training Accuracy:  73.4%, Loss: 0.3790\n",
      "Optimization Iteration:  17921, Training Accuracy:  78.1%, Loss: 0.3507\n",
      "Optimization Iteration:  17985, Training Accuracy:  81.2%, Loss: 0.3334\n",
      "Optimization Iteration:  18049, Training Accuracy:  78.1%, Loss: 0.3987\n",
      "Optimization Iteration:  18113, Training Accuracy:  62.5%, Loss: 0.5072\n",
      "Optimization Iteration:  18177, Training Accuracy:  71.9%, Loss: 0.4839\n",
      "Optimization Iteration:  18241, Training Accuracy:  67.2%, Loss: 0.4566\n",
      "Optimization Iteration:  18305, Training Accuracy:  70.3%, Loss: 0.4550\n",
      "Optimization Iteration:  18369, Training Accuracy:  78.1%, Loss: 0.3548\n",
      "Optimization Iteration:  18433, Training Accuracy:  68.8%, Loss: 0.4381\n",
      "Optimization Iteration:  18497, Training Accuracy:  82.8%, Loss: 0.3352\n",
      "Optimization Iteration:  18561, Training Accuracy:  73.4%, Loss: 0.3996\n",
      "Optimization Iteration:  18625, Training Accuracy:  76.6%, Loss: 0.4152\n",
      "Optimization Iteration:  18689, Training Accuracy:  79.7%, Loss: 0.3863\n",
      "Optimization Iteration:  18753, Training Accuracy:  73.4%, Loss: 0.3852\n",
      "Optimization Iteration:  18817, Training Accuracy:  71.9%, Loss: 0.4098\n",
      "Optimization Iteration:  18881, Training Accuracy:  75.0%, Loss: 0.4227\n",
      "Optimization Iteration:  18945, Training Accuracy:  75.0%, Loss: 0.3866\n",
      "Optimization Iteration:  19009, Training Accuracy:  82.8%, Loss: 0.3309\n",
      "Optimization Iteration:  19073, Training Accuracy:  71.9%, Loss: 0.4257\n",
      "Optimization Iteration:  19137, Training Accuracy:  65.6%, Loss: 0.4803\n",
      "Optimization Iteration:  19201, Training Accuracy:  68.8%, Loss: 0.4623\n",
      "Optimization Iteration:  19265, Training Accuracy:  79.7%, Loss: 0.4230\n",
      "Optimization Iteration:  19329, Training Accuracy:  87.5%, Loss: 0.3360\n",
      "Optimization Iteration:  19393, Training Accuracy:  70.3%, Loss: 0.4095\n",
      "Optimization Iteration:  19457, Training Accuracy:  78.1%, Loss: 0.3876\n",
      "Optimization Iteration:  19521, Training Accuracy:  79.7%, Loss: 0.3583\n",
      "Optimization Iteration:  19585, Training Accuracy:  67.2%, Loss: 0.4404\n",
      "Optimization Iteration:  19649, Training Accuracy:  79.7%, Loss: 0.3956\n",
      "Optimization Iteration:  19713, Training Accuracy:  81.2%, Loss: 0.3470\n",
      "Optimization Iteration:  19777, Training Accuracy:  81.2%, Loss: 0.3847\n",
      "Optimization Iteration:  19841, Training Accuracy:  78.1%, Loss: 0.3840\n",
      "Optimization Iteration:  19905, Training Accuracy:  65.6%, Loss: 0.4435\n",
      "Optimization Iteration:  19969, Training Accuracy:  76.6%, Loss: 0.4899\n",
      "Optimization Iteration:  20033, Training Accuracy:  79.7%, Loss: 0.3751\n",
      "Optimization Iteration:  20097, Training Accuracy:  71.9%, Loss: 0.4237\n",
      "Optimization Iteration:  20161, Training Accuracy:  73.4%, Loss: 0.3831\n",
      "Optimization Iteration:  20225, Training Accuracy:  70.3%, Loss: 0.4396\n",
      "Optimization Iteration:  20289, Training Accuracy:  67.2%, Loss: 0.4419\n",
      "Optimization Iteration:  20353, Training Accuracy:  75.0%, Loss: 0.4380\n",
      "Optimization Iteration:  20417, Training Accuracy:  81.2%, Loss: 0.3463\n",
      "Optimization Iteration:  20481, Training Accuracy:  78.1%, Loss: 0.3742\n",
      "Optimization Iteration:  20545, Training Accuracy:  71.9%, Loss: 0.4793\n",
      "Optimization Iteration:  20609, Training Accuracy:  79.7%, Loss: 0.4370\n",
      "Optimization Iteration:  20673, Training Accuracy:  71.9%, Loss: 0.4346\n",
      "Optimization Iteration:  20737, Training Accuracy:  81.2%, Loss: 0.3999\n",
      "Optimization Iteration:  20801, Training Accuracy:  79.7%, Loss: 0.3929\n",
      "Optimization Iteration:  20865, Training Accuracy:  75.0%, Loss: 0.3534\n",
      "Optimization Iteration:  20929, Training Accuracy:  79.7%, Loss: 0.3776\n",
      "Optimization Iteration:  20993, Training Accuracy:  73.4%, Loss: 0.4040\n",
      "Optimization Iteration:  21057, Training Accuracy:  73.4%, Loss: 0.3804\n",
      "Optimization Iteration:  21121, Training Accuracy:  68.8%, Loss: 0.4614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  21185, Training Accuracy:  76.6%, Loss: 0.5192\n",
      "Optimization Iteration:  21249, Training Accuracy:  73.4%, Loss: 0.4220\n",
      "Optimization Iteration:  21313, Training Accuracy:  82.8%, Loss: 0.3739\n",
      "Optimization Iteration:  21377, Training Accuracy:  82.8%, Loss: 0.3244\n",
      "Optimization Iteration:  21441, Training Accuracy:  64.1%, Loss: 0.4163\n",
      "Optimization Iteration:  21505, Training Accuracy:  84.4%, Loss: 0.3428\n",
      "Optimization Iteration:  21569, Training Accuracy:  71.9%, Loss: 0.3861\n",
      "Optimization Iteration:  21633, Training Accuracy:  87.5%, Loss: 0.3441\n",
      "Optimization Iteration:  21697, Training Accuracy:  70.3%, Loss: 0.5200\n",
      "Optimization Iteration:  21761, Training Accuracy:  78.1%, Loss: 0.2907\n",
      "Optimization Iteration:  21825, Training Accuracy:  70.3%, Loss: 0.5128\n",
      "Optimization Iteration:  21889, Training Accuracy:  78.1%, Loss: 0.3650\n",
      "Optimization Iteration:  21953, Training Accuracy:  76.6%, Loss: 0.5449\n",
      "Optimization Iteration:  22017, Training Accuracy:  78.1%, Loss: 0.4371\n",
      "Optimization Iteration:  22081, Training Accuracy:  81.2%, Loss: 0.3692\n",
      "Optimization Iteration:  22145, Training Accuracy:  78.1%, Loss: 0.4416\n",
      "Optimization Iteration:  22209, Training Accuracy:  85.9%, Loss: 0.3922\n",
      "Optimization Iteration:  22273, Training Accuracy:  70.3%, Loss: 0.4657\n",
      "Optimization Iteration:  22337, Training Accuracy:  71.9%, Loss: 0.3552\n",
      "Optimization Iteration:  22401, Training Accuracy:  70.3%, Loss: 0.4641\n",
      "Optimization Iteration:  22465, Training Accuracy:  73.4%, Loss: 0.4485\n",
      "Optimization Iteration:  22529, Training Accuracy:  81.2%, Loss: 0.3394\n",
      "Optimization Iteration:  22593, Training Accuracy:  78.1%, Loss: 0.4043\n",
      "Optimization Iteration:  22657, Training Accuracy:  85.9%, Loss: 0.3551\n",
      "Optimization Iteration:  22721, Training Accuracy:  73.4%, Loss: 0.3984\n",
      "Optimization Iteration:  22785, Training Accuracy:  78.1%, Loss: 0.4089\n",
      "Optimization Iteration:  22849, Training Accuracy:  76.6%, Loss: 0.3887\n",
      "Optimization Iteration:  22913, Training Accuracy:  81.2%, Loss: 0.3655\n",
      "Optimization Iteration:  22977, Training Accuracy:  84.4%, Loss: 0.3552\n",
      "Optimization Iteration:  23041, Training Accuracy:  75.0%, Loss: 0.3777\n",
      "Optimization Iteration:  23105, Training Accuracy:  78.1%, Loss: 0.3364\n",
      "Optimization Iteration:  23169, Training Accuracy:  85.9%, Loss: 0.3887\n",
      "Optimization Iteration:  23233, Training Accuracy:  73.4%, Loss: 0.5190\n",
      "Optimization Iteration:  23297, Training Accuracy:  76.6%, Loss: 0.4262\n",
      "Optimization Iteration:  23361, Training Accuracy:  71.9%, Loss: 0.4334\n",
      "Optimization Iteration:  23425, Training Accuracy:  81.2%, Loss: 0.3758\n",
      "Optimization Iteration:  23489, Training Accuracy:  78.1%, Loss: 0.4536\n",
      "Optimization Iteration:  23553, Training Accuracy:  76.6%, Loss: 0.3822\n",
      "Optimization Iteration:  23617, Training Accuracy:  75.0%, Loss: 0.4336\n",
      "Optimization Iteration:  23681, Training Accuracy:  75.0%, Loss: 0.4313\n",
      "Optimization Iteration:  23745, Training Accuracy:  68.8%, Loss: 0.3687\n",
      "Optimization Iteration:  23809, Training Accuracy:  75.0%, Loss: 0.4281\n",
      "Optimization Iteration:  23873, Training Accuracy:  73.4%, Loss: 0.3714\n",
      "Optimization Iteration:  23937, Training Accuracy:  64.1%, Loss: 0.4523\n",
      "Optimization Iteration:  24001, Training Accuracy:  84.4%, Loss: 0.3230\n",
      "Optimization Iteration:  24065, Training Accuracy:  73.4%, Loss: 0.4343\n",
      "Optimization Iteration:  24129, Training Accuracy:  82.8%, Loss: 0.3280\n",
      "Optimization Iteration:  24193, Training Accuracy:  81.2%, Loss: 0.3540\n",
      "Optimization Iteration:  24257, Training Accuracy:  76.6%, Loss: 0.3791\n",
      "Optimization Iteration:  24321, Training Accuracy:  70.3%, Loss: 0.4500\n",
      "Optimization Iteration:  24385, Training Accuracy:  70.3%, Loss: 0.4694\n",
      "Optimization Iteration:  24449, Training Accuracy:  75.0%, Loss: 0.3932\n",
      "Optimization Iteration:  24513, Training Accuracy:  76.6%, Loss: 0.4248\n",
      "Optimization Iteration:  24577, Training Accuracy:  67.2%, Loss: 0.4762\n",
      "Optimization Iteration:  24641, Training Accuracy:  76.6%, Loss: 0.4634\n",
      "Optimization Iteration:  24705, Training Accuracy:  78.1%, Loss: 0.3965\n",
      "Optimization Iteration:  24769, Training Accuracy:  75.0%, Loss: 0.3610\n",
      "Optimization Iteration:  24833, Training Accuracy:  82.8%, Loss: 0.3580\n",
      "Optimization Iteration:  24897, Training Accuracy:  78.1%, Loss: 0.4141\n",
      "Optimization Iteration:  24961, Training Accuracy:  81.2%, Loss: 0.3408\n",
      "Optimization Iteration:  25025, Training Accuracy:  71.9%, Loss: 0.4227\n",
      "Optimization Iteration:  25089, Training Accuracy:  73.4%, Loss: 0.4456\n",
      "Optimization Iteration:  25153, Training Accuracy:  68.8%, Loss: 0.4112\n",
      "Optimization Iteration:  25217, Training Accuracy:  70.3%, Loss: 0.5191\n",
      "Optimization Iteration:  25281, Training Accuracy:  75.0%, Loss: 0.3531\n",
      "Optimization Iteration:  25345, Training Accuracy:  76.6%, Loss: 0.4902\n",
      "Optimization Iteration:  25409, Training Accuracy:  75.0%, Loss: 0.3939\n",
      "Optimization Iteration:  25473, Training Accuracy:  68.8%, Loss: 0.4783\n",
      "Optimization Iteration:  25537, Training Accuracy:  75.0%, Loss: 0.4202\n",
      "Optimization Iteration:  25601, Training Accuracy:  71.9%, Loss: 0.4489\n",
      "Optimization Iteration:  25665, Training Accuracy:  73.4%, Loss: 0.4058\n",
      "Optimization Iteration:  25729, Training Accuracy:  78.1%, Loss: 0.3241\n",
      "Optimization Iteration:  25793, Training Accuracy:  81.2%, Loss: 0.3543\n",
      "Optimization Iteration:  25857, Training Accuracy:  68.8%, Loss: 0.4738\n",
      "Optimization Iteration:  25921, Training Accuracy:  79.7%, Loss: 0.4027\n",
      "Optimization Iteration:  25985, Training Accuracy:  68.8%, Loss: 0.4956\n",
      "Optimization Iteration:  26049, Training Accuracy:  81.2%, Loss: 0.3662\n",
      "Optimization Iteration:  26113, Training Accuracy:  78.1%, Loss: 0.3302\n",
      "Optimization Iteration:  26177, Training Accuracy:  73.4%, Loss: 0.4419\n",
      "Optimization Iteration:  26241, Training Accuracy:  76.6%, Loss: 0.3598\n",
      "Optimization Iteration:  26305, Training Accuracy:  82.8%, Loss: 0.3957\n",
      "Optimization Iteration:  26369, Training Accuracy:  78.1%, Loss: 0.3471\n",
      "Optimization Iteration:  26433, Training Accuracy:  73.4%, Loss: 0.4594\n",
      "Optimization Iteration:  26497, Training Accuracy:  73.4%, Loss: 0.4578\n",
      "Optimization Iteration:  26561, Training Accuracy:  76.6%, Loss: 0.3708\n",
      "Optimization Iteration:  26625, Training Accuracy:  68.8%, Loss: 0.4982\n",
      "Optimization Iteration:  26689, Training Accuracy:  84.4%, Loss: 0.3806\n",
      "Optimization Iteration:  26753, Training Accuracy:  76.6%, Loss: 0.4415\n",
      "Optimization Iteration:  26817, Training Accuracy:  76.6%, Loss: 0.3878\n",
      "Optimization Iteration:  26881, Training Accuracy:  82.8%, Loss: 0.3114\n",
      "Optimization Iteration:  26945, Training Accuracy:  75.0%, Loss: 0.4520\n",
      "Optimization Iteration:  27009, Training Accuracy:  89.1%, Loss: 0.3137\n",
      "Optimization Iteration:  27073, Training Accuracy:  76.6%, Loss: 0.4255\n",
      "Optimization Iteration:  27137, Training Accuracy:  89.1%, Loss: 0.3844\n",
      "Optimization Iteration:  27201, Training Accuracy:  78.1%, Loss: 0.3463\n",
      "Optimization Iteration:  27265, Training Accuracy:  78.1%, Loss: 0.4189\n",
      "Optimization Iteration:  27329, Training Accuracy:  76.6%, Loss: 0.3840\n",
      "Optimization Iteration:  27393, Training Accuracy:  78.1%, Loss: 0.3820\n",
      "Optimization Iteration:  27457, Training Accuracy:  76.6%, Loss: 0.3800\n",
      "Optimization Iteration:  27521, Training Accuracy:  81.2%, Loss: 0.3975\n",
      "Optimization Iteration:  27585, Training Accuracy:  79.7%, Loss: 0.3933\n",
      "Optimization Iteration:  27649, Training Accuracy:  81.2%, Loss: 0.3399\n",
      "Optimization Iteration:  27713, Training Accuracy:  70.3%, Loss: 0.4220\n",
      "Optimization Iteration:  27777, Training Accuracy:  85.9%, Loss: 0.2964\n",
      "Optimization Iteration:  27841, Training Accuracy:  67.2%, Loss: 0.4864\n",
      "Optimization Iteration:  27905, Training Accuracy:  71.9%, Loss: 0.5444\n",
      "Optimization Iteration:  27969, Training Accuracy:  68.8%, Loss: 0.4735\n",
      "Optimization Iteration:  28033, Training Accuracy:  81.2%, Loss: 0.3822\n",
      "Optimization Iteration:  28097, Training Accuracy:  84.4%, Loss: 0.3355\n",
      "Optimization Iteration:  28161, Training Accuracy:  75.0%, Loss: 0.4079\n",
      "Optimization Iteration:  28225, Training Accuracy:  78.1%, Loss: 0.3370\n",
      "Optimization Iteration:  28289, Training Accuracy:  84.4%, Loss: 0.3342\n",
      "Optimization Iteration:  28353, Training Accuracy:  79.7%, Loss: 0.3421\n",
      "Optimization Iteration:  28417, Training Accuracy:  79.7%, Loss: 0.4425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  28481, Training Accuracy:  73.4%, Loss: 0.3368\n",
      "Optimization Iteration:  28545, Training Accuracy:  85.9%, Loss: 0.3166\n",
      "Optimization Iteration:  28609, Training Accuracy:  82.8%, Loss: 0.3598\n",
      "Optimization Iteration:  28673, Training Accuracy:  73.4%, Loss: 0.3964\n",
      "Optimization Iteration:  28737, Training Accuracy:  64.1%, Loss: 0.4478\n",
      "Optimization Iteration:  28801, Training Accuracy:  78.1%, Loss: 0.3839\n",
      "Optimization Iteration:  28865, Training Accuracy:  82.8%, Loss: 0.3892\n",
      "Optimization Iteration:  28929, Training Accuracy:  79.7%, Loss: 0.3531\n",
      "Optimization Iteration:  28993, Training Accuracy:  81.2%, Loss: 0.3910\n",
      "Optimization Iteration:  29057, Training Accuracy:  68.8%, Loss: 0.4183\n",
      "Optimization Iteration:  29121, Training Accuracy:  60.9%, Loss: 0.5492\n",
      "Optimization Iteration:  29185, Training Accuracy:  76.6%, Loss: 0.3492\n",
      "Optimization Iteration:  29249, Training Accuracy:  70.3%, Loss: 0.4109\n",
      "Optimization Iteration:  29313, Training Accuracy:  75.0%, Loss: 0.4489\n",
      "Optimization Iteration:  29377, Training Accuracy:  79.7%, Loss: 0.3481\n",
      "Optimization Iteration:  29441, Training Accuracy:  75.0%, Loss: 0.4264\n",
      "Optimization Iteration:  29505, Training Accuracy:  67.2%, Loss: 0.4750\n",
      "Optimization Iteration:  29569, Training Accuracy:  68.8%, Loss: 0.4178\n",
      "Optimization Iteration:  29633, Training Accuracy:  70.3%, Loss: 0.4496\n",
      "Optimization Iteration:  29697, Training Accuracy:  78.1%, Loss: 0.3549\n",
      "Optimization Iteration:  29761, Training Accuracy:  75.0%, Loss: 0.3961\n",
      "Optimization Iteration:  29825, Training Accuracy:  70.3%, Loss: 0.4758\n",
      "Optimization Iteration:  29889, Training Accuracy:  78.1%, Loss: 0.4270\n",
      "Optimization Iteration:  29953, Training Accuracy:  68.8%, Loss: 0.4745\n",
      "Optimization Iteration:  30017, Training Accuracy:  82.8%, Loss: 0.2815\n",
      "Optimization Iteration:  30081, Training Accuracy:  81.2%, Loss: 0.3459\n",
      "Optimization Iteration:  30145, Training Accuracy:  79.7%, Loss: 0.4249\n",
      "Optimization Iteration:  30209, Training Accuracy:  78.1%, Loss: 0.3549\n",
      "Optimization Iteration:  30273, Training Accuracy:  75.0%, Loss: 0.4069\n",
      "Optimization Iteration:  30337, Training Accuracy:  71.9%, Loss: 0.3975\n",
      "Optimization Iteration:  30401, Training Accuracy:  81.2%, Loss: 0.3919\n",
      "Optimization Iteration:  30465, Training Accuracy:  76.6%, Loss: 0.3852\n",
      "Optimization Iteration:  30529, Training Accuracy:  76.6%, Loss: 0.4568\n",
      "Optimization Iteration:  30593, Training Accuracy:  78.1%, Loss: 0.3942\n",
      "Optimization Iteration:  30657, Training Accuracy:  73.4%, Loss: 0.3699\n",
      "Optimization Iteration:  30721, Training Accuracy:  79.7%, Loss: 0.3583\n",
      "Optimization Iteration:  30785, Training Accuracy:  70.3%, Loss: 0.4000\n",
      "Optimization Iteration:  30849, Training Accuracy:  73.4%, Loss: 0.3886\n",
      "Optimization Iteration:  30913, Training Accuracy:  79.7%, Loss: 0.3611\n",
      "Optimization Iteration:  30977, Training Accuracy:  71.9%, Loss: 0.4809\n",
      "Optimization Iteration:  31041, Training Accuracy:  78.1%, Loss: 0.3778\n",
      "Optimization Iteration:  31105, Training Accuracy:  79.7%, Loss: 0.3805\n",
      "Optimization Iteration:  31169, Training Accuracy:  78.1%, Loss: 0.3218\n",
      "Optimization Iteration:  31233, Training Accuracy:  67.2%, Loss: 0.3864\n",
      "Optimization Iteration:  31297, Training Accuracy:  76.6%, Loss: 0.3354\n",
      "Optimization Iteration:  31361, Training Accuracy:  78.1%, Loss: 0.4591\n",
      "Optimization Iteration:  31425, Training Accuracy:  89.1%, Loss: 0.3120\n",
      "Optimization Iteration:  31489, Training Accuracy:  79.7%, Loss: 0.4230\n",
      "Optimization Iteration:  31553, Training Accuracy:  78.1%, Loss: 0.3979\n",
      "Optimization Iteration:  31617, Training Accuracy:  75.0%, Loss: 0.3885\n",
      "Optimization Iteration:  31681, Training Accuracy:  71.9%, Loss: 0.4986\n",
      "Optimization Iteration:  31745, Training Accuracy:  71.9%, Loss: 0.3988\n",
      "Optimization Iteration:  31809, Training Accuracy:  70.3%, Loss: 0.4464\n",
      "Optimization Iteration:  31873, Training Accuracy:  78.1%, Loss: 0.3685\n",
      "Optimization Iteration:  31937, Training Accuracy:  67.2%, Loss: 0.5093\n",
      "Optimization Iteration:  32001, Training Accuracy:  73.4%, Loss: 0.4807\n",
      "Optimization Iteration:  32065, Training Accuracy:  76.6%, Loss: 0.3611\n",
      "Optimization Iteration:  32129, Training Accuracy:  70.3%, Loss: 0.4066\n",
      "Optimization Iteration:  32193, Training Accuracy:  79.7%, Loss: 0.4765\n",
      "Optimization Iteration:  32257, Training Accuracy:  71.9%, Loss: 0.4879\n",
      "Optimization Iteration:  32321, Training Accuracy:  73.4%, Loss: 0.3599\n",
      "Optimization Iteration:  32385, Training Accuracy:  73.4%, Loss: 0.4776\n",
      "Optimization Iteration:  32449, Training Accuracy:  76.6%, Loss: 0.4146\n",
      "Optimization Iteration:  32513, Training Accuracy:  73.4%, Loss: 0.3676\n",
      "Optimization Iteration:  32577, Training Accuracy:  76.6%, Loss: 0.3654\n",
      "Optimization Iteration:  32641, Training Accuracy:  79.7%, Loss: 0.4212\n",
      "Optimization Iteration:  32705, Training Accuracy:  79.7%, Loss: 0.3970\n",
      "Optimization Iteration:  32769, Training Accuracy:  79.7%, Loss: 0.3534\n",
      "Optimization Iteration:  32833, Training Accuracy:  81.2%, Loss: 0.3861\n",
      "Optimization Iteration:  32897, Training Accuracy:  78.1%, Loss: 0.3963\n",
      "Optimization Iteration:  32961, Training Accuracy:  70.3%, Loss: 0.4806\n",
      "Optimization Iteration:  33025, Training Accuracy:  71.9%, Loss: 0.3676\n",
      "Optimization Iteration:  33089, Training Accuracy:  81.2%, Loss: 0.4554\n",
      "Optimization Iteration:  33153, Training Accuracy:  75.0%, Loss: 0.3978\n",
      "Optimization Iteration:  33217, Training Accuracy:  79.7%, Loss: 0.3430\n",
      "Optimization Iteration:  33281, Training Accuracy:  65.6%, Loss: 0.5081\n",
      "Optimization Iteration:  33345, Training Accuracy:  73.4%, Loss: 0.4142\n",
      "Optimization Iteration:  33409, Training Accuracy:  82.8%, Loss: 0.4045\n",
      "Optimization Iteration:  33473, Training Accuracy:  71.9%, Loss: 0.4869\n",
      "Optimization Iteration:  33537, Training Accuracy:  76.6%, Loss: 0.3974\n",
      "Optimization Iteration:  33601, Training Accuracy:  73.4%, Loss: 0.4404\n",
      "Optimization Iteration:  33665, Training Accuracy:  75.0%, Loss: 0.4313\n",
      "Optimization Iteration:  33729, Training Accuracy:  75.0%, Loss: 0.4345\n",
      "Optimization Iteration:  33793, Training Accuracy:  70.3%, Loss: 0.5113\n",
      "Optimization Iteration:  33857, Training Accuracy:  78.1%, Loss: 0.3814\n",
      "Optimization Iteration:  33921, Training Accuracy:  76.6%, Loss: 0.3848\n",
      "Optimization Iteration:  33985, Training Accuracy:  78.1%, Loss: 0.3315\n",
      "Optimization Iteration:  34049, Training Accuracy:  71.9%, Loss: 0.4458\n",
      "Optimization Iteration:  34113, Training Accuracy:  70.3%, Loss: 0.4127\n",
      "Optimization Iteration:  34177, Training Accuracy:  71.9%, Loss: 0.3714\n",
      "Optimization Iteration:  34241, Training Accuracy:  71.9%, Loss: 0.4485\n",
      "Optimization Iteration:  34305, Training Accuracy:  76.6%, Loss: 0.4068\n",
      "Optimization Iteration:  34369, Training Accuracy:  81.2%, Loss: 0.3332\n",
      "Optimization Iteration:  34433, Training Accuracy:  78.1%, Loss: 0.4717\n",
      "Optimization Iteration:  34497, Training Accuracy:  82.8%, Loss: 0.3405\n",
      "Optimization Iteration:  34561, Training Accuracy:  82.8%, Loss: 0.4180\n",
      "Optimization Iteration:  34625, Training Accuracy:  70.3%, Loss: 0.5502\n",
      "Optimization Iteration:  34689, Training Accuracy:  84.4%, Loss: 0.3857\n",
      "Optimization Iteration:  34753, Training Accuracy:  71.9%, Loss: 0.4737\n",
      "Optimization Iteration:  34817, Training Accuracy:  82.8%, Loss: 0.4338\n",
      "Optimization Iteration:  34881, Training Accuracy:  79.7%, Loss: 0.3408\n",
      "Optimization Iteration:  34945, Training Accuracy:  76.6%, Loss: 0.4007\n",
      "Optimization Iteration:  35009, Training Accuracy:  79.7%, Loss: 0.3775\n",
      "Optimization Iteration:  35073, Training Accuracy:  76.6%, Loss: 0.4076\n",
      "Optimization Iteration:  35137, Training Accuracy:  78.1%, Loss: 0.3834\n",
      "Optimization Iteration:  35201, Training Accuracy:  75.0%, Loss: 0.3907\n",
      "Optimization Iteration:  35265, Training Accuracy:  75.0%, Loss: 0.4097\n",
      "Optimization Iteration:  35329, Training Accuracy:  70.3%, Loss: 0.4084\n",
      "Optimization Iteration:  35393, Training Accuracy:  67.2%, Loss: 0.3882\n",
      "Optimization Iteration:  35457, Training Accuracy:  76.6%, Loss: 0.3850\n",
      "Optimization Iteration:  35521, Training Accuracy:  76.6%, Loss: 0.4007\n",
      "Optimization Iteration:  35585, Training Accuracy:  79.7%, Loss: 0.4209\n",
      "Optimization Iteration:  35649, Training Accuracy:  75.0%, Loss: 0.4304\n",
      "Optimization Iteration:  35713, Training Accuracy:  85.9%, Loss: 0.3551\n",
      "Optimization Iteration:  35777, Training Accuracy:  90.6%, Loss: 0.3009\n",
      "Optimization Iteration:  35841, Training Accuracy:  82.8%, Loss: 0.3389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  35905, Training Accuracy:  79.7%, Loss: 0.4074\n",
      "Optimization Iteration:  35969, Training Accuracy:  68.8%, Loss: 0.4443\n",
      "Optimization Iteration:  36033, Training Accuracy:  70.3%, Loss: 0.4629\n",
      "Optimization Iteration:  36097, Training Accuracy:  70.3%, Loss: 0.4571\n",
      "Optimization Iteration:  36161, Training Accuracy:  79.7%, Loss: 0.3667\n",
      "Optimization Iteration:  36225, Training Accuracy:  78.1%, Loss: 0.3363\n",
      "Optimization Iteration:  36289, Training Accuracy:  79.7%, Loss: 0.3147\n",
      "Optimization Iteration:  36353, Training Accuracy:  79.7%, Loss: 0.3579\n",
      "Optimization Iteration:  36417, Training Accuracy:  85.9%, Loss: 0.3221\n",
      "Optimization Iteration:  36481, Training Accuracy:  81.2%, Loss: 0.3573\n",
      "Optimization Iteration:  36545, Training Accuracy:  82.8%, Loss: 0.3687\n",
      "Optimization Iteration:  36609, Training Accuracy:  71.9%, Loss: 0.4408\n",
      "Optimization Iteration:  36673, Training Accuracy:  78.1%, Loss: 0.3923\n",
      "Optimization Iteration:  36737, Training Accuracy:  76.6%, Loss: 0.3563\n",
      "Optimization Iteration:  36801, Training Accuracy:  84.4%, Loss: 0.3626\n",
      "Optimization Iteration:  36865, Training Accuracy:  75.0%, Loss: 0.4180\n",
      "Optimization Iteration:  36929, Training Accuracy:  67.2%, Loss: 0.4673\n",
      "Optimization Iteration:  36993, Training Accuracy:  75.0%, Loss: 0.4077\n",
      "Optimization Iteration:  37057, Training Accuracy:  82.8%, Loss: 0.3279\n",
      "Optimization Iteration:  37121, Training Accuracy:  81.2%, Loss: 0.3389\n",
      "Optimization Iteration:  37185, Training Accuracy:  82.8%, Loss: 0.3572\n",
      "Optimization Iteration:  37249, Training Accuracy:  70.3%, Loss: 0.4973\n",
      "Optimization Iteration:  37313, Training Accuracy:  71.9%, Loss: 0.3404\n",
      "Optimization Iteration:  37377, Training Accuracy:  79.7%, Loss: 0.4158\n",
      "Optimization Iteration:  37441, Training Accuracy:  68.8%, Loss: 0.4056\n",
      "Optimization Iteration:  37505, Training Accuracy:  73.4%, Loss: 0.4622\n",
      "Optimization Iteration:  37569, Training Accuracy:  71.9%, Loss: 0.4112\n",
      "Optimization Iteration:  37633, Training Accuracy:  64.1%, Loss: 0.5210\n",
      "Optimization Iteration:  37697, Training Accuracy:  78.1%, Loss: 0.3835\n",
      "Optimization Iteration:  37761, Training Accuracy:  70.3%, Loss: 0.4318\n",
      "Optimization Iteration:  37825, Training Accuracy:  75.0%, Loss: 0.3588\n",
      "Optimization Iteration:  37889, Training Accuracy:  76.6%, Loss: 0.4604\n",
      "Optimization Iteration:  37953, Training Accuracy:  73.4%, Loss: 0.3900\n",
      "Optimization Iteration:  38017, Training Accuracy:  67.2%, Loss: 0.4769\n",
      "Optimization Iteration:  38081, Training Accuracy:  64.1%, Loss: 0.4575\n",
      "Optimization Iteration:  38145, Training Accuracy:  75.0%, Loss: 0.3470\n",
      "Optimization Iteration:  38209, Training Accuracy:  81.2%, Loss: 0.4138\n",
      "Optimization Iteration:  38273, Training Accuracy:  85.9%, Loss: 0.3552\n",
      "Optimization Iteration:  38337, Training Accuracy:  81.2%, Loss: 0.3485\n",
      "Optimization Iteration:  38401, Training Accuracy:  73.4%, Loss: 0.4237\n",
      "Optimization Iteration:  38465, Training Accuracy:  68.8%, Loss: 0.4485\n",
      "Optimization Iteration:  38529, Training Accuracy:  84.4%, Loss: 0.3745\n",
      "Optimization Iteration:  38593, Training Accuracy:  65.6%, Loss: 0.5130\n",
      "Optimization Iteration:  38657, Training Accuracy:  68.8%, Loss: 0.4763\n",
      "Optimization Iteration:  38721, Training Accuracy:  73.4%, Loss: 0.3541\n",
      "Optimization Iteration:  38785, Training Accuracy:  73.4%, Loss: 0.4207\n",
      "Optimization Iteration:  38849, Training Accuracy:  84.4%, Loss: 0.3087\n",
      "Optimization Iteration:  38913, Training Accuracy:  73.4%, Loss: 0.3509\n",
      "Optimization Iteration:  38977, Training Accuracy:  73.4%, Loss: 0.4435\n",
      "Optimization Iteration:  39041, Training Accuracy:  79.7%, Loss: 0.4043\n",
      "Optimization Iteration:  39105, Training Accuracy:  73.4%, Loss: 0.4624\n",
      "Optimization Iteration:  39169, Training Accuracy:  75.0%, Loss: 0.4173\n",
      "Optimization Iteration:  39233, Training Accuracy:  68.8%, Loss: 0.5102\n",
      "Optimization Iteration:  39297, Training Accuracy:  65.6%, Loss: 0.3997\n",
      "Optimization Iteration:  39361, Training Accuracy:  78.1%, Loss: 0.3446\n",
      "Optimization Iteration:  39425, Training Accuracy:  73.4%, Loss: 0.4656\n",
      "Optimization Iteration:  39489, Training Accuracy:  79.7%, Loss: 0.3753\n",
      "Optimization Iteration:  39553, Training Accuracy:  81.2%, Loss: 0.3354\n",
      "Optimization Iteration:  39617, Training Accuracy:  81.2%, Loss: 0.4044\n",
      "Optimization Iteration:  39681, Training Accuracy:  67.2%, Loss: 0.4129\n",
      "Optimization Iteration:  39745, Training Accuracy:  65.6%, Loss: 0.4715\n",
      "Optimization Iteration:  39809, Training Accuracy:  73.4%, Loss: 0.4692\n",
      "Optimization Iteration:  39873, Training Accuracy:  71.9%, Loss: 0.3889\n",
      "Optimization Iteration:  39937, Training Accuracy:  76.6%, Loss: 0.4784\n",
      "Optimization Iteration:  40001, Training Accuracy:  78.1%, Loss: 0.3696\n",
      "Optimization Iteration:  40065, Training Accuracy:  67.2%, Loss: 0.3747\n",
      "Optimization Iteration:  40129, Training Accuracy:  73.4%, Loss: 0.3896\n",
      "Optimization Iteration:  40193, Training Accuracy:  84.4%, Loss: 0.3272\n",
      "Optimization Iteration:  40257, Training Accuracy:  73.4%, Loss: 0.3937\n",
      "Optimization Iteration:  40321, Training Accuracy:  62.5%, Loss: 0.4500\n",
      "Optimization Iteration:  40385, Training Accuracy:  73.4%, Loss: 0.3980\n",
      "Optimization Iteration:  40449, Training Accuracy:  76.6%, Loss: 0.3838\n",
      "Optimization Iteration:  40513, Training Accuracy:  84.4%, Loss: 0.3945\n",
      "Optimization Iteration:  40577, Training Accuracy:  75.0%, Loss: 0.4143\n",
      "Optimization Iteration:  40641, Training Accuracy:  81.2%, Loss: 0.3214\n",
      "Optimization Iteration:  40705, Training Accuracy:  76.6%, Loss: 0.3941\n",
      "Optimization Iteration:  40769, Training Accuracy:  71.9%, Loss: 0.3921\n",
      "Optimization Iteration:  40833, Training Accuracy:  79.7%, Loss: 0.3316\n",
      "Optimization Iteration:  40897, Training Accuracy:  76.6%, Loss: 0.4081\n",
      "Optimization Iteration:  40961, Training Accuracy:  82.8%, Loss: 0.3922\n",
      "Optimization Iteration:  41025, Training Accuracy:  79.7%, Loss: 0.4304\n",
      "Optimization Iteration:  41089, Training Accuracy:  81.2%, Loss: 0.3581\n",
      "Optimization Iteration:  41153, Training Accuracy:  70.3%, Loss: 0.4434\n",
      "Optimization Iteration:  41217, Training Accuracy:  79.7%, Loss: 0.3774\n",
      "Optimization Iteration:  41281, Training Accuracy:  67.2%, Loss: 0.4145\n",
      "Optimization Iteration:  41345, Training Accuracy:  76.6%, Loss: 0.4231\n",
      "Optimization Iteration:  41409, Training Accuracy:  76.6%, Loss: 0.4072\n",
      "Optimization Iteration:  41473, Training Accuracy:  79.7%, Loss: 0.4068\n",
      "Optimization Iteration:  41537, Training Accuracy:  64.1%, Loss: 0.4564\n",
      "Optimization Iteration:  41601, Training Accuracy:  76.6%, Loss: 0.4030\n",
      "Optimization Iteration:  41665, Training Accuracy:  71.9%, Loss: 0.3984\n",
      "Optimization Iteration:  41729, Training Accuracy:  76.6%, Loss: 0.3820\n",
      "Optimization Iteration:  41793, Training Accuracy:  75.0%, Loss: 0.4381\n",
      "Optimization Iteration:  41857, Training Accuracy:  68.8%, Loss: 0.4774\n",
      "Optimization Iteration:  41921, Training Accuracy:  79.7%, Loss: 0.3839\n",
      "Optimization Iteration:  41985, Training Accuracy:  71.9%, Loss: 0.4665\n",
      "Optimization Iteration:  42049, Training Accuracy:  71.9%, Loss: 0.4602\n",
      "Optimization Iteration:  42113, Training Accuracy:  81.2%, Loss: 0.3725\n",
      "Optimization Iteration:  42177, Training Accuracy:  75.0%, Loss: 0.3953\n",
      "Optimization Iteration:  42241, Training Accuracy:  79.7%, Loss: 0.3969\n",
      "Optimization Iteration:  42305, Training Accuracy:  67.2%, Loss: 0.4927\n",
      "Optimization Iteration:  42369, Training Accuracy:  81.2%, Loss: 0.3707\n",
      "Optimization Iteration:  42433, Training Accuracy:  67.2%, Loss: 0.4956\n",
      "Optimization Iteration:  42497, Training Accuracy:  70.3%, Loss: 0.4111\n",
      "Optimization Iteration:  42561, Training Accuracy:  78.1%, Loss: 0.4025\n",
      "Optimization Iteration:  42625, Training Accuracy:  76.6%, Loss: 0.3545\n",
      "Optimization Iteration:  42689, Training Accuracy:  75.0%, Loss: 0.3613\n",
      "Optimization Iteration:  42753, Training Accuracy:  67.2%, Loss: 0.4762\n",
      "Optimization Iteration:  42817, Training Accuracy:  81.2%, Loss: 0.3642\n",
      "Optimization Iteration:  42881, Training Accuracy:  73.4%, Loss: 0.4696\n",
      "Optimization Iteration:  42945, Training Accuracy:  68.8%, Loss: 0.4615\n",
      "Optimization Iteration:  43009, Training Accuracy:  81.2%, Loss: 0.3453\n",
      "Optimization Iteration:  43073, Training Accuracy:  79.7%, Loss: 0.3951\n",
      "Optimization Iteration:  43137, Training Accuracy:  78.1%, Loss: 0.3576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  43201, Training Accuracy:  84.4%, Loss: 0.3731\n",
      "Optimization Iteration:  43265, Training Accuracy:  70.3%, Loss: 0.4427\n",
      "Optimization Iteration:  43329, Training Accuracy:  75.0%, Loss: 0.3960\n",
      "Optimization Iteration:  43393, Training Accuracy:  70.3%, Loss: 0.4054\n",
      "Optimization Iteration:  43457, Training Accuracy:  73.4%, Loss: 0.3949\n",
      "Optimization Iteration:  43521, Training Accuracy:  79.7%, Loss: 0.4152\n",
      "Optimization Iteration:  43585, Training Accuracy:  79.7%, Loss: 0.3510\n",
      "Optimization Iteration:  43649, Training Accuracy:  70.3%, Loss: 0.4869\n",
      "Optimization Iteration:  43713, Training Accuracy:  82.8%, Loss: 0.3676\n",
      "Optimization Iteration:  43777, Training Accuracy:  76.6%, Loss: 0.3253\n",
      "Optimization Iteration:  43841, Training Accuracy:  78.1%, Loss: 0.4031\n",
      "Optimization Iteration:  43905, Training Accuracy:  82.8%, Loss: 0.3181\n",
      "Optimization Iteration:  43969, Training Accuracy:  85.9%, Loss: 0.2979\n",
      "Optimization Iteration:  44033, Training Accuracy:  71.9%, Loss: 0.4614\n",
      "Optimization Iteration:  44097, Training Accuracy:  78.1%, Loss: 0.3255\n",
      "Optimization Iteration:  44161, Training Accuracy:  81.2%, Loss: 0.3327\n",
      "Optimization Iteration:  44225, Training Accuracy:  75.0%, Loss: 0.4113\n",
      "Optimization Iteration:  44289, Training Accuracy:  75.0%, Loss: 0.5035\n",
      "Optimization Iteration:  44353, Training Accuracy:  75.0%, Loss: 0.4551\n",
      "Optimization Iteration:  44417, Training Accuracy:  78.1%, Loss: 0.4081\n",
      "Optimization Iteration:  44481, Training Accuracy:  65.6%, Loss: 0.4518\n",
      "Optimization Iteration:  44545, Training Accuracy:  79.7%, Loss: 0.3081\n",
      "Optimization Iteration:  44609, Training Accuracy:  84.4%, Loss: 0.3497\n",
      "Optimization Iteration:  44673, Training Accuracy:  82.8%, Loss: 0.4391\n",
      "Optimization Iteration:  44737, Training Accuracy:  71.9%, Loss: 0.3937\n",
      "Optimization Iteration:  44801, Training Accuracy:  65.6%, Loss: 0.4320\n",
      "Optimization Iteration:  44865, Training Accuracy:  73.4%, Loss: 0.4192\n",
      "Optimization Iteration:  44929, Training Accuracy:  81.2%, Loss: 0.3184\n",
      "Optimization Iteration:  44993, Training Accuracy:  78.1%, Loss: 0.4430\n",
      "Optimization Iteration:  45057, Training Accuracy:  81.2%, Loss: 0.3843\n",
      "Optimization Iteration:  45121, Training Accuracy:  82.8%, Loss: 0.3449\n",
      "Optimization Iteration:  45185, Training Accuracy:  71.9%, Loss: 0.3499\n",
      "Optimization Iteration:  45249, Training Accuracy:  79.7%, Loss: 0.4225\n",
      "Optimization Iteration:  45313, Training Accuracy:  79.7%, Loss: 0.4022\n",
      "Optimization Iteration:  45377, Training Accuracy:  75.0%, Loss: 0.4411\n",
      "Optimization Iteration:  45441, Training Accuracy:  79.7%, Loss: 0.4046\n",
      "Optimization Iteration:  45505, Training Accuracy:  71.9%, Loss: 0.3845\n",
      "Optimization Iteration:  45569, Training Accuracy:  67.2%, Loss: 0.4986\n",
      "Optimization Iteration:  45633, Training Accuracy:  78.1%, Loss: 0.4148\n",
      "Optimization Iteration:  45697, Training Accuracy:  78.1%, Loss: 0.3890\n",
      "Optimization Iteration:  45761, Training Accuracy:  81.2%, Loss: 0.3122\n",
      "Optimization Iteration:  45825, Training Accuracy:  71.9%, Loss: 0.4131\n",
      "Optimization Iteration:  45889, Training Accuracy:  70.3%, Loss: 0.4011\n",
      "Optimization Iteration:  45953, Training Accuracy:  75.0%, Loss: 0.3841\n",
      "Optimization Iteration:  46017, Training Accuracy:  73.4%, Loss: 0.4181\n",
      "Optimization Iteration:  46081, Training Accuracy:  78.1%, Loss: 0.3704\n",
      "Optimization Iteration:  46145, Training Accuracy:  81.2%, Loss: 0.3968\n",
      "Optimization Iteration:  46209, Training Accuracy:  85.9%, Loss: 0.3502\n",
      "Optimization Iteration:  46273, Training Accuracy:  73.4%, Loss: 0.4284\n",
      "Optimization Iteration:  46337, Training Accuracy:  79.7%, Loss: 0.3963\n",
      "Optimization Iteration:  46401, Training Accuracy:  73.4%, Loss: 0.3839\n",
      "Optimization Iteration:  46465, Training Accuracy:  71.9%, Loss: 0.4075\n",
      "Optimization Iteration:  46529, Training Accuracy:  73.4%, Loss: 0.3937\n",
      "Optimization Iteration:  46593, Training Accuracy:  71.9%, Loss: 0.4612\n",
      "Optimization Iteration:  46657, Training Accuracy:  76.6%, Loss: 0.4335\n",
      "Optimization Iteration:  46721, Training Accuracy:  78.1%, Loss: 0.4046\n",
      "Optimization Iteration:  46785, Training Accuracy:  68.8%, Loss: 0.5150\n",
      "Optimization Iteration:  46849, Training Accuracy:  82.8%, Loss: 0.3187\n",
      "Optimization Iteration:  46913, Training Accuracy:  87.5%, Loss: 0.3496\n",
      "Optimization Iteration:  46977, Training Accuracy:  71.9%, Loss: 0.4330\n",
      "Optimization Iteration:  47041, Training Accuracy:  78.1%, Loss: 0.3486\n",
      "Optimization Iteration:  47105, Training Accuracy:  65.6%, Loss: 0.4725\n",
      "Optimization Iteration:  47169, Training Accuracy:  68.8%, Loss: 0.4174\n",
      "Optimization Iteration:  47233, Training Accuracy:  73.4%, Loss: 0.4400\n",
      "Optimization Iteration:  47297, Training Accuracy:  70.3%, Loss: 0.3820\n",
      "Optimization Iteration:  47361, Training Accuracy:  73.4%, Loss: 0.3866\n",
      "Optimization Iteration:  47425, Training Accuracy:  78.1%, Loss: 0.3754\n",
      "Optimization Iteration:  47489, Training Accuracy:  82.8%, Loss: 0.3779\n",
      "Optimization Iteration:  47553, Training Accuracy:  73.4%, Loss: 0.4361\n",
      "Optimization Iteration:  47617, Training Accuracy:  79.7%, Loss: 0.3768\n",
      "Optimization Iteration:  47681, Training Accuracy:  79.7%, Loss: 0.3690\n",
      "Optimization Iteration:  47745, Training Accuracy:  68.8%, Loss: 0.4163\n",
      "Optimization Iteration:  47809, Training Accuracy:  68.8%, Loss: 0.4808\n",
      "Optimization Iteration:  47873, Training Accuracy:  78.1%, Loss: 0.3112\n",
      "Optimization Iteration:  47937, Training Accuracy:  70.3%, Loss: 0.4657\n",
      "Optimization Iteration:  48001, Training Accuracy:  76.6%, Loss: 0.4212\n",
      "Optimization Iteration:  48065, Training Accuracy:  76.6%, Loss: 0.3571\n",
      "Optimization Iteration:  48129, Training Accuracy:  82.8%, Loss: 0.4216\n",
      "Optimization Iteration:  48193, Training Accuracy:  68.8%, Loss: 0.5091\n",
      "Optimization Iteration:  48257, Training Accuracy:  73.4%, Loss: 0.3586\n",
      "Optimization Iteration:  48321, Training Accuracy:  82.8%, Loss: 0.3199\n",
      "Optimization Iteration:  48385, Training Accuracy:  82.8%, Loss: 0.3115\n",
      "Optimization Iteration:  48449, Training Accuracy:  70.3%, Loss: 0.4413\n",
      "Optimization Iteration:  48513, Training Accuracy:  71.9%, Loss: 0.3994\n",
      "Optimization Iteration:  48577, Training Accuracy:  67.2%, Loss: 0.4761\n",
      "Optimization Iteration:  48641, Training Accuracy:  78.1%, Loss: 0.3780\n",
      "Optimization Iteration:  48705, Training Accuracy:  81.2%, Loss: 0.4233\n",
      "Optimization Iteration:  48769, Training Accuracy:  81.2%, Loss: 0.3638\n",
      "Optimization Iteration:  48833, Training Accuracy:  78.1%, Loss: 0.3667\n",
      "Optimization Iteration:  48897, Training Accuracy:  75.0%, Loss: 0.4289\n",
      "Optimization Iteration:  48961, Training Accuracy:  82.8%, Loss: 0.4399\n",
      "Optimization Iteration:  49025, Training Accuracy:  76.6%, Loss: 0.4992\n",
      "Optimization Iteration:  49089, Training Accuracy:  78.1%, Loss: 0.3465\n",
      "Optimization Iteration:  49153, Training Accuracy:  78.1%, Loss: 0.3525\n",
      "Optimization Iteration:  49217, Training Accuracy:  78.1%, Loss: 0.3760\n",
      "Optimization Iteration:  49281, Training Accuracy:  71.9%, Loss: 0.4532\n",
      "Optimization Iteration:  49345, Training Accuracy:  71.9%, Loss: 0.4036\n",
      "Optimization Iteration:  49409, Training Accuracy:  73.4%, Loss: 0.4338\n",
      "Optimization Iteration:  49473, Training Accuracy:  75.0%, Loss: 0.3814\n",
      "Optimization Iteration:  49537, Training Accuracy:  73.4%, Loss: 0.4274\n",
      "Optimization Iteration:  49601, Training Accuracy:  70.3%, Loss: 0.4764\n",
      "Optimization Iteration:  49665, Training Accuracy:  85.9%, Loss: 0.2982\n",
      "Optimization Iteration:  49729, Training Accuracy:  71.9%, Loss: 0.4564\n",
      "Optimization Iteration:  49793, Training Accuracy:  71.9%, Loss: 0.4017\n",
      "Optimization Iteration:  49857, Training Accuracy:  70.3%, Loss: 0.4641\n",
      "Optimization Iteration:  49921, Training Accuracy:  81.2%, Loss: 0.3553\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 17\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  75.0%, Loss: 0.4556\n",
      "Optimization Iteration:    129, Training Accuracy:  78.1%, Loss: 0.4349\n",
      "Optimization Iteration:    193, Training Accuracy:  78.1%, Loss: 0.4348\n",
      "Optimization Iteration:    257, Training Accuracy:  68.8%, Loss: 0.3911\n",
      "Optimization Iteration:    321, Training Accuracy:  78.1%, Loss: 0.3746\n",
      "Optimization Iteration:    385, Training Accuracy:  75.0%, Loss: 0.3536\n",
      "Optimization Iteration:    449, Training Accuracy:  79.7%, Loss: 0.3557\n",
      "Optimization Iteration:    513, Training Accuracy:  75.0%, Loss: 0.4528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    577, Training Accuracy:  59.4%, Loss: 0.5023\n",
      "Optimization Iteration:    641, Training Accuracy:  81.2%, Loss: 0.3735\n",
      "Optimization Iteration:    705, Training Accuracy:  78.1%, Loss: 0.3923\n",
      "Optimization Iteration:    769, Training Accuracy:  71.9%, Loss: 0.4041\n",
      "Optimization Iteration:    833, Training Accuracy:  76.6%, Loss: 0.3790\n",
      "Optimization Iteration:    897, Training Accuracy:  81.2%, Loss: 0.3278\n",
      "Optimization Iteration:    961, Training Accuracy:  84.4%, Loss: 0.3275\n",
      "Optimization Iteration:   1025, Training Accuracy:  78.1%, Loss: 0.3360\n",
      "Optimization Iteration:   1089, Training Accuracy:  62.5%, Loss: 0.4576\n",
      "Optimization Iteration:   1153, Training Accuracy:  67.2%, Loss: 0.4553\n",
      "Optimization Iteration:   1217, Training Accuracy:  81.2%, Loss: 0.3023\n",
      "Optimization Iteration:   1281, Training Accuracy:  75.0%, Loss: 0.4042\n",
      "Optimization Iteration:   1345, Training Accuracy:  68.8%, Loss: 0.4926\n",
      "Optimization Iteration:   1409, Training Accuracy:  78.1%, Loss: 0.4343\n",
      "Optimization Iteration:   1473, Training Accuracy:  70.3%, Loss: 0.4755\n",
      "Optimization Iteration:   1537, Training Accuracy:  73.4%, Loss: 0.3800\n",
      "Optimization Iteration:   1601, Training Accuracy:  81.2%, Loss: 0.2896\n",
      "Optimization Iteration:   1665, Training Accuracy:  68.8%, Loss: 0.3585\n",
      "Optimization Iteration:   1729, Training Accuracy:  82.8%, Loss: 0.3121\n",
      "Optimization Iteration:   1793, Training Accuracy:  67.2%, Loss: 0.4070\n",
      "Optimization Iteration:   1857, Training Accuracy:  75.0%, Loss: 0.3627\n",
      "Optimization Iteration:   1921, Training Accuracy:  67.2%, Loss: 0.4803\n",
      "Optimization Iteration:   1985, Training Accuracy:  73.4%, Loss: 0.4288\n",
      "Optimization Iteration:   2049, Training Accuracy:  85.9%, Loss: 0.3206\n",
      "Optimization Iteration:   2113, Training Accuracy:  78.1%, Loss: 0.3817\n",
      "Optimization Iteration:   2177, Training Accuracy:  78.1%, Loss: 0.3659\n",
      "Optimization Iteration:   2241, Training Accuracy:  71.9%, Loss: 0.4187\n",
      "Optimization Iteration:   2305, Training Accuracy:  75.0%, Loss: 0.3738\n",
      "Optimization Iteration:   2369, Training Accuracy:  78.1%, Loss: 0.4048\n",
      "Optimization Iteration:   2433, Training Accuracy:  76.6%, Loss: 0.4081\n",
      "Optimization Iteration:   2497, Training Accuracy:  73.4%, Loss: 0.3701\n",
      "Optimization Iteration:   2561, Training Accuracy:  76.6%, Loss: 0.3404\n",
      "Optimization Iteration:   2625, Training Accuracy:  78.1%, Loss: 0.4157\n",
      "Optimization Iteration:   2689, Training Accuracy:  76.6%, Loss: 0.3875\n",
      "Optimization Iteration:   2753, Training Accuracy:  78.1%, Loss: 0.3384\n",
      "Optimization Iteration:   2817, Training Accuracy:  76.6%, Loss: 0.3900\n",
      "Optimization Iteration:   2881, Training Accuracy:  76.6%, Loss: 0.3863\n",
      "Optimization Iteration:   2945, Training Accuracy:  75.0%, Loss: 0.5121\n",
      "Optimization Iteration:   3009, Training Accuracy:  82.8%, Loss: 0.3761\n",
      "Optimization Iteration:   3073, Training Accuracy:  79.7%, Loss: 0.3723\n",
      "Optimization Iteration:   3137, Training Accuracy:  75.0%, Loss: 0.3445\n",
      "Optimization Iteration:   3201, Training Accuracy:  79.7%, Loss: 0.3488\n",
      "Optimization Iteration:   3265, Training Accuracy:  82.8%, Loss: 0.3645\n",
      "Optimization Iteration:   3329, Training Accuracy:  87.5%, Loss: 0.3240\n",
      "Optimization Iteration:   3393, Training Accuracy:  71.9%, Loss: 0.3826\n",
      "Optimization Iteration:   3457, Training Accuracy:  82.8%, Loss: 0.3183\n",
      "Optimization Iteration:   3521, Training Accuracy:  73.4%, Loss: 0.4310\n",
      "Optimization Iteration:   3585, Training Accuracy:  70.3%, Loss: 0.4413\n",
      "Optimization Iteration:   3649, Training Accuracy:  78.1%, Loss: 0.4159\n",
      "Optimization Iteration:   3713, Training Accuracy:  64.1%, Loss: 0.3944\n",
      "Optimization Iteration:   3777, Training Accuracy:  71.9%, Loss: 0.4187\n",
      "Optimization Iteration:   3841, Training Accuracy:  67.2%, Loss: 0.4546\n",
      "Optimization Iteration:   3905, Training Accuracy:  84.4%, Loss: 0.3351\n",
      "Optimization Iteration:   3969, Training Accuracy:  75.0%, Loss: 0.4397\n",
      "Optimization Iteration:   4033, Training Accuracy:  79.7%, Loss: 0.3102\n",
      "Optimization Iteration:   4097, Training Accuracy:  73.4%, Loss: 0.4124\n",
      "Optimization Iteration:   4161, Training Accuracy:  73.4%, Loss: 0.4183\n",
      "Optimization Iteration:   4225, Training Accuracy:  89.1%, Loss: 0.2812\n",
      "Optimization Iteration:   4289, Training Accuracy:  73.4%, Loss: 0.3616\n",
      "Optimization Iteration:   4353, Training Accuracy:  81.2%, Loss: 0.4158\n",
      "Optimization Iteration:   4417, Training Accuracy:  78.1%, Loss: 0.3820\n",
      "Optimization Iteration:   4481, Training Accuracy:  70.3%, Loss: 0.3858\n",
      "Optimization Iteration:   4545, Training Accuracy:  75.0%, Loss: 0.4159\n",
      "Optimization Iteration:   4609, Training Accuracy:  81.2%, Loss: 0.3470\n",
      "Optimization Iteration:   4673, Training Accuracy:  81.2%, Loss: 0.4347\n",
      "Optimization Iteration:   4737, Training Accuracy:  73.4%, Loss: 0.4390\n",
      "Optimization Iteration:   4801, Training Accuracy:  73.4%, Loss: 0.4421\n",
      "Optimization Iteration:   4865, Training Accuracy:  75.0%, Loss: 0.3840\n",
      "Optimization Iteration:   4929, Training Accuracy:  75.0%, Loss: 0.4321\n",
      "Optimization Iteration:   4993, Training Accuracy:  75.0%, Loss: 0.3819\n",
      "Optimization Iteration:   5057, Training Accuracy:  73.4%, Loss: 0.4102\n",
      "Optimization Iteration:   5121, Training Accuracy:  81.2%, Loss: 0.3361\n",
      "Optimization Iteration:   5185, Training Accuracy:  76.6%, Loss: 0.4012\n",
      "Optimization Iteration:   5249, Training Accuracy:  65.6%, Loss: 0.5329\n",
      "Optimization Iteration:   5313, Training Accuracy:  92.2%, Loss: 0.3571\n",
      "Optimization Iteration:   5377, Training Accuracy:  76.6%, Loss: 0.3638\n",
      "Optimization Iteration:   5441, Training Accuracy:  75.0%, Loss: 0.3456\n",
      "Optimization Iteration:   5505, Training Accuracy:  78.1%, Loss: 0.3440\n",
      "Optimization Iteration:   5569, Training Accuracy:  76.6%, Loss: 0.3890\n",
      "Optimization Iteration:   5633, Training Accuracy:  78.1%, Loss: 0.3901\n",
      "Optimization Iteration:   5697, Training Accuracy:  75.0%, Loss: 0.4274\n",
      "Optimization Iteration:   5761, Training Accuracy:  84.4%, Loss: 0.3251\n",
      "Optimization Iteration:   5825, Training Accuracy:  65.6%, Loss: 0.4208\n",
      "Optimization Iteration:   5889, Training Accuracy:  75.0%, Loss: 0.4129\n",
      "Optimization Iteration:   5953, Training Accuracy:  73.4%, Loss: 0.4823\n",
      "Optimization Iteration:   6017, Training Accuracy:  68.8%, Loss: 0.4883\n",
      "Optimization Iteration:   6081, Training Accuracy:  78.1%, Loss: 0.3765\n",
      "Optimization Iteration:   6145, Training Accuracy:  59.4%, Loss: 0.5999\n",
      "Optimization Iteration:   6209, Training Accuracy:  78.1%, Loss: 0.3521\n",
      "Optimization Iteration:   6273, Training Accuracy:  79.7%, Loss: 0.3729\n",
      "Optimization Iteration:   6337, Training Accuracy:  70.3%, Loss: 0.4428\n",
      "Optimization Iteration:   6401, Training Accuracy:  78.1%, Loss: 0.3771\n",
      "Optimization Iteration:   6465, Training Accuracy:  87.5%, Loss: 0.3255\n",
      "Optimization Iteration:   6529, Training Accuracy:  79.7%, Loss: 0.3566\n",
      "Optimization Iteration:   6593, Training Accuracy:  84.4%, Loss: 0.3792\n",
      "Optimization Iteration:   6657, Training Accuracy:  68.8%, Loss: 0.4341\n",
      "Optimization Iteration:   6721, Training Accuracy:  79.7%, Loss: 0.3902\n",
      "Optimization Iteration:   6785, Training Accuracy:  76.6%, Loss: 0.3900\n",
      "Optimization Iteration:   6849, Training Accuracy:  73.4%, Loss: 0.3846\n",
      "Optimization Iteration:   6913, Training Accuracy:  79.7%, Loss: 0.3572\n",
      "Optimization Iteration:   6977, Training Accuracy:  70.3%, Loss: 0.4345\n",
      "Optimization Iteration:   7041, Training Accuracy:  82.8%, Loss: 0.3708\n",
      "Optimization Iteration:   7105, Training Accuracy:  73.4%, Loss: 0.3822\n",
      "Optimization Iteration:   7169, Training Accuracy:  73.4%, Loss: 0.3887\n",
      "Optimization Iteration:   7233, Training Accuracy:  76.6%, Loss: 0.3995\n",
      "Optimization Iteration:   7297, Training Accuracy:  70.3%, Loss: 0.3979\n",
      "Optimization Iteration:   7361, Training Accuracy:  79.7%, Loss: 0.3752\n",
      "Optimization Iteration:   7425, Training Accuracy:  70.3%, Loss: 0.4034\n",
      "Optimization Iteration:   7489, Training Accuracy:  78.1%, Loss: 0.4149\n",
      "Optimization Iteration:   7553, Training Accuracy:  70.3%, Loss: 0.4451\n",
      "Optimization Iteration:   7617, Training Accuracy:  65.6%, Loss: 0.4374\n",
      "Optimization Iteration:   7681, Training Accuracy:  71.9%, Loss: 0.4480\n",
      "Optimization Iteration:   7745, Training Accuracy:  68.8%, Loss: 0.4186\n",
      "Optimization Iteration:   7809, Training Accuracy:  76.6%, Loss: 0.4008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7873, Training Accuracy:  70.3%, Loss: 0.4321\n",
      "Optimization Iteration:   7937, Training Accuracy:  68.8%, Loss: 0.4560\n",
      "Optimization Iteration:   8001, Training Accuracy:  78.1%, Loss: 0.3841\n",
      "Optimization Iteration:   8065, Training Accuracy:  71.9%, Loss: 0.4117\n",
      "Optimization Iteration:   8129, Training Accuracy:  76.6%, Loss: 0.3854\n",
      "Optimization Iteration:   8193, Training Accuracy:  73.4%, Loss: 0.4245\n",
      "Optimization Iteration:   8257, Training Accuracy:  78.1%, Loss: 0.4550\n",
      "Optimization Iteration:   8321, Training Accuracy:  75.0%, Loss: 0.4037\n",
      "Optimization Iteration:   8385, Training Accuracy:  64.1%, Loss: 0.5033\n",
      "Optimization Iteration:   8449, Training Accuracy:  73.4%, Loss: 0.4513\n",
      "Optimization Iteration:   8513, Training Accuracy:  79.7%, Loss: 0.3806\n",
      "Optimization Iteration:   8577, Training Accuracy:  75.0%, Loss: 0.4654\n",
      "Optimization Iteration:   8641, Training Accuracy:  81.2%, Loss: 0.3765\n",
      "Optimization Iteration:   8705, Training Accuracy:  70.3%, Loss: 0.4483\n",
      "Optimization Iteration:   8769, Training Accuracy:  79.7%, Loss: 0.3620\n",
      "Optimization Iteration:   8833, Training Accuracy:  64.1%, Loss: 0.4771\n",
      "Optimization Iteration:   8897, Training Accuracy:  71.9%, Loss: 0.4335\n",
      "Optimization Iteration:   8961, Training Accuracy:  70.3%, Loss: 0.4012\n",
      "Optimization Iteration:   9025, Training Accuracy:  65.6%, Loss: 0.5107\n",
      "Optimization Iteration:   9089, Training Accuracy:  76.6%, Loss: 0.4249\n",
      "Optimization Iteration:   9153, Training Accuracy:  70.3%, Loss: 0.4301\n",
      "Optimization Iteration:   9217, Training Accuracy:  78.1%, Loss: 0.3534\n",
      "Optimization Iteration:   9281, Training Accuracy:  81.2%, Loss: 0.3714\n",
      "Optimization Iteration:   9345, Training Accuracy:  73.4%, Loss: 0.4401\n",
      "Optimization Iteration:   9409, Training Accuracy:  78.1%, Loss: 0.4565\n",
      "Optimization Iteration:   9473, Training Accuracy:  79.7%, Loss: 0.3276\n",
      "Optimization Iteration:   9537, Training Accuracy:  75.0%, Loss: 0.3642\n",
      "Optimization Iteration:   9601, Training Accuracy:  70.3%, Loss: 0.4348\n",
      "Optimization Iteration:   9665, Training Accuracy:  73.4%, Loss: 0.4158\n",
      "Optimization Iteration:   9729, Training Accuracy:  71.9%, Loss: 0.4247\n",
      "Optimization Iteration:   9793, Training Accuracy:  67.2%, Loss: 0.4194\n",
      "Optimization Iteration:   9857, Training Accuracy:  73.4%, Loss: 0.4276\n",
      "Optimization Iteration:   9921, Training Accuracy:  75.0%, Loss: 0.4057\n",
      "Optimization Iteration:   9985, Training Accuracy:  75.0%, Loss: 0.3868\n",
      "Optimization Iteration:  10049, Training Accuracy:  78.1%, Loss: 0.4139\n",
      "Optimization Iteration:  10113, Training Accuracy:  76.6%, Loss: 0.3922\n",
      "Optimization Iteration:  10177, Training Accuracy:  70.3%, Loss: 0.5571\n",
      "Optimization Iteration:  10241, Training Accuracy:  79.7%, Loss: 0.3863\n",
      "Optimization Iteration:  10305, Training Accuracy:  78.1%, Loss: 0.3624\n",
      "Optimization Iteration:  10369, Training Accuracy:  76.6%, Loss: 0.3912\n",
      "Optimization Iteration:  10433, Training Accuracy:  71.9%, Loss: 0.4173\n",
      "Optimization Iteration:  10497, Training Accuracy:  70.3%, Loss: 0.4884\n",
      "Optimization Iteration:  10561, Training Accuracy:  76.6%, Loss: 0.3833\n",
      "Optimization Iteration:  10625, Training Accuracy:  82.8%, Loss: 0.3787\n",
      "Optimization Iteration:  10689, Training Accuracy:  76.6%, Loss: 0.4356\n",
      "Optimization Iteration:  10753, Training Accuracy:  79.7%, Loss: 0.4609\n",
      "Optimization Iteration:  10817, Training Accuracy:  79.7%, Loss: 0.3855\n",
      "Optimization Iteration:  10881, Training Accuracy:  76.6%, Loss: 0.3547\n",
      "Optimization Iteration:  10945, Training Accuracy:  76.6%, Loss: 0.4130\n",
      "Optimization Iteration:  11009, Training Accuracy:  68.8%, Loss: 0.3613\n",
      "Optimization Iteration:  11073, Training Accuracy:  81.2%, Loss: 0.3899\n",
      "Optimization Iteration:  11137, Training Accuracy:  76.6%, Loss: 0.4283\n",
      "Optimization Iteration:  11201, Training Accuracy:  79.7%, Loss: 0.3987\n",
      "Optimization Iteration:  11265, Training Accuracy:  82.8%, Loss: 0.3424\n",
      "Optimization Iteration:  11329, Training Accuracy:  71.9%, Loss: 0.5161\n",
      "Optimization Iteration:  11393, Training Accuracy:  71.9%, Loss: 0.5470\n",
      "Optimization Iteration:  11457, Training Accuracy:  76.6%, Loss: 0.3596\n",
      "Optimization Iteration:  11521, Training Accuracy:  76.6%, Loss: 0.3995\n",
      "Optimization Iteration:  11585, Training Accuracy:  70.3%, Loss: 0.3989\n",
      "Optimization Iteration:  11649, Training Accuracy:  70.3%, Loss: 0.4268\n",
      "Optimization Iteration:  11713, Training Accuracy:  79.7%, Loss: 0.3621\n",
      "Optimization Iteration:  11777, Training Accuracy:  82.8%, Loss: 0.4006\n",
      "Optimization Iteration:  11841, Training Accuracy:  73.4%, Loss: 0.4067\n",
      "Optimization Iteration:  11905, Training Accuracy:  75.0%, Loss: 0.4065\n",
      "Optimization Iteration:  11969, Training Accuracy:  79.7%, Loss: 0.3481\n",
      "Optimization Iteration:  12033, Training Accuracy:  68.8%, Loss: 0.4591\n",
      "Optimization Iteration:  12097, Training Accuracy:  79.7%, Loss: 0.3865\n",
      "Optimization Iteration:  12161, Training Accuracy:  70.3%, Loss: 0.5079\n",
      "Optimization Iteration:  12225, Training Accuracy:  79.7%, Loss: 0.3321\n",
      "Optimization Iteration:  12289, Training Accuracy:  79.7%, Loss: 0.3958\n",
      "Optimization Iteration:  12353, Training Accuracy:  85.9%, Loss: 0.3700\n",
      "Optimization Iteration:  12417, Training Accuracy:  84.4%, Loss: 0.3390\n",
      "Optimization Iteration:  12481, Training Accuracy:  82.8%, Loss: 0.4047\n",
      "Optimization Iteration:  12545, Training Accuracy:  68.8%, Loss: 0.4286\n",
      "Optimization Iteration:  12609, Training Accuracy:  73.4%, Loss: 0.3802\n",
      "Optimization Iteration:  12673, Training Accuracy:  81.2%, Loss: 0.3401\n",
      "Optimization Iteration:  12737, Training Accuracy:  67.2%, Loss: 0.5122\n",
      "Optimization Iteration:  12801, Training Accuracy:  76.6%, Loss: 0.3626\n",
      "Optimization Iteration:  12865, Training Accuracy:  70.3%, Loss: 0.4030\n",
      "Optimization Iteration:  12929, Training Accuracy:  68.8%, Loss: 0.3996\n",
      "Optimization Iteration:  12993, Training Accuracy:  73.4%, Loss: 0.3845\n",
      "Optimization Iteration:  13057, Training Accuracy:  67.2%, Loss: 0.4616\n",
      "Optimization Iteration:  13121, Training Accuracy:  84.4%, Loss: 0.3662\n",
      "Optimization Iteration:  13185, Training Accuracy:  81.2%, Loss: 0.3985\n",
      "Optimization Iteration:  13249, Training Accuracy:  65.6%, Loss: 0.5430\n",
      "Optimization Iteration:  13313, Training Accuracy:  78.1%, Loss: 0.4887\n",
      "Optimization Iteration:  13377, Training Accuracy:  71.9%, Loss: 0.5103\n",
      "Optimization Iteration:  13441, Training Accuracy:  73.4%, Loss: 0.3921\n",
      "Optimization Iteration:  13505, Training Accuracy:  79.7%, Loss: 0.4011\n",
      "Optimization Iteration:  13569, Training Accuracy:  76.6%, Loss: 0.3695\n",
      "Optimization Iteration:  13633, Training Accuracy:  71.9%, Loss: 0.3935\n",
      "Optimization Iteration:  13697, Training Accuracy:  81.2%, Loss: 0.4135\n",
      "Optimization Iteration:  13761, Training Accuracy:  76.6%, Loss: 0.3487\n",
      "Optimization Iteration:  13825, Training Accuracy:  79.7%, Loss: 0.4874\n",
      "Optimization Iteration:  13889, Training Accuracy:  71.9%, Loss: 0.4462\n",
      "Optimization Iteration:  13953, Training Accuracy:  85.9%, Loss: 0.3552\n",
      "Optimization Iteration:  14017, Training Accuracy:  73.4%, Loss: 0.4128\n",
      "Optimization Iteration:  14081, Training Accuracy:  73.4%, Loss: 0.3640\n",
      "Optimization Iteration:  14145, Training Accuracy:  76.6%, Loss: 0.3924\n",
      "Optimization Iteration:  14209, Training Accuracy:  81.2%, Loss: 0.3708\n",
      "Optimization Iteration:  14273, Training Accuracy:  67.2%, Loss: 0.4602\n",
      "Optimization Iteration:  14337, Training Accuracy:  85.9%, Loss: 0.2707\n",
      "Optimization Iteration:  14401, Training Accuracy:  71.9%, Loss: 0.4026\n",
      "Optimization Iteration:  14465, Training Accuracy:  70.3%, Loss: 0.4624\n",
      "Optimization Iteration:  14529, Training Accuracy:  70.3%, Loss: 0.5515\n",
      "Optimization Iteration:  14593, Training Accuracy:  85.9%, Loss: 0.2437\n",
      "Optimization Iteration:  14657, Training Accuracy:  76.6%, Loss: 0.4486\n",
      "Optimization Iteration:  14721, Training Accuracy:  81.2%, Loss: 0.3061\n",
      "Optimization Iteration:  14785, Training Accuracy:  70.3%, Loss: 0.4605\n",
      "Optimization Iteration:  14849, Training Accuracy:  76.6%, Loss: 0.3873\n",
      "Optimization Iteration:  14913, Training Accuracy:  73.4%, Loss: 0.3766\n",
      "Optimization Iteration:  14977, Training Accuracy:  76.6%, Loss: 0.3940\n",
      "Optimization Iteration:  15041, Training Accuracy:  75.0%, Loss: 0.4467\n",
      "Optimization Iteration:  15105, Training Accuracy:  78.1%, Loss: 0.4158\n",
      "Optimization Iteration:  15169, Training Accuracy:  81.2%, Loss: 0.3128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  15233, Training Accuracy:  67.2%, Loss: 0.4917\n",
      "Optimization Iteration:  15297, Training Accuracy:  85.9%, Loss: 0.3341\n",
      "Optimization Iteration:  15361, Training Accuracy:  89.1%, Loss: 0.2939\n",
      "Optimization Iteration:  15425, Training Accuracy:  75.0%, Loss: 0.4235\n",
      "Optimization Iteration:  15489, Training Accuracy:  68.8%, Loss: 0.4764\n",
      "Optimization Iteration:  15553, Training Accuracy:  79.7%, Loss: 0.3152\n",
      "Optimization Iteration:  15617, Training Accuracy:  75.0%, Loss: 0.4513\n",
      "Optimization Iteration:  15681, Training Accuracy:  73.4%, Loss: 0.4140\n",
      "Optimization Iteration:  15745, Training Accuracy:  71.9%, Loss: 0.3703\n",
      "Optimization Iteration:  15809, Training Accuracy:  75.0%, Loss: 0.4819\n",
      "Optimization Iteration:  15873, Training Accuracy:  76.6%, Loss: 0.4112\n",
      "Optimization Iteration:  15937, Training Accuracy:  76.6%, Loss: 0.3855\n",
      "Optimization Iteration:  16001, Training Accuracy:  70.3%, Loss: 0.4248\n",
      "Optimization Iteration:  16065, Training Accuracy:  75.0%, Loss: 0.4733\n",
      "Optimization Iteration:  16129, Training Accuracy:  73.4%, Loss: 0.3569\n",
      "Optimization Iteration:  16193, Training Accuracy:  73.4%, Loss: 0.4340\n",
      "Optimization Iteration:  16257, Training Accuracy:  75.0%, Loss: 0.4233\n",
      "Optimization Iteration:  16321, Training Accuracy:  76.6%, Loss: 0.4767\n",
      "Optimization Iteration:  16385, Training Accuracy:  73.4%, Loss: 0.3889\n",
      "Optimization Iteration:  16449, Training Accuracy:  70.3%, Loss: 0.3832\n",
      "Optimization Iteration:  16513, Training Accuracy:  73.4%, Loss: 0.4164\n",
      "Optimization Iteration:  16577, Training Accuracy:  78.1%, Loss: 0.3634\n",
      "Optimization Iteration:  16641, Training Accuracy:  65.6%, Loss: 0.4986\n",
      "Optimization Iteration:  16705, Training Accuracy:  75.0%, Loss: 0.4449\n",
      "Optimization Iteration:  16769, Training Accuracy:  79.7%, Loss: 0.3431\n",
      "Optimization Iteration:  16833, Training Accuracy:  75.0%, Loss: 0.3835\n",
      "Optimization Iteration:  16897, Training Accuracy:  79.7%, Loss: 0.4109\n",
      "Optimization Iteration:  16961, Training Accuracy:  78.1%, Loss: 0.3716\n",
      "Optimization Iteration:  17025, Training Accuracy:  67.2%, Loss: 0.4434\n",
      "Optimization Iteration:  17089, Training Accuracy:  73.4%, Loss: 0.4281\n",
      "Optimization Iteration:  17153, Training Accuracy:  71.9%, Loss: 0.4617\n",
      "Optimization Iteration:  17217, Training Accuracy:  68.8%, Loss: 0.4794\n",
      "Optimization Iteration:  17281, Training Accuracy:  65.6%, Loss: 0.4793\n",
      "Optimization Iteration:  17345, Training Accuracy:  79.7%, Loss: 0.3780\n",
      "Optimization Iteration:  17409, Training Accuracy:  75.0%, Loss: 0.3992\n",
      "Optimization Iteration:  17473, Training Accuracy:  71.9%, Loss: 0.4329\n",
      "Optimization Iteration:  17537, Training Accuracy:  73.4%, Loss: 0.3738\n",
      "Optimization Iteration:  17601, Training Accuracy:  67.2%, Loss: 0.4713\n",
      "Optimization Iteration:  17665, Training Accuracy:  78.1%, Loss: 0.4135\n",
      "Optimization Iteration:  17729, Training Accuracy:  76.6%, Loss: 0.3792\n",
      "Optimization Iteration:  17793, Training Accuracy:  68.8%, Loss: 0.4790\n",
      "Optimization Iteration:  17857, Training Accuracy:  68.8%, Loss: 0.4395\n",
      "Optimization Iteration:  17921, Training Accuracy:  75.0%, Loss: 0.3944\n",
      "Optimization Iteration:  17985, Training Accuracy:  79.7%, Loss: 0.3241\n",
      "Optimization Iteration:  18049, Training Accuracy:  71.9%, Loss: 0.3726\n",
      "Optimization Iteration:  18113, Training Accuracy:  64.1%, Loss: 0.5521\n",
      "Optimization Iteration:  18177, Training Accuracy:  64.1%, Loss: 0.5588\n",
      "Optimization Iteration:  18241, Training Accuracy:  70.3%, Loss: 0.4434\n",
      "Optimization Iteration:  18305, Training Accuracy:  70.3%, Loss: 0.4338\n",
      "Optimization Iteration:  18369, Training Accuracy:  76.6%, Loss: 0.3398\n",
      "Optimization Iteration:  18433, Training Accuracy:  73.4%, Loss: 0.3994\n",
      "Optimization Iteration:  18497, Training Accuracy:  76.6%, Loss: 0.4009\n",
      "Optimization Iteration:  18561, Training Accuracy:  71.9%, Loss: 0.4373\n",
      "Optimization Iteration:  18625, Training Accuracy:  75.0%, Loss: 0.4485\n",
      "Optimization Iteration:  18689, Training Accuracy:  73.4%, Loss: 0.4234\n",
      "Optimization Iteration:  18753, Training Accuracy:  76.6%, Loss: 0.4095\n",
      "Optimization Iteration:  18817, Training Accuracy:  79.7%, Loss: 0.3361\n",
      "Optimization Iteration:  18881, Training Accuracy:  67.2%, Loss: 0.4186\n",
      "Optimization Iteration:  18945, Training Accuracy:  79.7%, Loss: 0.3832\n",
      "Optimization Iteration:  19009, Training Accuracy:  81.2%, Loss: 0.3457\n",
      "Optimization Iteration:  19073, Training Accuracy:  76.6%, Loss: 0.3825\n",
      "Optimization Iteration:  19137, Training Accuracy:  68.8%, Loss: 0.4715\n",
      "Optimization Iteration:  19201, Training Accuracy:  81.2%, Loss: 0.3877\n",
      "Optimization Iteration:  19265, Training Accuracy:  75.0%, Loss: 0.3985\n",
      "Optimization Iteration:  19329, Training Accuracy:  82.8%, Loss: 0.3433\n",
      "Optimization Iteration:  19393, Training Accuracy:  81.2%, Loss: 0.3880\n",
      "Optimization Iteration:  19457, Training Accuracy:  73.4%, Loss: 0.3976\n",
      "Optimization Iteration:  19521, Training Accuracy:  81.2%, Loss: 0.4167\n",
      "Optimization Iteration:  19585, Training Accuracy:  75.0%, Loss: 0.4605\n",
      "Optimization Iteration:  19649, Training Accuracy:  82.8%, Loss: 0.4849\n",
      "Optimization Iteration:  19713, Training Accuracy:  78.1%, Loss: 0.3360\n",
      "Optimization Iteration:  19777, Training Accuracy:  75.0%, Loss: 0.4229\n",
      "Optimization Iteration:  19841, Training Accuracy:  70.3%, Loss: 0.4772\n",
      "Optimization Iteration:  19905, Training Accuracy:  68.8%, Loss: 0.4262\n",
      "Optimization Iteration:  19969, Training Accuracy:  78.1%, Loss: 0.4738\n",
      "Optimization Iteration:  20033, Training Accuracy:  85.9%, Loss: 0.3227\n",
      "Optimization Iteration:  20097, Training Accuracy:  75.0%, Loss: 0.4264\n",
      "Optimization Iteration:  20161, Training Accuracy:  71.9%, Loss: 0.4123\n",
      "Optimization Iteration:  20225, Training Accuracy:  71.9%, Loss: 0.4339\n",
      "Optimization Iteration:  20289, Training Accuracy:  73.4%, Loss: 0.4495\n",
      "Optimization Iteration:  20353, Training Accuracy:  71.9%, Loss: 0.3604\n",
      "Optimization Iteration:  20417, Training Accuracy:  73.4%, Loss: 0.3719\n",
      "Optimization Iteration:  20481, Training Accuracy:  75.0%, Loss: 0.3721\n",
      "Optimization Iteration:  20545, Training Accuracy:  76.6%, Loss: 0.4288\n",
      "Optimization Iteration:  20609, Training Accuracy:  70.3%, Loss: 0.4733\n",
      "Optimization Iteration:  20673, Training Accuracy:  78.1%, Loss: 0.3636\n",
      "Optimization Iteration:  20737, Training Accuracy:  79.7%, Loss: 0.4088\n",
      "Optimization Iteration:  20801, Training Accuracy:  81.2%, Loss: 0.3585\n",
      "Optimization Iteration:  20865, Training Accuracy:  79.7%, Loss: 0.2915\n",
      "Optimization Iteration:  20929, Training Accuracy:  87.5%, Loss: 0.3720\n",
      "Optimization Iteration:  20993, Training Accuracy:  76.6%, Loss: 0.3523\n",
      "Optimization Iteration:  21057, Training Accuracy:  75.0%, Loss: 0.4107\n",
      "Optimization Iteration:  21121, Training Accuracy:  67.2%, Loss: 0.4111\n",
      "Optimization Iteration:  21185, Training Accuracy:  76.6%, Loss: 0.5017\n",
      "Optimization Iteration:  21249, Training Accuracy:  71.9%, Loss: 0.5288\n",
      "Optimization Iteration:  21313, Training Accuracy:  75.0%, Loss: 0.3934\n",
      "Optimization Iteration:  21377, Training Accuracy:  75.0%, Loss: 0.4088\n",
      "Optimization Iteration:  21441, Training Accuracy:  68.8%, Loss: 0.3984\n",
      "Optimization Iteration:  21505, Training Accuracy:  79.7%, Loss: 0.4082\n",
      "Optimization Iteration:  21569, Training Accuracy:  73.4%, Loss: 0.4014\n",
      "Optimization Iteration:  21633, Training Accuracy:  89.1%, Loss: 0.3142\n",
      "Optimization Iteration:  21697, Training Accuracy:  73.4%, Loss: 0.5068\n",
      "Optimization Iteration:  21761, Training Accuracy:  79.7%, Loss: 0.3840\n",
      "Optimization Iteration:  21825, Training Accuracy:  67.2%, Loss: 0.5329\n",
      "Optimization Iteration:  21889, Training Accuracy:  76.6%, Loss: 0.4556\n",
      "Optimization Iteration:  21953, Training Accuracy:  70.3%, Loss: 0.4804\n",
      "Optimization Iteration:  22017, Training Accuracy:  81.2%, Loss: 0.3907\n",
      "Optimization Iteration:  22081, Training Accuracy:  78.1%, Loss: 0.3847\n",
      "Optimization Iteration:  22145, Training Accuracy:  84.4%, Loss: 0.3893\n",
      "Optimization Iteration:  22209, Training Accuracy:  76.6%, Loss: 0.4200\n",
      "Optimization Iteration:  22273, Training Accuracy:  70.3%, Loss: 0.4509\n",
      "Optimization Iteration:  22337, Training Accuracy:  71.9%, Loss: 0.4170\n",
      "Optimization Iteration:  22401, Training Accuracy:  81.2%, Loss: 0.4251\n",
      "Optimization Iteration:  22465, Training Accuracy:  70.3%, Loss: 0.4408\n",
      "Optimization Iteration:  22529, Training Accuracy:  81.2%, Loss: 0.3558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  22593, Training Accuracy:  81.2%, Loss: 0.3595\n",
      "Optimization Iteration:  22657, Training Accuracy:  70.3%, Loss: 0.4296\n",
      "Optimization Iteration:  22721, Training Accuracy:  62.5%, Loss: 0.4616\n",
      "Optimization Iteration:  22785, Training Accuracy:  73.4%, Loss: 0.4889\n",
      "Optimization Iteration:  22849, Training Accuracy:  76.6%, Loss: 0.4162\n",
      "Optimization Iteration:  22913, Training Accuracy:  75.0%, Loss: 0.3839\n",
      "Optimization Iteration:  22977, Training Accuracy:  81.2%, Loss: 0.3975\n",
      "Optimization Iteration:  23041, Training Accuracy:  75.0%, Loss: 0.3639\n",
      "Optimization Iteration:  23105, Training Accuracy:  70.3%, Loss: 0.3963\n",
      "Optimization Iteration:  23169, Training Accuracy:  85.9%, Loss: 0.3564\n",
      "Optimization Iteration:  23233, Training Accuracy:  64.1%, Loss: 0.5869\n",
      "Optimization Iteration:  23297, Training Accuracy:  73.4%, Loss: 0.4733\n",
      "Optimization Iteration:  23361, Training Accuracy:  79.7%, Loss: 0.4250\n",
      "Optimization Iteration:  23425, Training Accuracy:  73.4%, Loss: 0.4304\n",
      "Optimization Iteration:  23489, Training Accuracy:  75.0%, Loss: 0.4654\n",
      "Optimization Iteration:  23553, Training Accuracy:  76.6%, Loss: 0.3240\n",
      "Optimization Iteration:  23617, Training Accuracy:  71.9%, Loss: 0.4519\n",
      "Optimization Iteration:  23681, Training Accuracy:  75.0%, Loss: 0.4356\n",
      "Optimization Iteration:  23745, Training Accuracy:  76.6%, Loss: 0.4080\n",
      "Optimization Iteration:  23809, Training Accuracy:  82.8%, Loss: 0.4426\n",
      "Optimization Iteration:  23873, Training Accuracy:  82.8%, Loss: 0.3402\n",
      "Optimization Iteration:  23937, Training Accuracy:  64.1%, Loss: 0.4735\n",
      "Optimization Iteration:  24001, Training Accuracy:  78.1%, Loss: 0.3456\n",
      "Optimization Iteration:  24065, Training Accuracy:  84.4%, Loss: 0.3817\n",
      "Optimization Iteration:  24129, Training Accuracy:  75.0%, Loss: 0.4214\n",
      "Optimization Iteration:  24193, Training Accuracy:  71.9%, Loss: 0.4063\n",
      "Optimization Iteration:  24257, Training Accuracy:  73.4%, Loss: 0.3807\n",
      "Optimization Iteration:  24321, Training Accuracy:  62.5%, Loss: 0.5100\n",
      "Optimization Iteration:  24385, Training Accuracy:  73.4%, Loss: 0.4418\n",
      "Optimization Iteration:  24449, Training Accuracy:  78.1%, Loss: 0.3128\n",
      "Optimization Iteration:  24513, Training Accuracy:  81.2%, Loss: 0.3265\n",
      "Optimization Iteration:  24577, Training Accuracy:  73.4%, Loss: 0.4542\n",
      "Optimization Iteration:  24641, Training Accuracy:  78.1%, Loss: 0.3834\n",
      "Optimization Iteration:  24705, Training Accuracy:  75.0%, Loss: 0.3802\n",
      "Optimization Iteration:  24769, Training Accuracy:  78.1%, Loss: 0.3898\n",
      "Optimization Iteration:  24833, Training Accuracy:  75.0%, Loss: 0.3616\n",
      "Optimization Iteration:  24897, Training Accuracy:  78.1%, Loss: 0.3839\n",
      "Optimization Iteration:  24961, Training Accuracy:  68.8%, Loss: 0.4078\n",
      "Optimization Iteration:  25025, Training Accuracy:  73.4%, Loss: 0.4057\n",
      "Optimization Iteration:  25089, Training Accuracy:  70.3%, Loss: 0.3991\n",
      "Optimization Iteration:  25153, Training Accuracy:  73.4%, Loss: 0.4217\n",
      "Optimization Iteration:  25217, Training Accuracy:  64.1%, Loss: 0.5116\n",
      "Optimization Iteration:  25281, Training Accuracy:  71.9%, Loss: 0.4808\n",
      "Optimization Iteration:  25345, Training Accuracy:  70.3%, Loss: 0.4837\n",
      "Optimization Iteration:  25409, Training Accuracy:  73.4%, Loss: 0.4789\n",
      "Optimization Iteration:  25473, Training Accuracy:  70.3%, Loss: 0.5000\n",
      "Optimization Iteration:  25537, Training Accuracy:  78.1%, Loss: 0.3695\n",
      "Optimization Iteration:  25601, Training Accuracy:  67.2%, Loss: 0.4664\n",
      "Optimization Iteration:  25665, Training Accuracy:  76.6%, Loss: 0.4298\n",
      "Optimization Iteration:  25729, Training Accuracy:  76.6%, Loss: 0.3493\n",
      "Optimization Iteration:  25793, Training Accuracy:  82.8%, Loss: 0.3503\n",
      "Optimization Iteration:  25857, Training Accuracy:  76.6%, Loss: 0.4081\n",
      "Optimization Iteration:  25921, Training Accuracy:  73.4%, Loss: 0.4131\n",
      "Optimization Iteration:  25985, Training Accuracy:  75.0%, Loss: 0.4674\n",
      "Optimization Iteration:  26049, Training Accuracy:  75.0%, Loss: 0.4122\n",
      "Optimization Iteration:  26113, Training Accuracy:  71.9%, Loss: 0.4783\n",
      "Optimization Iteration:  26177, Training Accuracy:  71.9%, Loss: 0.4139\n",
      "Optimization Iteration:  26241, Training Accuracy:  70.3%, Loss: 0.4498\n",
      "Optimization Iteration:  26305, Training Accuracy:  75.0%, Loss: 0.4294\n",
      "Optimization Iteration:  26369, Training Accuracy:  73.4%, Loss: 0.3727\n",
      "Optimization Iteration:  26433, Training Accuracy:  68.8%, Loss: 0.4814\n",
      "Optimization Iteration:  26497, Training Accuracy:  75.0%, Loss: 0.3995\n",
      "Optimization Iteration:  26561, Training Accuracy:  78.1%, Loss: 0.3643\n",
      "Optimization Iteration:  26625, Training Accuracy:  78.1%, Loss: 0.4066\n",
      "Optimization Iteration:  26689, Training Accuracy:  75.0%, Loss: 0.4275\n",
      "Optimization Iteration:  26753, Training Accuracy:  73.4%, Loss: 0.4444\n",
      "Optimization Iteration:  26817, Training Accuracy:  73.4%, Loss: 0.4775\n",
      "Optimization Iteration:  26881, Training Accuracy:  79.7%, Loss: 0.3525\n",
      "Optimization Iteration:  26945, Training Accuracy:  71.9%, Loss: 0.4322\n",
      "Optimization Iteration:  27009, Training Accuracy:  76.6%, Loss: 0.3730\n",
      "Optimization Iteration:  27073, Training Accuracy:  79.7%, Loss: 0.4037\n",
      "Optimization Iteration:  27137, Training Accuracy:  82.8%, Loss: 0.3429\n",
      "Optimization Iteration:  27201, Training Accuracy:  73.4%, Loss: 0.3385\n",
      "Optimization Iteration:  27265, Training Accuracy:  76.6%, Loss: 0.3559\n",
      "Optimization Iteration:  27329, Training Accuracy:  73.4%, Loss: 0.4228\n",
      "Optimization Iteration:  27393, Training Accuracy:  75.0%, Loss: 0.4174\n",
      "Optimization Iteration:  27457, Training Accuracy:  78.1%, Loss: 0.3822\n",
      "Optimization Iteration:  27521, Training Accuracy:  79.7%, Loss: 0.4270\n",
      "Optimization Iteration:  27585, Training Accuracy:  81.2%, Loss: 0.3472\n",
      "Optimization Iteration:  27649, Training Accuracy:  78.1%, Loss: 0.4031\n",
      "Optimization Iteration:  27713, Training Accuracy:  75.0%, Loss: 0.4499\n",
      "Optimization Iteration:  27777, Training Accuracy:  78.1%, Loss: 0.3949\n",
      "Optimization Iteration:  27841, Training Accuracy:  73.4%, Loss: 0.4796\n",
      "Optimization Iteration:  27905, Training Accuracy:  71.9%, Loss: 0.3959\n",
      "Optimization Iteration:  27969, Training Accuracy:  67.2%, Loss: 0.5220\n",
      "Optimization Iteration:  28033, Training Accuracy:  76.6%, Loss: 0.3920\n",
      "Optimization Iteration:  28097, Training Accuracy:  78.1%, Loss: 0.4552\n",
      "Optimization Iteration:  28161, Training Accuracy:  85.9%, Loss: 0.3303\n",
      "Optimization Iteration:  28225, Training Accuracy:  89.1%, Loss: 0.3184\n",
      "Optimization Iteration:  28289, Training Accuracy:  73.4%, Loss: 0.3702\n",
      "Optimization Iteration:  28353, Training Accuracy:  78.1%, Loss: 0.4075\n",
      "Optimization Iteration:  28417, Training Accuracy:  73.4%, Loss: 0.5065\n",
      "Optimization Iteration:  28481, Training Accuracy:  79.7%, Loss: 0.3971\n",
      "Optimization Iteration:  28545, Training Accuracy:  76.6%, Loss: 0.3837\n",
      "Optimization Iteration:  28609, Training Accuracy:  82.8%, Loss: 0.3703\n",
      "Optimization Iteration:  28673, Training Accuracy:  76.6%, Loss: 0.4104\n",
      "Optimization Iteration:  28737, Training Accuracy:  81.2%, Loss: 0.3399\n",
      "Optimization Iteration:  28801, Training Accuracy:  78.1%, Loss: 0.3108\n",
      "Optimization Iteration:  28865, Training Accuracy:  79.7%, Loss: 0.3215\n",
      "Optimization Iteration:  28929, Training Accuracy:  78.1%, Loss: 0.3597\n",
      "Optimization Iteration:  28993, Training Accuracy:  64.1%, Loss: 0.5312\n",
      "Optimization Iteration:  29057, Training Accuracy:  64.1%, Loss: 0.4476\n",
      "Optimization Iteration:  29121, Training Accuracy:  62.5%, Loss: 0.5995\n",
      "Optimization Iteration:  29185, Training Accuracy:  68.8%, Loss: 0.4141\n",
      "Optimization Iteration:  29249, Training Accuracy:  75.0%, Loss: 0.4137\n",
      "Optimization Iteration:  29313, Training Accuracy:  70.3%, Loss: 0.4975\n",
      "Optimization Iteration:  29377, Training Accuracy:  76.6%, Loss: 0.4003\n",
      "Optimization Iteration:  29441, Training Accuracy:  75.0%, Loss: 0.4103\n",
      "Optimization Iteration:  29505, Training Accuracy:  81.2%, Loss: 0.4599\n",
      "Optimization Iteration:  29569, Training Accuracy:  71.9%, Loss: 0.4277\n",
      "Optimization Iteration:  29633, Training Accuracy:  70.3%, Loss: 0.3933\n",
      "Optimization Iteration:  29697, Training Accuracy:  76.6%, Loss: 0.3483\n",
      "Optimization Iteration:  29761, Training Accuracy:  76.6%, Loss: 0.4167\n",
      "Optimization Iteration:  29825, Training Accuracy:  76.6%, Loss: 0.4152\n",
      "Optimization Iteration:  29889, Training Accuracy:  73.4%, Loss: 0.4406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  29953, Training Accuracy:  67.2%, Loss: 0.4112\n",
      "Optimization Iteration:  30017, Training Accuracy:  76.6%, Loss: 0.3797\n",
      "Optimization Iteration:  30081, Training Accuracy:  79.7%, Loss: 0.3832\n",
      "Optimization Iteration:  30145, Training Accuracy:  73.4%, Loss: 0.4062\n",
      "Optimization Iteration:  30209, Training Accuracy:  78.1%, Loss: 0.3987\n",
      "Optimization Iteration:  30273, Training Accuracy:  68.8%, Loss: 0.4182\n",
      "Optimization Iteration:  30337, Training Accuracy:  87.5%, Loss: 0.3500\n",
      "Optimization Iteration:  30401, Training Accuracy:  76.6%, Loss: 0.4289\n",
      "Optimization Iteration:  30465, Training Accuracy:  75.0%, Loss: 0.4795\n",
      "Optimization Iteration:  30529, Training Accuracy:  79.7%, Loss: 0.3860\n",
      "Optimization Iteration:  30593, Training Accuracy:  82.8%, Loss: 0.4038\n",
      "Optimization Iteration:  30657, Training Accuracy:  76.6%, Loss: 0.3527\n",
      "Optimization Iteration:  30721, Training Accuracy:  73.4%, Loss: 0.4105\n",
      "Optimization Iteration:  30785, Training Accuracy:  68.8%, Loss: 0.4131\n",
      "Optimization Iteration:  30849, Training Accuracy:  70.3%, Loss: 0.3836\n",
      "Optimization Iteration:  30913, Training Accuracy:  84.4%, Loss: 0.3701\n",
      "Optimization Iteration:  30977, Training Accuracy:  70.3%, Loss: 0.4593\n",
      "Optimization Iteration:  31041, Training Accuracy:  79.7%, Loss: 0.3951\n",
      "Optimization Iteration:  31105, Training Accuracy:  79.7%, Loss: 0.3417\n",
      "Optimization Iteration:  31169, Training Accuracy:  73.4%, Loss: 0.3936\n",
      "Optimization Iteration:  31233, Training Accuracy:  76.6%, Loss: 0.4446\n",
      "Optimization Iteration:  31297, Training Accuracy:  71.9%, Loss: 0.4249\n",
      "Optimization Iteration:  31361, Training Accuracy:  73.4%, Loss: 0.4274\n",
      "Optimization Iteration:  31425, Training Accuracy:  87.5%, Loss: 0.2459\n",
      "Optimization Iteration:  31489, Training Accuracy:  87.5%, Loss: 0.3008\n",
      "Optimization Iteration:  31553, Training Accuracy:  76.6%, Loss: 0.4230\n",
      "Optimization Iteration:  31617, Training Accuracy:  76.6%, Loss: 0.3359\n",
      "Optimization Iteration:  31681, Training Accuracy:  79.7%, Loss: 0.4580\n",
      "Optimization Iteration:  31745, Training Accuracy:  60.9%, Loss: 0.4001\n",
      "Optimization Iteration:  31809, Training Accuracy:  68.8%, Loss: 0.5237\n",
      "Optimization Iteration:  31873, Training Accuracy:  79.7%, Loss: 0.3919\n",
      "Optimization Iteration:  31937, Training Accuracy:  71.9%, Loss: 0.4016\n",
      "Optimization Iteration:  32001, Training Accuracy:  87.5%, Loss: 0.3737\n",
      "Optimization Iteration:  32065, Training Accuracy:  76.6%, Loss: 0.3736\n",
      "Optimization Iteration:  32129, Training Accuracy:  81.2%, Loss: 0.3610\n",
      "Optimization Iteration:  32193, Training Accuracy:  76.6%, Loss: 0.3882\n",
      "Optimization Iteration:  32257, Training Accuracy:  71.9%, Loss: 0.4283\n",
      "Optimization Iteration:  32321, Training Accuracy:  82.8%, Loss: 0.3420\n",
      "Optimization Iteration:  32385, Training Accuracy:  81.2%, Loss: 0.4572\n",
      "Optimization Iteration:  32449, Training Accuracy:  68.8%, Loss: 0.4649\n",
      "Optimization Iteration:  32513, Training Accuracy:  78.1%, Loss: 0.3335\n",
      "Optimization Iteration:  32577, Training Accuracy:  78.1%, Loss: 0.3841\n",
      "Optimization Iteration:  32641, Training Accuracy:  65.6%, Loss: 0.5241\n",
      "Optimization Iteration:  32705, Training Accuracy:  73.4%, Loss: 0.4036\n",
      "Optimization Iteration:  32769, Training Accuracy:  78.1%, Loss: 0.4027\n",
      "Optimization Iteration:  32833, Training Accuracy:  78.1%, Loss: 0.3830\n",
      "Optimization Iteration:  32897, Training Accuracy:  76.6%, Loss: 0.4384\n",
      "Optimization Iteration:  32961, Training Accuracy:  75.0%, Loss: 0.4163\n",
      "Optimization Iteration:  33025, Training Accuracy:  68.8%, Loss: 0.3613\n",
      "Optimization Iteration:  33089, Training Accuracy:  78.1%, Loss: 0.3935\n",
      "Optimization Iteration:  33153, Training Accuracy:  73.4%, Loss: 0.4765\n",
      "Optimization Iteration:  33217, Training Accuracy:  68.8%, Loss: 0.4547\n",
      "Optimization Iteration:  33281, Training Accuracy:  75.0%, Loss: 0.4771\n",
      "Optimization Iteration:  33345, Training Accuracy:  73.4%, Loss: 0.4293\n",
      "Optimization Iteration:  33409, Training Accuracy:  82.8%, Loss: 0.4494\n",
      "Optimization Iteration:  33473, Training Accuracy:  68.8%, Loss: 0.4561\n",
      "Optimization Iteration:  33537, Training Accuracy:  79.7%, Loss: 0.4422\n",
      "Optimization Iteration:  33601, Training Accuracy:  78.1%, Loss: 0.4714\n",
      "Optimization Iteration:  33665, Training Accuracy:  71.9%, Loss: 0.4126\n",
      "Optimization Iteration:  33729, Training Accuracy:  81.2%, Loss: 0.4299\n",
      "Optimization Iteration:  33793, Training Accuracy:  68.8%, Loss: 0.4689\n",
      "Optimization Iteration:  33857, Training Accuracy:  79.7%, Loss: 0.3499\n",
      "Optimization Iteration:  33921, Training Accuracy:  73.4%, Loss: 0.3809\n",
      "Optimization Iteration:  33985, Training Accuracy:  78.1%, Loss: 0.3780\n",
      "Optimization Iteration:  34049, Training Accuracy:  73.4%, Loss: 0.4308\n",
      "Optimization Iteration:  34113, Training Accuracy:  76.6%, Loss: 0.3949\n",
      "Optimization Iteration:  34177, Training Accuracy:  71.9%, Loss: 0.3864\n",
      "Optimization Iteration:  34241, Training Accuracy:  67.2%, Loss: 0.5290\n",
      "Optimization Iteration:  34305, Training Accuracy:  75.0%, Loss: 0.4579\n",
      "Optimization Iteration:  34369, Training Accuracy:  82.8%, Loss: 0.3095\n",
      "Optimization Iteration:  34433, Training Accuracy:  76.6%, Loss: 0.4278\n",
      "Optimization Iteration:  34497, Training Accuracy:  76.6%, Loss: 0.3708\n",
      "Optimization Iteration:  34561, Training Accuracy:  75.0%, Loss: 0.4349\n",
      "Optimization Iteration:  34625, Training Accuracy:  75.0%, Loss: 0.5143\n",
      "Optimization Iteration:  34689, Training Accuracy:  70.3%, Loss: 0.4572\n",
      "Optimization Iteration:  34753, Training Accuracy:  76.6%, Loss: 0.4715\n",
      "Optimization Iteration:  34817, Training Accuracy:  76.6%, Loss: 0.3889\n",
      "Optimization Iteration:  34881, Training Accuracy:  70.3%, Loss: 0.4072\n",
      "Optimization Iteration:  34945, Training Accuracy:  82.8%, Loss: 0.3864\n",
      "Optimization Iteration:  35009, Training Accuracy:  75.0%, Loss: 0.4363\n",
      "Optimization Iteration:  35073, Training Accuracy:  73.4%, Loss: 0.3260\n",
      "Optimization Iteration:  35137, Training Accuracy:  81.2%, Loss: 0.2848\n",
      "Optimization Iteration:  35201, Training Accuracy:  79.7%, Loss: 0.3429\n",
      "Optimization Iteration:  35265, Training Accuracy:  73.4%, Loss: 0.3992\n",
      "Optimization Iteration:  35329, Training Accuracy:  71.9%, Loss: 0.4235\n",
      "Optimization Iteration:  35393, Training Accuracy:  67.2%, Loss: 0.4510\n",
      "Optimization Iteration:  35457, Training Accuracy:  82.8%, Loss: 0.3833\n",
      "Optimization Iteration:  35521, Training Accuracy:  68.8%, Loss: 0.4428\n",
      "Optimization Iteration:  35585, Training Accuracy:  81.2%, Loss: 0.2802\n",
      "Optimization Iteration:  35649, Training Accuracy:  65.6%, Loss: 0.5233\n",
      "Optimization Iteration:  35713, Training Accuracy:  73.4%, Loss: 0.4025\n",
      "Optimization Iteration:  35777, Training Accuracy:  78.1%, Loss: 0.3547\n",
      "Optimization Iteration:  35841, Training Accuracy:  76.6%, Loss: 0.3823\n",
      "Optimization Iteration:  35905, Training Accuracy:  90.6%, Loss: 0.3546\n",
      "Optimization Iteration:  35969, Training Accuracy:  76.6%, Loss: 0.4332\n",
      "Optimization Iteration:  36033, Training Accuracy:  73.4%, Loss: 0.3942\n",
      "Optimization Iteration:  36097, Training Accuracy:  64.1%, Loss: 0.4720\n",
      "Optimization Iteration:  36161, Training Accuracy:  70.3%, Loss: 0.4078\n",
      "Optimization Iteration:  36225, Training Accuracy:  71.9%, Loss: 0.4196\n",
      "Optimization Iteration:  36289, Training Accuracy:  78.1%, Loss: 0.3551\n",
      "Optimization Iteration:  36353, Training Accuracy:  76.6%, Loss: 0.3458\n",
      "Optimization Iteration:  36417, Training Accuracy:  76.6%, Loss: 0.4355\n",
      "Optimization Iteration:  36481, Training Accuracy:  76.6%, Loss: 0.3558\n",
      "Optimization Iteration:  36545, Training Accuracy:  78.1%, Loss: 0.4067\n",
      "Optimization Iteration:  36609, Training Accuracy:  78.1%, Loss: 0.3530\n",
      "Optimization Iteration:  36673, Training Accuracy:  67.2%, Loss: 0.4391\n",
      "Optimization Iteration:  36737, Training Accuracy:  78.1%, Loss: 0.3597\n",
      "Optimization Iteration:  36801, Training Accuracy:  75.0%, Loss: 0.3605\n",
      "Optimization Iteration:  36865, Training Accuracy:  71.9%, Loss: 0.4098\n",
      "Optimization Iteration:  36929, Training Accuracy:  70.3%, Loss: 0.4902\n",
      "Optimization Iteration:  36993, Training Accuracy:  65.6%, Loss: 0.4188\n",
      "Optimization Iteration:  37057, Training Accuracy:  84.4%, Loss: 0.3348\n",
      "Optimization Iteration:  37121, Training Accuracy:  75.0%, Loss: 0.3795\n",
      "Optimization Iteration:  37185, Training Accuracy:  81.2%, Loss: 0.3494\n",
      "Optimization Iteration:  37249, Training Accuracy:  79.7%, Loss: 0.4767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  37313, Training Accuracy:  75.0%, Loss: 0.3235\n",
      "Optimization Iteration:  37377, Training Accuracy:  68.8%, Loss: 0.5214\n",
      "Optimization Iteration:  37441, Training Accuracy:  75.0%, Loss: 0.4124\n",
      "Optimization Iteration:  37505, Training Accuracy:  68.8%, Loss: 0.4531\n",
      "Optimization Iteration:  37569, Training Accuracy:  70.3%, Loss: 0.4867\n",
      "Optimization Iteration:  37633, Training Accuracy:  68.8%, Loss: 0.4428\n",
      "Optimization Iteration:  37697, Training Accuracy:  79.7%, Loss: 0.3383\n",
      "Optimization Iteration:  37761, Training Accuracy:  67.2%, Loss: 0.4069\n",
      "Optimization Iteration:  37825, Training Accuracy:  71.9%, Loss: 0.3619\n",
      "Optimization Iteration:  37889, Training Accuracy:  73.4%, Loss: 0.3367\n",
      "Optimization Iteration:  37953, Training Accuracy:  78.1%, Loss: 0.3539\n",
      "Optimization Iteration:  38017, Training Accuracy:  79.7%, Loss: 0.4232\n",
      "Optimization Iteration:  38081, Training Accuracy:  71.9%, Loss: 0.4477\n",
      "Optimization Iteration:  38145, Training Accuracy:  71.9%, Loss: 0.3748\n",
      "Optimization Iteration:  38209, Training Accuracy:  78.1%, Loss: 0.4313\n",
      "Optimization Iteration:  38273, Training Accuracy:  79.7%, Loss: 0.3579\n",
      "Optimization Iteration:  38337, Training Accuracy:  79.7%, Loss: 0.3075\n",
      "Optimization Iteration:  38401, Training Accuracy:  76.6%, Loss: 0.3919\n",
      "Optimization Iteration:  38465, Training Accuracy:  75.0%, Loss: 0.4143\n",
      "Optimization Iteration:  38529, Training Accuracy:  71.9%, Loss: 0.4005\n",
      "Optimization Iteration:  38593, Training Accuracy:  73.4%, Loss: 0.4878\n",
      "Optimization Iteration:  38657, Training Accuracy:  60.9%, Loss: 0.4942\n",
      "Optimization Iteration:  38721, Training Accuracy:  73.4%, Loss: 0.3520\n",
      "Optimization Iteration:  38785, Training Accuracy:  73.4%, Loss: 0.4530\n",
      "Optimization Iteration:  38849, Training Accuracy:  76.6%, Loss: 0.3810\n",
      "Optimization Iteration:  38913, Training Accuracy:  75.0%, Loss: 0.4006\n",
      "Optimization Iteration:  38977, Training Accuracy:  68.8%, Loss: 0.4519\n",
      "Optimization Iteration:  39041, Training Accuracy:  78.1%, Loss: 0.3878\n",
      "Optimization Iteration:  39105, Training Accuracy:  68.8%, Loss: 0.4667\n",
      "Optimization Iteration:  39169, Training Accuracy:  67.2%, Loss: 0.4747\n",
      "Optimization Iteration:  39233, Training Accuracy:  68.8%, Loss: 0.4642\n",
      "Optimization Iteration:  39297, Training Accuracy:  71.9%, Loss: 0.4026\n",
      "Optimization Iteration:  39361, Training Accuracy:  75.0%, Loss: 0.4040\n",
      "Optimization Iteration:  39425, Training Accuracy:  71.9%, Loss: 0.4707\n",
      "Optimization Iteration:  39489, Training Accuracy:  71.9%, Loss: 0.3854\n",
      "Optimization Iteration:  39553, Training Accuracy:  75.0%, Loss: 0.4266\n",
      "Optimization Iteration:  39617, Training Accuracy:  81.2%, Loss: 0.3951\n",
      "Optimization Iteration:  39681, Training Accuracy:  76.6%, Loss: 0.3775\n",
      "Optimization Iteration:  39745, Training Accuracy:  82.8%, Loss: 0.4124\n",
      "Optimization Iteration:  39809, Training Accuracy:  71.9%, Loss: 0.4151\n",
      "Optimization Iteration:  39873, Training Accuracy:  75.0%, Loss: 0.4012\n",
      "Optimization Iteration:  39937, Training Accuracy:  75.0%, Loss: 0.5417\n",
      "Optimization Iteration:  40001, Training Accuracy:  71.9%, Loss: 0.4101\n",
      "Optimization Iteration:  40065, Training Accuracy:  71.9%, Loss: 0.3328\n",
      "Optimization Iteration:  40129, Training Accuracy:  71.9%, Loss: 0.4134\n",
      "Optimization Iteration:  40193, Training Accuracy:  87.5%, Loss: 0.3389\n",
      "Optimization Iteration:  40257, Training Accuracy:  81.2%, Loss: 0.3509\n",
      "Optimization Iteration:  40321, Training Accuracy:  67.2%, Loss: 0.4389\n",
      "Optimization Iteration:  40385, Training Accuracy:  78.1%, Loss: 0.3928\n",
      "Optimization Iteration:  40449, Training Accuracy:  73.4%, Loss: 0.3527\n",
      "Optimization Iteration:  40513, Training Accuracy:  81.2%, Loss: 0.3234\n",
      "Optimization Iteration:  40577, Training Accuracy:  85.9%, Loss: 0.3579\n",
      "Optimization Iteration:  40641, Training Accuracy:  71.9%, Loss: 0.3749\n",
      "Optimization Iteration:  40705, Training Accuracy:  79.7%, Loss: 0.3662\n",
      "Optimization Iteration:  40769, Training Accuracy:  82.8%, Loss: 0.3505\n",
      "Optimization Iteration:  40833, Training Accuracy:  82.8%, Loss: 0.3458\n",
      "Optimization Iteration:  40897, Training Accuracy:  75.0%, Loss: 0.4008\n",
      "Optimization Iteration:  40961, Training Accuracy:  75.0%, Loss: 0.4157\n",
      "Optimization Iteration:  41025, Training Accuracy:  79.7%, Loss: 0.3797\n",
      "Optimization Iteration:  41089, Training Accuracy:  75.0%, Loss: 0.4297\n",
      "Optimization Iteration:  41153, Training Accuracy:  75.0%, Loss: 0.4196\n",
      "Optimization Iteration:  41217, Training Accuracy:  84.4%, Loss: 0.3441\n",
      "Optimization Iteration:  41281, Training Accuracy:  67.2%, Loss: 0.4388\n",
      "Optimization Iteration:  41345, Training Accuracy:  73.4%, Loss: 0.4095\n",
      "Optimization Iteration:  41409, Training Accuracy:  75.0%, Loss: 0.3892\n",
      "Optimization Iteration:  41473, Training Accuracy:  84.4%, Loss: 0.4168\n",
      "Optimization Iteration:  41537, Training Accuracy:  84.4%, Loss: 0.3743\n",
      "Optimization Iteration:  41601, Training Accuracy:  75.0%, Loss: 0.4747\n",
      "Optimization Iteration:  41665, Training Accuracy:  78.1%, Loss: 0.3841\n",
      "Optimization Iteration:  41729, Training Accuracy:  81.2%, Loss: 0.3101\n",
      "Optimization Iteration:  41793, Training Accuracy:  79.7%, Loss: 0.3921\n",
      "Optimization Iteration:  41857, Training Accuracy:  60.9%, Loss: 0.5510\n",
      "Optimization Iteration:  41921, Training Accuracy:  84.4%, Loss: 0.3232\n",
      "Optimization Iteration:  41985, Training Accuracy:  62.5%, Loss: 0.5023\n",
      "Optimization Iteration:  42049, Training Accuracy:  73.4%, Loss: 0.4146\n",
      "Optimization Iteration:  42113, Training Accuracy:  82.8%, Loss: 0.3892\n",
      "Optimization Iteration:  42177, Training Accuracy:  78.1%, Loss: 0.3961\n",
      "Optimization Iteration:  42241, Training Accuracy:  75.0%, Loss: 0.4288\n",
      "Optimization Iteration:  42305, Training Accuracy:  76.6%, Loss: 0.4867\n",
      "Optimization Iteration:  42369, Training Accuracy:  79.7%, Loss: 0.4007\n",
      "Optimization Iteration:  42433, Training Accuracy:  75.0%, Loss: 0.4382\n",
      "Optimization Iteration:  42497, Training Accuracy:  79.7%, Loss: 0.3959\n",
      "Optimization Iteration:  42561, Training Accuracy:  76.6%, Loss: 0.4143\n",
      "Optimization Iteration:  42625, Training Accuracy:  76.6%, Loss: 0.4020\n",
      "Optimization Iteration:  42689, Training Accuracy:  73.4%, Loss: 0.3570\n",
      "Optimization Iteration:  42753, Training Accuracy:  67.2%, Loss: 0.4631\n",
      "Optimization Iteration:  42817, Training Accuracy:  82.8%, Loss: 0.2951\n",
      "Optimization Iteration:  42881, Training Accuracy:  75.0%, Loss: 0.5072\n",
      "Optimization Iteration:  42945, Training Accuracy:  68.8%, Loss: 0.3956\n",
      "Optimization Iteration:  43009, Training Accuracy:  70.3%, Loss: 0.4334\n",
      "Optimization Iteration:  43073, Training Accuracy:  78.1%, Loss: 0.4216\n",
      "Optimization Iteration:  43137, Training Accuracy:  78.1%, Loss: 0.3986\n",
      "Optimization Iteration:  43201, Training Accuracy:  68.8%, Loss: 0.4221\n",
      "Optimization Iteration:  43265, Training Accuracy:  78.1%, Loss: 0.3197\n",
      "Optimization Iteration:  43329, Training Accuracy:  78.1%, Loss: 0.3934\n",
      "Optimization Iteration:  43393, Training Accuracy:  71.9%, Loss: 0.3561\n",
      "Optimization Iteration:  43457, Training Accuracy:  84.4%, Loss: 0.3099\n",
      "Optimization Iteration:  43521, Training Accuracy:  79.7%, Loss: 0.3424\n",
      "Optimization Iteration:  43585, Training Accuracy:  75.0%, Loss: 0.4015\n",
      "Optimization Iteration:  43649, Training Accuracy:  76.6%, Loss: 0.4408\n",
      "Optimization Iteration:  43713, Training Accuracy:  79.7%, Loss: 0.3554\n",
      "Optimization Iteration:  43777, Training Accuracy:  82.8%, Loss: 0.2752\n",
      "Optimization Iteration:  43841, Training Accuracy:  70.3%, Loss: 0.4403\n",
      "Optimization Iteration:  43905, Training Accuracy:  71.9%, Loss: 0.4276\n",
      "Optimization Iteration:  43969, Training Accuracy:  73.4%, Loss: 0.3189\n",
      "Optimization Iteration:  44033, Training Accuracy:  75.0%, Loss: 0.3893\n",
      "Optimization Iteration:  44097, Training Accuracy:  82.8%, Loss: 0.3247\n",
      "Optimization Iteration:  44161, Training Accuracy:  81.2%, Loss: 0.4040\n",
      "Optimization Iteration:  44225, Training Accuracy:  71.9%, Loss: 0.4373\n",
      "Optimization Iteration:  44289, Training Accuracy:  75.0%, Loss: 0.4327\n",
      "Optimization Iteration:  44353, Training Accuracy:  78.1%, Loss: 0.4609\n",
      "Optimization Iteration:  44417, Training Accuracy:  82.8%, Loss: 0.3418\n",
      "Optimization Iteration:  44481, Training Accuracy:  79.7%, Loss: 0.3855\n",
      "Optimization Iteration:  44545, Training Accuracy:  76.6%, Loss: 0.3728\n",
      "Optimization Iteration:  44609, Training Accuracy:  78.1%, Loss: 0.3587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  44673, Training Accuracy:  62.5%, Loss: 0.6068\n",
      "Optimization Iteration:  44737, Training Accuracy:  78.1%, Loss: 0.3695\n",
      "Optimization Iteration:  44801, Training Accuracy:  76.6%, Loss: 0.3974\n",
      "Optimization Iteration:  44865, Training Accuracy:  78.1%, Loss: 0.4070\n",
      "Optimization Iteration:  44929, Training Accuracy:  76.6%, Loss: 0.3876\n",
      "Optimization Iteration:  44993, Training Accuracy:  82.8%, Loss: 0.4023\n",
      "Optimization Iteration:  45057, Training Accuracy:  75.0%, Loss: 0.4327\n",
      "Optimization Iteration:  45121, Training Accuracy:  81.2%, Loss: 0.3777\n",
      "Optimization Iteration:  45185, Training Accuracy:  87.5%, Loss: 0.3122\n",
      "Optimization Iteration:  45249, Training Accuracy:  68.8%, Loss: 0.4199\n",
      "Optimization Iteration:  45313, Training Accuracy:  81.2%, Loss: 0.3764\n",
      "Optimization Iteration:  45377, Training Accuracy:  79.7%, Loss: 0.3755\n",
      "Optimization Iteration:  45441, Training Accuracy:  84.4%, Loss: 0.3885\n",
      "Optimization Iteration:  45505, Training Accuracy:  71.9%, Loss: 0.4472\n",
      "Optimization Iteration:  45569, Training Accuracy:  68.8%, Loss: 0.5020\n",
      "Optimization Iteration:  45633, Training Accuracy:  76.6%, Loss: 0.4474\n",
      "Optimization Iteration:  45697, Training Accuracy:  79.7%, Loss: 0.3882\n",
      "Optimization Iteration:  45761, Training Accuracy:  90.6%, Loss: 0.3064\n",
      "Optimization Iteration:  45825, Training Accuracy:  79.7%, Loss: 0.3404\n",
      "Optimization Iteration:  45889, Training Accuracy:  73.4%, Loss: 0.4162\n",
      "Optimization Iteration:  45953, Training Accuracy:  82.8%, Loss: 0.3265\n",
      "Optimization Iteration:  46017, Training Accuracy:  71.9%, Loss: 0.4145\n",
      "Optimization Iteration:  46081, Training Accuracy:  71.9%, Loss: 0.4027\n",
      "Optimization Iteration:  46145, Training Accuracy:  73.4%, Loss: 0.4205\n",
      "Optimization Iteration:  46209, Training Accuracy:  81.2%, Loss: 0.3408\n",
      "Optimization Iteration:  46273, Training Accuracy:  73.4%, Loss: 0.4779\n",
      "Optimization Iteration:  46337, Training Accuracy:  81.2%, Loss: 0.4044\n",
      "Optimization Iteration:  46401, Training Accuracy:  81.2%, Loss: 0.3257\n",
      "Optimization Iteration:  46465, Training Accuracy:  82.8%, Loss: 0.4016\n",
      "Optimization Iteration:  46529, Training Accuracy:  68.8%, Loss: 0.5251\n",
      "Optimization Iteration:  46593, Training Accuracy:  76.6%, Loss: 0.3620\n",
      "Optimization Iteration:  46657, Training Accuracy:  75.0%, Loss: 0.4604\n",
      "Optimization Iteration:  46721, Training Accuracy:  78.1%, Loss: 0.3465\n",
      "Optimization Iteration:  46785, Training Accuracy:  75.0%, Loss: 0.4517\n",
      "Optimization Iteration:  46849, Training Accuracy:  75.0%, Loss: 0.4001\n",
      "Optimization Iteration:  46913, Training Accuracy:  75.0%, Loss: 0.3697\n",
      "Optimization Iteration:  46977, Training Accuracy:  71.9%, Loss: 0.4152\n",
      "Optimization Iteration:  47041, Training Accuracy:  81.2%, Loss: 0.4149\n",
      "Optimization Iteration:  47105, Training Accuracy:  79.7%, Loss: 0.4172\n",
      "Optimization Iteration:  47169, Training Accuracy:  71.9%, Loss: 0.4725\n",
      "Optimization Iteration:  47233, Training Accuracy:  78.1%, Loss: 0.4054\n",
      "Optimization Iteration:  47297, Training Accuracy:  73.4%, Loss: 0.3527\n",
      "Optimization Iteration:  47361, Training Accuracy:  73.4%, Loss: 0.3468\n",
      "Optimization Iteration:  47425, Training Accuracy:  76.6%, Loss: 0.3876\n",
      "Optimization Iteration:  47489, Training Accuracy:  76.6%, Loss: 0.4051\n",
      "Optimization Iteration:  47553, Training Accuracy:  81.2%, Loss: 0.4090\n",
      "Optimization Iteration:  47617, Training Accuracy:  71.9%, Loss: 0.3992\n",
      "Optimization Iteration:  47681, Training Accuracy:  79.7%, Loss: 0.3675\n",
      "Optimization Iteration:  47745, Training Accuracy:  75.0%, Loss: 0.4168\n",
      "Optimization Iteration:  47809, Training Accuracy:  75.0%, Loss: 0.3766\n",
      "Optimization Iteration:  47873, Training Accuracy:  84.4%, Loss: 0.2775\n",
      "Optimization Iteration:  47937, Training Accuracy:  75.0%, Loss: 0.4015\n",
      "Optimization Iteration:  48001, Training Accuracy:  79.7%, Loss: 0.4230\n",
      "Optimization Iteration:  48065, Training Accuracy:  71.9%, Loss: 0.4331\n",
      "Optimization Iteration:  48129, Training Accuracy:  73.4%, Loss: 0.3907\n",
      "Optimization Iteration:  48193, Training Accuracy:  78.1%, Loss: 0.4521\n",
      "Optimization Iteration:  48257, Training Accuracy:  76.6%, Loss: 0.3383\n",
      "Optimization Iteration:  48321, Training Accuracy:  67.2%, Loss: 0.4146\n",
      "Optimization Iteration:  48385, Training Accuracy:  70.3%, Loss: 0.4076\n",
      "Optimization Iteration:  48449, Training Accuracy:  75.0%, Loss: 0.3775\n",
      "Optimization Iteration:  48513, Training Accuracy:  67.2%, Loss: 0.4287\n",
      "Optimization Iteration:  48577, Training Accuracy:  65.6%, Loss: 0.5273\n",
      "Optimization Iteration:  48641, Training Accuracy:  70.3%, Loss: 0.3976\n",
      "Optimization Iteration:  48705, Training Accuracy:  82.8%, Loss: 0.3607\n",
      "Optimization Iteration:  48769, Training Accuracy:  84.4%, Loss: 0.3501\n",
      "Optimization Iteration:  48833, Training Accuracy:  82.8%, Loss: 0.3606\n",
      "Optimization Iteration:  48897, Training Accuracy:  68.8%, Loss: 0.5051\n",
      "Optimization Iteration:  48961, Training Accuracy:  73.4%, Loss: 0.4471\n",
      "Optimization Iteration:  49025, Training Accuracy:  78.1%, Loss: 0.4340\n",
      "Optimization Iteration:  49089, Training Accuracy:  65.6%, Loss: 0.4787\n",
      "Optimization Iteration:  49153, Training Accuracy:  73.4%, Loss: 0.3503\n",
      "Optimization Iteration:  49217, Training Accuracy:  73.4%, Loss: 0.4239\n",
      "Optimization Iteration:  49281, Training Accuracy:  73.4%, Loss: 0.3585\n",
      "Optimization Iteration:  49345, Training Accuracy:  70.3%, Loss: 0.3993\n",
      "Optimization Iteration:  49409, Training Accuracy:  76.6%, Loss: 0.3900\n",
      "Optimization Iteration:  49473, Training Accuracy:  73.4%, Loss: 0.4004\n",
      "Optimization Iteration:  49537, Training Accuracy:  76.6%, Loss: 0.3602\n",
      "Optimization Iteration:  49601, Training Accuracy:  79.7%, Loss: 0.3826\n",
      "Optimization Iteration:  49665, Training Accuracy:  82.8%, Loss: 0.3307\n",
      "Optimization Iteration:  49729, Training Accuracy:  75.0%, Loss: 0.4069\n",
      "Optimization Iteration:  49793, Training Accuracy:  73.4%, Loss: 0.4041\n",
      "Optimization Iteration:  49857, Training Accuracy:  71.9%, Loss: 0.4199\n",
      "Optimization Iteration:  49921, Training Accuracy:  82.8%, Loss: 0.3964\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 18\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  70.3%, Loss: 0.4348\n",
      "Optimization Iteration:    129, Training Accuracy:  71.9%, Loss: 0.4544\n",
      "Optimization Iteration:    193, Training Accuracy:  73.4%, Loss: 0.4227\n",
      "Optimization Iteration:    257, Training Accuracy:  67.2%, Loss: 0.3917\n",
      "Optimization Iteration:    321, Training Accuracy:  73.4%, Loss: 0.3947\n",
      "Optimization Iteration:    385, Training Accuracy:  75.0%, Loss: 0.3623\n",
      "Optimization Iteration:    449, Training Accuracy:  79.7%, Loss: 0.3359\n",
      "Optimization Iteration:    513, Training Accuracy:  68.8%, Loss: 0.4861\n",
      "Optimization Iteration:    577, Training Accuracy:  56.2%, Loss: 0.5596\n",
      "Optimization Iteration:    641, Training Accuracy:  75.0%, Loss: 0.3769\n",
      "Optimization Iteration:    705, Training Accuracy:  75.0%, Loss: 0.4232\n",
      "Optimization Iteration:    769, Training Accuracy:  84.4%, Loss: 0.3550\n",
      "Optimization Iteration:    833, Training Accuracy:  81.2%, Loss: 0.3656\n",
      "Optimization Iteration:    897, Training Accuracy:  70.3%, Loss: 0.3681\n",
      "Optimization Iteration:    961, Training Accuracy:  79.7%, Loss: 0.2670\n",
      "Optimization Iteration:   1025, Training Accuracy:  79.7%, Loss: 0.3689\n",
      "Optimization Iteration:   1089, Training Accuracy:  68.8%, Loss: 0.4501\n",
      "Optimization Iteration:   1153, Training Accuracy:  71.9%, Loss: 0.4190\n",
      "Optimization Iteration:   1217, Training Accuracy:  71.9%, Loss: 0.3440\n",
      "Optimization Iteration:   1281, Training Accuracy:  73.4%, Loss: 0.5153\n",
      "Optimization Iteration:   1345, Training Accuracy:  78.1%, Loss: 0.4424\n",
      "Optimization Iteration:   1409, Training Accuracy:  82.8%, Loss: 0.3467\n",
      "Optimization Iteration:   1473, Training Accuracy:  70.3%, Loss: 0.4598\n",
      "Optimization Iteration:   1537, Training Accuracy:  75.0%, Loss: 0.3681\n",
      "Optimization Iteration:   1601, Training Accuracy:  84.4%, Loss: 0.3229\n",
      "Optimization Iteration:   1665, Training Accuracy:  78.1%, Loss: 0.3848\n",
      "Optimization Iteration:   1729, Training Accuracy:  79.7%, Loss: 0.3962\n",
      "Optimization Iteration:   1793, Training Accuracy:  82.8%, Loss: 0.3962\n",
      "Optimization Iteration:   1857, Training Accuracy:  73.4%, Loss: 0.3976\n",
      "Optimization Iteration:   1921, Training Accuracy:  73.4%, Loss: 0.4915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   1985, Training Accuracy:  76.6%, Loss: 0.3983\n",
      "Optimization Iteration:   2049, Training Accuracy:  75.0%, Loss: 0.3755\n",
      "Optimization Iteration:   2113, Training Accuracy:  79.7%, Loss: 0.3543\n",
      "Optimization Iteration:   2177, Training Accuracy:  82.8%, Loss: 0.3117\n",
      "Optimization Iteration:   2241, Training Accuracy:  76.6%, Loss: 0.3715\n",
      "Optimization Iteration:   2305, Training Accuracy:  75.0%, Loss: 0.3820\n",
      "Optimization Iteration:   2369, Training Accuracy:  67.2%, Loss: 0.5240\n",
      "Optimization Iteration:   2433, Training Accuracy:  76.6%, Loss: 0.3902\n",
      "Optimization Iteration:   2497, Training Accuracy:  79.7%, Loss: 0.3600\n",
      "Optimization Iteration:   2561, Training Accuracy:  75.0%, Loss: 0.3232\n",
      "Optimization Iteration:   2625, Training Accuracy:  75.0%, Loss: 0.3883\n",
      "Optimization Iteration:   2689, Training Accuracy:  75.0%, Loss: 0.3964\n",
      "Optimization Iteration:   2753, Training Accuracy:  76.6%, Loss: 0.3886\n",
      "Optimization Iteration:   2817, Training Accuracy:  84.4%, Loss: 0.3675\n",
      "Optimization Iteration:   2881, Training Accuracy:  64.1%, Loss: 0.4328\n",
      "Optimization Iteration:   2945, Training Accuracy:  75.0%, Loss: 0.4630\n",
      "Optimization Iteration:   3009, Training Accuracy:  78.1%, Loss: 0.3842\n",
      "Optimization Iteration:   3073, Training Accuracy:  81.2%, Loss: 0.3444\n",
      "Optimization Iteration:   3137, Training Accuracy:  79.7%, Loss: 0.3717\n",
      "Optimization Iteration:   3201, Training Accuracy:  84.4%, Loss: 0.3146\n",
      "Optimization Iteration:   3265, Training Accuracy:  82.8%, Loss: 0.3317\n",
      "Optimization Iteration:   3329, Training Accuracy:  76.6%, Loss: 0.4423\n",
      "Optimization Iteration:   3393, Training Accuracy:  76.6%, Loss: 0.3712\n",
      "Optimization Iteration:   3457, Training Accuracy:  76.6%, Loss: 0.3843\n",
      "Optimization Iteration:   3521, Training Accuracy:  71.9%, Loss: 0.4170\n",
      "Optimization Iteration:   3585, Training Accuracy:  73.4%, Loss: 0.4376\n",
      "Optimization Iteration:   3649, Training Accuracy:  73.4%, Loss: 0.3551\n",
      "Optimization Iteration:   3713, Training Accuracy:  75.0%, Loss: 0.3763\n",
      "Optimization Iteration:   3777, Training Accuracy:  68.8%, Loss: 0.4478\n",
      "Optimization Iteration:   3841, Training Accuracy:  70.3%, Loss: 0.3903\n",
      "Optimization Iteration:   3905, Training Accuracy:  82.8%, Loss: 0.3762\n",
      "Optimization Iteration:   3969, Training Accuracy:  82.8%, Loss: 0.3567\n",
      "Optimization Iteration:   4033, Training Accuracy:  81.2%, Loss: 0.3199\n",
      "Optimization Iteration:   4097, Training Accuracy:  76.6%, Loss: 0.3885\n",
      "Optimization Iteration:   4161, Training Accuracy:  76.6%, Loss: 0.4170\n",
      "Optimization Iteration:   4225, Training Accuracy:  79.7%, Loss: 0.3699\n",
      "Optimization Iteration:   4289, Training Accuracy:  79.7%, Loss: 0.3547\n",
      "Optimization Iteration:   4353, Training Accuracy:  73.4%, Loss: 0.4486\n",
      "Optimization Iteration:   4417, Training Accuracy:  75.0%, Loss: 0.4273\n",
      "Optimization Iteration:   4481, Training Accuracy:  68.8%, Loss: 0.4099\n",
      "Optimization Iteration:   4545, Training Accuracy:  67.2%, Loss: 0.4664\n",
      "Optimization Iteration:   4609, Training Accuracy:  82.8%, Loss: 0.4014\n",
      "Optimization Iteration:   4673, Training Accuracy:  82.8%, Loss: 0.3778\n",
      "Optimization Iteration:   4737, Training Accuracy:  79.7%, Loss: 0.3808\n",
      "Optimization Iteration:   4801, Training Accuracy:  62.5%, Loss: 0.4691\n",
      "Optimization Iteration:   4865, Training Accuracy:  75.0%, Loss: 0.3937\n",
      "Optimization Iteration:   4929, Training Accuracy:  78.1%, Loss: 0.3940\n",
      "Optimization Iteration:   4993, Training Accuracy:  79.7%, Loss: 0.3804\n",
      "Optimization Iteration:   5057, Training Accuracy:  75.0%, Loss: 0.4422\n",
      "Optimization Iteration:   5121, Training Accuracy:  79.7%, Loss: 0.3363\n",
      "Optimization Iteration:   5185, Training Accuracy:  73.4%, Loss: 0.3730\n",
      "Optimization Iteration:   5249, Training Accuracy:  54.7%, Loss: 0.5095\n",
      "Optimization Iteration:   5313, Training Accuracy:  73.4%, Loss: 0.4160\n",
      "Optimization Iteration:   5377, Training Accuracy:  81.2%, Loss: 0.3414\n",
      "Optimization Iteration:   5441, Training Accuracy:  73.4%, Loss: 0.3693\n",
      "Optimization Iteration:   5505, Training Accuracy:  85.9%, Loss: 0.3086\n",
      "Optimization Iteration:   5569, Training Accuracy:  82.8%, Loss: 0.3861\n",
      "Optimization Iteration:   5633, Training Accuracy:  73.4%, Loss: 0.3239\n",
      "Optimization Iteration:   5697, Training Accuracy:  78.1%, Loss: 0.3715\n",
      "Optimization Iteration:   5761, Training Accuracy:  81.2%, Loss: 0.3239\n",
      "Optimization Iteration:   5825, Training Accuracy:  70.3%, Loss: 0.4173\n",
      "Optimization Iteration:   5889, Training Accuracy:  82.8%, Loss: 0.3496\n",
      "Optimization Iteration:   5953, Training Accuracy:  73.4%, Loss: 0.4674\n",
      "Optimization Iteration:   6017, Training Accuracy:  62.5%, Loss: 0.5401\n",
      "Optimization Iteration:   6081, Training Accuracy:  85.9%, Loss: 0.3234\n",
      "Optimization Iteration:   6145, Training Accuracy:  73.4%, Loss: 0.4806\n",
      "Optimization Iteration:   6209, Training Accuracy:  76.6%, Loss: 0.3599\n",
      "Optimization Iteration:   6273, Training Accuracy:  79.7%, Loss: 0.3708\n",
      "Optimization Iteration:   6337, Training Accuracy:  71.9%, Loss: 0.4454\n",
      "Optimization Iteration:   6401, Training Accuracy:  82.8%, Loss: 0.3373\n",
      "Optimization Iteration:   6465, Training Accuracy:  84.4%, Loss: 0.3464\n",
      "Optimization Iteration:   6529, Training Accuracy:  84.4%, Loss: 0.3644\n",
      "Optimization Iteration:   6593, Training Accuracy:  75.0%, Loss: 0.3960\n",
      "Optimization Iteration:   6657, Training Accuracy:  78.1%, Loss: 0.3707\n",
      "Optimization Iteration:   6721, Training Accuracy:  79.7%, Loss: 0.3468\n",
      "Optimization Iteration:   6785, Training Accuracy:  70.3%, Loss: 0.4795\n",
      "Optimization Iteration:   6849, Training Accuracy:  81.2%, Loss: 0.4493\n",
      "Optimization Iteration:   6913, Training Accuracy:  78.1%, Loss: 0.3695\n",
      "Optimization Iteration:   6977, Training Accuracy:  76.6%, Loss: 0.4004\n",
      "Optimization Iteration:   7041, Training Accuracy:  79.7%, Loss: 0.3384\n",
      "Optimization Iteration:   7105, Training Accuracy:  78.1%, Loss: 0.4100\n",
      "Optimization Iteration:   7169, Training Accuracy:  78.1%, Loss: 0.3753\n",
      "Optimization Iteration:   7233, Training Accuracy:  71.9%, Loss: 0.4302\n",
      "Optimization Iteration:   7297, Training Accuracy:  73.4%, Loss: 0.5337\n",
      "Optimization Iteration:   7361, Training Accuracy:  82.8%, Loss: 0.3543\n",
      "Optimization Iteration:   7425, Training Accuracy:  70.3%, Loss: 0.3794\n",
      "Optimization Iteration:   7489, Training Accuracy:  79.7%, Loss: 0.4562\n",
      "Optimization Iteration:   7553, Training Accuracy:  81.2%, Loss: 0.3675\n",
      "Optimization Iteration:   7617, Training Accuracy:  75.0%, Loss: 0.3509\n",
      "Optimization Iteration:   7681, Training Accuracy:  78.1%, Loss: 0.4124\n",
      "Optimization Iteration:   7745, Training Accuracy:  78.1%, Loss: 0.3357\n",
      "Optimization Iteration:   7809, Training Accuracy:  73.4%, Loss: 0.4801\n",
      "Optimization Iteration:   7873, Training Accuracy:  76.6%, Loss: 0.3360\n",
      "Optimization Iteration:   7937, Training Accuracy:  73.4%, Loss: 0.4218\n",
      "Optimization Iteration:   8001, Training Accuracy:  70.3%, Loss: 0.4248\n",
      "Optimization Iteration:   8065, Training Accuracy:  71.9%, Loss: 0.3993\n",
      "Optimization Iteration:   8129, Training Accuracy:  71.9%, Loss: 0.4160\n",
      "Optimization Iteration:   8193, Training Accuracy:  76.6%, Loss: 0.3681\n",
      "Optimization Iteration:   8257, Training Accuracy:  70.3%, Loss: 0.4784\n",
      "Optimization Iteration:   8321, Training Accuracy:  68.8%, Loss: 0.4400\n",
      "Optimization Iteration:   8385, Training Accuracy:  78.1%, Loss: 0.4180\n",
      "Optimization Iteration:   8449, Training Accuracy:  71.9%, Loss: 0.4462\n",
      "Optimization Iteration:   8513, Training Accuracy:  84.4%, Loss: 0.3313\n",
      "Optimization Iteration:   8577, Training Accuracy:  75.0%, Loss: 0.4238\n",
      "Optimization Iteration:   8641, Training Accuracy:  73.4%, Loss: 0.3959\n",
      "Optimization Iteration:   8705, Training Accuracy:  79.7%, Loss: 0.4116\n",
      "Optimization Iteration:   8769, Training Accuracy:  76.6%, Loss: 0.3617\n",
      "Optimization Iteration:   8833, Training Accuracy:  73.4%, Loss: 0.4306\n",
      "Optimization Iteration:   8897, Training Accuracy:  68.8%, Loss: 0.5041\n",
      "Optimization Iteration:   8961, Training Accuracy:  73.4%, Loss: 0.4445\n",
      "Optimization Iteration:   9025, Training Accuracy:  65.6%, Loss: 0.5011\n",
      "Optimization Iteration:   9089, Training Accuracy:  71.9%, Loss: 0.4731\n",
      "Optimization Iteration:   9153, Training Accuracy:  68.8%, Loss: 0.4147\n",
      "Optimization Iteration:   9217, Training Accuracy:  73.4%, Loss: 0.4137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   9281, Training Accuracy:  75.0%, Loss: 0.4254\n",
      "Optimization Iteration:   9345, Training Accuracy:  79.7%, Loss: 0.3494\n",
      "Optimization Iteration:   9409, Training Accuracy:  73.4%, Loss: 0.4435\n",
      "Optimization Iteration:   9473, Training Accuracy:  76.6%, Loss: 0.4041\n",
      "Optimization Iteration:   9537, Training Accuracy:  70.3%, Loss: 0.4011\n",
      "Optimization Iteration:   9601, Training Accuracy:  78.1%, Loss: 0.4031\n",
      "Optimization Iteration:   9665, Training Accuracy:  70.3%, Loss: 0.5277\n",
      "Optimization Iteration:   9729, Training Accuracy:  71.9%, Loss: 0.4459\n",
      "Optimization Iteration:   9793, Training Accuracy:  75.0%, Loss: 0.3857\n",
      "Optimization Iteration:   9857, Training Accuracy:  78.1%, Loss: 0.3769\n",
      "Optimization Iteration:   9921, Training Accuracy:  76.6%, Loss: 0.3946\n",
      "Optimization Iteration:   9985, Training Accuracy:  62.5%, Loss: 0.4631\n",
      "Optimization Iteration:  10049, Training Accuracy:  71.9%, Loss: 0.4149\n",
      "Optimization Iteration:  10113, Training Accuracy:  75.0%, Loss: 0.3994\n",
      "Optimization Iteration:  10177, Training Accuracy:  76.6%, Loss: 0.4934\n",
      "Optimization Iteration:  10241, Training Accuracy:  79.7%, Loss: 0.3827\n",
      "Optimization Iteration:  10305, Training Accuracy:  78.1%, Loss: 0.3812\n",
      "Optimization Iteration:  10369, Training Accuracy:  76.6%, Loss: 0.4086\n",
      "Optimization Iteration:  10433, Training Accuracy:  82.8%, Loss: 0.3361\n",
      "Optimization Iteration:  10497, Training Accuracy:  76.6%, Loss: 0.4534\n",
      "Optimization Iteration:  10561, Training Accuracy:  81.2%, Loss: 0.2716\n",
      "Optimization Iteration:  10625, Training Accuracy:  68.8%, Loss: 0.4225\n",
      "Optimization Iteration:  10689, Training Accuracy:  73.4%, Loss: 0.4317\n",
      "Optimization Iteration:  10753, Training Accuracy:  75.0%, Loss: 0.4273\n",
      "Optimization Iteration:  10817, Training Accuracy:  82.8%, Loss: 0.3817\n",
      "Optimization Iteration:  10881, Training Accuracy:  81.2%, Loss: 0.3012\n",
      "Optimization Iteration:  10945, Training Accuracy:  81.2%, Loss: 0.3318\n",
      "Optimization Iteration:  11009, Training Accuracy:  82.8%, Loss: 0.3586\n",
      "Optimization Iteration:  11073, Training Accuracy:  82.8%, Loss: 0.3530\n",
      "Optimization Iteration:  11137, Training Accuracy:  70.3%, Loss: 0.4345\n",
      "Optimization Iteration:  11201, Training Accuracy:  84.4%, Loss: 0.3453\n",
      "Optimization Iteration:  11265, Training Accuracy:  79.7%, Loss: 0.3484\n",
      "Optimization Iteration:  11329, Training Accuracy:  71.9%, Loss: 0.4880\n",
      "Optimization Iteration:  11393, Training Accuracy:  71.9%, Loss: 0.4245\n",
      "Optimization Iteration:  11457, Training Accuracy:  82.8%, Loss: 0.3917\n",
      "Optimization Iteration:  11521, Training Accuracy:  71.9%, Loss: 0.4216\n",
      "Optimization Iteration:  11585, Training Accuracy:  85.9%, Loss: 0.2989\n",
      "Optimization Iteration:  11649, Training Accuracy:  71.9%, Loss: 0.3893\n",
      "Optimization Iteration:  11713, Training Accuracy:  73.4%, Loss: 0.3771\n",
      "Optimization Iteration:  11777, Training Accuracy:  76.6%, Loss: 0.4125\n",
      "Optimization Iteration:  11841, Training Accuracy:  82.8%, Loss: 0.3704\n",
      "Optimization Iteration:  11905, Training Accuracy:  75.0%, Loss: 0.3847\n",
      "Optimization Iteration:  11969, Training Accuracy:  78.1%, Loss: 0.3868\n",
      "Optimization Iteration:  12033, Training Accuracy:  75.0%, Loss: 0.3730\n",
      "Optimization Iteration:  12097, Training Accuracy:  81.2%, Loss: 0.3487\n",
      "Optimization Iteration:  12161, Training Accuracy:  79.7%, Loss: 0.4405\n",
      "Optimization Iteration:  12225, Training Accuracy:  78.1%, Loss: 0.3327\n",
      "Optimization Iteration:  12289, Training Accuracy:  79.7%, Loss: 0.3731\n",
      "Optimization Iteration:  12353, Training Accuracy:  81.2%, Loss: 0.4116\n",
      "Optimization Iteration:  12417, Training Accuracy:  81.2%, Loss: 0.3909\n",
      "Optimization Iteration:  12481, Training Accuracy:  79.7%, Loss: 0.3935\n",
      "Optimization Iteration:  12545, Training Accuracy:  62.5%, Loss: 0.5060\n",
      "Optimization Iteration:  12609, Training Accuracy:  84.4%, Loss: 0.3310\n",
      "Optimization Iteration:  12673, Training Accuracy:  79.7%, Loss: 0.3924\n",
      "Optimization Iteration:  12737, Training Accuracy:  68.8%, Loss: 0.5047\n",
      "Optimization Iteration:  12801, Training Accuracy:  76.6%, Loss: 0.3632\n",
      "Optimization Iteration:  12865, Training Accuracy:  75.0%, Loss: 0.4158\n",
      "Optimization Iteration:  12929, Training Accuracy:  70.3%, Loss: 0.3820\n",
      "Optimization Iteration:  12993, Training Accuracy:  84.4%, Loss: 0.3864\n",
      "Optimization Iteration:  13057, Training Accuracy:  71.9%, Loss: 0.5077\n",
      "Optimization Iteration:  13121, Training Accuracy:  78.1%, Loss: 0.3613\n",
      "Optimization Iteration:  13185, Training Accuracy:  75.0%, Loss: 0.3980\n",
      "Optimization Iteration:  13249, Training Accuracy:  71.9%, Loss: 0.4066\n",
      "Optimization Iteration:  13313, Training Accuracy:  71.9%, Loss: 0.5189\n",
      "Optimization Iteration:  13377, Training Accuracy:  78.1%, Loss: 0.4308\n",
      "Optimization Iteration:  13441, Training Accuracy:  73.4%, Loss: 0.4110\n",
      "Optimization Iteration:  13505, Training Accuracy:  79.7%, Loss: 0.3827\n",
      "Optimization Iteration:  13569, Training Accuracy:  84.4%, Loss: 0.3042\n",
      "Optimization Iteration:  13633, Training Accuracy:  71.9%, Loss: 0.3555\n",
      "Optimization Iteration:  13697, Training Accuracy:  73.4%, Loss: 0.4345\n",
      "Optimization Iteration:  13761, Training Accuracy:  84.4%, Loss: 0.3269\n",
      "Optimization Iteration:  13825, Training Accuracy:  84.4%, Loss: 0.4240\n",
      "Optimization Iteration:  13889, Training Accuracy:  81.2%, Loss: 0.4016\n",
      "Optimization Iteration:  13953, Training Accuracy:  76.6%, Loss: 0.3578\n",
      "Optimization Iteration:  14017, Training Accuracy:  71.9%, Loss: 0.3951\n",
      "Optimization Iteration:  14081, Training Accuracy:  78.1%, Loss: 0.3657\n",
      "Optimization Iteration:  14145, Training Accuracy:  75.0%, Loss: 0.3676\n",
      "Optimization Iteration:  14209, Training Accuracy:  82.8%, Loss: 0.4235\n",
      "Optimization Iteration:  14273, Training Accuracy:  68.8%, Loss: 0.5032\n",
      "Optimization Iteration:  14337, Training Accuracy:  79.7%, Loss: 0.2763\n",
      "Optimization Iteration:  14401, Training Accuracy:  78.1%, Loss: 0.3643\n",
      "Optimization Iteration:  14465, Training Accuracy:  73.4%, Loss: 0.4636\n",
      "Optimization Iteration:  14529, Training Accuracy:  81.2%, Loss: 0.4234\n",
      "Optimization Iteration:  14593, Training Accuracy:  75.0%, Loss: 0.3785\n",
      "Optimization Iteration:  14657, Training Accuracy:  70.3%, Loss: 0.4842\n",
      "Optimization Iteration:  14721, Training Accuracy:  85.9%, Loss: 0.3098\n",
      "Optimization Iteration:  14785, Training Accuracy:  75.0%, Loss: 0.4802\n",
      "Optimization Iteration:  14849, Training Accuracy:  67.2%, Loss: 0.4415\n",
      "Optimization Iteration:  14913, Training Accuracy:  84.4%, Loss: 0.3263\n",
      "Optimization Iteration:  14977, Training Accuracy:  78.1%, Loss: 0.3930\n",
      "Optimization Iteration:  15041, Training Accuracy:  70.3%, Loss: 0.4637\n",
      "Optimization Iteration:  15105, Training Accuracy:  82.8%, Loss: 0.3278\n",
      "Optimization Iteration:  15169, Training Accuracy:  79.7%, Loss: 0.3224\n",
      "Optimization Iteration:  15233, Training Accuracy:  79.7%, Loss: 0.4285\n",
      "Optimization Iteration:  15297, Training Accuracy:  78.1%, Loss: 0.4135\n",
      "Optimization Iteration:  15361, Training Accuracy:  84.4%, Loss: 0.3622\n",
      "Optimization Iteration:  15425, Training Accuracy:  76.6%, Loss: 0.3866\n",
      "Optimization Iteration:  15489, Training Accuracy:  73.4%, Loss: 0.4051\n",
      "Optimization Iteration:  15553, Training Accuracy:  71.9%, Loss: 0.3563\n",
      "Optimization Iteration:  15617, Training Accuracy:  78.1%, Loss: 0.3767\n",
      "Optimization Iteration:  15681, Training Accuracy:  79.7%, Loss: 0.3756\n",
      "Optimization Iteration:  15745, Training Accuracy:  79.7%, Loss: 0.3159\n",
      "Optimization Iteration:  15809, Training Accuracy:  75.0%, Loss: 0.3501\n",
      "Optimization Iteration:  15873, Training Accuracy:  73.4%, Loss: 0.4053\n",
      "Optimization Iteration:  15937, Training Accuracy:  81.2%, Loss: 0.3663\n",
      "Optimization Iteration:  16001, Training Accuracy:  75.0%, Loss: 0.3544\n",
      "Optimization Iteration:  16065, Training Accuracy:  65.6%, Loss: 0.5298\n",
      "Optimization Iteration:  16129, Training Accuracy:  75.0%, Loss: 0.3553\n",
      "Optimization Iteration:  16193, Training Accuracy:  71.9%, Loss: 0.4450\n",
      "Optimization Iteration:  16257, Training Accuracy:  75.0%, Loss: 0.4425\n",
      "Optimization Iteration:  16321, Training Accuracy:  76.6%, Loss: 0.4505\n",
      "Optimization Iteration:  16385, Training Accuracy:  79.7%, Loss: 0.3839\n",
      "Optimization Iteration:  16449, Training Accuracy:  79.7%, Loss: 0.3597\n",
      "Optimization Iteration:  16513, Training Accuracy:  71.9%, Loss: 0.4446\n",
      "Optimization Iteration:  16577, Training Accuracy:  79.7%, Loss: 0.3415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  16641, Training Accuracy:  73.4%, Loss: 0.4690\n",
      "Optimization Iteration:  16705, Training Accuracy:  81.2%, Loss: 0.3569\n",
      "Optimization Iteration:  16769, Training Accuracy:  76.6%, Loss: 0.3753\n",
      "Optimization Iteration:  16833, Training Accuracy:  78.1%, Loss: 0.3967\n",
      "Optimization Iteration:  16897, Training Accuracy:  81.2%, Loss: 0.4222\n",
      "Optimization Iteration:  16961, Training Accuracy:  73.4%, Loss: 0.3662\n",
      "Optimization Iteration:  17025, Training Accuracy:  73.4%, Loss: 0.4479\n",
      "Optimization Iteration:  17089, Training Accuracy:  79.7%, Loss: 0.4357\n",
      "Optimization Iteration:  17153, Training Accuracy:  82.8%, Loss: 0.3739\n",
      "Optimization Iteration:  17217, Training Accuracy:  79.7%, Loss: 0.4882\n",
      "Optimization Iteration:  17281, Training Accuracy:  67.2%, Loss: 0.4884\n",
      "Optimization Iteration:  17345, Training Accuracy:  73.4%, Loss: 0.3778\n",
      "Optimization Iteration:  17409, Training Accuracy:  73.4%, Loss: 0.4652\n",
      "Optimization Iteration:  17473, Training Accuracy:  64.1%, Loss: 0.5051\n",
      "Optimization Iteration:  17537, Training Accuracy:  75.0%, Loss: 0.4078\n",
      "Optimization Iteration:  17601, Training Accuracy:  67.2%, Loss: 0.4341\n",
      "Optimization Iteration:  17665, Training Accuracy:  76.6%, Loss: 0.4205\n",
      "Optimization Iteration:  17729, Training Accuracy:  73.4%, Loss: 0.4348\n",
      "Optimization Iteration:  17793, Training Accuracy:  73.4%, Loss: 0.4192\n",
      "Optimization Iteration:  17857, Training Accuracy:  75.0%, Loss: 0.4067\n",
      "Optimization Iteration:  17921, Training Accuracy:  81.2%, Loss: 0.3428\n",
      "Optimization Iteration:  17985, Training Accuracy:  67.2%, Loss: 0.3703\n",
      "Optimization Iteration:  18049, Training Accuracy:  71.9%, Loss: 0.3943\n",
      "Optimization Iteration:  18113, Training Accuracy:  75.0%, Loss: 0.4206\n",
      "Optimization Iteration:  18177, Training Accuracy:  73.4%, Loss: 0.4155\n",
      "Optimization Iteration:  18241, Training Accuracy:  73.4%, Loss: 0.3558\n",
      "Optimization Iteration:  18305, Training Accuracy:  67.2%, Loss: 0.4386\n",
      "Optimization Iteration:  18369, Training Accuracy:  76.6%, Loss: 0.3862\n",
      "Optimization Iteration:  18433, Training Accuracy:  68.8%, Loss: 0.4701\n",
      "Optimization Iteration:  18497, Training Accuracy:  78.1%, Loss: 0.3293\n",
      "Optimization Iteration:  18561, Training Accuracy:  75.0%, Loss: 0.4072\n",
      "Optimization Iteration:  18625, Training Accuracy:  75.0%, Loss: 0.4439\n",
      "Optimization Iteration:  18689, Training Accuracy:  73.4%, Loss: 0.4312\n",
      "Optimization Iteration:  18753, Training Accuracy:  67.2%, Loss: 0.4535\n",
      "Optimization Iteration:  18817, Training Accuracy:  81.2%, Loss: 0.3463\n",
      "Optimization Iteration:  18881, Training Accuracy:  62.5%, Loss: 0.4736\n",
      "Optimization Iteration:  18945, Training Accuracy:  73.4%, Loss: 0.4493\n",
      "Optimization Iteration:  19009, Training Accuracy:  76.6%, Loss: 0.3473\n",
      "Optimization Iteration:  19073, Training Accuracy:  84.4%, Loss: 0.4107\n",
      "Optimization Iteration:  19137, Training Accuracy:  68.8%, Loss: 0.4344\n",
      "Optimization Iteration:  19201, Training Accuracy:  78.1%, Loss: 0.3713\n",
      "Optimization Iteration:  19265, Training Accuracy:  73.4%, Loss: 0.4012\n",
      "Optimization Iteration:  19329, Training Accuracy:  82.8%, Loss: 0.2941\n",
      "Optimization Iteration:  19393, Training Accuracy:  78.1%, Loss: 0.3456\n",
      "Optimization Iteration:  19457, Training Accuracy:  73.4%, Loss: 0.4392\n",
      "Optimization Iteration:  19521, Training Accuracy:  68.8%, Loss: 0.4424\n",
      "Optimization Iteration:  19585, Training Accuracy:  68.8%, Loss: 0.4381\n",
      "Optimization Iteration:  19649, Training Accuracy:  78.1%, Loss: 0.4492\n",
      "Optimization Iteration:  19713, Training Accuracy:  82.8%, Loss: 0.3307\n",
      "Optimization Iteration:  19777, Training Accuracy:  79.7%, Loss: 0.4459\n",
      "Optimization Iteration:  19841, Training Accuracy:  67.2%, Loss: 0.4318\n",
      "Optimization Iteration:  19905, Training Accuracy:  71.9%, Loss: 0.4268\n",
      "Optimization Iteration:  19969, Training Accuracy:  75.0%, Loss: 0.4165\n",
      "Optimization Iteration:  20033, Training Accuracy:  79.7%, Loss: 0.3491\n",
      "Optimization Iteration:  20097, Training Accuracy:  78.1%, Loss: 0.4488\n",
      "Optimization Iteration:  20161, Training Accuracy:  76.6%, Loss: 0.3952\n",
      "Optimization Iteration:  20225, Training Accuracy:  73.4%, Loss: 0.4193\n",
      "Optimization Iteration:  20289, Training Accuracy:  73.4%, Loss: 0.4294\n",
      "Optimization Iteration:  20353, Training Accuracy:  75.0%, Loss: 0.3515\n",
      "Optimization Iteration:  20417, Training Accuracy:  68.8%, Loss: 0.4012\n",
      "Optimization Iteration:  20481, Training Accuracy:  79.7%, Loss: 0.3714\n",
      "Optimization Iteration:  20545, Training Accuracy:  81.2%, Loss: 0.3939\n",
      "Optimization Iteration:  20609, Training Accuracy:  73.4%, Loss: 0.4266\n",
      "Optimization Iteration:  20673, Training Accuracy:  76.6%, Loss: 0.4248\n",
      "Optimization Iteration:  20737, Training Accuracy:  82.8%, Loss: 0.3666\n",
      "Optimization Iteration:  20801, Training Accuracy:  65.6%, Loss: 0.4777\n",
      "Optimization Iteration:  20865, Training Accuracy:  78.1%, Loss: 0.3791\n",
      "Optimization Iteration:  20929, Training Accuracy:  75.0%, Loss: 0.3919\n",
      "Optimization Iteration:  20993, Training Accuracy:  71.9%, Loss: 0.4266\n",
      "Optimization Iteration:  21057, Training Accuracy:  81.2%, Loss: 0.4177\n",
      "Optimization Iteration:  21121, Training Accuracy:  75.0%, Loss: 0.4108\n",
      "Optimization Iteration:  21185, Training Accuracy:  75.0%, Loss: 0.4879\n",
      "Optimization Iteration:  21249, Training Accuracy:  70.3%, Loss: 0.4996\n",
      "Optimization Iteration:  21313, Training Accuracy:  71.9%, Loss: 0.4511\n",
      "Optimization Iteration:  21377, Training Accuracy:  76.6%, Loss: 0.3691\n",
      "Optimization Iteration:  21441, Training Accuracy:  65.6%, Loss: 0.4054\n",
      "Optimization Iteration:  21505, Training Accuracy:  78.1%, Loss: 0.3915\n",
      "Optimization Iteration:  21569, Training Accuracy:  85.9%, Loss: 0.3427\n",
      "Optimization Iteration:  21633, Training Accuracy:  79.7%, Loss: 0.3283\n",
      "Optimization Iteration:  21697, Training Accuracy:  75.0%, Loss: 0.4471\n",
      "Optimization Iteration:  21761, Training Accuracy:  81.2%, Loss: 0.3451\n",
      "Optimization Iteration:  21825, Training Accuracy:  73.4%, Loss: 0.4508\n",
      "Optimization Iteration:  21889, Training Accuracy:  82.8%, Loss: 0.3558\n",
      "Optimization Iteration:  21953, Training Accuracy:  71.9%, Loss: 0.5052\n",
      "Optimization Iteration:  22017, Training Accuracy:  78.1%, Loss: 0.4046\n",
      "Optimization Iteration:  22081, Training Accuracy:  84.4%, Loss: 0.3731\n",
      "Optimization Iteration:  22145, Training Accuracy:  82.8%, Loss: 0.4052\n",
      "Optimization Iteration:  22209, Training Accuracy:  71.9%, Loss: 0.4288\n",
      "Optimization Iteration:  22273, Training Accuracy:  75.0%, Loss: 0.3967\n",
      "Optimization Iteration:  22337, Training Accuracy:  84.4%, Loss: 0.3018\n",
      "Optimization Iteration:  22401, Training Accuracy:  68.8%, Loss: 0.4158\n",
      "Optimization Iteration:  22465, Training Accuracy:  75.0%, Loss: 0.4786\n",
      "Optimization Iteration:  22529, Training Accuracy:  68.8%, Loss: 0.3982\n",
      "Optimization Iteration:  22593, Training Accuracy:  70.3%, Loss: 0.4191\n",
      "Optimization Iteration:  22657, Training Accuracy:  71.9%, Loss: 0.3813\n",
      "Optimization Iteration:  22721, Training Accuracy:  73.4%, Loss: 0.4495\n",
      "Optimization Iteration:  22785, Training Accuracy:  68.8%, Loss: 0.4371\n",
      "Optimization Iteration:  22849, Training Accuracy:  71.9%, Loss: 0.3789\n",
      "Optimization Iteration:  22913, Training Accuracy:  75.0%, Loss: 0.4067\n",
      "Optimization Iteration:  22977, Training Accuracy:  78.1%, Loss: 0.4071\n",
      "Optimization Iteration:  23041, Training Accuracy:  79.7%, Loss: 0.3295\n",
      "Optimization Iteration:  23105, Training Accuracy:  79.7%, Loss: 0.3674\n",
      "Optimization Iteration:  23169, Training Accuracy:  79.7%, Loss: 0.3680\n",
      "Optimization Iteration:  23233, Training Accuracy:  71.9%, Loss: 0.4528\n",
      "Optimization Iteration:  23297, Training Accuracy:  78.1%, Loss: 0.4380\n",
      "Optimization Iteration:  23361, Training Accuracy:  75.0%, Loss: 0.4079\n",
      "Optimization Iteration:  23425, Training Accuracy:  85.9%, Loss: 0.3912\n",
      "Optimization Iteration:  23489, Training Accuracy:  84.4%, Loss: 0.4213\n",
      "Optimization Iteration:  23553, Training Accuracy:  81.2%, Loss: 0.3600\n",
      "Optimization Iteration:  23617, Training Accuracy:  76.6%, Loss: 0.4682\n",
      "Optimization Iteration:  23681, Training Accuracy:  78.1%, Loss: 0.3953\n",
      "Optimization Iteration:  23745, Training Accuracy:  79.7%, Loss: 0.3723\n",
      "Optimization Iteration:  23809, Training Accuracy:  67.2%, Loss: 0.4274\n",
      "Optimization Iteration:  23873, Training Accuracy:  75.0%, Loss: 0.3667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  23937, Training Accuracy:  71.9%, Loss: 0.4777\n",
      "Optimization Iteration:  24001, Training Accuracy:  81.2%, Loss: 0.2925\n",
      "Optimization Iteration:  24065, Training Accuracy:  70.3%, Loss: 0.3861\n",
      "Optimization Iteration:  24129, Training Accuracy:  79.7%, Loss: 0.4237\n",
      "Optimization Iteration:  24193, Training Accuracy:  75.0%, Loss: 0.3872\n",
      "Optimization Iteration:  24257, Training Accuracy:  75.0%, Loss: 0.4160\n",
      "Optimization Iteration:  24321, Training Accuracy:  79.7%, Loss: 0.3739\n",
      "Optimization Iteration:  24385, Training Accuracy:  76.6%, Loss: 0.4367\n",
      "Optimization Iteration:  24449, Training Accuracy:  78.1%, Loss: 0.3634\n",
      "Optimization Iteration:  24513, Training Accuracy:  76.6%, Loss: 0.4076\n",
      "Optimization Iteration:  24577, Training Accuracy:  64.1%, Loss: 0.5430\n",
      "Optimization Iteration:  24641, Training Accuracy:  73.4%, Loss: 0.4451\n",
      "Optimization Iteration:  24705, Training Accuracy:  84.4%, Loss: 0.3566\n",
      "Optimization Iteration:  24769, Training Accuracy:  70.3%, Loss: 0.4294\n",
      "Optimization Iteration:  24833, Training Accuracy:  76.6%, Loss: 0.3324\n",
      "Optimization Iteration:  24897, Training Accuracy:  75.0%, Loss: 0.3763\n",
      "Optimization Iteration:  24961, Training Accuracy:  75.0%, Loss: 0.3444\n",
      "Optimization Iteration:  25025, Training Accuracy:  84.4%, Loss: 0.3050\n",
      "Optimization Iteration:  25089, Training Accuracy:  79.7%, Loss: 0.3878\n",
      "Optimization Iteration:  25153, Training Accuracy:  78.1%, Loss: 0.3492\n",
      "Optimization Iteration:  25217, Training Accuracy:  79.7%, Loss: 0.4320\n",
      "Optimization Iteration:  25281, Training Accuracy:  79.7%, Loss: 0.3965\n",
      "Optimization Iteration:  25345, Training Accuracy:  78.1%, Loss: 0.4437\n",
      "Optimization Iteration:  25409, Training Accuracy:  75.0%, Loss: 0.4171\n",
      "Optimization Iteration:  25473, Training Accuracy:  75.0%, Loss: 0.4399\n",
      "Optimization Iteration:  25537, Training Accuracy:  73.4%, Loss: 0.4033\n",
      "Optimization Iteration:  25601, Training Accuracy:  76.6%, Loss: 0.4415\n",
      "Optimization Iteration:  25665, Training Accuracy:  71.9%, Loss: 0.4051\n",
      "Optimization Iteration:  25729, Training Accuracy:  78.1%, Loss: 0.3922\n",
      "Optimization Iteration:  25793, Training Accuracy:  84.4%, Loss: 0.2946\n",
      "Optimization Iteration:  25857, Training Accuracy:  75.0%, Loss: 0.4115\n",
      "Optimization Iteration:  25921, Training Accuracy:  79.7%, Loss: 0.3546\n",
      "Optimization Iteration:  25985, Training Accuracy:  78.1%, Loss: 0.4337\n",
      "Optimization Iteration:  26049, Training Accuracy:  76.6%, Loss: 0.4570\n",
      "Optimization Iteration:  26113, Training Accuracy:  76.6%, Loss: 0.4112\n",
      "Optimization Iteration:  26177, Training Accuracy:  78.1%, Loss: 0.3425\n",
      "Optimization Iteration:  26241, Training Accuracy:  68.8%, Loss: 0.4085\n",
      "Optimization Iteration:  26305, Training Accuracy:  75.0%, Loss: 0.4245\n",
      "Optimization Iteration:  26369, Training Accuracy:  81.2%, Loss: 0.3633\n",
      "Optimization Iteration:  26433, Training Accuracy:  78.1%, Loss: 0.3814\n",
      "Optimization Iteration:  26497, Training Accuracy:  75.0%, Loss: 0.3883\n",
      "Optimization Iteration:  26561, Training Accuracy:  76.6%, Loss: 0.3783\n",
      "Optimization Iteration:  26625, Training Accuracy:  70.3%, Loss: 0.4911\n",
      "Optimization Iteration:  26689, Training Accuracy:  76.6%, Loss: 0.4196\n",
      "Optimization Iteration:  26753, Training Accuracy:  79.7%, Loss: 0.4119\n",
      "Optimization Iteration:  26817, Training Accuracy:  70.3%, Loss: 0.4713\n",
      "Optimization Iteration:  26881, Training Accuracy:  73.4%, Loss: 0.3745\n",
      "Optimization Iteration:  26945, Training Accuracy:  68.8%, Loss: 0.4569\n",
      "Optimization Iteration:  27009, Training Accuracy:  84.4%, Loss: 0.3645\n",
      "Optimization Iteration:  27073, Training Accuracy:  78.1%, Loss: 0.3822\n",
      "Optimization Iteration:  27137, Training Accuracy:  89.1%, Loss: 0.3243\n",
      "Optimization Iteration:  27201, Training Accuracy:  81.2%, Loss: 0.3098\n",
      "Optimization Iteration:  27265, Training Accuracy:  81.2%, Loss: 0.4011\n",
      "Optimization Iteration:  27329, Training Accuracy:  65.6%, Loss: 0.4678\n",
      "Optimization Iteration:  27393, Training Accuracy:  76.6%, Loss: 0.3668\n",
      "Optimization Iteration:  27457, Training Accuracy:  71.9%, Loss: 0.3547\n",
      "Optimization Iteration:  27521, Training Accuracy:  67.2%, Loss: 0.4880\n",
      "Optimization Iteration:  27585, Training Accuracy:  75.0%, Loss: 0.3809\n",
      "Optimization Iteration:  27649, Training Accuracy:  70.3%, Loss: 0.3575\n",
      "Optimization Iteration:  27713, Training Accuracy:  73.4%, Loss: 0.4375\n",
      "Optimization Iteration:  27777, Training Accuracy:  76.6%, Loss: 0.4297\n",
      "Optimization Iteration:  27841, Training Accuracy:  73.4%, Loss: 0.3967\n",
      "Optimization Iteration:  27905, Training Accuracy:  78.1%, Loss: 0.3872\n",
      "Optimization Iteration:  27969, Training Accuracy:  73.4%, Loss: 0.4589\n",
      "Optimization Iteration:  28033, Training Accuracy:  81.2%, Loss: 0.3621\n",
      "Optimization Iteration:  28097, Training Accuracy:  68.8%, Loss: 0.3911\n",
      "Optimization Iteration:  28161, Training Accuracy:  82.8%, Loss: 0.3537\n",
      "Optimization Iteration:  28225, Training Accuracy:  81.2%, Loss: 0.3580\n",
      "Optimization Iteration:  28289, Training Accuracy:  75.0%, Loss: 0.3875\n",
      "Optimization Iteration:  28353, Training Accuracy:  76.6%, Loss: 0.3648\n",
      "Optimization Iteration:  28417, Training Accuracy:  79.7%, Loss: 0.3920\n",
      "Optimization Iteration:  28481, Training Accuracy:  78.1%, Loss: 0.3621\n",
      "Optimization Iteration:  28545, Training Accuracy:  81.2%, Loss: 0.3217\n",
      "Optimization Iteration:  28609, Training Accuracy:  84.4%, Loss: 0.4021\n",
      "Optimization Iteration:  28673, Training Accuracy:  73.4%, Loss: 0.4984\n",
      "Optimization Iteration:  28737, Training Accuracy:  70.3%, Loss: 0.4217\n",
      "Optimization Iteration:  28801, Training Accuracy:  79.7%, Loss: 0.2805\n",
      "Optimization Iteration:  28865, Training Accuracy:  85.9%, Loss: 0.3319\n",
      "Optimization Iteration:  28929, Training Accuracy:  73.4%, Loss: 0.3841\n",
      "Optimization Iteration:  28993, Training Accuracy:  71.9%, Loss: 0.4445\n",
      "Optimization Iteration:  29057, Training Accuracy:  78.1%, Loss: 0.4070\n",
      "Optimization Iteration:  29121, Training Accuracy:  76.6%, Loss: 0.4209\n",
      "Optimization Iteration:  29185, Training Accuracy:  68.8%, Loss: 0.4173\n",
      "Optimization Iteration:  29249, Training Accuracy:  73.4%, Loss: 0.4063\n",
      "Optimization Iteration:  29313, Training Accuracy:  81.2%, Loss: 0.3213\n",
      "Optimization Iteration:  29377, Training Accuracy:  75.0%, Loss: 0.3829\n",
      "Optimization Iteration:  29441, Training Accuracy:  76.6%, Loss: 0.4160\n",
      "Optimization Iteration:  29505, Training Accuracy:  79.7%, Loss: 0.4242\n",
      "Optimization Iteration:  29569, Training Accuracy:  70.3%, Loss: 0.4324\n",
      "Optimization Iteration:  29633, Training Accuracy:  70.3%, Loss: 0.4372\n",
      "Optimization Iteration:  29697, Training Accuracy:  79.7%, Loss: 0.3570\n",
      "Optimization Iteration:  29761, Training Accuracy:  78.1%, Loss: 0.3990\n",
      "Optimization Iteration:  29825, Training Accuracy:  64.1%, Loss: 0.4999\n",
      "Optimization Iteration:  29889, Training Accuracy:  78.1%, Loss: 0.4263\n",
      "Optimization Iteration:  29953, Training Accuracy:  71.9%, Loss: 0.4197\n",
      "Optimization Iteration:  30017, Training Accuracy:  85.9%, Loss: 0.2836\n",
      "Optimization Iteration:  30081, Training Accuracy:  81.2%, Loss: 0.3318\n",
      "Optimization Iteration:  30145, Training Accuracy:  84.4%, Loss: 0.3783\n",
      "Optimization Iteration:  30209, Training Accuracy:  76.6%, Loss: 0.3905\n",
      "Optimization Iteration:  30273, Training Accuracy:  79.7%, Loss: 0.4573\n",
      "Optimization Iteration:  30337, Training Accuracy:  81.2%, Loss: 0.3681\n",
      "Optimization Iteration:  30401, Training Accuracy:  73.4%, Loss: 0.4102\n",
      "Optimization Iteration:  30465, Training Accuracy:  71.9%, Loss: 0.5031\n",
      "Optimization Iteration:  30529, Training Accuracy:  73.4%, Loss: 0.4093\n",
      "Optimization Iteration:  30593, Training Accuracy:  78.1%, Loss: 0.3720\n",
      "Optimization Iteration:  30657, Training Accuracy:  76.6%, Loss: 0.4133\n",
      "Optimization Iteration:  30721, Training Accuracy:  81.2%, Loss: 0.3804\n",
      "Optimization Iteration:  30785, Training Accuracy:  73.4%, Loss: 0.3766\n",
      "Optimization Iteration:  30849, Training Accuracy:  73.4%, Loss: 0.4756\n",
      "Optimization Iteration:  30913, Training Accuracy:  81.2%, Loss: 0.3331\n",
      "Optimization Iteration:  30977, Training Accuracy:  68.8%, Loss: 0.4280\n",
      "Optimization Iteration:  31041, Training Accuracy:  81.2%, Loss: 0.3448\n",
      "Optimization Iteration:  31105, Training Accuracy:  76.6%, Loss: 0.4171\n",
      "Optimization Iteration:  31169, Training Accuracy:  75.0%, Loss: 0.3835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  31233, Training Accuracy:  75.0%, Loss: 0.4016\n",
      "Optimization Iteration:  31297, Training Accuracy:  76.6%, Loss: 0.3049\n",
      "Optimization Iteration:  31361, Training Accuracy:  75.0%, Loss: 0.4075\n",
      "Optimization Iteration:  31425, Training Accuracy:  84.4%, Loss: 0.2926\n",
      "Optimization Iteration:  31489, Training Accuracy:  79.7%, Loss: 0.3435\n",
      "Optimization Iteration:  31553, Training Accuracy:  75.0%, Loss: 0.3601\n",
      "Optimization Iteration:  31617, Training Accuracy:  76.6%, Loss: 0.2979\n",
      "Optimization Iteration:  31681, Training Accuracy:  81.2%, Loss: 0.4036\n",
      "Optimization Iteration:  31745, Training Accuracy:  73.4%, Loss: 0.4527\n",
      "Optimization Iteration:  31809, Training Accuracy:  67.2%, Loss: 0.4860\n",
      "Optimization Iteration:  31873, Training Accuracy:  78.1%, Loss: 0.3506\n",
      "Optimization Iteration:  31937, Training Accuracy:  70.3%, Loss: 0.4524\n",
      "Optimization Iteration:  32001, Training Accuracy:  75.0%, Loss: 0.4107\n",
      "Optimization Iteration:  32065, Training Accuracy:  73.4%, Loss: 0.3605\n",
      "Optimization Iteration:  32129, Training Accuracy:  73.4%, Loss: 0.4446\n",
      "Optimization Iteration:  32193, Training Accuracy:  75.0%, Loss: 0.4137\n",
      "Optimization Iteration:  32257, Training Accuracy:  73.4%, Loss: 0.4658\n",
      "Optimization Iteration:  32321, Training Accuracy:  81.2%, Loss: 0.3187\n",
      "Optimization Iteration:  32385, Training Accuracy:  75.0%, Loss: 0.4109\n",
      "Optimization Iteration:  32449, Training Accuracy:  70.3%, Loss: 0.4747\n",
      "Optimization Iteration:  32513, Training Accuracy:  73.4%, Loss: 0.3872\n",
      "Optimization Iteration:  32577, Training Accuracy:  75.0%, Loss: 0.3723\n",
      "Optimization Iteration:  32641, Training Accuracy:  73.4%, Loss: 0.4252\n",
      "Optimization Iteration:  32705, Training Accuracy:  75.0%, Loss: 0.4086\n",
      "Optimization Iteration:  32769, Training Accuracy:  75.0%, Loss: 0.4325\n",
      "Optimization Iteration:  32833, Training Accuracy:  68.8%, Loss: 0.4883\n",
      "Optimization Iteration:  32897, Training Accuracy:  67.2%, Loss: 0.5123\n",
      "Optimization Iteration:  32961, Training Accuracy:  70.3%, Loss: 0.4730\n",
      "Optimization Iteration:  33025, Training Accuracy:  78.1%, Loss: 0.3678\n",
      "Optimization Iteration:  33089, Training Accuracy:  73.4%, Loss: 0.4412\n",
      "Optimization Iteration:  33153, Training Accuracy:  76.6%, Loss: 0.4200\n",
      "Optimization Iteration:  33217, Training Accuracy:  73.4%, Loss: 0.3521\n",
      "Optimization Iteration:  33281, Training Accuracy:  67.2%, Loss: 0.4958\n",
      "Optimization Iteration:  33345, Training Accuracy:  71.9%, Loss: 0.4170\n",
      "Optimization Iteration:  33409, Training Accuracy:  78.1%, Loss: 0.4269\n",
      "Optimization Iteration:  33473, Training Accuracy:  81.2%, Loss: 0.5005\n",
      "Optimization Iteration:  33537, Training Accuracy:  64.1%, Loss: 0.4561\n",
      "Optimization Iteration:  33601, Training Accuracy:  82.8%, Loss: 0.3918\n",
      "Optimization Iteration:  33665, Training Accuracy:  76.6%, Loss: 0.3648\n",
      "Optimization Iteration:  33729, Training Accuracy:  70.3%, Loss: 0.4692\n",
      "Optimization Iteration:  33793, Training Accuracy:  75.0%, Loss: 0.4895\n",
      "Optimization Iteration:  33857, Training Accuracy:  73.4%, Loss: 0.3676\n",
      "Optimization Iteration:  33921, Training Accuracy:  76.6%, Loss: 0.3989\n",
      "Optimization Iteration:  33985, Training Accuracy:  85.9%, Loss: 0.3730\n",
      "Optimization Iteration:  34049, Training Accuracy:  70.3%, Loss: 0.4983\n",
      "Optimization Iteration:  34113, Training Accuracy:  84.4%, Loss: 0.3245\n",
      "Optimization Iteration:  34177, Training Accuracy:  73.4%, Loss: 0.4050\n",
      "Optimization Iteration:  34241, Training Accuracy:  73.4%, Loss: 0.3859\n",
      "Optimization Iteration:  34305, Training Accuracy:  70.3%, Loss: 0.4826\n",
      "Optimization Iteration:  34369, Training Accuracy:  70.3%, Loss: 0.3887\n",
      "Optimization Iteration:  34433, Training Accuracy:  68.8%, Loss: 0.4575\n",
      "Optimization Iteration:  34497, Training Accuracy:  81.2%, Loss: 0.3072\n",
      "Optimization Iteration:  34561, Training Accuracy:  81.2%, Loss: 0.3820\n",
      "Optimization Iteration:  34625, Training Accuracy:  75.0%, Loss: 0.4195\n",
      "Optimization Iteration:  34689, Training Accuracy:  76.6%, Loss: 0.4122\n",
      "Optimization Iteration:  34753, Training Accuracy:  64.1%, Loss: 0.5064\n",
      "Optimization Iteration:  34817, Training Accuracy:  75.0%, Loss: 0.3886\n",
      "Optimization Iteration:  34881, Training Accuracy:  73.4%, Loss: 0.4097\n",
      "Optimization Iteration:  34945, Training Accuracy:  78.1%, Loss: 0.3772\n",
      "Optimization Iteration:  35009, Training Accuracy:  84.4%, Loss: 0.4142\n",
      "Optimization Iteration:  35073, Training Accuracy:  73.4%, Loss: 0.3888\n",
      "Optimization Iteration:  35137, Training Accuracy:  81.2%, Loss: 0.3233\n",
      "Optimization Iteration:  35201, Training Accuracy:  75.0%, Loss: 0.3834\n",
      "Optimization Iteration:  35265, Training Accuracy:  71.9%, Loss: 0.3757\n",
      "Optimization Iteration:  35329, Training Accuracy:  75.0%, Loss: 0.4522\n",
      "Optimization Iteration:  35393, Training Accuracy:  76.6%, Loss: 0.3406\n",
      "Optimization Iteration:  35457, Training Accuracy:  68.8%, Loss: 0.4276\n",
      "Optimization Iteration:  35521, Training Accuracy:  67.2%, Loss: 0.3921\n",
      "Optimization Iteration:  35585, Training Accuracy:  81.2%, Loss: 0.3091\n",
      "Optimization Iteration:  35649, Training Accuracy:  71.9%, Loss: 0.4423\n",
      "Optimization Iteration:  35713, Training Accuracy:  81.2%, Loss: 0.4076\n",
      "Optimization Iteration:  35777, Training Accuracy:  84.4%, Loss: 0.2609\n",
      "Optimization Iteration:  35841, Training Accuracy:  78.1%, Loss: 0.3696\n",
      "Optimization Iteration:  35905, Training Accuracy:  84.4%, Loss: 0.4143\n",
      "Optimization Iteration:  35969, Training Accuracy:  75.0%, Loss: 0.4275\n",
      "Optimization Iteration:  36033, Training Accuracy:  70.3%, Loss: 0.4046\n",
      "Optimization Iteration:  36097, Training Accuracy:  70.3%, Loss: 0.4566\n",
      "Optimization Iteration:  36161, Training Accuracy:  78.1%, Loss: 0.4363\n",
      "Optimization Iteration:  36225, Training Accuracy:  82.8%, Loss: 0.3684\n",
      "Optimization Iteration:  36289, Training Accuracy:  84.4%, Loss: 0.3294\n",
      "Optimization Iteration:  36353, Training Accuracy:  73.4%, Loss: 0.3655\n",
      "Optimization Iteration:  36417, Training Accuracy:  76.6%, Loss: 0.4569\n",
      "Optimization Iteration:  36481, Training Accuracy:  71.9%, Loss: 0.4248\n",
      "Optimization Iteration:  36545, Training Accuracy:  82.8%, Loss: 0.3399\n",
      "Optimization Iteration:  36609, Training Accuracy:  78.1%, Loss: 0.3502\n",
      "Optimization Iteration:  36673, Training Accuracy:  75.0%, Loss: 0.3971\n",
      "Optimization Iteration:  36737, Training Accuracy:  68.8%, Loss: 0.4113\n",
      "Optimization Iteration:  36801, Training Accuracy:  82.8%, Loss: 0.3348\n",
      "Optimization Iteration:  36865, Training Accuracy:  79.7%, Loss: 0.3842\n",
      "Optimization Iteration:  36929, Training Accuracy:  68.8%, Loss: 0.4891\n",
      "Optimization Iteration:  36993, Training Accuracy:  70.3%, Loss: 0.4462\n",
      "Optimization Iteration:  37057, Training Accuracy:  71.9%, Loss: 0.3858\n",
      "Optimization Iteration:  37121, Training Accuracy:  84.4%, Loss: 0.3165\n",
      "Optimization Iteration:  37185, Training Accuracy:  75.0%, Loss: 0.4581\n",
      "Optimization Iteration:  37249, Training Accuracy:  67.2%, Loss: 0.4555\n",
      "Optimization Iteration:  37313, Training Accuracy:  79.7%, Loss: 0.3528\n",
      "Optimization Iteration:  37377, Training Accuracy:  75.0%, Loss: 0.5624\n",
      "Optimization Iteration:  37441, Training Accuracy:  78.1%, Loss: 0.4117\n",
      "Optimization Iteration:  37505, Training Accuracy:  75.0%, Loss: 0.4402\n",
      "Optimization Iteration:  37569, Training Accuracy:  81.2%, Loss: 0.4344\n",
      "Optimization Iteration:  37633, Training Accuracy:  70.3%, Loss: 0.4800\n",
      "Optimization Iteration:  37697, Training Accuracy:  76.6%, Loss: 0.3753\n",
      "Optimization Iteration:  37761, Training Accuracy:  79.7%, Loss: 0.3456\n",
      "Optimization Iteration:  37825, Training Accuracy:  76.6%, Loss: 0.3800\n",
      "Optimization Iteration:  37889, Training Accuracy:  76.6%, Loss: 0.4886\n",
      "Optimization Iteration:  37953, Training Accuracy:  82.8%, Loss: 0.3315\n",
      "Optimization Iteration:  38017, Training Accuracy:  68.8%, Loss: 0.4778\n",
      "Optimization Iteration:  38081, Training Accuracy:  75.0%, Loss: 0.4078\n",
      "Optimization Iteration:  38145, Training Accuracy:  81.2%, Loss: 0.3430\n",
      "Optimization Iteration:  38209, Training Accuracy:  82.8%, Loss: 0.3574\n",
      "Optimization Iteration:  38273, Training Accuracy:  75.0%, Loss: 0.4537\n",
      "Optimization Iteration:  38337, Training Accuracy:  87.5%, Loss: 0.2926\n",
      "Optimization Iteration:  38401, Training Accuracy:  81.2%, Loss: 0.3603\n",
      "Optimization Iteration:  38465, Training Accuracy:  73.4%, Loss: 0.4463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  38529, Training Accuracy:  78.1%, Loss: 0.4120\n",
      "Optimization Iteration:  38593, Training Accuracy:  68.8%, Loss: 0.5141\n",
      "Optimization Iteration:  38657, Training Accuracy:  71.9%, Loss: 0.4678\n",
      "Optimization Iteration:  38721, Training Accuracy:  70.3%, Loss: 0.4250\n",
      "Optimization Iteration:  38785, Training Accuracy:  75.0%, Loss: 0.4772\n",
      "Optimization Iteration:  38849, Training Accuracy:  78.1%, Loss: 0.3434\n",
      "Optimization Iteration:  38913, Training Accuracy:  76.6%, Loss: 0.4071\n",
      "Optimization Iteration:  38977, Training Accuracy:  73.4%, Loss: 0.4423\n",
      "Optimization Iteration:  39041, Training Accuracy:  70.3%, Loss: 0.3898\n",
      "Optimization Iteration:  39105, Training Accuracy:  76.6%, Loss: 0.4911\n",
      "Optimization Iteration:  39169, Training Accuracy:  78.1%, Loss: 0.4226\n",
      "Optimization Iteration:  39233, Training Accuracy:  71.9%, Loss: 0.4635\n",
      "Optimization Iteration:  39297, Training Accuracy:  82.8%, Loss: 0.3802\n",
      "Optimization Iteration:  39361, Training Accuracy:  70.3%, Loss: 0.4163\n",
      "Optimization Iteration:  39425, Training Accuracy:  79.7%, Loss: 0.4017\n",
      "Optimization Iteration:  39489, Training Accuracy:  71.9%, Loss: 0.3479\n",
      "Optimization Iteration:  39553, Training Accuracy:  70.3%, Loss: 0.4321\n",
      "Optimization Iteration:  39617, Training Accuracy:  84.4%, Loss: 0.3863\n",
      "Optimization Iteration:  39681, Training Accuracy:  68.8%, Loss: 0.3844\n",
      "Optimization Iteration:  39745, Training Accuracy:  81.2%, Loss: 0.4193\n",
      "Optimization Iteration:  39809, Training Accuracy:  71.9%, Loss: 0.4700\n",
      "Optimization Iteration:  39873, Training Accuracy:  76.6%, Loss: 0.4559\n",
      "Optimization Iteration:  39937, Training Accuracy:  76.6%, Loss: 0.4166\n",
      "Optimization Iteration:  40001, Training Accuracy:  76.6%, Loss: 0.3527\n",
      "Optimization Iteration:  40065, Training Accuracy:  67.2%, Loss: 0.4145\n",
      "Optimization Iteration:  40129, Training Accuracy:  73.4%, Loss: 0.3916\n",
      "Optimization Iteration:  40193, Training Accuracy:  78.1%, Loss: 0.5182\n",
      "Optimization Iteration:  40257, Training Accuracy:  81.2%, Loss: 0.3767\n",
      "Optimization Iteration:  40321, Training Accuracy:  67.2%, Loss: 0.4272\n",
      "Optimization Iteration:  40385, Training Accuracy:  76.6%, Loss: 0.4985\n",
      "Optimization Iteration:  40449, Training Accuracy:  75.0%, Loss: 0.4419\n",
      "Optimization Iteration:  40513, Training Accuracy:  82.8%, Loss: 0.3628\n",
      "Optimization Iteration:  40577, Training Accuracy:  84.4%, Loss: 0.3407\n",
      "Optimization Iteration:  40641, Training Accuracy:  79.7%, Loss: 0.3700\n",
      "Optimization Iteration:  40705, Training Accuracy:  71.9%, Loss: 0.4247\n",
      "Optimization Iteration:  40769, Training Accuracy:  78.1%, Loss: 0.3075\n",
      "Optimization Iteration:  40833, Training Accuracy:  81.2%, Loss: 0.3548\n",
      "Optimization Iteration:  40897, Training Accuracy:  78.1%, Loss: 0.3983\n",
      "Optimization Iteration:  40961, Training Accuracy:  73.4%, Loss: 0.3581\n",
      "Optimization Iteration:  41025, Training Accuracy:  87.5%, Loss: 0.3257\n",
      "Optimization Iteration:  41089, Training Accuracy:  79.7%, Loss: 0.3665\n",
      "Optimization Iteration:  41153, Training Accuracy:  81.2%, Loss: 0.4142\n",
      "Optimization Iteration:  41217, Training Accuracy:  73.4%, Loss: 0.3762\n",
      "Optimization Iteration:  41281, Training Accuracy:  75.0%, Loss: 0.4788\n",
      "Optimization Iteration:  41345, Training Accuracy:  76.6%, Loss: 0.3707\n",
      "Optimization Iteration:  41409, Training Accuracy:  81.2%, Loss: 0.3766\n",
      "Optimization Iteration:  41473, Training Accuracy:  71.9%, Loss: 0.4410\n",
      "Optimization Iteration:  41537, Training Accuracy:  84.4%, Loss: 0.3578\n",
      "Optimization Iteration:  41601, Training Accuracy:  65.6%, Loss: 0.4072\n",
      "Optimization Iteration:  41665, Training Accuracy:  76.6%, Loss: 0.3725\n",
      "Optimization Iteration:  41729, Training Accuracy:  78.1%, Loss: 0.3411\n",
      "Optimization Iteration:  41793, Training Accuracy:  73.4%, Loss: 0.3827\n",
      "Optimization Iteration:  41857, Training Accuracy:  73.4%, Loss: 0.4519\n",
      "Optimization Iteration:  41921, Training Accuracy:  73.4%, Loss: 0.3761\n",
      "Optimization Iteration:  41985, Training Accuracy:  73.4%, Loss: 0.4339\n",
      "Optimization Iteration:  42049, Training Accuracy:  75.0%, Loss: 0.4229\n",
      "Optimization Iteration:  42113, Training Accuracy:  75.0%, Loss: 0.3900\n",
      "Optimization Iteration:  42177, Training Accuracy:  71.9%, Loss: 0.4893\n",
      "Optimization Iteration:  42241, Training Accuracy:  73.4%, Loss: 0.3951\n",
      "Optimization Iteration:  42305, Training Accuracy:  78.1%, Loss: 0.4326\n",
      "Optimization Iteration:  42369, Training Accuracy:  82.8%, Loss: 0.3591\n",
      "Optimization Iteration:  42433, Training Accuracy:  76.6%, Loss: 0.4138\n",
      "Optimization Iteration:  42497, Training Accuracy:  75.0%, Loss: 0.3791\n",
      "Optimization Iteration:  42561, Training Accuracy:  75.0%, Loss: 0.4254\n",
      "Optimization Iteration:  42625, Training Accuracy:  84.4%, Loss: 0.3685\n",
      "Optimization Iteration:  42689, Training Accuracy:  79.7%, Loss: 0.3778\n",
      "Optimization Iteration:  42753, Training Accuracy:  71.9%, Loss: 0.4496\n",
      "Optimization Iteration:  42817, Training Accuracy:  78.1%, Loss: 0.3753\n",
      "Optimization Iteration:  42881, Training Accuracy:  70.3%, Loss: 0.4646\n",
      "Optimization Iteration:  42945, Training Accuracy:  76.6%, Loss: 0.4291\n",
      "Optimization Iteration:  43009, Training Accuracy:  79.7%, Loss: 0.4248\n",
      "Optimization Iteration:  43073, Training Accuracy:  78.1%, Loss: 0.3954\n",
      "Optimization Iteration:  43137, Training Accuracy:  82.8%, Loss: 0.3672\n",
      "Optimization Iteration:  43201, Training Accuracy:  76.6%, Loss: 0.4213\n",
      "Optimization Iteration:  43265, Training Accuracy:  75.0%, Loss: 0.4358\n",
      "Optimization Iteration:  43329, Training Accuracy:  84.4%, Loss: 0.3587\n",
      "Optimization Iteration:  43393, Training Accuracy:  68.8%, Loss: 0.4007\n",
      "Optimization Iteration:  43457, Training Accuracy:  76.6%, Loss: 0.3285\n",
      "Optimization Iteration:  43521, Training Accuracy:  78.1%, Loss: 0.4147\n",
      "Optimization Iteration:  43585, Training Accuracy:  76.6%, Loss: 0.3981\n",
      "Optimization Iteration:  43649, Training Accuracy:  76.6%, Loss: 0.4206\n",
      "Optimization Iteration:  43713, Training Accuracy:  81.2%, Loss: 0.3086\n",
      "Optimization Iteration:  43777, Training Accuracy:  82.8%, Loss: 0.3229\n",
      "Optimization Iteration:  43841, Training Accuracy:  76.6%, Loss: 0.3927\n",
      "Optimization Iteration:  43905, Training Accuracy:  81.2%, Loss: 0.3354\n",
      "Optimization Iteration:  43969, Training Accuracy:  78.1%, Loss: 0.3288\n",
      "Optimization Iteration:  44033, Training Accuracy:  75.0%, Loss: 0.3534\n",
      "Optimization Iteration:  44097, Training Accuracy:  81.2%, Loss: 0.3804\n",
      "Optimization Iteration:  44161, Training Accuracy:  79.7%, Loss: 0.3393\n",
      "Optimization Iteration:  44225, Training Accuracy:  84.4%, Loss: 0.3768\n",
      "Optimization Iteration:  44289, Training Accuracy:  70.3%, Loss: 0.4779\n",
      "Optimization Iteration:  44353, Training Accuracy:  70.3%, Loss: 0.4620\n",
      "Optimization Iteration:  44417, Training Accuracy:  75.0%, Loss: 0.3556\n",
      "Optimization Iteration:  44481, Training Accuracy:  75.0%, Loss: 0.4044\n",
      "Optimization Iteration:  44545, Training Accuracy:  75.0%, Loss: 0.3457\n",
      "Optimization Iteration:  44609, Training Accuracy:  75.0%, Loss: 0.3995\n",
      "Optimization Iteration:  44673, Training Accuracy:  71.9%, Loss: 0.5324\n",
      "Optimization Iteration:  44737, Training Accuracy:  68.8%, Loss: 0.4363\n",
      "Optimization Iteration:  44801, Training Accuracy:  78.1%, Loss: 0.3627\n",
      "Optimization Iteration:  44865, Training Accuracy:  65.6%, Loss: 0.4693\n",
      "Optimization Iteration:  44929, Training Accuracy:  81.2%, Loss: 0.3552\n",
      "Optimization Iteration:  44993, Training Accuracy:  76.6%, Loss: 0.3718\n",
      "Optimization Iteration:  45057, Training Accuracy:  76.6%, Loss: 0.4448\n",
      "Optimization Iteration:  45121, Training Accuracy:  71.9%, Loss: 0.3709\n",
      "Optimization Iteration:  45185, Training Accuracy:  87.5%, Loss: 0.2897\n",
      "Optimization Iteration:  45249, Training Accuracy:  68.8%, Loss: 0.4354\n",
      "Optimization Iteration:  45313, Training Accuracy:  79.7%, Loss: 0.3692\n",
      "Optimization Iteration:  45377, Training Accuracy:  76.6%, Loss: 0.4442\n",
      "Optimization Iteration:  45441, Training Accuracy:  70.3%, Loss: 0.3867\n",
      "Optimization Iteration:  45505, Training Accuracy:  71.9%, Loss: 0.3924\n",
      "Optimization Iteration:  45569, Training Accuracy:  71.9%, Loss: 0.5000\n",
      "Optimization Iteration:  45633, Training Accuracy:  79.7%, Loss: 0.4166\n",
      "Optimization Iteration:  45697, Training Accuracy:  78.1%, Loss: 0.3784\n",
      "Optimization Iteration:  45761, Training Accuracy:  82.8%, Loss: 0.3698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  45825, Training Accuracy:  76.6%, Loss: 0.3497\n",
      "Optimization Iteration:  45889, Training Accuracy:  67.2%, Loss: 0.4104\n",
      "Optimization Iteration:  45953, Training Accuracy:  75.0%, Loss: 0.4205\n",
      "Optimization Iteration:  46017, Training Accuracy:  64.1%, Loss: 0.4850\n",
      "Optimization Iteration:  46081, Training Accuracy:  81.2%, Loss: 0.3260\n",
      "Optimization Iteration:  46145, Training Accuracy:  75.0%, Loss: 0.3779\n",
      "Optimization Iteration:  46209, Training Accuracy:  78.1%, Loss: 0.3544\n",
      "Optimization Iteration:  46273, Training Accuracy:  64.1%, Loss: 0.5130\n",
      "Optimization Iteration:  46337, Training Accuracy:  75.0%, Loss: 0.4551\n",
      "Optimization Iteration:  46401, Training Accuracy:  79.7%, Loss: 0.3572\n",
      "Optimization Iteration:  46465, Training Accuracy:  73.4%, Loss: 0.4177\n",
      "Optimization Iteration:  46529, Training Accuracy:  73.4%, Loss: 0.3944\n",
      "Optimization Iteration:  46593, Training Accuracy:  79.7%, Loss: 0.4120\n",
      "Optimization Iteration:  46657, Training Accuracy:  78.1%, Loss: 0.4241\n",
      "Optimization Iteration:  46721, Training Accuracy:  75.0%, Loss: 0.3871\n",
      "Optimization Iteration:  46785, Training Accuracy:  75.0%, Loss: 0.4093\n",
      "Optimization Iteration:  46849, Training Accuracy:  62.5%, Loss: 0.4748\n",
      "Optimization Iteration:  46913, Training Accuracy:  85.9%, Loss: 0.3853\n",
      "Optimization Iteration:  46977, Training Accuracy:  81.2%, Loss: 0.3923\n",
      "Optimization Iteration:  47041, Training Accuracy:  78.1%, Loss: 0.3981\n",
      "Optimization Iteration:  47105, Training Accuracy:  71.9%, Loss: 0.4984\n",
      "Optimization Iteration:  47169, Training Accuracy:  71.9%, Loss: 0.4459\n",
      "Optimization Iteration:  47233, Training Accuracy:  76.6%, Loss: 0.3847\n",
      "Optimization Iteration:  47297, Training Accuracy:  71.9%, Loss: 0.4023\n",
      "Optimization Iteration:  47361, Training Accuracy:  76.6%, Loss: 0.3380\n",
      "Optimization Iteration:  47425, Training Accuracy:  84.4%, Loss: 0.3928\n",
      "Optimization Iteration:  47489, Training Accuracy:  82.8%, Loss: 0.3832\n",
      "Optimization Iteration:  47553, Training Accuracy:  76.6%, Loss: 0.4381\n",
      "Optimization Iteration:  47617, Training Accuracy:  81.2%, Loss: 0.3881\n",
      "Optimization Iteration:  47681, Training Accuracy:  79.7%, Loss: 0.3803\n",
      "Optimization Iteration:  47745, Training Accuracy:  71.9%, Loss: 0.4568\n",
      "Optimization Iteration:  47809, Training Accuracy:  82.8%, Loss: 0.4382\n",
      "Optimization Iteration:  47873, Training Accuracy:  84.4%, Loss: 0.3043\n",
      "Optimization Iteration:  47937, Training Accuracy:  78.1%, Loss: 0.3725\n",
      "Optimization Iteration:  48001, Training Accuracy:  71.9%, Loss: 0.4416\n",
      "Optimization Iteration:  48065, Training Accuracy:  70.3%, Loss: 0.4095\n",
      "Optimization Iteration:  48129, Training Accuracy:  65.6%, Loss: 0.4775\n",
      "Optimization Iteration:  48193, Training Accuracy:  75.0%, Loss: 0.4244\n",
      "Optimization Iteration:  48257, Training Accuracy:  75.0%, Loss: 0.3821\n",
      "Optimization Iteration:  48321, Training Accuracy:  79.7%, Loss: 0.3777\n",
      "Optimization Iteration:  48385, Training Accuracy:  73.4%, Loss: 0.3453\n",
      "Optimization Iteration:  48449, Training Accuracy:  78.1%, Loss: 0.3932\n",
      "Optimization Iteration:  48513, Training Accuracy:  79.7%, Loss: 0.3726\n",
      "Optimization Iteration:  48577, Training Accuracy:  60.9%, Loss: 0.5729\n",
      "Optimization Iteration:  48641, Training Accuracy:  78.1%, Loss: 0.3748\n",
      "Optimization Iteration:  48705, Training Accuracy:  73.4%, Loss: 0.3756\n",
      "Optimization Iteration:  48769, Training Accuracy:  82.8%, Loss: 0.3113\n",
      "Optimization Iteration:  48833, Training Accuracy:  78.1%, Loss: 0.3737\n",
      "Optimization Iteration:  48897, Training Accuracy:  79.7%, Loss: 0.4150\n",
      "Optimization Iteration:  48961, Training Accuracy:  75.0%, Loss: 0.4530\n",
      "Optimization Iteration:  49025, Training Accuracy:  71.9%, Loss: 0.4408\n",
      "Optimization Iteration:  49089, Training Accuracy:  79.7%, Loss: 0.4013\n",
      "Optimization Iteration:  49153, Training Accuracy:  76.6%, Loss: 0.3782\n",
      "Optimization Iteration:  49217, Training Accuracy:  76.6%, Loss: 0.3608\n",
      "Optimization Iteration:  49281, Training Accuracy:  76.6%, Loss: 0.4041\n",
      "Optimization Iteration:  49345, Training Accuracy:  81.2%, Loss: 0.3323\n",
      "Optimization Iteration:  49409, Training Accuracy:  70.3%, Loss: 0.4389\n",
      "Optimization Iteration:  49473, Training Accuracy:  81.2%, Loss: 0.3796\n",
      "Optimization Iteration:  49537, Training Accuracy:  81.2%, Loss: 0.3628\n",
      "Optimization Iteration:  49601, Training Accuracy:  75.0%, Loss: 0.3824\n",
      "Optimization Iteration:  49665, Training Accuracy:  76.6%, Loss: 0.2905\n",
      "Optimization Iteration:  49729, Training Accuracy:  64.1%, Loss: 0.4638\n",
      "Optimization Iteration:  49793, Training Accuracy:  76.6%, Loss: 0.3447\n",
      "Optimization Iteration:  49857, Training Accuracy:  75.0%, Loss: 0.3924\n",
      "Optimization Iteration:  49921, Training Accuracy:  82.8%, Loss: 0.3607\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 19\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  65.6%, Loss: 0.4811\n",
      "Optimization Iteration:    129, Training Accuracy:  73.4%, Loss: 0.4608\n",
      "Optimization Iteration:    193, Training Accuracy:  73.4%, Loss: 0.4561\n",
      "Optimization Iteration:    257, Training Accuracy:  67.2%, Loss: 0.4151\n",
      "Optimization Iteration:    321, Training Accuracy:  79.7%, Loss: 0.3900\n",
      "Optimization Iteration:    385, Training Accuracy:  68.8%, Loss: 0.3557\n",
      "Optimization Iteration:    449, Training Accuracy:  84.4%, Loss: 0.3256\n",
      "Optimization Iteration:    513, Training Accuracy:  78.1%, Loss: 0.3866\n",
      "Optimization Iteration:    577, Training Accuracy:  54.7%, Loss: 0.5135\n",
      "Optimization Iteration:    641, Training Accuracy:  73.4%, Loss: 0.4451\n",
      "Optimization Iteration:    705, Training Accuracy:  71.9%, Loss: 0.3944\n",
      "Optimization Iteration:    769, Training Accuracy:  81.2%, Loss: 0.3477\n",
      "Optimization Iteration:    833, Training Accuracy:  78.1%, Loss: 0.4222\n",
      "Optimization Iteration:    897, Training Accuracy:  71.9%, Loss: 0.3730\n",
      "Optimization Iteration:    961, Training Accuracy:  76.6%, Loss: 0.3908\n",
      "Optimization Iteration:   1025, Training Accuracy:  73.4%, Loss: 0.3987\n",
      "Optimization Iteration:   1089, Training Accuracy:  81.2%, Loss: 0.3007\n",
      "Optimization Iteration:   1153, Training Accuracy:  81.2%, Loss: 0.3758\n",
      "Optimization Iteration:   1217, Training Accuracy:  70.3%, Loss: 0.4005\n",
      "Optimization Iteration:   1281, Training Accuracy:  73.4%, Loss: 0.4296\n",
      "Optimization Iteration:   1345, Training Accuracy:  73.4%, Loss: 0.4143\n",
      "Optimization Iteration:   1409, Training Accuracy:  64.1%, Loss: 0.4751\n",
      "Optimization Iteration:   1473, Training Accuracy:  67.2%, Loss: 0.3865\n",
      "Optimization Iteration:   1537, Training Accuracy:  84.4%, Loss: 0.3146\n",
      "Optimization Iteration:   1601, Training Accuracy:  84.4%, Loss: 0.3399\n",
      "Optimization Iteration:   1665, Training Accuracy:  85.9%, Loss: 0.3109\n",
      "Optimization Iteration:   1729, Training Accuracy:  75.0%, Loss: 0.3397\n",
      "Optimization Iteration:   1793, Training Accuracy:  70.3%, Loss: 0.4339\n",
      "Optimization Iteration:   1857, Training Accuracy:  76.6%, Loss: 0.4023\n",
      "Optimization Iteration:   1921, Training Accuracy:  73.4%, Loss: 0.3932\n",
      "Optimization Iteration:   1985, Training Accuracy:  76.6%, Loss: 0.3621\n",
      "Optimization Iteration:   2049, Training Accuracy:  84.4%, Loss: 0.2722\n",
      "Optimization Iteration:   2113, Training Accuracy:  75.0%, Loss: 0.3874\n",
      "Optimization Iteration:   2177, Training Accuracy:  81.2%, Loss: 0.3071\n",
      "Optimization Iteration:   2241, Training Accuracy:  71.9%, Loss: 0.4470\n",
      "Optimization Iteration:   2305, Training Accuracy:  79.7%, Loss: 0.3591\n",
      "Optimization Iteration:   2369, Training Accuracy:  75.0%, Loss: 0.4005\n",
      "Optimization Iteration:   2433, Training Accuracy:  70.3%, Loss: 0.4251\n",
      "Optimization Iteration:   2497, Training Accuracy:  84.4%, Loss: 0.3562\n",
      "Optimization Iteration:   2561, Training Accuracy:  71.9%, Loss: 0.3766\n",
      "Optimization Iteration:   2625, Training Accuracy:  79.7%, Loss: 0.4032\n",
      "Optimization Iteration:   2689, Training Accuracy:  73.4%, Loss: 0.3502\n",
      "Optimization Iteration:   2753, Training Accuracy:  75.0%, Loss: 0.4025\n",
      "Optimization Iteration:   2817, Training Accuracy:  75.0%, Loss: 0.3876\n",
      "Optimization Iteration:   2881, Training Accuracy:  68.8%, Loss: 0.4437\n",
      "Optimization Iteration:   2945, Training Accuracy:  79.7%, Loss: 0.4397\n",
      "Optimization Iteration:   3009, Training Accuracy:  73.4%, Loss: 0.3977\n",
      "Optimization Iteration:   3073, Training Accuracy:  73.4%, Loss: 0.3827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   3137, Training Accuracy:  82.8%, Loss: 0.3701\n",
      "Optimization Iteration:   3201, Training Accuracy:  89.1%, Loss: 0.2658\n",
      "Optimization Iteration:   3265, Training Accuracy:  82.8%, Loss: 0.3282\n",
      "Optimization Iteration:   3329, Training Accuracy:  79.7%, Loss: 0.3266\n",
      "Optimization Iteration:   3393, Training Accuracy:  78.1%, Loss: 0.3572\n",
      "Optimization Iteration:   3457, Training Accuracy:  78.1%, Loss: 0.4321\n",
      "Optimization Iteration:   3521, Training Accuracy:  70.3%, Loss: 0.4454\n",
      "Optimization Iteration:   3585, Training Accuracy:  71.9%, Loss: 0.4232\n",
      "Optimization Iteration:   3649, Training Accuracy:  70.3%, Loss: 0.4422\n",
      "Optimization Iteration:   3713, Training Accuracy:  71.9%, Loss: 0.3931\n",
      "Optimization Iteration:   3777, Training Accuracy:  65.6%, Loss: 0.4576\n",
      "Optimization Iteration:   3841, Training Accuracy:  68.8%, Loss: 0.4560\n",
      "Optimization Iteration:   3905, Training Accuracy:  78.1%, Loss: 0.4215\n",
      "Optimization Iteration:   3969, Training Accuracy:  82.8%, Loss: 0.3717\n",
      "Optimization Iteration:   4033, Training Accuracy:  71.9%, Loss: 0.3534\n",
      "Optimization Iteration:   4097, Training Accuracy:  81.2%, Loss: 0.4165\n",
      "Optimization Iteration:   4161, Training Accuracy:  78.1%, Loss: 0.3970\n",
      "Optimization Iteration:   4225, Training Accuracy:  73.4%, Loss: 0.3568\n",
      "Optimization Iteration:   4289, Training Accuracy:  79.7%, Loss: 0.3525\n",
      "Optimization Iteration:   4353, Training Accuracy:  75.0%, Loss: 0.3947\n",
      "Optimization Iteration:   4417, Training Accuracy:  75.0%, Loss: 0.4452\n",
      "Optimization Iteration:   4481, Training Accuracy:  79.7%, Loss: 0.3794\n",
      "Optimization Iteration:   4545, Training Accuracy:  81.2%, Loss: 0.3392\n",
      "Optimization Iteration:   4609, Training Accuracy:  70.3%, Loss: 0.4378\n",
      "Optimization Iteration:   4673, Training Accuracy:  84.4%, Loss: 0.4081\n",
      "Optimization Iteration:   4737, Training Accuracy:  81.2%, Loss: 0.3923\n",
      "Optimization Iteration:   4801, Training Accuracy:  76.6%, Loss: 0.4398\n",
      "Optimization Iteration:   4865, Training Accuracy:  76.6%, Loss: 0.3948\n",
      "Optimization Iteration:   4929, Training Accuracy:  78.1%, Loss: 0.3709\n",
      "Optimization Iteration:   4993, Training Accuracy:  73.4%, Loss: 0.3648\n",
      "Optimization Iteration:   5057, Training Accuracy:  73.4%, Loss: 0.4190\n",
      "Optimization Iteration:   5121, Training Accuracy:  75.0%, Loss: 0.4269\n",
      "Optimization Iteration:   5185, Training Accuracy:  81.2%, Loss: 0.3868\n",
      "Optimization Iteration:   5249, Training Accuracy:  59.4%, Loss: 0.5279\n",
      "Optimization Iteration:   5313, Training Accuracy:  82.8%, Loss: 0.3153\n",
      "Optimization Iteration:   5377, Training Accuracy:  84.4%, Loss: 0.3300\n",
      "Optimization Iteration:   5441, Training Accuracy:  71.9%, Loss: 0.4083\n",
      "Optimization Iteration:   5505, Training Accuracy:  85.9%, Loss: 0.3352\n",
      "Optimization Iteration:   5569, Training Accuracy:  79.7%, Loss: 0.3422\n",
      "Optimization Iteration:   5633, Training Accuracy:  84.4%, Loss: 0.3392\n",
      "Optimization Iteration:   5697, Training Accuracy:  75.0%, Loss: 0.4187\n",
      "Optimization Iteration:   5761, Training Accuracy:  73.4%, Loss: 0.3105\n",
      "Optimization Iteration:   5825, Training Accuracy:  71.9%, Loss: 0.4332\n",
      "Optimization Iteration:   5889, Training Accuracy:  78.1%, Loss: 0.3815\n",
      "Optimization Iteration:   5953, Training Accuracy:  82.8%, Loss: 0.4428\n",
      "Optimization Iteration:   6017, Training Accuracy:  62.5%, Loss: 0.4513\n",
      "Optimization Iteration:   6081, Training Accuracy:  79.7%, Loss: 0.3287\n",
      "Optimization Iteration:   6145, Training Accuracy:  68.8%, Loss: 0.6292\n",
      "Optimization Iteration:   6209, Training Accuracy:  70.3%, Loss: 0.3953\n",
      "Optimization Iteration:   6273, Training Accuracy:  76.6%, Loss: 0.3679\n",
      "Optimization Iteration:   6337, Training Accuracy:  65.6%, Loss: 0.4518\n",
      "Optimization Iteration:   6401, Training Accuracy:  76.6%, Loss: 0.4091\n",
      "Optimization Iteration:   6465, Training Accuracy:  79.7%, Loss: 0.3267\n",
      "Optimization Iteration:   6529, Training Accuracy:  84.4%, Loss: 0.4308\n",
      "Optimization Iteration:   6593, Training Accuracy:  82.8%, Loss: 0.4068\n",
      "Optimization Iteration:   6657, Training Accuracy:  78.1%, Loss: 0.3948\n",
      "Optimization Iteration:   6721, Training Accuracy:  79.7%, Loss: 0.3300\n",
      "Optimization Iteration:   6785, Training Accuracy:  75.0%, Loss: 0.4030\n",
      "Optimization Iteration:   6849, Training Accuracy:  78.1%, Loss: 0.3923\n",
      "Optimization Iteration:   6913, Training Accuracy:  78.1%, Loss: 0.3989\n",
      "Optimization Iteration:   6977, Training Accuracy:  65.6%, Loss: 0.4274\n",
      "Optimization Iteration:   7041, Training Accuracy:  84.4%, Loss: 0.3329\n",
      "Optimization Iteration:   7105, Training Accuracy:  73.4%, Loss: 0.3812\n",
      "Optimization Iteration:   7169, Training Accuracy:  81.2%, Loss: 0.3444\n",
      "Optimization Iteration:   7233, Training Accuracy:  76.6%, Loss: 0.4176\n",
      "Optimization Iteration:   7297, Training Accuracy:  76.6%, Loss: 0.4000\n",
      "Optimization Iteration:   7361, Training Accuracy:  73.4%, Loss: 0.3770\n",
      "Optimization Iteration:   7425, Training Accuracy:  78.1%, Loss: 0.3589\n",
      "Optimization Iteration:   7489, Training Accuracy:  73.4%, Loss: 0.4391\n",
      "Optimization Iteration:   7553, Training Accuracy:  78.1%, Loss: 0.4073\n",
      "Optimization Iteration:   7617, Training Accuracy:  67.2%, Loss: 0.4323\n",
      "Optimization Iteration:   7681, Training Accuracy:  81.2%, Loss: 0.3399\n",
      "Optimization Iteration:   7745, Training Accuracy:  81.2%, Loss: 0.3436\n",
      "Optimization Iteration:   7809, Training Accuracy:  78.1%, Loss: 0.4690\n",
      "Optimization Iteration:   7873, Training Accuracy:  79.7%, Loss: 0.3588\n",
      "Optimization Iteration:   7937, Training Accuracy:  81.2%, Loss: 0.3823\n",
      "Optimization Iteration:   8001, Training Accuracy:  75.0%, Loss: 0.3950\n",
      "Optimization Iteration:   8065, Training Accuracy:  71.9%, Loss: 0.4573\n",
      "Optimization Iteration:   8129, Training Accuracy:  73.4%, Loss: 0.4093\n",
      "Optimization Iteration:   8193, Training Accuracy:  65.6%, Loss: 0.4482\n",
      "Optimization Iteration:   8257, Training Accuracy:  82.8%, Loss: 0.4474\n",
      "Optimization Iteration:   8321, Training Accuracy:  70.3%, Loss: 0.4175\n",
      "Optimization Iteration:   8385, Training Accuracy:  68.8%, Loss: 0.4137\n",
      "Optimization Iteration:   8449, Training Accuracy:  75.0%, Loss: 0.4367\n",
      "Optimization Iteration:   8513, Training Accuracy:  81.2%, Loss: 0.3904\n",
      "Optimization Iteration:   8577, Training Accuracy:  82.8%, Loss: 0.4831\n",
      "Optimization Iteration:   8641, Training Accuracy:  75.0%, Loss: 0.3520\n",
      "Optimization Iteration:   8705, Training Accuracy:  78.1%, Loss: 0.3891\n",
      "Optimization Iteration:   8769, Training Accuracy:  78.1%, Loss: 0.3276\n",
      "Optimization Iteration:   8833, Training Accuracy:  71.9%, Loss: 0.3746\n",
      "Optimization Iteration:   8897, Training Accuracy:  70.3%, Loss: 0.3844\n",
      "Optimization Iteration:   8961, Training Accuracy:  76.6%, Loss: 0.4459\n",
      "Optimization Iteration:   9025, Training Accuracy:  73.4%, Loss: 0.4636\n",
      "Optimization Iteration:   9089, Training Accuracy:  75.0%, Loss: 0.4752\n",
      "Optimization Iteration:   9153, Training Accuracy:  70.3%, Loss: 0.3901\n",
      "Optimization Iteration:   9217, Training Accuracy:  76.6%, Loss: 0.3684\n",
      "Optimization Iteration:   9281, Training Accuracy:  79.7%, Loss: 0.3967\n",
      "Optimization Iteration:   9345, Training Accuracy:  76.6%, Loss: 0.3961\n",
      "Optimization Iteration:   9409, Training Accuracy:  73.4%, Loss: 0.5009\n",
      "Optimization Iteration:   9473, Training Accuracy:  78.1%, Loss: 0.3936\n",
      "Optimization Iteration:   9537, Training Accuracy:  81.2%, Loss: 0.3761\n",
      "Optimization Iteration:   9601, Training Accuracy:  73.4%, Loss: 0.4209\n",
      "Optimization Iteration:   9665, Training Accuracy:  67.2%, Loss: 0.4664\n",
      "Optimization Iteration:   9729, Training Accuracy:  73.4%, Loss: 0.4176\n",
      "Optimization Iteration:   9793, Training Accuracy:  70.3%, Loss: 0.3678\n",
      "Optimization Iteration:   9857, Training Accuracy:  73.4%, Loss: 0.4149\n",
      "Optimization Iteration:   9921, Training Accuracy:  75.0%, Loss: 0.4034\n",
      "Optimization Iteration:   9985, Training Accuracy:  59.4%, Loss: 0.4869\n",
      "Optimization Iteration:  10049, Training Accuracy:  75.0%, Loss: 0.4195\n",
      "Optimization Iteration:  10113, Training Accuracy:  71.9%, Loss: 0.4391\n",
      "Optimization Iteration:  10177, Training Accuracy:  60.9%, Loss: 0.5605\n",
      "Optimization Iteration:  10241, Training Accuracy:  79.7%, Loss: 0.4322\n",
      "Optimization Iteration:  10305, Training Accuracy:  82.8%, Loss: 0.3442\n",
      "Optimization Iteration:  10369, Training Accuracy:  70.3%, Loss: 0.4223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  10433, Training Accuracy:  82.8%, Loss: 0.3996\n",
      "Optimization Iteration:  10497, Training Accuracy:  75.0%, Loss: 0.4362\n",
      "Optimization Iteration:  10561, Training Accuracy:  82.8%, Loss: 0.3094\n",
      "Optimization Iteration:  10625, Training Accuracy:  85.9%, Loss: 0.3256\n",
      "Optimization Iteration:  10689, Training Accuracy:  73.4%, Loss: 0.3686\n",
      "Optimization Iteration:  10753, Training Accuracy:  76.6%, Loss: 0.4756\n",
      "Optimization Iteration:  10817, Training Accuracy:  68.8%, Loss: 0.5097\n",
      "Optimization Iteration:  10881, Training Accuracy:  81.2%, Loss: 0.3655\n",
      "Optimization Iteration:  10945, Training Accuracy:  76.6%, Loss: 0.3976\n",
      "Optimization Iteration:  11009, Training Accuracy:  84.4%, Loss: 0.3460\n",
      "Optimization Iteration:  11073, Training Accuracy:  81.2%, Loss: 0.3269\n",
      "Optimization Iteration:  11137, Training Accuracy:  79.7%, Loss: 0.3646\n",
      "Optimization Iteration:  11201, Training Accuracy:  82.8%, Loss: 0.3550\n",
      "Optimization Iteration:  11265, Training Accuracy:  76.6%, Loss: 0.3691\n",
      "Optimization Iteration:  11329, Training Accuracy:  75.0%, Loss: 0.4905\n",
      "Optimization Iteration:  11393, Training Accuracy:  78.1%, Loss: 0.4154\n",
      "Optimization Iteration:  11457, Training Accuracy:  81.2%, Loss: 0.3811\n",
      "Optimization Iteration:  11521, Training Accuracy:  81.2%, Loss: 0.3767\n",
      "Optimization Iteration:  11585, Training Accuracy:  81.2%, Loss: 0.3313\n",
      "Optimization Iteration:  11649, Training Accuracy:  70.3%, Loss: 0.4344\n",
      "Optimization Iteration:  11713, Training Accuracy:  81.2%, Loss: 0.4136\n",
      "Optimization Iteration:  11777, Training Accuracy:  82.8%, Loss: 0.4177\n",
      "Optimization Iteration:  11841, Training Accuracy:  81.2%, Loss: 0.3459\n",
      "Optimization Iteration:  11905, Training Accuracy:  75.0%, Loss: 0.3864\n",
      "Optimization Iteration:  11969, Training Accuracy:  78.1%, Loss: 0.3767\n",
      "Optimization Iteration:  12033, Training Accuracy:  75.0%, Loss: 0.3799\n",
      "Optimization Iteration:  12097, Training Accuracy:  76.6%, Loss: 0.3621\n",
      "Optimization Iteration:  12161, Training Accuracy:  70.3%, Loss: 0.5100\n",
      "Optimization Iteration:  12225, Training Accuracy:  78.1%, Loss: 0.3138\n",
      "Optimization Iteration:  12289, Training Accuracy:  84.4%, Loss: 0.2791\n",
      "Optimization Iteration:  12353, Training Accuracy:  79.7%, Loss: 0.3954\n",
      "Optimization Iteration:  12417, Training Accuracy:  76.6%, Loss: 0.3890\n",
      "Optimization Iteration:  12481, Training Accuracy:  75.0%, Loss: 0.3997\n",
      "Optimization Iteration:  12545, Training Accuracy:  79.7%, Loss: 0.3864\n",
      "Optimization Iteration:  12609, Training Accuracy:  71.9%, Loss: 0.4111\n",
      "Optimization Iteration:  12673, Training Accuracy:  79.7%, Loss: 0.4149\n",
      "Optimization Iteration:  12737, Training Accuracy:  68.8%, Loss: 0.4292\n",
      "Optimization Iteration:  12801, Training Accuracy:  70.3%, Loss: 0.4942\n",
      "Optimization Iteration:  12865, Training Accuracy:  75.0%, Loss: 0.4619\n",
      "Optimization Iteration:  12929, Training Accuracy:  70.3%, Loss: 0.4104\n",
      "Optimization Iteration:  12993, Training Accuracy:  85.9%, Loss: 0.3063\n",
      "Optimization Iteration:  13057, Training Accuracy:  70.3%, Loss: 0.4816\n",
      "Optimization Iteration:  13121, Training Accuracy:  78.1%, Loss: 0.3657\n",
      "Optimization Iteration:  13185, Training Accuracy:  79.7%, Loss: 0.4283\n",
      "Optimization Iteration:  13249, Training Accuracy:  71.9%, Loss: 0.4456\n",
      "Optimization Iteration:  13313, Training Accuracy:  71.9%, Loss: 0.5636\n",
      "Optimization Iteration:  13377, Training Accuracy:  71.9%, Loss: 0.4175\n",
      "Optimization Iteration:  13441, Training Accuracy:  73.4%, Loss: 0.3931\n",
      "Optimization Iteration:  13505, Training Accuracy:  71.9%, Loss: 0.4426\n",
      "Optimization Iteration:  13569, Training Accuracy:  85.9%, Loss: 0.3273\n",
      "Optimization Iteration:  13633, Training Accuracy:  68.8%, Loss: 0.4332\n",
      "Optimization Iteration:  13697, Training Accuracy:  81.2%, Loss: 0.3513\n",
      "Optimization Iteration:  13761, Training Accuracy:  75.0%, Loss: 0.3951\n",
      "Optimization Iteration:  13825, Training Accuracy:  84.4%, Loss: 0.3648\n",
      "Optimization Iteration:  13889, Training Accuracy:  79.7%, Loss: 0.5557\n",
      "Optimization Iteration:  13953, Training Accuracy:  79.7%, Loss: 0.3396\n",
      "Optimization Iteration:  14017, Training Accuracy:  79.7%, Loss: 0.3958\n",
      "Optimization Iteration:  14081, Training Accuracy:  68.8%, Loss: 0.3922\n",
      "Optimization Iteration:  14145, Training Accuracy:  73.4%, Loss: 0.3768\n",
      "Optimization Iteration:  14209, Training Accuracy:  79.7%, Loss: 0.4273\n",
      "Optimization Iteration:  14273, Training Accuracy:  73.4%, Loss: 0.4386\n",
      "Optimization Iteration:  14337, Training Accuracy:  85.9%, Loss: 0.2797\n",
      "Optimization Iteration:  14401, Training Accuracy:  76.6%, Loss: 0.3760\n",
      "Optimization Iteration:  14465, Training Accuracy:  70.3%, Loss: 0.4581\n",
      "Optimization Iteration:  14529, Training Accuracy:  75.0%, Loss: 0.4206\n",
      "Optimization Iteration:  14593, Training Accuracy:  81.2%, Loss: 0.2963\n",
      "Optimization Iteration:  14657, Training Accuracy:  65.6%, Loss: 0.4738\n",
      "Optimization Iteration:  14721, Training Accuracy:  76.6%, Loss: 0.3920\n",
      "Optimization Iteration:  14785, Training Accuracy:  81.2%, Loss: 0.4610\n",
      "Optimization Iteration:  14849, Training Accuracy:  76.6%, Loss: 0.3944\n",
      "Optimization Iteration:  14913, Training Accuracy:  75.0%, Loss: 0.3175\n",
      "Optimization Iteration:  14977, Training Accuracy:  81.2%, Loss: 0.3862\n",
      "Optimization Iteration:  15041, Training Accuracy:  78.1%, Loss: 0.4080\n",
      "Optimization Iteration:  15105, Training Accuracy:  79.7%, Loss: 0.3269\n",
      "Optimization Iteration:  15169, Training Accuracy:  70.3%, Loss: 0.4250\n",
      "Optimization Iteration:  15233, Training Accuracy:  75.0%, Loss: 0.4207\n",
      "Optimization Iteration:  15297, Training Accuracy:  79.7%, Loss: 0.3631\n",
      "Optimization Iteration:  15361, Training Accuracy:  82.8%, Loss: 0.3470\n",
      "Optimization Iteration:  15425, Training Accuracy:  67.2%, Loss: 0.4647\n",
      "Optimization Iteration:  15489, Training Accuracy:  67.2%, Loss: 0.4440\n",
      "Optimization Iteration:  15553, Training Accuracy:  76.6%, Loss: 0.3327\n",
      "Optimization Iteration:  15617, Training Accuracy:  78.1%, Loss: 0.4291\n",
      "Optimization Iteration:  15681, Training Accuracy:  76.6%, Loss: 0.3531\n",
      "Optimization Iteration:  15745, Training Accuracy:  82.8%, Loss: 0.3420\n",
      "Optimization Iteration:  15809, Training Accuracy:  75.0%, Loss: 0.4180\n",
      "Optimization Iteration:  15873, Training Accuracy:  70.3%, Loss: 0.4152\n",
      "Optimization Iteration:  15937, Training Accuracy:  75.0%, Loss: 0.3903\n",
      "Optimization Iteration:  16001, Training Accuracy:  70.3%, Loss: 0.4252\n",
      "Optimization Iteration:  16065, Training Accuracy:  71.9%, Loss: 0.4075\n",
      "Optimization Iteration:  16129, Training Accuracy:  76.6%, Loss: 0.3721\n",
      "Optimization Iteration:  16193, Training Accuracy:  82.8%, Loss: 0.4117\n",
      "Optimization Iteration:  16257, Training Accuracy:  78.1%, Loss: 0.3845\n",
      "Optimization Iteration:  16321, Training Accuracy:  76.6%, Loss: 0.4528\n",
      "Optimization Iteration:  16385, Training Accuracy:  78.1%, Loss: 0.3785\n",
      "Optimization Iteration:  16449, Training Accuracy:  76.6%, Loss: 0.3931\n",
      "Optimization Iteration:  16513, Training Accuracy:  73.4%, Loss: 0.4389\n",
      "Optimization Iteration:  16577, Training Accuracy:  76.6%, Loss: 0.3767\n",
      "Optimization Iteration:  16641, Training Accuracy:  75.0%, Loss: 0.4358\n",
      "Optimization Iteration:  16705, Training Accuracy:  78.1%, Loss: 0.3606\n",
      "Optimization Iteration:  16769, Training Accuracy:  75.0%, Loss: 0.3757\n",
      "Optimization Iteration:  16833, Training Accuracy:  70.3%, Loss: 0.3461\n",
      "Optimization Iteration:  16897, Training Accuracy:  75.0%, Loss: 0.4111\n",
      "Optimization Iteration:  16961, Training Accuracy:  76.6%, Loss: 0.4141\n",
      "Optimization Iteration:  17025, Training Accuracy:  76.6%, Loss: 0.3965\n",
      "Optimization Iteration:  17089, Training Accuracy:  68.8%, Loss: 0.5028\n",
      "Optimization Iteration:  17153, Training Accuracy:  78.1%, Loss: 0.3798\n",
      "Optimization Iteration:  17217, Training Accuracy:  76.6%, Loss: 0.4391\n",
      "Optimization Iteration:  17281, Training Accuracy:  68.8%, Loss: 0.4483\n",
      "Optimization Iteration:  17345, Training Accuracy:  68.8%, Loss: 0.3813\n",
      "Optimization Iteration:  17409, Training Accuracy:  68.8%, Loss: 0.4447\n",
      "Optimization Iteration:  17473, Training Accuracy:  75.0%, Loss: 0.4879\n",
      "Optimization Iteration:  17537, Training Accuracy:  79.7%, Loss: 0.3532\n",
      "Optimization Iteration:  17601, Training Accuracy:  68.8%, Loss: 0.4219\n",
      "Optimization Iteration:  17665, Training Accuracy:  75.0%, Loss: 0.3792\n",
      "Optimization Iteration:  17729, Training Accuracy:  68.8%, Loss: 0.4489\n",
      "Optimization Iteration:  17793, Training Accuracy:  65.6%, Loss: 0.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  17857, Training Accuracy:  79.7%, Loss: 0.4282\n",
      "Optimization Iteration:  17921, Training Accuracy:  81.2%, Loss: 0.3453\n",
      "Optimization Iteration:  17985, Training Accuracy:  79.7%, Loss: 0.3294\n",
      "Optimization Iteration:  18049, Training Accuracy:  79.7%, Loss: 0.3487\n",
      "Optimization Iteration:  18113, Training Accuracy:  67.2%, Loss: 0.5291\n",
      "Optimization Iteration:  18177, Training Accuracy:  68.8%, Loss: 0.4839\n",
      "Optimization Iteration:  18241, Training Accuracy:  75.0%, Loss: 0.3943\n",
      "Optimization Iteration:  18305, Training Accuracy:  70.3%, Loss: 0.4462\n",
      "Optimization Iteration:  18369, Training Accuracy:  78.1%, Loss: 0.3376\n",
      "Optimization Iteration:  18433, Training Accuracy:  71.9%, Loss: 0.4286\n",
      "Optimization Iteration:  18497, Training Accuracy:  78.1%, Loss: 0.3694\n",
      "Optimization Iteration:  18561, Training Accuracy:  78.1%, Loss: 0.4251\n",
      "Optimization Iteration:  18625, Training Accuracy:  71.9%, Loss: 0.4644\n",
      "Optimization Iteration:  18689, Training Accuracy:  79.7%, Loss: 0.3887\n",
      "Optimization Iteration:  18753, Training Accuracy:  81.2%, Loss: 0.3534\n",
      "Optimization Iteration:  18817, Training Accuracy:  79.7%, Loss: 0.3490\n",
      "Optimization Iteration:  18881, Training Accuracy:  78.1%, Loss: 0.3646\n",
      "Optimization Iteration:  18945, Training Accuracy:  75.0%, Loss: 0.4749\n",
      "Optimization Iteration:  19009, Training Accuracy:  79.7%, Loss: 0.3393\n",
      "Optimization Iteration:  19073, Training Accuracy:  71.9%, Loss: 0.5006\n",
      "Optimization Iteration:  19137, Training Accuracy:  71.9%, Loss: 0.5145\n",
      "Optimization Iteration:  19201, Training Accuracy:  87.5%, Loss: 0.3834\n",
      "Optimization Iteration:  19265, Training Accuracy:  78.1%, Loss: 0.4017\n",
      "Optimization Iteration:  19329, Training Accuracy:  82.8%, Loss: 0.3466\n",
      "Optimization Iteration:  19393, Training Accuracy:  75.0%, Loss: 0.4280\n",
      "Optimization Iteration:  19457, Training Accuracy:  82.8%, Loss: 0.3456\n",
      "Optimization Iteration:  19521, Training Accuracy:  73.4%, Loss: 0.4232\n",
      "Optimization Iteration:  19585, Training Accuracy:  70.3%, Loss: 0.4157\n",
      "Optimization Iteration:  19649, Training Accuracy:  75.0%, Loss: 0.3758\n",
      "Optimization Iteration:  19713, Training Accuracy:  78.1%, Loss: 0.3174\n",
      "Optimization Iteration:  19777, Training Accuracy:  81.2%, Loss: 0.3351\n",
      "Optimization Iteration:  19841, Training Accuracy:  70.3%, Loss: 0.3881\n",
      "Optimization Iteration:  19905, Training Accuracy:  68.8%, Loss: 0.4555\n",
      "Optimization Iteration:  19969, Training Accuracy:  76.6%, Loss: 0.4162\n",
      "Optimization Iteration:  20033, Training Accuracy:  84.4%, Loss: 0.3213\n",
      "Optimization Iteration:  20097, Training Accuracy:  75.0%, Loss: 0.4144\n",
      "Optimization Iteration:  20161, Training Accuracy:  73.4%, Loss: 0.3819\n",
      "Optimization Iteration:  20225, Training Accuracy:  76.6%, Loss: 0.3960\n",
      "Optimization Iteration:  20289, Training Accuracy:  71.9%, Loss: 0.4533\n",
      "Optimization Iteration:  20353, Training Accuracy:  79.7%, Loss: 0.3591\n",
      "Optimization Iteration:  20417, Training Accuracy:  76.6%, Loss: 0.4126\n",
      "Optimization Iteration:  20481, Training Accuracy:  85.9%, Loss: 0.3599\n",
      "Optimization Iteration:  20545, Training Accuracy:  65.6%, Loss: 0.4915\n",
      "Optimization Iteration:  20609, Training Accuracy:  75.0%, Loss: 0.4362\n",
      "Optimization Iteration:  20673, Training Accuracy:  71.9%, Loss: 0.3980\n",
      "Optimization Iteration:  20737, Training Accuracy:  81.2%, Loss: 0.3722\n",
      "Optimization Iteration:  20801, Training Accuracy:  79.7%, Loss: 0.3979\n",
      "Optimization Iteration:  20865, Training Accuracy:  71.9%, Loss: 0.4078\n",
      "Optimization Iteration:  20929, Training Accuracy:  76.6%, Loss: 0.3982\n",
      "Optimization Iteration:  20993, Training Accuracy:  78.1%, Loss: 0.4275\n",
      "Optimization Iteration:  21057, Training Accuracy:  78.1%, Loss: 0.3115\n",
      "Optimization Iteration:  21121, Training Accuracy:  62.5%, Loss: 0.4234\n",
      "Optimization Iteration:  21185, Training Accuracy:  73.4%, Loss: 0.4503\n",
      "Optimization Iteration:  21249, Training Accuracy:  73.4%, Loss: 0.4578\n",
      "Optimization Iteration:  21313, Training Accuracy:  71.9%, Loss: 0.4496\n",
      "Optimization Iteration:  21377, Training Accuracy:  73.4%, Loss: 0.3918\n",
      "Optimization Iteration:  21441, Training Accuracy:  78.1%, Loss: 0.3731\n",
      "Optimization Iteration:  21505, Training Accuracy:  70.3%, Loss: 0.4170\n",
      "Optimization Iteration:  21569, Training Accuracy:  71.9%, Loss: 0.3380\n",
      "Optimization Iteration:  21633, Training Accuracy:  79.7%, Loss: 0.3347\n",
      "Optimization Iteration:  21697, Training Accuracy:  73.4%, Loss: 0.4928\n",
      "Optimization Iteration:  21761, Training Accuracy:  75.0%, Loss: 0.3582\n",
      "Optimization Iteration:  21825, Training Accuracy:  76.6%, Loss: 0.4568\n",
      "Optimization Iteration:  21889, Training Accuracy:  81.2%, Loss: 0.3605\n",
      "Optimization Iteration:  21953, Training Accuracy:  65.6%, Loss: 0.5462\n",
      "Optimization Iteration:  22017, Training Accuracy:  78.1%, Loss: 0.3761\n",
      "Optimization Iteration:  22081, Training Accuracy:  78.1%, Loss: 0.3639\n",
      "Optimization Iteration:  22145, Training Accuracy:  82.8%, Loss: 0.3427\n",
      "Optimization Iteration:  22209, Training Accuracy:  78.1%, Loss: 0.3723\n",
      "Optimization Iteration:  22273, Training Accuracy:  76.6%, Loss: 0.4370\n",
      "Optimization Iteration:  22337, Training Accuracy:  78.1%, Loss: 0.2987\n",
      "Optimization Iteration:  22401, Training Accuracy:  78.1%, Loss: 0.4147\n",
      "Optimization Iteration:  22465, Training Accuracy:  76.6%, Loss: 0.3631\n",
      "Optimization Iteration:  22529, Training Accuracy:  82.8%, Loss: 0.3658\n",
      "Optimization Iteration:  22593, Training Accuracy:  79.7%, Loss: 0.4262\n",
      "Optimization Iteration:  22657, Training Accuracy:  78.1%, Loss: 0.3784\n",
      "Optimization Iteration:  22721, Training Accuracy:  70.3%, Loss: 0.3795\n",
      "Optimization Iteration:  22785, Training Accuracy:  78.1%, Loss: 0.3830\n",
      "Optimization Iteration:  22849, Training Accuracy:  73.4%, Loss: 0.3992\n",
      "Optimization Iteration:  22913, Training Accuracy:  76.6%, Loss: 0.3990\n",
      "Optimization Iteration:  22977, Training Accuracy:  76.6%, Loss: 0.3889\n",
      "Optimization Iteration:  23041, Training Accuracy:  73.4%, Loss: 0.3647\n",
      "Optimization Iteration:  23105, Training Accuracy:  60.9%, Loss: 0.3606\n",
      "Optimization Iteration:  23169, Training Accuracy:  81.2%, Loss: 0.3891\n",
      "Optimization Iteration:  23233, Training Accuracy:  73.4%, Loss: 0.5356\n",
      "Optimization Iteration:  23297, Training Accuracy:  75.0%, Loss: 0.4453\n",
      "Optimization Iteration:  23361, Training Accuracy:  79.7%, Loss: 0.4436\n",
      "Optimization Iteration:  23425, Training Accuracy:  75.0%, Loss: 0.4722\n",
      "Optimization Iteration:  23489, Training Accuracy:  78.1%, Loss: 0.3735\n",
      "Optimization Iteration:  23553, Training Accuracy:  79.7%, Loss: 0.3093\n",
      "Optimization Iteration:  23617, Training Accuracy:  78.1%, Loss: 0.4782\n",
      "Optimization Iteration:  23681, Training Accuracy:  79.7%, Loss: 0.4564\n",
      "Optimization Iteration:  23745, Training Accuracy:  71.9%, Loss: 0.3831\n",
      "Optimization Iteration:  23809, Training Accuracy:  73.4%, Loss: 0.4351\n",
      "Optimization Iteration:  23873, Training Accuracy:  76.6%, Loss: 0.3129\n",
      "Optimization Iteration:  23937, Training Accuracy:  65.6%, Loss: 0.4585\n",
      "Optimization Iteration:  24001, Training Accuracy:  67.2%, Loss: 0.3314\n",
      "Optimization Iteration:  24065, Training Accuracy:  68.8%, Loss: 0.4640\n",
      "Optimization Iteration:  24129, Training Accuracy:  75.0%, Loss: 0.4107\n",
      "Optimization Iteration:  24193, Training Accuracy:  73.4%, Loss: 0.4297\n",
      "Optimization Iteration:  24257, Training Accuracy:  76.6%, Loss: 0.3800\n",
      "Optimization Iteration:  24321, Training Accuracy:  62.5%, Loss: 0.5156\n",
      "Optimization Iteration:  24385, Training Accuracy:  68.8%, Loss: 0.4490\n",
      "Optimization Iteration:  24449, Training Accuracy:  79.7%, Loss: 0.3443\n",
      "Optimization Iteration:  24513, Training Accuracy:  76.6%, Loss: 0.3839\n",
      "Optimization Iteration:  24577, Training Accuracy:  70.3%, Loss: 0.5239\n",
      "Optimization Iteration:  24641, Training Accuracy:  81.2%, Loss: 0.4248\n",
      "Optimization Iteration:  24705, Training Accuracy:  82.8%, Loss: 0.3706\n",
      "Optimization Iteration:  24769, Training Accuracy:  73.4%, Loss: 0.4085\n",
      "Optimization Iteration:  24833, Training Accuracy:  81.2%, Loss: 0.3284\n",
      "Optimization Iteration:  24897, Training Accuracy:  76.6%, Loss: 0.3934\n",
      "Optimization Iteration:  24961, Training Accuracy:  76.6%, Loss: 0.3249\n",
      "Optimization Iteration:  25025, Training Accuracy:  73.4%, Loss: 0.4018\n",
      "Optimization Iteration:  25089, Training Accuracy:  78.1%, Loss: 0.3393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  25153, Training Accuracy:  70.3%, Loss: 0.4424\n",
      "Optimization Iteration:  25217, Training Accuracy:  70.3%, Loss: 0.4639\n",
      "Optimization Iteration:  25281, Training Accuracy:  82.8%, Loss: 0.3519\n",
      "Optimization Iteration:  25345, Training Accuracy:  79.7%, Loss: 0.4088\n",
      "Optimization Iteration:  25409, Training Accuracy:  79.7%, Loss: 0.3759\n",
      "Optimization Iteration:  25473, Training Accuracy:  75.0%, Loss: 0.4569\n",
      "Optimization Iteration:  25537, Training Accuracy:  71.9%, Loss: 0.3815\n",
      "Optimization Iteration:  25601, Training Accuracy:  65.6%, Loss: 0.4412\n",
      "Optimization Iteration:  25665, Training Accuracy:  68.8%, Loss: 0.4581\n",
      "Optimization Iteration:  25729, Training Accuracy:  81.2%, Loss: 0.3117\n",
      "Optimization Iteration:  25793, Training Accuracy:  73.4%, Loss: 0.4331\n",
      "Optimization Iteration:  25857, Training Accuracy:  70.3%, Loss: 0.4565\n",
      "Optimization Iteration:  25921, Training Accuracy:  73.4%, Loss: 0.5041\n",
      "Optimization Iteration:  25985, Training Accuracy:  79.7%, Loss: 0.4532\n",
      "Optimization Iteration:  26049, Training Accuracy:  73.4%, Loss: 0.3685\n",
      "Optimization Iteration:  26113, Training Accuracy:  73.4%, Loss: 0.4011\n",
      "Optimization Iteration:  26177, Training Accuracy:  79.7%, Loss: 0.3552\n",
      "Optimization Iteration:  26241, Training Accuracy:  75.0%, Loss: 0.4263\n",
      "Optimization Iteration:  26305, Training Accuracy:  78.1%, Loss: 0.4704\n",
      "Optimization Iteration:  26369, Training Accuracy:  73.4%, Loss: 0.4106\n",
      "Optimization Iteration:  26433, Training Accuracy:  71.9%, Loss: 0.4213\n",
      "Optimization Iteration:  26497, Training Accuracy:  78.1%, Loss: 0.4190\n",
      "Optimization Iteration:  26561, Training Accuracy:  84.4%, Loss: 0.2868\n",
      "Optimization Iteration:  26625, Training Accuracy:  75.0%, Loss: 0.3699\n",
      "Optimization Iteration:  26689, Training Accuracy:  81.2%, Loss: 0.4037\n",
      "Optimization Iteration:  26753, Training Accuracy:  73.4%, Loss: 0.4487\n",
      "Optimization Iteration:  26817, Training Accuracy:  73.4%, Loss: 0.4248\n",
      "Optimization Iteration:  26881, Training Accuracy:  84.4%, Loss: 0.3367\n",
      "Optimization Iteration:  26945, Training Accuracy:  70.3%, Loss: 0.4708\n",
      "Optimization Iteration:  27009, Training Accuracy:  75.0%, Loss: 0.3462\n",
      "Optimization Iteration:  27073, Training Accuracy:  87.5%, Loss: 0.3362\n",
      "Optimization Iteration:  27137, Training Accuracy:  90.6%, Loss: 0.3649\n",
      "Optimization Iteration:  27201, Training Accuracy:  85.9%, Loss: 0.2821\n",
      "Optimization Iteration:  27265, Training Accuracy:  79.7%, Loss: 0.3637\n",
      "Optimization Iteration:  27329, Training Accuracy:  81.2%, Loss: 0.3332\n",
      "Optimization Iteration:  27393, Training Accuracy:  73.4%, Loss: 0.4167\n",
      "Optimization Iteration:  27457, Training Accuracy:  79.7%, Loss: 0.3695\n",
      "Optimization Iteration:  27521, Training Accuracy:  76.6%, Loss: 0.4246\n",
      "Optimization Iteration:  27585, Training Accuracy:  78.1%, Loss: 0.3719\n",
      "Optimization Iteration:  27649, Training Accuracy:  84.4%, Loss: 0.3200\n",
      "Optimization Iteration:  27713, Training Accuracy:  79.7%, Loss: 0.4023\n",
      "Optimization Iteration:  27777, Training Accuracy:  79.7%, Loss: 0.3460\n",
      "Optimization Iteration:  27841, Training Accuracy:  78.1%, Loss: 0.4586\n",
      "Optimization Iteration:  27905, Training Accuracy:  70.3%, Loss: 0.4322\n",
      "Optimization Iteration:  27969, Training Accuracy:  70.3%, Loss: 0.4459\n",
      "Optimization Iteration:  28033, Training Accuracy:  84.4%, Loss: 0.3695\n",
      "Optimization Iteration:  28097, Training Accuracy:  81.2%, Loss: 0.3549\n",
      "Optimization Iteration:  28161, Training Accuracy:  87.5%, Loss: 0.3090\n",
      "Optimization Iteration:  28225, Training Accuracy:  81.2%, Loss: 0.3372\n",
      "Optimization Iteration:  28289, Training Accuracy:  79.7%, Loss: 0.4202\n",
      "Optimization Iteration:  28353, Training Accuracy:  71.9%, Loss: 0.4165\n",
      "Optimization Iteration:  28417, Training Accuracy:  68.8%, Loss: 0.5645\n",
      "Optimization Iteration:  28481, Training Accuracy:  84.4%, Loss: 0.2986\n",
      "Optimization Iteration:  28545, Training Accuracy:  78.1%, Loss: 0.3462\n",
      "Optimization Iteration:  28609, Training Accuracy:  81.2%, Loss: 0.2870\n",
      "Optimization Iteration:  28673, Training Accuracy:  73.4%, Loss: 0.4336\n",
      "Optimization Iteration:  28737, Training Accuracy:  70.3%, Loss: 0.4321\n",
      "Optimization Iteration:  28801, Training Accuracy:  81.2%, Loss: 0.3200\n",
      "Optimization Iteration:  28865, Training Accuracy:  82.8%, Loss: 0.3048\n",
      "Optimization Iteration:  28929, Training Accuracy:  73.4%, Loss: 0.3380\n",
      "Optimization Iteration:  28993, Training Accuracy:  68.8%, Loss: 0.4253\n",
      "Optimization Iteration:  29057, Training Accuracy:  73.4%, Loss: 0.4304\n",
      "Optimization Iteration:  29121, Training Accuracy:  75.0%, Loss: 0.4835\n",
      "Optimization Iteration:  29185, Training Accuracy:  73.4%, Loss: 0.3653\n",
      "Optimization Iteration:  29249, Training Accuracy:  76.6%, Loss: 0.4053\n",
      "Optimization Iteration:  29313, Training Accuracy:  82.8%, Loss: 0.3990\n",
      "Optimization Iteration:  29377, Training Accuracy:  75.0%, Loss: 0.3793\n",
      "Optimization Iteration:  29441, Training Accuracy:  65.6%, Loss: 0.4473\n",
      "Optimization Iteration:  29505, Training Accuracy:  71.9%, Loss: 0.4900\n",
      "Optimization Iteration:  29569, Training Accuracy:  76.6%, Loss: 0.4295\n",
      "Optimization Iteration:  29633, Training Accuracy:  73.4%, Loss: 0.4293\n",
      "Optimization Iteration:  29697, Training Accuracy:  75.0%, Loss: 0.4090\n",
      "Optimization Iteration:  29761, Training Accuracy:  81.2%, Loss: 0.3392\n",
      "Optimization Iteration:  29825, Training Accuracy:  76.6%, Loss: 0.3738\n",
      "Optimization Iteration:  29889, Training Accuracy:  75.0%, Loss: 0.4016\n",
      "Optimization Iteration:  29953, Training Accuracy:  67.2%, Loss: 0.4477\n",
      "Optimization Iteration:  30017, Training Accuracy:  89.1%, Loss: 0.3344\n",
      "Optimization Iteration:  30081, Training Accuracy:  81.2%, Loss: 0.3420\n",
      "Optimization Iteration:  30145, Training Accuracy:  81.2%, Loss: 0.3780\n",
      "Optimization Iteration:  30209, Training Accuracy:  75.0%, Loss: 0.4092\n",
      "Optimization Iteration:  30273, Training Accuracy:  71.9%, Loss: 0.4255\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.3480\n",
      "Optimization Iteration:  30401, Training Accuracy:  78.1%, Loss: 0.3788\n",
      "Optimization Iteration:  30465, Training Accuracy:  73.4%, Loss: 0.4310\n",
      "Optimization Iteration:  30529, Training Accuracy:  75.0%, Loss: 0.3826\n",
      "Optimization Iteration:  30593, Training Accuracy:  75.0%, Loss: 0.3583\n",
      "Optimization Iteration:  30657, Training Accuracy:  81.2%, Loss: 0.3797\n",
      "Optimization Iteration:  30721, Training Accuracy:  79.7%, Loss: 0.3363\n",
      "Optimization Iteration:  30785, Training Accuracy:  71.9%, Loss: 0.3984\n",
      "Optimization Iteration:  30849, Training Accuracy:  76.6%, Loss: 0.3978\n",
      "Optimization Iteration:  30913, Training Accuracy:  81.2%, Loss: 0.3570\n",
      "Optimization Iteration:  30977, Training Accuracy:  75.0%, Loss: 0.4346\n",
      "Optimization Iteration:  31041, Training Accuracy:  81.2%, Loss: 0.3862\n",
      "Optimization Iteration:  31105, Training Accuracy:  81.2%, Loss: 0.3900\n",
      "Optimization Iteration:  31169, Training Accuracy:  73.4%, Loss: 0.3528\n",
      "Optimization Iteration:  31233, Training Accuracy:  75.0%, Loss: 0.3910\n",
      "Optimization Iteration:  31297, Training Accuracy:  70.3%, Loss: 0.3490\n",
      "Optimization Iteration:  31361, Training Accuracy:  75.0%, Loss: 0.4074\n",
      "Optimization Iteration:  31425, Training Accuracy:  81.2%, Loss: 0.3738\n",
      "Optimization Iteration:  31489, Training Accuracy:  90.6%, Loss: 0.3178\n",
      "Optimization Iteration:  31553, Training Accuracy:  71.9%, Loss: 0.4123\n",
      "Optimization Iteration:  31617, Training Accuracy:  71.9%, Loss: 0.3542\n",
      "Optimization Iteration:  31681, Training Accuracy:  81.2%, Loss: 0.4170\n",
      "Optimization Iteration:  31745, Training Accuracy:  75.0%, Loss: 0.3851\n",
      "Optimization Iteration:  31809, Training Accuracy:  73.4%, Loss: 0.4541\n",
      "Optimization Iteration:  31873, Training Accuracy:  78.1%, Loss: 0.3927\n",
      "Optimization Iteration:  31937, Training Accuracy:  67.2%, Loss: 0.4918\n",
      "Optimization Iteration:  32001, Training Accuracy:  76.6%, Loss: 0.3806\n",
      "Optimization Iteration:  32065, Training Accuracy:  73.4%, Loss: 0.3581\n",
      "Optimization Iteration:  32129, Training Accuracy:  84.4%, Loss: 0.3816\n",
      "Optimization Iteration:  32193, Training Accuracy:  70.3%, Loss: 0.4152\n",
      "Optimization Iteration:  32257, Training Accuracy:  71.9%, Loss: 0.4355\n",
      "Optimization Iteration:  32321, Training Accuracy:  79.7%, Loss: 0.3426\n",
      "Optimization Iteration:  32385, Training Accuracy:  89.1%, Loss: 0.3430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  32449, Training Accuracy:  71.9%, Loss: 0.4047\n",
      "Optimization Iteration:  32513, Training Accuracy:  79.7%, Loss: 0.2948\n",
      "Optimization Iteration:  32577, Training Accuracy:  70.3%, Loss: 0.4067\n",
      "Optimization Iteration:  32641, Training Accuracy:  70.3%, Loss: 0.4491\n",
      "Optimization Iteration:  32705, Training Accuracy:  73.4%, Loss: 0.3726\n",
      "Optimization Iteration:  32769, Training Accuracy:  78.1%, Loss: 0.3643\n",
      "Optimization Iteration:  32833, Training Accuracy:  79.7%, Loss: 0.3505\n",
      "Optimization Iteration:  32897, Training Accuracy:  79.7%, Loss: 0.3862\n",
      "Optimization Iteration:  32961, Training Accuracy:  71.9%, Loss: 0.4487\n",
      "Optimization Iteration:  33025, Training Accuracy:  75.0%, Loss: 0.3095\n",
      "Optimization Iteration:  33089, Training Accuracy:  78.1%, Loss: 0.4444\n",
      "Optimization Iteration:  33153, Training Accuracy:  65.6%, Loss: 0.4304\n",
      "Optimization Iteration:  33217, Training Accuracy:  73.4%, Loss: 0.3514\n",
      "Optimization Iteration:  33281, Training Accuracy:  64.1%, Loss: 0.5567\n",
      "Optimization Iteration:  33345, Training Accuracy:  73.4%, Loss: 0.4389\n",
      "Optimization Iteration:  33409, Training Accuracy:  81.2%, Loss: 0.3927\n",
      "Optimization Iteration:  33473, Training Accuracy:  84.4%, Loss: 0.4577\n",
      "Optimization Iteration:  33537, Training Accuracy:  75.0%, Loss: 0.4297\n",
      "Optimization Iteration:  33601, Training Accuracy:  75.0%, Loss: 0.3983\n",
      "Optimization Iteration:  33665, Training Accuracy:  78.1%, Loss: 0.3538\n",
      "Optimization Iteration:  33729, Training Accuracy:  79.7%, Loss: 0.3926\n",
      "Optimization Iteration:  33793, Training Accuracy:  71.9%, Loss: 0.4402\n",
      "Optimization Iteration:  33857, Training Accuracy:  78.1%, Loss: 0.3783\n",
      "Optimization Iteration:  33921, Training Accuracy:  75.0%, Loss: 0.3783\n",
      "Optimization Iteration:  33985, Training Accuracy:  79.7%, Loss: 0.3525\n",
      "Optimization Iteration:  34049, Training Accuracy:  68.8%, Loss: 0.4780\n",
      "Optimization Iteration:  34113, Training Accuracy:  73.4%, Loss: 0.3594\n",
      "Optimization Iteration:  34177, Training Accuracy:  78.1%, Loss: 0.3412\n",
      "Optimization Iteration:  34241, Training Accuracy:  76.6%, Loss: 0.3643\n",
      "Optimization Iteration:  34305, Training Accuracy:  73.4%, Loss: 0.4115\n",
      "Optimization Iteration:  34369, Training Accuracy:  78.1%, Loss: 0.3112\n",
      "Optimization Iteration:  34433, Training Accuracy:  75.0%, Loss: 0.4501\n",
      "Optimization Iteration:  34497, Training Accuracy:  82.8%, Loss: 0.2957\n",
      "Optimization Iteration:  34561, Training Accuracy:  76.6%, Loss: 0.4532\n",
      "Optimization Iteration:  34625, Training Accuracy:  76.6%, Loss: 0.3927\n",
      "Optimization Iteration:  34689, Training Accuracy:  75.0%, Loss: 0.4814\n",
      "Optimization Iteration:  34753, Training Accuracy:  76.6%, Loss: 0.4663\n",
      "Optimization Iteration:  34817, Training Accuracy:  75.0%, Loss: 0.4235\n",
      "Optimization Iteration:  34881, Training Accuracy:  76.6%, Loss: 0.3285\n",
      "Optimization Iteration:  34945, Training Accuracy:  78.1%, Loss: 0.3762\n",
      "Optimization Iteration:  35009, Training Accuracy:  81.2%, Loss: 0.3825\n",
      "Optimization Iteration:  35073, Training Accuracy:  68.8%, Loss: 0.4403\n",
      "Optimization Iteration:  35137, Training Accuracy:  78.1%, Loss: 0.3363\n",
      "Optimization Iteration:  35201, Training Accuracy:  73.4%, Loss: 0.3696\n",
      "Optimization Iteration:  35265, Training Accuracy:  73.4%, Loss: 0.4116\n",
      "Optimization Iteration:  35329, Training Accuracy:  70.3%, Loss: 0.5078\n",
      "Optimization Iteration:  35393, Training Accuracy:  71.9%, Loss: 0.3865\n",
      "Optimization Iteration:  35457, Training Accuracy:  71.9%, Loss: 0.4214\n",
      "Optimization Iteration:  35521, Training Accuracy:  75.0%, Loss: 0.4310\n",
      "Optimization Iteration:  35585, Training Accuracy:  82.8%, Loss: 0.2985\n",
      "Optimization Iteration:  35649, Training Accuracy:  68.8%, Loss: 0.4163\n",
      "Optimization Iteration:  35713, Training Accuracy:  81.2%, Loss: 0.3856\n",
      "Optimization Iteration:  35777, Training Accuracy:  82.8%, Loss: 0.3553\n",
      "Optimization Iteration:  35841, Training Accuracy:  76.6%, Loss: 0.3447\n",
      "Optimization Iteration:  35905, Training Accuracy:  78.1%, Loss: 0.3518\n",
      "Optimization Iteration:  35969, Training Accuracy:  59.4%, Loss: 0.4451\n",
      "Optimization Iteration:  36033, Training Accuracy:  75.0%, Loss: 0.3578\n",
      "Optimization Iteration:  36097, Training Accuracy:  75.0%, Loss: 0.4099\n",
      "Optimization Iteration:  36161, Training Accuracy:  81.2%, Loss: 0.3325\n",
      "Optimization Iteration:  36225, Training Accuracy:  73.4%, Loss: 0.3821\n",
      "Optimization Iteration:  36289, Training Accuracy:  78.1%, Loss: 0.3614\n",
      "Optimization Iteration:  36353, Training Accuracy:  71.9%, Loss: 0.3517\n",
      "Optimization Iteration:  36417, Training Accuracy:  84.4%, Loss: 0.3918\n",
      "Optimization Iteration:  36481, Training Accuracy:  68.8%, Loss: 0.3639\n",
      "Optimization Iteration:  36545, Training Accuracy:  82.8%, Loss: 0.4174\n",
      "Optimization Iteration:  36609, Training Accuracy:  70.3%, Loss: 0.3723\n",
      "Optimization Iteration:  36673, Training Accuracy:  68.8%, Loss: 0.4491\n",
      "Optimization Iteration:  36737, Training Accuracy:  68.8%, Loss: 0.4128\n",
      "Optimization Iteration:  36801, Training Accuracy:  78.1%, Loss: 0.3795\n",
      "Optimization Iteration:  36865, Training Accuracy:  71.9%, Loss: 0.4510\n",
      "Optimization Iteration:  36929, Training Accuracy:  71.9%, Loss: 0.4236\n",
      "Optimization Iteration:  36993, Training Accuracy:  85.9%, Loss: 0.3229\n",
      "Optimization Iteration:  37057, Training Accuracy:  81.2%, Loss: 0.2836\n",
      "Optimization Iteration:  37121, Training Accuracy:  81.2%, Loss: 0.3806\n",
      "Optimization Iteration:  37185, Training Accuracy:  81.2%, Loss: 0.3483\n",
      "Optimization Iteration:  37249, Training Accuracy:  71.9%, Loss: 0.4647\n",
      "Optimization Iteration:  37313, Training Accuracy:  81.2%, Loss: 0.3171\n",
      "Optimization Iteration:  37377, Training Accuracy:  68.8%, Loss: 0.5864\n",
      "Optimization Iteration:  37441, Training Accuracy:  75.0%, Loss: 0.4217\n",
      "Optimization Iteration:  37505, Training Accuracy:  75.0%, Loss: 0.3854\n",
      "Optimization Iteration:  37569, Training Accuracy:  67.2%, Loss: 0.5030\n",
      "Optimization Iteration:  37633, Training Accuracy:  67.2%, Loss: 0.4704\n",
      "Optimization Iteration:  37697, Training Accuracy:  70.3%, Loss: 0.4102\n",
      "Optimization Iteration:  37761, Training Accuracy:  76.6%, Loss: 0.3780\n",
      "Optimization Iteration:  37825, Training Accuracy:  75.0%, Loss: 0.4262\n",
      "Optimization Iteration:  37889, Training Accuracy:  75.0%, Loss: 0.4509\n",
      "Optimization Iteration:  37953, Training Accuracy:  75.0%, Loss: 0.4173\n",
      "Optimization Iteration:  38017, Training Accuracy:  73.4%, Loss: 0.4330\n",
      "Optimization Iteration:  38081, Training Accuracy:  71.9%, Loss: 0.3999\n",
      "Optimization Iteration:  38145, Training Accuracy:  75.0%, Loss: 0.3785\n",
      "Optimization Iteration:  38209, Training Accuracy:  78.1%, Loss: 0.3906\n",
      "Optimization Iteration:  38273, Training Accuracy:  79.7%, Loss: 0.4314\n",
      "Optimization Iteration:  38337, Training Accuracy:  73.4%, Loss: 0.3733\n",
      "Optimization Iteration:  38401, Training Accuracy:  79.7%, Loss: 0.3706\n",
      "Optimization Iteration:  38465, Training Accuracy:  70.3%, Loss: 0.4493\n",
      "Optimization Iteration:  38529, Training Accuracy:  70.3%, Loss: 0.4253\n",
      "Optimization Iteration:  38593, Training Accuracy:  81.2%, Loss: 0.4456\n",
      "Optimization Iteration:  38657, Training Accuracy:  79.7%, Loss: 0.3931\n",
      "Optimization Iteration:  38721, Training Accuracy:  78.1%, Loss: 0.3571\n",
      "Optimization Iteration:  38785, Training Accuracy:  76.6%, Loss: 0.4497\n",
      "Optimization Iteration:  38849, Training Accuracy:  75.0%, Loss: 0.3338\n",
      "Optimization Iteration:  38913, Training Accuracy:  78.1%, Loss: 0.3811\n",
      "Optimization Iteration:  38977, Training Accuracy:  76.6%, Loss: 0.3735\n",
      "Optimization Iteration:  39041, Training Accuracy:  78.1%, Loss: 0.3998\n",
      "Optimization Iteration:  39105, Training Accuracy:  76.6%, Loss: 0.4657\n",
      "Optimization Iteration:  39169, Training Accuracy:  67.2%, Loss: 0.4810\n",
      "Optimization Iteration:  39233, Training Accuracy:  73.4%, Loss: 0.4291\n",
      "Optimization Iteration:  39297, Training Accuracy:  79.7%, Loss: 0.3438\n",
      "Optimization Iteration:  39361, Training Accuracy:  75.0%, Loss: 0.3715\n",
      "Optimization Iteration:  39425, Training Accuracy:  70.3%, Loss: 0.4383\n",
      "Optimization Iteration:  39489, Training Accuracy:  85.9%, Loss: 0.3485\n",
      "Optimization Iteration:  39553, Training Accuracy:  81.2%, Loss: 0.3146\n",
      "Optimization Iteration:  39617, Training Accuracy:  78.1%, Loss: 0.4977\n",
      "Optimization Iteration:  39681, Training Accuracy:  67.2%, Loss: 0.4147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  39745, Training Accuracy:  73.4%, Loss: 0.4177\n",
      "Optimization Iteration:  39809, Training Accuracy:  76.6%, Loss: 0.4518\n",
      "Optimization Iteration:  39873, Training Accuracy:  71.9%, Loss: 0.4132\n",
      "Optimization Iteration:  39937, Training Accuracy:  73.4%, Loss: 0.5170\n",
      "Optimization Iteration:  40001, Training Accuracy:  70.3%, Loss: 0.4439\n",
      "Optimization Iteration:  40065, Training Accuracy:  71.9%, Loss: 0.3639\n",
      "Optimization Iteration:  40129, Training Accuracy:  71.9%, Loss: 0.3996\n",
      "Optimization Iteration:  40193, Training Accuracy:  76.6%, Loss: 0.3562\n",
      "Optimization Iteration:  40257, Training Accuracy:  81.2%, Loss: 0.3675\n",
      "Optimization Iteration:  40321, Training Accuracy:  71.9%, Loss: 0.5035\n",
      "Optimization Iteration:  40385, Training Accuracy:  81.2%, Loss: 0.5003\n",
      "Optimization Iteration:  40449, Training Accuracy:  73.4%, Loss: 0.4130\n",
      "Optimization Iteration:  40513, Training Accuracy:  79.7%, Loss: 0.4042\n",
      "Optimization Iteration:  40577, Training Accuracy:  75.0%, Loss: 0.3846\n",
      "Optimization Iteration:  40641, Training Accuracy:  71.9%, Loss: 0.3517\n",
      "Optimization Iteration:  40705, Training Accuracy:  70.3%, Loss: 0.4683\n",
      "Optimization Iteration:  40769, Training Accuracy:  75.0%, Loss: 0.3524\n",
      "Optimization Iteration:  40833, Training Accuracy:  89.1%, Loss: 0.3074\n",
      "Optimization Iteration:  40897, Training Accuracy:  82.8%, Loss: 0.3680\n",
      "Optimization Iteration:  40961, Training Accuracy:  81.2%, Loss: 0.3720\n",
      "Optimization Iteration:  41025, Training Accuracy:  79.7%, Loss: 0.3765\n",
      "Optimization Iteration:  41089, Training Accuracy:  81.2%, Loss: 0.3752\n",
      "Optimization Iteration:  41153, Training Accuracy:  76.6%, Loss: 0.4270\n",
      "Optimization Iteration:  41217, Training Accuracy:  76.6%, Loss: 0.3742\n",
      "Optimization Iteration:  41281, Training Accuracy:  70.3%, Loss: 0.4444\n",
      "Optimization Iteration:  41345, Training Accuracy:  73.4%, Loss: 0.4071\n",
      "Optimization Iteration:  41409, Training Accuracy:  70.3%, Loss: 0.4177\n",
      "Optimization Iteration:  41473, Training Accuracy:  76.6%, Loss: 0.4185\n",
      "Optimization Iteration:  41537, Training Accuracy:  76.6%, Loss: 0.3879\n",
      "Optimization Iteration:  41601, Training Accuracy:  75.0%, Loss: 0.3840\n",
      "Optimization Iteration:  41665, Training Accuracy:  70.3%, Loss: 0.4033\n",
      "Optimization Iteration:  41729, Training Accuracy:  81.2%, Loss: 0.3174\n",
      "Optimization Iteration:  41793, Training Accuracy:  71.9%, Loss: 0.4275\n",
      "Optimization Iteration:  41857, Training Accuracy:  78.1%, Loss: 0.3842\n",
      "Optimization Iteration:  41921, Training Accuracy:  75.0%, Loss: 0.3855\n",
      "Optimization Iteration:  41985, Training Accuracy:  75.0%, Loss: 0.4047\n",
      "Optimization Iteration:  42049, Training Accuracy:  70.3%, Loss: 0.4709\n",
      "Optimization Iteration:  42113, Training Accuracy:  81.2%, Loss: 0.3763\n",
      "Optimization Iteration:  42177, Training Accuracy:  68.8%, Loss: 0.4855\n",
      "Optimization Iteration:  42241, Training Accuracy:  79.7%, Loss: 0.3975\n",
      "Optimization Iteration:  42305, Training Accuracy:  70.3%, Loss: 0.4883\n",
      "Optimization Iteration:  42369, Training Accuracy:  70.3%, Loss: 0.3993\n",
      "Optimization Iteration:  42433, Training Accuracy:  75.0%, Loss: 0.4610\n",
      "Optimization Iteration:  42497, Training Accuracy:  70.3%, Loss: 0.4119\n",
      "Optimization Iteration:  42561, Training Accuracy:  78.1%, Loss: 0.4432\n",
      "Optimization Iteration:  42625, Training Accuracy:  79.7%, Loss: 0.4228\n",
      "Optimization Iteration:  42689, Training Accuracy:  79.7%, Loss: 0.3993\n",
      "Optimization Iteration:  42753, Training Accuracy:  76.6%, Loss: 0.4316\n",
      "Optimization Iteration:  42817, Training Accuracy:  75.0%, Loss: 0.3598\n",
      "Optimization Iteration:  42881, Training Accuracy:  75.0%, Loss: 0.4160\n",
      "Optimization Iteration:  42945, Training Accuracy:  76.6%, Loss: 0.4027\n",
      "Optimization Iteration:  43009, Training Accuracy:  73.4%, Loss: 0.4374\n",
      "Optimization Iteration:  43073, Training Accuracy:  84.4%, Loss: 0.3720\n",
      "Optimization Iteration:  43137, Training Accuracy:  81.2%, Loss: 0.3419\n",
      "Optimization Iteration:  43201, Training Accuracy:  78.1%, Loss: 0.3902\n",
      "Optimization Iteration:  43265, Training Accuracy:  76.6%, Loss: 0.3849\n",
      "Optimization Iteration:  43329, Training Accuracy:  70.3%, Loss: 0.4358\n",
      "Optimization Iteration:  43393, Training Accuracy:  81.2%, Loss: 0.3658\n",
      "Optimization Iteration:  43457, Training Accuracy:  78.1%, Loss: 0.3172\n",
      "Optimization Iteration:  43521, Training Accuracy:  75.0%, Loss: 0.4421\n",
      "Optimization Iteration:  43585, Training Accuracy:  76.6%, Loss: 0.3876\n",
      "Optimization Iteration:  43649, Training Accuracy:  82.8%, Loss: 0.4059\n",
      "Optimization Iteration:  43713, Training Accuracy:  78.1%, Loss: 0.3557\n",
      "Optimization Iteration:  43777, Training Accuracy:  81.2%, Loss: 0.2639\n",
      "Optimization Iteration:  43841, Training Accuracy:  79.7%, Loss: 0.4148\n",
      "Optimization Iteration:  43905, Training Accuracy:  75.0%, Loss: 0.3772\n",
      "Optimization Iteration:  43969, Training Accuracy:  78.1%, Loss: 0.3748\n",
      "Optimization Iteration:  44033, Training Accuracy:  70.3%, Loss: 0.3918\n",
      "Optimization Iteration:  44097, Training Accuracy:  67.2%, Loss: 0.3949\n",
      "Optimization Iteration:  44161, Training Accuracy:  84.4%, Loss: 0.3284\n",
      "Optimization Iteration:  44225, Training Accuracy:  76.6%, Loss: 0.3780\n",
      "Optimization Iteration:  44289, Training Accuracy:  71.9%, Loss: 0.4863\n",
      "Optimization Iteration:  44353, Training Accuracy:  70.3%, Loss: 0.5384\n",
      "Optimization Iteration:  44417, Training Accuracy:  81.2%, Loss: 0.3717\n",
      "Optimization Iteration:  44481, Training Accuracy:  73.4%, Loss: 0.4453\n",
      "Optimization Iteration:  44545, Training Accuracy:  75.0%, Loss: 0.3740\n",
      "Optimization Iteration:  44609, Training Accuracy:  76.6%, Loss: 0.3811\n",
      "Optimization Iteration:  44673, Training Accuracy:  78.1%, Loss: 0.6451\n",
      "Optimization Iteration:  44737, Training Accuracy:  71.9%, Loss: 0.4412\n",
      "Optimization Iteration:  44801, Training Accuracy:  85.9%, Loss: 0.3479\n",
      "Optimization Iteration:  44865, Training Accuracy:  78.1%, Loss: 0.3747\n",
      "Optimization Iteration:  44929, Training Accuracy:  79.7%, Loss: 0.3628\n",
      "Optimization Iteration:  44993, Training Accuracy:  68.8%, Loss: 0.4732\n",
      "Optimization Iteration:  45057, Training Accuracy:  78.1%, Loss: 0.3861\n",
      "Optimization Iteration:  45121, Training Accuracy:  87.5%, Loss: 0.3399\n",
      "Optimization Iteration:  45185, Training Accuracy:  84.4%, Loss: 0.3280\n",
      "Optimization Iteration:  45249, Training Accuracy:  75.0%, Loss: 0.4446\n",
      "Optimization Iteration:  45313, Training Accuracy:  78.1%, Loss: 0.4106\n",
      "Optimization Iteration:  45377, Training Accuracy:  71.9%, Loss: 0.4934\n",
      "Optimization Iteration:  45441, Training Accuracy:  71.9%, Loss: 0.4185\n",
      "Optimization Iteration:  45505, Training Accuracy:  65.6%, Loss: 0.4785\n",
      "Optimization Iteration:  45569, Training Accuracy:  73.4%, Loss: 0.4438\n",
      "Optimization Iteration:  45633, Training Accuracy:  85.9%, Loss: 0.3436\n",
      "Optimization Iteration:  45697, Training Accuracy:  71.9%, Loss: 0.3952\n",
      "Optimization Iteration:  45761, Training Accuracy:  85.9%, Loss: 0.3513\n",
      "Optimization Iteration:  45825, Training Accuracy:  81.2%, Loss: 0.3729\n",
      "Optimization Iteration:  45889, Training Accuracy:  71.9%, Loss: 0.4002\n",
      "Optimization Iteration:  45953, Training Accuracy:  84.4%, Loss: 0.3576\n",
      "Optimization Iteration:  46017, Training Accuracy:  75.0%, Loss: 0.3878\n",
      "Optimization Iteration:  46081, Training Accuracy:  79.7%, Loss: 0.3422\n",
      "Optimization Iteration:  46145, Training Accuracy:  76.6%, Loss: 0.4256\n",
      "Optimization Iteration:  46209, Training Accuracy:  76.6%, Loss: 0.3871\n",
      "Optimization Iteration:  46273, Training Accuracy:  73.4%, Loss: 0.4283\n",
      "Optimization Iteration:  46337, Training Accuracy:  75.0%, Loss: 0.4861\n",
      "Optimization Iteration:  46401, Training Accuracy:  79.7%, Loss: 0.3657\n",
      "Optimization Iteration:  46465, Training Accuracy:  79.7%, Loss: 0.4341\n",
      "Optimization Iteration:  46529, Training Accuracy:  79.7%, Loss: 0.4029\n",
      "Optimization Iteration:  46593, Training Accuracy:  79.7%, Loss: 0.4216\n",
      "Optimization Iteration:  46657, Training Accuracy:  76.6%, Loss: 0.4391\n",
      "Optimization Iteration:  46721, Training Accuracy:  79.7%, Loss: 0.4168\n",
      "Optimization Iteration:  46785, Training Accuracy:  71.9%, Loss: 0.4704\n",
      "Optimization Iteration:  46849, Training Accuracy:  85.9%, Loss: 0.3226\n",
      "Optimization Iteration:  46913, Training Accuracy:  76.6%, Loss: 0.3990\n",
      "Optimization Iteration:  46977, Training Accuracy:  78.1%, Loss: 0.3669\n",
      "Optimization Iteration:  47041, Training Accuracy:  79.7%, Loss: 0.3449\n",
      "Optimization Iteration:  47105, Training Accuracy:  76.6%, Loss: 0.4875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  47169, Training Accuracy:  64.1%, Loss: 0.4249\n",
      "Optimization Iteration:  47233, Training Accuracy:  68.8%, Loss: 0.4479\n",
      "Optimization Iteration:  47297, Training Accuracy:  78.1%, Loss: 0.3689\n",
      "Optimization Iteration:  47361, Training Accuracy:  84.4%, Loss: 0.3095\n",
      "Optimization Iteration:  47425, Training Accuracy:  79.7%, Loss: 0.3752\n",
      "Optimization Iteration:  47489, Training Accuracy:  79.7%, Loss: 0.4391\n",
      "Optimization Iteration:  47553, Training Accuracy:  73.4%, Loss: 0.3944\n",
      "Optimization Iteration:  47617, Training Accuracy:  71.9%, Loss: 0.4121\n",
      "Optimization Iteration:  47681, Training Accuracy:  82.8%, Loss: 0.2997\n",
      "Optimization Iteration:  47745, Training Accuracy:  71.9%, Loss: 0.4572\n",
      "Optimization Iteration:  47809, Training Accuracy:  82.8%, Loss: 0.3725\n",
      "Optimization Iteration:  47873, Training Accuracy:  81.2%, Loss: 0.3322\n",
      "Optimization Iteration:  47937, Training Accuracy:  73.4%, Loss: 0.3884\n",
      "Optimization Iteration:  48001, Training Accuracy:  79.7%, Loss: 0.3690\n",
      "Optimization Iteration:  48065, Training Accuracy:  82.8%, Loss: 0.3947\n",
      "Optimization Iteration:  48129, Training Accuracy:  79.7%, Loss: 0.4287\n",
      "Optimization Iteration:  48193, Training Accuracy:  76.6%, Loss: 0.4644\n",
      "Optimization Iteration:  48257, Training Accuracy:  71.9%, Loss: 0.4446\n",
      "Optimization Iteration:  48321, Training Accuracy:  78.1%, Loss: 0.3652\n",
      "Optimization Iteration:  48385, Training Accuracy:  81.2%, Loss: 0.3821\n",
      "Optimization Iteration:  48449, Training Accuracy:  78.1%, Loss: 0.3676\n",
      "Optimization Iteration:  48513, Training Accuracy:  78.1%, Loss: 0.3456\n",
      "Optimization Iteration:  48577, Training Accuracy:  67.2%, Loss: 0.4677\n",
      "Optimization Iteration:  48641, Training Accuracy:  82.8%, Loss: 0.3667\n",
      "Optimization Iteration:  48705, Training Accuracy:  89.1%, Loss: 0.3005\n",
      "Optimization Iteration:  48769, Training Accuracy:  87.5%, Loss: 0.3440\n",
      "Optimization Iteration:  48833, Training Accuracy:  75.0%, Loss: 0.4200\n",
      "Optimization Iteration:  48897, Training Accuracy:  79.7%, Loss: 0.3560\n",
      "Optimization Iteration:  48961, Training Accuracy:  76.6%, Loss: 0.4175\n",
      "Optimization Iteration:  49025, Training Accuracy:  73.4%, Loss: 0.4188\n",
      "Optimization Iteration:  49089, Training Accuracy:  78.1%, Loss: 0.3898\n",
      "Optimization Iteration:  49153, Training Accuracy:  67.2%, Loss: 0.3873\n",
      "Optimization Iteration:  49217, Training Accuracy:  79.7%, Loss: 0.3727\n",
      "Optimization Iteration:  49281, Training Accuracy:  73.4%, Loss: 0.3977\n",
      "Optimization Iteration:  49345, Training Accuracy:  78.1%, Loss: 0.3540\n",
      "Optimization Iteration:  49409, Training Accuracy:  76.6%, Loss: 0.3993\n",
      "Optimization Iteration:  49473, Training Accuracy:  75.0%, Loss: 0.3718\n",
      "Optimization Iteration:  49537, Training Accuracy:  79.7%, Loss: 0.3780\n",
      "Optimization Iteration:  49601, Training Accuracy:  71.9%, Loss: 0.4326\n",
      "Optimization Iteration:  49665, Training Accuracy:  87.5%, Loss: 0.3057\n",
      "Optimization Iteration:  49729, Training Accuracy:  65.6%, Loss: 0.4670\n",
      "Optimization Iteration:  49793, Training Accuracy:  71.9%, Loss: 0.4065\n",
      "Optimization Iteration:  49857, Training Accuracy:  64.1%, Loss: 0.5086\n",
      "Optimization Iteration:  49921, Training Accuracy:  78.1%, Loss: 0.3677\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 20\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  78.1%, Loss: 0.4201\n",
      "Optimization Iteration:    129, Training Accuracy:  73.4%, Loss: 0.4799\n",
      "Optimization Iteration:    193, Training Accuracy:  75.0%, Loss: 0.3895\n",
      "Optimization Iteration:    257, Training Accuracy:  70.3%, Loss: 0.4183\n",
      "Optimization Iteration:    321, Training Accuracy:  79.7%, Loss: 0.3665\n",
      "Optimization Iteration:    385, Training Accuracy:  76.6%, Loss: 0.3685\n",
      "Optimization Iteration:    449, Training Accuracy:  82.8%, Loss: 0.3519\n",
      "Optimization Iteration:    513, Training Accuracy:  79.7%, Loss: 0.4689\n",
      "Optimization Iteration:    577, Training Accuracy:  57.8%, Loss: 0.5137\n",
      "Optimization Iteration:    641, Training Accuracy:  71.9%, Loss: 0.3887\n",
      "Optimization Iteration:    705, Training Accuracy:  62.5%, Loss: 0.5192\n",
      "Optimization Iteration:    769, Training Accuracy:  71.9%, Loss: 0.4221\n",
      "Optimization Iteration:    833, Training Accuracy:  78.1%, Loss: 0.3599\n",
      "Optimization Iteration:    897, Training Accuracy:  79.7%, Loss: 0.3166\n",
      "Optimization Iteration:    961, Training Accuracy:  82.8%, Loss: 0.3221\n",
      "Optimization Iteration:   1025, Training Accuracy:  76.6%, Loss: 0.3790\n",
      "Optimization Iteration:   1089, Training Accuracy:  68.8%, Loss: 0.4209\n",
      "Optimization Iteration:   1153, Training Accuracy:  79.7%, Loss: 0.3796\n",
      "Optimization Iteration:   1217, Training Accuracy:  75.0%, Loss: 0.3998\n",
      "Optimization Iteration:   1281, Training Accuracy:  71.9%, Loss: 0.4531\n",
      "Optimization Iteration:   1345, Training Accuracy:  73.4%, Loss: 0.4563\n",
      "Optimization Iteration:   1409, Training Accuracy:  78.1%, Loss: 0.4223\n",
      "Optimization Iteration:   1473, Training Accuracy:  71.9%, Loss: 0.3846\n",
      "Optimization Iteration:   1537, Training Accuracy:  75.0%, Loss: 0.3562\n",
      "Optimization Iteration:   1601, Training Accuracy:  90.6%, Loss: 0.3155\n",
      "Optimization Iteration:   1665, Training Accuracy:  76.6%, Loss: 0.3848\n",
      "Optimization Iteration:   1729, Training Accuracy:  67.2%, Loss: 0.4215\n",
      "Optimization Iteration:   1793, Training Accuracy:  71.9%, Loss: 0.5074\n",
      "Optimization Iteration:   1857, Training Accuracy:  78.1%, Loss: 0.3860\n",
      "Optimization Iteration:   1921, Training Accuracy:  68.8%, Loss: 0.4457\n",
      "Optimization Iteration:   1985, Training Accuracy:  73.4%, Loss: 0.4033\n",
      "Optimization Iteration:   2049, Training Accuracy:  79.7%, Loss: 0.2979\n",
      "Optimization Iteration:   2113, Training Accuracy:  82.8%, Loss: 0.3301\n",
      "Optimization Iteration:   2177, Training Accuracy:  81.2%, Loss: 0.3493\n",
      "Optimization Iteration:   2241, Training Accuracy:  79.7%, Loss: 0.3854\n",
      "Optimization Iteration:   2305, Training Accuracy:  65.6%, Loss: 0.4167\n",
      "Optimization Iteration:   2369, Training Accuracy:  79.7%, Loss: 0.4021\n",
      "Optimization Iteration:   2433, Training Accuracy:  67.2%, Loss: 0.4511\n",
      "Optimization Iteration:   2497, Training Accuracy:  76.6%, Loss: 0.3442\n",
      "Optimization Iteration:   2561, Training Accuracy:  73.4%, Loss: 0.3954\n",
      "Optimization Iteration:   2625, Training Accuracy:  76.6%, Loss: 0.4000\n",
      "Optimization Iteration:   2689, Training Accuracy:  78.1%, Loss: 0.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:  78.1%, Loss: 0.3765\n",
      "Optimization Iteration:   2817, Training Accuracy:  82.8%, Loss: 0.3511\n",
      "Optimization Iteration:   2881, Training Accuracy:  71.9%, Loss: 0.3709\n",
      "Optimization Iteration:   2945, Training Accuracy:  76.6%, Loss: 0.5163\n",
      "Optimization Iteration:   3009, Training Accuracy:  76.6%, Loss: 0.4602\n",
      "Optimization Iteration:   3073, Training Accuracy:  73.4%, Loss: 0.3973\n",
      "Optimization Iteration:   3137, Training Accuracy:  79.7%, Loss: 0.3704\n",
      "Optimization Iteration:   3201, Training Accuracy:  84.4%, Loss: 0.2994\n",
      "Optimization Iteration:   3265, Training Accuracy:  76.6%, Loss: 0.4313\n",
      "Optimization Iteration:   3329, Training Accuracy:  84.4%, Loss: 0.3690\n",
      "Optimization Iteration:   3393, Training Accuracy:  76.6%, Loss: 0.3445\n",
      "Optimization Iteration:   3457, Training Accuracy:  71.9%, Loss: 0.4556\n",
      "Optimization Iteration:   3521, Training Accuracy:  75.0%, Loss: 0.4104\n",
      "Optimization Iteration:   3585, Training Accuracy:  78.1%, Loss: 0.4388\n",
      "Optimization Iteration:   3649, Training Accuracy:  68.8%, Loss: 0.4230\n",
      "Optimization Iteration:   3713, Training Accuracy:  76.6%, Loss: 0.3688\n",
      "Optimization Iteration:   3777, Training Accuracy:  67.2%, Loss: 0.4920\n",
      "Optimization Iteration:   3841, Training Accuracy:  73.4%, Loss: 0.4380\n",
      "Optimization Iteration:   3905, Training Accuracy:  78.1%, Loss: 0.3915\n",
      "Optimization Iteration:   3969, Training Accuracy:  78.1%, Loss: 0.3795\n",
      "Optimization Iteration:   4033, Training Accuracy:  84.4%, Loss: 0.3320\n",
      "Optimization Iteration:   4097, Training Accuracy:  81.2%, Loss: 0.3868\n",
      "Optimization Iteration:   4161, Training Accuracy:  68.8%, Loss: 0.3941\n",
      "Optimization Iteration:   4225, Training Accuracy:  79.7%, Loss: 0.3424\n",
      "Optimization Iteration:   4289, Training Accuracy:  82.8%, Loss: 0.3696\n",
      "Optimization Iteration:   4353, Training Accuracy:  76.6%, Loss: 0.3436\n",
      "Optimization Iteration:   4417, Training Accuracy:  71.9%, Loss: 0.3973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   4481, Training Accuracy:  78.1%, Loss: 0.3113\n",
      "Optimization Iteration:   4545, Training Accuracy:  79.7%, Loss: 0.3522\n",
      "Optimization Iteration:   4609, Training Accuracy:  82.8%, Loss: 0.3710\n",
      "Optimization Iteration:   4673, Training Accuracy:  70.3%, Loss: 0.4785\n",
      "Optimization Iteration:   4737, Training Accuracy:  75.0%, Loss: 0.4198\n",
      "Optimization Iteration:   4801, Training Accuracy:  76.6%, Loss: 0.4151\n",
      "Optimization Iteration:   4865, Training Accuracy:  82.8%, Loss: 0.3663\n",
      "Optimization Iteration:   4929, Training Accuracy:  73.4%, Loss: 0.4039\n",
      "Optimization Iteration:   4993, Training Accuracy:  75.0%, Loss: 0.4249\n",
      "Optimization Iteration:   5057, Training Accuracy:  73.4%, Loss: 0.4185\n",
      "Optimization Iteration:   5121, Training Accuracy:  79.7%, Loss: 0.2964\n",
      "Optimization Iteration:   5185, Training Accuracy:  81.2%, Loss: 0.3628\n",
      "Optimization Iteration:   5249, Training Accuracy:  73.4%, Loss: 0.4064\n",
      "Optimization Iteration:   5313, Training Accuracy:  84.4%, Loss: 0.3225\n",
      "Optimization Iteration:   5377, Training Accuracy:  76.6%, Loss: 0.4019\n",
      "Optimization Iteration:   5441, Training Accuracy:  71.9%, Loss: 0.3939\n",
      "Optimization Iteration:   5505, Training Accuracy:  89.1%, Loss: 0.3093\n",
      "Optimization Iteration:   5569, Training Accuracy:  76.6%, Loss: 0.3684\n",
      "Optimization Iteration:   5633, Training Accuracy:  76.6%, Loss: 0.3802\n",
      "Optimization Iteration:   5697, Training Accuracy:  73.4%, Loss: 0.4836\n",
      "Optimization Iteration:   5761, Training Accuracy:  71.9%, Loss: 0.3538\n",
      "Optimization Iteration:   5825, Training Accuracy:  65.6%, Loss: 0.4374\n",
      "Optimization Iteration:   5889, Training Accuracy:  81.2%, Loss: 0.3850\n",
      "Optimization Iteration:   5953, Training Accuracy:  73.4%, Loss: 0.3942\n",
      "Optimization Iteration:   6017, Training Accuracy:  67.2%, Loss: 0.4871\n",
      "Optimization Iteration:   6081, Training Accuracy:  78.1%, Loss: 0.3892\n",
      "Optimization Iteration:   6145, Training Accuracy:  73.4%, Loss: 0.4793\n",
      "Optimization Iteration:   6209, Training Accuracy:  71.9%, Loss: 0.3889\n",
      "Optimization Iteration:   6273, Training Accuracy:  76.6%, Loss: 0.4212\n",
      "Optimization Iteration:   6337, Training Accuracy:  67.2%, Loss: 0.4317\n",
      "Optimization Iteration:   6401, Training Accuracy:  76.6%, Loss: 0.4138\n",
      "Optimization Iteration:   6465, Training Accuracy:  82.8%, Loss: 0.3584\n",
      "Optimization Iteration:   6529, Training Accuracy:  76.6%, Loss: 0.4380\n",
      "Optimization Iteration:   6593, Training Accuracy:  73.4%, Loss: 0.4413\n",
      "Optimization Iteration:   6657, Training Accuracy:  76.6%, Loss: 0.3693\n",
      "Optimization Iteration:   6721, Training Accuracy:  76.6%, Loss: 0.3475\n",
      "Optimization Iteration:   6785, Training Accuracy:  67.2%, Loss: 0.4343\n",
      "Optimization Iteration:   6849, Training Accuracy:  73.4%, Loss: 0.4045\n",
      "Optimization Iteration:   6913, Training Accuracy:  78.1%, Loss: 0.3496\n",
      "Optimization Iteration:   6977, Training Accuracy:  68.8%, Loss: 0.4381\n",
      "Optimization Iteration:   7041, Training Accuracy:  70.3%, Loss: 0.4047\n",
      "Optimization Iteration:   7105, Training Accuracy:  76.6%, Loss: 0.3972\n",
      "Optimization Iteration:   7169, Training Accuracy:  81.2%, Loss: 0.3775\n",
      "Optimization Iteration:   7233, Training Accuracy:  70.3%, Loss: 0.4866\n",
      "Optimization Iteration:   7297, Training Accuracy:  79.7%, Loss: 0.4057\n",
      "Optimization Iteration:   7361, Training Accuracy:  82.8%, Loss: 0.3762\n",
      "Optimization Iteration:   7425, Training Accuracy:  73.4%, Loss: 0.4092\n",
      "Optimization Iteration:   7489, Training Accuracy:  75.0%, Loss: 0.4581\n",
      "Optimization Iteration:   7553, Training Accuracy:  73.4%, Loss: 0.3991\n",
      "Optimization Iteration:   7617, Training Accuracy:  82.8%, Loss: 0.3481\n",
      "Optimization Iteration:   7681, Training Accuracy:  71.9%, Loss: 0.4755\n",
      "Optimization Iteration:   7745, Training Accuracy:  75.0%, Loss: 0.3415\n",
      "Optimization Iteration:   7809, Training Accuracy:  70.3%, Loss: 0.5019\n",
      "Optimization Iteration:   7873, Training Accuracy:  75.0%, Loss: 0.3726\n",
      "Optimization Iteration:   7937, Training Accuracy:  81.2%, Loss: 0.3941\n",
      "Optimization Iteration:   8001, Training Accuracy:  76.6%, Loss: 0.3928\n",
      "Optimization Iteration:   8065, Training Accuracy:  65.6%, Loss: 0.4379\n",
      "Optimization Iteration:   8129, Training Accuracy:  82.8%, Loss: 0.3606\n",
      "Optimization Iteration:   8193, Training Accuracy:  68.8%, Loss: 0.4862\n",
      "Optimization Iteration:   8257, Training Accuracy:  75.0%, Loss: 0.4942\n",
      "Optimization Iteration:   8321, Training Accuracy:  68.8%, Loss: 0.4865\n",
      "Optimization Iteration:   8385, Training Accuracy:  67.2%, Loss: 0.5031\n",
      "Optimization Iteration:   8449, Training Accuracy:  71.9%, Loss: 0.4350\n",
      "Optimization Iteration:   8513, Training Accuracy:  81.2%, Loss: 0.3070\n",
      "Optimization Iteration:   8577, Training Accuracy:  75.0%, Loss: 0.4647\n",
      "Optimization Iteration:   8641, Training Accuracy:  73.4%, Loss: 0.3729\n",
      "Optimization Iteration:   8705, Training Accuracy:  73.4%, Loss: 0.3987\n",
      "Optimization Iteration:   8769, Training Accuracy:  76.6%, Loss: 0.4170\n",
      "Optimization Iteration:   8833, Training Accuracy:  68.8%, Loss: 0.3876\n",
      "Optimization Iteration:   8897, Training Accuracy:  68.8%, Loss: 0.4497\n",
      "Optimization Iteration:   8961, Training Accuracy:  73.4%, Loss: 0.4688\n",
      "Optimization Iteration:   9025, Training Accuracy:  73.4%, Loss: 0.4492\n",
      "Optimization Iteration:   9089, Training Accuracy:  68.8%, Loss: 0.4845\n",
      "Optimization Iteration:   9153, Training Accuracy:  68.8%, Loss: 0.4419\n",
      "Optimization Iteration:   9217, Training Accuracy:  76.6%, Loss: 0.4377\n",
      "Optimization Iteration:   9281, Training Accuracy:  76.6%, Loss: 0.3659\n",
      "Optimization Iteration:   9345, Training Accuracy:  82.8%, Loss: 0.3466\n",
      "Optimization Iteration:   9409, Training Accuracy:  75.0%, Loss: 0.4759\n",
      "Optimization Iteration:   9473, Training Accuracy:  71.9%, Loss: 0.3827\n",
      "Optimization Iteration:   9537, Training Accuracy:  76.6%, Loss: 0.3854\n",
      "Optimization Iteration:   9601, Training Accuracy:  78.1%, Loss: 0.4265\n",
      "Optimization Iteration:   9665, Training Accuracy:  71.9%, Loss: 0.4069\n",
      "Optimization Iteration:   9729, Training Accuracy:  78.1%, Loss: 0.3986\n",
      "Optimization Iteration:   9793, Training Accuracy:  79.7%, Loss: 0.3514\n",
      "Optimization Iteration:   9857, Training Accuracy:  67.2%, Loss: 0.4638\n",
      "Optimization Iteration:   9921, Training Accuracy:  78.1%, Loss: 0.3366\n",
      "Optimization Iteration:   9985, Training Accuracy:  81.2%, Loss: 0.3984\n",
      "Optimization Iteration:  10049, Training Accuracy:  81.2%, Loss: 0.3688\n",
      "Optimization Iteration:  10113, Training Accuracy:  78.1%, Loss: 0.3796\n",
      "Optimization Iteration:  10177, Training Accuracy:  71.9%, Loss: 0.4588\n",
      "Optimization Iteration:  10241, Training Accuracy:  78.1%, Loss: 0.4330\n",
      "Optimization Iteration:  10305, Training Accuracy:  84.4%, Loss: 0.3905\n",
      "Optimization Iteration:  10369, Training Accuracy:  81.2%, Loss: 0.4170\n",
      "Optimization Iteration:  10433, Training Accuracy:  81.2%, Loss: 0.4035\n",
      "Optimization Iteration:  10497, Training Accuracy:  71.9%, Loss: 0.4707\n",
      "Optimization Iteration:  10561, Training Accuracy:  79.7%, Loss: 0.3222\n",
      "Optimization Iteration:  10625, Training Accuracy:  78.1%, Loss: 0.3860\n",
      "Optimization Iteration:  10689, Training Accuracy:  75.0%, Loss: 0.4060\n",
      "Optimization Iteration:  10753, Training Accuracy:  67.2%, Loss: 0.4765\n",
      "Optimization Iteration:  10817, Training Accuracy:  76.6%, Loss: 0.3915\n",
      "Optimization Iteration:  10881, Training Accuracy:  75.0%, Loss: 0.3672\n",
      "Optimization Iteration:  10945, Training Accuracy:  82.8%, Loss: 0.3609\n",
      "Optimization Iteration:  11009, Training Accuracy:  82.8%, Loss: 0.3376\n",
      "Optimization Iteration:  11073, Training Accuracy:  73.4%, Loss: 0.3493\n",
      "Optimization Iteration:  11137, Training Accuracy:  71.9%, Loss: 0.4210\n",
      "Optimization Iteration:  11201, Training Accuracy:  79.7%, Loss: 0.3813\n",
      "Optimization Iteration:  11265, Training Accuracy:  81.2%, Loss: 0.3623\n",
      "Optimization Iteration:  11329, Training Accuracy:  76.6%, Loss: 0.3936\n",
      "Optimization Iteration:  11393, Training Accuracy:  79.7%, Loss: 0.3988\n",
      "Optimization Iteration:  11457, Training Accuracy:  76.6%, Loss: 0.3748\n",
      "Optimization Iteration:  11521, Training Accuracy:  84.4%, Loss: 0.3515\n",
      "Optimization Iteration:  11585, Training Accuracy:  73.4%, Loss: 0.3895\n",
      "Optimization Iteration:  11649, Training Accuracy:  79.7%, Loss: 0.4051\n",
      "Optimization Iteration:  11713, Training Accuracy:  70.3%, Loss: 0.4451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  11777, Training Accuracy:  73.4%, Loss: 0.4624\n",
      "Optimization Iteration:  11841, Training Accuracy:  82.8%, Loss: 0.3601\n",
      "Optimization Iteration:  11905, Training Accuracy:  75.0%, Loss: 0.3856\n",
      "Optimization Iteration:  11969, Training Accuracy:  78.1%, Loss: 0.3435\n",
      "Optimization Iteration:  12033, Training Accuracy:  70.3%, Loss: 0.5059\n",
      "Optimization Iteration:  12097, Training Accuracy:  81.2%, Loss: 0.3344\n",
      "Optimization Iteration:  12161, Training Accuracy:  71.9%, Loss: 0.5151\n",
      "Optimization Iteration:  12225, Training Accuracy:  78.1%, Loss: 0.3570\n",
      "Optimization Iteration:  12289, Training Accuracy:  85.9%, Loss: 0.2851\n",
      "Optimization Iteration:  12353, Training Accuracy:  84.4%, Loss: 0.3301\n",
      "Optimization Iteration:  12417, Training Accuracy:  75.0%, Loss: 0.4448\n",
      "Optimization Iteration:  12481, Training Accuracy:  79.7%, Loss: 0.4119\n",
      "Optimization Iteration:  12545, Training Accuracy:  78.1%, Loss: 0.4052\n",
      "Optimization Iteration:  12609, Training Accuracy:  76.6%, Loss: 0.3696\n",
      "Optimization Iteration:  12673, Training Accuracy:  75.0%, Loss: 0.3675\n",
      "Optimization Iteration:  12737, Training Accuracy:  76.6%, Loss: 0.4401\n",
      "Optimization Iteration:  12801, Training Accuracy:  68.8%, Loss: 0.4187\n",
      "Optimization Iteration:  12865, Training Accuracy:  73.4%, Loss: 0.4422\n",
      "Optimization Iteration:  12929, Training Accuracy:  65.6%, Loss: 0.4618\n",
      "Optimization Iteration:  12993, Training Accuracy:  82.8%, Loss: 0.4012\n",
      "Optimization Iteration:  13057, Training Accuracy:  71.9%, Loss: 0.4513\n",
      "Optimization Iteration:  13121, Training Accuracy:  75.0%, Loss: 0.3385\n",
      "Optimization Iteration:  13185, Training Accuracy:  75.0%, Loss: 0.3961\n",
      "Optimization Iteration:  13249, Training Accuracy:  68.8%, Loss: 0.5200\n",
      "Optimization Iteration:  13313, Training Accuracy:  67.2%, Loss: 0.4739\n",
      "Optimization Iteration:  13377, Training Accuracy:  71.9%, Loss: 0.4396\n",
      "Optimization Iteration:  13441, Training Accuracy:  85.9%, Loss: 0.2877\n",
      "Optimization Iteration:  13505, Training Accuracy:  78.1%, Loss: 0.3492\n",
      "Optimization Iteration:  13569, Training Accuracy:  85.9%, Loss: 0.2750\n",
      "Optimization Iteration:  13633, Training Accuracy:  76.6%, Loss: 0.3729\n",
      "Optimization Iteration:  13697, Training Accuracy:  81.2%, Loss: 0.3850\n",
      "Optimization Iteration:  13761, Training Accuracy:  78.1%, Loss: 0.3996\n",
      "Optimization Iteration:  13825, Training Accuracy:  76.6%, Loss: 0.4466\n",
      "Optimization Iteration:  13889, Training Accuracy:  73.4%, Loss: 0.4966\n",
      "Optimization Iteration:  13953, Training Accuracy:  70.3%, Loss: 0.4071\n",
      "Optimization Iteration:  14017, Training Accuracy:  68.8%, Loss: 0.4426\n",
      "Optimization Iteration:  14081, Training Accuracy:  76.6%, Loss: 0.3806\n",
      "Optimization Iteration:  14145, Training Accuracy:  79.7%, Loss: 0.3761\n",
      "Optimization Iteration:  14209, Training Accuracy:  82.8%, Loss: 0.3953\n",
      "Optimization Iteration:  14273, Training Accuracy:  78.1%, Loss: 0.3873\n",
      "Optimization Iteration:  14337, Training Accuracy:  79.7%, Loss: 0.3782\n",
      "Optimization Iteration:  14401, Training Accuracy:  81.2%, Loss: 0.3170\n",
      "Optimization Iteration:  14465, Training Accuracy:  73.4%, Loss: 0.4110\n",
      "Optimization Iteration:  14529, Training Accuracy:  79.7%, Loss: 0.4474\n",
      "Optimization Iteration:  14593, Training Accuracy:  76.6%, Loss: 0.4153\n",
      "Optimization Iteration:  14657, Training Accuracy:  75.0%, Loss: 0.4126\n",
      "Optimization Iteration:  14721, Training Accuracy:  79.7%, Loss: 0.3452\n",
      "Optimization Iteration:  14785, Training Accuracy:  71.9%, Loss: 0.4644\n",
      "Optimization Iteration:  14849, Training Accuracy:  73.4%, Loss: 0.4222\n",
      "Optimization Iteration:  14913, Training Accuracy:  87.5%, Loss: 0.3121\n",
      "Optimization Iteration:  14977, Training Accuracy:  78.1%, Loss: 0.4748\n",
      "Optimization Iteration:  15041, Training Accuracy:  70.3%, Loss: 0.3948\n",
      "Optimization Iteration:  15105, Training Accuracy:  79.7%, Loss: 0.3376\n",
      "Optimization Iteration:  15169, Training Accuracy:  85.9%, Loss: 0.3358\n",
      "Optimization Iteration:  15233, Training Accuracy:  75.0%, Loss: 0.3463\n",
      "Optimization Iteration:  15297, Training Accuracy:  71.9%, Loss: 0.4160\n",
      "Optimization Iteration:  15361, Training Accuracy:  85.9%, Loss: 0.3518\n",
      "Optimization Iteration:  15425, Training Accuracy:  75.0%, Loss: 0.3760\n",
      "Optimization Iteration:  15489, Training Accuracy:  75.0%, Loss: 0.4538\n",
      "Optimization Iteration:  15553, Training Accuracy:  82.8%, Loss: 0.3539\n",
      "Optimization Iteration:  15617, Training Accuracy:  78.1%, Loss: 0.3795\n",
      "Optimization Iteration:  15681, Training Accuracy:  79.7%, Loss: 0.3676\n",
      "Optimization Iteration:  15745, Training Accuracy:  79.7%, Loss: 0.3390\n",
      "Optimization Iteration:  15809, Training Accuracy:  70.3%, Loss: 0.4481\n",
      "Optimization Iteration:  15873, Training Accuracy:  79.7%, Loss: 0.4132\n",
      "Optimization Iteration:  15937, Training Accuracy:  75.0%, Loss: 0.3182\n",
      "Optimization Iteration:  16001, Training Accuracy:  73.4%, Loss: 0.4121\n",
      "Optimization Iteration:  16065, Training Accuracy:  67.2%, Loss: 0.4591\n",
      "Optimization Iteration:  16129, Training Accuracy:  78.1%, Loss: 0.3573\n",
      "Optimization Iteration:  16193, Training Accuracy:  81.2%, Loss: 0.3910\n",
      "Optimization Iteration:  16257, Training Accuracy:  78.1%, Loss: 0.3716\n",
      "Optimization Iteration:  16321, Training Accuracy:  78.1%, Loss: 0.3846\n",
      "Optimization Iteration:  16385, Training Accuracy:  81.2%, Loss: 0.3280\n",
      "Optimization Iteration:  16449, Training Accuracy:  71.9%, Loss: 0.3985\n",
      "Optimization Iteration:  16513, Training Accuracy:  73.4%, Loss: 0.4801\n",
      "Optimization Iteration:  16577, Training Accuracy:  78.1%, Loss: 0.3717\n",
      "Optimization Iteration:  16641, Training Accuracy:  78.1%, Loss: 0.5139\n",
      "Optimization Iteration:  16705, Training Accuracy:  75.0%, Loss: 0.4020\n",
      "Optimization Iteration:  16769, Training Accuracy:  78.1%, Loss: 0.3543\n",
      "Optimization Iteration:  16833, Training Accuracy:  65.6%, Loss: 0.4272\n",
      "Optimization Iteration:  16897, Training Accuracy:  78.1%, Loss: 0.3299\n",
      "Optimization Iteration:  16961, Training Accuracy:  75.0%, Loss: 0.3784\n",
      "Optimization Iteration:  17025, Training Accuracy:  73.4%, Loss: 0.3966\n",
      "Optimization Iteration:  17089, Training Accuracy:  70.3%, Loss: 0.4885\n",
      "Optimization Iteration:  17153, Training Accuracy:  73.4%, Loss: 0.4166\n",
      "Optimization Iteration:  17217, Training Accuracy:  79.7%, Loss: 0.4208\n",
      "Optimization Iteration:  17281, Training Accuracy:  62.5%, Loss: 0.4897\n",
      "Optimization Iteration:  17345, Training Accuracy:  78.1%, Loss: 0.3880\n",
      "Optimization Iteration:  17409, Training Accuracy:  68.8%, Loss: 0.4088\n",
      "Optimization Iteration:  17473, Training Accuracy:  73.4%, Loss: 0.4643\n",
      "Optimization Iteration:  17537, Training Accuracy:  84.4%, Loss: 0.3864\n",
      "Optimization Iteration:  17601, Training Accuracy:  71.9%, Loss: 0.4182\n",
      "Optimization Iteration:  17665, Training Accuracy:  78.1%, Loss: 0.3802\n",
      "Optimization Iteration:  17729, Training Accuracy:  70.3%, Loss: 0.4216\n",
      "Optimization Iteration:  17793, Training Accuracy:  67.2%, Loss: 0.4591\n",
      "Optimization Iteration:  17857, Training Accuracy:  70.3%, Loss: 0.5022\n",
      "Optimization Iteration:  17921, Training Accuracy:  81.2%, Loss: 0.3597\n",
      "Optimization Iteration:  17985, Training Accuracy:  76.6%, Loss: 0.3554\n",
      "Optimization Iteration:  18049, Training Accuracy:  81.2%, Loss: 0.3375\n",
      "Optimization Iteration:  18113, Training Accuracy:  65.6%, Loss: 0.4716\n",
      "Optimization Iteration:  18177, Training Accuracy:  71.9%, Loss: 0.4392\n",
      "Optimization Iteration:  18241, Training Accuracy:  70.3%, Loss: 0.4259\n",
      "Optimization Iteration:  18305, Training Accuracy:  70.3%, Loss: 0.4162\n",
      "Optimization Iteration:  18369, Training Accuracy:  75.0%, Loss: 0.3306\n",
      "Optimization Iteration:  18433, Training Accuracy:  70.3%, Loss: 0.4126\n",
      "Optimization Iteration:  18497, Training Accuracy:  79.7%, Loss: 0.3024\n",
      "Optimization Iteration:  18561, Training Accuracy:  75.0%, Loss: 0.4193\n",
      "Optimization Iteration:  18625, Training Accuracy:  68.8%, Loss: 0.4571\n",
      "Optimization Iteration:  18689, Training Accuracy:  71.9%, Loss: 0.4240\n",
      "Optimization Iteration:  18753, Training Accuracy:  81.2%, Loss: 0.3624\n",
      "Optimization Iteration:  18817, Training Accuracy:  82.8%, Loss: 0.3134\n",
      "Optimization Iteration:  18881, Training Accuracy:  84.4%, Loss: 0.3696\n",
      "Optimization Iteration:  18945, Training Accuracy:  75.0%, Loss: 0.3916\n",
      "Optimization Iteration:  19009, Training Accuracy:  67.2%, Loss: 0.4413\n",
      "Optimization Iteration:  19073, Training Accuracy:  79.7%, Loss: 0.3623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  19137, Training Accuracy:  70.3%, Loss: 0.4139\n",
      "Optimization Iteration:  19201, Training Accuracy:  85.9%, Loss: 0.3301\n",
      "Optimization Iteration:  19265, Training Accuracy:  81.2%, Loss: 0.4515\n",
      "Optimization Iteration:  19329, Training Accuracy:  78.1%, Loss: 0.3509\n",
      "Optimization Iteration:  19393, Training Accuracy:  75.0%, Loss: 0.4182\n",
      "Optimization Iteration:  19457, Training Accuracy:  71.9%, Loss: 0.4225\n",
      "Optimization Iteration:  19521, Training Accuracy:  75.0%, Loss: 0.4729\n",
      "Optimization Iteration:  19585, Training Accuracy:  71.9%, Loss: 0.4028\n",
      "Optimization Iteration:  19649, Training Accuracy:  78.1%, Loss: 0.5460\n",
      "Optimization Iteration:  19713, Training Accuracy:  79.7%, Loss: 0.3149\n",
      "Optimization Iteration:  19777, Training Accuracy:  71.9%, Loss: 0.4564\n",
      "Optimization Iteration:  19841, Training Accuracy:  64.1%, Loss: 0.4737\n",
      "Optimization Iteration:  19905, Training Accuracy:  73.4%, Loss: 0.4240\n",
      "Optimization Iteration:  19969, Training Accuracy:  78.1%, Loss: 0.4362\n",
      "Optimization Iteration:  20033, Training Accuracy:  79.7%, Loss: 0.3583\n",
      "Optimization Iteration:  20097, Training Accuracy:  71.9%, Loss: 0.4828\n",
      "Optimization Iteration:  20161, Training Accuracy:  79.7%, Loss: 0.4334\n",
      "Optimization Iteration:  20225, Training Accuracy:  65.6%, Loss: 0.4393\n",
      "Optimization Iteration:  20289, Training Accuracy:  75.0%, Loss: 0.4268\n",
      "Optimization Iteration:  20353, Training Accuracy:  78.1%, Loss: 0.3496\n",
      "Optimization Iteration:  20417, Training Accuracy:  71.9%, Loss: 0.4263\n",
      "Optimization Iteration:  20481, Training Accuracy:  67.2%, Loss: 0.4641\n",
      "Optimization Iteration:  20545, Training Accuracy:  75.0%, Loss: 0.4606\n",
      "Optimization Iteration:  20609, Training Accuracy:  78.1%, Loss: 0.3908\n",
      "Optimization Iteration:  20673, Training Accuracy:  75.0%, Loss: 0.3717\n",
      "Optimization Iteration:  20737, Training Accuracy:  79.7%, Loss: 0.3695\n",
      "Optimization Iteration:  20801, Training Accuracy:  81.2%, Loss: 0.3106\n",
      "Optimization Iteration:  20865, Training Accuracy:  79.7%, Loss: 0.3573\n",
      "Optimization Iteration:  20929, Training Accuracy:  85.9%, Loss: 0.3563\n",
      "Optimization Iteration:  20993, Training Accuracy:  73.4%, Loss: 0.3851\n",
      "Optimization Iteration:  21057, Training Accuracy:  85.9%, Loss: 0.3335\n",
      "Optimization Iteration:  21121, Training Accuracy:  79.7%, Loss: 0.3690\n",
      "Optimization Iteration:  21185, Training Accuracy:  75.0%, Loss: 0.4088\n",
      "Optimization Iteration:  21249, Training Accuracy:  70.3%, Loss: 0.4834\n",
      "Optimization Iteration:  21313, Training Accuracy:  79.7%, Loss: 0.4042\n",
      "Optimization Iteration:  21377, Training Accuracy:  78.1%, Loss: 0.3787\n",
      "Optimization Iteration:  21441, Training Accuracy:  79.7%, Loss: 0.3646\n",
      "Optimization Iteration:  21505, Training Accuracy:  81.2%, Loss: 0.3595\n",
      "Optimization Iteration:  21569, Training Accuracy:  78.1%, Loss: 0.3829\n",
      "Optimization Iteration:  21633, Training Accuracy:  82.8%, Loss: 0.3577\n",
      "Optimization Iteration:  21697, Training Accuracy:  71.9%, Loss: 0.4580\n",
      "Optimization Iteration:  21761, Training Accuracy:  75.0%, Loss: 0.3424\n",
      "Optimization Iteration:  21825, Training Accuracy:  73.4%, Loss: 0.4434\n",
      "Optimization Iteration:  21889, Training Accuracy:  76.6%, Loss: 0.3663\n",
      "Optimization Iteration:  21953, Training Accuracy:  71.9%, Loss: 0.4938\n",
      "Optimization Iteration:  22017, Training Accuracy:  82.8%, Loss: 0.3797\n",
      "Optimization Iteration:  22081, Training Accuracy:  75.0%, Loss: 0.3879\n",
      "Optimization Iteration:  22145, Training Accuracy:  82.8%, Loss: 0.3293\n",
      "Optimization Iteration:  22209, Training Accuracy:  78.1%, Loss: 0.3838\n",
      "Optimization Iteration:  22273, Training Accuracy:  75.0%, Loss: 0.3794\n",
      "Optimization Iteration:  22337, Training Accuracy:  79.7%, Loss: 0.3900\n",
      "Optimization Iteration:  22401, Training Accuracy:  73.4%, Loss: 0.4428\n",
      "Optimization Iteration:  22465, Training Accuracy:  76.6%, Loss: 0.4690\n",
      "Optimization Iteration:  22529, Training Accuracy:  75.0%, Loss: 0.4055\n",
      "Optimization Iteration:  22593, Training Accuracy:  78.1%, Loss: 0.3835\n",
      "Optimization Iteration:  22657, Training Accuracy:  70.3%, Loss: 0.3986\n",
      "Optimization Iteration:  22721, Training Accuracy:  67.2%, Loss: 0.4464\n",
      "Optimization Iteration:  22785, Training Accuracy:  70.3%, Loss: 0.4545\n",
      "Optimization Iteration:  22849, Training Accuracy:  82.8%, Loss: 0.3491\n",
      "Optimization Iteration:  22913, Training Accuracy:  70.3%, Loss: 0.4151\n",
      "Optimization Iteration:  22977, Training Accuracy:  78.1%, Loss: 0.3682\n",
      "Optimization Iteration:  23041, Training Accuracy:  78.1%, Loss: 0.3340\n",
      "Optimization Iteration:  23105, Training Accuracy:  70.3%, Loss: 0.3692\n",
      "Optimization Iteration:  23169, Training Accuracy:  81.2%, Loss: 0.4133\n",
      "Optimization Iteration:  23233, Training Accuracy:  71.9%, Loss: 0.5159\n",
      "Optimization Iteration:  23297, Training Accuracy:  73.4%, Loss: 0.4300\n",
      "Optimization Iteration:  23361, Training Accuracy:  85.9%, Loss: 0.4057\n",
      "Optimization Iteration:  23425, Training Accuracy:  82.8%, Loss: 0.3828\n",
      "Optimization Iteration:  23489, Training Accuracy:  73.4%, Loss: 0.3883\n",
      "Optimization Iteration:  23553, Training Accuracy:  75.0%, Loss: 0.3347\n",
      "Optimization Iteration:  23617, Training Accuracy:  73.4%, Loss: 0.4985\n",
      "Optimization Iteration:  23681, Training Accuracy:  79.7%, Loss: 0.4375\n",
      "Optimization Iteration:  23745, Training Accuracy:  78.1%, Loss: 0.3588\n",
      "Optimization Iteration:  23809, Training Accuracy:  75.0%, Loss: 0.4220\n",
      "Optimization Iteration:  23873, Training Accuracy:  73.4%, Loss: 0.3963\n",
      "Optimization Iteration:  23937, Training Accuracy:  67.2%, Loss: 0.4480\n",
      "Optimization Iteration:  24001, Training Accuracy:  78.1%, Loss: 0.3587\n",
      "Optimization Iteration:  24065, Training Accuracy:  75.0%, Loss: 0.4138\n",
      "Optimization Iteration:  24129, Training Accuracy:  75.0%, Loss: 0.4094\n",
      "Optimization Iteration:  24193, Training Accuracy:  70.3%, Loss: 0.4482\n",
      "Optimization Iteration:  24257, Training Accuracy:  67.2%, Loss: 0.3918\n",
      "Optimization Iteration:  24321, Training Accuracy:  68.8%, Loss: 0.4412\n",
      "Optimization Iteration:  24385, Training Accuracy:  76.6%, Loss: 0.3933\n",
      "Optimization Iteration:  24449, Training Accuracy:  78.1%, Loss: 0.3077\n",
      "Optimization Iteration:  24513, Training Accuracy:  75.0%, Loss: 0.3847\n",
      "Optimization Iteration:  24577, Training Accuracy:  60.9%, Loss: 0.5054\n",
      "Optimization Iteration:  24641, Training Accuracy:  70.3%, Loss: 0.3948\n",
      "Optimization Iteration:  24705, Training Accuracy:  82.8%, Loss: 0.4128\n",
      "Optimization Iteration:  24769, Training Accuracy:  70.3%, Loss: 0.3730\n",
      "Optimization Iteration:  24833, Training Accuracy:  82.8%, Loss: 0.3712\n",
      "Optimization Iteration:  24897, Training Accuracy:  67.2%, Loss: 0.3793\n",
      "Optimization Iteration:  24961, Training Accuracy:  78.1%, Loss: 0.3371\n",
      "Optimization Iteration:  25025, Training Accuracy:  73.4%, Loss: 0.4070\n",
      "Optimization Iteration:  25089, Training Accuracy:  78.1%, Loss: 0.3804\n",
      "Optimization Iteration:  25153, Training Accuracy:  71.9%, Loss: 0.3873\n",
      "Optimization Iteration:  25217, Training Accuracy:  79.7%, Loss: 0.4174\n",
      "Optimization Iteration:  25281, Training Accuracy:  75.0%, Loss: 0.3970\n",
      "Optimization Iteration:  25345, Training Accuracy:  79.7%, Loss: 0.4153\n",
      "Optimization Iteration:  25409, Training Accuracy:  78.1%, Loss: 0.4200\n",
      "Optimization Iteration:  25473, Training Accuracy:  65.6%, Loss: 0.4816\n",
      "Optimization Iteration:  25537, Training Accuracy:  75.0%, Loss: 0.3827\n",
      "Optimization Iteration:  25601, Training Accuracy:  81.2%, Loss: 0.4242\n",
      "Optimization Iteration:  25665, Training Accuracy:  79.7%, Loss: 0.3805\n",
      "Optimization Iteration:  25729, Training Accuracy:  78.1%, Loss: 0.3826\n",
      "Optimization Iteration:  25793, Training Accuracy:  79.7%, Loss: 0.4002\n",
      "Optimization Iteration:  25857, Training Accuracy:  71.9%, Loss: 0.4304\n",
      "Optimization Iteration:  25921, Training Accuracy:  82.8%, Loss: 0.4703\n",
      "Optimization Iteration:  25985, Training Accuracy:  70.3%, Loss: 0.4974\n",
      "Optimization Iteration:  26049, Training Accuracy:  71.9%, Loss: 0.3997\n",
      "Optimization Iteration:  26113, Training Accuracy:  73.4%, Loss: 0.4245\n",
      "Optimization Iteration:  26177, Training Accuracy:  73.4%, Loss: 0.4168\n",
      "Optimization Iteration:  26241, Training Accuracy:  75.0%, Loss: 0.3494\n",
      "Optimization Iteration:  26305, Training Accuracy:  76.6%, Loss: 0.4353\n",
      "Optimization Iteration:  26369, Training Accuracy:  73.4%, Loss: 0.3869\n",
      "Optimization Iteration:  26433, Training Accuracy:  75.0%, Loss: 0.3880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  26497, Training Accuracy:  87.5%, Loss: 0.3388\n",
      "Optimization Iteration:  26561, Training Accuracy:  71.9%, Loss: 0.3243\n",
      "Optimization Iteration:  26625, Training Accuracy:  78.1%, Loss: 0.3981\n",
      "Optimization Iteration:  26689, Training Accuracy:  76.6%, Loss: 0.4137\n",
      "Optimization Iteration:  26753, Training Accuracy:  70.3%, Loss: 0.4340\n",
      "Optimization Iteration:  26817, Training Accuracy:  67.2%, Loss: 0.4109\n",
      "Optimization Iteration:  26881, Training Accuracy:  82.8%, Loss: 0.3353\n",
      "Optimization Iteration:  26945, Training Accuracy:  73.4%, Loss: 0.4002\n",
      "Optimization Iteration:  27009, Training Accuracy:  79.7%, Loss: 0.3259\n",
      "Optimization Iteration:  27073, Training Accuracy:  75.0%, Loss: 0.4124\n",
      "Optimization Iteration:  27137, Training Accuracy:  84.4%, Loss: 0.3942\n",
      "Optimization Iteration:  27201, Training Accuracy:  71.9%, Loss: 0.4050\n",
      "Optimization Iteration:  27265, Training Accuracy:  79.7%, Loss: 0.4066\n",
      "Optimization Iteration:  27329, Training Accuracy:  78.1%, Loss: 0.3684\n",
      "Optimization Iteration:  27393, Training Accuracy:  71.9%, Loss: 0.4474\n",
      "Optimization Iteration:  27457, Training Accuracy:  73.4%, Loss: 0.4147\n",
      "Optimization Iteration:  27521, Training Accuracy:  81.2%, Loss: 0.3985\n",
      "Optimization Iteration:  27585, Training Accuracy:  68.8%, Loss: 0.4460\n",
      "Optimization Iteration:  27649, Training Accuracy:  75.0%, Loss: 0.3333\n",
      "Optimization Iteration:  27713, Training Accuracy:  75.0%, Loss: 0.4381\n",
      "Optimization Iteration:  27777, Training Accuracy:  73.4%, Loss: 0.3861\n",
      "Optimization Iteration:  27841, Training Accuracy:  71.9%, Loss: 0.4020\n",
      "Optimization Iteration:  27905, Training Accuracy:  79.7%, Loss: 0.3836\n",
      "Optimization Iteration:  27969, Training Accuracy:  68.8%, Loss: 0.4151\n",
      "Optimization Iteration:  28033, Training Accuracy:  78.1%, Loss: 0.3527\n",
      "Optimization Iteration:  28097, Training Accuracy:  73.4%, Loss: 0.4164\n",
      "Optimization Iteration:  28161, Training Accuracy:  82.8%, Loss: 0.3459\n",
      "Optimization Iteration:  28225, Training Accuracy:  75.0%, Loss: 0.3735\n",
      "Optimization Iteration:  28289, Training Accuracy:  73.4%, Loss: 0.3849\n",
      "Optimization Iteration:  28353, Training Accuracy:  75.0%, Loss: 0.3113\n",
      "Optimization Iteration:  28417, Training Accuracy:  73.4%, Loss: 0.3841\n",
      "Optimization Iteration:  28481, Training Accuracy:  76.6%, Loss: 0.4038\n",
      "Optimization Iteration:  28545, Training Accuracy:  78.1%, Loss: 0.3488\n",
      "Optimization Iteration:  28609, Training Accuracy:  81.2%, Loss: 0.3102\n",
      "Optimization Iteration:  28673, Training Accuracy:  78.1%, Loss: 0.5132\n",
      "Optimization Iteration:  28737, Training Accuracy:  78.1%, Loss: 0.3676\n",
      "Optimization Iteration:  28801, Training Accuracy:  85.9%, Loss: 0.3657\n",
      "Optimization Iteration:  28865, Training Accuracy:  78.1%, Loss: 0.3478\n",
      "Optimization Iteration:  28929, Training Accuracy:  85.9%, Loss: 0.3067\n",
      "Optimization Iteration:  28993, Training Accuracy:  76.6%, Loss: 0.4698\n",
      "Optimization Iteration:  29057, Training Accuracy:  71.9%, Loss: 0.4268\n",
      "Optimization Iteration:  29121, Training Accuracy:  76.6%, Loss: 0.4281\n",
      "Optimization Iteration:  29185, Training Accuracy:  79.7%, Loss: 0.3417\n",
      "Optimization Iteration:  29249, Training Accuracy:  75.0%, Loss: 0.4463\n",
      "Optimization Iteration:  29313, Training Accuracy:  78.1%, Loss: 0.4210\n",
      "Optimization Iteration:  29377, Training Accuracy:  85.9%, Loss: 0.2889\n",
      "Optimization Iteration:  29441, Training Accuracy:  75.0%, Loss: 0.4532\n",
      "Optimization Iteration:  29505, Training Accuracy:  84.4%, Loss: 0.3509\n",
      "Optimization Iteration:  29569, Training Accuracy:  75.0%, Loss: 0.3771\n",
      "Optimization Iteration:  29633, Training Accuracy:  67.2%, Loss: 0.4341\n",
      "Optimization Iteration:  29697, Training Accuracy:  78.1%, Loss: 0.3921\n",
      "Optimization Iteration:  29761, Training Accuracy:  79.7%, Loss: 0.4079\n",
      "Optimization Iteration:  29825, Training Accuracy:  73.4%, Loss: 0.4123\n",
      "Optimization Iteration:  29889, Training Accuracy:  75.0%, Loss: 0.4271\n",
      "Optimization Iteration:  29953, Training Accuracy:  71.9%, Loss: 0.4457\n",
      "Optimization Iteration:  30017, Training Accuracy:  82.8%, Loss: 0.3394\n",
      "Optimization Iteration:  30081, Training Accuracy:  81.2%, Loss: 0.3587\n",
      "Optimization Iteration:  30145, Training Accuracy:  71.9%, Loss: 0.4531\n",
      "Optimization Iteration:  30209, Training Accuracy:  71.9%, Loss: 0.4443\n",
      "Optimization Iteration:  30273, Training Accuracy:  73.4%, Loss: 0.4428\n",
      "Optimization Iteration:  30337, Training Accuracy:  82.8%, Loss: 0.3540\n",
      "Optimization Iteration:  30401, Training Accuracy:  79.7%, Loss: 0.4013\n",
      "Optimization Iteration:  30465, Training Accuracy:  73.4%, Loss: 0.4357\n",
      "Optimization Iteration:  30529, Training Accuracy:  76.6%, Loss: 0.3831\n",
      "Optimization Iteration:  30593, Training Accuracy:  81.2%, Loss: 0.3187\n",
      "Optimization Iteration:  30657, Training Accuracy:  81.2%, Loss: 0.3796\n",
      "Optimization Iteration:  30721, Training Accuracy:  70.3%, Loss: 0.3682\n",
      "Optimization Iteration:  30785, Training Accuracy:  70.3%, Loss: 0.4092\n",
      "Optimization Iteration:  30849, Training Accuracy:  71.9%, Loss: 0.3857\n",
      "Optimization Iteration:  30913, Training Accuracy:  84.4%, Loss: 0.3683\n",
      "Optimization Iteration:  30977, Training Accuracy:  70.3%, Loss: 0.4272\n",
      "Optimization Iteration:  31041, Training Accuracy:  81.2%, Loss: 0.3772\n",
      "Optimization Iteration:  31105, Training Accuracy:  75.0%, Loss: 0.4147\n",
      "Optimization Iteration:  31169, Training Accuracy:  70.3%, Loss: 0.3507\n",
      "Optimization Iteration:  31233, Training Accuracy:  76.6%, Loss: 0.4193\n",
      "Optimization Iteration:  31297, Training Accuracy:  73.4%, Loss: 0.3620\n",
      "Optimization Iteration:  31361, Training Accuracy:  76.6%, Loss: 0.3752\n",
      "Optimization Iteration:  31425, Training Accuracy:  78.1%, Loss: 0.3329\n",
      "Optimization Iteration:  31489, Training Accuracy:  81.2%, Loss: 0.3489\n",
      "Optimization Iteration:  31553, Training Accuracy:  78.1%, Loss: 0.3914\n",
      "Optimization Iteration:  31617, Training Accuracy:  71.9%, Loss: 0.3414\n",
      "Optimization Iteration:  31681, Training Accuracy:  78.1%, Loss: 0.3750\n",
      "Optimization Iteration:  31745, Training Accuracy:  81.2%, Loss: 0.3220\n",
      "Optimization Iteration:  31809, Training Accuracy:  71.9%, Loss: 0.5210\n",
      "Optimization Iteration:  31873, Training Accuracy:  81.2%, Loss: 0.3235\n",
      "Optimization Iteration:  31937, Training Accuracy:  73.4%, Loss: 0.4802\n",
      "Optimization Iteration:  32001, Training Accuracy:  78.1%, Loss: 0.4247\n",
      "Optimization Iteration:  32065, Training Accuracy:  71.9%, Loss: 0.3993\n",
      "Optimization Iteration:  32129, Training Accuracy:  70.3%, Loss: 0.4194\n",
      "Optimization Iteration:  32193, Training Accuracy:  65.6%, Loss: 0.4154\n",
      "Optimization Iteration:  32257, Training Accuracy:  75.0%, Loss: 0.3925\n",
      "Optimization Iteration:  32321, Training Accuracy:  70.3%, Loss: 0.3964\n",
      "Optimization Iteration:  32385, Training Accuracy:  82.8%, Loss: 0.3738\n",
      "Optimization Iteration:  32449, Training Accuracy:  68.8%, Loss: 0.4515\n",
      "Optimization Iteration:  32513, Training Accuracy:  76.6%, Loss: 0.3757\n",
      "Optimization Iteration:  32577, Training Accuracy:  79.7%, Loss: 0.3798\n",
      "Optimization Iteration:  32641, Training Accuracy:  84.4%, Loss: 0.3811\n",
      "Optimization Iteration:  32705, Training Accuracy:  73.4%, Loss: 0.4242\n",
      "Optimization Iteration:  32769, Training Accuracy:  75.0%, Loss: 0.4090\n",
      "Optimization Iteration:  32833, Training Accuracy:  76.6%, Loss: 0.3917\n",
      "Optimization Iteration:  32897, Training Accuracy:  71.9%, Loss: 0.4690\n",
      "Optimization Iteration:  32961, Training Accuracy:  76.6%, Loss: 0.3922\n",
      "Optimization Iteration:  33025, Training Accuracy:  70.3%, Loss: 0.4096\n",
      "Optimization Iteration:  33089, Training Accuracy:  75.0%, Loss: 0.4564\n",
      "Optimization Iteration:  33153, Training Accuracy:  73.4%, Loss: 0.4325\n",
      "Optimization Iteration:  33217, Training Accuracy:  70.3%, Loss: 0.3886\n",
      "Optimization Iteration:  33281, Training Accuracy:  68.8%, Loss: 0.5064\n",
      "Optimization Iteration:  33345, Training Accuracy:  71.9%, Loss: 0.4364\n",
      "Optimization Iteration:  33409, Training Accuracy:  78.1%, Loss: 0.4508\n",
      "Optimization Iteration:  33473, Training Accuracy:  82.8%, Loss: 0.3435\n",
      "Optimization Iteration:  33537, Training Accuracy:  65.6%, Loss: 0.5029\n",
      "Optimization Iteration:  33601, Training Accuracy:  70.3%, Loss: 0.5112\n",
      "Optimization Iteration:  33665, Training Accuracy:  75.0%, Loss: 0.4309\n",
      "Optimization Iteration:  33729, Training Accuracy:  75.0%, Loss: 0.4081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  33793, Training Accuracy:  71.9%, Loss: 0.4764\n",
      "Optimization Iteration:  33857, Training Accuracy:  78.1%, Loss: 0.3610\n",
      "Optimization Iteration:  33921, Training Accuracy:  75.0%, Loss: 0.3923\n",
      "Optimization Iteration:  33985, Training Accuracy:  82.8%, Loss: 0.4045\n",
      "Optimization Iteration:  34049, Training Accuracy:  75.0%, Loss: 0.4442\n",
      "Optimization Iteration:  34113, Training Accuracy:  85.9%, Loss: 0.3377\n",
      "Optimization Iteration:  34177, Training Accuracy:  75.0%, Loss: 0.3609\n",
      "Optimization Iteration:  34241, Training Accuracy:  70.3%, Loss: 0.4224\n",
      "Optimization Iteration:  34305, Training Accuracy:  75.0%, Loss: 0.4105\n",
      "Optimization Iteration:  34369, Training Accuracy:  76.6%, Loss: 0.3875\n",
      "Optimization Iteration:  34433, Training Accuracy:  75.0%, Loss: 0.4751\n",
      "Optimization Iteration:  34497, Training Accuracy:  81.2%, Loss: 0.3395\n",
      "Optimization Iteration:  34561, Training Accuracy:  79.7%, Loss: 0.3673\n",
      "Optimization Iteration:  34625, Training Accuracy:  75.0%, Loss: 0.4165\n",
      "Optimization Iteration:  34689, Training Accuracy:  78.1%, Loss: 0.4083\n",
      "Optimization Iteration:  34753, Training Accuracy:  75.0%, Loss: 0.4689\n",
      "Optimization Iteration:  34817, Training Accuracy:  79.7%, Loss: 0.3891\n",
      "Optimization Iteration:  34881, Training Accuracy:  70.3%, Loss: 0.3692\n",
      "Optimization Iteration:  34945, Training Accuracy:  79.7%, Loss: 0.3918\n",
      "Optimization Iteration:  35009, Training Accuracy:  76.6%, Loss: 0.4651\n",
      "Optimization Iteration:  35073, Training Accuracy:  78.1%, Loss: 0.3227\n",
      "Optimization Iteration:  35137, Training Accuracy:  78.1%, Loss: 0.3558\n",
      "Optimization Iteration:  35201, Training Accuracy:  79.7%, Loss: 0.3738\n",
      "Optimization Iteration:  35265, Training Accuracy:  78.1%, Loss: 0.3510\n",
      "Optimization Iteration:  35329, Training Accuracy:  76.6%, Loss: 0.4560\n",
      "Optimization Iteration:  35393, Training Accuracy:  67.2%, Loss: 0.3917\n",
      "Optimization Iteration:  35457, Training Accuracy:  81.2%, Loss: 0.3711\n",
      "Optimization Iteration:  35521, Training Accuracy:  75.0%, Loss: 0.4067\n",
      "Optimization Iteration:  35585, Training Accuracy:  89.1%, Loss: 0.3150\n",
      "Optimization Iteration:  35649, Training Accuracy:  71.9%, Loss: 0.4812\n",
      "Optimization Iteration:  35713, Training Accuracy:  75.0%, Loss: 0.4251\n",
      "Optimization Iteration:  35777, Training Accuracy:  78.1%, Loss: 0.3016\n",
      "Optimization Iteration:  35841, Training Accuracy:  75.0%, Loss: 0.3896\n",
      "Optimization Iteration:  35905, Training Accuracy:  76.6%, Loss: 0.3763\n",
      "Optimization Iteration:  35969, Training Accuracy:  71.9%, Loss: 0.4201\n",
      "Optimization Iteration:  36033, Training Accuracy:  76.6%, Loss: 0.3551\n",
      "Optimization Iteration:  36097, Training Accuracy:  68.8%, Loss: 0.4929\n",
      "Optimization Iteration:  36161, Training Accuracy:  67.2%, Loss: 0.4517\n",
      "Optimization Iteration:  36225, Training Accuracy:  81.2%, Loss: 0.3889\n",
      "Optimization Iteration:  36289, Training Accuracy:  76.6%, Loss: 0.3740\n",
      "Optimization Iteration:  36353, Training Accuracy:  75.0%, Loss: 0.3946\n",
      "Optimization Iteration:  36417, Training Accuracy:  68.8%, Loss: 0.5230\n",
      "Optimization Iteration:  36481, Training Accuracy:  68.8%, Loss: 0.4277\n",
      "Optimization Iteration:  36545, Training Accuracy:  76.6%, Loss: 0.3559\n",
      "Optimization Iteration:  36609, Training Accuracy:  76.6%, Loss: 0.3964\n",
      "Optimization Iteration:  36673, Training Accuracy:  71.9%, Loss: 0.4208\n",
      "Optimization Iteration:  36737, Training Accuracy:  76.6%, Loss: 0.4073\n",
      "Optimization Iteration:  36801, Training Accuracy:  75.0%, Loss: 0.4256\n",
      "Optimization Iteration:  36865, Training Accuracy:  71.9%, Loss: 0.4105\n",
      "Optimization Iteration:  36929, Training Accuracy:  76.6%, Loss: 0.3698\n",
      "Optimization Iteration:  36993, Training Accuracy:  73.4%, Loss: 0.4269\n",
      "Optimization Iteration:  37057, Training Accuracy:  89.1%, Loss: 0.2943\n",
      "Optimization Iteration:  37121, Training Accuracy:  78.1%, Loss: 0.3494\n",
      "Optimization Iteration:  37185, Training Accuracy:  85.9%, Loss: 0.3165\n",
      "Optimization Iteration:  37249, Training Accuracy:  73.4%, Loss: 0.4539\n",
      "Optimization Iteration:  37313, Training Accuracy:  81.2%, Loss: 0.3307\n",
      "Optimization Iteration:  37377, Training Accuracy:  64.1%, Loss: 0.5786\n",
      "Optimization Iteration:  37441, Training Accuracy:  76.6%, Loss: 0.3664\n",
      "Optimization Iteration:  37505, Training Accuracy:  76.6%, Loss: 0.4058\n",
      "Optimization Iteration:  37569, Training Accuracy:  75.0%, Loss: 0.4692\n",
      "Optimization Iteration:  37633, Training Accuracy:  71.9%, Loss: 0.4448\n",
      "Optimization Iteration:  37697, Training Accuracy:  76.6%, Loss: 0.3484\n",
      "Optimization Iteration:  37761, Training Accuracy:  79.7%, Loss: 0.3157\n",
      "Optimization Iteration:  37825, Training Accuracy:  73.4%, Loss: 0.4472\n",
      "Optimization Iteration:  37889, Training Accuracy:  75.0%, Loss: 0.3736\n",
      "Optimization Iteration:  37953, Training Accuracy:  78.1%, Loss: 0.3358\n",
      "Optimization Iteration:  38017, Training Accuracy:  73.4%, Loss: 0.4031\n",
      "Optimization Iteration:  38081, Training Accuracy:  75.0%, Loss: 0.3507\n",
      "Optimization Iteration:  38145, Training Accuracy:  79.7%, Loss: 0.3126\n",
      "Optimization Iteration:  38209, Training Accuracy:  81.2%, Loss: 0.4144\n",
      "Optimization Iteration:  38273, Training Accuracy:  71.9%, Loss: 0.3660\n",
      "Optimization Iteration:  38337, Training Accuracy:  79.7%, Loss: 0.3176\n",
      "Optimization Iteration:  38401, Training Accuracy:  76.6%, Loss: 0.4100\n",
      "Optimization Iteration:  38465, Training Accuracy:  73.4%, Loss: 0.4082\n",
      "Optimization Iteration:  38529, Training Accuracy:  84.4%, Loss: 0.3572\n",
      "Optimization Iteration:  38593, Training Accuracy:  76.6%, Loss: 0.4665\n",
      "Optimization Iteration:  38657, Training Accuracy:  71.9%, Loss: 0.4206\n",
      "Optimization Iteration:  38721, Training Accuracy:  73.4%, Loss: 0.3731\n",
      "Optimization Iteration:  38785, Training Accuracy:  76.6%, Loss: 0.4324\n",
      "Optimization Iteration:  38849, Training Accuracy:  85.9%, Loss: 0.2775\n",
      "Optimization Iteration:  38913, Training Accuracy:  75.0%, Loss: 0.4098\n",
      "Optimization Iteration:  38977, Training Accuracy:  78.1%, Loss: 0.3994\n",
      "Optimization Iteration:  39041, Training Accuracy:  65.6%, Loss: 0.4459\n",
      "Optimization Iteration:  39105, Training Accuracy:  70.3%, Loss: 0.4900\n",
      "Optimization Iteration:  39169, Training Accuracy:  70.3%, Loss: 0.4495\n",
      "Optimization Iteration:  39233, Training Accuracy:  70.3%, Loss: 0.4323\n",
      "Optimization Iteration:  39297, Training Accuracy:  75.0%, Loss: 0.4278\n",
      "Optimization Iteration:  39361, Training Accuracy:  81.2%, Loss: 0.3741\n",
      "Optimization Iteration:  39425, Training Accuracy:  78.1%, Loss: 0.3813\n",
      "Optimization Iteration:  39489, Training Accuracy:  82.8%, Loss: 0.2958\n",
      "Optimization Iteration:  39553, Training Accuracy:  75.0%, Loss: 0.3894\n",
      "Optimization Iteration:  39617, Training Accuracy:  73.4%, Loss: 0.4233\n",
      "Optimization Iteration:  39681, Training Accuracy:  68.8%, Loss: 0.3916\n",
      "Optimization Iteration:  39745, Training Accuracy:  75.0%, Loss: 0.4773\n",
      "Optimization Iteration:  39809, Training Accuracy:  76.6%, Loss: 0.3773\n",
      "Optimization Iteration:  39873, Training Accuracy:  67.2%, Loss: 0.4507\n",
      "Optimization Iteration:  39937, Training Accuracy:  71.9%, Loss: 0.4964\n",
      "Optimization Iteration:  40001, Training Accuracy:  76.6%, Loss: 0.3864\n",
      "Optimization Iteration:  40065, Training Accuracy:  75.0%, Loss: 0.3587\n",
      "Optimization Iteration:  40129, Training Accuracy:  71.9%, Loss: 0.4459\n",
      "Optimization Iteration:  40193, Training Accuracy:  85.9%, Loss: 0.3238\n",
      "Optimization Iteration:  40257, Training Accuracy:  70.3%, Loss: 0.4127\n",
      "Optimization Iteration:  40321, Training Accuracy:  75.0%, Loss: 0.4459\n",
      "Optimization Iteration:  40385, Training Accuracy:  76.6%, Loss: 0.3780\n",
      "Optimization Iteration:  40449, Training Accuracy:  78.1%, Loss: 0.3545\n",
      "Optimization Iteration:  40513, Training Accuracy:  82.8%, Loss: 0.3761\n",
      "Optimization Iteration:  40577, Training Accuracy:  73.4%, Loss: 0.4002\n",
      "Optimization Iteration:  40641, Training Accuracy:  78.1%, Loss: 0.3636\n",
      "Optimization Iteration:  40705, Training Accuracy:  71.9%, Loss: 0.3817\n",
      "Optimization Iteration:  40769, Training Accuracy:  85.9%, Loss: 0.3479\n",
      "Optimization Iteration:  40833, Training Accuracy:  78.1%, Loss: 0.3382\n",
      "Optimization Iteration:  40897, Training Accuracy:  84.4%, Loss: 0.4048\n",
      "Optimization Iteration:  40961, Training Accuracy:  87.5%, Loss: 0.3265\n",
      "Optimization Iteration:  41025, Training Accuracy:  81.2%, Loss: 0.3753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  41089, Training Accuracy:  81.2%, Loss: 0.4248\n",
      "Optimization Iteration:  41153, Training Accuracy:  75.0%, Loss: 0.3821\n",
      "Optimization Iteration:  41217, Training Accuracy:  84.4%, Loss: 0.3648\n",
      "Optimization Iteration:  41281, Training Accuracy:  70.3%, Loss: 0.4242\n",
      "Optimization Iteration:  41345, Training Accuracy:  73.4%, Loss: 0.4020\n",
      "Optimization Iteration:  41409, Training Accuracy:  75.0%, Loss: 0.4113\n",
      "Optimization Iteration:  41473, Training Accuracy:  70.3%, Loss: 0.4552\n",
      "Optimization Iteration:  41537, Training Accuracy:  79.7%, Loss: 0.3934\n",
      "Optimization Iteration:  41601, Training Accuracy:  76.6%, Loss: 0.4092\n",
      "Optimization Iteration:  41665, Training Accuracy:  71.9%, Loss: 0.3549\n",
      "Optimization Iteration:  41729, Training Accuracy:  84.4%, Loss: 0.3596\n",
      "Optimization Iteration:  41793, Training Accuracy:  79.7%, Loss: 0.3349\n",
      "Optimization Iteration:  41857, Training Accuracy:  75.0%, Loss: 0.4467\n",
      "Optimization Iteration:  41921, Training Accuracy:  73.4%, Loss: 0.3321\n",
      "Optimization Iteration:  41985, Training Accuracy:  71.9%, Loss: 0.4739\n",
      "Optimization Iteration:  42049, Training Accuracy:  67.2%, Loss: 0.4063\n",
      "Optimization Iteration:  42113, Training Accuracy:  71.9%, Loss: 0.3771\n",
      "Optimization Iteration:  42177, Training Accuracy:  75.0%, Loss: 0.4157\n",
      "Optimization Iteration:  42241, Training Accuracy:  78.1%, Loss: 0.3955\n",
      "Optimization Iteration:  42305, Training Accuracy:  68.8%, Loss: 0.5268\n",
      "Optimization Iteration:  42369, Training Accuracy:  76.6%, Loss: 0.3771\n",
      "Optimization Iteration:  42433, Training Accuracy:  79.7%, Loss: 0.4204\n",
      "Optimization Iteration:  42497, Training Accuracy:  73.4%, Loss: 0.4288\n",
      "Optimization Iteration:  42561, Training Accuracy:  73.4%, Loss: 0.3727\n",
      "Optimization Iteration:  42625, Training Accuracy:  78.1%, Loss: 0.3653\n",
      "Optimization Iteration:  42689, Training Accuracy:  68.8%, Loss: 0.3897\n",
      "Optimization Iteration:  42753, Training Accuracy:  73.4%, Loss: 0.4400\n",
      "Optimization Iteration:  42817, Training Accuracy:  85.9%, Loss: 0.3254\n",
      "Optimization Iteration:  42881, Training Accuracy:  76.6%, Loss: 0.4133\n",
      "Optimization Iteration:  42945, Training Accuracy:  75.0%, Loss: 0.3824\n",
      "Optimization Iteration:  43009, Training Accuracy:  73.4%, Loss: 0.4519\n",
      "Optimization Iteration:  43073, Training Accuracy:  82.8%, Loss: 0.3314\n",
      "Optimization Iteration:  43137, Training Accuracy:  82.8%, Loss: 0.3517\n",
      "Optimization Iteration:  43201, Training Accuracy:  76.6%, Loss: 0.3869\n",
      "Optimization Iteration:  43265, Training Accuracy:  76.6%, Loss: 0.3625\n",
      "Optimization Iteration:  43329, Training Accuracy:  84.4%, Loss: 0.3208\n",
      "Optimization Iteration:  43393, Training Accuracy:  70.3%, Loss: 0.3905\n",
      "Optimization Iteration:  43457, Training Accuracy:  78.1%, Loss: 0.3241\n",
      "Optimization Iteration:  43521, Training Accuracy:  75.0%, Loss: 0.4458\n",
      "Optimization Iteration:  43585, Training Accuracy:  76.6%, Loss: 0.3614\n",
      "Optimization Iteration:  43649, Training Accuracy:  71.9%, Loss: 0.4231\n",
      "Optimization Iteration:  43713, Training Accuracy:  89.1%, Loss: 0.3684\n",
      "Optimization Iteration:  43777, Training Accuracy:  90.6%, Loss: 0.2567\n",
      "Optimization Iteration:  43841, Training Accuracy:  82.8%, Loss: 0.3965\n",
      "Optimization Iteration:  43905, Training Accuracy:  82.8%, Loss: 0.3604\n",
      "Optimization Iteration:  43969, Training Accuracy:  79.7%, Loss: 0.3285\n",
      "Optimization Iteration:  44033, Training Accuracy:  82.8%, Loss: 0.3716\n",
      "Optimization Iteration:  44097, Training Accuracy:  78.1%, Loss: 0.3288\n",
      "Optimization Iteration:  44161, Training Accuracy:  79.7%, Loss: 0.3111\n",
      "Optimization Iteration:  44225, Training Accuracy:  75.0%, Loss: 0.4179\n",
      "Optimization Iteration:  44289, Training Accuracy:  70.3%, Loss: 0.4485\n",
      "Optimization Iteration:  44353, Training Accuracy:  65.6%, Loss: 0.4988\n",
      "Optimization Iteration:  44417, Training Accuracy:  75.0%, Loss: 0.3551\n",
      "Optimization Iteration:  44481, Training Accuracy:  76.6%, Loss: 0.4171\n",
      "Optimization Iteration:  44545, Training Accuracy:  79.7%, Loss: 0.3601\n",
      "Optimization Iteration:  44609, Training Accuracy:  79.7%, Loss: 0.3538\n",
      "Optimization Iteration:  44673, Training Accuracy:  67.2%, Loss: 0.4662\n",
      "Optimization Iteration:  44737, Training Accuracy:  75.0%, Loss: 0.4101\n",
      "Optimization Iteration:  44801, Training Accuracy:  78.1%, Loss: 0.4412\n",
      "Optimization Iteration:  44865, Training Accuracy:  76.6%, Loss: 0.3655\n",
      "Optimization Iteration:  44929, Training Accuracy:  81.2%, Loss: 0.3746\n",
      "Optimization Iteration:  44993, Training Accuracy:  73.4%, Loss: 0.3669\n",
      "Optimization Iteration:  45057, Training Accuracy:  71.9%, Loss: 0.4351\n",
      "Optimization Iteration:  45121, Training Accuracy:  82.8%, Loss: 0.3510\n",
      "Optimization Iteration:  45185, Training Accuracy:  81.2%, Loss: 0.3509\n",
      "Optimization Iteration:  45249, Training Accuracy:  76.6%, Loss: 0.4367\n",
      "Optimization Iteration:  45313, Training Accuracy:  81.2%, Loss: 0.3700\n",
      "Optimization Iteration:  45377, Training Accuracy:  76.6%, Loss: 0.4469\n",
      "Optimization Iteration:  45441, Training Accuracy:  82.8%, Loss: 0.3754\n",
      "Optimization Iteration:  45505, Training Accuracy:  79.7%, Loss: 0.3858\n",
      "Optimization Iteration:  45569, Training Accuracy:  71.9%, Loss: 0.4535\n",
      "Optimization Iteration:  45633, Training Accuracy:  75.0%, Loss: 0.4755\n",
      "Optimization Iteration:  45697, Training Accuracy:  76.6%, Loss: 0.3695\n",
      "Optimization Iteration:  45761, Training Accuracy:  92.2%, Loss: 0.3054\n",
      "Optimization Iteration:  45825, Training Accuracy:  73.4%, Loss: 0.3823\n",
      "Optimization Iteration:  45889, Training Accuracy:  71.9%, Loss: 0.3948\n",
      "Optimization Iteration:  45953, Training Accuracy:  78.1%, Loss: 0.3286\n",
      "Optimization Iteration:  46017, Training Accuracy:  71.9%, Loss: 0.4551\n",
      "Optimization Iteration:  46081, Training Accuracy:  75.0%, Loss: 0.3620\n",
      "Optimization Iteration:  46145, Training Accuracy:  65.6%, Loss: 0.4207\n",
      "Optimization Iteration:  46209, Training Accuracy:  75.0%, Loss: 0.3916\n",
      "Optimization Iteration:  46273, Training Accuracy:  73.4%, Loss: 0.4189\n",
      "Optimization Iteration:  46337, Training Accuracy:  82.8%, Loss: 0.3866\n",
      "Optimization Iteration:  46401, Training Accuracy:  81.2%, Loss: 0.3384\n",
      "Optimization Iteration:  46465, Training Accuracy:  75.0%, Loss: 0.4376\n",
      "Optimization Iteration:  46529, Training Accuracy:  76.6%, Loss: 0.4095\n",
      "Optimization Iteration:  46593, Training Accuracy:  73.4%, Loss: 0.3982\n",
      "Optimization Iteration:  46657, Training Accuracy:  70.3%, Loss: 0.4158\n",
      "Optimization Iteration:  46721, Training Accuracy:  75.0%, Loss: 0.4224\n",
      "Optimization Iteration:  46785, Training Accuracy:  76.6%, Loss: 0.4415\n",
      "Optimization Iteration:  46849, Training Accuracy:  76.6%, Loss: 0.3788\n",
      "Optimization Iteration:  46913, Training Accuracy:  81.2%, Loss: 0.3246\n",
      "Optimization Iteration:  46977, Training Accuracy:  81.2%, Loss: 0.3928\n",
      "Optimization Iteration:  47041, Training Accuracy:  76.6%, Loss: 0.3575\n",
      "Optimization Iteration:  47105, Training Accuracy:  78.1%, Loss: 0.4832\n",
      "Optimization Iteration:  47169, Training Accuracy:  73.4%, Loss: 0.4142\n",
      "Optimization Iteration:  47233, Training Accuracy:  76.6%, Loss: 0.3994\n",
      "Optimization Iteration:  47297, Training Accuracy:  71.9%, Loss: 0.4061\n",
      "Optimization Iteration:  47361, Training Accuracy:  85.9%, Loss: 0.3256\n",
      "Optimization Iteration:  47425, Training Accuracy:  82.8%, Loss: 0.3526\n",
      "Optimization Iteration:  47489, Training Accuracy:  65.6%, Loss: 0.4832\n",
      "Optimization Iteration:  47553, Training Accuracy:  78.1%, Loss: 0.3739\n",
      "Optimization Iteration:  47617, Training Accuracy:  76.6%, Loss: 0.4572\n",
      "Optimization Iteration:  47681, Training Accuracy:  76.6%, Loss: 0.3491\n",
      "Optimization Iteration:  47745, Training Accuracy:  73.4%, Loss: 0.4381\n",
      "Optimization Iteration:  47809, Training Accuracy:  79.7%, Loss: 0.3770\n",
      "Optimization Iteration:  47873, Training Accuracy:  87.5%, Loss: 0.2865\n",
      "Optimization Iteration:  47937, Training Accuracy:  73.4%, Loss: 0.3546\n",
      "Optimization Iteration:  48001, Training Accuracy:  79.7%, Loss: 0.3679\n",
      "Optimization Iteration:  48065, Training Accuracy:  79.7%, Loss: 0.3601\n",
      "Optimization Iteration:  48129, Training Accuracy:  75.0%, Loss: 0.4465\n",
      "Optimization Iteration:  48193, Training Accuracy:  73.4%, Loss: 0.4527\n",
      "Optimization Iteration:  48257, Training Accuracy:  75.0%, Loss: 0.4067\n",
      "Optimization Iteration:  48321, Training Accuracy:  79.7%, Loss: 0.3197\n",
      "Optimization Iteration:  48385, Training Accuracy:  67.2%, Loss: 0.3769\n",
      "Optimization Iteration:  48449, Training Accuracy:  76.6%, Loss: 0.3800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  48513, Training Accuracy:  73.4%, Loss: 0.4139\n",
      "Optimization Iteration:  48577, Training Accuracy:  64.1%, Loss: 0.4958\n",
      "Optimization Iteration:  48641, Training Accuracy:  81.2%, Loss: 0.3799\n",
      "Optimization Iteration:  48705, Training Accuracy:  87.5%, Loss: 0.2969\n",
      "Optimization Iteration:  48769, Training Accuracy:  87.5%, Loss: 0.2997\n",
      "Optimization Iteration:  48833, Training Accuracy:  76.6%, Loss: 0.3432\n",
      "Optimization Iteration:  48897, Training Accuracy:  76.6%, Loss: 0.4305\n",
      "Optimization Iteration:  48961, Training Accuracy:  78.1%, Loss: 0.4484\n",
      "Optimization Iteration:  49025, Training Accuracy:  70.3%, Loss: 0.4499\n",
      "Optimization Iteration:  49089, Training Accuracy:  75.0%, Loss: 0.3469\n",
      "Optimization Iteration:  49153, Training Accuracy:  75.0%, Loss: 0.4347\n",
      "Optimization Iteration:  49217, Training Accuracy:  76.6%, Loss: 0.4223\n",
      "Optimization Iteration:  49281, Training Accuracy:  73.4%, Loss: 0.3574\n",
      "Optimization Iteration:  49345, Training Accuracy:  67.2%, Loss: 0.3929\n",
      "Optimization Iteration:  49409, Training Accuracy:  75.0%, Loss: 0.3761\n",
      "Optimization Iteration:  49473, Training Accuracy:  82.8%, Loss: 0.3989\n",
      "Optimization Iteration:  49537, Training Accuracy:  79.7%, Loss: 0.3414\n",
      "Optimization Iteration:  49601, Training Accuracy:  78.1%, Loss: 0.4473\n",
      "Optimization Iteration:  49665, Training Accuracy:  84.4%, Loss: 0.2969\n",
      "Optimization Iteration:  49729, Training Accuracy:  71.9%, Loss: 0.3925\n",
      "Optimization Iteration:  49793, Training Accuracy:  73.4%, Loss: 0.3543\n",
      "Optimization Iteration:  49857, Training Accuracy:  75.0%, Loss: 0.4505\n",
      "Optimization Iteration:  49921, Training Accuracy:  79.7%, Loss: 0.4209\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 21\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  71.9%, Loss: 0.4782\n",
      "Optimization Iteration:    129, Training Accuracy:  78.1%, Loss: 0.4169\n",
      "Optimization Iteration:    193, Training Accuracy:  70.3%, Loss: 0.4357\n",
      "Optimization Iteration:    257, Training Accuracy:  71.9%, Loss: 0.3415\n",
      "Optimization Iteration:    321, Training Accuracy:  78.1%, Loss: 0.4257\n",
      "Optimization Iteration:    385, Training Accuracy:  79.7%, Loss: 0.3618\n",
      "Optimization Iteration:    449, Training Accuracy:  82.8%, Loss: 0.3179\n",
      "Optimization Iteration:    513, Training Accuracy:  76.6%, Loss: 0.4064\n",
      "Optimization Iteration:    577, Training Accuracy:  65.6%, Loss: 0.4457\n",
      "Optimization Iteration:    641, Training Accuracy:  78.1%, Loss: 0.4013\n",
      "Optimization Iteration:    705, Training Accuracy:  70.3%, Loss: 0.4217\n",
      "Optimization Iteration:    769, Training Accuracy:  81.2%, Loss: 0.3889\n",
      "Optimization Iteration:    833, Training Accuracy:  78.1%, Loss: 0.4167\n",
      "Optimization Iteration:    897, Training Accuracy:  76.6%, Loss: 0.2967\n",
      "Optimization Iteration:    961, Training Accuracy:  81.2%, Loss: 0.2910\n",
      "Optimization Iteration:   1025, Training Accuracy:  81.2%, Loss: 0.3424\n",
      "Optimization Iteration:   1089, Training Accuracy:  68.8%, Loss: 0.4172\n",
      "Optimization Iteration:   1153, Training Accuracy:  75.0%, Loss: 0.4412\n",
      "Optimization Iteration:   1217, Training Accuracy:  71.9%, Loss: 0.3932\n",
      "Optimization Iteration:   1281, Training Accuracy:  81.2%, Loss: 0.3603\n",
      "Optimization Iteration:   1345, Training Accuracy:  78.1%, Loss: 0.3978\n",
      "Optimization Iteration:   1409, Training Accuracy:  79.7%, Loss: 0.3693\n",
      "Optimization Iteration:   1473, Training Accuracy:  73.4%, Loss: 0.4427\n",
      "Optimization Iteration:   1537, Training Accuracy:  84.4%, Loss: 0.3267\n",
      "Optimization Iteration:   1601, Training Accuracy:  81.2%, Loss: 0.3295\n",
      "Optimization Iteration:   1665, Training Accuracy:  68.8%, Loss: 0.3866\n",
      "Optimization Iteration:   1729, Training Accuracy:  73.4%, Loss: 0.3683\n",
      "Optimization Iteration:   1793, Training Accuracy:  81.2%, Loss: 0.4203\n",
      "Optimization Iteration:   1857, Training Accuracy:  78.1%, Loss: 0.4404\n",
      "Optimization Iteration:   1921, Training Accuracy:  81.2%, Loss: 0.4060\n",
      "Optimization Iteration:   1985, Training Accuracy:  70.3%, Loss: 0.4133\n",
      "Optimization Iteration:   2049, Training Accuracy:  84.4%, Loss: 0.3204\n",
      "Optimization Iteration:   2113, Training Accuracy:  79.7%, Loss: 0.3996\n",
      "Optimization Iteration:   2177, Training Accuracy:  70.3%, Loss: 0.4100\n",
      "Optimization Iteration:   2241, Training Accuracy:  84.4%, Loss: 0.3428\n",
      "Optimization Iteration:   2305, Training Accuracy:  67.2%, Loss: 0.4580\n",
      "Optimization Iteration:   2369, Training Accuracy:  71.9%, Loss: 0.4372\n",
      "Optimization Iteration:   2433, Training Accuracy:  76.6%, Loss: 0.3966\n",
      "Optimization Iteration:   2497, Training Accuracy:  81.2%, Loss: 0.3224\n",
      "Optimization Iteration:   2561, Training Accuracy:  73.4%, Loss: 0.3667\n",
      "Optimization Iteration:   2625, Training Accuracy:  76.6%, Loss: 0.3949\n",
      "Optimization Iteration:   2689, Training Accuracy:  73.4%, Loss: 0.3889\n",
      "Optimization Iteration:   2753, Training Accuracy:  79.7%, Loss: 0.3594\n",
      "Optimization Iteration:   2817, Training Accuracy:  79.7%, Loss: 0.3325\n",
      "Optimization Iteration:   2881, Training Accuracy:  68.8%, Loss: 0.4233\n",
      "Optimization Iteration:   2945, Training Accuracy:  64.1%, Loss: 0.4989\n",
      "Optimization Iteration:   3009, Training Accuracy:  78.1%, Loss: 0.4015\n",
      "Optimization Iteration:   3073, Training Accuracy:  70.3%, Loss: 0.4674\n",
      "Optimization Iteration:   3137, Training Accuracy:  84.4%, Loss: 0.2956\n",
      "Optimization Iteration:   3201, Training Accuracy:  78.1%, Loss: 0.3763\n",
      "Optimization Iteration:   3265, Training Accuracy:  79.7%, Loss: 0.3785\n",
      "Optimization Iteration:   3329, Training Accuracy:  75.0%, Loss: 0.4239\n",
      "Optimization Iteration:   3393, Training Accuracy:  78.1%, Loss: 0.3682\n",
      "Optimization Iteration:   3457, Training Accuracy:  78.1%, Loss: 0.4316\n",
      "Optimization Iteration:   3521, Training Accuracy:  70.3%, Loss: 0.4856\n",
      "Optimization Iteration:   3585, Training Accuracy:  75.0%, Loss: 0.4152\n",
      "Optimization Iteration:   3649, Training Accuracy:  78.1%, Loss: 0.3961\n",
      "Optimization Iteration:   3713, Training Accuracy:  64.1%, Loss: 0.4278\n",
      "Optimization Iteration:   3777, Training Accuracy:  64.1%, Loss: 0.4780\n",
      "Optimization Iteration:   3841, Training Accuracy:  78.1%, Loss: 0.4085\n",
      "Optimization Iteration:   3905, Training Accuracy:  81.2%, Loss: 0.3933\n",
      "Optimization Iteration:   3969, Training Accuracy:  76.6%, Loss: 0.4094\n",
      "Optimization Iteration:   4033, Training Accuracy:  82.8%, Loss: 0.3114\n",
      "Optimization Iteration:   4097, Training Accuracy:  71.9%, Loss: 0.3597\n",
      "Optimization Iteration:   4161, Training Accuracy:  67.2%, Loss: 0.4802\n",
      "Optimization Iteration:   4225, Training Accuracy:  70.3%, Loss: 0.4072\n",
      "Optimization Iteration:   4289, Training Accuracy:  84.4%, Loss: 0.3797\n",
      "Optimization Iteration:   4353, Training Accuracy:  75.0%, Loss: 0.4270\n",
      "Optimization Iteration:   4417, Training Accuracy:  75.0%, Loss: 0.4032\n",
      "Optimization Iteration:   4481, Training Accuracy:  78.1%, Loss: 0.3712\n",
      "Optimization Iteration:   4545, Training Accuracy:  75.0%, Loss: 0.4079\n",
      "Optimization Iteration:   4609, Training Accuracy:  76.6%, Loss: 0.4045\n",
      "Optimization Iteration:   4673, Training Accuracy:  79.7%, Loss: 0.4072\n",
      "Optimization Iteration:   4737, Training Accuracy:  67.2%, Loss: 0.3888\n",
      "Optimization Iteration:   4801, Training Accuracy:  75.0%, Loss: 0.4356\n",
      "Optimization Iteration:   4865, Training Accuracy:  70.3%, Loss: 0.4154\n",
      "Optimization Iteration:   4929, Training Accuracy:  75.0%, Loss: 0.3930\n",
      "Optimization Iteration:   4993, Training Accuracy:  78.1%, Loss: 0.3661\n",
      "Optimization Iteration:   5057, Training Accuracy:  68.8%, Loss: 0.4399\n",
      "Optimization Iteration:   5121, Training Accuracy:  76.6%, Loss: 0.3772\n",
      "Optimization Iteration:   5185, Training Accuracy:  78.1%, Loss: 0.4056\n",
      "Optimization Iteration:   5249, Training Accuracy:  59.4%, Loss: 0.4903\n",
      "Optimization Iteration:   5313, Training Accuracy:  82.8%, Loss: 0.4128\n",
      "Optimization Iteration:   5377, Training Accuracy:  73.4%, Loss: 0.3853\n",
      "Optimization Iteration:   5441, Training Accuracy:  67.2%, Loss: 0.4563\n",
      "Optimization Iteration:   5505, Training Accuracy:  76.6%, Loss: 0.3916\n",
      "Optimization Iteration:   5569, Training Accuracy:  75.0%, Loss: 0.3835\n",
      "Optimization Iteration:   5633, Training Accuracy:  76.6%, Loss: 0.3629\n",
      "Optimization Iteration:   5697, Training Accuracy:  71.9%, Loss: 0.4252\n",
      "Optimization Iteration:   5761, Training Accuracy:  79.7%, Loss: 0.3418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   5825, Training Accuracy:  71.9%, Loss: 0.3787\n",
      "Optimization Iteration:   5889, Training Accuracy:  76.6%, Loss: 0.4306\n",
      "Optimization Iteration:   5953, Training Accuracy:  78.1%, Loss: 0.3482\n",
      "Optimization Iteration:   6017, Training Accuracy:  65.6%, Loss: 0.5454\n",
      "Optimization Iteration:   6081, Training Accuracy:  75.0%, Loss: 0.3965\n",
      "Optimization Iteration:   6145, Training Accuracy:  67.2%, Loss: 0.4726\n",
      "Optimization Iteration:   6209, Training Accuracy:  70.3%, Loss: 0.4200\n",
      "Optimization Iteration:   6273, Training Accuracy:  82.8%, Loss: 0.3518\n",
      "Optimization Iteration:   6337, Training Accuracy:  71.9%, Loss: 0.4208\n",
      "Optimization Iteration:   6401, Training Accuracy:  82.8%, Loss: 0.3767\n",
      "Optimization Iteration:   6465, Training Accuracy:  89.1%, Loss: 0.3207\n",
      "Optimization Iteration:   6529, Training Accuracy:  84.4%, Loss: 0.4041\n",
      "Optimization Iteration:   6593, Training Accuracy:  76.6%, Loss: 0.3907\n",
      "Optimization Iteration:   6657, Training Accuracy:  75.0%, Loss: 0.4382\n",
      "Optimization Iteration:   6721, Training Accuracy:  81.2%, Loss: 0.2925\n",
      "Optimization Iteration:   6785, Training Accuracy:  70.3%, Loss: 0.3818\n",
      "Optimization Iteration:   6849, Training Accuracy:  78.1%, Loss: 0.4043\n",
      "Optimization Iteration:   6913, Training Accuracy:  76.6%, Loss: 0.4157\n",
      "Optimization Iteration:   6977, Training Accuracy:  73.4%, Loss: 0.4041\n",
      "Optimization Iteration:   7041, Training Accuracy:  82.8%, Loss: 0.3164\n",
      "Optimization Iteration:   7105, Training Accuracy:  76.6%, Loss: 0.3784\n",
      "Optimization Iteration:   7169, Training Accuracy:  70.3%, Loss: 0.3980\n",
      "Optimization Iteration:   7233, Training Accuracy:  76.6%, Loss: 0.4058\n",
      "Optimization Iteration:   7297, Training Accuracy:  60.9%, Loss: 0.4664\n",
      "Optimization Iteration:   7361, Training Accuracy:  75.0%, Loss: 0.3754\n",
      "Optimization Iteration:   7425, Training Accuracy:  76.6%, Loss: 0.3639\n",
      "Optimization Iteration:   7489, Training Accuracy:  78.1%, Loss: 0.3833\n",
      "Optimization Iteration:   7553, Training Accuracy:  68.8%, Loss: 0.4392\n",
      "Optimization Iteration:   7617, Training Accuracy:  78.1%, Loss: 0.3886\n",
      "Optimization Iteration:   7681, Training Accuracy:  70.3%, Loss: 0.3890\n",
      "Optimization Iteration:   7745, Training Accuracy:  76.6%, Loss: 0.3185\n",
      "Optimization Iteration:   7809, Training Accuracy:  70.3%, Loss: 0.4191\n",
      "Optimization Iteration:   7873, Training Accuracy:  78.1%, Loss: 0.3481\n",
      "Optimization Iteration:   7937, Training Accuracy:  76.6%, Loss: 0.3826\n",
      "Optimization Iteration:   8001, Training Accuracy:  76.6%, Loss: 0.4035\n",
      "Optimization Iteration:   8065, Training Accuracy:  75.0%, Loss: 0.3463\n",
      "Optimization Iteration:   8129, Training Accuracy:  76.6%, Loss: 0.3918\n",
      "Optimization Iteration:   8193, Training Accuracy:  71.9%, Loss: 0.4649\n",
      "Optimization Iteration:   8257, Training Accuracy:  76.6%, Loss: 0.4773\n",
      "Optimization Iteration:   8321, Training Accuracy:  73.4%, Loss: 0.3962\n",
      "Optimization Iteration:   8385, Training Accuracy:  73.4%, Loss: 0.4180\n",
      "Optimization Iteration:   8449, Training Accuracy:  79.7%, Loss: 0.4078\n",
      "Optimization Iteration:   8513, Training Accuracy:  82.8%, Loss: 0.3411\n",
      "Optimization Iteration:   8577, Training Accuracy:  70.3%, Loss: 0.4777\n",
      "Optimization Iteration:   8641, Training Accuracy:  82.8%, Loss: 0.4006\n",
      "Optimization Iteration:   8705, Training Accuracy:  81.2%, Loss: 0.3309\n",
      "Optimization Iteration:   8769, Training Accuracy:  75.0%, Loss: 0.4436\n",
      "Optimization Iteration:   8833, Training Accuracy:  75.0%, Loss: 0.4220\n",
      "Optimization Iteration:   8897, Training Accuracy:  73.4%, Loss: 0.4252\n",
      "Optimization Iteration:   8961, Training Accuracy:  78.1%, Loss: 0.4069\n",
      "Optimization Iteration:   9025, Training Accuracy:  64.1%, Loss: 0.5359\n",
      "Optimization Iteration:   9089, Training Accuracy:  65.6%, Loss: 0.4700\n",
      "Optimization Iteration:   9153, Training Accuracy:  70.3%, Loss: 0.3903\n",
      "Optimization Iteration:   9217, Training Accuracy:  71.9%, Loss: 0.4262\n",
      "Optimization Iteration:   9281, Training Accuracy:  79.7%, Loss: 0.4130\n",
      "Optimization Iteration:   9345, Training Accuracy:  87.5%, Loss: 0.3610\n",
      "Optimization Iteration:   9409, Training Accuracy:  76.6%, Loss: 0.5176\n",
      "Optimization Iteration:   9473, Training Accuracy:  79.7%, Loss: 0.3644\n",
      "Optimization Iteration:   9537, Training Accuracy:  82.8%, Loss: 0.3218\n",
      "Optimization Iteration:   9601, Training Accuracy:  76.6%, Loss: 0.3604\n",
      "Optimization Iteration:   9665, Training Accuracy:  64.1%, Loss: 0.4978\n",
      "Optimization Iteration:   9729, Training Accuracy:  70.3%, Loss: 0.4171\n",
      "Optimization Iteration:   9793, Training Accuracy:  71.9%, Loss: 0.3723\n",
      "Optimization Iteration:   9857, Training Accuracy:  70.3%, Loss: 0.4174\n",
      "Optimization Iteration:   9921, Training Accuracy:  82.8%, Loss: 0.3477\n",
      "Optimization Iteration:   9985, Training Accuracy:  67.2%, Loss: 0.4645\n",
      "Optimization Iteration:  10049, Training Accuracy:  68.8%, Loss: 0.4194\n",
      "Optimization Iteration:  10113, Training Accuracy:  59.4%, Loss: 0.5042\n",
      "Optimization Iteration:  10177, Training Accuracy:  68.8%, Loss: 0.4611\n",
      "Optimization Iteration:  10241, Training Accuracy:  75.0%, Loss: 0.4276\n",
      "Optimization Iteration:  10305, Training Accuracy:  78.1%, Loss: 0.3537\n",
      "Optimization Iteration:  10369, Training Accuracy:  68.8%, Loss: 0.4170\n",
      "Optimization Iteration:  10433, Training Accuracy:  84.4%, Loss: 0.3674\n",
      "Optimization Iteration:  10497, Training Accuracy:  75.0%, Loss: 0.4672\n",
      "Optimization Iteration:  10561, Training Accuracy:  78.1%, Loss: 0.3613\n",
      "Optimization Iteration:  10625, Training Accuracy:  75.0%, Loss: 0.3626\n",
      "Optimization Iteration:  10689, Training Accuracy:  73.4%, Loss: 0.3560\n",
      "Optimization Iteration:  10753, Training Accuracy:  76.6%, Loss: 0.4715\n",
      "Optimization Iteration:  10817, Training Accuracy:  75.0%, Loss: 0.4777\n",
      "Optimization Iteration:  10881, Training Accuracy:  84.4%, Loss: 0.3050\n",
      "Optimization Iteration:  10945, Training Accuracy:  70.3%, Loss: 0.4225\n",
      "Optimization Iteration:  11009, Training Accuracy:  78.1%, Loss: 0.4052\n",
      "Optimization Iteration:  11073, Training Accuracy:  76.6%, Loss: 0.3448\n",
      "Optimization Iteration:  11137, Training Accuracy:  75.0%, Loss: 0.4506\n",
      "Optimization Iteration:  11201, Training Accuracy:  75.0%, Loss: 0.3901\n",
      "Optimization Iteration:  11265, Training Accuracy:  75.0%, Loss: 0.3802\n",
      "Optimization Iteration:  11329, Training Accuracy:  78.1%, Loss: 0.4482\n",
      "Optimization Iteration:  11393, Training Accuracy:  75.0%, Loss: 0.3820\n",
      "Optimization Iteration:  11457, Training Accuracy:  76.6%, Loss: 0.4150\n",
      "Optimization Iteration:  11521, Training Accuracy:  73.4%, Loss: 0.4310\n",
      "Optimization Iteration:  11585, Training Accuracy:  76.6%, Loss: 0.3752\n",
      "Optimization Iteration:  11649, Training Accuracy:  70.3%, Loss: 0.4070\n",
      "Optimization Iteration:  11713, Training Accuracy:  78.1%, Loss: 0.3130\n",
      "Optimization Iteration:  11777, Training Accuracy:  76.6%, Loss: 0.4615\n",
      "Optimization Iteration:  11841, Training Accuracy:  78.1%, Loss: 0.3856\n",
      "Optimization Iteration:  11905, Training Accuracy:  79.7%, Loss: 0.3604\n",
      "Optimization Iteration:  11969, Training Accuracy:  81.2%, Loss: 0.3235\n",
      "Optimization Iteration:  12033, Training Accuracy:  71.9%, Loss: 0.4084\n",
      "Optimization Iteration:  12097, Training Accuracy:  70.3%, Loss: 0.4496\n",
      "Optimization Iteration:  12161, Training Accuracy:  81.2%, Loss: 0.3872\n",
      "Optimization Iteration:  12225, Training Accuracy:  81.2%, Loss: 0.3429\n",
      "Optimization Iteration:  12289, Training Accuracy:  75.0%, Loss: 0.3873\n",
      "Optimization Iteration:  12353, Training Accuracy:  84.4%, Loss: 0.3097\n",
      "Optimization Iteration:  12417, Training Accuracy:  82.8%, Loss: 0.3611\n",
      "Optimization Iteration:  12481, Training Accuracy:  75.0%, Loss: 0.3997\n",
      "Optimization Iteration:  12545, Training Accuracy:  76.6%, Loss: 0.4103\n",
      "Optimization Iteration:  12609, Training Accuracy:  79.7%, Loss: 0.3484\n",
      "Optimization Iteration:  12673, Training Accuracy:  71.9%, Loss: 0.4130\n",
      "Optimization Iteration:  12737, Training Accuracy:  73.4%, Loss: 0.4332\n",
      "Optimization Iteration:  12801, Training Accuracy:  76.6%, Loss: 0.4147\n",
      "Optimization Iteration:  12865, Training Accuracy:  81.2%, Loss: 0.3772\n",
      "Optimization Iteration:  12929, Training Accuracy:  70.3%, Loss: 0.4339\n",
      "Optimization Iteration:  12993, Training Accuracy:  84.4%, Loss: 0.3197\n",
      "Optimization Iteration:  13057, Training Accuracy:  67.2%, Loss: 0.4841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  13121, Training Accuracy:  71.9%, Loss: 0.3982\n",
      "Optimization Iteration:  13185, Training Accuracy:  78.1%, Loss: 0.4409\n",
      "Optimization Iteration:  13249, Training Accuracy:  68.8%, Loss: 0.4685\n",
      "Optimization Iteration:  13313, Training Accuracy:  71.9%, Loss: 0.5205\n",
      "Optimization Iteration:  13377, Training Accuracy:  79.7%, Loss: 0.4333\n",
      "Optimization Iteration:  13441, Training Accuracy:  78.1%, Loss: 0.3751\n",
      "Optimization Iteration:  13505, Training Accuracy:  82.8%, Loss: 0.3594\n",
      "Optimization Iteration:  13569, Training Accuracy:  82.8%, Loss: 0.3595\n",
      "Optimization Iteration:  13633, Training Accuracy:  67.2%, Loss: 0.4259\n",
      "Optimization Iteration:  13697, Training Accuracy:  79.7%, Loss: 0.3618\n",
      "Optimization Iteration:  13761, Training Accuracy:  76.6%, Loss: 0.3543\n",
      "Optimization Iteration:  13825, Training Accuracy:  76.6%, Loss: 0.3607\n",
      "Optimization Iteration:  13889, Training Accuracy:  68.8%, Loss: 0.6873\n",
      "Optimization Iteration:  13953, Training Accuracy:  78.1%, Loss: 0.3786\n",
      "Optimization Iteration:  14017, Training Accuracy:  78.1%, Loss: 0.3941\n",
      "Optimization Iteration:  14081, Training Accuracy:  70.3%, Loss: 0.4522\n",
      "Optimization Iteration:  14145, Training Accuracy:  78.1%, Loss: 0.3875\n",
      "Optimization Iteration:  14209, Training Accuracy:  79.7%, Loss: 0.3802\n",
      "Optimization Iteration:  14273, Training Accuracy:  73.4%, Loss: 0.4691\n",
      "Optimization Iteration:  14337, Training Accuracy:  82.8%, Loss: 0.3318\n",
      "Optimization Iteration:  14401, Training Accuracy:  84.4%, Loss: 0.3149\n",
      "Optimization Iteration:  14465, Training Accuracy:  67.2%, Loss: 0.4506\n",
      "Optimization Iteration:  14529, Training Accuracy:  76.6%, Loss: 0.3384\n",
      "Optimization Iteration:  14593, Training Accuracy:  79.7%, Loss: 0.4181\n",
      "Optimization Iteration:  14657, Training Accuracy:  73.4%, Loss: 0.3554\n",
      "Optimization Iteration:  14721, Training Accuracy:  84.4%, Loss: 0.3349\n",
      "Optimization Iteration:  14785, Training Accuracy:  75.0%, Loss: 0.3885\n",
      "Optimization Iteration:  14849, Training Accuracy:  75.0%, Loss: 0.4063\n",
      "Optimization Iteration:  14913, Training Accuracy:  78.1%, Loss: 0.3367\n",
      "Optimization Iteration:  14977, Training Accuracy:  68.8%, Loss: 0.4988\n",
      "Optimization Iteration:  15041, Training Accuracy:  75.0%, Loss: 0.3543\n",
      "Optimization Iteration:  15105, Training Accuracy:  82.8%, Loss: 0.3415\n",
      "Optimization Iteration:  15169, Training Accuracy:  73.4%, Loss: 0.3830\n",
      "Optimization Iteration:  15233, Training Accuracy:  71.9%, Loss: 0.4184\n",
      "Optimization Iteration:  15297, Training Accuracy:  79.7%, Loss: 0.4100\n",
      "Optimization Iteration:  15361, Training Accuracy:  75.0%, Loss: 0.4511\n",
      "Optimization Iteration:  15425, Training Accuracy:  70.3%, Loss: 0.4412\n",
      "Optimization Iteration:  15489, Training Accuracy:  67.2%, Loss: 0.4518\n",
      "Optimization Iteration:  15553, Training Accuracy:  73.4%, Loss: 0.4127\n",
      "Optimization Iteration:  15617, Training Accuracy:  81.2%, Loss: 0.3460\n",
      "Optimization Iteration:  15681, Training Accuracy:  81.2%, Loss: 0.3445\n",
      "Optimization Iteration:  15745, Training Accuracy:  78.1%, Loss: 0.3400\n",
      "Optimization Iteration:  15809, Training Accuracy:  75.0%, Loss: 0.4204\n",
      "Optimization Iteration:  15873, Training Accuracy:  79.7%, Loss: 0.4067\n",
      "Optimization Iteration:  15937, Training Accuracy:  73.4%, Loss: 0.4512\n",
      "Optimization Iteration:  16001, Training Accuracy:  70.3%, Loss: 0.4086\n",
      "Optimization Iteration:  16065, Training Accuracy:  68.8%, Loss: 0.4567\n",
      "Optimization Iteration:  16129, Training Accuracy:  71.9%, Loss: 0.4142\n",
      "Optimization Iteration:  16193, Training Accuracy:  81.2%, Loss: 0.4117\n",
      "Optimization Iteration:  16257, Training Accuracy:  82.8%, Loss: 0.4155\n",
      "Optimization Iteration:  16321, Training Accuracy:  78.1%, Loss: 0.4116\n",
      "Optimization Iteration:  16385, Training Accuracy:  79.7%, Loss: 0.3868\n",
      "Optimization Iteration:  16449, Training Accuracy:  78.1%, Loss: 0.4309\n",
      "Optimization Iteration:  16513, Training Accuracy:  79.7%, Loss: 0.3835\n",
      "Optimization Iteration:  16577, Training Accuracy:  78.1%, Loss: 0.3614\n",
      "Optimization Iteration:  16641, Training Accuracy:  75.0%, Loss: 0.4277\n",
      "Optimization Iteration:  16705, Training Accuracy:  71.9%, Loss: 0.4467\n",
      "Optimization Iteration:  16769, Training Accuracy:  73.4%, Loss: 0.4095\n",
      "Optimization Iteration:  16833, Training Accuracy:  73.4%, Loss: 0.3895\n",
      "Optimization Iteration:  16897, Training Accuracy:  75.0%, Loss: 0.3723\n",
      "Optimization Iteration:  16961, Training Accuracy:  75.0%, Loss: 0.4189\n",
      "Optimization Iteration:  17025, Training Accuracy:  71.9%, Loss: 0.4246\n",
      "Optimization Iteration:  17089, Training Accuracy:  76.6%, Loss: 0.3979\n",
      "Optimization Iteration:  17153, Training Accuracy:  73.4%, Loss: 0.3968\n",
      "Optimization Iteration:  17217, Training Accuracy:  70.3%, Loss: 0.4324\n",
      "Optimization Iteration:  17281, Training Accuracy:  68.8%, Loss: 0.4333\n",
      "Optimization Iteration:  17345, Training Accuracy:  76.6%, Loss: 0.3267\n",
      "Optimization Iteration:  17409, Training Accuracy:  70.3%, Loss: 0.4105\n",
      "Optimization Iteration:  17473, Training Accuracy:  68.8%, Loss: 0.4554\n",
      "Optimization Iteration:  17537, Training Accuracy:  73.4%, Loss: 0.3031\n",
      "Optimization Iteration:  17601, Training Accuracy:  73.4%, Loss: 0.4184\n",
      "Optimization Iteration:  17665, Training Accuracy:  76.6%, Loss: 0.3561\n",
      "Optimization Iteration:  17729, Training Accuracy:  70.3%, Loss: 0.4133\n",
      "Optimization Iteration:  17793, Training Accuracy:  67.2%, Loss: 0.4376\n",
      "Optimization Iteration:  17857, Training Accuracy:  71.9%, Loss: 0.4015\n",
      "Optimization Iteration:  17921, Training Accuracy:  76.6%, Loss: 0.3560\n",
      "Optimization Iteration:  17985, Training Accuracy:  70.3%, Loss: 0.3436\n",
      "Optimization Iteration:  18049, Training Accuracy:  76.6%, Loss: 0.3590\n",
      "Optimization Iteration:  18113, Training Accuracy:  68.8%, Loss: 0.4461\n",
      "Optimization Iteration:  18177, Training Accuracy:  68.8%, Loss: 0.4619\n",
      "Optimization Iteration:  18241, Training Accuracy:  76.6%, Loss: 0.3608\n",
      "Optimization Iteration:  18305, Training Accuracy:  75.0%, Loss: 0.3916\n",
      "Optimization Iteration:  18369, Training Accuracy:  67.2%, Loss: 0.3672\n",
      "Optimization Iteration:  18433, Training Accuracy:  65.6%, Loss: 0.5127\n",
      "Optimization Iteration:  18497, Training Accuracy:  84.4%, Loss: 0.2750\n",
      "Optimization Iteration:  18561, Training Accuracy:  65.6%, Loss: 0.4972\n",
      "Optimization Iteration:  18625, Training Accuracy:  78.1%, Loss: 0.4180\n",
      "Optimization Iteration:  18689, Training Accuracy:  73.4%, Loss: 0.4183\n",
      "Optimization Iteration:  18753, Training Accuracy:  82.8%, Loss: 0.3557\n",
      "Optimization Iteration:  18817, Training Accuracy:  78.1%, Loss: 0.3418\n",
      "Optimization Iteration:  18881, Training Accuracy:  79.7%, Loss: 0.3859\n",
      "Optimization Iteration:  18945, Training Accuracy:  73.4%, Loss: 0.3919\n",
      "Optimization Iteration:  19009, Training Accuracy:  67.2%, Loss: 0.3973\n",
      "Optimization Iteration:  19073, Training Accuracy:  79.7%, Loss: 0.3860\n",
      "Optimization Iteration:  19137, Training Accuracy:  65.6%, Loss: 0.4468\n",
      "Optimization Iteration:  19201, Training Accuracy:  71.9%, Loss: 0.4290\n",
      "Optimization Iteration:  19265, Training Accuracy:  81.2%, Loss: 0.3672\n",
      "Optimization Iteration:  19329, Training Accuracy:  81.2%, Loss: 0.3829\n",
      "Optimization Iteration:  19393, Training Accuracy:  75.0%, Loss: 0.4043\n",
      "Optimization Iteration:  19457, Training Accuracy:  76.6%, Loss: 0.3558\n",
      "Optimization Iteration:  19521, Training Accuracy:  78.1%, Loss: 0.4064\n",
      "Optimization Iteration:  19585, Training Accuracy:  67.2%, Loss: 0.4865\n",
      "Optimization Iteration:  19649, Training Accuracy:  81.2%, Loss: 0.3835\n",
      "Optimization Iteration:  19713, Training Accuracy:  87.5%, Loss: 0.2990\n",
      "Optimization Iteration:  19777, Training Accuracy:  68.8%, Loss: 0.5428\n",
      "Optimization Iteration:  19841, Training Accuracy:  73.4%, Loss: 0.4805\n",
      "Optimization Iteration:  19905, Training Accuracy:  73.4%, Loss: 0.3847\n",
      "Optimization Iteration:  19969, Training Accuracy:  71.9%, Loss: 0.4806\n",
      "Optimization Iteration:  20033, Training Accuracy:  76.6%, Loss: 0.3471\n",
      "Optimization Iteration:  20097, Training Accuracy:  73.4%, Loss: 0.4144\n",
      "Optimization Iteration:  20161, Training Accuracy:  75.0%, Loss: 0.3706\n",
      "Optimization Iteration:  20225, Training Accuracy:  70.3%, Loss: 0.3755\n",
      "Optimization Iteration:  20289, Training Accuracy:  76.6%, Loss: 0.3551\n",
      "Optimization Iteration:  20353, Training Accuracy:  78.1%, Loss: 0.3761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  20417, Training Accuracy:  65.6%, Loss: 0.4532\n",
      "Optimization Iteration:  20481, Training Accuracy:  76.6%, Loss: 0.3918\n",
      "Optimization Iteration:  20545, Training Accuracy:  79.7%, Loss: 0.3774\n",
      "Optimization Iteration:  20609, Training Accuracy:  71.9%, Loss: 0.4646\n",
      "Optimization Iteration:  20673, Training Accuracy:  70.3%, Loss: 0.4026\n",
      "Optimization Iteration:  20737, Training Accuracy:  90.6%, Loss: 0.4095\n",
      "Optimization Iteration:  20801, Training Accuracy:  82.8%, Loss: 0.3725\n",
      "Optimization Iteration:  20865, Training Accuracy:  89.1%, Loss: 0.3046\n",
      "Optimization Iteration:  20929, Training Accuracy:  82.8%, Loss: 0.3166\n",
      "Optimization Iteration:  20993, Training Accuracy:  79.7%, Loss: 0.3810\n",
      "Optimization Iteration:  21057, Training Accuracy:  79.7%, Loss: 0.4393\n",
      "Optimization Iteration:  21121, Training Accuracy:  68.8%, Loss: 0.4312\n",
      "Optimization Iteration:  21185, Training Accuracy:  73.4%, Loss: 0.4537\n",
      "Optimization Iteration:  21249, Training Accuracy:  71.9%, Loss: 0.4826\n",
      "Optimization Iteration:  21313, Training Accuracy:  84.4%, Loss: 0.3380\n",
      "Optimization Iteration:  21377, Training Accuracy:  78.1%, Loss: 0.3315\n",
      "Optimization Iteration:  21441, Training Accuracy:  71.9%, Loss: 0.4134\n",
      "Optimization Iteration:  21505, Training Accuracy:  81.2%, Loss: 0.3603\n",
      "Optimization Iteration:  21569, Training Accuracy:  81.2%, Loss: 0.3413\n",
      "Optimization Iteration:  21633, Training Accuracy:  82.8%, Loss: 0.3287\n",
      "Optimization Iteration:  21697, Training Accuracy:  68.8%, Loss: 0.5677\n",
      "Optimization Iteration:  21761, Training Accuracy:  84.4%, Loss: 0.3398\n",
      "Optimization Iteration:  21825, Training Accuracy:  73.4%, Loss: 0.4430\n",
      "Optimization Iteration:  21889, Training Accuracy:  71.9%, Loss: 0.3995\n",
      "Optimization Iteration:  21953, Training Accuracy:  65.6%, Loss: 0.6428\n",
      "Optimization Iteration:  22017, Training Accuracy:  76.6%, Loss: 0.3859\n",
      "Optimization Iteration:  22081, Training Accuracy:  78.1%, Loss: 0.3481\n",
      "Optimization Iteration:  22145, Training Accuracy:  78.1%, Loss: 0.4129\n",
      "Optimization Iteration:  22209, Training Accuracy:  81.2%, Loss: 0.4046\n",
      "Optimization Iteration:  22273, Training Accuracy:  71.9%, Loss: 0.4358\n",
      "Optimization Iteration:  22337, Training Accuracy:  79.7%, Loss: 0.3286\n",
      "Optimization Iteration:  22401, Training Accuracy:  81.2%, Loss: 0.3240\n",
      "Optimization Iteration:  22465, Training Accuracy:  70.3%, Loss: 0.4376\n",
      "Optimization Iteration:  22529, Training Accuracy:  76.6%, Loss: 0.3901\n",
      "Optimization Iteration:  22593, Training Accuracy:  73.4%, Loss: 0.4997\n",
      "Optimization Iteration:  22657, Training Accuracy:  76.6%, Loss: 0.3951\n",
      "Optimization Iteration:  22721, Training Accuracy:  78.1%, Loss: 0.3547\n",
      "Optimization Iteration:  22785, Training Accuracy:  81.2%, Loss: 0.3924\n",
      "Optimization Iteration:  22849, Training Accuracy:  73.4%, Loss: 0.4249\n",
      "Optimization Iteration:  22913, Training Accuracy:  87.5%, Loss: 0.2944\n",
      "Optimization Iteration:  22977, Training Accuracy:  89.1%, Loss: 0.3079\n",
      "Optimization Iteration:  23041, Training Accuracy:  70.3%, Loss: 0.3844\n",
      "Optimization Iteration:  23105, Training Accuracy:  64.1%, Loss: 0.4271\n",
      "Optimization Iteration:  23169, Training Accuracy:  75.0%, Loss: 0.3628\n",
      "Optimization Iteration:  23233, Training Accuracy:  75.0%, Loss: 0.4343\n",
      "Optimization Iteration:  23297, Training Accuracy:  71.9%, Loss: 0.4339\n",
      "Optimization Iteration:  23361, Training Accuracy:  68.8%, Loss: 0.4754\n",
      "Optimization Iteration:  23425, Training Accuracy:  76.6%, Loss: 0.4002\n",
      "Optimization Iteration:  23489, Training Accuracy:  76.6%, Loss: 0.3970\n",
      "Optimization Iteration:  23553, Training Accuracy:  76.6%, Loss: 0.3802\n",
      "Optimization Iteration:  23617, Training Accuracy:  82.8%, Loss: 0.3457\n",
      "Optimization Iteration:  23681, Training Accuracy:  70.3%, Loss: 0.4630\n",
      "Optimization Iteration:  23745, Training Accuracy:  75.0%, Loss: 0.3941\n",
      "Optimization Iteration:  23809, Training Accuracy:  76.6%, Loss: 0.4168\n",
      "Optimization Iteration:  23873, Training Accuracy:  84.4%, Loss: 0.3695\n",
      "Optimization Iteration:  23937, Training Accuracy:  70.3%, Loss: 0.4804\n",
      "Optimization Iteration:  24001, Training Accuracy:  76.6%, Loss: 0.2911\n",
      "Optimization Iteration:  24065, Training Accuracy:  75.0%, Loss: 0.3924\n",
      "Optimization Iteration:  24129, Training Accuracy:  78.1%, Loss: 0.3669\n",
      "Optimization Iteration:  24193, Training Accuracy:  73.4%, Loss: 0.4526\n",
      "Optimization Iteration:  24257, Training Accuracy:  75.0%, Loss: 0.4382\n",
      "Optimization Iteration:  24321, Training Accuracy:  67.2%, Loss: 0.4974\n",
      "Optimization Iteration:  24385, Training Accuracy:  81.2%, Loss: 0.4724\n",
      "Optimization Iteration:  24449, Training Accuracy:  79.7%, Loss: 0.3086\n",
      "Optimization Iteration:  24513, Training Accuracy:  75.0%, Loss: 0.4299\n",
      "Optimization Iteration:  24577, Training Accuracy:  68.8%, Loss: 0.5395\n",
      "Optimization Iteration:  24641, Training Accuracy:  79.7%, Loss: 0.3556\n",
      "Optimization Iteration:  24705, Training Accuracy:  78.1%, Loss: 0.3196\n",
      "Optimization Iteration:  24769, Training Accuracy:  68.8%, Loss: 0.4063\n",
      "Optimization Iteration:  24833, Training Accuracy:  84.4%, Loss: 0.3344\n",
      "Optimization Iteration:  24897, Training Accuracy:  71.9%, Loss: 0.4030\n",
      "Optimization Iteration:  24961, Training Accuracy:  82.8%, Loss: 0.3225\n",
      "Optimization Iteration:  25025, Training Accuracy:  78.1%, Loss: 0.3977\n",
      "Optimization Iteration:  25089, Training Accuracy:  76.6%, Loss: 0.3975\n",
      "Optimization Iteration:  25153, Training Accuracy:  73.4%, Loss: 0.4056\n",
      "Optimization Iteration:  25217, Training Accuracy:  73.4%, Loss: 0.4785\n",
      "Optimization Iteration:  25281, Training Accuracy:  79.7%, Loss: 0.4006\n",
      "Optimization Iteration:  25345, Training Accuracy:  76.6%, Loss: 0.4159\n",
      "Optimization Iteration:  25409, Training Accuracy:  82.8%, Loss: 0.3332\n",
      "Optimization Iteration:  25473, Training Accuracy:  68.8%, Loss: 0.5314\n",
      "Optimization Iteration:  25537, Training Accuracy:  79.7%, Loss: 0.4035\n",
      "Optimization Iteration:  25601, Training Accuracy:  64.1%, Loss: 0.5081\n",
      "Optimization Iteration:  25665, Training Accuracy:  73.4%, Loss: 0.4421\n",
      "Optimization Iteration:  25729, Training Accuracy:  79.7%, Loss: 0.3662\n",
      "Optimization Iteration:  25793, Training Accuracy:  78.1%, Loss: 0.3659\n",
      "Optimization Iteration:  25857, Training Accuracy:  56.2%, Loss: 0.5751\n",
      "Optimization Iteration:  25921, Training Accuracy:  71.9%, Loss: 0.4710\n",
      "Optimization Iteration:  25985, Training Accuracy:  71.9%, Loss: 0.4689\n",
      "Optimization Iteration:  26049, Training Accuracy:  75.0%, Loss: 0.3674\n",
      "Optimization Iteration:  26113, Training Accuracy:  76.6%, Loss: 0.3562\n",
      "Optimization Iteration:  26177, Training Accuracy:  73.4%, Loss: 0.3722\n",
      "Optimization Iteration:  26241, Training Accuracy:  78.1%, Loss: 0.3137\n",
      "Optimization Iteration:  26305, Training Accuracy:  85.9%, Loss: 0.3466\n",
      "Optimization Iteration:  26369, Training Accuracy:  78.1%, Loss: 0.3773\n",
      "Optimization Iteration:  26433, Training Accuracy:  71.9%, Loss: 0.4053\n",
      "Optimization Iteration:  26497, Training Accuracy:  70.3%, Loss: 0.4163\n",
      "Optimization Iteration:  26561, Training Accuracy:  84.4%, Loss: 0.3297\n",
      "Optimization Iteration:  26625, Training Accuracy:  78.1%, Loss: 0.3622\n",
      "Optimization Iteration:  26689, Training Accuracy:  75.0%, Loss: 0.4446\n",
      "Optimization Iteration:  26753, Training Accuracy:  73.4%, Loss: 0.4586\n",
      "Optimization Iteration:  26817, Training Accuracy:  78.1%, Loss: 0.4302\n",
      "Optimization Iteration:  26881, Training Accuracy:  76.6%, Loss: 0.3310\n",
      "Optimization Iteration:  26945, Training Accuracy:  70.3%, Loss: 0.4356\n",
      "Optimization Iteration:  27009, Training Accuracy:  81.2%, Loss: 0.3407\n",
      "Optimization Iteration:  27073, Training Accuracy:  78.1%, Loss: 0.4018\n",
      "Optimization Iteration:  27137, Training Accuracy:  84.4%, Loss: 0.4086\n",
      "Optimization Iteration:  27201, Training Accuracy:  79.7%, Loss: 0.3120\n",
      "Optimization Iteration:  27265, Training Accuracy:  71.9%, Loss: 0.3717\n",
      "Optimization Iteration:  27329, Training Accuracy:  75.0%, Loss: 0.3497\n",
      "Optimization Iteration:  27393, Training Accuracy:  81.2%, Loss: 0.3976\n",
      "Optimization Iteration:  27457, Training Accuracy:  81.2%, Loss: 0.3885\n",
      "Optimization Iteration:  27521, Training Accuracy:  76.6%, Loss: 0.3827\n",
      "Optimization Iteration:  27585, Training Accuracy:  70.3%, Loss: 0.3808\n",
      "Optimization Iteration:  27649, Training Accuracy:  71.9%, Loss: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  27713, Training Accuracy:  70.3%, Loss: 0.5383\n",
      "Optimization Iteration:  27777, Training Accuracy:  75.0%, Loss: 0.3709\n",
      "Optimization Iteration:  27841, Training Accuracy:  76.6%, Loss: 0.3811\n",
      "Optimization Iteration:  27905, Training Accuracy:  71.9%, Loss: 0.4278\n",
      "Optimization Iteration:  27969, Training Accuracy:  84.4%, Loss: 0.4212\n",
      "Optimization Iteration:  28033, Training Accuracy:  81.2%, Loss: 0.3956\n",
      "Optimization Iteration:  28097, Training Accuracy:  75.0%, Loss: 0.3740\n",
      "Optimization Iteration:  28161, Training Accuracy:  82.8%, Loss: 0.3616\n",
      "Optimization Iteration:  28225, Training Accuracy:  71.9%, Loss: 0.3665\n",
      "Optimization Iteration:  28289, Training Accuracy:  82.8%, Loss: 0.3638\n",
      "Optimization Iteration:  28353, Training Accuracy:  76.6%, Loss: 0.3471\n",
      "Optimization Iteration:  28417, Training Accuracy:  75.0%, Loss: 0.4249\n",
      "Optimization Iteration:  28481, Training Accuracy:  75.0%, Loss: 0.3821\n",
      "Optimization Iteration:  28545, Training Accuracy:  79.7%, Loss: 0.3167\n",
      "Optimization Iteration:  28609, Training Accuracy:  87.5%, Loss: 0.2333\n",
      "Optimization Iteration:  28673, Training Accuracy:  70.3%, Loss: 0.4956\n",
      "Optimization Iteration:  28737, Training Accuracy:  68.8%, Loss: 0.3816\n",
      "Optimization Iteration:  28801, Training Accuracy:  71.9%, Loss: 0.3944\n",
      "Optimization Iteration:  28865, Training Accuracy:  82.8%, Loss: 0.3288\n",
      "Optimization Iteration:  28929, Training Accuracy:  81.2%, Loss: 0.3217\n",
      "Optimization Iteration:  28993, Training Accuracy:  68.8%, Loss: 0.4540\n",
      "Optimization Iteration:  29057, Training Accuracy:  70.3%, Loss: 0.4120\n",
      "Optimization Iteration:  29121, Training Accuracy:  75.0%, Loss: 0.4101\n",
      "Optimization Iteration:  29185, Training Accuracy:  78.1%, Loss: 0.3349\n",
      "Optimization Iteration:  29249, Training Accuracy:  73.4%, Loss: 0.3950\n",
      "Optimization Iteration:  29313, Training Accuracy:  79.7%, Loss: 0.4135\n",
      "Optimization Iteration:  29377, Training Accuracy:  76.6%, Loss: 0.3518\n",
      "Optimization Iteration:  29441, Training Accuracy:  75.0%, Loss: 0.4116\n",
      "Optimization Iteration:  29505, Training Accuracy:  82.8%, Loss: 0.4042\n",
      "Optimization Iteration:  29569, Training Accuracy:  76.6%, Loss: 0.4063\n",
      "Optimization Iteration:  29633, Training Accuracy:  78.1%, Loss: 0.3867\n",
      "Optimization Iteration:  29697, Training Accuracy:  71.9%, Loss: 0.3920\n",
      "Optimization Iteration:  29761, Training Accuracy:  79.7%, Loss: 0.3512\n",
      "Optimization Iteration:  29825, Training Accuracy:  64.1%, Loss: 0.4124\n",
      "Optimization Iteration:  29889, Training Accuracy:  71.9%, Loss: 0.4245\n",
      "Optimization Iteration:  29953, Training Accuracy:  71.9%, Loss: 0.4551\n",
      "Optimization Iteration:  30017, Training Accuracy:  92.2%, Loss: 0.2717\n",
      "Optimization Iteration:  30081, Training Accuracy:  81.2%, Loss: 0.3624\n",
      "Optimization Iteration:  30145, Training Accuracy:  70.3%, Loss: 0.4301\n",
      "Optimization Iteration:  30209, Training Accuracy:  70.3%, Loss: 0.4656\n",
      "Optimization Iteration:  30273, Training Accuracy:  76.6%, Loss: 0.3871\n",
      "Optimization Iteration:  30337, Training Accuracy:  78.1%, Loss: 0.3386\n",
      "Optimization Iteration:  30401, Training Accuracy:  81.2%, Loss: 0.3797\n",
      "Optimization Iteration:  30465, Training Accuracy:  79.7%, Loss: 0.4037\n",
      "Optimization Iteration:  30529, Training Accuracy:  76.6%, Loss: 0.4179\n",
      "Optimization Iteration:  30593, Training Accuracy:  78.1%, Loss: 0.3302\n",
      "Optimization Iteration:  30657, Training Accuracy:  75.0%, Loss: 0.3858\n",
      "Optimization Iteration:  30721, Training Accuracy:  71.9%, Loss: 0.3880\n",
      "Optimization Iteration:  30785, Training Accuracy:  76.6%, Loss: 0.4410\n",
      "Optimization Iteration:  30849, Training Accuracy:  71.9%, Loss: 0.4466\n",
      "Optimization Iteration:  30913, Training Accuracy:  78.1%, Loss: 0.3972\n",
      "Optimization Iteration:  30977, Training Accuracy:  73.4%, Loss: 0.4169\n",
      "Optimization Iteration:  31041, Training Accuracy:  78.1%, Loss: 0.4000\n",
      "Optimization Iteration:  31105, Training Accuracy:  71.9%, Loss: 0.4161\n",
      "Optimization Iteration:  31169, Training Accuracy:  68.8%, Loss: 0.3890\n",
      "Optimization Iteration:  31233, Training Accuracy:  70.3%, Loss: 0.4566\n",
      "Optimization Iteration:  31297, Training Accuracy:  81.2%, Loss: 0.3316\n",
      "Optimization Iteration:  31361, Training Accuracy:  71.9%, Loss: 0.4380\n",
      "Optimization Iteration:  31425, Training Accuracy:  85.9%, Loss: 0.2638\n",
      "Optimization Iteration:  31489, Training Accuracy:  85.9%, Loss: 0.3009\n",
      "Optimization Iteration:  31553, Training Accuracy:  81.2%, Loss: 0.3103\n",
      "Optimization Iteration:  31617, Training Accuracy:  68.8%, Loss: 0.3857\n",
      "Optimization Iteration:  31681, Training Accuracy:  71.9%, Loss: 0.4529\n",
      "Optimization Iteration:  31745, Training Accuracy:  73.4%, Loss: 0.4367\n",
      "Optimization Iteration:  31809, Training Accuracy:  75.0%, Loss: 0.4713\n",
      "Optimization Iteration:  31873, Training Accuracy:  73.4%, Loss: 0.3998\n",
      "Optimization Iteration:  31937, Training Accuracy:  67.2%, Loss: 0.4740\n",
      "Optimization Iteration:  32001, Training Accuracy:  73.4%, Loss: 0.4126\n",
      "Optimization Iteration:  32065, Training Accuracy:  67.2%, Loss: 0.4138\n",
      "Optimization Iteration:  32129, Training Accuracy:  70.3%, Loss: 0.4019\n",
      "Optimization Iteration:  32193, Training Accuracy:  71.9%, Loss: 0.4058\n",
      "Optimization Iteration:  32257, Training Accuracy:  76.6%, Loss: 0.4630\n",
      "Optimization Iteration:  32321, Training Accuracy:  81.2%, Loss: 0.3199\n",
      "Optimization Iteration:  32385, Training Accuracy:  73.4%, Loss: 0.4583\n",
      "Optimization Iteration:  32449, Training Accuracy:  65.6%, Loss: 0.4851\n",
      "Optimization Iteration:  32513, Training Accuracy:  70.3%, Loss: 0.4212\n",
      "Optimization Iteration:  32577, Training Accuracy:  76.6%, Loss: 0.3647\n",
      "Optimization Iteration:  32641, Training Accuracy:  68.8%, Loss: 0.4476\n",
      "Optimization Iteration:  32705, Training Accuracy:  78.1%, Loss: 0.4040\n",
      "Optimization Iteration:  32769, Training Accuracy:  75.0%, Loss: 0.3979\n",
      "Optimization Iteration:  32833, Training Accuracy:  73.4%, Loss: 0.3962\n",
      "Optimization Iteration:  32897, Training Accuracy:  75.0%, Loss: 0.4273\n",
      "Optimization Iteration:  32961, Training Accuracy:  78.1%, Loss: 0.4375\n",
      "Optimization Iteration:  33025, Training Accuracy:  71.9%, Loss: 0.4058\n",
      "Optimization Iteration:  33089, Training Accuracy:  70.3%, Loss: 0.4347\n",
      "Optimization Iteration:  33153, Training Accuracy:  70.3%, Loss: 0.4962\n",
      "Optimization Iteration:  33217, Training Accuracy:  73.4%, Loss: 0.3366\n",
      "Optimization Iteration:  33281, Training Accuracy:  79.7%, Loss: 0.4365\n",
      "Optimization Iteration:  33345, Training Accuracy:  73.4%, Loss: 0.4987\n",
      "Optimization Iteration:  33409, Training Accuracy:  79.7%, Loss: 0.3654\n",
      "Optimization Iteration:  33473, Training Accuracy:  79.7%, Loss: 0.4694\n",
      "Optimization Iteration:  33537, Training Accuracy:  65.6%, Loss: 0.4274\n",
      "Optimization Iteration:  33601, Training Accuracy:  81.2%, Loss: 0.4566\n",
      "Optimization Iteration:  33665, Training Accuracy:  75.0%, Loss: 0.4005\n",
      "Optimization Iteration:  33729, Training Accuracy:  71.9%, Loss: 0.4334\n",
      "Optimization Iteration:  33793, Training Accuracy:  71.9%, Loss: 0.4844\n",
      "Optimization Iteration:  33857, Training Accuracy:  84.4%, Loss: 0.3255\n",
      "Optimization Iteration:  33921, Training Accuracy:  78.1%, Loss: 0.4113\n",
      "Optimization Iteration:  33985, Training Accuracy:  79.7%, Loss: 0.3554\n",
      "Optimization Iteration:  34049, Training Accuracy:  70.3%, Loss: 0.5669\n",
      "Optimization Iteration:  34113, Training Accuracy:  78.1%, Loss: 0.3885\n",
      "Optimization Iteration:  34177, Training Accuracy:  70.3%, Loss: 0.3999\n",
      "Optimization Iteration:  34241, Training Accuracy:  76.6%, Loss: 0.4274\n",
      "Optimization Iteration:  34305, Training Accuracy:  76.6%, Loss: 0.3802\n",
      "Optimization Iteration:  34369, Training Accuracy:  81.2%, Loss: 0.2948\n",
      "Optimization Iteration:  34433, Training Accuracy:  67.2%, Loss: 0.4394\n",
      "Optimization Iteration:  34497, Training Accuracy:  67.2%, Loss: 0.3305\n",
      "Optimization Iteration:  34561, Training Accuracy:  75.0%, Loss: 0.3948\n",
      "Optimization Iteration:  34625, Training Accuracy:  78.1%, Loss: 0.4600\n",
      "Optimization Iteration:  34689, Training Accuracy:  79.7%, Loss: 0.3673\n",
      "Optimization Iteration:  34753, Training Accuracy:  68.8%, Loss: 0.4935\n",
      "Optimization Iteration:  34817, Training Accuracy:  79.7%, Loss: 0.3690\n",
      "Optimization Iteration:  34881, Training Accuracy:  75.0%, Loss: 0.4117\n",
      "Optimization Iteration:  34945, Training Accuracy:  73.4%, Loss: 0.3748\n",
      "Optimization Iteration:  35009, Training Accuracy:  87.5%, Loss: 0.3541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  35073, Training Accuracy:  73.4%, Loss: 0.4020\n",
      "Optimization Iteration:  35137, Training Accuracy:  82.8%, Loss: 0.2676\n",
      "Optimization Iteration:  35201, Training Accuracy:  71.9%, Loss: 0.3835\n",
      "Optimization Iteration:  35265, Training Accuracy:  79.7%, Loss: 0.3961\n",
      "Optimization Iteration:  35329, Training Accuracy:  73.4%, Loss: 0.4614\n",
      "Optimization Iteration:  35393, Training Accuracy:  78.1%, Loss: 0.3305\n",
      "Optimization Iteration:  35457, Training Accuracy:  76.6%, Loss: 0.4180\n",
      "Optimization Iteration:  35521, Training Accuracy:  71.9%, Loss: 0.3888\n",
      "Optimization Iteration:  35585, Training Accuracy:  79.7%, Loss: 0.3964\n",
      "Optimization Iteration:  35649, Training Accuracy:  70.3%, Loss: 0.5010\n",
      "Optimization Iteration:  35713, Training Accuracy:  81.2%, Loss: 0.4333\n",
      "Optimization Iteration:  35777, Training Accuracy:  85.9%, Loss: 0.3420\n",
      "Optimization Iteration:  35841, Training Accuracy:  79.7%, Loss: 0.4115\n",
      "Optimization Iteration:  35905, Training Accuracy:  82.8%, Loss: 0.3416\n",
      "Optimization Iteration:  35969, Training Accuracy:  70.3%, Loss: 0.4451\n",
      "Optimization Iteration:  36033, Training Accuracy:  79.7%, Loss: 0.3504\n",
      "Optimization Iteration:  36097, Training Accuracy:  65.6%, Loss: 0.4547\n",
      "Optimization Iteration:  36161, Training Accuracy:  78.1%, Loss: 0.3439\n",
      "Optimization Iteration:  36225, Training Accuracy:  71.9%, Loss: 0.4040\n",
      "Optimization Iteration:  36289, Training Accuracy:  76.6%, Loss: 0.3452\n",
      "Optimization Iteration:  36353, Training Accuracy:  75.0%, Loss: 0.3818\n",
      "Optimization Iteration:  36417, Training Accuracy:  75.0%, Loss: 0.3676\n",
      "Optimization Iteration:  36481, Training Accuracy:  81.2%, Loss: 0.3456\n",
      "Optimization Iteration:  36545, Training Accuracy:  76.6%, Loss: 0.3989\n",
      "Optimization Iteration:  36609, Training Accuracy:  90.6%, Loss: 0.3292\n",
      "Optimization Iteration:  36673, Training Accuracy:  73.4%, Loss: 0.4437\n",
      "Optimization Iteration:  36737, Training Accuracy:  81.2%, Loss: 0.3865\n",
      "Optimization Iteration:  36801, Training Accuracy:  84.4%, Loss: 0.3408\n",
      "Optimization Iteration:  36865, Training Accuracy:  70.3%, Loss: 0.4280\n",
      "Optimization Iteration:  36929, Training Accuracy:  79.7%, Loss: 0.3803\n",
      "Optimization Iteration:  36993, Training Accuracy:  79.7%, Loss: 0.3721\n",
      "Optimization Iteration:  37057, Training Accuracy:  81.2%, Loss: 0.3273\n",
      "Optimization Iteration:  37121, Training Accuracy:  76.6%, Loss: 0.3641\n",
      "Optimization Iteration:  37185, Training Accuracy:  71.9%, Loss: 0.4422\n",
      "Optimization Iteration:  37249, Training Accuracy:  73.4%, Loss: 0.4626\n",
      "Optimization Iteration:  37313, Training Accuracy:  78.1%, Loss: 0.3127\n",
      "Optimization Iteration:  37377, Training Accuracy:  71.9%, Loss: 0.5804\n",
      "Optimization Iteration:  37441, Training Accuracy:  75.0%, Loss: 0.3422\n",
      "Optimization Iteration:  37505, Training Accuracy:  67.2%, Loss: 0.4123\n",
      "Optimization Iteration:  37569, Training Accuracy:  71.9%, Loss: 0.4265\n",
      "Optimization Iteration:  37633, Training Accuracy:  70.3%, Loss: 0.4201\n",
      "Optimization Iteration:  37697, Training Accuracy:  79.7%, Loss: 0.3820\n",
      "Optimization Iteration:  37761, Training Accuracy:  70.3%, Loss: 0.3948\n",
      "Optimization Iteration:  37825, Training Accuracy:  76.6%, Loss: 0.3796\n",
      "Optimization Iteration:  37889, Training Accuracy:  75.0%, Loss: 0.3984\n",
      "Optimization Iteration:  37953, Training Accuracy:  79.7%, Loss: 0.3468\n",
      "Optimization Iteration:  38017, Training Accuracy:  70.3%, Loss: 0.4117\n",
      "Optimization Iteration:  38081, Training Accuracy:  76.6%, Loss: 0.3819\n",
      "Optimization Iteration:  38145, Training Accuracy:  73.4%, Loss: 0.3889\n",
      "Optimization Iteration:  38209, Training Accuracy:  78.1%, Loss: 0.3694\n",
      "Optimization Iteration:  38273, Training Accuracy:  76.6%, Loss: 0.3512\n",
      "Optimization Iteration:  38337, Training Accuracy:  87.5%, Loss: 0.3157\n",
      "Optimization Iteration:  38401, Training Accuracy:  78.1%, Loss: 0.3606\n",
      "Optimization Iteration:  38465, Training Accuracy:  78.1%, Loss: 0.3983\n",
      "Optimization Iteration:  38529, Training Accuracy:  75.0%, Loss: 0.3951\n",
      "Optimization Iteration:  38593, Training Accuracy:  78.1%, Loss: 0.5159\n",
      "Optimization Iteration:  38657, Training Accuracy:  68.8%, Loss: 0.4725\n",
      "Optimization Iteration:  38721, Training Accuracy:  71.9%, Loss: 0.3609\n",
      "Optimization Iteration:  38785, Training Accuracy:  65.6%, Loss: 0.4387\n",
      "Optimization Iteration:  38849, Training Accuracy:  73.4%, Loss: 0.3149\n",
      "Optimization Iteration:  38913, Training Accuracy:  78.1%, Loss: 0.3873\n",
      "Optimization Iteration:  38977, Training Accuracy:  78.1%, Loss: 0.3760\n",
      "Optimization Iteration:  39041, Training Accuracy:  82.8%, Loss: 0.3270\n",
      "Optimization Iteration:  39105, Training Accuracy:  78.1%, Loss: 0.4081\n",
      "Optimization Iteration:  39169, Training Accuracy:  60.9%, Loss: 0.4537\n",
      "Optimization Iteration:  39233, Training Accuracy:  70.3%, Loss: 0.4793\n",
      "Optimization Iteration:  39297, Training Accuracy:  79.7%, Loss: 0.4073\n",
      "Optimization Iteration:  39361, Training Accuracy:  78.1%, Loss: 0.3436\n",
      "Optimization Iteration:  39425, Training Accuracy:  79.7%, Loss: 0.4133\n",
      "Optimization Iteration:  39489, Training Accuracy:  81.2%, Loss: 0.2963\n",
      "Optimization Iteration:  39553, Training Accuracy:  76.6%, Loss: 0.4064\n",
      "Optimization Iteration:  39617, Training Accuracy:  76.6%, Loss: 0.4371\n",
      "Optimization Iteration:  39681, Training Accuracy:  65.6%, Loss: 0.3947\n",
      "Optimization Iteration:  39745, Training Accuracy:  70.3%, Loss: 0.4285\n",
      "Optimization Iteration:  39809, Training Accuracy:  62.5%, Loss: 0.4686\n",
      "Optimization Iteration:  39873, Training Accuracy:  71.9%, Loss: 0.4389\n",
      "Optimization Iteration:  39937, Training Accuracy:  67.2%, Loss: 0.4783\n",
      "Optimization Iteration:  40001, Training Accuracy:  71.9%, Loss: 0.4771\n",
      "Optimization Iteration:  40065, Training Accuracy:  68.8%, Loss: 0.3861\n",
      "Optimization Iteration:  40129, Training Accuracy:  84.4%, Loss: 0.3520\n",
      "Optimization Iteration:  40193, Training Accuracy:  79.7%, Loss: 0.3881\n",
      "Optimization Iteration:  40257, Training Accuracy:  78.1%, Loss: 0.3671\n",
      "Optimization Iteration:  40321, Training Accuracy:  70.3%, Loss: 0.4275\n",
      "Optimization Iteration:  40385, Training Accuracy:  73.4%, Loss: 0.4294\n",
      "Optimization Iteration:  40449, Training Accuracy:  76.6%, Loss: 0.4012\n",
      "Optimization Iteration:  40513, Training Accuracy:  82.8%, Loss: 0.3569\n",
      "Optimization Iteration:  40577, Training Accuracy:  76.6%, Loss: 0.4087\n",
      "Optimization Iteration:  40641, Training Accuracy:  82.8%, Loss: 0.3919\n",
      "Optimization Iteration:  40705, Training Accuracy:  75.0%, Loss: 0.3339\n",
      "Optimization Iteration:  40769, Training Accuracy:  75.0%, Loss: 0.3357\n",
      "Optimization Iteration:  40833, Training Accuracy:  81.2%, Loss: 0.3463\n",
      "Optimization Iteration:  40897, Training Accuracy:  75.0%, Loss: 0.3577\n",
      "Optimization Iteration:  40961, Training Accuracy:  78.1%, Loss: 0.3435\n",
      "Optimization Iteration:  41025, Training Accuracy:  73.4%, Loss: 0.3737\n",
      "Optimization Iteration:  41089, Training Accuracy:  78.1%, Loss: 0.4204\n",
      "Optimization Iteration:  41153, Training Accuracy:  75.0%, Loss: 0.3913\n",
      "Optimization Iteration:  41217, Training Accuracy:  84.4%, Loss: 0.4047\n",
      "Optimization Iteration:  41281, Training Accuracy:  65.6%, Loss: 0.4758\n",
      "Optimization Iteration:  41345, Training Accuracy:  75.0%, Loss: 0.4332\n",
      "Optimization Iteration:  41409, Training Accuracy:  81.2%, Loss: 0.3792\n",
      "Optimization Iteration:  41473, Training Accuracy:  79.7%, Loss: 0.3842\n",
      "Optimization Iteration:  41537, Training Accuracy:  76.6%, Loss: 0.3962\n",
      "Optimization Iteration:  41601, Training Accuracy:  76.6%, Loss: 0.3843\n",
      "Optimization Iteration:  41665, Training Accuracy:  76.6%, Loss: 0.3576\n",
      "Optimization Iteration:  41729, Training Accuracy:  84.4%, Loss: 0.2934\n",
      "Optimization Iteration:  41793, Training Accuracy:  71.9%, Loss: 0.4585\n",
      "Optimization Iteration:  41857, Training Accuracy:  68.8%, Loss: 0.4792\n",
      "Optimization Iteration:  41921, Training Accuracy:  82.8%, Loss: 0.3190\n",
      "Optimization Iteration:  41985, Training Accuracy:  67.2%, Loss: 0.4369\n",
      "Optimization Iteration:  42049, Training Accuracy:  67.2%, Loss: 0.4532\n",
      "Optimization Iteration:  42113, Training Accuracy:  75.0%, Loss: 0.3570\n",
      "Optimization Iteration:  42177, Training Accuracy:  71.9%, Loss: 0.4459\n",
      "Optimization Iteration:  42241, Training Accuracy:  68.8%, Loss: 0.4671\n",
      "Optimization Iteration:  42305, Training Accuracy:  81.2%, Loss: 0.4780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  42369, Training Accuracy:  73.4%, Loss: 0.3557\n",
      "Optimization Iteration:  42433, Training Accuracy:  71.9%, Loss: 0.4428\n",
      "Optimization Iteration:  42497, Training Accuracy:  71.9%, Loss: 0.3700\n",
      "Optimization Iteration:  42561, Training Accuracy:  82.8%, Loss: 0.3598\n",
      "Optimization Iteration:  42625, Training Accuracy:  76.6%, Loss: 0.4051\n",
      "Optimization Iteration:  42689, Training Accuracy:  78.1%, Loss: 0.3337\n",
      "Optimization Iteration:  42753, Training Accuracy:  76.6%, Loss: 0.4040\n",
      "Optimization Iteration:  42817, Training Accuracy:  82.8%, Loss: 0.3298\n",
      "Optimization Iteration:  42881, Training Accuracy:  71.9%, Loss: 0.4549\n",
      "Optimization Iteration:  42945, Training Accuracy:  84.4%, Loss: 0.3527\n",
      "Optimization Iteration:  43009, Training Accuracy:  68.8%, Loss: 0.4397\n",
      "Optimization Iteration:  43073, Training Accuracy:  81.2%, Loss: 0.3965\n",
      "Optimization Iteration:  43137, Training Accuracy:  79.7%, Loss: 0.3732\n",
      "Optimization Iteration:  43201, Training Accuracy:  76.6%, Loss: 0.4274\n",
      "Optimization Iteration:  43265, Training Accuracy:  78.1%, Loss: 0.4052\n",
      "Optimization Iteration:  43329, Training Accuracy:  81.2%, Loss: 0.3809\n",
      "Optimization Iteration:  43393, Training Accuracy:  75.0%, Loss: 0.4140\n",
      "Optimization Iteration:  43457, Training Accuracy:  81.2%, Loss: 0.2864\n",
      "Optimization Iteration:  43521, Training Accuracy:  75.0%, Loss: 0.3576\n",
      "Optimization Iteration:  43585, Training Accuracy:  76.6%, Loss: 0.3516\n",
      "Optimization Iteration:  43649, Training Accuracy:  76.6%, Loss: 0.4655\n",
      "Optimization Iteration:  43713, Training Accuracy:  78.1%, Loss: 0.3571\n",
      "Optimization Iteration:  43777, Training Accuracy:  79.7%, Loss: 0.2705\n",
      "Optimization Iteration:  43841, Training Accuracy:  81.2%, Loss: 0.3428\n",
      "Optimization Iteration:  43905, Training Accuracy:  79.7%, Loss: 0.3703\n",
      "Optimization Iteration:  43969, Training Accuracy:  71.9%, Loss: 0.3797\n",
      "Optimization Iteration:  44033, Training Accuracy:  73.4%, Loss: 0.3868\n",
      "Optimization Iteration:  44097, Training Accuracy:  82.8%, Loss: 0.4008\n",
      "Optimization Iteration:  44161, Training Accuracy:  76.6%, Loss: 0.3532\n",
      "Optimization Iteration:  44225, Training Accuracy:  75.0%, Loss: 0.4400\n",
      "Optimization Iteration:  44289, Training Accuracy:  73.4%, Loss: 0.4756\n",
      "Optimization Iteration:  44353, Training Accuracy:  68.8%, Loss: 0.4851\n",
      "Optimization Iteration:  44417, Training Accuracy:  70.3%, Loss: 0.4155\n",
      "Optimization Iteration:  44481, Training Accuracy:  81.2%, Loss: 0.3646\n",
      "Optimization Iteration:  44545, Training Accuracy:  82.8%, Loss: 0.3033\n",
      "Optimization Iteration:  44609, Training Accuracy:  84.4%, Loss: 0.3209\n",
      "Optimization Iteration:  44673, Training Accuracy:  81.2%, Loss: 0.3772\n",
      "Optimization Iteration:  44737, Training Accuracy:  73.4%, Loss: 0.4076\n",
      "Optimization Iteration:  44801, Training Accuracy:  81.2%, Loss: 0.4179\n",
      "Optimization Iteration:  44865, Training Accuracy:  68.8%, Loss: 0.4696\n",
      "Optimization Iteration:  44929, Training Accuracy:  79.7%, Loss: 0.3419\n",
      "Optimization Iteration:  44993, Training Accuracy:  67.2%, Loss: 0.4175\n",
      "Optimization Iteration:  45057, Training Accuracy:  82.8%, Loss: 0.4162\n",
      "Optimization Iteration:  45121, Training Accuracy:  76.6%, Loss: 0.3655\n",
      "Optimization Iteration:  45185, Training Accuracy:  85.9%, Loss: 0.3066\n",
      "Optimization Iteration:  45249, Training Accuracy:  81.2%, Loss: 0.3838\n",
      "Optimization Iteration:  45313, Training Accuracy:  76.6%, Loss: 0.4050\n",
      "Optimization Iteration:  45377, Training Accuracy:  71.9%, Loss: 0.4680\n",
      "Optimization Iteration:  45441, Training Accuracy:  82.8%, Loss: 0.3753\n",
      "Optimization Iteration:  45505, Training Accuracy:  75.0%, Loss: 0.3950\n",
      "Optimization Iteration:  45569, Training Accuracy:  68.8%, Loss: 0.4894\n",
      "Optimization Iteration:  45633, Training Accuracy:  79.7%, Loss: 0.4275\n",
      "Optimization Iteration:  45697, Training Accuracy:  79.7%, Loss: 0.3069\n",
      "Optimization Iteration:  45761, Training Accuracy:  92.2%, Loss: 0.3442\n",
      "Optimization Iteration:  45825, Training Accuracy:  78.1%, Loss: 0.3415\n",
      "Optimization Iteration:  45889, Training Accuracy:  75.0%, Loss: 0.3759\n",
      "Optimization Iteration:  45953, Training Accuracy:  84.4%, Loss: 0.3419\n",
      "Optimization Iteration:  46017, Training Accuracy:  75.0%, Loss: 0.3910\n",
      "Optimization Iteration:  46081, Training Accuracy:  79.7%, Loss: 0.3805\n",
      "Optimization Iteration:  46145, Training Accuracy:  70.3%, Loss: 0.4421\n",
      "Optimization Iteration:  46209, Training Accuracy:  78.1%, Loss: 0.4028\n",
      "Optimization Iteration:  46273, Training Accuracy:  78.1%, Loss: 0.4126\n",
      "Optimization Iteration:  46337, Training Accuracy:  78.1%, Loss: 0.4172\n",
      "Optimization Iteration:  46401, Training Accuracy:  79.7%, Loss: 0.3333\n",
      "Optimization Iteration:  46465, Training Accuracy:  79.7%, Loss: 0.4186\n",
      "Optimization Iteration:  46529, Training Accuracy:  68.8%, Loss: 0.4663\n",
      "Optimization Iteration:  46593, Training Accuracy:  75.0%, Loss: 0.3749\n",
      "Optimization Iteration:  46657, Training Accuracy:  76.6%, Loss: 0.3888\n",
      "Optimization Iteration:  46721, Training Accuracy:  76.6%, Loss: 0.3767\n",
      "Optimization Iteration:  46785, Training Accuracy:  70.3%, Loss: 0.4285\n",
      "Optimization Iteration:  46849, Training Accuracy:  79.7%, Loss: 0.3663\n",
      "Optimization Iteration:  46913, Training Accuracy:  79.7%, Loss: 0.3547\n",
      "Optimization Iteration:  46977, Training Accuracy:  75.0%, Loss: 0.3718\n",
      "Optimization Iteration:  47041, Training Accuracy:  81.2%, Loss: 0.3231\n",
      "Optimization Iteration:  47105, Training Accuracy:  70.3%, Loss: 0.4720\n",
      "Optimization Iteration:  47169, Training Accuracy:  82.8%, Loss: 0.3628\n",
      "Optimization Iteration:  47233, Training Accuracy:  76.6%, Loss: 0.3983\n",
      "Optimization Iteration:  47297, Training Accuracy:  70.3%, Loss: 0.3676\n",
      "Optimization Iteration:  47361, Training Accuracy:  78.1%, Loss: 0.3029\n",
      "Optimization Iteration:  47425, Training Accuracy:  85.9%, Loss: 0.3068\n",
      "Optimization Iteration:  47489, Training Accuracy:  70.3%, Loss: 0.4441\n",
      "Optimization Iteration:  47553, Training Accuracy:  75.0%, Loss: 0.4309\n",
      "Optimization Iteration:  47617, Training Accuracy:  78.1%, Loss: 0.4271\n",
      "Optimization Iteration:  47681, Training Accuracy:  87.5%, Loss: 0.3550\n",
      "Optimization Iteration:  47745, Training Accuracy:  75.0%, Loss: 0.4404\n",
      "Optimization Iteration:  47809, Training Accuracy:  67.2%, Loss: 0.4912\n",
      "Optimization Iteration:  47873, Training Accuracy:  84.4%, Loss: 0.2760\n",
      "Optimization Iteration:  47937, Training Accuracy:  70.3%, Loss: 0.4346\n",
      "Optimization Iteration:  48001, Training Accuracy:  79.7%, Loss: 0.3275\n",
      "Optimization Iteration:  48065, Training Accuracy:  71.9%, Loss: 0.3944\n",
      "Optimization Iteration:  48129, Training Accuracy:  68.8%, Loss: 0.5133\n",
      "Optimization Iteration:  48193, Training Accuracy:  67.2%, Loss: 0.5048\n",
      "Optimization Iteration:  48257, Training Accuracy:  78.1%, Loss: 0.3833\n",
      "Optimization Iteration:  48321, Training Accuracy:  79.7%, Loss: 0.3426\n",
      "Optimization Iteration:  48385, Training Accuracy:  68.8%, Loss: 0.3346\n",
      "Optimization Iteration:  48449, Training Accuracy:  75.0%, Loss: 0.3966\n",
      "Optimization Iteration:  48513, Training Accuracy:  68.8%, Loss: 0.4027\n",
      "Optimization Iteration:  48577, Training Accuracy:  73.4%, Loss: 0.5051\n",
      "Optimization Iteration:  48641, Training Accuracy:  82.8%, Loss: 0.3200\n",
      "Optimization Iteration:  48705, Training Accuracy:  65.6%, Loss: 0.4083\n",
      "Optimization Iteration:  48769, Training Accuracy:  78.1%, Loss: 0.4051\n",
      "Optimization Iteration:  48833, Training Accuracy:  75.0%, Loss: 0.3963\n",
      "Optimization Iteration:  48897, Training Accuracy:  73.4%, Loss: 0.3905\n",
      "Optimization Iteration:  48961, Training Accuracy:  78.1%, Loss: 0.4560\n",
      "Optimization Iteration:  49025, Training Accuracy:  75.0%, Loss: 0.3960\n",
      "Optimization Iteration:  49089, Training Accuracy:  75.0%, Loss: 0.4011\n",
      "Optimization Iteration:  49153, Training Accuracy:  82.8%, Loss: 0.3635\n",
      "Optimization Iteration:  49217, Training Accuracy:  71.9%, Loss: 0.3973\n",
      "Optimization Iteration:  49281, Training Accuracy:  76.6%, Loss: 0.3931\n",
      "Optimization Iteration:  49345, Training Accuracy:  81.2%, Loss: 0.3953\n",
      "Optimization Iteration:  49409, Training Accuracy:  78.1%, Loss: 0.4515\n",
      "Optimization Iteration:  49473, Training Accuracy:  68.8%, Loss: 0.4543\n",
      "Optimization Iteration:  49537, Training Accuracy:  71.9%, Loss: 0.3847\n",
      "Optimization Iteration:  49601, Training Accuracy:  78.1%, Loss: 0.4013\n",
      "Optimization Iteration:  49665, Training Accuracy:  73.4%, Loss: 0.3761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  49729, Training Accuracy:  71.9%, Loss: 0.4352\n",
      "Optimization Iteration:  49793, Training Accuracy:  71.9%, Loss: 0.3806\n",
      "Optimization Iteration:  49857, Training Accuracy:  60.9%, Loss: 0.5256\n",
      "Optimization Iteration:  49921, Training Accuracy:  76.6%, Loss: 0.4255\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 22\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  73.4%, Loss: 0.4363\n",
      "Optimization Iteration:    129, Training Accuracy:  71.9%, Loss: 0.4160\n",
      "Optimization Iteration:    193, Training Accuracy:  76.6%, Loss: 0.4129\n",
      "Optimization Iteration:    257, Training Accuracy:  76.6%, Loss: 0.3744\n",
      "Optimization Iteration:    321, Training Accuracy:  73.4%, Loss: 0.4154\n",
      "Optimization Iteration:    385, Training Accuracy:  81.2%, Loss: 0.3156\n",
      "Optimization Iteration:    449, Training Accuracy:  81.2%, Loss: 0.3090\n",
      "Optimization Iteration:    513, Training Accuracy:  67.2%, Loss: 0.4765\n",
      "Optimization Iteration:    577, Training Accuracy:  65.6%, Loss: 0.5106\n",
      "Optimization Iteration:    641, Training Accuracy:  82.8%, Loss: 0.3535\n",
      "Optimization Iteration:    705, Training Accuracy:  75.0%, Loss: 0.4767\n",
      "Optimization Iteration:    769, Training Accuracy:  78.1%, Loss: 0.3857\n",
      "Optimization Iteration:    833, Training Accuracy:  75.0%, Loss: 0.3882\n",
      "Optimization Iteration:    897, Training Accuracy:  78.1%, Loss: 0.3305\n",
      "Optimization Iteration:    961, Training Accuracy:  78.1%, Loss: 0.3384\n",
      "Optimization Iteration:   1025, Training Accuracy:  81.2%, Loss: 0.3435\n",
      "Optimization Iteration:   1089, Training Accuracy:  71.9%, Loss: 0.3577\n",
      "Optimization Iteration:   1153, Training Accuracy:  78.1%, Loss: 0.4209\n",
      "Optimization Iteration:   1217, Training Accuracy:  71.9%, Loss: 0.4402\n",
      "Optimization Iteration:   1281, Training Accuracy:  81.2%, Loss: 0.4182\n",
      "Optimization Iteration:   1345, Training Accuracy:  78.1%, Loss: 0.3910\n",
      "Optimization Iteration:   1409, Training Accuracy:  78.1%, Loss: 0.3890\n",
      "Optimization Iteration:   1473, Training Accuracy:  73.4%, Loss: 0.4162\n",
      "Optimization Iteration:   1537, Training Accuracy:  70.3%, Loss: 0.3835\n",
      "Optimization Iteration:   1601, Training Accuracy:  81.2%, Loss: 0.2925\n",
      "Optimization Iteration:   1665, Training Accuracy:  82.8%, Loss: 0.3595\n",
      "Optimization Iteration:   1729, Training Accuracy:  76.6%, Loss: 0.3486\n",
      "Optimization Iteration:   1793, Training Accuracy:  73.4%, Loss: 0.4087\n",
      "Optimization Iteration:   1857, Training Accuracy:  76.6%, Loss: 0.4040\n",
      "Optimization Iteration:   1921, Training Accuracy:  75.0%, Loss: 0.4739\n",
      "Optimization Iteration:   1985, Training Accuracy:  73.4%, Loss: 0.3740\n",
      "Optimization Iteration:   2049, Training Accuracy:  85.9%, Loss: 0.2878\n",
      "Optimization Iteration:   2113, Training Accuracy:  78.1%, Loss: 0.3034\n",
      "Optimization Iteration:   2177, Training Accuracy:  76.6%, Loss: 0.3795\n",
      "Optimization Iteration:   2241, Training Accuracy:  71.9%, Loss: 0.4500\n",
      "Optimization Iteration:   2305, Training Accuracy:  76.6%, Loss: 0.3501\n",
      "Optimization Iteration:   2369, Training Accuracy:  75.0%, Loss: 0.4821\n",
      "Optimization Iteration:   2433, Training Accuracy:  68.8%, Loss: 0.4339\n",
      "Optimization Iteration:   2497, Training Accuracy:  75.0%, Loss: 0.3367\n",
      "Optimization Iteration:   2561, Training Accuracy:  70.3%, Loss: 0.3996\n",
      "Optimization Iteration:   2625, Training Accuracy:  78.1%, Loss: 0.3614\n",
      "Optimization Iteration:   2689, Training Accuracy:  82.8%, Loss: 0.3600\n",
      "Optimization Iteration:   2753, Training Accuracy:  81.2%, Loss: 0.3192\n",
      "Optimization Iteration:   2817, Training Accuracy:  73.4%, Loss: 0.4408\n",
      "Optimization Iteration:   2881, Training Accuracy:  71.9%, Loss: 0.4109\n",
      "Optimization Iteration:   2945, Training Accuracy:  70.3%, Loss: 0.5556\n",
      "Optimization Iteration:   3009, Training Accuracy:  73.4%, Loss: 0.4437\n",
      "Optimization Iteration:   3073, Training Accuracy:  78.1%, Loss: 0.3465\n",
      "Optimization Iteration:   3137, Training Accuracy:  78.1%, Loss: 0.3696\n",
      "Optimization Iteration:   3201, Training Accuracy:  81.2%, Loss: 0.3758\n",
      "Optimization Iteration:   3265, Training Accuracy:  81.2%, Loss: 0.3605\n",
      "Optimization Iteration:   3329, Training Accuracy:  79.7%, Loss: 0.3865\n",
      "Optimization Iteration:   3393, Training Accuracy:  76.6%, Loss: 0.3808\n",
      "Optimization Iteration:   3457, Training Accuracy:  79.7%, Loss: 0.3434\n",
      "Optimization Iteration:   3521, Training Accuracy:  75.0%, Loss: 0.4355\n",
      "Optimization Iteration:   3585, Training Accuracy:  68.8%, Loss: 0.5041\n",
      "Optimization Iteration:   3649, Training Accuracy:  73.4%, Loss: 0.4257\n",
      "Optimization Iteration:   3713, Training Accuracy:  71.9%, Loss: 0.3767\n",
      "Optimization Iteration:   3777, Training Accuracy:  71.9%, Loss: 0.4467\n",
      "Optimization Iteration:   3841, Training Accuracy:  73.4%, Loss: 0.3880\n",
      "Optimization Iteration:   3905, Training Accuracy:  84.4%, Loss: 0.3345\n",
      "Optimization Iteration:   3969, Training Accuracy:  70.3%, Loss: 0.4261\n",
      "Optimization Iteration:   4033, Training Accuracy:  82.8%, Loss: 0.3537\n",
      "Optimization Iteration:   4097, Training Accuracy:  71.9%, Loss: 0.3977\n",
      "Optimization Iteration:   4161, Training Accuracy:  68.8%, Loss: 0.4642\n",
      "Optimization Iteration:   4225, Training Accuracy:  78.1%, Loss: 0.3508\n",
      "Optimization Iteration:   4289, Training Accuracy:  75.0%, Loss: 0.3474\n",
      "Optimization Iteration:   4353, Training Accuracy:  82.8%, Loss: 0.3892\n",
      "Optimization Iteration:   4417, Training Accuracy:  67.2%, Loss: 0.4125\n",
      "Optimization Iteration:   4481, Training Accuracy:  76.6%, Loss: 0.3456\n",
      "Optimization Iteration:   4545, Training Accuracy:  75.0%, Loss: 0.3677\n",
      "Optimization Iteration:   4609, Training Accuracy:  81.2%, Loss: 0.3530\n",
      "Optimization Iteration:   4673, Training Accuracy:  79.7%, Loss: 0.3641\n",
      "Optimization Iteration:   4737, Training Accuracy:  75.0%, Loss: 0.3925\n",
      "Optimization Iteration:   4801, Training Accuracy:  71.9%, Loss: 0.4008\n",
      "Optimization Iteration:   4865, Training Accuracy:  73.4%, Loss: 0.4060\n",
      "Optimization Iteration:   4929, Training Accuracy:  82.8%, Loss: 0.3585\n",
      "Optimization Iteration:   4993, Training Accuracy:  78.1%, Loss: 0.4149\n",
      "Optimization Iteration:   5057, Training Accuracy:  60.9%, Loss: 0.5410\n",
      "Optimization Iteration:   5121, Training Accuracy:  76.6%, Loss: 0.3718\n",
      "Optimization Iteration:   5185, Training Accuracy:  71.9%, Loss: 0.3896\n",
      "Optimization Iteration:   5249, Training Accuracy:  64.1%, Loss: 0.5105\n",
      "Optimization Iteration:   5313, Training Accuracy:  76.6%, Loss: 0.3800\n",
      "Optimization Iteration:   5377, Training Accuracy:  82.8%, Loss: 0.3780\n",
      "Optimization Iteration:   5441, Training Accuracy:  75.0%, Loss: 0.3899\n",
      "Optimization Iteration:   5505, Training Accuracy:  78.1%, Loss: 0.3603\n",
      "Optimization Iteration:   5569, Training Accuracy:  79.7%, Loss: 0.3709\n",
      "Optimization Iteration:   5633, Training Accuracy:  76.6%, Loss: 0.3688\n",
      "Optimization Iteration:   5697, Training Accuracy:  70.3%, Loss: 0.5201\n",
      "Optimization Iteration:   5761, Training Accuracy:  81.2%, Loss: 0.3586\n",
      "Optimization Iteration:   5825, Training Accuracy:  70.3%, Loss: 0.4408\n",
      "Optimization Iteration:   5889, Training Accuracy:  85.9%, Loss: 0.3184\n",
      "Optimization Iteration:   5953, Training Accuracy:  76.6%, Loss: 0.3790\n",
      "Optimization Iteration:   6017, Training Accuracy:  60.9%, Loss: 0.5057\n",
      "Optimization Iteration:   6081, Training Accuracy:  76.6%, Loss: 0.3526\n",
      "Optimization Iteration:   6145, Training Accuracy:  62.5%, Loss: 0.5456\n",
      "Optimization Iteration:   6209, Training Accuracy:  84.4%, Loss: 0.2905\n",
      "Optimization Iteration:   6273, Training Accuracy:  75.0%, Loss: 0.4504\n",
      "Optimization Iteration:   6337, Training Accuracy:  78.1%, Loss: 0.4108\n",
      "Optimization Iteration:   6401, Training Accuracy:  78.1%, Loss: 0.3869\n",
      "Optimization Iteration:   6465, Training Accuracy:  87.5%, Loss: 0.3212\n",
      "Optimization Iteration:   6529, Training Accuracy:  81.2%, Loss: 0.4296\n",
      "Optimization Iteration:   6593, Training Accuracy:  71.9%, Loss: 0.3775\n",
      "Optimization Iteration:   6657, Training Accuracy:  67.2%, Loss: 0.4380\n",
      "Optimization Iteration:   6721, Training Accuracy:  71.9%, Loss: 0.3708\n",
      "Optimization Iteration:   6785, Training Accuracy:  70.3%, Loss: 0.4229\n",
      "Optimization Iteration:   6849, Training Accuracy:  71.9%, Loss: 0.3566\n",
      "Optimization Iteration:   6913, Training Accuracy:  84.4%, Loss: 0.3104\n",
      "Optimization Iteration:   6977, Training Accuracy:  78.1%, Loss: 0.4302\n",
      "Optimization Iteration:   7041, Training Accuracy:  79.7%, Loss: 0.3721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7105, Training Accuracy:  78.1%, Loss: 0.3374\n",
      "Optimization Iteration:   7169, Training Accuracy:  81.2%, Loss: 0.3504\n",
      "Optimization Iteration:   7233, Training Accuracy:  73.4%, Loss: 0.4397\n",
      "Optimization Iteration:   7297, Training Accuracy:  81.2%, Loss: 0.4090\n",
      "Optimization Iteration:   7361, Training Accuracy:  75.0%, Loss: 0.3400\n",
      "Optimization Iteration:   7425, Training Accuracy:  73.4%, Loss: 0.3750\n",
      "Optimization Iteration:   7489, Training Accuracy:  75.0%, Loss: 0.4101\n",
      "Optimization Iteration:   7553, Training Accuracy:  76.6%, Loss: 0.3980\n",
      "Optimization Iteration:   7617, Training Accuracy:  79.7%, Loss: 0.3557\n",
      "Optimization Iteration:   7681, Training Accuracy:  79.7%, Loss: 0.3581\n",
      "Optimization Iteration:   7745, Training Accuracy:  78.1%, Loss: 0.3942\n",
      "Optimization Iteration:   7809, Training Accuracy:  76.6%, Loss: 0.3936\n",
      "Optimization Iteration:   7873, Training Accuracy:  75.0%, Loss: 0.3279\n",
      "Optimization Iteration:   7937, Training Accuracy:  79.7%, Loss: 0.3848\n",
      "Optimization Iteration:   8001, Training Accuracy:  75.0%, Loss: 0.3861\n",
      "Optimization Iteration:   8065, Training Accuracy:  81.2%, Loss: 0.3848\n",
      "Optimization Iteration:   8129, Training Accuracy:  75.0%, Loss: 0.3717\n",
      "Optimization Iteration:   8193, Training Accuracy:  70.3%, Loss: 0.3931\n",
      "Optimization Iteration:   8257, Training Accuracy:  76.6%, Loss: 0.4239\n",
      "Optimization Iteration:   8321, Training Accuracy:  60.9%, Loss: 0.4142\n",
      "Optimization Iteration:   8385, Training Accuracy:  70.3%, Loss: 0.4005\n",
      "Optimization Iteration:   8449, Training Accuracy:  67.2%, Loss: 0.4816\n",
      "Optimization Iteration:   8513, Training Accuracy:  90.6%, Loss: 0.2979\n",
      "Optimization Iteration:   8577, Training Accuracy:  78.1%, Loss: 0.4590\n",
      "Optimization Iteration:   8641, Training Accuracy:  78.1%, Loss: 0.3919\n",
      "Optimization Iteration:   8705, Training Accuracy:  73.4%, Loss: 0.3996\n",
      "Optimization Iteration:   8769, Training Accuracy:  60.9%, Loss: 0.5179\n",
      "Optimization Iteration:   8833, Training Accuracy:  70.3%, Loss: 0.4120\n",
      "Optimization Iteration:   8897, Training Accuracy:  71.9%, Loss: 0.4199\n",
      "Optimization Iteration:   8961, Training Accuracy:  71.9%, Loss: 0.4148\n",
      "Optimization Iteration:   9025, Training Accuracy:  68.8%, Loss: 0.4893\n",
      "Optimization Iteration:   9089, Training Accuracy:  67.2%, Loss: 0.4778\n",
      "Optimization Iteration:   9153, Training Accuracy:  76.6%, Loss: 0.4000\n",
      "Optimization Iteration:   9217, Training Accuracy:  78.1%, Loss: 0.3774\n",
      "Optimization Iteration:   9281, Training Accuracy:  79.7%, Loss: 0.3565\n",
      "Optimization Iteration:   9345, Training Accuracy:  85.9%, Loss: 0.4339\n",
      "Optimization Iteration:   9409, Training Accuracy:  62.5%, Loss: 0.4908\n",
      "Optimization Iteration:   9473, Training Accuracy:  71.9%, Loss: 0.3781\n",
      "Optimization Iteration:   9537, Training Accuracy:  81.2%, Loss: 0.3480\n",
      "Optimization Iteration:   9601, Training Accuracy:  76.6%, Loss: 0.3852\n",
      "Optimization Iteration:   9665, Training Accuracy:  65.6%, Loss: 0.4560\n",
      "Optimization Iteration:   9729, Training Accuracy:  78.1%, Loss: 0.4155\n",
      "Optimization Iteration:   9793, Training Accuracy:  76.6%, Loss: 0.3428\n",
      "Optimization Iteration:   9857, Training Accuracy:  68.8%, Loss: 0.4155\n",
      "Optimization Iteration:   9921, Training Accuracy:  76.6%, Loss: 0.3548\n",
      "Optimization Iteration:   9985, Training Accuracy:  73.4%, Loss: 0.4172\n",
      "Optimization Iteration:  10049, Training Accuracy:  75.0%, Loss: 0.3780\n",
      "Optimization Iteration:  10113, Training Accuracy:  75.0%, Loss: 0.3698\n",
      "Optimization Iteration:  10177, Training Accuracy:  79.7%, Loss: 0.4540\n",
      "Optimization Iteration:  10241, Training Accuracy:  76.6%, Loss: 0.4413\n",
      "Optimization Iteration:  10305, Training Accuracy:  75.0%, Loss: 0.3847\n",
      "Optimization Iteration:  10369, Training Accuracy:  81.2%, Loss: 0.3719\n",
      "Optimization Iteration:  10433, Training Accuracy:  81.2%, Loss: 0.3877\n",
      "Optimization Iteration:  10497, Training Accuracy:  70.3%, Loss: 0.4640\n",
      "Optimization Iteration:  10561, Training Accuracy:  82.8%, Loss: 0.2819\n",
      "Optimization Iteration:  10625, Training Accuracy:  84.4%, Loss: 0.2964\n",
      "Optimization Iteration:  10689, Training Accuracy:  73.4%, Loss: 0.4058\n",
      "Optimization Iteration:  10753, Training Accuracy:  64.1%, Loss: 0.5065\n",
      "Optimization Iteration:  10817, Training Accuracy:  70.3%, Loss: 0.4200\n",
      "Optimization Iteration:  10881, Training Accuracy:  70.3%, Loss: 0.3722\n",
      "Optimization Iteration:  10945, Training Accuracy:  81.2%, Loss: 0.4120\n",
      "Optimization Iteration:  11009, Training Accuracy:  82.8%, Loss: 0.3164\n",
      "Optimization Iteration:  11073, Training Accuracy:  78.1%, Loss: 0.3202\n",
      "Optimization Iteration:  11137, Training Accuracy:  70.3%, Loss: 0.4547\n",
      "Optimization Iteration:  11201, Training Accuracy:  78.1%, Loss: 0.3543\n",
      "Optimization Iteration:  11265, Training Accuracy:  81.2%, Loss: 0.3336\n",
      "Optimization Iteration:  11329, Training Accuracy:  82.8%, Loss: 0.4637\n",
      "Optimization Iteration:  11393, Training Accuracy:  79.7%, Loss: 0.5072\n",
      "Optimization Iteration:  11457, Training Accuracy:  70.3%, Loss: 0.4445\n",
      "Optimization Iteration:  11521, Training Accuracy:  71.9%, Loss: 0.3773\n",
      "Optimization Iteration:  11585, Training Accuracy:  75.0%, Loss: 0.3718\n",
      "Optimization Iteration:  11649, Training Accuracy:  78.1%, Loss: 0.3654\n",
      "Optimization Iteration:  11713, Training Accuracy:  68.8%, Loss: 0.4150\n",
      "Optimization Iteration:  11777, Training Accuracy:  68.8%, Loss: 0.4811\n",
      "Optimization Iteration:  11841, Training Accuracy:  78.1%, Loss: 0.3836\n",
      "Optimization Iteration:  11905, Training Accuracy:  76.6%, Loss: 0.3885\n",
      "Optimization Iteration:  11969, Training Accuracy:  81.2%, Loss: 0.3636\n",
      "Optimization Iteration:  12033, Training Accuracy:  79.7%, Loss: 0.3641\n",
      "Optimization Iteration:  12097, Training Accuracy:  73.4%, Loss: 0.4051\n",
      "Optimization Iteration:  12161, Training Accuracy:  79.7%, Loss: 0.4210\n",
      "Optimization Iteration:  12225, Training Accuracy:  79.7%, Loss: 0.3639\n",
      "Optimization Iteration:  12289, Training Accuracy:  82.8%, Loss: 0.3800\n",
      "Optimization Iteration:  12353, Training Accuracy:  87.5%, Loss: 0.3497\n",
      "Optimization Iteration:  12417, Training Accuracy:  79.7%, Loss: 0.3959\n",
      "Optimization Iteration:  12481, Training Accuracy:  78.1%, Loss: 0.3928\n",
      "Optimization Iteration:  12545, Training Accuracy:  75.0%, Loss: 0.4429\n",
      "Optimization Iteration:  12609, Training Accuracy:  76.6%, Loss: 0.3672\n",
      "Optimization Iteration:  12673, Training Accuracy:  73.4%, Loss: 0.3591\n",
      "Optimization Iteration:  12737, Training Accuracy:  70.3%, Loss: 0.4472\n",
      "Optimization Iteration:  12801, Training Accuracy:  76.6%, Loss: 0.3761\n",
      "Optimization Iteration:  12865, Training Accuracy:  79.7%, Loss: 0.4089\n",
      "Optimization Iteration:  12929, Training Accuracy:  70.3%, Loss: 0.4250\n",
      "Optimization Iteration:  12993, Training Accuracy:  76.6%, Loss: 0.3245\n",
      "Optimization Iteration:  13057, Training Accuracy:  68.8%, Loss: 0.4707\n",
      "Optimization Iteration:  13121, Training Accuracy:  75.0%, Loss: 0.3249\n",
      "Optimization Iteration:  13185, Training Accuracy:  75.0%, Loss: 0.4167\n",
      "Optimization Iteration:  13249, Training Accuracy:  73.4%, Loss: 0.4406\n",
      "Optimization Iteration:  13313, Training Accuracy:  76.6%, Loss: 0.5126\n",
      "Optimization Iteration:  13377, Training Accuracy:  71.9%, Loss: 0.4180\n",
      "Optimization Iteration:  13441, Training Accuracy:  70.3%, Loss: 0.4238\n",
      "Optimization Iteration:  13505, Training Accuracy:  78.1%, Loss: 0.3876\n",
      "Optimization Iteration:  13569, Training Accuracy:  85.9%, Loss: 0.2821\n",
      "Optimization Iteration:  13633, Training Accuracy:  70.3%, Loss: 0.4308\n",
      "Optimization Iteration:  13697, Training Accuracy:  75.0%, Loss: 0.3576\n",
      "Optimization Iteration:  13761, Training Accuracy:  82.8%, Loss: 0.3343\n",
      "Optimization Iteration:  13825, Training Accuracy:  81.2%, Loss: 0.4033\n",
      "Optimization Iteration:  13889, Training Accuracy:  71.9%, Loss: 0.5007\n",
      "Optimization Iteration:  13953, Training Accuracy:  79.7%, Loss: 0.3253\n",
      "Optimization Iteration:  14017, Training Accuracy:  78.1%, Loss: 0.3698\n",
      "Optimization Iteration:  14081, Training Accuracy:  70.3%, Loss: 0.3947\n",
      "Optimization Iteration:  14145, Training Accuracy:  75.0%, Loss: 0.4115\n",
      "Optimization Iteration:  14209, Training Accuracy:  87.5%, Loss: 0.3752\n",
      "Optimization Iteration:  14273, Training Accuracy:  71.9%, Loss: 0.4307\n",
      "Optimization Iteration:  14337, Training Accuracy:  79.7%, Loss: 0.3364\n",
      "Optimization Iteration:  14401, Training Accuracy:  85.9%, Loss: 0.2892\n",
      "Optimization Iteration:  14465, Training Accuracy:  64.1%, Loss: 0.4210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  14529, Training Accuracy:  71.9%, Loss: 0.4020\n",
      "Optimization Iteration:  14593, Training Accuracy:  79.7%, Loss: 0.3337\n",
      "Optimization Iteration:  14657, Training Accuracy:  73.4%, Loss: 0.4563\n",
      "Optimization Iteration:  14721, Training Accuracy:  76.6%, Loss: 0.4135\n",
      "Optimization Iteration:  14785, Training Accuracy:  81.2%, Loss: 0.3734\n",
      "Optimization Iteration:  14849, Training Accuracy:  71.9%, Loss: 0.4105\n",
      "Optimization Iteration:  14913, Training Accuracy:  79.7%, Loss: 0.3476\n",
      "Optimization Iteration:  14977, Training Accuracy:  82.8%, Loss: 0.3919\n",
      "Optimization Iteration:  15041, Training Accuracy:  82.8%, Loss: 0.3164\n",
      "Optimization Iteration:  15105, Training Accuracy:  76.6%, Loss: 0.3307\n",
      "Optimization Iteration:  15169, Training Accuracy:  82.8%, Loss: 0.3479\n",
      "Optimization Iteration:  15233, Training Accuracy:  73.4%, Loss: 0.3969\n",
      "Optimization Iteration:  15297, Training Accuracy:  78.1%, Loss: 0.4082\n",
      "Optimization Iteration:  15361, Training Accuracy:  82.8%, Loss: 0.3570\n",
      "Optimization Iteration:  15425, Training Accuracy:  75.0%, Loss: 0.4398\n",
      "Optimization Iteration:  15489, Training Accuracy:  67.2%, Loss: 0.4496\n",
      "Optimization Iteration:  15553, Training Accuracy:  75.0%, Loss: 0.3212\n",
      "Optimization Iteration:  15617, Training Accuracy:  79.7%, Loss: 0.3605\n",
      "Optimization Iteration:  15681, Training Accuracy:  76.6%, Loss: 0.3225\n",
      "Optimization Iteration:  15745, Training Accuracy:  82.8%, Loss: 0.3338\n",
      "Optimization Iteration:  15809, Training Accuracy:  68.8%, Loss: 0.4744\n",
      "Optimization Iteration:  15873, Training Accuracy:  71.9%, Loss: 0.4145\n",
      "Optimization Iteration:  15937, Training Accuracy:  73.4%, Loss: 0.3477\n",
      "Optimization Iteration:  16001, Training Accuracy:  68.8%, Loss: 0.4842\n",
      "Optimization Iteration:  16065, Training Accuracy:  68.8%, Loss: 0.4585\n",
      "Optimization Iteration:  16129, Training Accuracy:  84.4%, Loss: 0.3826\n",
      "Optimization Iteration:  16193, Training Accuracy:  71.9%, Loss: 0.4727\n",
      "Optimization Iteration:  16257, Training Accuracy:  76.6%, Loss: 0.3657\n",
      "Optimization Iteration:  16321, Training Accuracy:  76.6%, Loss: 0.4215\n",
      "Optimization Iteration:  16385, Training Accuracy:  78.1%, Loss: 0.3752\n",
      "Optimization Iteration:  16449, Training Accuracy:  79.7%, Loss: 0.3879\n",
      "Optimization Iteration:  16513, Training Accuracy:  79.7%, Loss: 0.4517\n",
      "Optimization Iteration:  16577, Training Accuracy:  78.1%, Loss: 0.3494\n",
      "Optimization Iteration:  16641, Training Accuracy:  78.1%, Loss: 0.4171\n",
      "Optimization Iteration:  16705, Training Accuracy:  76.6%, Loss: 0.4220\n",
      "Optimization Iteration:  16769, Training Accuracy:  82.8%, Loss: 0.3855\n",
      "Optimization Iteration:  16833, Training Accuracy:  76.6%, Loss: 0.3611\n",
      "Optimization Iteration:  16897, Training Accuracy:  78.1%, Loss: 0.3643\n",
      "Optimization Iteration:  16961, Training Accuracy:  82.8%, Loss: 0.3803\n",
      "Optimization Iteration:  17025, Training Accuracy:  73.4%, Loss: 0.3850\n",
      "Optimization Iteration:  17089, Training Accuracy:  81.2%, Loss: 0.3736\n",
      "Optimization Iteration:  17153, Training Accuracy:  76.6%, Loss: 0.3793\n",
      "Optimization Iteration:  17217, Training Accuracy:  76.6%, Loss: 0.5113\n",
      "Optimization Iteration:  17281, Training Accuracy:  67.2%, Loss: 0.4074\n",
      "Optimization Iteration:  17345, Training Accuracy:  81.2%, Loss: 0.3516\n",
      "Optimization Iteration:  17409, Training Accuracy:  70.3%, Loss: 0.4053\n",
      "Optimization Iteration:  17473, Training Accuracy:  62.5%, Loss: 0.5205\n",
      "Optimization Iteration:  17537, Training Accuracy:  73.4%, Loss: 0.4392\n",
      "Optimization Iteration:  17601, Training Accuracy:  79.7%, Loss: 0.4039\n",
      "Optimization Iteration:  17665, Training Accuracy:  76.6%, Loss: 0.3761\n",
      "Optimization Iteration:  17729, Training Accuracy:  75.0%, Loss: 0.3673\n",
      "Optimization Iteration:  17793, Training Accuracy:  65.6%, Loss: 0.3921\n",
      "Optimization Iteration:  17857, Training Accuracy:  78.1%, Loss: 0.3663\n",
      "Optimization Iteration:  17921, Training Accuracy:  92.2%, Loss: 0.2380\n",
      "Optimization Iteration:  17985, Training Accuracy:  81.2%, Loss: 0.2654\n",
      "Optimization Iteration:  18049, Training Accuracy:  81.2%, Loss: 0.3996\n",
      "Optimization Iteration:  18113, Training Accuracy:  68.8%, Loss: 0.4643\n",
      "Optimization Iteration:  18177, Training Accuracy:  73.4%, Loss: 0.4008\n",
      "Optimization Iteration:  18241, Training Accuracy:  71.9%, Loss: 0.3688\n",
      "Optimization Iteration:  18305, Training Accuracy:  67.2%, Loss: 0.4172\n",
      "Optimization Iteration:  18369, Training Accuracy:  75.0%, Loss: 0.3261\n",
      "Optimization Iteration:  18433, Training Accuracy:  75.0%, Loss: 0.4294\n",
      "Optimization Iteration:  18497, Training Accuracy:  73.4%, Loss: 0.3751\n",
      "Optimization Iteration:  18561, Training Accuracy:  76.6%, Loss: 0.3669\n",
      "Optimization Iteration:  18625, Training Accuracy:  76.6%, Loss: 0.4562\n",
      "Optimization Iteration:  18689, Training Accuracy:  60.9%, Loss: 0.4873\n",
      "Optimization Iteration:  18753, Training Accuracy:  78.1%, Loss: 0.3843\n",
      "Optimization Iteration:  18817, Training Accuracy:  79.7%, Loss: 0.3360\n",
      "Optimization Iteration:  18881, Training Accuracy:  73.4%, Loss: 0.4081\n",
      "Optimization Iteration:  18945, Training Accuracy:  68.8%, Loss: 0.4196\n",
      "Optimization Iteration:  19009, Training Accuracy:  76.6%, Loss: 0.4150\n",
      "Optimization Iteration:  19073, Training Accuracy:  78.1%, Loss: 0.4171\n",
      "Optimization Iteration:  19137, Training Accuracy:  65.6%, Loss: 0.4735\n",
      "Optimization Iteration:  19201, Training Accuracy:  68.8%, Loss: 0.3998\n",
      "Optimization Iteration:  19265, Training Accuracy:  81.2%, Loss: 0.3802\n",
      "Optimization Iteration:  19329, Training Accuracy:  70.3%, Loss: 0.4214\n",
      "Optimization Iteration:  19393, Training Accuracy:  75.0%, Loss: 0.3898\n",
      "Optimization Iteration:  19457, Training Accuracy:  71.9%, Loss: 0.4472\n",
      "Optimization Iteration:  19521, Training Accuracy:  71.9%, Loss: 0.4132\n",
      "Optimization Iteration:  19585, Training Accuracy:  71.9%, Loss: 0.4084\n",
      "Optimization Iteration:  19649, Training Accuracy:  84.4%, Loss: 0.3901\n",
      "Optimization Iteration:  19713, Training Accuracy:  79.7%, Loss: 0.3658\n",
      "Optimization Iteration:  19777, Training Accuracy:  81.2%, Loss: 0.3586\n",
      "Optimization Iteration:  19841, Training Accuracy:  75.0%, Loss: 0.3839\n",
      "Optimization Iteration:  19905, Training Accuracy:  76.6%, Loss: 0.4214\n",
      "Optimization Iteration:  19969, Training Accuracy:  79.7%, Loss: 0.3254\n",
      "Optimization Iteration:  20033, Training Accuracy:  84.4%, Loss: 0.3859\n",
      "Optimization Iteration:  20097, Training Accuracy:  70.3%, Loss: 0.4453\n",
      "Optimization Iteration:  20161, Training Accuracy:  73.4%, Loss: 0.3621\n",
      "Optimization Iteration:  20225, Training Accuracy:  65.6%, Loss: 0.4354\n",
      "Optimization Iteration:  20289, Training Accuracy:  79.7%, Loss: 0.3609\n",
      "Optimization Iteration:  20353, Training Accuracy:  67.2%, Loss: 0.3913\n",
      "Optimization Iteration:  20417, Training Accuracy:  71.9%, Loss: 0.3959\n",
      "Optimization Iteration:  20481, Training Accuracy:  79.7%, Loss: 0.3930\n",
      "Optimization Iteration:  20545, Training Accuracy:  81.2%, Loss: 0.4590\n",
      "Optimization Iteration:  20609, Training Accuracy:  82.8%, Loss: 0.3823\n",
      "Optimization Iteration:  20673, Training Accuracy:  75.0%, Loss: 0.3867\n",
      "Optimization Iteration:  20737, Training Accuracy:  85.9%, Loss: 0.4035\n",
      "Optimization Iteration:  20801, Training Accuracy:  84.4%, Loss: 0.3212\n",
      "Optimization Iteration:  20865, Training Accuracy:  81.2%, Loss: 0.3728\n",
      "Optimization Iteration:  20929, Training Accuracy:  75.0%, Loss: 0.3808\n",
      "Optimization Iteration:  20993, Training Accuracy:  71.9%, Loss: 0.4497\n",
      "Optimization Iteration:  21057, Training Accuracy:  78.1%, Loss: 0.3597\n",
      "Optimization Iteration:  21121, Training Accuracy:  76.6%, Loss: 0.3502\n",
      "Optimization Iteration:  21185, Training Accuracy:  75.0%, Loss: 0.3991\n",
      "Optimization Iteration:  21249, Training Accuracy:  64.1%, Loss: 0.4823\n",
      "Optimization Iteration:  21313, Training Accuracy:  76.6%, Loss: 0.4331\n",
      "Optimization Iteration:  21377, Training Accuracy:  81.2%, Loss: 0.2957\n",
      "Optimization Iteration:  21441, Training Accuracy:  75.0%, Loss: 0.3430\n",
      "Optimization Iteration:  21505, Training Accuracy:  75.0%, Loss: 0.4415\n",
      "Optimization Iteration:  21569, Training Accuracy:  75.0%, Loss: 0.3372\n",
      "Optimization Iteration:  21633, Training Accuracy:  81.2%, Loss: 0.3499\n",
      "Optimization Iteration:  21697, Training Accuracy:  73.4%, Loss: 0.4586\n",
      "Optimization Iteration:  21761, Training Accuracy:  75.0%, Loss: 0.3137\n",
      "Optimization Iteration:  21825, Training Accuracy:  73.4%, Loss: 0.4251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  21889, Training Accuracy:  76.6%, Loss: 0.3391\n",
      "Optimization Iteration:  21953, Training Accuracy:  71.9%, Loss: 0.4861\n",
      "Optimization Iteration:  22017, Training Accuracy:  84.4%, Loss: 0.3533\n",
      "Optimization Iteration:  22081, Training Accuracy:  67.2%, Loss: 0.3988\n",
      "Optimization Iteration:  22145, Training Accuracy:  75.0%, Loss: 0.4459\n",
      "Optimization Iteration:  22209, Training Accuracy:  75.0%, Loss: 0.5092\n",
      "Optimization Iteration:  22273, Training Accuracy:  81.2%, Loss: 0.3741\n",
      "Optimization Iteration:  22337, Training Accuracy:  79.7%, Loss: 0.3920\n",
      "Optimization Iteration:  22401, Training Accuracy:  78.1%, Loss: 0.4415\n",
      "Optimization Iteration:  22465, Training Accuracy:  76.6%, Loss: 0.3678\n",
      "Optimization Iteration:  22529, Training Accuracy:  75.0%, Loss: 0.3826\n",
      "Optimization Iteration:  22593, Training Accuracy:  79.7%, Loss: 0.4188\n",
      "Optimization Iteration:  22657, Training Accuracy:  75.0%, Loss: 0.4239\n",
      "Optimization Iteration:  22721, Training Accuracy:  78.1%, Loss: 0.4158\n",
      "Optimization Iteration:  22785, Training Accuracy:  84.4%, Loss: 0.3908\n",
      "Optimization Iteration:  22849, Training Accuracy:  78.1%, Loss: 0.4548\n",
      "Optimization Iteration:  22913, Training Accuracy:  71.9%, Loss: 0.3909\n",
      "Optimization Iteration:  22977, Training Accuracy:  70.3%, Loss: 0.3815\n",
      "Optimization Iteration:  23041, Training Accuracy:  75.0%, Loss: 0.3133\n",
      "Optimization Iteration:  23105, Training Accuracy:  73.4%, Loss: 0.3577\n",
      "Optimization Iteration:  23169, Training Accuracy:  78.1%, Loss: 0.3539\n",
      "Optimization Iteration:  23233, Training Accuracy:  76.6%, Loss: 0.4383\n",
      "Optimization Iteration:  23297, Training Accuracy:  71.9%, Loss: 0.4738\n",
      "Optimization Iteration:  23361, Training Accuracy:  81.2%, Loss: 0.3838\n",
      "Optimization Iteration:  23425, Training Accuracy:  79.7%, Loss: 0.4540\n",
      "Optimization Iteration:  23489, Training Accuracy:  79.7%, Loss: 0.3841\n",
      "Optimization Iteration:  23553, Training Accuracy:  82.8%, Loss: 0.2849\n",
      "Optimization Iteration:  23617, Training Accuracy:  73.4%, Loss: 0.4659\n",
      "Optimization Iteration:  23681, Training Accuracy:  73.4%, Loss: 0.4293\n",
      "Optimization Iteration:  23745, Training Accuracy:  81.2%, Loss: 0.2883\n",
      "Optimization Iteration:  23809, Training Accuracy:  71.9%, Loss: 0.4040\n",
      "Optimization Iteration:  23873, Training Accuracy:  75.0%, Loss: 0.3479\n",
      "Optimization Iteration:  23937, Training Accuracy:  68.8%, Loss: 0.4150\n",
      "Optimization Iteration:  24001, Training Accuracy:  78.1%, Loss: 0.2645\n",
      "Optimization Iteration:  24065, Training Accuracy:  82.8%, Loss: 0.3351\n",
      "Optimization Iteration:  24129, Training Accuracy:  81.2%, Loss: 0.3456\n",
      "Optimization Iteration:  24193, Training Accuracy:  70.3%, Loss: 0.4456\n",
      "Optimization Iteration:  24257, Training Accuracy:  79.7%, Loss: 0.3659\n",
      "Optimization Iteration:  24321, Training Accuracy:  78.1%, Loss: 0.4224\n",
      "Optimization Iteration:  24385, Training Accuracy:  81.2%, Loss: 0.3721\n",
      "Optimization Iteration:  24449, Training Accuracy:  68.8%, Loss: 0.3961\n",
      "Optimization Iteration:  24513, Training Accuracy:  75.0%, Loss: 0.3454\n",
      "Optimization Iteration:  24577, Training Accuracy:  71.9%, Loss: 0.4764\n",
      "Optimization Iteration:  24641, Training Accuracy:  73.4%, Loss: 0.4657\n",
      "Optimization Iteration:  24705, Training Accuracy:  82.8%, Loss: 0.3567\n",
      "Optimization Iteration:  24769, Training Accuracy:  68.8%, Loss: 0.4081\n",
      "Optimization Iteration:  24833, Training Accuracy:  75.0%, Loss: 0.3428\n",
      "Optimization Iteration:  24897, Training Accuracy:  71.9%, Loss: 0.3835\n",
      "Optimization Iteration:  24961, Training Accuracy:  78.1%, Loss: 0.3602\n",
      "Optimization Iteration:  25025, Training Accuracy:  75.0%, Loss: 0.4185\n",
      "Optimization Iteration:  25089, Training Accuracy:  76.6%, Loss: 0.3833\n",
      "Optimization Iteration:  25153, Training Accuracy:  73.4%, Loss: 0.3671\n",
      "Optimization Iteration:  25217, Training Accuracy:  60.9%, Loss: 0.5410\n",
      "Optimization Iteration:  25281, Training Accuracy:  67.2%, Loss: 0.4227\n",
      "Optimization Iteration:  25345, Training Accuracy:  76.6%, Loss: 0.4457\n",
      "Optimization Iteration:  25409, Training Accuracy:  70.3%, Loss: 0.4130\n",
      "Optimization Iteration:  25473, Training Accuracy:  70.3%, Loss: 0.4633\n",
      "Optimization Iteration:  25537, Training Accuracy:  79.7%, Loss: 0.3438\n",
      "Optimization Iteration:  25601, Training Accuracy:  71.9%, Loss: 0.4584\n",
      "Optimization Iteration:  25665, Training Accuracy:  82.8%, Loss: 0.3553\n",
      "Optimization Iteration:  25729, Training Accuracy:  78.1%, Loss: 0.3460\n",
      "Optimization Iteration:  25793, Training Accuracy:  84.4%, Loss: 0.3488\n",
      "Optimization Iteration:  25857, Training Accuracy:  67.2%, Loss: 0.5237\n",
      "Optimization Iteration:  25921, Training Accuracy:  79.7%, Loss: 0.4683\n",
      "Optimization Iteration:  25985, Training Accuracy:  70.3%, Loss: 0.4629\n",
      "Optimization Iteration:  26049, Training Accuracy:  82.8%, Loss: 0.3162\n",
      "Optimization Iteration:  26113, Training Accuracy:  78.1%, Loss: 0.3893\n",
      "Optimization Iteration:  26177, Training Accuracy:  85.9%, Loss: 0.3535\n",
      "Optimization Iteration:  26241, Training Accuracy:  76.6%, Loss: 0.3683\n",
      "Optimization Iteration:  26305, Training Accuracy:  76.6%, Loss: 0.4286\n",
      "Optimization Iteration:  26369, Training Accuracy:  84.4%, Loss: 0.3073\n",
      "Optimization Iteration:  26433, Training Accuracy:  71.9%, Loss: 0.4014\n",
      "Optimization Iteration:  26497, Training Accuracy:  82.8%, Loss: 0.4317\n",
      "Optimization Iteration:  26561, Training Accuracy:  81.2%, Loss: 0.3198\n",
      "Optimization Iteration:  26625, Training Accuracy:  78.1%, Loss: 0.3925\n",
      "Optimization Iteration:  26689, Training Accuracy:  73.4%, Loss: 0.4154\n",
      "Optimization Iteration:  26753, Training Accuracy:  78.1%, Loss: 0.4189\n",
      "Optimization Iteration:  26817, Training Accuracy:  78.1%, Loss: 0.3506\n",
      "Optimization Iteration:  26881, Training Accuracy:  84.4%, Loss: 0.2946\n",
      "Optimization Iteration:  26945, Training Accuracy:  76.6%, Loss: 0.4211\n",
      "Optimization Iteration:  27009, Training Accuracy:  84.4%, Loss: 0.2927\n",
      "Optimization Iteration:  27073, Training Accuracy:  81.2%, Loss: 0.3648\n",
      "Optimization Iteration:  27137, Training Accuracy:  84.4%, Loss: 0.3723\n",
      "Optimization Iteration:  27201, Training Accuracy:  82.8%, Loss: 0.2920\n",
      "Optimization Iteration:  27265, Training Accuracy:  84.4%, Loss: 0.3134\n",
      "Optimization Iteration:  27329, Training Accuracy:  68.8%, Loss: 0.4164\n",
      "Optimization Iteration:  27393, Training Accuracy:  78.1%, Loss: 0.4232\n",
      "Optimization Iteration:  27457, Training Accuracy:  79.7%, Loss: 0.3555\n",
      "Optimization Iteration:  27521, Training Accuracy:  76.6%, Loss: 0.4037\n",
      "Optimization Iteration:  27585, Training Accuracy:  71.9%, Loss: 0.3463\n",
      "Optimization Iteration:  27649, Training Accuracy:  82.8%, Loss: 0.3343\n",
      "Optimization Iteration:  27713, Training Accuracy:  75.0%, Loss: 0.4178\n",
      "Optimization Iteration:  27777, Training Accuracy:  73.4%, Loss: 0.4006\n",
      "Optimization Iteration:  27841, Training Accuracy:  78.1%, Loss: 0.4043\n",
      "Optimization Iteration:  27905, Training Accuracy:  73.4%, Loss: 0.3550\n",
      "Optimization Iteration:  27969, Training Accuracy:  76.6%, Loss: 0.4196\n",
      "Optimization Iteration:  28033, Training Accuracy:  76.6%, Loss: 0.4503\n",
      "Optimization Iteration:  28097, Training Accuracy:  81.2%, Loss: 0.3669\n",
      "Optimization Iteration:  28161, Training Accuracy:  89.1%, Loss: 0.2734\n",
      "Optimization Iteration:  28225, Training Accuracy:  79.7%, Loss: 0.3422\n",
      "Optimization Iteration:  28289, Training Accuracy:  79.7%, Loss: 0.3966\n",
      "Optimization Iteration:  28353, Training Accuracy:  76.6%, Loss: 0.3366\n",
      "Optimization Iteration:  28417, Training Accuracy:  81.2%, Loss: 0.3871\n",
      "Optimization Iteration:  28481, Training Accuracy:  73.4%, Loss: 0.3869\n",
      "Optimization Iteration:  28545, Training Accuracy:  68.8%, Loss: 0.4281\n",
      "Optimization Iteration:  28609, Training Accuracy:  75.0%, Loss: 0.3941\n",
      "Optimization Iteration:  28673, Training Accuracy:  73.4%, Loss: 0.4788\n",
      "Optimization Iteration:  28737, Training Accuracy:  76.6%, Loss: 0.4069\n",
      "Optimization Iteration:  28801, Training Accuracy:  81.2%, Loss: 0.3210\n",
      "Optimization Iteration:  28865, Training Accuracy:  75.0%, Loss: 0.3379\n",
      "Optimization Iteration:  28929, Training Accuracy:  71.9%, Loss: 0.3945\n",
      "Optimization Iteration:  28993, Training Accuracy:  71.9%, Loss: 0.4858\n",
      "Optimization Iteration:  29057, Training Accuracy:  71.9%, Loss: 0.4520\n",
      "Optimization Iteration:  29121, Training Accuracy:  78.1%, Loss: 0.3978\n",
      "Optimization Iteration:  29185, Training Accuracy:  75.0%, Loss: 0.3560\n",
      "Optimization Iteration:  29249, Training Accuracy:  75.0%, Loss: 0.4501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  29313, Training Accuracy:  75.0%, Loss: 0.3621\n",
      "Optimization Iteration:  29377, Training Accuracy:  76.6%, Loss: 0.3575\n",
      "Optimization Iteration:  29441, Training Accuracy:  81.2%, Loss: 0.3950\n",
      "Optimization Iteration:  29505, Training Accuracy:  76.6%, Loss: 0.4401\n",
      "Optimization Iteration:  29569, Training Accuracy:  73.4%, Loss: 0.4612\n",
      "Optimization Iteration:  29633, Training Accuracy:  73.4%, Loss: 0.3928\n",
      "Optimization Iteration:  29697, Training Accuracy:  71.9%, Loss: 0.3663\n",
      "Optimization Iteration:  29761, Training Accuracy:  81.2%, Loss: 0.3892\n",
      "Optimization Iteration:  29825, Training Accuracy:  76.6%, Loss: 0.4186\n",
      "Optimization Iteration:  29889, Training Accuracy:  78.1%, Loss: 0.4155\n",
      "Optimization Iteration:  29953, Training Accuracy:  65.6%, Loss: 0.4722\n",
      "Optimization Iteration:  30017, Training Accuracy:  79.7%, Loss: 0.3471\n",
      "Optimization Iteration:  30081, Training Accuracy:  81.2%, Loss: 0.3583\n",
      "Optimization Iteration:  30145, Training Accuracy:  82.8%, Loss: 0.3631\n",
      "Optimization Iteration:  30209, Training Accuracy:  76.6%, Loss: 0.3642\n",
      "Optimization Iteration:  30273, Training Accuracy:  73.4%, Loss: 0.4282\n",
      "Optimization Iteration:  30337, Training Accuracy:  75.0%, Loss: 0.4137\n",
      "Optimization Iteration:  30401, Training Accuracy:  79.7%, Loss: 0.3904\n",
      "Optimization Iteration:  30465, Training Accuracy:  68.8%, Loss: 0.5087\n",
      "Optimization Iteration:  30529, Training Accuracy:  76.6%, Loss: 0.3774\n",
      "Optimization Iteration:  30593, Training Accuracy:  70.3%, Loss: 0.4420\n",
      "Optimization Iteration:  30657, Training Accuracy:  84.4%, Loss: 0.3707\n",
      "Optimization Iteration:  30721, Training Accuracy:  73.4%, Loss: 0.4154\n",
      "Optimization Iteration:  30785, Training Accuracy:  71.9%, Loss: 0.3806\n",
      "Optimization Iteration:  30849, Training Accuracy:  76.6%, Loss: 0.4124\n",
      "Optimization Iteration:  30913, Training Accuracy:  76.6%, Loss: 0.3707\n",
      "Optimization Iteration:  30977, Training Accuracy:  67.2%, Loss: 0.4177\n",
      "Optimization Iteration:  31041, Training Accuracy:  71.9%, Loss: 0.4339\n",
      "Optimization Iteration:  31105, Training Accuracy:  82.8%, Loss: 0.3515\n",
      "Optimization Iteration:  31169, Training Accuracy:  78.1%, Loss: 0.3615\n",
      "Optimization Iteration:  31233, Training Accuracy:  78.1%, Loss: 0.3810\n",
      "Optimization Iteration:  31297, Training Accuracy:  81.2%, Loss: 0.3421\n",
      "Optimization Iteration:  31361, Training Accuracy:  76.6%, Loss: 0.3472\n",
      "Optimization Iteration:  31425, Training Accuracy:  82.8%, Loss: 0.3034\n",
      "Optimization Iteration:  31489, Training Accuracy:  78.1%, Loss: 0.3625\n",
      "Optimization Iteration:  31553, Training Accuracy:  71.9%, Loss: 0.4547\n",
      "Optimization Iteration:  31617, Training Accuracy:  73.4%, Loss: 0.3870\n",
      "Optimization Iteration:  31681, Training Accuracy:  78.1%, Loss: 0.4181\n",
      "Optimization Iteration:  31745, Training Accuracy:  78.1%, Loss: 0.4049\n",
      "Optimization Iteration:  31809, Training Accuracy:  65.6%, Loss: 0.4782\n",
      "Optimization Iteration:  31873, Training Accuracy:  73.4%, Loss: 0.3844\n",
      "Optimization Iteration:  31937, Training Accuracy:  68.8%, Loss: 0.4025\n",
      "Optimization Iteration:  32001, Training Accuracy:  65.6%, Loss: 0.4363\n",
      "Optimization Iteration:  32065, Training Accuracy:  75.0%, Loss: 0.3707\n",
      "Optimization Iteration:  32129, Training Accuracy:  71.9%, Loss: 0.3878\n",
      "Optimization Iteration:  32193, Training Accuracy:  75.0%, Loss: 0.4358\n",
      "Optimization Iteration:  32257, Training Accuracy:  79.7%, Loss: 0.4025\n",
      "Optimization Iteration:  32321, Training Accuracy:  73.4%, Loss: 0.3625\n",
      "Optimization Iteration:  32385, Training Accuracy:  73.4%, Loss: 0.4421\n",
      "Optimization Iteration:  32449, Training Accuracy:  65.6%, Loss: 0.4930\n",
      "Optimization Iteration:  32513, Training Accuracy:  76.6%, Loss: 0.3209\n",
      "Optimization Iteration:  32577, Training Accuracy:  79.7%, Loss: 0.3556\n",
      "Optimization Iteration:  32641, Training Accuracy:  75.0%, Loss: 0.4167\n",
      "Optimization Iteration:  32705, Training Accuracy:  78.1%, Loss: 0.4192\n",
      "Optimization Iteration:  32769, Training Accuracy:  76.6%, Loss: 0.3854\n",
      "Optimization Iteration:  32833, Training Accuracy:  70.3%, Loss: 0.4019\n",
      "Optimization Iteration:  32897, Training Accuracy:  73.4%, Loss: 0.4447\n",
      "Optimization Iteration:  32961, Training Accuracy:  78.1%, Loss: 0.4342\n",
      "Optimization Iteration:  33025, Training Accuracy:  75.0%, Loss: 0.3905\n",
      "Optimization Iteration:  33089, Training Accuracy:  71.9%, Loss: 0.4706\n",
      "Optimization Iteration:  33153, Training Accuracy:  73.4%, Loss: 0.4459\n",
      "Optimization Iteration:  33217, Training Accuracy:  70.3%, Loss: 0.3810\n",
      "Optimization Iteration:  33281, Training Accuracy:  71.9%, Loss: 0.4288\n",
      "Optimization Iteration:  33345, Training Accuracy:  78.1%, Loss: 0.3954\n",
      "Optimization Iteration:  33409, Training Accuracy:  78.1%, Loss: 0.4163\n",
      "Optimization Iteration:  33473, Training Accuracy:  76.6%, Loss: 0.4933\n",
      "Optimization Iteration:  33537, Training Accuracy:  78.1%, Loss: 0.3526\n",
      "Optimization Iteration:  33601, Training Accuracy:  82.8%, Loss: 0.3863\n",
      "Optimization Iteration:  33665, Training Accuracy:  73.4%, Loss: 0.4156\n",
      "Optimization Iteration:  33729, Training Accuracy:  81.2%, Loss: 0.4542\n",
      "Optimization Iteration:  33793, Training Accuracy:  65.6%, Loss: 0.4964\n",
      "Optimization Iteration:  33857, Training Accuracy:  73.4%, Loss: 0.3955\n",
      "Optimization Iteration:  33921, Training Accuracy:  75.0%, Loss: 0.3840\n",
      "Optimization Iteration:  33985, Training Accuracy:  73.4%, Loss: 0.4232\n",
      "Optimization Iteration:  34049, Training Accuracy:  71.9%, Loss: 0.5256\n",
      "Optimization Iteration:  34113, Training Accuracy:  79.7%, Loss: 0.3760\n",
      "Optimization Iteration:  34177, Training Accuracy:  82.8%, Loss: 0.3692\n",
      "Optimization Iteration:  34241, Training Accuracy:  82.8%, Loss: 0.4118\n",
      "Optimization Iteration:  34305, Training Accuracy:  79.7%, Loss: 0.4118\n",
      "Optimization Iteration:  34369, Training Accuracy:  85.9%, Loss: 0.3066\n",
      "Optimization Iteration:  34433, Training Accuracy:  82.8%, Loss: 0.3994\n",
      "Optimization Iteration:  34497, Training Accuracy:  81.2%, Loss: 0.3236\n",
      "Optimization Iteration:  34561, Training Accuracy:  76.6%, Loss: 0.4254\n",
      "Optimization Iteration:  34625, Training Accuracy:  71.9%, Loss: 0.4160\n",
      "Optimization Iteration:  34689, Training Accuracy:  76.6%, Loss: 0.3940\n",
      "Optimization Iteration:  34753, Training Accuracy:  71.9%, Loss: 0.4641\n",
      "Optimization Iteration:  34817, Training Accuracy:  71.9%, Loss: 0.3892\n",
      "Optimization Iteration:  34881, Training Accuracy:  81.2%, Loss: 0.2971\n",
      "Optimization Iteration:  34945, Training Accuracy:  84.4%, Loss: 0.3651\n",
      "Optimization Iteration:  35009, Training Accuracy:  78.1%, Loss: 0.3666\n",
      "Optimization Iteration:  35073, Training Accuracy:  76.6%, Loss: 0.4155\n",
      "Optimization Iteration:  35137, Training Accuracy:  68.8%, Loss: 0.4016\n",
      "Optimization Iteration:  35201, Training Accuracy:  75.0%, Loss: 0.3698\n",
      "Optimization Iteration:  35265, Training Accuracy:  76.6%, Loss: 0.3679\n",
      "Optimization Iteration:  35329, Training Accuracy:  76.6%, Loss: 0.3858\n",
      "Optimization Iteration:  35393, Training Accuracy:  76.6%, Loss: 0.4212\n",
      "Optimization Iteration:  35457, Training Accuracy:  73.4%, Loss: 0.3159\n",
      "Optimization Iteration:  35521, Training Accuracy:  76.6%, Loss: 0.3991\n",
      "Optimization Iteration:  35585, Training Accuracy:  79.7%, Loss: 0.3088\n",
      "Optimization Iteration:  35649, Training Accuracy:  71.9%, Loss: 0.4679\n",
      "Optimization Iteration:  35713, Training Accuracy:  75.0%, Loss: 0.4255\n",
      "Optimization Iteration:  35777, Training Accuracy:  75.0%, Loss: 0.3520\n",
      "Optimization Iteration:  35841, Training Accuracy:  78.1%, Loss: 0.4033\n",
      "Optimization Iteration:  35905, Training Accuracy:  82.8%, Loss: 0.4108\n",
      "Optimization Iteration:  35969, Training Accuracy:  75.0%, Loss: 0.4432\n",
      "Optimization Iteration:  36033, Training Accuracy:  71.9%, Loss: 0.3974\n",
      "Optimization Iteration:  36097, Training Accuracy:  70.3%, Loss: 0.4750\n",
      "Optimization Iteration:  36161, Training Accuracy:  78.1%, Loss: 0.4027\n",
      "Optimization Iteration:  36225, Training Accuracy:  82.8%, Loss: 0.3371\n",
      "Optimization Iteration:  36289, Training Accuracy:  76.6%, Loss: 0.3522\n",
      "Optimization Iteration:  36353, Training Accuracy:  79.7%, Loss: 0.3799\n",
      "Optimization Iteration:  36417, Training Accuracy:  70.3%, Loss: 0.3740\n",
      "Optimization Iteration:  36481, Training Accuracy:  76.6%, Loss: 0.3739\n",
      "Optimization Iteration:  36545, Training Accuracy:  75.0%, Loss: 0.4002\n",
      "Optimization Iteration:  36609, Training Accuracy:  82.8%, Loss: 0.3778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  36673, Training Accuracy:  75.0%, Loss: 0.3961\n",
      "Optimization Iteration:  36737, Training Accuracy:  75.0%, Loss: 0.3594\n",
      "Optimization Iteration:  36801, Training Accuracy:  87.5%, Loss: 0.3535\n",
      "Optimization Iteration:  36865, Training Accuracy:  67.2%, Loss: 0.4262\n",
      "Optimization Iteration:  36929, Training Accuracy:  81.2%, Loss: 0.3492\n",
      "Optimization Iteration:  36993, Training Accuracy:  73.4%, Loss: 0.3952\n",
      "Optimization Iteration:  37057, Training Accuracy:  81.2%, Loss: 0.3204\n",
      "Optimization Iteration:  37121, Training Accuracy:  87.5%, Loss: 0.2832\n",
      "Optimization Iteration:  37185, Training Accuracy:  71.9%, Loss: 0.3616\n",
      "Optimization Iteration:  37249, Training Accuracy:  76.6%, Loss: 0.4348\n",
      "Optimization Iteration:  37313, Training Accuracy:  84.4%, Loss: 0.3036\n",
      "Optimization Iteration:  37377, Training Accuracy:  75.0%, Loss: 0.4637\n",
      "Optimization Iteration:  37441, Training Accuracy:  76.6%, Loss: 0.3375\n",
      "Optimization Iteration:  37505, Training Accuracy:  75.0%, Loss: 0.4317\n",
      "Optimization Iteration:  37569, Training Accuracy:  71.9%, Loss: 0.4458\n",
      "Optimization Iteration:  37633, Training Accuracy:  73.4%, Loss: 0.4344\n",
      "Optimization Iteration:  37697, Training Accuracy:  81.2%, Loss: 0.3594\n",
      "Optimization Iteration:  37761, Training Accuracy:  73.4%, Loss: 0.4155\n",
      "Optimization Iteration:  37825, Training Accuracy:  71.9%, Loss: 0.4640\n",
      "Optimization Iteration:  37889, Training Accuracy:  76.6%, Loss: 0.4659\n",
      "Optimization Iteration:  37953, Training Accuracy:  79.7%, Loss: 0.3242\n",
      "Optimization Iteration:  38017, Training Accuracy:  67.2%, Loss: 0.4635\n",
      "Optimization Iteration:  38081, Training Accuracy:  68.8%, Loss: 0.4736\n",
      "Optimization Iteration:  38145, Training Accuracy:  79.7%, Loss: 0.2998\n",
      "Optimization Iteration:  38209, Training Accuracy:  84.4%, Loss: 0.3708\n",
      "Optimization Iteration:  38273, Training Accuracy:  81.2%, Loss: 0.3223\n",
      "Optimization Iteration:  38337, Training Accuracy:  89.1%, Loss: 0.2934\n",
      "Optimization Iteration:  38401, Training Accuracy:  76.6%, Loss: 0.4054\n",
      "Optimization Iteration:  38465, Training Accuracy:  73.4%, Loss: 0.3595\n",
      "Optimization Iteration:  38529, Training Accuracy:  79.7%, Loss: 0.3537\n",
      "Optimization Iteration:  38593, Training Accuracy:  76.6%, Loss: 0.4170\n",
      "Optimization Iteration:  38657, Training Accuracy:  78.1%, Loss: 0.4463\n",
      "Optimization Iteration:  38721, Training Accuracy:  75.0%, Loss: 0.3806\n",
      "Optimization Iteration:  38785, Training Accuracy:  67.2%, Loss: 0.4556\n",
      "Optimization Iteration:  38849, Training Accuracy:  78.1%, Loss: 0.3018\n",
      "Optimization Iteration:  38913, Training Accuracy:  78.1%, Loss: 0.3814\n",
      "Optimization Iteration:  38977, Training Accuracy:  67.2%, Loss: 0.4728\n",
      "Optimization Iteration:  39041, Training Accuracy:  73.4%, Loss: 0.3762\n",
      "Optimization Iteration:  39105, Training Accuracy:  75.0%, Loss: 0.4302\n",
      "Optimization Iteration:  39169, Training Accuracy:  64.1%, Loss: 0.5372\n",
      "Optimization Iteration:  39233, Training Accuracy:  70.3%, Loss: 0.4360\n",
      "Optimization Iteration:  39297, Training Accuracy:  76.6%, Loss: 0.4045\n",
      "Optimization Iteration:  39361, Training Accuracy:  78.1%, Loss: 0.3297\n",
      "Optimization Iteration:  39425, Training Accuracy:  71.9%, Loss: 0.4643\n",
      "Optimization Iteration:  39489, Training Accuracy:  78.1%, Loss: 0.3178\n",
      "Optimization Iteration:  39553, Training Accuracy:  70.3%, Loss: 0.4508\n",
      "Optimization Iteration:  39617, Training Accuracy:  71.9%, Loss: 0.4908\n",
      "Optimization Iteration:  39681, Training Accuracy:  73.4%, Loss: 0.3884\n",
      "Optimization Iteration:  39745, Training Accuracy:  84.4%, Loss: 0.3735\n",
      "Optimization Iteration:  39809, Training Accuracy:  70.3%, Loss: 0.4324\n",
      "Optimization Iteration:  39873, Training Accuracy:  75.0%, Loss: 0.4619\n",
      "Optimization Iteration:  39937, Training Accuracy:  82.8%, Loss: 0.4684\n",
      "Optimization Iteration:  40001, Training Accuracy:  75.0%, Loss: 0.3600\n",
      "Optimization Iteration:  40065, Training Accuracy:  78.1%, Loss: 0.3212\n",
      "Optimization Iteration:  40129, Training Accuracy:  75.0%, Loss: 0.4118\n",
      "Optimization Iteration:  40193, Training Accuracy:  81.2%, Loss: 0.3494\n",
      "Optimization Iteration:  40257, Training Accuracy:  84.4%, Loss: 0.3295\n",
      "Optimization Iteration:  40321, Training Accuracy:  65.6%, Loss: 0.4335\n",
      "Optimization Iteration:  40385, Training Accuracy:  71.9%, Loss: 0.4578\n",
      "Optimization Iteration:  40449, Training Accuracy:  73.4%, Loss: 0.4040\n",
      "Optimization Iteration:  40513, Training Accuracy:  81.2%, Loss: 0.3537\n",
      "Optimization Iteration:  40577, Training Accuracy:  76.6%, Loss: 0.3693\n",
      "Optimization Iteration:  40641, Training Accuracy:  79.7%, Loss: 0.3881\n",
      "Optimization Iteration:  40705, Training Accuracy:  68.8%, Loss: 0.3842\n",
      "Optimization Iteration:  40769, Training Accuracy:  84.4%, Loss: 0.2948\n",
      "Optimization Iteration:  40833, Training Accuracy:  87.5%, Loss: 0.3642\n",
      "Optimization Iteration:  40897, Training Accuracy:  82.8%, Loss: 0.3217\n",
      "Optimization Iteration:  40961, Training Accuracy:  75.0%, Loss: 0.3790\n",
      "Optimization Iteration:  41025, Training Accuracy:  84.4%, Loss: 0.3991\n",
      "Optimization Iteration:  41089, Training Accuracy:  81.2%, Loss: 0.3845\n",
      "Optimization Iteration:  41153, Training Accuracy:  78.1%, Loss: 0.4020\n",
      "Optimization Iteration:  41217, Training Accuracy:  75.0%, Loss: 0.3773\n",
      "Optimization Iteration:  41281, Training Accuracy:  82.8%, Loss: 0.3584\n",
      "Optimization Iteration:  41345, Training Accuracy:  78.1%, Loss: 0.4060\n",
      "Optimization Iteration:  41409, Training Accuracy:  70.3%, Loss: 0.4292\n",
      "Optimization Iteration:  41473, Training Accuracy:  75.0%, Loss: 0.3973\n",
      "Optimization Iteration:  41537, Training Accuracy:  78.1%, Loss: 0.4104\n",
      "Optimization Iteration:  41601, Training Accuracy:  73.4%, Loss: 0.4133\n",
      "Optimization Iteration:  41665, Training Accuracy:  75.0%, Loss: 0.3668\n",
      "Optimization Iteration:  41729, Training Accuracy:  75.0%, Loss: 0.3689\n",
      "Optimization Iteration:  41793, Training Accuracy:  82.8%, Loss: 0.3862\n",
      "Optimization Iteration:  41857, Training Accuracy:  68.8%, Loss: 0.4252\n",
      "Optimization Iteration:  41921, Training Accuracy:  81.2%, Loss: 0.3682\n",
      "Optimization Iteration:  41985, Training Accuracy:  76.6%, Loss: 0.4232\n",
      "Optimization Iteration:  42049, Training Accuracy:  73.4%, Loss: 0.4487\n",
      "Optimization Iteration:  42113, Training Accuracy:  70.3%, Loss: 0.4060\n",
      "Optimization Iteration:  42177, Training Accuracy:  65.6%, Loss: 0.4446\n",
      "Optimization Iteration:  42241, Training Accuracy:  76.6%, Loss: 0.4272\n",
      "Optimization Iteration:  42305, Training Accuracy:  76.6%, Loss: 0.4574\n",
      "Optimization Iteration:  42369, Training Accuracy:  65.6%, Loss: 0.3820\n",
      "Optimization Iteration:  42433, Training Accuracy:  82.8%, Loss: 0.3841\n",
      "Optimization Iteration:  42497, Training Accuracy:  79.7%, Loss: 0.4465\n",
      "Optimization Iteration:  42561, Training Accuracy:  81.2%, Loss: 0.3654\n",
      "Optimization Iteration:  42625, Training Accuracy:  79.7%, Loss: 0.3643\n",
      "Optimization Iteration:  42689, Training Accuracy:  62.5%, Loss: 0.4379\n",
      "Optimization Iteration:  42753, Training Accuracy:  76.6%, Loss: 0.4375\n",
      "Optimization Iteration:  42817, Training Accuracy:  84.4%, Loss: 0.3438\n",
      "Optimization Iteration:  42881, Training Accuracy:  78.1%, Loss: 0.3819\n",
      "Optimization Iteration:  42945, Training Accuracy:  79.7%, Loss: 0.3574\n",
      "Optimization Iteration:  43009, Training Accuracy:  71.9%, Loss: 0.4470\n",
      "Optimization Iteration:  43073, Training Accuracy:  76.6%, Loss: 0.3951\n",
      "Optimization Iteration:  43137, Training Accuracy:  81.2%, Loss: 0.4413\n",
      "Optimization Iteration:  43201, Training Accuracy:  76.6%, Loss: 0.4107\n",
      "Optimization Iteration:  43265, Training Accuracy:  73.4%, Loss: 0.3855\n",
      "Optimization Iteration:  43329, Training Accuracy:  81.2%, Loss: 0.4530\n",
      "Optimization Iteration:  43393, Training Accuracy:  79.7%, Loss: 0.3472\n",
      "Optimization Iteration:  43457, Training Accuracy:  71.9%, Loss: 0.5333\n",
      "Optimization Iteration:  43521, Training Accuracy:  75.0%, Loss: 0.4253\n",
      "Optimization Iteration:  43585, Training Accuracy:  81.2%, Loss: 0.3509\n",
      "Optimization Iteration:  43649, Training Accuracy:  76.6%, Loss: 0.4062\n",
      "Optimization Iteration:  43713, Training Accuracy:  75.0%, Loss: 0.4073\n",
      "Optimization Iteration:  43777, Training Accuracy:  76.6%, Loss: 0.3740\n",
      "Optimization Iteration:  43841, Training Accuracy:  78.1%, Loss: 0.4338\n",
      "Optimization Iteration:  43905, Training Accuracy:  79.7%, Loss: 0.3016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  43969, Training Accuracy:  75.0%, Loss: 0.4120\n",
      "Optimization Iteration:  44033, Training Accuracy:  70.3%, Loss: 0.4677\n",
      "Optimization Iteration:  44097, Training Accuracy:  82.8%, Loss: 0.3416\n",
      "Optimization Iteration:  44161, Training Accuracy:  79.7%, Loss: 0.3454\n",
      "Optimization Iteration:  44225, Training Accuracy:  76.6%, Loss: 0.3615\n",
      "Optimization Iteration:  44289, Training Accuracy:  79.7%, Loss: 0.3856\n",
      "Optimization Iteration:  44353, Training Accuracy:  71.9%, Loss: 0.4520\n",
      "Optimization Iteration:  44417, Training Accuracy:  82.8%, Loss: 0.3463\n",
      "Optimization Iteration:  44481, Training Accuracy:  75.0%, Loss: 0.3915\n",
      "Optimization Iteration:  44545, Training Accuracy:  79.7%, Loss: 0.3324\n",
      "Optimization Iteration:  44609, Training Accuracy:  79.7%, Loss: 0.3457\n",
      "Optimization Iteration:  44673, Training Accuracy:  79.7%, Loss: 0.4068\n",
      "Optimization Iteration:  44737, Training Accuracy:  78.1%, Loss: 0.4153\n",
      "Optimization Iteration:  44801, Training Accuracy:  70.3%, Loss: 0.4690\n",
      "Optimization Iteration:  44865, Training Accuracy:  70.3%, Loss: 0.4029\n",
      "Optimization Iteration:  44929, Training Accuracy:  82.8%, Loss: 0.3652\n",
      "Optimization Iteration:  44993, Training Accuracy:  76.6%, Loss: 0.3812\n",
      "Optimization Iteration:  45057, Training Accuracy:  73.4%, Loss: 0.4618\n",
      "Optimization Iteration:  45121, Training Accuracy:  78.1%, Loss: 0.3551\n",
      "Optimization Iteration:  45185, Training Accuracy:  84.4%, Loss: 0.2470\n",
      "Optimization Iteration:  45249, Training Accuracy:  78.1%, Loss: 0.4104\n",
      "Optimization Iteration:  45313, Training Accuracy:  78.1%, Loss: 0.3805\n",
      "Optimization Iteration:  45377, Training Accuracy:  71.9%, Loss: 0.4383\n",
      "Optimization Iteration:  45441, Training Accuracy:  76.6%, Loss: 0.4070\n",
      "Optimization Iteration:  45505, Training Accuracy:  71.9%, Loss: 0.4291\n",
      "Optimization Iteration:  45569, Training Accuracy:  68.8%, Loss: 0.5802\n",
      "Optimization Iteration:  45633, Training Accuracy:  79.7%, Loss: 0.4248\n",
      "Optimization Iteration:  45697, Training Accuracy:  76.6%, Loss: 0.3643\n",
      "Optimization Iteration:  45761, Training Accuracy:  81.2%, Loss: 0.3655\n",
      "Optimization Iteration:  45825, Training Accuracy:  76.6%, Loss: 0.3900\n",
      "Optimization Iteration:  45889, Training Accuracy:  70.3%, Loss: 0.3881\n",
      "Optimization Iteration:  45953, Training Accuracy:  70.3%, Loss: 0.3801\n",
      "Optimization Iteration:  46017, Training Accuracy:  70.3%, Loss: 0.4098\n",
      "Optimization Iteration:  46081, Training Accuracy:  73.4%, Loss: 0.3851\n",
      "Optimization Iteration:  46145, Training Accuracy:  76.6%, Loss: 0.4073\n",
      "Optimization Iteration:  46209, Training Accuracy:  79.7%, Loss: 0.3814\n",
      "Optimization Iteration:  46273, Training Accuracy:  70.3%, Loss: 0.4756\n",
      "Optimization Iteration:  46337, Training Accuracy:  71.9%, Loss: 0.4420\n",
      "Optimization Iteration:  46401, Training Accuracy:  81.2%, Loss: 0.3526\n",
      "Optimization Iteration:  46465, Training Accuracy:  79.7%, Loss: 0.3557\n",
      "Optimization Iteration:  46529, Training Accuracy:  76.6%, Loss: 0.3977\n",
      "Optimization Iteration:  46593, Training Accuracy:  71.9%, Loss: 0.3919\n",
      "Optimization Iteration:  46657, Training Accuracy:  71.9%, Loss: 0.4248\n",
      "Optimization Iteration:  46721, Training Accuracy:  79.7%, Loss: 0.4795\n",
      "Optimization Iteration:  46785, Training Accuracy:  73.4%, Loss: 0.4295\n",
      "Optimization Iteration:  46849, Training Accuracy:  70.3%, Loss: 0.4087\n",
      "Optimization Iteration:  46913, Training Accuracy:  70.3%, Loss: 0.3789\n",
      "Optimization Iteration:  46977, Training Accuracy:  78.1%, Loss: 0.4086\n",
      "Optimization Iteration:  47041, Training Accuracy:  76.6%, Loss: 0.3952\n",
      "Optimization Iteration:  47105, Training Accuracy:  79.7%, Loss: 0.4862\n",
      "Optimization Iteration:  47169, Training Accuracy:  76.6%, Loss: 0.4327\n",
      "Optimization Iteration:  47233, Training Accuracy:  68.8%, Loss: 0.4413\n",
      "Optimization Iteration:  47297, Training Accuracy:  73.4%, Loss: 0.3765\n",
      "Optimization Iteration:  47361, Training Accuracy:  82.8%, Loss: 0.3430\n",
      "Optimization Iteration:  47425, Training Accuracy:  84.4%, Loss: 0.3493\n",
      "Optimization Iteration:  47489, Training Accuracy:  82.8%, Loss: 0.3992\n",
      "Optimization Iteration:  47553, Training Accuracy:  73.4%, Loss: 0.3895\n",
      "Optimization Iteration:  47617, Training Accuracy:  71.9%, Loss: 0.4111\n",
      "Optimization Iteration:  47681, Training Accuracy:  68.8%, Loss: 0.3625\n",
      "Optimization Iteration:  47745, Training Accuracy:  76.6%, Loss: 0.4760\n",
      "Optimization Iteration:  47809, Training Accuracy:  70.3%, Loss: 0.4531\n",
      "Optimization Iteration:  47873, Training Accuracy:  82.8%, Loss: 0.3271\n",
      "Optimization Iteration:  47937, Training Accuracy:  79.7%, Loss: 0.3395\n",
      "Optimization Iteration:  48001, Training Accuracy:  79.7%, Loss: 0.3296\n",
      "Optimization Iteration:  48065, Training Accuracy:  75.0%, Loss: 0.3658\n",
      "Optimization Iteration:  48129, Training Accuracy:  76.6%, Loss: 0.4322\n",
      "Optimization Iteration:  48193, Training Accuracy:  68.8%, Loss: 0.4665\n",
      "Optimization Iteration:  48257, Training Accuracy:  81.2%, Loss: 0.3515\n",
      "Optimization Iteration:  48321, Training Accuracy:  81.2%, Loss: 0.3523\n",
      "Optimization Iteration:  48385, Training Accuracy:  73.4%, Loss: 0.3727\n",
      "Optimization Iteration:  48449, Training Accuracy:  76.6%, Loss: 0.3792\n",
      "Optimization Iteration:  48513, Training Accuracy:  81.2%, Loss: 0.3637\n",
      "Optimization Iteration:  48577, Training Accuracy:  73.4%, Loss: 0.4215\n",
      "Optimization Iteration:  48641, Training Accuracy:  81.2%, Loss: 0.3496\n",
      "Optimization Iteration:  48705, Training Accuracy:  81.2%, Loss: 0.3360\n",
      "Optimization Iteration:  48769, Training Accuracy:  73.4%, Loss: 0.3415\n",
      "Optimization Iteration:  48833, Training Accuracy:  82.8%, Loss: 0.3761\n",
      "Optimization Iteration:  48897, Training Accuracy:  70.3%, Loss: 0.4813\n",
      "Optimization Iteration:  48961, Training Accuracy:  75.0%, Loss: 0.4632\n",
      "Optimization Iteration:  49025, Training Accuracy:  73.4%, Loss: 0.4528\n",
      "Optimization Iteration:  49089, Training Accuracy:  75.0%, Loss: 0.4374\n",
      "Optimization Iteration:  49153, Training Accuracy:  73.4%, Loss: 0.3963\n",
      "Optimization Iteration:  49217, Training Accuracy:  68.8%, Loss: 0.4526\n",
      "Optimization Iteration:  49281, Training Accuracy:  76.6%, Loss: 0.4294\n",
      "Optimization Iteration:  49345, Training Accuracy:  82.8%, Loss: 0.3532\n",
      "Optimization Iteration:  49409, Training Accuracy:  71.9%, Loss: 0.3856\n",
      "Optimization Iteration:  49473, Training Accuracy:  89.1%, Loss: 0.3456\n",
      "Optimization Iteration:  49537, Training Accuracy:  75.0%, Loss: 0.4031\n",
      "Optimization Iteration:  49601, Training Accuracy:  75.0%, Loss: 0.4234\n",
      "Optimization Iteration:  49665, Training Accuracy:  79.7%, Loss: 0.3224\n",
      "Optimization Iteration:  49729, Training Accuracy:  70.3%, Loss: 0.4019\n",
      "Optimization Iteration:  49793, Training Accuracy:  75.0%, Loss: 0.3949\n",
      "Optimization Iteration:  49857, Training Accuracy:  75.0%, Loss: 0.4308\n",
      "Optimization Iteration:  49921, Training Accuracy:  71.9%, Loss: 0.4670\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 23\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  78.1%, Loss: 0.3816\n",
      "Optimization Iteration:    129, Training Accuracy:  68.8%, Loss: 0.4489\n",
      "Optimization Iteration:    193, Training Accuracy:  73.4%, Loss: 0.4172\n",
      "Optimization Iteration:    257, Training Accuracy:  75.0%, Loss: 0.3501\n",
      "Optimization Iteration:    321, Training Accuracy:  84.4%, Loss: 0.4112\n",
      "Optimization Iteration:    385, Training Accuracy:  73.4%, Loss: 0.3791\n",
      "Optimization Iteration:    449, Training Accuracy:  82.8%, Loss: 0.3400\n",
      "Optimization Iteration:    513, Training Accuracy:  76.6%, Loss: 0.4279\n",
      "Optimization Iteration:    577, Training Accuracy:  64.1%, Loss: 0.4778\n",
      "Optimization Iteration:    641, Training Accuracy:  81.2%, Loss: 0.3845\n",
      "Optimization Iteration:    705, Training Accuracy:  76.6%, Loss: 0.3967\n",
      "Optimization Iteration:    769, Training Accuracy:  65.6%, Loss: 0.4428\n",
      "Optimization Iteration:    833, Training Accuracy:  71.9%, Loss: 0.3895\n",
      "Optimization Iteration:    897, Training Accuracy:  78.1%, Loss: 0.3270\n",
      "Optimization Iteration:    961, Training Accuracy:  81.2%, Loss: 0.3247\n",
      "Optimization Iteration:   1025, Training Accuracy:  70.3%, Loss: 0.3805\n",
      "Optimization Iteration:   1089, Training Accuracy:  67.2%, Loss: 0.4354\n",
      "Optimization Iteration:   1153, Training Accuracy:  73.4%, Loss: 0.3828\n",
      "Optimization Iteration:   1217, Training Accuracy:  75.0%, Loss: 0.4126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   1281, Training Accuracy:  73.4%, Loss: 0.4039\n",
      "Optimization Iteration:   1345, Training Accuracy:  71.9%, Loss: 0.4242\n",
      "Optimization Iteration:   1409, Training Accuracy:  73.4%, Loss: 0.4452\n",
      "Optimization Iteration:   1473, Training Accuracy:  65.6%, Loss: 0.4487\n",
      "Optimization Iteration:   1537, Training Accuracy:  75.0%, Loss: 0.3615\n",
      "Optimization Iteration:   1601, Training Accuracy:  82.8%, Loss: 0.3580\n",
      "Optimization Iteration:   1665, Training Accuracy:  71.9%, Loss: 0.3402\n",
      "Optimization Iteration:   1729, Training Accuracy:  82.8%, Loss: 0.3381\n",
      "Optimization Iteration:   1793, Training Accuracy:  78.1%, Loss: 0.3637\n",
      "Optimization Iteration:   1857, Training Accuracy:  79.7%, Loss: 0.4394\n",
      "Optimization Iteration:   1921, Training Accuracy:  82.8%, Loss: 0.4058\n",
      "Optimization Iteration:   1985, Training Accuracy:  73.4%, Loss: 0.3774\n",
      "Optimization Iteration:   2049, Training Accuracy:  81.2%, Loss: 0.3179\n",
      "Optimization Iteration:   2113, Training Accuracy:  82.8%, Loss: 0.3785\n",
      "Optimization Iteration:   2177, Training Accuracy:  78.1%, Loss: 0.3227\n",
      "Optimization Iteration:   2241, Training Accuracy:  75.0%, Loss: 0.4504\n",
      "Optimization Iteration:   2305, Training Accuracy:  71.9%, Loss: 0.4013\n",
      "Optimization Iteration:   2369, Training Accuracy:  87.5%, Loss: 0.3767\n",
      "Optimization Iteration:   2433, Training Accuracy:  71.9%, Loss: 0.4247\n",
      "Optimization Iteration:   2497, Training Accuracy:  76.6%, Loss: 0.3590\n",
      "Optimization Iteration:   2561, Training Accuracy:  79.7%, Loss: 0.3038\n",
      "Optimization Iteration:   2625, Training Accuracy:  78.1%, Loss: 0.3839\n",
      "Optimization Iteration:   2689, Training Accuracy:  76.6%, Loss: 0.3545\n",
      "Optimization Iteration:   2753, Training Accuracy:  71.9%, Loss: 0.3741\n",
      "Optimization Iteration:   2817, Training Accuracy:  78.1%, Loss: 0.3518\n",
      "Optimization Iteration:   2881, Training Accuracy:  68.8%, Loss: 0.4509\n",
      "Optimization Iteration:   2945, Training Accuracy:  76.6%, Loss: 0.4591\n",
      "Optimization Iteration:   3009, Training Accuracy:  76.6%, Loss: 0.3647\n",
      "Optimization Iteration:   3073, Training Accuracy:  75.0%, Loss: 0.3143\n",
      "Optimization Iteration:   3137, Training Accuracy:  87.5%, Loss: 0.2920\n",
      "Optimization Iteration:   3201, Training Accuracy:  76.6%, Loss: 0.4127\n",
      "Optimization Iteration:   3265, Training Accuracy:  70.3%, Loss: 0.3842\n",
      "Optimization Iteration:   3329, Training Accuracy:  79.7%, Loss: 0.4139\n",
      "Optimization Iteration:   3393, Training Accuracy:  75.0%, Loss: 0.3655\n",
      "Optimization Iteration:   3457, Training Accuracy:  78.1%, Loss: 0.3937\n",
      "Optimization Iteration:   3521, Training Accuracy:  79.7%, Loss: 0.4218\n",
      "Optimization Iteration:   3585, Training Accuracy:  75.0%, Loss: 0.4063\n",
      "Optimization Iteration:   3649, Training Accuracy:  68.8%, Loss: 0.4170\n",
      "Optimization Iteration:   3713, Training Accuracy:  78.1%, Loss: 0.3960\n",
      "Optimization Iteration:   3777, Training Accuracy:  64.1%, Loss: 0.4669\n",
      "Optimization Iteration:   3841, Training Accuracy:  59.4%, Loss: 0.4509\n",
      "Optimization Iteration:   3905, Training Accuracy:  78.1%, Loss: 0.4282\n",
      "Optimization Iteration:   3969, Training Accuracy:  78.1%, Loss: 0.3971\n",
      "Optimization Iteration:   4033, Training Accuracy:  78.1%, Loss: 0.3054\n",
      "Optimization Iteration:   4097, Training Accuracy:  82.8%, Loss: 0.3570\n",
      "Optimization Iteration:   4161, Training Accuracy:  70.3%, Loss: 0.4932\n",
      "Optimization Iteration:   4225, Training Accuracy:  82.8%, Loss: 0.3273\n",
      "Optimization Iteration:   4289, Training Accuracy:  73.4%, Loss: 0.3514\n",
      "Optimization Iteration:   4353, Training Accuracy:  78.1%, Loss: 0.3726\n",
      "Optimization Iteration:   4417, Training Accuracy:  81.2%, Loss: 0.3575\n",
      "Optimization Iteration:   4481, Training Accuracy:  67.2%, Loss: 0.4398\n",
      "Optimization Iteration:   4545, Training Accuracy:  71.9%, Loss: 0.4546\n",
      "Optimization Iteration:   4609, Training Accuracy:  78.1%, Loss: 0.3241\n",
      "Optimization Iteration:   4673, Training Accuracy:  75.0%, Loss: 0.4007\n",
      "Optimization Iteration:   4737, Training Accuracy:  81.2%, Loss: 0.3175\n",
      "Optimization Iteration:   4801, Training Accuracy:  67.2%, Loss: 0.4811\n",
      "Optimization Iteration:   4865, Training Accuracy:  70.3%, Loss: 0.4477\n",
      "Optimization Iteration:   4929, Training Accuracy:  73.4%, Loss: 0.3862\n",
      "Optimization Iteration:   4993, Training Accuracy:  75.0%, Loss: 0.4072\n",
      "Optimization Iteration:   5057, Training Accuracy:  64.1%, Loss: 0.4693\n",
      "Optimization Iteration:   5121, Training Accuracy:  81.2%, Loss: 0.3465\n",
      "Optimization Iteration:   5185, Training Accuracy:  89.1%, Loss: 0.3417\n",
      "Optimization Iteration:   5249, Training Accuracy:  54.7%, Loss: 0.5011\n",
      "Optimization Iteration:   5313, Training Accuracy:  79.7%, Loss: 0.3654\n",
      "Optimization Iteration:   5377, Training Accuracy:  87.5%, Loss: 0.3184\n",
      "Optimization Iteration:   5441, Training Accuracy:  70.3%, Loss: 0.4397\n",
      "Optimization Iteration:   5505, Training Accuracy:  78.1%, Loss: 0.3559\n",
      "Optimization Iteration:   5569, Training Accuracy:  78.1%, Loss: 0.3285\n",
      "Optimization Iteration:   5633, Training Accuracy:  79.7%, Loss: 0.3617\n",
      "Optimization Iteration:   5697, Training Accuracy:  68.8%, Loss: 0.5155\n",
      "Optimization Iteration:   5761, Training Accuracy:  82.8%, Loss: 0.3544\n",
      "Optimization Iteration:   5825, Training Accuracy:  75.0%, Loss: 0.4193\n",
      "Optimization Iteration:   5889, Training Accuracy:  85.9%, Loss: 0.3606\n",
      "Optimization Iteration:   5953, Training Accuracy:  75.0%, Loss: 0.3817\n",
      "Optimization Iteration:   6017, Training Accuracy:  70.3%, Loss: 0.4522\n",
      "Optimization Iteration:   6081, Training Accuracy:  73.4%, Loss: 0.3935\n",
      "Optimization Iteration:   6145, Training Accuracy:  75.0%, Loss: 0.4436\n",
      "Optimization Iteration:   6209, Training Accuracy:  68.8%, Loss: 0.4190\n",
      "Optimization Iteration:   6273, Training Accuracy:  78.1%, Loss: 0.4306\n",
      "Optimization Iteration:   6337, Training Accuracy:  70.3%, Loss: 0.4065\n",
      "Optimization Iteration:   6401, Training Accuracy:  71.9%, Loss: 0.4257\n",
      "Optimization Iteration:   6465, Training Accuracy:  79.7%, Loss: 0.3400\n",
      "Optimization Iteration:   6529, Training Accuracy:  79.7%, Loss: 0.4053\n",
      "Optimization Iteration:   6593, Training Accuracy:  78.1%, Loss: 0.3680\n",
      "Optimization Iteration:   6657, Training Accuracy:  71.9%, Loss: 0.4394\n",
      "Optimization Iteration:   6721, Training Accuracy:  73.4%, Loss: 0.3680\n",
      "Optimization Iteration:   6785, Training Accuracy:  78.1%, Loss: 0.3788\n",
      "Optimization Iteration:   6849, Training Accuracy:  82.8%, Loss: 0.3264\n",
      "Optimization Iteration:   6913, Training Accuracy:  75.0%, Loss: 0.3529\n",
      "Optimization Iteration:   6977, Training Accuracy:  79.7%, Loss: 0.3586\n",
      "Optimization Iteration:   7041, Training Accuracy:  84.4%, Loss: 0.3380\n",
      "Optimization Iteration:   7105, Training Accuracy:  81.2%, Loss: 0.3167\n",
      "Optimization Iteration:   7169, Training Accuracy:  81.2%, Loss: 0.3815\n",
      "Optimization Iteration:   7233, Training Accuracy:  67.2%, Loss: 0.5142\n",
      "Optimization Iteration:   7297, Training Accuracy:  68.8%, Loss: 0.4800\n",
      "Optimization Iteration:   7361, Training Accuracy:  76.6%, Loss: 0.3545\n",
      "Optimization Iteration:   7425, Training Accuracy:  71.9%, Loss: 0.4345\n",
      "Optimization Iteration:   7489, Training Accuracy:  73.4%, Loss: 0.4447\n",
      "Optimization Iteration:   7553, Training Accuracy:  75.0%, Loss: 0.4185\n",
      "Optimization Iteration:   7617, Training Accuracy:  75.0%, Loss: 0.3715\n",
      "Optimization Iteration:   7681, Training Accuracy:  84.4%, Loss: 0.3353\n",
      "Optimization Iteration:   7745, Training Accuracy:  79.7%, Loss: 0.3335\n",
      "Optimization Iteration:   7809, Training Accuracy:  75.0%, Loss: 0.4988\n",
      "Optimization Iteration:   7873, Training Accuracy:  76.6%, Loss: 0.3471\n",
      "Optimization Iteration:   7937, Training Accuracy:  78.1%, Loss: 0.3781\n",
      "Optimization Iteration:   8001, Training Accuracy:  60.9%, Loss: 0.4284\n",
      "Optimization Iteration:   8065, Training Accuracy:  73.4%, Loss: 0.3759\n",
      "Optimization Iteration:   8129, Training Accuracy:  76.6%, Loss: 0.3620\n",
      "Optimization Iteration:   8193, Training Accuracy:  82.8%, Loss: 0.3731\n",
      "Optimization Iteration:   8257, Training Accuracy:  78.1%, Loss: 0.4194\n",
      "Optimization Iteration:   8321, Training Accuracy:  73.4%, Loss: 0.3936\n",
      "Optimization Iteration:   8385, Training Accuracy:  78.1%, Loss: 0.3490\n",
      "Optimization Iteration:   8449, Training Accuracy:  71.9%, Loss: 0.4352\n",
      "Optimization Iteration:   8513, Training Accuracy:  82.8%, Loss: 0.3290\n",
      "Optimization Iteration:   8577, Training Accuracy:  81.2%, Loss: 0.4061\n",
      "Optimization Iteration:   8641, Training Accuracy:  76.6%, Loss: 0.3586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   8705, Training Accuracy:  73.4%, Loss: 0.4302\n",
      "Optimization Iteration:   8769, Training Accuracy:  70.3%, Loss: 0.3880\n",
      "Optimization Iteration:   8833, Training Accuracy:  73.4%, Loss: 0.3995\n",
      "Optimization Iteration:   8897, Training Accuracy:  71.9%, Loss: 0.4333\n",
      "Optimization Iteration:   8961, Training Accuracy:  70.3%, Loss: 0.4819\n",
      "Optimization Iteration:   9025, Training Accuracy:  70.3%, Loss: 0.4966\n",
      "Optimization Iteration:   9089, Training Accuracy:  75.0%, Loss: 0.4910\n",
      "Optimization Iteration:   9153, Training Accuracy:  76.6%, Loss: 0.3532\n",
      "Optimization Iteration:   9217, Training Accuracy:  79.7%, Loss: 0.3588\n",
      "Optimization Iteration:   9281, Training Accuracy:  78.1%, Loss: 0.3426\n",
      "Optimization Iteration:   9345, Training Accuracy:  75.0%, Loss: 0.4389\n",
      "Optimization Iteration:   9409, Training Accuracy:  71.9%, Loss: 0.4219\n",
      "Optimization Iteration:   9473, Training Accuracy:  79.7%, Loss: 0.3733\n",
      "Optimization Iteration:   9537, Training Accuracy:  75.0%, Loss: 0.3877\n",
      "Optimization Iteration:   9601, Training Accuracy:  76.6%, Loss: 0.4306\n",
      "Optimization Iteration:   9665, Training Accuracy:  65.6%, Loss: 0.4264\n",
      "Optimization Iteration:   9729, Training Accuracy:  70.3%, Loss: 0.4107\n",
      "Optimization Iteration:   9793, Training Accuracy:  73.4%, Loss: 0.4033\n",
      "Optimization Iteration:   9857, Training Accuracy:  71.9%, Loss: 0.4331\n",
      "Optimization Iteration:   9921, Training Accuracy:  75.0%, Loss: 0.3637\n",
      "Optimization Iteration:   9985, Training Accuracy:  76.6%, Loss: 0.3909\n",
      "Optimization Iteration:  10049, Training Accuracy:  79.7%, Loss: 0.3779\n",
      "Optimization Iteration:  10113, Training Accuracy:  71.9%, Loss: 0.4086\n",
      "Optimization Iteration:  10177, Training Accuracy:  73.4%, Loss: 0.4749\n",
      "Optimization Iteration:  10241, Training Accuracy:  73.4%, Loss: 0.4628\n",
      "Optimization Iteration:  10305, Training Accuracy:  76.6%, Loss: 0.3879\n",
      "Optimization Iteration:  10369, Training Accuracy:  78.1%, Loss: 0.3593\n",
      "Optimization Iteration:  10433, Training Accuracy:  85.9%, Loss: 0.3473\n",
      "Optimization Iteration:  10497, Training Accuracy:  71.9%, Loss: 0.4411\n",
      "Optimization Iteration:  10561, Training Accuracy:  79.7%, Loss: 0.3658\n",
      "Optimization Iteration:  10625, Training Accuracy:  82.8%, Loss: 0.3918\n",
      "Optimization Iteration:  10689, Training Accuracy:  65.6%, Loss: 0.4204\n",
      "Optimization Iteration:  10753, Training Accuracy:  73.4%, Loss: 0.4516\n",
      "Optimization Iteration:  10817, Training Accuracy:  78.1%, Loss: 0.3789\n",
      "Optimization Iteration:  10881, Training Accuracy:  82.8%, Loss: 0.3347\n",
      "Optimization Iteration:  10945, Training Accuracy:  73.4%, Loss: 0.4001\n",
      "Optimization Iteration:  11009, Training Accuracy:  79.7%, Loss: 0.3935\n",
      "Optimization Iteration:  11073, Training Accuracy:  71.9%, Loss: 0.3887\n",
      "Optimization Iteration:  11137, Training Accuracy:  81.2%, Loss: 0.3814\n",
      "Optimization Iteration:  11201, Training Accuracy:  79.7%, Loss: 0.3535\n",
      "Optimization Iteration:  11265, Training Accuracy:  79.7%, Loss: 0.3275\n",
      "Optimization Iteration:  11329, Training Accuracy:  79.7%, Loss: 0.4523\n",
      "Optimization Iteration:  11393, Training Accuracy:  70.3%, Loss: 0.4723\n",
      "Optimization Iteration:  11457, Training Accuracy:  78.1%, Loss: 0.3694\n",
      "Optimization Iteration:  11521, Training Accuracy:  64.1%, Loss: 0.4716\n",
      "Optimization Iteration:  11585, Training Accuracy:  70.3%, Loss: 0.4280\n",
      "Optimization Iteration:  11649, Training Accuracy:  71.9%, Loss: 0.3981\n",
      "Optimization Iteration:  11713, Training Accuracy:  73.4%, Loss: 0.3859\n",
      "Optimization Iteration:  11777, Training Accuracy:  67.2%, Loss: 0.4963\n",
      "Optimization Iteration:  11841, Training Accuracy:  85.9%, Loss: 0.3386\n",
      "Optimization Iteration:  11905, Training Accuracy:  78.1%, Loss: 0.3337\n",
      "Optimization Iteration:  11969, Training Accuracy:  89.1%, Loss: 0.2707\n",
      "Optimization Iteration:  12033, Training Accuracy:  76.6%, Loss: 0.4472\n",
      "Optimization Iteration:  12097, Training Accuracy:  81.2%, Loss: 0.3679\n",
      "Optimization Iteration:  12161, Training Accuracy:  75.0%, Loss: 0.4409\n",
      "Optimization Iteration:  12225, Training Accuracy:  85.9%, Loss: 0.3322\n",
      "Optimization Iteration:  12289, Training Accuracy:  75.0%, Loss: 0.3719\n",
      "Optimization Iteration:  12353, Training Accuracy:  78.1%, Loss: 0.3288\n",
      "Optimization Iteration:  12417, Training Accuracy:  79.7%, Loss: 0.3645\n",
      "Optimization Iteration:  12481, Training Accuracy:  75.0%, Loss: 0.3652\n",
      "Optimization Iteration:  12545, Training Accuracy:  71.9%, Loss: 0.4187\n",
      "Optimization Iteration:  12609, Training Accuracy:  78.1%, Loss: 0.3975\n",
      "Optimization Iteration:  12673, Training Accuracy:  71.9%, Loss: 0.3919\n",
      "Optimization Iteration:  12737, Training Accuracy:  73.4%, Loss: 0.3806\n",
      "Optimization Iteration:  12801, Training Accuracy:  71.9%, Loss: 0.3653\n",
      "Optimization Iteration:  12865, Training Accuracy:  79.7%, Loss: 0.3677\n",
      "Optimization Iteration:  12929, Training Accuracy:  67.2%, Loss: 0.4468\n",
      "Optimization Iteration:  12993, Training Accuracy:  79.7%, Loss: 0.3475\n",
      "Optimization Iteration:  13057, Training Accuracy:  67.2%, Loss: 0.4863\n",
      "Optimization Iteration:  13121, Training Accuracy:  85.9%, Loss: 0.3081\n",
      "Optimization Iteration:  13185, Training Accuracy:  78.1%, Loss: 0.4049\n",
      "Optimization Iteration:  13249, Training Accuracy:  73.4%, Loss: 0.4790\n",
      "Optimization Iteration:  13313, Training Accuracy:  75.0%, Loss: 0.5021\n",
      "Optimization Iteration:  13377, Training Accuracy:  76.6%, Loss: 0.4678\n",
      "Optimization Iteration:  13441, Training Accuracy:  75.0%, Loss: 0.3859\n",
      "Optimization Iteration:  13505, Training Accuracy:  76.6%, Loss: 0.3899\n",
      "Optimization Iteration:  13569, Training Accuracy:  84.4%, Loss: 0.3084\n",
      "Optimization Iteration:  13633, Training Accuracy:  70.3%, Loss: 0.3750\n",
      "Optimization Iteration:  13697, Training Accuracy:  75.0%, Loss: 0.4010\n",
      "Optimization Iteration:  13761, Training Accuracy:  76.6%, Loss: 0.3824\n",
      "Optimization Iteration:  13825, Training Accuracy:  87.5%, Loss: 0.3508\n",
      "Optimization Iteration:  13889, Training Accuracy:  85.9%, Loss: 0.4582\n",
      "Optimization Iteration:  13953, Training Accuracy:  79.7%, Loss: 0.2986\n",
      "Optimization Iteration:  14017, Training Accuracy:  78.1%, Loss: 0.3990\n",
      "Optimization Iteration:  14081, Training Accuracy:  76.6%, Loss: 0.3577\n",
      "Optimization Iteration:  14145, Training Accuracy:  76.6%, Loss: 0.3413\n",
      "Optimization Iteration:  14209, Training Accuracy:  82.8%, Loss: 0.4470\n",
      "Optimization Iteration:  14273, Training Accuracy:  78.1%, Loss: 0.3955\n",
      "Optimization Iteration:  14337, Training Accuracy:  87.5%, Loss: 0.2828\n",
      "Optimization Iteration:  14401, Training Accuracy:  85.9%, Loss: 0.3095\n",
      "Optimization Iteration:  14465, Training Accuracy:  68.8%, Loss: 0.4697\n",
      "Optimization Iteration:  14529, Training Accuracy:  79.7%, Loss: 0.4350\n",
      "Optimization Iteration:  14593, Training Accuracy:  76.6%, Loss: 0.3720\n",
      "Optimization Iteration:  14657, Training Accuracy:  65.6%, Loss: 0.4556\n",
      "Optimization Iteration:  14721, Training Accuracy:  73.4%, Loss: 0.4082\n",
      "Optimization Iteration:  14785, Training Accuracy:  68.8%, Loss: 0.5160\n",
      "Optimization Iteration:  14849, Training Accuracy:  67.2%, Loss: 0.4405\n",
      "Optimization Iteration:  14913, Training Accuracy:  76.6%, Loss: 0.3423\n",
      "Optimization Iteration:  14977, Training Accuracy:  78.1%, Loss: 0.3785\n",
      "Optimization Iteration:  15041, Training Accuracy:  78.1%, Loss: 0.3612\n",
      "Optimization Iteration:  15105, Training Accuracy:  79.7%, Loss: 0.3507\n",
      "Optimization Iteration:  15169, Training Accuracy:  71.9%, Loss: 0.3687\n",
      "Optimization Iteration:  15233, Training Accuracy:  70.3%, Loss: 0.3973\n",
      "Optimization Iteration:  15297, Training Accuracy:  79.7%, Loss: 0.3570\n",
      "Optimization Iteration:  15361, Training Accuracy:  79.7%, Loss: 0.3917\n",
      "Optimization Iteration:  15425, Training Accuracy:  73.4%, Loss: 0.4752\n",
      "Optimization Iteration:  15489, Training Accuracy:  67.2%, Loss: 0.4777\n",
      "Optimization Iteration:  15553, Training Accuracy:  75.0%, Loss: 0.3270\n",
      "Optimization Iteration:  15617, Training Accuracy:  79.7%, Loss: 0.3613\n",
      "Optimization Iteration:  15681, Training Accuracy:  76.6%, Loss: 0.3518\n",
      "Optimization Iteration:  15745, Training Accuracy:  79.7%, Loss: 0.3961\n",
      "Optimization Iteration:  15809, Training Accuracy:  79.7%, Loss: 0.3968\n",
      "Optimization Iteration:  15873, Training Accuracy:  81.2%, Loss: 0.3794\n",
      "Optimization Iteration:  15937, Training Accuracy:  71.9%, Loss: 0.3970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  16001, Training Accuracy:  71.9%, Loss: 0.4639\n",
      "Optimization Iteration:  16065, Training Accuracy:  67.2%, Loss: 0.4431\n",
      "Optimization Iteration:  16129, Training Accuracy:  71.9%, Loss: 0.4006\n",
      "Optimization Iteration:  16193, Training Accuracy:  76.6%, Loss: 0.4105\n",
      "Optimization Iteration:  16257, Training Accuracy:  85.9%, Loss: 0.3601\n",
      "Optimization Iteration:  16321, Training Accuracy:  87.5%, Loss: 0.3460\n",
      "Optimization Iteration:  16385, Training Accuracy:  78.1%, Loss: 0.4019\n",
      "Optimization Iteration:  16449, Training Accuracy:  67.2%, Loss: 0.4357\n",
      "Optimization Iteration:  16513, Training Accuracy:  70.3%, Loss: 0.4416\n",
      "Optimization Iteration:  16577, Training Accuracy:  76.6%, Loss: 0.3963\n",
      "Optimization Iteration:  16641, Training Accuracy:  76.6%, Loss: 0.4743\n",
      "Optimization Iteration:  16705, Training Accuracy:  73.4%, Loss: 0.3550\n",
      "Optimization Iteration:  16769, Training Accuracy:  75.0%, Loss: 0.3492\n",
      "Optimization Iteration:  16833, Training Accuracy:  81.2%, Loss: 0.3683\n",
      "Optimization Iteration:  16897, Training Accuracy:  73.4%, Loss: 0.3924\n",
      "Optimization Iteration:  16961, Training Accuracy:  76.6%, Loss: 0.3439\n",
      "Optimization Iteration:  17025, Training Accuracy:  71.9%, Loss: 0.4321\n",
      "Optimization Iteration:  17089, Training Accuracy:  81.2%, Loss: 0.3720\n",
      "Optimization Iteration:  17153, Training Accuracy:  73.4%, Loss: 0.4479\n",
      "Optimization Iteration:  17217, Training Accuracy:  76.6%, Loss: 0.4451\n",
      "Optimization Iteration:  17281, Training Accuracy:  67.2%, Loss: 0.4559\n",
      "Optimization Iteration:  17345, Training Accuracy:  81.2%, Loss: 0.3546\n",
      "Optimization Iteration:  17409, Training Accuracy:  71.9%, Loss: 0.3765\n",
      "Optimization Iteration:  17473, Training Accuracy:  75.0%, Loss: 0.4437\n",
      "Optimization Iteration:  17537, Training Accuracy:  79.7%, Loss: 0.3602\n",
      "Optimization Iteration:  17601, Training Accuracy:  76.6%, Loss: 0.3940\n",
      "Optimization Iteration:  17665, Training Accuracy:  79.7%, Loss: 0.3192\n",
      "Optimization Iteration:  17729, Training Accuracy:  71.9%, Loss: 0.4036\n",
      "Optimization Iteration:  17793, Training Accuracy:  70.3%, Loss: 0.4243\n",
      "Optimization Iteration:  17857, Training Accuracy:  78.1%, Loss: 0.3879\n",
      "Optimization Iteration:  17921, Training Accuracy:  76.6%, Loss: 0.3661\n",
      "Optimization Iteration:  17985, Training Accuracy:  76.6%, Loss: 0.3252\n",
      "Optimization Iteration:  18049, Training Accuracy:  81.2%, Loss: 0.3454\n",
      "Optimization Iteration:  18113, Training Accuracy:  65.6%, Loss: 0.4438\n",
      "Optimization Iteration:  18177, Training Accuracy:  73.4%, Loss: 0.4792\n",
      "Optimization Iteration:  18241, Training Accuracy:  76.6%, Loss: 0.4134\n",
      "Optimization Iteration:  18305, Training Accuracy:  76.6%, Loss: 0.4282\n",
      "Optimization Iteration:  18369, Training Accuracy:  73.4%, Loss: 0.3705\n",
      "Optimization Iteration:  18433, Training Accuracy:  76.6%, Loss: 0.3998\n",
      "Optimization Iteration:  18497, Training Accuracy:  76.6%, Loss: 0.4204\n",
      "Optimization Iteration:  18561, Training Accuracy:  76.6%, Loss: 0.4059\n",
      "Optimization Iteration:  18625, Training Accuracy:  81.2%, Loss: 0.4302\n",
      "Optimization Iteration:  18689, Training Accuracy:  67.2%, Loss: 0.4803\n",
      "Optimization Iteration:  18753, Training Accuracy:  73.4%, Loss: 0.4025\n",
      "Optimization Iteration:  18817, Training Accuracy:  79.7%, Loss: 0.3644\n",
      "Optimization Iteration:  18881, Training Accuracy:  71.9%, Loss: 0.4174\n",
      "Optimization Iteration:  18945, Training Accuracy:  81.2%, Loss: 0.3678\n",
      "Optimization Iteration:  19009, Training Accuracy:  71.9%, Loss: 0.3914\n",
      "Optimization Iteration:  19073, Training Accuracy:  78.1%, Loss: 0.4206\n",
      "Optimization Iteration:  19137, Training Accuracy:  75.0%, Loss: 0.4308\n",
      "Optimization Iteration:  19201, Training Accuracy:  76.6%, Loss: 0.4026\n",
      "Optimization Iteration:  19265, Training Accuracy:  79.7%, Loss: 0.3902\n",
      "Optimization Iteration:  19329, Training Accuracy:  75.0%, Loss: 0.3814\n",
      "Optimization Iteration:  19393, Training Accuracy:  68.8%, Loss: 0.4067\n",
      "Optimization Iteration:  19457, Training Accuracy:  70.3%, Loss: 0.4491\n",
      "Optimization Iteration:  19521, Training Accuracy:  73.4%, Loss: 0.3749\n",
      "Optimization Iteration:  19585, Training Accuracy:  75.0%, Loss: 0.4006\n",
      "Optimization Iteration:  19649, Training Accuracy:  84.4%, Loss: 0.4001\n",
      "Optimization Iteration:  19713, Training Accuracy:  71.9%, Loss: 0.3596\n",
      "Optimization Iteration:  19777, Training Accuracy:  76.6%, Loss: 0.3704\n",
      "Optimization Iteration:  19841, Training Accuracy:  68.8%, Loss: 0.4926\n",
      "Optimization Iteration:  19905, Training Accuracy:  71.9%, Loss: 0.4663\n",
      "Optimization Iteration:  19969, Training Accuracy:  73.4%, Loss: 0.4315\n",
      "Optimization Iteration:  20033, Training Accuracy:  87.5%, Loss: 0.3307\n",
      "Optimization Iteration:  20097, Training Accuracy:  73.4%, Loss: 0.3872\n",
      "Optimization Iteration:  20161, Training Accuracy:  73.4%, Loss: 0.4187\n",
      "Optimization Iteration:  20225, Training Accuracy:  70.3%, Loss: 0.4444\n",
      "Optimization Iteration:  20289, Training Accuracy:  73.4%, Loss: 0.4118\n",
      "Optimization Iteration:  20353, Training Accuracy:  81.2%, Loss: 0.4613\n",
      "Optimization Iteration:  20417, Training Accuracy:  75.0%, Loss: 0.3602\n",
      "Optimization Iteration:  20481, Training Accuracy:  75.0%, Loss: 0.4045\n",
      "Optimization Iteration:  20545, Training Accuracy:  76.6%, Loss: 0.3836\n",
      "Optimization Iteration:  20609, Training Accuracy:  79.7%, Loss: 0.3800\n",
      "Optimization Iteration:  20673, Training Accuracy:  71.9%, Loss: 0.3978\n",
      "Optimization Iteration:  20737, Training Accuracy:  84.4%, Loss: 0.3976\n",
      "Optimization Iteration:  20801, Training Accuracy:  75.0%, Loss: 0.3639\n",
      "Optimization Iteration:  20865, Training Accuracy:  76.6%, Loss: 0.3821\n",
      "Optimization Iteration:  20929, Training Accuracy:  79.7%, Loss: 0.4025\n",
      "Optimization Iteration:  20993, Training Accuracy:  82.8%, Loss: 0.4001\n",
      "Optimization Iteration:  21057, Training Accuracy:  76.6%, Loss: 0.3882\n",
      "Optimization Iteration:  21121, Training Accuracy:  68.8%, Loss: 0.3952\n",
      "Optimization Iteration:  21185, Training Accuracy:  79.7%, Loss: 0.3888\n",
      "Optimization Iteration:  21249, Training Accuracy:  67.2%, Loss: 0.4550\n",
      "Optimization Iteration:  21313, Training Accuracy:  76.6%, Loss: 0.3927\n",
      "Optimization Iteration:  21377, Training Accuracy:  81.2%, Loss: 0.3608\n",
      "Optimization Iteration:  21441, Training Accuracy:  75.0%, Loss: 0.3670\n",
      "Optimization Iteration:  21505, Training Accuracy:  84.4%, Loss: 0.3859\n",
      "Optimization Iteration:  21569, Training Accuracy:  71.9%, Loss: 0.3737\n",
      "Optimization Iteration:  21633, Training Accuracy:  92.2%, Loss: 0.3259\n",
      "Optimization Iteration:  21697, Training Accuracy:  70.3%, Loss: 0.4722\n",
      "Optimization Iteration:  21761, Training Accuracy:  87.5%, Loss: 0.3303\n",
      "Optimization Iteration:  21825, Training Accuracy:  68.8%, Loss: 0.4609\n",
      "Optimization Iteration:  21889, Training Accuracy:  79.7%, Loss: 0.3185\n",
      "Optimization Iteration:  21953, Training Accuracy:  68.8%, Loss: 0.5446\n",
      "Optimization Iteration:  22017, Training Accuracy:  76.6%, Loss: 0.3913\n",
      "Optimization Iteration:  22081, Training Accuracy:  81.2%, Loss: 0.3651\n",
      "Optimization Iteration:  22145, Training Accuracy:  78.1%, Loss: 0.3967\n",
      "Optimization Iteration:  22209, Training Accuracy:  85.9%, Loss: 0.3373\n",
      "Optimization Iteration:  22273, Training Accuracy:  76.6%, Loss: 0.3951\n",
      "Optimization Iteration:  22337, Training Accuracy:  75.0%, Loss: 0.3458\n",
      "Optimization Iteration:  22401, Training Accuracy:  70.3%, Loss: 0.5079\n",
      "Optimization Iteration:  22465, Training Accuracy:  71.9%, Loss: 0.4540\n",
      "Optimization Iteration:  22529, Training Accuracy:  62.5%, Loss: 0.4237\n",
      "Optimization Iteration:  22593, Training Accuracy:  71.9%, Loss: 0.3895\n",
      "Optimization Iteration:  22657, Training Accuracy:  78.1%, Loss: 0.4111\n",
      "Optimization Iteration:  22721, Training Accuracy:  81.2%, Loss: 0.4072\n",
      "Optimization Iteration:  22785, Training Accuracy:  84.4%, Loss: 0.3578\n",
      "Optimization Iteration:  22849, Training Accuracy:  78.1%, Loss: 0.3678\n",
      "Optimization Iteration:  22913, Training Accuracy:  71.9%, Loss: 0.4129\n",
      "Optimization Iteration:  22977, Training Accuracy:  76.6%, Loss: 0.3347\n",
      "Optimization Iteration:  23041, Training Accuracy:  76.6%, Loss: 0.3402\n",
      "Optimization Iteration:  23105, Training Accuracy:  68.8%, Loss: 0.3662\n",
      "Optimization Iteration:  23169, Training Accuracy:  81.2%, Loss: 0.3808\n",
      "Optimization Iteration:  23233, Training Accuracy:  67.2%, Loss: 0.5074\n",
      "Optimization Iteration:  23297, Training Accuracy:  70.3%, Loss: 0.4558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  23361, Training Accuracy:  78.1%, Loss: 0.4050\n",
      "Optimization Iteration:  23425, Training Accuracy:  71.9%, Loss: 0.5321\n",
      "Optimization Iteration:  23489, Training Accuracy:  78.1%, Loss: 0.4110\n",
      "Optimization Iteration:  23553, Training Accuracy:  78.1%, Loss: 0.3604\n",
      "Optimization Iteration:  23617, Training Accuracy:  70.3%, Loss: 0.4801\n",
      "Optimization Iteration:  23681, Training Accuracy:  68.8%, Loss: 0.4589\n",
      "Optimization Iteration:  23745, Training Accuracy:  75.0%, Loss: 0.4059\n",
      "Optimization Iteration:  23809, Training Accuracy:  78.1%, Loss: 0.4198\n",
      "Optimization Iteration:  23873, Training Accuracy:  73.4%, Loss: 0.3881\n",
      "Optimization Iteration:  23937, Training Accuracy:  62.5%, Loss: 0.4728\n",
      "Optimization Iteration:  24001, Training Accuracy:  73.4%, Loss: 0.3751\n",
      "Optimization Iteration:  24065, Training Accuracy:  65.6%, Loss: 0.4106\n",
      "Optimization Iteration:  24129, Training Accuracy:  84.4%, Loss: 0.4026\n",
      "Optimization Iteration:  24193, Training Accuracy:  73.4%, Loss: 0.3647\n",
      "Optimization Iteration:  24257, Training Accuracy:  67.2%, Loss: 0.4368\n",
      "Optimization Iteration:  24321, Training Accuracy:  73.4%, Loss: 0.4487\n",
      "Optimization Iteration:  24385, Training Accuracy:  76.6%, Loss: 0.3581\n",
      "Optimization Iteration:  24449, Training Accuracy:  71.9%, Loss: 0.4236\n",
      "Optimization Iteration:  24513, Training Accuracy:  73.4%, Loss: 0.4413\n",
      "Optimization Iteration:  24577, Training Accuracy:  78.1%, Loss: 0.4229\n",
      "Optimization Iteration:  24641, Training Accuracy:  70.3%, Loss: 0.4353\n",
      "Optimization Iteration:  24705, Training Accuracy:  76.6%, Loss: 0.3616\n",
      "Optimization Iteration:  24769, Training Accuracy:  73.4%, Loss: 0.3740\n",
      "Optimization Iteration:  24833, Training Accuracy:  81.2%, Loss: 0.3447\n",
      "Optimization Iteration:  24897, Training Accuracy:  73.4%, Loss: 0.3940\n",
      "Optimization Iteration:  24961, Training Accuracy:  75.0%, Loss: 0.3273\n",
      "Optimization Iteration:  25025, Training Accuracy:  79.7%, Loss: 0.3950\n",
      "Optimization Iteration:  25089, Training Accuracy:  78.1%, Loss: 0.3839\n",
      "Optimization Iteration:  25153, Training Accuracy:  78.1%, Loss: 0.3597\n",
      "Optimization Iteration:  25217, Training Accuracy:  65.6%, Loss: 0.4670\n",
      "Optimization Iteration:  25281, Training Accuracy:  79.7%, Loss: 0.4071\n",
      "Optimization Iteration:  25345, Training Accuracy:  82.8%, Loss: 0.4370\n",
      "Optimization Iteration:  25409, Training Accuracy:  73.4%, Loss: 0.4188\n",
      "Optimization Iteration:  25473, Training Accuracy:  70.3%, Loss: 0.4741\n",
      "Optimization Iteration:  25537, Training Accuracy:  73.4%, Loss: 0.3711\n",
      "Optimization Iteration:  25601, Training Accuracy:  67.2%, Loss: 0.5417\n",
      "Optimization Iteration:  25665, Training Accuracy:  79.7%, Loss: 0.4171\n",
      "Optimization Iteration:  25729, Training Accuracy:  78.1%, Loss: 0.3456\n",
      "Optimization Iteration:  25793, Training Accuracy:  73.4%, Loss: 0.4007\n",
      "Optimization Iteration:  25857, Training Accuracy:  62.5%, Loss: 0.4844\n",
      "Optimization Iteration:  25921, Training Accuracy:  73.4%, Loss: 0.4183\n",
      "Optimization Iteration:  25985, Training Accuracy:  81.2%, Loss: 0.3760\n",
      "Optimization Iteration:  26049, Training Accuracy:  82.8%, Loss: 0.3599\n",
      "Optimization Iteration:  26113, Training Accuracy:  73.4%, Loss: 0.3768\n",
      "Optimization Iteration:  26177, Training Accuracy:  70.3%, Loss: 0.4413\n",
      "Optimization Iteration:  26241, Training Accuracy:  71.9%, Loss: 0.3951\n",
      "Optimization Iteration:  26305, Training Accuracy:  82.8%, Loss: 0.3964\n",
      "Optimization Iteration:  26369, Training Accuracy:  71.9%, Loss: 0.4400\n",
      "Optimization Iteration:  26433, Training Accuracy:  73.4%, Loss: 0.3784\n",
      "Optimization Iteration:  26497, Training Accuracy:  76.6%, Loss: 0.4047\n",
      "Optimization Iteration:  26561, Training Accuracy:  79.7%, Loss: 0.3427\n",
      "Optimization Iteration:  26625, Training Accuracy:  75.0%, Loss: 0.4108\n",
      "Optimization Iteration:  26689, Training Accuracy:  75.0%, Loss: 0.3884\n",
      "Optimization Iteration:  26753, Training Accuracy:  67.2%, Loss: 0.4711\n",
      "Optimization Iteration:  26817, Training Accuracy:  67.2%, Loss: 0.5063\n",
      "Optimization Iteration:  26881, Training Accuracy:  73.4%, Loss: 0.3374\n",
      "Optimization Iteration:  26945, Training Accuracy:  79.7%, Loss: 0.4217\n",
      "Optimization Iteration:  27009, Training Accuracy:  68.8%, Loss: 0.4185\n",
      "Optimization Iteration:  27073, Training Accuracy:  82.8%, Loss: 0.3582\n",
      "Optimization Iteration:  27137, Training Accuracy:  81.2%, Loss: 0.4011\n",
      "Optimization Iteration:  27201, Training Accuracy:  82.8%, Loss: 0.2774\n",
      "Optimization Iteration:  27265, Training Accuracy:  70.3%, Loss: 0.4425\n",
      "Optimization Iteration:  27329, Training Accuracy:  81.2%, Loss: 0.3545\n",
      "Optimization Iteration:  27393, Training Accuracy:  81.2%, Loss: 0.4157\n",
      "Optimization Iteration:  27457, Training Accuracy:  79.7%, Loss: 0.3925\n",
      "Optimization Iteration:  27521, Training Accuracy:  79.7%, Loss: 0.3531\n",
      "Optimization Iteration:  27585, Training Accuracy:  70.3%, Loss: 0.4241\n",
      "Optimization Iteration:  27649, Training Accuracy:  85.9%, Loss: 0.3504\n",
      "Optimization Iteration:  27713, Training Accuracy:  71.9%, Loss: 0.3836\n",
      "Optimization Iteration:  27777, Training Accuracy:  70.3%, Loss: 0.3842\n",
      "Optimization Iteration:  27841, Training Accuracy:  76.6%, Loss: 0.4438\n",
      "Optimization Iteration:  27905, Training Accuracy:  70.3%, Loss: 0.4616\n",
      "Optimization Iteration:  27969, Training Accuracy:  70.3%, Loss: 0.5087\n",
      "Optimization Iteration:  28033, Training Accuracy:  75.0%, Loss: 0.3988\n",
      "Optimization Iteration:  28097, Training Accuracy:  84.4%, Loss: 0.3192\n",
      "Optimization Iteration:  28161, Training Accuracy:  90.6%, Loss: 0.3327\n",
      "Optimization Iteration:  28225, Training Accuracy:  79.7%, Loss: 0.3949\n",
      "Optimization Iteration:  28289, Training Accuracy:  75.0%, Loss: 0.3730\n",
      "Optimization Iteration:  28353, Training Accuracy:  75.0%, Loss: 0.3746\n",
      "Optimization Iteration:  28417, Training Accuracy:  71.9%, Loss: 0.4760\n",
      "Optimization Iteration:  28481, Training Accuracy:  76.6%, Loss: 0.4080\n",
      "Optimization Iteration:  28545, Training Accuracy:  82.8%, Loss: 0.2688\n",
      "Optimization Iteration:  28609, Training Accuracy:  78.1%, Loss: 0.3604\n",
      "Optimization Iteration:  28673, Training Accuracy:  70.3%, Loss: 0.5644\n",
      "Optimization Iteration:  28737, Training Accuracy:  79.7%, Loss: 0.3603\n",
      "Optimization Iteration:  28801, Training Accuracy:  73.4%, Loss: 0.3918\n",
      "Optimization Iteration:  28865, Training Accuracy:  81.2%, Loss: 0.3138\n",
      "Optimization Iteration:  28929, Training Accuracy:  78.1%, Loss: 0.3617\n",
      "Optimization Iteration:  28993, Training Accuracy:  75.0%, Loss: 0.3543\n",
      "Optimization Iteration:  29057, Training Accuracy:  71.9%, Loss: 0.4251\n",
      "Optimization Iteration:  29121, Training Accuracy:  76.6%, Loss: 0.4329\n",
      "Optimization Iteration:  29185, Training Accuracy:  70.3%, Loss: 0.3701\n",
      "Optimization Iteration:  29249, Training Accuracy:  78.1%, Loss: 0.4135\n",
      "Optimization Iteration:  29313, Training Accuracy:  78.1%, Loss: 0.4451\n",
      "Optimization Iteration:  29377, Training Accuracy:  78.1%, Loss: 0.3634\n",
      "Optimization Iteration:  29441, Training Accuracy:  75.0%, Loss: 0.4018\n",
      "Optimization Iteration:  29505, Training Accuracy:  76.6%, Loss: 0.5038\n",
      "Optimization Iteration:  29569, Training Accuracy:  82.8%, Loss: 0.3939\n",
      "Optimization Iteration:  29633, Training Accuracy:  76.6%, Loss: 0.3403\n",
      "Optimization Iteration:  29697, Training Accuracy:  75.0%, Loss: 0.4115\n",
      "Optimization Iteration:  29761, Training Accuracy:  76.6%, Loss: 0.3943\n",
      "Optimization Iteration:  29825, Training Accuracy:  71.9%, Loss: 0.4337\n",
      "Optimization Iteration:  29889, Training Accuracy:  81.2%, Loss: 0.3618\n",
      "Optimization Iteration:  29953, Training Accuracy:  76.6%, Loss: 0.4538\n",
      "Optimization Iteration:  30017, Training Accuracy:  85.9%, Loss: 0.2969\n",
      "Optimization Iteration:  30081, Training Accuracy:  84.4%, Loss: 0.3578\n",
      "Optimization Iteration:  30145, Training Accuracy:  76.6%, Loss: 0.3863\n",
      "Optimization Iteration:  30209, Training Accuracy:  75.0%, Loss: 0.3909\n",
      "Optimization Iteration:  30273, Training Accuracy:  70.3%, Loss: 0.4378\n",
      "Optimization Iteration:  30337, Training Accuracy:  73.4%, Loss: 0.4392\n",
      "Optimization Iteration:  30401, Training Accuracy:  71.9%, Loss: 0.4509\n",
      "Optimization Iteration:  30465, Training Accuracy:  75.0%, Loss: 0.4031\n",
      "Optimization Iteration:  30529, Training Accuracy:  78.1%, Loss: 0.3724\n",
      "Optimization Iteration:  30593, Training Accuracy:  70.3%, Loss: 0.3917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  30657, Training Accuracy:  81.2%, Loss: 0.3881\n",
      "Optimization Iteration:  30721, Training Accuracy:  71.9%, Loss: 0.4038\n",
      "Optimization Iteration:  30785, Training Accuracy:  70.3%, Loss: 0.4138\n",
      "Optimization Iteration:  30849, Training Accuracy:  73.4%, Loss: 0.3814\n",
      "Optimization Iteration:  30913, Training Accuracy:  78.1%, Loss: 0.3855\n",
      "Optimization Iteration:  30977, Training Accuracy:  73.4%, Loss: 0.4005\n",
      "Optimization Iteration:  31041, Training Accuracy:  79.7%, Loss: 0.3879\n",
      "Optimization Iteration:  31105, Training Accuracy:  68.8%, Loss: 0.4415\n",
      "Optimization Iteration:  31169, Training Accuracy:  75.0%, Loss: 0.3717\n",
      "Optimization Iteration:  31233, Training Accuracy:  75.0%, Loss: 0.3751\n",
      "Optimization Iteration:  31297, Training Accuracy:  76.6%, Loss: 0.3157\n",
      "Optimization Iteration:  31361, Training Accuracy:  78.1%, Loss: 0.3814\n",
      "Optimization Iteration:  31425, Training Accuracy:  78.1%, Loss: 0.3230\n",
      "Optimization Iteration:  31489, Training Accuracy:  81.2%, Loss: 0.3721\n",
      "Optimization Iteration:  31553, Training Accuracy:  76.6%, Loss: 0.4100\n",
      "Optimization Iteration:  31617, Training Accuracy:  73.4%, Loss: 0.4148\n",
      "Optimization Iteration:  31681, Training Accuracy:  79.7%, Loss: 0.4319\n",
      "Optimization Iteration:  31745, Training Accuracy:  75.0%, Loss: 0.3876\n",
      "Optimization Iteration:  31809, Training Accuracy:  70.3%, Loss: 0.5253\n",
      "Optimization Iteration:  31873, Training Accuracy:  79.7%, Loss: 0.3214\n",
      "Optimization Iteration:  31937, Training Accuracy:  73.4%, Loss: 0.3862\n",
      "Optimization Iteration:  32001, Training Accuracy:  79.7%, Loss: 0.3757\n",
      "Optimization Iteration:  32065, Training Accuracy:  70.3%, Loss: 0.3983\n",
      "Optimization Iteration:  32129, Training Accuracy:  68.8%, Loss: 0.3708\n",
      "Optimization Iteration:  32193, Training Accuracy:  78.1%, Loss: 0.4602\n",
      "Optimization Iteration:  32257, Training Accuracy:  79.7%, Loss: 0.3495\n",
      "Optimization Iteration:  32321, Training Accuracy:  71.9%, Loss: 0.3672\n",
      "Optimization Iteration:  32385, Training Accuracy:  79.7%, Loss: 0.3946\n",
      "Optimization Iteration:  32449, Training Accuracy:  67.2%, Loss: 0.4977\n",
      "Optimization Iteration:  32513, Training Accuracy:  71.9%, Loss: 0.3824\n",
      "Optimization Iteration:  32577, Training Accuracy:  71.9%, Loss: 0.3945\n",
      "Optimization Iteration:  32641, Training Accuracy:  79.7%, Loss: 0.4098\n",
      "Optimization Iteration:  32705, Training Accuracy:  70.3%, Loss: 0.4795\n",
      "Optimization Iteration:  32769, Training Accuracy:  73.4%, Loss: 0.3694\n",
      "Optimization Iteration:  32833, Training Accuracy:  70.3%, Loss: 0.3760\n",
      "Optimization Iteration:  32897, Training Accuracy:  78.1%, Loss: 0.4003\n",
      "Optimization Iteration:  32961, Training Accuracy:  78.1%, Loss: 0.3707\n",
      "Optimization Iteration:  33025, Training Accuracy:  75.0%, Loss: 0.4345\n",
      "Optimization Iteration:  33089, Training Accuracy:  73.4%, Loss: 0.4643\n",
      "Optimization Iteration:  33153, Training Accuracy:  76.6%, Loss: 0.4190\n",
      "Optimization Iteration:  33217, Training Accuracy:  71.9%, Loss: 0.3679\n",
      "Optimization Iteration:  33281, Training Accuracy:  62.5%, Loss: 0.4910\n",
      "Optimization Iteration:  33345, Training Accuracy:  76.6%, Loss: 0.4359\n",
      "Optimization Iteration:  33409, Training Accuracy:  78.1%, Loss: 0.3700\n",
      "Optimization Iteration:  33473, Training Accuracy:  70.3%, Loss: 0.4709\n",
      "Optimization Iteration:  33537, Training Accuracy:  70.3%, Loss: 0.4505\n",
      "Optimization Iteration:  33601, Training Accuracy:  70.3%, Loss: 0.4454\n",
      "Optimization Iteration:  33665, Training Accuracy:  79.7%, Loss: 0.3443\n",
      "Optimization Iteration:  33729, Training Accuracy:  78.1%, Loss: 0.4356\n",
      "Optimization Iteration:  33793, Training Accuracy:  70.3%, Loss: 0.5129\n",
      "Optimization Iteration:  33857, Training Accuracy:  82.8%, Loss: 0.3316\n",
      "Optimization Iteration:  33921, Training Accuracy:  81.2%, Loss: 0.4319\n",
      "Optimization Iteration:  33985, Training Accuracy:  75.0%, Loss: 0.4130\n",
      "Optimization Iteration:  34049, Training Accuracy:  70.3%, Loss: 0.4804\n",
      "Optimization Iteration:  34113, Training Accuracy:  79.7%, Loss: 0.3201\n",
      "Optimization Iteration:  34177, Training Accuracy:  78.1%, Loss: 0.3450\n",
      "Optimization Iteration:  34241, Training Accuracy:  75.0%, Loss: 0.4195\n",
      "Optimization Iteration:  34305, Training Accuracy:  78.1%, Loss: 0.3780\n",
      "Optimization Iteration:  34369, Training Accuracy:  81.2%, Loss: 0.3740\n",
      "Optimization Iteration:  34433, Training Accuracy:  81.2%, Loss: 0.3493\n",
      "Optimization Iteration:  34497, Training Accuracy:  81.2%, Loss: 0.3027\n",
      "Optimization Iteration:  34561, Training Accuracy:  81.2%, Loss: 0.3565\n",
      "Optimization Iteration:  34625, Training Accuracy:  78.1%, Loss: 0.4119\n",
      "Optimization Iteration:  34689, Training Accuracy:  78.1%, Loss: 0.3858\n",
      "Optimization Iteration:  34753, Training Accuracy:  68.8%, Loss: 0.4760\n",
      "Optimization Iteration:  34817, Training Accuracy:  82.8%, Loss: 0.3339\n",
      "Optimization Iteration:  34881, Training Accuracy:  78.1%, Loss: 0.3937\n",
      "Optimization Iteration:  34945, Training Accuracy:  79.7%, Loss: 0.3655\n",
      "Optimization Iteration:  35009, Training Accuracy:  82.8%, Loss: 0.3517\n",
      "Optimization Iteration:  35073, Training Accuracy:  78.1%, Loss: 0.3512\n",
      "Optimization Iteration:  35137, Training Accuracy:  84.4%, Loss: 0.3541\n",
      "Optimization Iteration:  35201, Training Accuracy:  78.1%, Loss: 0.3682\n",
      "Optimization Iteration:  35265, Training Accuracy:  65.6%, Loss: 0.4257\n",
      "Optimization Iteration:  35329, Training Accuracy:  65.6%, Loss: 0.4495\n",
      "Optimization Iteration:  35393, Training Accuracy:  76.6%, Loss: 0.3564\n",
      "Optimization Iteration:  35457, Training Accuracy:  71.9%, Loss: 0.3651\n",
      "Optimization Iteration:  35521, Training Accuracy:  76.6%, Loss: 0.3245\n",
      "Optimization Iteration:  35585, Training Accuracy:  82.8%, Loss: 0.3292\n",
      "Optimization Iteration:  35649, Training Accuracy:  71.9%, Loss: 0.5193\n",
      "Optimization Iteration:  35713, Training Accuracy:  81.2%, Loss: 0.3875\n",
      "Optimization Iteration:  35777, Training Accuracy:  78.1%, Loss: 0.3532\n",
      "Optimization Iteration:  35841, Training Accuracy:  78.1%, Loss: 0.3803\n",
      "Optimization Iteration:  35905, Training Accuracy:  73.4%, Loss: 0.4493\n",
      "Optimization Iteration:  35969, Training Accuracy:  71.9%, Loss: 0.4317\n",
      "Optimization Iteration:  36033, Training Accuracy:  71.9%, Loss: 0.3635\n",
      "Optimization Iteration:  36097, Training Accuracy:  73.4%, Loss: 0.4363\n",
      "Optimization Iteration:  36161, Training Accuracy:  78.1%, Loss: 0.3820\n",
      "Optimization Iteration:  36225, Training Accuracy:  79.7%, Loss: 0.3004\n",
      "Optimization Iteration:  36289, Training Accuracy:  78.1%, Loss: 0.3185\n",
      "Optimization Iteration:  36353, Training Accuracy:  75.0%, Loss: 0.3962\n",
      "Optimization Iteration:  36417, Training Accuracy:  79.7%, Loss: 0.3529\n",
      "Optimization Iteration:  36481, Training Accuracy:  71.9%, Loss: 0.3992\n",
      "Optimization Iteration:  36545, Training Accuracy:  89.1%, Loss: 0.3617\n",
      "Optimization Iteration:  36609, Training Accuracy:  82.8%, Loss: 0.3236\n",
      "Optimization Iteration:  36673, Training Accuracy:  76.6%, Loss: 0.3708\n",
      "Optimization Iteration:  36737, Training Accuracy:  79.7%, Loss: 0.3542\n",
      "Optimization Iteration:  36801, Training Accuracy:  82.8%, Loss: 0.3397\n",
      "Optimization Iteration:  36865, Training Accuracy:  64.1%, Loss: 0.4606\n",
      "Optimization Iteration:  36929, Training Accuracy:  73.4%, Loss: 0.4472\n",
      "Optimization Iteration:  36993, Training Accuracy:  76.6%, Loss: 0.3930\n",
      "Optimization Iteration:  37057, Training Accuracy:  81.2%, Loss: 0.3285\n",
      "Optimization Iteration:  37121, Training Accuracy:  84.4%, Loss: 0.3048\n",
      "Optimization Iteration:  37185, Training Accuracy:  70.3%, Loss: 0.4494\n",
      "Optimization Iteration:  37249, Training Accuracy:  70.3%, Loss: 0.4680\n",
      "Optimization Iteration:  37313, Training Accuracy:  87.5%, Loss: 0.2698\n",
      "Optimization Iteration:  37377, Training Accuracy:  68.8%, Loss: 0.5335\n",
      "Optimization Iteration:  37441, Training Accuracy:  79.7%, Loss: 0.3333\n",
      "Optimization Iteration:  37505, Training Accuracy:  82.8%, Loss: 0.4511\n",
      "Optimization Iteration:  37569, Training Accuracy:  67.2%, Loss: 0.4453\n",
      "Optimization Iteration:  37633, Training Accuracy:  78.1%, Loss: 0.3916\n",
      "Optimization Iteration:  37697, Training Accuracy:  73.4%, Loss: 0.3932\n",
      "Optimization Iteration:  37761, Training Accuracy:  78.1%, Loss: 0.4197\n",
      "Optimization Iteration:  37825, Training Accuracy:  73.4%, Loss: 0.4390\n",
      "Optimization Iteration:  37889, Training Accuracy:  70.3%, Loss: 0.4269\n",
      "Optimization Iteration:  37953, Training Accuracy:  76.6%, Loss: 0.3520\n",
      "Optimization Iteration:  38017, Training Accuracy:  76.6%, Loss: 0.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  38081, Training Accuracy:  65.6%, Loss: 0.4692\n",
      "Optimization Iteration:  38145, Training Accuracy:  76.6%, Loss: 0.3152\n",
      "Optimization Iteration:  38209, Training Accuracy:  79.7%, Loss: 0.4695\n",
      "Optimization Iteration:  38273, Training Accuracy:  84.4%, Loss: 0.3260\n",
      "Optimization Iteration:  38337, Training Accuracy:  85.9%, Loss: 0.3279\n",
      "Optimization Iteration:  38401, Training Accuracy:  81.2%, Loss: 0.3472\n",
      "Optimization Iteration:  38465, Training Accuracy:  60.9%, Loss: 0.4267\n",
      "Optimization Iteration:  38529, Training Accuracy:  81.2%, Loss: 0.3566\n",
      "Optimization Iteration:  38593, Training Accuracy:  79.7%, Loss: 0.4905\n",
      "Optimization Iteration:  38657, Training Accuracy:  68.8%, Loss: 0.5177\n",
      "Optimization Iteration:  38721, Training Accuracy:  78.1%, Loss: 0.3655\n",
      "Optimization Iteration:  38785, Training Accuracy:  71.9%, Loss: 0.4432\n",
      "Optimization Iteration:  38849, Training Accuracy:  79.7%, Loss: 0.3337\n",
      "Optimization Iteration:  38913, Training Accuracy:  76.6%, Loss: 0.4227\n",
      "Optimization Iteration:  38977, Training Accuracy:  68.8%, Loss: 0.4126\n",
      "Optimization Iteration:  39041, Training Accuracy:  71.9%, Loss: 0.4689\n",
      "Optimization Iteration:  39105, Training Accuracy:  71.9%, Loss: 0.4910\n",
      "Optimization Iteration:  39169, Training Accuracy:  76.6%, Loss: 0.4276\n",
      "Optimization Iteration:  39233, Training Accuracy:  70.3%, Loss: 0.4138\n",
      "Optimization Iteration:  39297, Training Accuracy:  71.9%, Loss: 0.3569\n",
      "Optimization Iteration:  39361, Training Accuracy:  73.4%, Loss: 0.3401\n",
      "Optimization Iteration:  39425, Training Accuracy:  70.3%, Loss: 0.3988\n",
      "Optimization Iteration:  39489, Training Accuracy:  81.2%, Loss: 0.3311\n",
      "Optimization Iteration:  39553, Training Accuracy:  75.0%, Loss: 0.3498\n",
      "Optimization Iteration:  39617, Training Accuracy:  70.3%, Loss: 0.4444\n",
      "Optimization Iteration:  39681, Training Accuracy:  64.1%, Loss: 0.3906\n",
      "Optimization Iteration:  39745, Training Accuracy:  81.2%, Loss: 0.3406\n",
      "Optimization Iteration:  39809, Training Accuracy:  76.6%, Loss: 0.3791\n",
      "Optimization Iteration:  39873, Training Accuracy:  71.9%, Loss: 0.4483\n",
      "Optimization Iteration:  39937, Training Accuracy:  71.9%, Loss: 0.4663\n",
      "Optimization Iteration:  40001, Training Accuracy:  71.9%, Loss: 0.4174\n",
      "Optimization Iteration:  40065, Training Accuracy:  78.1%, Loss: 0.3513\n",
      "Optimization Iteration:  40129, Training Accuracy:  73.4%, Loss: 0.4320\n",
      "Optimization Iteration:  40193, Training Accuracy:  82.8%, Loss: 0.3618\n",
      "Optimization Iteration:  40257, Training Accuracy:  78.1%, Loss: 0.3963\n",
      "Optimization Iteration:  40321, Training Accuracy:  65.6%, Loss: 0.4578\n",
      "Optimization Iteration:  40385, Training Accuracy:  81.2%, Loss: 0.4140\n",
      "Optimization Iteration:  40449, Training Accuracy:  76.6%, Loss: 0.3671\n",
      "Optimization Iteration:  40513, Training Accuracy:  87.5%, Loss: 0.3548\n",
      "Optimization Iteration:  40577, Training Accuracy:  79.7%, Loss: 0.3762\n",
      "Optimization Iteration:  40641, Training Accuracy:  76.6%, Loss: 0.3338\n",
      "Optimization Iteration:  40705, Training Accuracy:  78.1%, Loss: 0.3624\n",
      "Optimization Iteration:  40769, Training Accuracy:  87.5%, Loss: 0.3157\n",
      "Optimization Iteration:  40833, Training Accuracy:  76.6%, Loss: 0.3359\n",
      "Optimization Iteration:  40897, Training Accuracy:  79.7%, Loss: 0.3319\n",
      "Optimization Iteration:  40961, Training Accuracy:  85.9%, Loss: 0.3125\n",
      "Optimization Iteration:  41025, Training Accuracy:  73.4%, Loss: 0.3851\n",
      "Optimization Iteration:  41089, Training Accuracy:  81.2%, Loss: 0.4051\n",
      "Optimization Iteration:  41153, Training Accuracy:  81.2%, Loss: 0.4104\n",
      "Optimization Iteration:  41217, Training Accuracy:  73.4%, Loss: 0.3534\n",
      "Optimization Iteration:  41281, Training Accuracy:  67.2%, Loss: 0.4368\n",
      "Optimization Iteration:  41345, Training Accuracy:  65.6%, Loss: 0.4483\n",
      "Optimization Iteration:  41409, Training Accuracy:  79.7%, Loss: 0.4040\n",
      "Optimization Iteration:  41473, Training Accuracy:  76.6%, Loss: 0.3670\n",
      "Optimization Iteration:  41537, Training Accuracy:  84.4%, Loss: 0.4328\n",
      "Optimization Iteration:  41601, Training Accuracy:  75.0%, Loss: 0.3927\n",
      "Optimization Iteration:  41665, Training Accuracy:  79.7%, Loss: 0.3186\n",
      "Optimization Iteration:  41729, Training Accuracy:  85.9%, Loss: 0.2800\n",
      "Optimization Iteration:  41793, Training Accuracy:  81.2%, Loss: 0.3816\n",
      "Optimization Iteration:  41857, Training Accuracy:  70.3%, Loss: 0.4289\n",
      "Optimization Iteration:  41921, Training Accuracy:  76.6%, Loss: 0.4118\n",
      "Optimization Iteration:  41985, Training Accuracy:  78.1%, Loss: 0.4579\n",
      "Optimization Iteration:  42049, Training Accuracy:  75.0%, Loss: 0.4074\n",
      "Optimization Iteration:  42113, Training Accuracy:  73.4%, Loss: 0.4250\n",
      "Optimization Iteration:  42177, Training Accuracy:  67.2%, Loss: 0.4465\n",
      "Optimization Iteration:  42241, Training Accuracy:  73.4%, Loss: 0.4376\n",
      "Optimization Iteration:  42305, Training Accuracy:  73.4%, Loss: 0.4019\n",
      "Optimization Iteration:  42369, Training Accuracy:  79.7%, Loss: 0.3319\n",
      "Optimization Iteration:  42433, Training Accuracy:  73.4%, Loss: 0.4466\n",
      "Optimization Iteration:  42497, Training Accuracy:  78.1%, Loss: 0.3750\n",
      "Optimization Iteration:  42561, Training Accuracy:  90.6%, Loss: 0.3325\n",
      "Optimization Iteration:  42625, Training Accuracy:  78.1%, Loss: 0.3789\n",
      "Optimization Iteration:  42689, Training Accuracy:  79.7%, Loss: 0.3822\n",
      "Optimization Iteration:  42753, Training Accuracy:  84.4%, Loss: 0.3797\n",
      "Optimization Iteration:  42817, Training Accuracy:  73.4%, Loss: 0.3780\n",
      "Optimization Iteration:  42881, Training Accuracy:  68.8%, Loss: 0.4631\n",
      "Optimization Iteration:  42945, Training Accuracy:  73.4%, Loss: 0.3974\n",
      "Optimization Iteration:  43009, Training Accuracy:  71.9%, Loss: 0.4374\n",
      "Optimization Iteration:  43073, Training Accuracy:  73.4%, Loss: 0.3749\n",
      "Optimization Iteration:  43137, Training Accuracy:  76.6%, Loss: 0.4128\n",
      "Optimization Iteration:  43201, Training Accuracy:  79.7%, Loss: 0.3708\n",
      "Optimization Iteration:  43265, Training Accuracy:  70.3%, Loss: 0.4028\n",
      "Optimization Iteration:  43329, Training Accuracy:  84.4%, Loss: 0.2985\n",
      "Optimization Iteration:  43393, Training Accuracy:  75.0%, Loss: 0.3631\n",
      "Optimization Iteration:  43457, Training Accuracy:  79.7%, Loss: 0.2909\n",
      "Optimization Iteration:  43521, Training Accuracy:  79.7%, Loss: 0.3626\n",
      "Optimization Iteration:  43585, Training Accuracy:  70.3%, Loss: 0.4380\n",
      "Optimization Iteration:  43649, Training Accuracy:  67.2%, Loss: 0.5125\n",
      "Optimization Iteration:  43713, Training Accuracy:  82.8%, Loss: 0.3318\n",
      "Optimization Iteration:  43777, Training Accuracy:  81.2%, Loss: 0.2459\n",
      "Optimization Iteration:  43841, Training Accuracy:  85.9%, Loss: 0.3955\n",
      "Optimization Iteration:  43905, Training Accuracy:  71.9%, Loss: 0.3864\n",
      "Optimization Iteration:  43969, Training Accuracy:  82.8%, Loss: 0.3189\n",
      "Optimization Iteration:  44033, Training Accuracy:  75.0%, Loss: 0.3992\n",
      "Optimization Iteration:  44097, Training Accuracy:  73.4%, Loss: 0.3934\n",
      "Optimization Iteration:  44161, Training Accuracy:  73.4%, Loss: 0.4356\n",
      "Optimization Iteration:  44225, Training Accuracy:  68.8%, Loss: 0.4155\n",
      "Optimization Iteration:  44289, Training Accuracy:  71.9%, Loss: 0.4125\n",
      "Optimization Iteration:  44353, Training Accuracy:  71.9%, Loss: 0.5287\n",
      "Optimization Iteration:  44417, Training Accuracy:  76.6%, Loss: 0.3453\n",
      "Optimization Iteration:  44481, Training Accuracy:  75.0%, Loss: 0.3942\n",
      "Optimization Iteration:  44545, Training Accuracy:  82.8%, Loss: 0.2953\n",
      "Optimization Iteration:  44609, Training Accuracy:  78.1%, Loss: 0.3868\n",
      "Optimization Iteration:  44673, Training Accuracy:  75.0%, Loss: 0.5113\n",
      "Optimization Iteration:  44737, Training Accuracy:  70.3%, Loss: 0.3946\n",
      "Optimization Iteration:  44801, Training Accuracy:  67.2%, Loss: 0.4854\n",
      "Optimization Iteration:  44865, Training Accuracy:  76.6%, Loss: 0.4505\n",
      "Optimization Iteration:  44929, Training Accuracy:  75.0%, Loss: 0.3180\n",
      "Optimization Iteration:  44993, Training Accuracy:  79.7%, Loss: 0.4168\n",
      "Optimization Iteration:  45057, Training Accuracy:  76.6%, Loss: 0.4130\n",
      "Optimization Iteration:  45121, Training Accuracy:  79.7%, Loss: 0.3348\n",
      "Optimization Iteration:  45185, Training Accuracy:  84.4%, Loss: 0.2996\n",
      "Optimization Iteration:  45249, Training Accuracy:  78.1%, Loss: 0.4235\n",
      "Optimization Iteration:  45313, Training Accuracy:  71.9%, Loss: 0.4238\n",
      "Optimization Iteration:  45377, Training Accuracy:  78.1%, Loss: 0.4579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  45441, Training Accuracy:  81.2%, Loss: 0.4134\n",
      "Optimization Iteration:  45505, Training Accuracy:  78.1%, Loss: 0.3954\n",
      "Optimization Iteration:  45569, Training Accuracy:  76.6%, Loss: 0.4114\n",
      "Optimization Iteration:  45633, Training Accuracy:  78.1%, Loss: 0.4644\n",
      "Optimization Iteration:  45697, Training Accuracy:  87.5%, Loss: 0.3290\n",
      "Optimization Iteration:  45761, Training Accuracy:  84.4%, Loss: 0.3066\n",
      "Optimization Iteration:  45825, Training Accuracy:  82.8%, Loss: 0.3043\n",
      "Optimization Iteration:  45889, Training Accuracy:  75.0%, Loss: 0.4284\n",
      "Optimization Iteration:  45953, Training Accuracy:  75.0%, Loss: 0.4400\n",
      "Optimization Iteration:  46017, Training Accuracy:  71.9%, Loss: 0.4049\n",
      "Optimization Iteration:  46081, Training Accuracy:  89.1%, Loss: 0.2834\n",
      "Optimization Iteration:  46145, Training Accuracy:  73.4%, Loss: 0.4750\n",
      "Optimization Iteration:  46209, Training Accuracy:  85.9%, Loss: 0.3277\n",
      "Optimization Iteration:  46273, Training Accuracy:  70.3%, Loss: 0.4304\n",
      "Optimization Iteration:  46337, Training Accuracy:  73.4%, Loss: 0.4120\n",
      "Optimization Iteration:  46401, Training Accuracy:  70.3%, Loss: 0.4057\n",
      "Optimization Iteration:  46465, Training Accuracy:  76.6%, Loss: 0.4021\n",
      "Optimization Iteration:  46529, Training Accuracy:  64.1%, Loss: 0.5331\n",
      "Optimization Iteration:  46593, Training Accuracy:  70.3%, Loss: 0.4386\n",
      "Optimization Iteration:  46657, Training Accuracy:  78.1%, Loss: 0.4096\n",
      "Optimization Iteration:  46721, Training Accuracy:  78.1%, Loss: 0.3955\n",
      "Optimization Iteration:  46785, Training Accuracy:  68.8%, Loss: 0.4734\n",
      "Optimization Iteration:  46849, Training Accuracy:  75.0%, Loss: 0.3848\n",
      "Optimization Iteration:  46913, Training Accuracy:  81.2%, Loss: 0.3244\n",
      "Optimization Iteration:  46977, Training Accuracy:  79.7%, Loss: 0.3961\n",
      "Optimization Iteration:  47041, Training Accuracy:  76.6%, Loss: 0.3300\n",
      "Optimization Iteration:  47105, Training Accuracy:  65.6%, Loss: 0.4694\n",
      "Optimization Iteration:  47169, Training Accuracy:  78.1%, Loss: 0.3712\n",
      "Optimization Iteration:  47233, Training Accuracy:  71.9%, Loss: 0.4187\n",
      "Optimization Iteration:  47297, Training Accuracy:  70.3%, Loss: 0.3770\n",
      "Optimization Iteration:  47361, Training Accuracy:  85.9%, Loss: 0.3126\n",
      "Optimization Iteration:  47425, Training Accuracy:  81.2%, Loss: 0.3122\n",
      "Optimization Iteration:  47489, Training Accuracy:  71.9%, Loss: 0.4138\n",
      "Optimization Iteration:  47553, Training Accuracy:  82.8%, Loss: 0.3682\n",
      "Optimization Iteration:  47617, Training Accuracy:  76.6%, Loss: 0.4078\n",
      "Optimization Iteration:  47681, Training Accuracy:  84.4%, Loss: 0.3254\n",
      "Optimization Iteration:  47745, Training Accuracy:  71.9%, Loss: 0.4749\n",
      "Optimization Iteration:  47809, Training Accuracy:  70.3%, Loss: 0.4134\n",
      "Optimization Iteration:  47873, Training Accuracy:  87.5%, Loss: 0.2470\n",
      "Optimization Iteration:  47937, Training Accuracy:  76.6%, Loss: 0.4101\n",
      "Optimization Iteration:  48001, Training Accuracy:  68.8%, Loss: 0.4648\n",
      "Optimization Iteration:  48065, Training Accuracy:  73.4%, Loss: 0.3774\n",
      "Optimization Iteration:  48129, Training Accuracy:  75.0%, Loss: 0.4412\n",
      "Optimization Iteration:  48193, Training Accuracy:  71.9%, Loss: 0.4276\n",
      "Optimization Iteration:  48257, Training Accuracy:  82.8%, Loss: 0.3515\n",
      "Optimization Iteration:  48321, Training Accuracy:  84.4%, Loss: 0.3688\n",
      "Optimization Iteration:  48385, Training Accuracy:  71.9%, Loss: 0.4741\n",
      "Optimization Iteration:  48449, Training Accuracy:  76.6%, Loss: 0.4014\n",
      "Optimization Iteration:  48513, Training Accuracy:  78.1%, Loss: 0.3532\n",
      "Optimization Iteration:  48577, Training Accuracy:  67.2%, Loss: 0.4533\n",
      "Optimization Iteration:  48641, Training Accuracy:  73.4%, Loss: 0.3519\n",
      "Optimization Iteration:  48705, Training Accuracy:  78.1%, Loss: 0.3930\n",
      "Optimization Iteration:  48769, Training Accuracy:  78.1%, Loss: 0.3858\n",
      "Optimization Iteration:  48833, Training Accuracy:  81.2%, Loss: 0.3059\n",
      "Optimization Iteration:  48897, Training Accuracy:  68.8%, Loss: 0.4315\n",
      "Optimization Iteration:  48961, Training Accuracy:  76.6%, Loss: 0.4452\n",
      "Optimization Iteration:  49025, Training Accuracy:  78.1%, Loss: 0.4308\n",
      "Optimization Iteration:  49089, Training Accuracy:  75.0%, Loss: 0.3872\n",
      "Optimization Iteration:  49153, Training Accuracy:  68.8%, Loss: 0.3725\n",
      "Optimization Iteration:  49217, Training Accuracy:  73.4%, Loss: 0.3867\n",
      "Optimization Iteration:  49281, Training Accuracy:  68.8%, Loss: 0.4522\n",
      "Optimization Iteration:  49345, Training Accuracy:  73.4%, Loss: 0.3978\n",
      "Optimization Iteration:  49409, Training Accuracy:  75.0%, Loss: 0.3793\n",
      "Optimization Iteration:  49473, Training Accuracy:  84.4%, Loss: 0.3701\n",
      "Optimization Iteration:  49537, Training Accuracy:  73.4%, Loss: 0.3775\n",
      "Optimization Iteration:  49601, Training Accuracy:  76.6%, Loss: 0.3974\n",
      "Optimization Iteration:  49665, Training Accuracy:  76.6%, Loss: 0.3401\n",
      "Optimization Iteration:  49729, Training Accuracy:  71.9%, Loss: 0.3734\n",
      "Optimization Iteration:  49793, Training Accuracy:  71.9%, Loss: 0.3740\n",
      "Optimization Iteration:  49857, Training Accuracy:  70.3%, Loss: 0.4494\n",
      "Optimization Iteration:  49921, Training Accuracy:  75.0%, Loss: 0.4208\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 24\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  73.4%, Loss: 0.4166\n",
      "Optimization Iteration:    129, Training Accuracy:  67.2%, Loss: 0.4716\n",
      "Optimization Iteration:    193, Training Accuracy:  73.4%, Loss: 0.4280\n",
      "Optimization Iteration:    257, Training Accuracy:  79.7%, Loss: 0.3533\n",
      "Optimization Iteration:    321, Training Accuracy:  78.1%, Loss: 0.3331\n",
      "Optimization Iteration:    385, Training Accuracy:  73.4%, Loss: 0.3361\n",
      "Optimization Iteration:    449, Training Accuracy:  85.9%, Loss: 0.3062\n",
      "Optimization Iteration:    513, Training Accuracy:  70.3%, Loss: 0.4814\n",
      "Optimization Iteration:    577, Training Accuracy:  64.1%, Loss: 0.4442\n",
      "Optimization Iteration:    641, Training Accuracy:  64.1%, Loss: 0.3971\n",
      "Optimization Iteration:    705, Training Accuracy:  68.8%, Loss: 0.4787\n",
      "Optimization Iteration:    769, Training Accuracy:  75.0%, Loss: 0.4372\n",
      "Optimization Iteration:    833, Training Accuracy:  78.1%, Loss: 0.3952\n",
      "Optimization Iteration:    897, Training Accuracy:  76.6%, Loss: 0.2895\n",
      "Optimization Iteration:    961, Training Accuracy:  79.7%, Loss: 0.3494\n",
      "Optimization Iteration:   1025, Training Accuracy:  85.9%, Loss: 0.3070\n",
      "Optimization Iteration:   1089, Training Accuracy:  71.9%, Loss: 0.3890\n",
      "Optimization Iteration:   1153, Training Accuracy:  70.3%, Loss: 0.4629\n",
      "Optimization Iteration:   1217, Training Accuracy:  71.9%, Loss: 0.3722\n",
      "Optimization Iteration:   1281, Training Accuracy:  76.6%, Loss: 0.3759\n",
      "Optimization Iteration:   1345, Training Accuracy:  70.3%, Loss: 0.4318\n",
      "Optimization Iteration:   1409, Training Accuracy:  79.7%, Loss: 0.3391\n",
      "Optimization Iteration:   1473, Training Accuracy:  62.5%, Loss: 0.4200\n",
      "Optimization Iteration:   1537, Training Accuracy:  82.8%, Loss: 0.3360\n",
      "Optimization Iteration:   1601, Training Accuracy:  79.7%, Loss: 0.3634\n",
      "Optimization Iteration:   1665, Training Accuracy:  70.3%, Loss: 0.4261\n",
      "Optimization Iteration:   1729, Training Accuracy:  67.2%, Loss: 0.4346\n",
      "Optimization Iteration:   1793, Training Accuracy:  67.2%, Loss: 0.4380\n",
      "Optimization Iteration:   1857, Training Accuracy:  71.9%, Loss: 0.4409\n",
      "Optimization Iteration:   1921, Training Accuracy:  67.2%, Loss: 0.4372\n",
      "Optimization Iteration:   1985, Training Accuracy:  64.1%, Loss: 0.4102\n",
      "Optimization Iteration:   2049, Training Accuracy:  85.9%, Loss: 0.2943\n",
      "Optimization Iteration:   2113, Training Accuracy:  78.1%, Loss: 0.3969\n",
      "Optimization Iteration:   2177, Training Accuracy:  75.0%, Loss: 0.3659\n",
      "Optimization Iteration:   2241, Training Accuracy:  78.1%, Loss: 0.4035\n",
      "Optimization Iteration:   2305, Training Accuracy:  71.9%, Loss: 0.3951\n",
      "Optimization Iteration:   2369, Training Accuracy:  78.1%, Loss: 0.4439\n",
      "Optimization Iteration:   2433, Training Accuracy:  64.1%, Loss: 0.4305\n",
      "Optimization Iteration:   2497, Training Accuracy:  79.7%, Loss: 0.3634\n",
      "Optimization Iteration:   2561, Training Accuracy:  81.2%, Loss: 0.3326\n",
      "Optimization Iteration:   2625, Training Accuracy:  75.0%, Loss: 0.3817\n",
      "Optimization Iteration:   2689, Training Accuracy:  79.7%, Loss: 0.3134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   2753, Training Accuracy:  76.6%, Loss: 0.3631\n",
      "Optimization Iteration:   2817, Training Accuracy:  81.2%, Loss: 0.3632\n",
      "Optimization Iteration:   2881, Training Accuracy:  70.3%, Loss: 0.4617\n",
      "Optimization Iteration:   2945, Training Accuracy:  79.7%, Loss: 0.5361\n",
      "Optimization Iteration:   3009, Training Accuracy:  81.2%, Loss: 0.3959\n",
      "Optimization Iteration:   3073, Training Accuracy:  78.1%, Loss: 0.3206\n",
      "Optimization Iteration:   3137, Training Accuracy:  82.8%, Loss: 0.3540\n",
      "Optimization Iteration:   3201, Training Accuracy:  76.6%, Loss: 0.3462\n",
      "Optimization Iteration:   3265, Training Accuracy:  82.8%, Loss: 0.4269\n",
      "Optimization Iteration:   3329, Training Accuracy:  82.8%, Loss: 0.3467\n",
      "Optimization Iteration:   3393, Training Accuracy:  76.6%, Loss: 0.4020\n",
      "Optimization Iteration:   3457, Training Accuracy:  84.4%, Loss: 0.3679\n",
      "Optimization Iteration:   3521, Training Accuracy:  75.0%, Loss: 0.4090\n",
      "Optimization Iteration:   3585, Training Accuracy:  79.7%, Loss: 0.3604\n",
      "Optimization Iteration:   3649, Training Accuracy:  78.1%, Loss: 0.3648\n",
      "Optimization Iteration:   3713, Training Accuracy:  70.3%, Loss: 0.4112\n",
      "Optimization Iteration:   3777, Training Accuracy:  76.6%, Loss: 0.4337\n",
      "Optimization Iteration:   3841, Training Accuracy:  73.4%, Loss: 0.4140\n",
      "Optimization Iteration:   3905, Training Accuracy:  79.7%, Loss: 0.3626\n",
      "Optimization Iteration:   3969, Training Accuracy:  76.6%, Loss: 0.3789\n",
      "Optimization Iteration:   4033, Training Accuracy:  81.2%, Loss: 0.3028\n",
      "Optimization Iteration:   4097, Training Accuracy:  70.3%, Loss: 0.4080\n",
      "Optimization Iteration:   4161, Training Accuracy:  70.3%, Loss: 0.5035\n",
      "Optimization Iteration:   4225, Training Accuracy:  76.6%, Loss: 0.3859\n",
      "Optimization Iteration:   4289, Training Accuracy:  68.8%, Loss: 0.4270\n",
      "Optimization Iteration:   4353, Training Accuracy:  81.2%, Loss: 0.4046\n",
      "Optimization Iteration:   4417, Training Accuracy:  81.2%, Loss: 0.3424\n",
      "Optimization Iteration:   4481, Training Accuracy:  73.4%, Loss: 0.4333\n",
      "Optimization Iteration:   4545, Training Accuracy:  68.8%, Loss: 0.4479\n",
      "Optimization Iteration:   4609, Training Accuracy:  85.9%, Loss: 0.3528\n",
      "Optimization Iteration:   4673, Training Accuracy:  70.3%, Loss: 0.4162\n",
      "Optimization Iteration:   4737, Training Accuracy:  81.2%, Loss: 0.3992\n",
      "Optimization Iteration:   4801, Training Accuracy:  68.8%, Loss: 0.4236\n",
      "Optimization Iteration:   4865, Training Accuracy:  75.0%, Loss: 0.3895\n",
      "Optimization Iteration:   4929, Training Accuracy:  73.4%, Loss: 0.3780\n",
      "Optimization Iteration:   4993, Training Accuracy:  75.0%, Loss: 0.3957\n",
      "Optimization Iteration:   5057, Training Accuracy:  65.6%, Loss: 0.5283\n",
      "Optimization Iteration:   5121, Training Accuracy:  76.6%, Loss: 0.3847\n",
      "Optimization Iteration:   5185, Training Accuracy:  79.7%, Loss: 0.3728\n",
      "Optimization Iteration:   5249, Training Accuracy:  62.5%, Loss: 0.4563\n",
      "Optimization Iteration:   5313, Training Accuracy:  81.2%, Loss: 0.3665\n",
      "Optimization Iteration:   5377, Training Accuracy:  84.4%, Loss: 0.3085\n",
      "Optimization Iteration:   5441, Training Accuracy:  73.4%, Loss: 0.3752\n",
      "Optimization Iteration:   5505, Training Accuracy:  82.8%, Loss: 0.3220\n",
      "Optimization Iteration:   5569, Training Accuracy:  82.8%, Loss: 0.3182\n",
      "Optimization Iteration:   5633, Training Accuracy:  78.1%, Loss: 0.3246\n",
      "Optimization Iteration:   5697, Training Accuracy:  65.6%, Loss: 0.4618\n",
      "Optimization Iteration:   5761, Training Accuracy:  73.4%, Loss: 0.3230\n",
      "Optimization Iteration:   5825, Training Accuracy:  73.4%, Loss: 0.4259\n",
      "Optimization Iteration:   5889, Training Accuracy:  78.1%, Loss: 0.3617\n",
      "Optimization Iteration:   5953, Training Accuracy:  78.1%, Loss: 0.4169\n",
      "Optimization Iteration:   6017, Training Accuracy:  76.6%, Loss: 0.3927\n",
      "Optimization Iteration:   6081, Training Accuracy:  73.4%, Loss: 0.3858\n",
      "Optimization Iteration:   6145, Training Accuracy:  62.5%, Loss: 0.5774\n",
      "Optimization Iteration:   6209, Training Accuracy:  70.3%, Loss: 0.3655\n",
      "Optimization Iteration:   6273, Training Accuracy:  84.4%, Loss: 0.3844\n",
      "Optimization Iteration:   6337, Training Accuracy:  73.4%, Loss: 0.4354\n",
      "Optimization Iteration:   6401, Training Accuracy:  73.4%, Loss: 0.4260\n",
      "Optimization Iteration:   6465, Training Accuracy:  84.4%, Loss: 0.3424\n",
      "Optimization Iteration:   6529, Training Accuracy:  76.6%, Loss: 0.4254\n",
      "Optimization Iteration:   6593, Training Accuracy:  70.3%, Loss: 0.3954\n",
      "Optimization Iteration:   6657, Training Accuracy:  81.2%, Loss: 0.4027\n",
      "Optimization Iteration:   6721, Training Accuracy:  73.4%, Loss: 0.3281\n",
      "Optimization Iteration:   6785, Training Accuracy:  78.1%, Loss: 0.3705\n",
      "Optimization Iteration:   6849, Training Accuracy:  76.6%, Loss: 0.3804\n",
      "Optimization Iteration:   6913, Training Accuracy:  78.1%, Loss: 0.3547\n",
      "Optimization Iteration:   6977, Training Accuracy:  84.4%, Loss: 0.3888\n",
      "Optimization Iteration:   7041, Training Accuracy:  76.6%, Loss: 0.3921\n",
      "Optimization Iteration:   7105, Training Accuracy:  76.6%, Loss: 0.3715\n",
      "Optimization Iteration:   7169, Training Accuracy:  82.8%, Loss: 0.3733\n",
      "Optimization Iteration:   7233, Training Accuracy:  85.9%, Loss: 0.3424\n",
      "Optimization Iteration:   7297, Training Accuracy:  76.6%, Loss: 0.4545\n",
      "Optimization Iteration:   7361, Training Accuracy:  79.7%, Loss: 0.3021\n",
      "Optimization Iteration:   7425, Training Accuracy:  73.4%, Loss: 0.3695\n",
      "Optimization Iteration:   7489, Training Accuracy:  78.1%, Loss: 0.3881\n",
      "Optimization Iteration:   7553, Training Accuracy:  78.1%, Loss: 0.4077\n",
      "Optimization Iteration:   7617, Training Accuracy:  73.4%, Loss: 0.3792\n",
      "Optimization Iteration:   7681, Training Accuracy:  82.8%, Loss: 0.4363\n",
      "Optimization Iteration:   7745, Training Accuracy:  75.0%, Loss: 0.3321\n",
      "Optimization Iteration:   7809, Training Accuracy:  81.2%, Loss: 0.5296\n",
      "Optimization Iteration:   7873, Training Accuracy:  78.1%, Loss: 0.3561\n",
      "Optimization Iteration:   7937, Training Accuracy:  85.9%, Loss: 0.4168\n",
      "Optimization Iteration:   8001, Training Accuracy:  71.9%, Loss: 0.4151\n",
      "Optimization Iteration:   8065, Training Accuracy:  64.1%, Loss: 0.4397\n",
      "Optimization Iteration:   8129, Training Accuracy:  75.0%, Loss: 0.4266\n",
      "Optimization Iteration:   8193, Training Accuracy:  65.6%, Loss: 0.4375\n",
      "Optimization Iteration:   8257, Training Accuracy:  68.8%, Loss: 0.4734\n",
      "Optimization Iteration:   8321, Training Accuracy:  73.4%, Loss: 0.4026\n",
      "Optimization Iteration:   8385, Training Accuracy:  78.1%, Loss: 0.3974\n",
      "Optimization Iteration:   8449, Training Accuracy:  76.6%, Loss: 0.4455\n",
      "Optimization Iteration:   8513, Training Accuracy:  84.4%, Loss: 0.3762\n",
      "Optimization Iteration:   8577, Training Accuracy:  82.8%, Loss: 0.4364\n",
      "Optimization Iteration:   8641, Training Accuracy:  71.9%, Loss: 0.4292\n",
      "Optimization Iteration:   8705, Training Accuracy:  73.4%, Loss: 0.3674\n",
      "Optimization Iteration:   8769, Training Accuracy:  75.0%, Loss: 0.3439\n",
      "Optimization Iteration:   8833, Training Accuracy:  70.3%, Loss: 0.4048\n",
      "Optimization Iteration:   8897, Training Accuracy:  81.2%, Loss: 0.4217\n",
      "Optimization Iteration:   8961, Training Accuracy:  76.6%, Loss: 0.3535\n",
      "Optimization Iteration:   9025, Training Accuracy:  65.6%, Loss: 0.4827\n",
      "Optimization Iteration:   9089, Training Accuracy:  79.7%, Loss: 0.4033\n",
      "Optimization Iteration:   9153, Training Accuracy:  73.4%, Loss: 0.3356\n",
      "Optimization Iteration:   9217, Training Accuracy:  75.0%, Loss: 0.3687\n",
      "Optimization Iteration:   9281, Training Accuracy:  67.2%, Loss: 0.4147\n",
      "Optimization Iteration:   9345, Training Accuracy:  81.2%, Loss: 0.3786\n",
      "Optimization Iteration:   9409, Training Accuracy:  70.3%, Loss: 0.4924\n",
      "Optimization Iteration:   9473, Training Accuracy:  82.8%, Loss: 0.3538\n",
      "Optimization Iteration:   9537, Training Accuracy:  81.2%, Loss: 0.3468\n",
      "Optimization Iteration:   9601, Training Accuracy:  71.9%, Loss: 0.4651\n",
      "Optimization Iteration:   9665, Training Accuracy:  79.7%, Loss: 0.4216\n",
      "Optimization Iteration:   9729, Training Accuracy:  75.0%, Loss: 0.3975\n",
      "Optimization Iteration:   9793, Training Accuracy:  84.4%, Loss: 0.3532\n",
      "Optimization Iteration:   9857, Training Accuracy:  68.8%, Loss: 0.4675\n",
      "Optimization Iteration:   9921, Training Accuracy:  90.6%, Loss: 0.2996\n",
      "Optimization Iteration:   9985, Training Accuracy:  81.2%, Loss: 0.3617\n",
      "Optimization Iteration:  10049, Training Accuracy:  73.4%, Loss: 0.3774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  10113, Training Accuracy:  75.0%, Loss: 0.3613\n",
      "Optimization Iteration:  10177, Training Accuracy:  67.2%, Loss: 0.5361\n",
      "Optimization Iteration:  10241, Training Accuracy:  78.1%, Loss: 0.4003\n",
      "Optimization Iteration:  10305, Training Accuracy:  82.8%, Loss: 0.3922\n",
      "Optimization Iteration:  10369, Training Accuracy:  89.1%, Loss: 0.3486\n",
      "Optimization Iteration:  10433, Training Accuracy:  79.7%, Loss: 0.3610\n",
      "Optimization Iteration:  10497, Training Accuracy:  71.9%, Loss: 0.4869\n",
      "Optimization Iteration:  10561, Training Accuracy:  87.5%, Loss: 0.3167\n",
      "Optimization Iteration:  10625, Training Accuracy:  78.1%, Loss: 0.3497\n",
      "Optimization Iteration:  10689, Training Accuracy:  76.6%, Loss: 0.3745\n",
      "Optimization Iteration:  10753, Training Accuracy:  71.9%, Loss: 0.4211\n",
      "Optimization Iteration:  10817, Training Accuracy:  82.8%, Loss: 0.3866\n",
      "Optimization Iteration:  10881, Training Accuracy:  76.6%, Loss: 0.3229\n",
      "Optimization Iteration:  10945, Training Accuracy:  76.6%, Loss: 0.3865\n",
      "Optimization Iteration:  11009, Training Accuracy:  76.6%, Loss: 0.3544\n",
      "Optimization Iteration:  11073, Training Accuracy:  79.7%, Loss: 0.3104\n",
      "Optimization Iteration:  11137, Training Accuracy:  68.8%, Loss: 0.4360\n",
      "Optimization Iteration:  11201, Training Accuracy:  79.7%, Loss: 0.3704\n",
      "Optimization Iteration:  11265, Training Accuracy:  81.2%, Loss: 0.2923\n",
      "Optimization Iteration:  11329, Training Accuracy:  71.9%, Loss: 0.4078\n",
      "Optimization Iteration:  11393, Training Accuracy:  76.6%, Loss: 0.4588\n",
      "Optimization Iteration:  11457, Training Accuracy:  78.1%, Loss: 0.3615\n",
      "Optimization Iteration:  11521, Training Accuracy:  71.9%, Loss: 0.4476\n",
      "Optimization Iteration:  11585, Training Accuracy:  75.0%, Loss: 0.3680\n",
      "Optimization Iteration:  11649, Training Accuracy:  78.1%, Loss: 0.4054\n",
      "Optimization Iteration:  11713, Training Accuracy:  78.1%, Loss: 0.3811\n",
      "Optimization Iteration:  11777, Training Accuracy:  75.0%, Loss: 0.4993\n",
      "Optimization Iteration:  11841, Training Accuracy:  71.9%, Loss: 0.4186\n",
      "Optimization Iteration:  11905, Training Accuracy:  81.2%, Loss: 0.3296\n",
      "Optimization Iteration:  11969, Training Accuracy:  78.1%, Loss: 0.3757\n",
      "Optimization Iteration:  12033, Training Accuracy:  81.2%, Loss: 0.3624\n",
      "Optimization Iteration:  12097, Training Accuracy:  76.6%, Loss: 0.4378\n",
      "Optimization Iteration:  12161, Training Accuracy:  70.3%, Loss: 0.4496\n",
      "Optimization Iteration:  12225, Training Accuracy:  81.2%, Loss: 0.3978\n",
      "Optimization Iteration:  12289, Training Accuracy:  82.8%, Loss: 0.3459\n",
      "Optimization Iteration:  12353, Training Accuracy:  73.4%, Loss: 0.3793\n",
      "Optimization Iteration:  12417, Training Accuracy:  79.7%, Loss: 0.3681\n",
      "Optimization Iteration:  12481, Training Accuracy:  76.6%, Loss: 0.4206\n",
      "Optimization Iteration:  12545, Training Accuracy:  75.0%, Loss: 0.4070\n",
      "Optimization Iteration:  12609, Training Accuracy:  79.7%, Loss: 0.3893\n",
      "Optimization Iteration:  12673, Training Accuracy:  75.0%, Loss: 0.3943\n",
      "Optimization Iteration:  12737, Training Accuracy:  75.0%, Loss: 0.3708\n",
      "Optimization Iteration:  12801, Training Accuracy:  81.2%, Loss: 0.3778\n",
      "Optimization Iteration:  12865, Training Accuracy:  73.4%, Loss: 0.4190\n",
      "Optimization Iteration:  12929, Training Accuracy:  73.4%, Loss: 0.3997\n",
      "Optimization Iteration:  12993, Training Accuracy:  68.8%, Loss: 0.3569\n",
      "Optimization Iteration:  13057, Training Accuracy:  70.3%, Loss: 0.4687\n",
      "Optimization Iteration:  13121, Training Accuracy:  75.0%, Loss: 0.4219\n",
      "Optimization Iteration:  13185, Training Accuracy:  75.0%, Loss: 0.4460\n",
      "Optimization Iteration:  13249, Training Accuracy:  78.1%, Loss: 0.4252\n",
      "Optimization Iteration:  13313, Training Accuracy:  73.4%, Loss: 0.4150\n",
      "Optimization Iteration:  13377, Training Accuracy:  70.3%, Loss: 0.4357\n",
      "Optimization Iteration:  13441, Training Accuracy:  81.2%, Loss: 0.3962\n",
      "Optimization Iteration:  13505, Training Accuracy:  78.1%, Loss: 0.3681\n",
      "Optimization Iteration:  13569, Training Accuracy:  71.9%, Loss: 0.3500\n",
      "Optimization Iteration:  13633, Training Accuracy:  79.7%, Loss: 0.3689\n",
      "Optimization Iteration:  13697, Training Accuracy:  79.7%, Loss: 0.3627\n",
      "Optimization Iteration:  13761, Training Accuracy:  84.4%, Loss: 0.2857\n",
      "Optimization Iteration:  13825, Training Accuracy:  79.7%, Loss: 0.3369\n",
      "Optimization Iteration:  13889, Training Accuracy:  75.0%, Loss: 0.3662\n",
      "Optimization Iteration:  13953, Training Accuracy:  82.8%, Loss: 0.3210\n",
      "Optimization Iteration:  14017, Training Accuracy:  73.4%, Loss: 0.3995\n",
      "Optimization Iteration:  14081, Training Accuracy:  73.4%, Loss: 0.3753\n",
      "Optimization Iteration:  14145, Training Accuracy:  81.2%, Loss: 0.3526\n",
      "Optimization Iteration:  14209, Training Accuracy:  76.6%, Loss: 0.4266\n",
      "Optimization Iteration:  14273, Training Accuracy:  68.8%, Loss: 0.4904\n",
      "Optimization Iteration:  14337, Training Accuracy:  84.4%, Loss: 0.2778\n",
      "Optimization Iteration:  14401, Training Accuracy:  75.0%, Loss: 0.3374\n",
      "Optimization Iteration:  14465, Training Accuracy:  75.0%, Loss: 0.4181\n",
      "Optimization Iteration:  14529, Training Accuracy:  76.6%, Loss: 0.3498\n",
      "Optimization Iteration:  14593, Training Accuracy:  75.0%, Loss: 0.3336\n",
      "Optimization Iteration:  14657, Training Accuracy:  73.4%, Loss: 0.4544\n",
      "Optimization Iteration:  14721, Training Accuracy:  81.2%, Loss: 0.3780\n",
      "Optimization Iteration:  14785, Training Accuracy:  76.6%, Loss: 0.3910\n",
      "Optimization Iteration:  14849, Training Accuracy:  75.0%, Loss: 0.3855\n",
      "Optimization Iteration:  14913, Training Accuracy:  73.4%, Loss: 0.3671\n",
      "Optimization Iteration:  14977, Training Accuracy:  79.7%, Loss: 0.4169\n",
      "Optimization Iteration:  15041, Training Accuracy:  79.7%, Loss: 0.3168\n",
      "Optimization Iteration:  15105, Training Accuracy:  87.5%, Loss: 0.3766\n",
      "Optimization Iteration:  15169, Training Accuracy:  81.2%, Loss: 0.3701\n",
      "Optimization Iteration:  15233, Training Accuracy:  78.1%, Loss: 0.4027\n",
      "Optimization Iteration:  15297, Training Accuracy:  82.8%, Loss: 0.3599\n",
      "Optimization Iteration:  15361, Training Accuracy:  85.9%, Loss: 0.3243\n",
      "Optimization Iteration:  15425, Training Accuracy:  78.1%, Loss: 0.3784\n",
      "Optimization Iteration:  15489, Training Accuracy:  68.8%, Loss: 0.4217\n",
      "Optimization Iteration:  15553, Training Accuracy:  76.6%, Loss: 0.3922\n",
      "Optimization Iteration:  15617, Training Accuracy:  70.3%, Loss: 0.3488\n",
      "Optimization Iteration:  15681, Training Accuracy:  78.1%, Loss: 0.3938\n",
      "Optimization Iteration:  15745, Training Accuracy:  84.4%, Loss: 0.3559\n",
      "Optimization Iteration:  15809, Training Accuracy:  71.9%, Loss: 0.4663\n",
      "Optimization Iteration:  15873, Training Accuracy:  75.0%, Loss: 0.3953\n",
      "Optimization Iteration:  15937, Training Accuracy:  81.2%, Loss: 0.3782\n",
      "Optimization Iteration:  16001, Training Accuracy:  73.4%, Loss: 0.4421\n",
      "Optimization Iteration:  16065, Training Accuracy:  79.7%, Loss: 0.3991\n",
      "Optimization Iteration:  16129, Training Accuracy:  78.1%, Loss: 0.3501\n",
      "Optimization Iteration:  16193, Training Accuracy:  75.0%, Loss: 0.3937\n",
      "Optimization Iteration:  16257, Training Accuracy:  84.4%, Loss: 0.3888\n",
      "Optimization Iteration:  16321, Training Accuracy:  75.0%, Loss: 0.3684\n",
      "Optimization Iteration:  16385, Training Accuracy:  79.7%, Loss: 0.3304\n",
      "Optimization Iteration:  16449, Training Accuracy:  76.6%, Loss: 0.3790\n",
      "Optimization Iteration:  16513, Training Accuracy:  81.2%, Loss: 0.3871\n",
      "Optimization Iteration:  16577, Training Accuracy:  76.6%, Loss: 0.3867\n",
      "Optimization Iteration:  16641, Training Accuracy:  75.0%, Loss: 0.4588\n",
      "Optimization Iteration:  16705, Training Accuracy:  76.6%, Loss: 0.3966\n",
      "Optimization Iteration:  16769, Training Accuracy:  75.0%, Loss: 0.3982\n",
      "Optimization Iteration:  16833, Training Accuracy:  84.4%, Loss: 0.3633\n",
      "Optimization Iteration:  16897, Training Accuracy:  82.8%, Loss: 0.3523\n",
      "Optimization Iteration:  16961, Training Accuracy:  81.2%, Loss: 0.3120\n",
      "Optimization Iteration:  17025, Training Accuracy:  71.9%, Loss: 0.3694\n",
      "Optimization Iteration:  17089, Training Accuracy:  79.7%, Loss: 0.4112\n",
      "Optimization Iteration:  17153, Training Accuracy:  68.8%, Loss: 0.4289\n",
      "Optimization Iteration:  17217, Training Accuracy:  75.0%, Loss: 0.4198\n",
      "Optimization Iteration:  17281, Training Accuracy:  64.1%, Loss: 0.4883\n",
      "Optimization Iteration:  17345, Training Accuracy:  78.1%, Loss: 0.3676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  17409, Training Accuracy:  71.9%, Loss: 0.3626\n",
      "Optimization Iteration:  17473, Training Accuracy:  60.9%, Loss: 0.4980\n",
      "Optimization Iteration:  17537, Training Accuracy:  76.6%, Loss: 0.4334\n",
      "Optimization Iteration:  17601, Training Accuracy:  70.3%, Loss: 0.4256\n",
      "Optimization Iteration:  17665, Training Accuracy:  82.8%, Loss: 0.3424\n",
      "Optimization Iteration:  17729, Training Accuracy:  73.4%, Loss: 0.4303\n",
      "Optimization Iteration:  17793, Training Accuracy:  68.8%, Loss: 0.4014\n",
      "Optimization Iteration:  17857, Training Accuracy:  75.0%, Loss: 0.4285\n",
      "Optimization Iteration:  17921, Training Accuracy:  76.6%, Loss: 0.3617\n",
      "Optimization Iteration:  17985, Training Accuracy:  81.2%, Loss: 0.2730\n",
      "Optimization Iteration:  18049, Training Accuracy:  68.8%, Loss: 0.4126\n",
      "Optimization Iteration:  18113, Training Accuracy:  62.5%, Loss: 0.4902\n",
      "Optimization Iteration:  18177, Training Accuracy:  75.0%, Loss: 0.4337\n",
      "Optimization Iteration:  18241, Training Accuracy:  76.6%, Loss: 0.3503\n",
      "Optimization Iteration:  18305, Training Accuracy:  68.8%, Loss: 0.4680\n",
      "Optimization Iteration:  18369, Training Accuracy:  73.4%, Loss: 0.3427\n",
      "Optimization Iteration:  18433, Training Accuracy:  71.9%, Loss: 0.4231\n",
      "Optimization Iteration:  18497, Training Accuracy:  79.7%, Loss: 0.3491\n",
      "Optimization Iteration:  18561, Training Accuracy:  78.1%, Loss: 0.3702\n",
      "Optimization Iteration:  18625, Training Accuracy:  79.7%, Loss: 0.4322\n",
      "Optimization Iteration:  18689, Training Accuracy:  70.3%, Loss: 0.4236\n",
      "Optimization Iteration:  18753, Training Accuracy:  75.0%, Loss: 0.4125\n",
      "Optimization Iteration:  18817, Training Accuracy:  78.1%, Loss: 0.3816\n",
      "Optimization Iteration:  18881, Training Accuracy:  76.6%, Loss: 0.3537\n",
      "Optimization Iteration:  18945, Training Accuracy:  78.1%, Loss: 0.3483\n",
      "Optimization Iteration:  19009, Training Accuracy:  60.9%, Loss: 0.4660\n",
      "Optimization Iteration:  19073, Training Accuracy:  81.2%, Loss: 0.3713\n",
      "Optimization Iteration:  19137, Training Accuracy:  70.3%, Loss: 0.4780\n",
      "Optimization Iteration:  19201, Training Accuracy:  79.7%, Loss: 0.3665\n",
      "Optimization Iteration:  19265, Training Accuracy:  81.2%, Loss: 0.4045\n",
      "Optimization Iteration:  19329, Training Accuracy:  78.1%, Loss: 0.3923\n",
      "Optimization Iteration:  19393, Training Accuracy:  81.2%, Loss: 0.3475\n",
      "Optimization Iteration:  19457, Training Accuracy:  75.0%, Loss: 0.4089\n",
      "Optimization Iteration:  19521, Training Accuracy:  68.8%, Loss: 0.4607\n",
      "Optimization Iteration:  19585, Training Accuracy:  79.7%, Loss: 0.4060\n",
      "Optimization Iteration:  19649, Training Accuracy:  75.0%, Loss: 0.4303\n",
      "Optimization Iteration:  19713, Training Accuracy:  79.7%, Loss: 0.3161\n",
      "Optimization Iteration:  19777, Training Accuracy:  76.6%, Loss: 0.3803\n",
      "Optimization Iteration:  19841, Training Accuracy:  71.9%, Loss: 0.4798\n",
      "Optimization Iteration:  19905, Training Accuracy:  68.8%, Loss: 0.4343\n",
      "Optimization Iteration:  19969, Training Accuracy:  73.4%, Loss: 0.4853\n",
      "Optimization Iteration:  20033, Training Accuracy:  84.4%, Loss: 0.3216\n",
      "Optimization Iteration:  20097, Training Accuracy:  76.6%, Loss: 0.5039\n",
      "Optimization Iteration:  20161, Training Accuracy:  78.1%, Loss: 0.3751\n",
      "Optimization Iteration:  20225, Training Accuracy:  79.7%, Loss: 0.3844\n",
      "Optimization Iteration:  20289, Training Accuracy:  76.6%, Loss: 0.4333\n",
      "Optimization Iteration:  20353, Training Accuracy:  78.1%, Loss: 0.3599\n",
      "Optimization Iteration:  20417, Training Accuracy:  60.9%, Loss: 0.4809\n",
      "Optimization Iteration:  20481, Training Accuracy:  76.6%, Loss: 0.3642\n",
      "Optimization Iteration:  20545, Training Accuracy:  75.0%, Loss: 0.4423\n",
      "Optimization Iteration:  20609, Training Accuracy:  73.4%, Loss: 0.4375\n",
      "Optimization Iteration:  20673, Training Accuracy:  75.0%, Loss: 0.3846\n",
      "Optimization Iteration:  20737, Training Accuracy:  87.5%, Loss: 0.3120\n",
      "Optimization Iteration:  20801, Training Accuracy:  70.3%, Loss: 0.4810\n",
      "Optimization Iteration:  20865, Training Accuracy:  79.7%, Loss: 0.2914\n",
      "Optimization Iteration:  20929, Training Accuracy:  79.7%, Loss: 0.3744\n",
      "Optimization Iteration:  20993, Training Accuracy:  71.9%, Loss: 0.4724\n",
      "Optimization Iteration:  21057, Training Accuracy:  78.1%, Loss: 0.3404\n",
      "Optimization Iteration:  21121, Training Accuracy:  73.4%, Loss: 0.4190\n",
      "Optimization Iteration:  21185, Training Accuracy:  68.8%, Loss: 0.4701\n",
      "Optimization Iteration:  21249, Training Accuracy:  68.8%, Loss: 0.4378\n",
      "Optimization Iteration:  21313, Training Accuracy:  79.7%, Loss: 0.3555\n",
      "Optimization Iteration:  21377, Training Accuracy:  82.8%, Loss: 0.3329\n",
      "Optimization Iteration:  21441, Training Accuracy:  65.6%, Loss: 0.4649\n",
      "Optimization Iteration:  21505, Training Accuracy:  67.2%, Loss: 0.4497\n",
      "Optimization Iteration:  21569, Training Accuracy:  82.8%, Loss: 0.3310\n",
      "Optimization Iteration:  21633, Training Accuracy:  90.6%, Loss: 0.2514\n",
      "Optimization Iteration:  21697, Training Accuracy:  75.0%, Loss: 0.4883\n",
      "Optimization Iteration:  21761, Training Accuracy:  81.2%, Loss: 0.3271\n",
      "Optimization Iteration:  21825, Training Accuracy:  73.4%, Loss: 0.4580\n",
      "Optimization Iteration:  21889, Training Accuracy:  73.4%, Loss: 0.3831\n",
      "Optimization Iteration:  21953, Training Accuracy:  67.2%, Loss: 0.5715\n",
      "Optimization Iteration:  22017, Training Accuracy:  75.0%, Loss: 0.3600\n",
      "Optimization Iteration:  22081, Training Accuracy:  73.4%, Loss: 0.4190\n",
      "Optimization Iteration:  22145, Training Accuracy:  81.2%, Loss: 0.3904\n",
      "Optimization Iteration:  22209, Training Accuracy:  82.8%, Loss: 0.3883\n",
      "Optimization Iteration:  22273, Training Accuracy:  76.6%, Loss: 0.4035\n",
      "Optimization Iteration:  22337, Training Accuracy:  84.4%, Loss: 0.3352\n",
      "Optimization Iteration:  22401, Training Accuracy:  81.2%, Loss: 0.4220\n",
      "Optimization Iteration:  22465, Training Accuracy:  73.4%, Loss: 0.4628\n",
      "Optimization Iteration:  22529, Training Accuracy:  81.2%, Loss: 0.3650\n",
      "Optimization Iteration:  22593, Training Accuracy:  78.1%, Loss: 0.3910\n",
      "Optimization Iteration:  22657, Training Accuracy:  68.8%, Loss: 0.4494\n",
      "Optimization Iteration:  22721, Training Accuracy:  79.7%, Loss: 0.3976\n",
      "Optimization Iteration:  22785, Training Accuracy:  79.7%, Loss: 0.4116\n",
      "Optimization Iteration:  22849, Training Accuracy:  73.4%, Loss: 0.4116\n",
      "Optimization Iteration:  22913, Training Accuracy:  73.4%, Loss: 0.4283\n",
      "Optimization Iteration:  22977, Training Accuracy:  76.6%, Loss: 0.3603\n",
      "Optimization Iteration:  23041, Training Accuracy:  68.8%, Loss: 0.4044\n",
      "Optimization Iteration:  23105, Training Accuracy:  71.9%, Loss: 0.3793\n",
      "Optimization Iteration:  23169, Training Accuracy:  78.1%, Loss: 0.3655\n",
      "Optimization Iteration:  23233, Training Accuracy:  71.9%, Loss: 0.4338\n",
      "Optimization Iteration:  23297, Training Accuracy:  76.6%, Loss: 0.4373\n",
      "Optimization Iteration:  23361, Training Accuracy:  68.8%, Loss: 0.4019\n",
      "Optimization Iteration:  23425, Training Accuracy:  76.6%, Loss: 0.4529\n",
      "Optimization Iteration:  23489, Training Accuracy:  76.6%, Loss: 0.4098\n",
      "Optimization Iteration:  23553, Training Accuracy:  75.0%, Loss: 0.3376\n",
      "Optimization Iteration:  23617, Training Accuracy:  70.3%, Loss: 0.4711\n",
      "Optimization Iteration:  23681, Training Accuracy:  76.6%, Loss: 0.3907\n",
      "Optimization Iteration:  23745, Training Accuracy:  79.7%, Loss: 0.3859\n",
      "Optimization Iteration:  23809, Training Accuracy:  71.9%, Loss: 0.4675\n",
      "Optimization Iteration:  23873, Training Accuracy:  75.0%, Loss: 0.4265\n",
      "Optimization Iteration:  23937, Training Accuracy:  75.0%, Loss: 0.4344\n",
      "Optimization Iteration:  24001, Training Accuracy:  76.6%, Loss: 0.3267\n",
      "Optimization Iteration:  24065, Training Accuracy:  71.9%, Loss: 0.3512\n",
      "Optimization Iteration:  24129, Training Accuracy:  70.3%, Loss: 0.3877\n",
      "Optimization Iteration:  24193, Training Accuracy:  75.0%, Loss: 0.4303\n",
      "Optimization Iteration:  24257, Training Accuracy:  73.4%, Loss: 0.4039\n",
      "Optimization Iteration:  24321, Training Accuracy:  70.3%, Loss: 0.4564\n",
      "Optimization Iteration:  24385, Training Accuracy:  67.2%, Loss: 0.4458\n",
      "Optimization Iteration:  24449, Training Accuracy:  76.6%, Loss: 0.3312\n",
      "Optimization Iteration:  24513, Training Accuracy:  78.1%, Loss: 0.3489\n",
      "Optimization Iteration:  24577, Training Accuracy:  71.9%, Loss: 0.4951\n",
      "Optimization Iteration:  24641, Training Accuracy:  70.3%, Loss: 0.4704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  24705, Training Accuracy:  81.2%, Loss: 0.3434\n",
      "Optimization Iteration:  24769, Training Accuracy:  76.6%, Loss: 0.3621\n",
      "Optimization Iteration:  24833, Training Accuracy:  81.2%, Loss: 0.3404\n",
      "Optimization Iteration:  24897, Training Accuracy:  73.4%, Loss: 0.3965\n",
      "Optimization Iteration:  24961, Training Accuracy:  82.8%, Loss: 0.2794\n",
      "Optimization Iteration:  25025, Training Accuracy:  75.0%, Loss: 0.4012\n",
      "Optimization Iteration:  25089, Training Accuracy:  82.8%, Loss: 0.3422\n",
      "Optimization Iteration:  25153, Training Accuracy:  76.6%, Loss: 0.3619\n",
      "Optimization Iteration:  25217, Training Accuracy:  70.3%, Loss: 0.4892\n",
      "Optimization Iteration:  25281, Training Accuracy:  71.9%, Loss: 0.4847\n",
      "Optimization Iteration:  25345, Training Accuracy:  82.8%, Loss: 0.4231\n",
      "Optimization Iteration:  25409, Training Accuracy:  78.1%, Loss: 0.4359\n",
      "Optimization Iteration:  25473, Training Accuracy:  67.2%, Loss: 0.4308\n",
      "Optimization Iteration:  25537, Training Accuracy:  73.4%, Loss: 0.3813\n",
      "Optimization Iteration:  25601, Training Accuracy:  75.0%, Loss: 0.4566\n",
      "Optimization Iteration:  25665, Training Accuracy:  81.2%, Loss: 0.4234\n",
      "Optimization Iteration:  25729, Training Accuracy:  68.8%, Loss: 0.4170\n",
      "Optimization Iteration:  25793, Training Accuracy:  76.6%, Loss: 0.3684\n",
      "Optimization Iteration:  25857, Training Accuracy:  76.6%, Loss: 0.3817\n",
      "Optimization Iteration:  25921, Training Accuracy:  73.4%, Loss: 0.4720\n",
      "Optimization Iteration:  25985, Training Accuracy:  70.3%, Loss: 0.4290\n",
      "Optimization Iteration:  26049, Training Accuracy:  71.9%, Loss: 0.3991\n",
      "Optimization Iteration:  26113, Training Accuracy:  64.1%, Loss: 0.4153\n",
      "Optimization Iteration:  26177, Training Accuracy:  76.6%, Loss: 0.4034\n",
      "Optimization Iteration:  26241, Training Accuracy:  78.1%, Loss: 0.3532\n",
      "Optimization Iteration:  26305, Training Accuracy:  82.8%, Loss: 0.3515\n",
      "Optimization Iteration:  26369, Training Accuracy:  82.8%, Loss: 0.3855\n",
      "Optimization Iteration:  26433, Training Accuracy:  68.8%, Loss: 0.4125\n",
      "Optimization Iteration:  26497, Training Accuracy:  75.0%, Loss: 0.4112\n",
      "Optimization Iteration:  26561, Training Accuracy:  82.8%, Loss: 0.2805\n",
      "Optimization Iteration:  26625, Training Accuracy:  75.0%, Loss: 0.4045\n",
      "Optimization Iteration:  26689, Training Accuracy:  78.1%, Loss: 0.3665\n",
      "Optimization Iteration:  26753, Training Accuracy:  67.2%, Loss: 0.4387\n",
      "Optimization Iteration:  26817, Training Accuracy:  71.9%, Loss: 0.3990\n",
      "Optimization Iteration:  26881, Training Accuracy:  87.5%, Loss: 0.2998\n",
      "Optimization Iteration:  26945, Training Accuracy:  70.3%, Loss: 0.4582\n",
      "Optimization Iteration:  27009, Training Accuracy:  84.4%, Loss: 0.3406\n",
      "Optimization Iteration:  27073, Training Accuracy:  70.3%, Loss: 0.4179\n",
      "Optimization Iteration:  27137, Training Accuracy:  81.2%, Loss: 0.3313\n",
      "Optimization Iteration:  27201, Training Accuracy:  81.2%, Loss: 0.2680\n",
      "Optimization Iteration:  27265, Training Accuracy:  79.7%, Loss: 0.3487\n",
      "Optimization Iteration:  27329, Training Accuracy:  73.4%, Loss: 0.3546\n",
      "Optimization Iteration:  27393, Training Accuracy:  70.3%, Loss: 0.4220\n",
      "Optimization Iteration:  27457, Training Accuracy:  81.2%, Loss: 0.3232\n",
      "Optimization Iteration:  27521, Training Accuracy:  71.9%, Loss: 0.4787\n",
      "Optimization Iteration:  27585, Training Accuracy:  65.6%, Loss: 0.4093\n",
      "Optimization Iteration:  27649, Training Accuracy:  75.0%, Loss: 0.3800\n",
      "Optimization Iteration:  27713, Training Accuracy:  75.0%, Loss: 0.4081\n",
      "Optimization Iteration:  27777, Training Accuracy:  76.6%, Loss: 0.3614\n",
      "Optimization Iteration:  27841, Training Accuracy:  79.7%, Loss: 0.4046\n",
      "Optimization Iteration:  27905, Training Accuracy:  78.1%, Loss: 0.3515\n",
      "Optimization Iteration:  27969, Training Accuracy:  73.4%, Loss: 0.4499\n",
      "Optimization Iteration:  28033, Training Accuracy:  76.6%, Loss: 0.3723\n",
      "Optimization Iteration:  28097, Training Accuracy:  76.6%, Loss: 0.3929\n",
      "Optimization Iteration:  28161, Training Accuracy:  89.1%, Loss: 0.3848\n",
      "Optimization Iteration:  28225, Training Accuracy:  73.4%, Loss: 0.3620\n",
      "Optimization Iteration:  28289, Training Accuracy:  79.7%, Loss: 0.3730\n",
      "Optimization Iteration:  28353, Training Accuracy:  73.4%, Loss: 0.4385\n",
      "Optimization Iteration:  28417, Training Accuracy:  68.8%, Loss: 0.4580\n",
      "Optimization Iteration:  28481, Training Accuracy:  78.1%, Loss: 0.3333\n",
      "Optimization Iteration:  28545, Training Accuracy:  73.4%, Loss: 0.3463\n",
      "Optimization Iteration:  28609, Training Accuracy:  79.7%, Loss: 0.3314\n",
      "Optimization Iteration:  28673, Training Accuracy:  67.2%, Loss: 0.4400\n",
      "Optimization Iteration:  28737, Training Accuracy:  67.2%, Loss: 0.3915\n",
      "Optimization Iteration:  28801, Training Accuracy:  76.6%, Loss: 0.3038\n",
      "Optimization Iteration:  28865, Training Accuracy:  75.0%, Loss: 0.3362\n",
      "Optimization Iteration:  28929, Training Accuracy:  76.6%, Loss: 0.3746\n",
      "Optimization Iteration:  28993, Training Accuracy:  71.9%, Loss: 0.4045\n",
      "Optimization Iteration:  29057, Training Accuracy:  67.2%, Loss: 0.3999\n",
      "Optimization Iteration:  29121, Training Accuracy:  82.8%, Loss: 0.3947\n",
      "Optimization Iteration:  29185, Training Accuracy:  75.0%, Loss: 0.3529\n",
      "Optimization Iteration:  29249, Training Accuracy:  78.1%, Loss: 0.4206\n",
      "Optimization Iteration:  29313, Training Accuracy:  76.6%, Loss: 0.4092\n",
      "Optimization Iteration:  29377, Training Accuracy:  79.7%, Loss: 0.3882\n",
      "Optimization Iteration:  29441, Training Accuracy:  84.4%, Loss: 0.3519\n",
      "Optimization Iteration:  29505, Training Accuracy:  78.1%, Loss: 0.3849\n",
      "Optimization Iteration:  29569, Training Accuracy:  73.4%, Loss: 0.3878\n",
      "Optimization Iteration:  29633, Training Accuracy:  78.1%, Loss: 0.4041\n",
      "Optimization Iteration:  29697, Training Accuracy:  82.8%, Loss: 0.3582\n",
      "Optimization Iteration:  29761, Training Accuracy:  78.1%, Loss: 0.3444\n",
      "Optimization Iteration:  29825, Training Accuracy:  73.4%, Loss: 0.4028\n",
      "Optimization Iteration:  29889, Training Accuracy:  79.7%, Loss: 0.4018\n",
      "Optimization Iteration:  29953, Training Accuracy:  76.6%, Loss: 0.4134\n",
      "Optimization Iteration:  30017, Training Accuracy:  92.2%, Loss: 0.2786\n",
      "Optimization Iteration:  30081, Training Accuracy:  90.6%, Loss: 0.2731\n",
      "Optimization Iteration:  30145, Training Accuracy:  79.7%, Loss: 0.4262\n",
      "Optimization Iteration:  30209, Training Accuracy:  68.8%, Loss: 0.3753\n",
      "Optimization Iteration:  30273, Training Accuracy:  76.6%, Loss: 0.3565\n",
      "Optimization Iteration:  30337, Training Accuracy:  73.4%, Loss: 0.3459\n",
      "Optimization Iteration:  30401, Training Accuracy:  75.0%, Loss: 0.4372\n",
      "Optimization Iteration:  30465, Training Accuracy:  70.3%, Loss: 0.3923\n",
      "Optimization Iteration:  30529, Training Accuracy:  79.7%, Loss: 0.3525\n",
      "Optimization Iteration:  30593, Training Accuracy:  85.9%, Loss: 0.3272\n",
      "Optimization Iteration:  30657, Training Accuracy:  79.7%, Loss: 0.3419\n",
      "Optimization Iteration:  30721, Training Accuracy:  68.8%, Loss: 0.3884\n",
      "Optimization Iteration:  30785, Training Accuracy:  68.8%, Loss: 0.4537\n",
      "Optimization Iteration:  30849, Training Accuracy:  71.9%, Loss: 0.4181\n",
      "Optimization Iteration:  30913, Training Accuracy:  78.1%, Loss: 0.3754\n",
      "Optimization Iteration:  30977, Training Accuracy:  73.4%, Loss: 0.3890\n",
      "Optimization Iteration:  31041, Training Accuracy:  78.1%, Loss: 0.3760\n",
      "Optimization Iteration:  31105, Training Accuracy:  68.8%, Loss: 0.4099\n",
      "Optimization Iteration:  31169, Training Accuracy:  71.9%, Loss: 0.3827\n",
      "Optimization Iteration:  31233, Training Accuracy:  73.4%, Loss: 0.3667\n",
      "Optimization Iteration:  31297, Training Accuracy:  71.9%, Loss: 0.3269\n",
      "Optimization Iteration:  31361, Training Accuracy:  75.0%, Loss: 0.3699\n",
      "Optimization Iteration:  31425, Training Accuracy:  81.2%, Loss: 0.2601\n",
      "Optimization Iteration:  31489, Training Accuracy:  85.9%, Loss: 0.3768\n",
      "Optimization Iteration:  31553, Training Accuracy:  79.7%, Loss: 0.3520\n",
      "Optimization Iteration:  31617, Training Accuracy:  79.7%, Loss: 0.3672\n",
      "Optimization Iteration:  31681, Training Accuracy:  82.8%, Loss: 0.3957\n",
      "Optimization Iteration:  31745, Training Accuracy:  76.6%, Loss: 0.3751\n",
      "Optimization Iteration:  31809, Training Accuracy:  59.4%, Loss: 0.4702\n",
      "Optimization Iteration:  31873, Training Accuracy:  81.2%, Loss: 0.2805\n",
      "Optimization Iteration:  31937, Training Accuracy:  71.9%, Loss: 0.4053\n",
      "Optimization Iteration:  32001, Training Accuracy:  73.4%, Loss: 0.4262\n",
      "Optimization Iteration:  32065, Training Accuracy:  78.1%, Loss: 0.3204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  32129, Training Accuracy:  81.2%, Loss: 0.3767\n",
      "Optimization Iteration:  32193, Training Accuracy:  68.8%, Loss: 0.4456\n",
      "Optimization Iteration:  32257, Training Accuracy:  81.2%, Loss: 0.3969\n",
      "Optimization Iteration:  32321, Training Accuracy:  78.1%, Loss: 0.3408\n",
      "Optimization Iteration:  32385, Training Accuracy:  75.0%, Loss: 0.3809\n",
      "Optimization Iteration:  32449, Training Accuracy:  70.3%, Loss: 0.4196\n",
      "Optimization Iteration:  32513, Training Accuracy:  82.8%, Loss: 0.3055\n",
      "Optimization Iteration:  32577, Training Accuracy:  73.4%, Loss: 0.3728\n",
      "Optimization Iteration:  32641, Training Accuracy:  75.0%, Loss: 0.4113\n",
      "Optimization Iteration:  32705, Training Accuracy:  81.2%, Loss: 0.3532\n",
      "Optimization Iteration:  32769, Training Accuracy:  70.3%, Loss: 0.3801\n",
      "Optimization Iteration:  32833, Training Accuracy:  78.1%, Loss: 0.3606\n",
      "Optimization Iteration:  32897, Training Accuracy:  75.0%, Loss: 0.4023\n",
      "Optimization Iteration:  32961, Training Accuracy:  67.2%, Loss: 0.4561\n",
      "Optimization Iteration:  33025, Training Accuracy:  71.9%, Loss: 0.3917\n",
      "Optimization Iteration:  33089, Training Accuracy:  70.3%, Loss: 0.4773\n",
      "Optimization Iteration:  33153, Training Accuracy:  68.8%, Loss: 0.4998\n",
      "Optimization Iteration:  33217, Training Accuracy:  70.3%, Loss: 0.3907\n",
      "Optimization Iteration:  33281, Training Accuracy:  60.9%, Loss: 0.4925\n",
      "Optimization Iteration:  33345, Training Accuracy:  71.9%, Loss: 0.4029\n",
      "Optimization Iteration:  33409, Training Accuracy:  70.3%, Loss: 0.4549\n",
      "Optimization Iteration:  33473, Training Accuracy:  79.7%, Loss: 0.4004\n",
      "Optimization Iteration:  33537, Training Accuracy:  71.9%, Loss: 0.4526\n",
      "Optimization Iteration:  33601, Training Accuracy:  81.2%, Loss: 0.3925\n",
      "Optimization Iteration:  33665, Training Accuracy:  81.2%, Loss: 0.3514\n",
      "Optimization Iteration:  33729, Training Accuracy:  81.2%, Loss: 0.3930\n",
      "Optimization Iteration:  33793, Training Accuracy:  75.0%, Loss: 0.4347\n",
      "Optimization Iteration:  33857, Training Accuracy:  73.4%, Loss: 0.3772\n",
      "Optimization Iteration:  33921, Training Accuracy:  82.8%, Loss: 0.3613\n",
      "Optimization Iteration:  33985, Training Accuracy:  76.6%, Loss: 0.3886\n",
      "Optimization Iteration:  34049, Training Accuracy:  70.3%, Loss: 0.5092\n",
      "Optimization Iteration:  34113, Training Accuracy:  82.8%, Loss: 0.3500\n",
      "Optimization Iteration:  34177, Training Accuracy:  71.9%, Loss: 0.3676\n",
      "Optimization Iteration:  34241, Training Accuracy:  79.7%, Loss: 0.4079\n",
      "Optimization Iteration:  34305, Training Accuracy:  70.3%, Loss: 0.4992\n",
      "Optimization Iteration:  34369, Training Accuracy:  81.2%, Loss: 0.3037\n",
      "Optimization Iteration:  34433, Training Accuracy:  78.1%, Loss: 0.4060\n",
      "Optimization Iteration:  34497, Training Accuracy:  85.9%, Loss: 0.3088\n",
      "Optimization Iteration:  34561, Training Accuracy:  81.2%, Loss: 0.3460\n",
      "Optimization Iteration:  34625, Training Accuracy:  73.4%, Loss: 0.4642\n",
      "Optimization Iteration:  34689, Training Accuracy:  75.0%, Loss: 0.4445\n",
      "Optimization Iteration:  34753, Training Accuracy:  71.9%, Loss: 0.4039\n",
      "Optimization Iteration:  34817, Training Accuracy:  78.1%, Loss: 0.4213\n",
      "Optimization Iteration:  34881, Training Accuracy:  73.4%, Loss: 0.4132\n",
      "Optimization Iteration:  34945, Training Accuracy:  81.2%, Loss: 0.3781\n",
      "Optimization Iteration:  35009, Training Accuracy:  79.7%, Loss: 0.3421\n",
      "Optimization Iteration:  35073, Training Accuracy:  76.6%, Loss: 0.3450\n",
      "Optimization Iteration:  35137, Training Accuracy:  67.2%, Loss: 0.4155\n",
      "Optimization Iteration:  35201, Training Accuracy:  76.6%, Loss: 0.3150\n",
      "Optimization Iteration:  35265, Training Accuracy:  73.4%, Loss: 0.3751\n",
      "Optimization Iteration:  35329, Training Accuracy:  81.2%, Loss: 0.3883\n",
      "Optimization Iteration:  35393, Training Accuracy:  70.3%, Loss: 0.4049\n",
      "Optimization Iteration:  35457, Training Accuracy:  76.6%, Loss: 0.3663\n",
      "Optimization Iteration:  35521, Training Accuracy:  65.6%, Loss: 0.4094\n",
      "Optimization Iteration:  35585, Training Accuracy:  84.4%, Loss: 0.2351\n",
      "Optimization Iteration:  35649, Training Accuracy:  78.1%, Loss: 0.4389\n",
      "Optimization Iteration:  35713, Training Accuracy:  79.7%, Loss: 0.3749\n",
      "Optimization Iteration:  35777, Training Accuracy:  79.7%, Loss: 0.4512\n",
      "Optimization Iteration:  35841, Training Accuracy:  75.0%, Loss: 0.3705\n",
      "Optimization Iteration:  35905, Training Accuracy:  79.7%, Loss: 0.3621\n",
      "Optimization Iteration:  35969, Training Accuracy:  70.3%, Loss: 0.4490\n",
      "Optimization Iteration:  36033, Training Accuracy:  73.4%, Loss: 0.3931\n",
      "Optimization Iteration:  36097, Training Accuracy:  70.3%, Loss: 0.3925\n",
      "Optimization Iteration:  36161, Training Accuracy:  71.9%, Loss: 0.3831\n",
      "Optimization Iteration:  36225, Training Accuracy:  78.1%, Loss: 0.3846\n",
      "Optimization Iteration:  36289, Training Accuracy:  78.1%, Loss: 0.3448\n",
      "Optimization Iteration:  36353, Training Accuracy:  81.2%, Loss: 0.3205\n",
      "Optimization Iteration:  36417, Training Accuracy:  79.7%, Loss: 0.3979\n",
      "Optimization Iteration:  36481, Training Accuracy:  73.4%, Loss: 0.4007\n",
      "Optimization Iteration:  36545, Training Accuracy:  81.2%, Loss: 0.3469\n",
      "Optimization Iteration:  36609, Training Accuracy:  78.1%, Loss: 0.3557\n",
      "Optimization Iteration:  36673, Training Accuracy:  78.1%, Loss: 0.3907\n",
      "Optimization Iteration:  36737, Training Accuracy:  75.0%, Loss: 0.3971\n",
      "Optimization Iteration:  36801, Training Accuracy:  76.6%, Loss: 0.3619\n",
      "Optimization Iteration:  36865, Training Accuracy:  76.6%, Loss: 0.4401\n",
      "Optimization Iteration:  36929, Training Accuracy:  81.2%, Loss: 0.4088\n",
      "Optimization Iteration:  36993, Training Accuracy:  75.0%, Loss: 0.4182\n",
      "Optimization Iteration:  37057, Training Accuracy:  79.7%, Loss: 0.3133\n",
      "Optimization Iteration:  37121, Training Accuracy:  78.1%, Loss: 0.3363\n",
      "Optimization Iteration:  37185, Training Accuracy:  81.2%, Loss: 0.3800\n",
      "Optimization Iteration:  37249, Training Accuracy:  71.9%, Loss: 0.5111\n",
      "Optimization Iteration:  37313, Training Accuracy:  82.8%, Loss: 0.3537\n",
      "Optimization Iteration:  37377, Training Accuracy:  73.4%, Loss: 0.3977\n",
      "Optimization Iteration:  37441, Training Accuracy:  73.4%, Loss: 0.3935\n",
      "Optimization Iteration:  37505, Training Accuracy:  76.6%, Loss: 0.3676\n",
      "Optimization Iteration:  37569, Training Accuracy:  81.2%, Loss: 0.3679\n",
      "Optimization Iteration:  37633, Training Accuracy:  70.3%, Loss: 0.3930\n",
      "Optimization Iteration:  37697, Training Accuracy:  73.4%, Loss: 0.4267\n",
      "Optimization Iteration:  37761, Training Accuracy:  75.0%, Loss: 0.3934\n",
      "Optimization Iteration:  37825, Training Accuracy:  78.1%, Loss: 0.3532\n",
      "Optimization Iteration:  37889, Training Accuracy:  75.0%, Loss: 0.3522\n",
      "Optimization Iteration:  37953, Training Accuracy:  78.1%, Loss: 0.3710\n",
      "Optimization Iteration:  38017, Training Accuracy:  79.7%, Loss: 0.4122\n",
      "Optimization Iteration:  38081, Training Accuracy:  67.2%, Loss: 0.4544\n",
      "Optimization Iteration:  38145, Training Accuracy:  76.6%, Loss: 0.3554\n",
      "Optimization Iteration:  38209, Training Accuracy:  73.4%, Loss: 0.4346\n",
      "Optimization Iteration:  38273, Training Accuracy:  76.6%, Loss: 0.3836\n",
      "Optimization Iteration:  38337, Training Accuracy:  76.6%, Loss: 0.3054\n",
      "Optimization Iteration:  38401, Training Accuracy:  79.7%, Loss: 0.3615\n",
      "Optimization Iteration:  38465, Training Accuracy:  76.6%, Loss: 0.4478\n",
      "Optimization Iteration:  38529, Training Accuracy:  70.3%, Loss: 0.5125\n",
      "Optimization Iteration:  38593, Training Accuracy:  67.2%, Loss: 0.5101\n",
      "Optimization Iteration:  38657, Training Accuracy:  70.3%, Loss: 0.4950\n",
      "Optimization Iteration:  38721, Training Accuracy:  68.8%, Loss: 0.4184\n",
      "Optimization Iteration:  38785, Training Accuracy:  71.9%, Loss: 0.4767\n",
      "Optimization Iteration:  38849, Training Accuracy:  79.7%, Loss: 0.2836\n",
      "Optimization Iteration:  38913, Training Accuracy:  82.8%, Loss: 0.3926\n",
      "Optimization Iteration:  38977, Training Accuracy:  76.6%, Loss: 0.4008\n",
      "Optimization Iteration:  39041, Training Accuracy:  82.8%, Loss: 0.3125\n",
      "Optimization Iteration:  39105, Training Accuracy:  78.1%, Loss: 0.4026\n",
      "Optimization Iteration:  39169, Training Accuracy:  67.2%, Loss: 0.5434\n",
      "Optimization Iteration:  39233, Training Accuracy:  73.4%, Loss: 0.4565\n",
      "Optimization Iteration:  39297, Training Accuracy:  75.0%, Loss: 0.4272\n",
      "Optimization Iteration:  39361, Training Accuracy:  73.4%, Loss: 0.4320\n",
      "Optimization Iteration:  39425, Training Accuracy:  76.6%, Loss: 0.3822\n",
      "Optimization Iteration:  39489, Training Accuracy:  78.1%, Loss: 0.3395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  39553, Training Accuracy:  76.6%, Loss: 0.3799\n",
      "Optimization Iteration:  39617, Training Accuracy:  81.2%, Loss: 0.4311\n",
      "Optimization Iteration:  39681, Training Accuracy:  71.9%, Loss: 0.4169\n",
      "Optimization Iteration:  39745, Training Accuracy:  75.0%, Loss: 0.4287\n",
      "Optimization Iteration:  39809, Training Accuracy:  73.4%, Loss: 0.4391\n",
      "Optimization Iteration:  39873, Training Accuracy:  70.3%, Loss: 0.4531\n",
      "Optimization Iteration:  39937, Training Accuracy:  82.8%, Loss: 0.4624\n",
      "Optimization Iteration:  40001, Training Accuracy:  70.3%, Loss: 0.4354\n",
      "Optimization Iteration:  40065, Training Accuracy:  71.9%, Loss: 0.3695\n",
      "Optimization Iteration:  40129, Training Accuracy:  75.0%, Loss: 0.4029\n",
      "Optimization Iteration:  40193, Training Accuracy:  79.7%, Loss: 0.3679\n",
      "Optimization Iteration:  40257, Training Accuracy:  73.4%, Loss: 0.3641\n",
      "Optimization Iteration:  40321, Training Accuracy:  73.4%, Loss: 0.4289\n",
      "Optimization Iteration:  40385, Training Accuracy:  76.6%, Loss: 0.3767\n",
      "Optimization Iteration:  40449, Training Accuracy:  75.0%, Loss: 0.3971\n",
      "Optimization Iteration:  40513, Training Accuracy:  81.2%, Loss: 0.3344\n",
      "Optimization Iteration:  40577, Training Accuracy:  76.6%, Loss: 0.3533\n",
      "Optimization Iteration:  40641, Training Accuracy:  78.1%, Loss: 0.4022\n",
      "Optimization Iteration:  40705, Training Accuracy:  73.4%, Loss: 0.4012\n",
      "Optimization Iteration:  40769, Training Accuracy:  75.0%, Loss: 0.3903\n",
      "Optimization Iteration:  40833, Training Accuracy:  79.7%, Loss: 0.3746\n",
      "Optimization Iteration:  40897, Training Accuracy:  76.6%, Loss: 0.4332\n",
      "Optimization Iteration:  40961, Training Accuracy:  87.5%, Loss: 0.3323\n",
      "Optimization Iteration:  41025, Training Accuracy:  79.7%, Loss: 0.4038\n",
      "Optimization Iteration:  41089, Training Accuracy:  78.1%, Loss: 0.3718\n",
      "Optimization Iteration:  41153, Training Accuracy:  81.2%, Loss: 0.4096\n",
      "Optimization Iteration:  41217, Training Accuracy:  84.4%, Loss: 0.2925\n",
      "Optimization Iteration:  41281, Training Accuracy:  68.8%, Loss: 0.4906\n",
      "Optimization Iteration:  41345, Training Accuracy:  75.0%, Loss: 0.4138\n",
      "Optimization Iteration:  41409, Training Accuracy:  76.6%, Loss: 0.3554\n",
      "Optimization Iteration:  41473, Training Accuracy:  70.3%, Loss: 0.4608\n",
      "Optimization Iteration:  41537, Training Accuracy:  73.4%, Loss: 0.4197\n",
      "Optimization Iteration:  41601, Training Accuracy:  73.4%, Loss: 0.3729\n",
      "Optimization Iteration:  41665, Training Accuracy:  81.2%, Loss: 0.3890\n",
      "Optimization Iteration:  41729, Training Accuracy:  78.1%, Loss: 0.3414\n",
      "Optimization Iteration:  41793, Training Accuracy:  82.8%, Loss: 0.3731\n",
      "Optimization Iteration:  41857, Training Accuracy:  71.9%, Loss: 0.4200\n",
      "Optimization Iteration:  41921, Training Accuracy:  81.2%, Loss: 0.3078\n",
      "Optimization Iteration:  41985, Training Accuracy:  71.9%, Loss: 0.4440\n",
      "Optimization Iteration:  42049, Training Accuracy:  68.8%, Loss: 0.4657\n",
      "Optimization Iteration:  42113, Training Accuracy:  79.7%, Loss: 0.3675\n",
      "Optimization Iteration:  42177, Training Accuracy:  76.6%, Loss: 0.4035\n",
      "Optimization Iteration:  42241, Training Accuracy:  75.0%, Loss: 0.3863\n",
      "Optimization Iteration:  42305, Training Accuracy:  70.3%, Loss: 0.4692\n",
      "Optimization Iteration:  42369, Training Accuracy:  73.4%, Loss: 0.4077\n",
      "Optimization Iteration:  42433, Training Accuracy:  67.2%, Loss: 0.4603\n",
      "Optimization Iteration:  42497, Training Accuracy:  75.0%, Loss: 0.4120\n",
      "Optimization Iteration:  42561, Training Accuracy:  89.1%, Loss: 0.3457\n",
      "Optimization Iteration:  42625, Training Accuracy:  76.6%, Loss: 0.4157\n",
      "Optimization Iteration:  42689, Training Accuracy:  76.6%, Loss: 0.3740\n",
      "Optimization Iteration:  42753, Training Accuracy:  71.9%, Loss: 0.4300\n",
      "Optimization Iteration:  42817, Training Accuracy:  78.1%, Loss: 0.3606\n",
      "Optimization Iteration:  42881, Training Accuracy:  78.1%, Loss: 0.4314\n",
      "Optimization Iteration:  42945, Training Accuracy:  78.1%, Loss: 0.3644\n",
      "Optimization Iteration:  43009, Training Accuracy:  73.4%, Loss: 0.4342\n",
      "Optimization Iteration:  43073, Training Accuracy:  76.6%, Loss: 0.3865\n",
      "Optimization Iteration:  43137, Training Accuracy:  84.4%, Loss: 0.3906\n",
      "Optimization Iteration:  43201, Training Accuracy:  78.1%, Loss: 0.3787\n",
      "Optimization Iteration:  43265, Training Accuracy:  84.4%, Loss: 0.3578\n",
      "Optimization Iteration:  43329, Training Accuracy:  76.6%, Loss: 0.3832\n",
      "Optimization Iteration:  43393, Training Accuracy:  78.1%, Loss: 0.4002\n",
      "Optimization Iteration:  43457, Training Accuracy:  82.8%, Loss: 0.3507\n",
      "Optimization Iteration:  43521, Training Accuracy:  78.1%, Loss: 0.3983\n",
      "Optimization Iteration:  43585, Training Accuracy:  76.6%, Loss: 0.3466\n",
      "Optimization Iteration:  43649, Training Accuracy:  73.4%, Loss: 0.3772\n",
      "Optimization Iteration:  43713, Training Accuracy:  75.0%, Loss: 0.4128\n",
      "Optimization Iteration:  43777, Training Accuracy:  85.9%, Loss: 0.3082\n",
      "Optimization Iteration:  43841, Training Accuracy:  78.1%, Loss: 0.4424\n",
      "Optimization Iteration:  43905, Training Accuracy:  81.2%, Loss: 0.4252\n",
      "Optimization Iteration:  43969, Training Accuracy:  84.4%, Loss: 0.3434\n",
      "Optimization Iteration:  44033, Training Accuracy:  76.6%, Loss: 0.3662\n",
      "Optimization Iteration:  44097, Training Accuracy:  84.4%, Loss: 0.3221\n",
      "Optimization Iteration:  44161, Training Accuracy:  73.4%, Loss: 0.3944\n",
      "Optimization Iteration:  44225, Training Accuracy:  75.0%, Loss: 0.3786\n",
      "Optimization Iteration:  44289, Training Accuracy:  75.0%, Loss: 0.4344\n",
      "Optimization Iteration:  44353, Training Accuracy:  68.8%, Loss: 0.5006\n",
      "Optimization Iteration:  44417, Training Accuracy:  76.6%, Loss: 0.4017\n",
      "Optimization Iteration:  44481, Training Accuracy:  68.8%, Loss: 0.4345\n",
      "Optimization Iteration:  44545, Training Accuracy:  76.6%, Loss: 0.3455\n",
      "Optimization Iteration:  44609, Training Accuracy:  78.1%, Loss: 0.3612\n",
      "Optimization Iteration:  44673, Training Accuracy:  82.8%, Loss: 0.6038\n",
      "Optimization Iteration:  44737, Training Accuracy:  75.0%, Loss: 0.3964\n",
      "Optimization Iteration:  44801, Training Accuracy:  78.1%, Loss: 0.3848\n",
      "Optimization Iteration:  44865, Training Accuracy:  70.3%, Loss: 0.4416\n",
      "Optimization Iteration:  44929, Training Accuracy:  84.4%, Loss: 0.3575\n",
      "Optimization Iteration:  44993, Training Accuracy:  76.6%, Loss: 0.3545\n",
      "Optimization Iteration:  45057, Training Accuracy:  81.2%, Loss: 0.4267\n",
      "Optimization Iteration:  45121, Training Accuracy:  84.4%, Loss: 0.3217\n",
      "Optimization Iteration:  45185, Training Accuracy:  84.4%, Loss: 0.2985\n",
      "Optimization Iteration:  45249, Training Accuracy:  78.1%, Loss: 0.4017\n",
      "Optimization Iteration:  45313, Training Accuracy:  81.2%, Loss: 0.3645\n",
      "Optimization Iteration:  45377, Training Accuracy:  78.1%, Loss: 0.4137\n",
      "Optimization Iteration:  45441, Training Accuracy:  71.9%, Loss: 0.4001\n",
      "Optimization Iteration:  45505, Training Accuracy:  75.0%, Loss: 0.3831\n",
      "Optimization Iteration:  45569, Training Accuracy:  73.4%, Loss: 0.4228\n",
      "Optimization Iteration:  45633, Training Accuracy:  84.4%, Loss: 0.4192\n",
      "Optimization Iteration:  45697, Training Accuracy:  79.7%, Loss: 0.3685\n",
      "Optimization Iteration:  45761, Training Accuracy:  85.9%, Loss: 0.3905\n",
      "Optimization Iteration:  45825, Training Accuracy:  76.6%, Loss: 0.3422\n",
      "Optimization Iteration:  45889, Training Accuracy:  79.7%, Loss: 0.3403\n",
      "Optimization Iteration:  45953, Training Accuracy:  71.9%, Loss: 0.4137\n",
      "Optimization Iteration:  46017, Training Accuracy:  75.0%, Loss: 0.4023\n",
      "Optimization Iteration:  46081, Training Accuracy:  76.6%, Loss: 0.3123\n",
      "Optimization Iteration:  46145, Training Accuracy:  71.9%, Loss: 0.4175\n",
      "Optimization Iteration:  46209, Training Accuracy:  85.9%, Loss: 0.3509\n",
      "Optimization Iteration:  46273, Training Accuracy:  70.3%, Loss: 0.4585\n",
      "Optimization Iteration:  46337, Training Accuracy:  70.3%, Loss: 0.4250\n",
      "Optimization Iteration:  46401, Training Accuracy:  78.1%, Loss: 0.3827\n",
      "Optimization Iteration:  46465, Training Accuracy:  68.8%, Loss: 0.4537\n",
      "Optimization Iteration:  46529, Training Accuracy:  73.4%, Loss: 0.4076\n",
      "Optimization Iteration:  46593, Training Accuracy:  78.1%, Loss: 0.3852\n",
      "Optimization Iteration:  46657, Training Accuracy:  76.6%, Loss: 0.4376\n",
      "Optimization Iteration:  46721, Training Accuracy:  73.4%, Loss: 0.3667\n",
      "Optimization Iteration:  46785, Training Accuracy:  73.4%, Loss: 0.4388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  46849, Training Accuracy:  71.9%, Loss: 0.3851\n",
      "Optimization Iteration:  46913, Training Accuracy:  76.6%, Loss: 0.3670\n",
      "Optimization Iteration:  46977, Training Accuracy:  85.9%, Loss: 0.3901\n",
      "Optimization Iteration:  47041, Training Accuracy:  76.6%, Loss: 0.3441\n",
      "Optimization Iteration:  47105, Training Accuracy:  76.6%, Loss: 0.4669\n",
      "Optimization Iteration:  47169, Training Accuracy:  67.2%, Loss: 0.4367\n",
      "Optimization Iteration:  47233, Training Accuracy:  73.4%, Loss: 0.4131\n",
      "Optimization Iteration:  47297, Training Accuracy:  70.3%, Loss: 0.3444\n",
      "Optimization Iteration:  47361, Training Accuracy:  81.2%, Loss: 0.2969\n",
      "Optimization Iteration:  47425, Training Accuracy:  82.8%, Loss: 0.3409\n",
      "Optimization Iteration:  47489, Training Accuracy:  71.9%, Loss: 0.4691\n",
      "Optimization Iteration:  47553, Training Accuracy:  79.7%, Loss: 0.4141\n",
      "Optimization Iteration:  47617, Training Accuracy:  79.7%, Loss: 0.4295\n",
      "Optimization Iteration:  47681, Training Accuracy:  84.4%, Loss: 0.3427\n",
      "Optimization Iteration:  47745, Training Accuracy:  78.1%, Loss: 0.4178\n",
      "Optimization Iteration:  47809, Training Accuracy:  71.9%, Loss: 0.3887\n",
      "Optimization Iteration:  47873, Training Accuracy:  82.8%, Loss: 0.3101\n",
      "Optimization Iteration:  47937, Training Accuracy:  64.1%, Loss: 0.4027\n",
      "Optimization Iteration:  48001, Training Accuracy:  73.4%, Loss: 0.3529\n",
      "Optimization Iteration:  48065, Training Accuracy:  79.7%, Loss: 0.3663\n",
      "Optimization Iteration:  48129, Training Accuracy:  82.8%, Loss: 0.4044\n",
      "Optimization Iteration:  48193, Training Accuracy:  75.0%, Loss: 0.4932\n",
      "Optimization Iteration:  48257, Training Accuracy:  78.1%, Loss: 0.3790\n",
      "Optimization Iteration:  48321, Training Accuracy:  70.3%, Loss: 0.3944\n",
      "Optimization Iteration:  48385, Training Accuracy:  84.4%, Loss: 0.3419\n",
      "Optimization Iteration:  48449, Training Accuracy:  71.9%, Loss: 0.4016\n",
      "Optimization Iteration:  48513, Training Accuracy:  78.1%, Loss: 0.4148\n",
      "Optimization Iteration:  48577, Training Accuracy:  70.3%, Loss: 0.4261\n",
      "Optimization Iteration:  48641, Training Accuracy:  78.1%, Loss: 0.3471\n",
      "Optimization Iteration:  48705, Training Accuracy:  81.2%, Loss: 0.3204\n",
      "Optimization Iteration:  48769, Training Accuracy:  82.8%, Loss: 0.3897\n",
      "Optimization Iteration:  48833, Training Accuracy:  85.9%, Loss: 0.3101\n",
      "Optimization Iteration:  48897, Training Accuracy:  71.9%, Loss: 0.4077\n",
      "Optimization Iteration:  48961, Training Accuracy:  76.6%, Loss: 0.4639\n",
      "Optimization Iteration:  49025, Training Accuracy:  73.4%, Loss: 0.4284\n",
      "Optimization Iteration:  49089, Training Accuracy:  73.4%, Loss: 0.3842\n",
      "Optimization Iteration:  49153, Training Accuracy:  71.9%, Loss: 0.3783\n",
      "Optimization Iteration:  49217, Training Accuracy:  79.7%, Loss: 0.3665\n",
      "Optimization Iteration:  49281, Training Accuracy:  68.8%, Loss: 0.4347\n",
      "Optimization Iteration:  49345, Training Accuracy:  71.9%, Loss: 0.3932\n",
      "Optimization Iteration:  49409, Training Accuracy:  73.4%, Loss: 0.3945\n",
      "Optimization Iteration:  49473, Training Accuracy:  75.0%, Loss: 0.3824\n",
      "Optimization Iteration:  49537, Training Accuracy:  76.6%, Loss: 0.3659\n",
      "Optimization Iteration:  49601, Training Accuracy:  78.1%, Loss: 0.3809\n",
      "Optimization Iteration:  49665, Training Accuracy:  78.1%, Loss: 0.3763\n",
      "Optimization Iteration:  49729, Training Accuracy:  65.6%, Loss: 0.4663\n",
      "Optimization Iteration:  49793, Training Accuracy:  71.9%, Loss: 0.3532\n",
      "Optimization Iteration:  49857, Training Accuracy:  73.4%, Loss: 0.4569\n",
      "Optimization Iteration:  49921, Training Accuracy:  73.4%, Loss: 0.3964\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 25\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  78.1%, Loss: 0.4533\n",
      "Optimization Iteration:    129, Training Accuracy:  71.9%, Loss: 0.4611\n",
      "Optimization Iteration:    193, Training Accuracy:  75.0%, Loss: 0.4204\n",
      "Optimization Iteration:    257, Training Accuracy:  79.7%, Loss: 0.3545\n",
      "Optimization Iteration:    321, Training Accuracy:  84.4%, Loss: 0.3273\n",
      "Optimization Iteration:    385, Training Accuracy:  71.9%, Loss: 0.3635\n",
      "Optimization Iteration:    449, Training Accuracy:  85.9%, Loss: 0.2884\n",
      "Optimization Iteration:    513, Training Accuracy:  78.1%, Loss: 0.3683\n",
      "Optimization Iteration:    577, Training Accuracy:  71.9%, Loss: 0.3893\n",
      "Optimization Iteration:    641, Training Accuracy:  78.1%, Loss: 0.4127\n",
      "Optimization Iteration:    705, Training Accuracy:  68.8%, Loss: 0.4714\n",
      "Optimization Iteration:    769, Training Accuracy:  79.7%, Loss: 0.3479\n",
      "Optimization Iteration:    833, Training Accuracy:  75.0%, Loss: 0.3615\n",
      "Optimization Iteration:    897, Training Accuracy:  79.7%, Loss: 0.2896\n",
      "Optimization Iteration:    961, Training Accuracy:  78.1%, Loss: 0.3546\n",
      "Optimization Iteration:   1025, Training Accuracy:  82.8%, Loss: 0.3856\n",
      "Optimization Iteration:   1089, Training Accuracy:  75.0%, Loss: 0.3680\n",
      "Optimization Iteration:   1153, Training Accuracy:  76.6%, Loss: 0.3575\n",
      "Optimization Iteration:   1217, Training Accuracy:  68.8%, Loss: 0.4321\n",
      "Optimization Iteration:   1281, Training Accuracy:  73.4%, Loss: 0.4618\n",
      "Optimization Iteration:   1345, Training Accuracy:  73.4%, Loss: 0.3904\n",
      "Optimization Iteration:   1409, Training Accuracy:  73.4%, Loss: 0.3806\n",
      "Optimization Iteration:   1473, Training Accuracy:  62.5%, Loss: 0.4646\n",
      "Optimization Iteration:   1537, Training Accuracy:  78.1%, Loss: 0.3753\n",
      "Optimization Iteration:   1601, Training Accuracy:  81.2%, Loss: 0.3710\n",
      "Optimization Iteration:   1665, Training Accuracy:  89.1%, Loss: 0.3160\n",
      "Optimization Iteration:   1729, Training Accuracy:  75.0%, Loss: 0.4260\n",
      "Optimization Iteration:   1793, Training Accuracy:  71.9%, Loss: 0.4041\n",
      "Optimization Iteration:   1857, Training Accuracy:  73.4%, Loss: 0.3990\n",
      "Optimization Iteration:   1921, Training Accuracy:  79.7%, Loss: 0.3866\n",
      "Optimization Iteration:   1985, Training Accuracy:  75.0%, Loss: 0.3477\n",
      "Optimization Iteration:   2049, Training Accuracy:  85.9%, Loss: 0.2962\n",
      "Optimization Iteration:   2113, Training Accuracy:  75.0%, Loss: 0.4101\n",
      "Optimization Iteration:   2177, Training Accuracy:  73.4%, Loss: 0.3693\n",
      "Optimization Iteration:   2241, Training Accuracy:  85.9%, Loss: 0.3391\n",
      "Optimization Iteration:   2305, Training Accuracy:  73.4%, Loss: 0.3413\n",
      "Optimization Iteration:   2369, Training Accuracy:  71.9%, Loss: 0.4207\n",
      "Optimization Iteration:   2433, Training Accuracy:  67.2%, Loss: 0.4228\n",
      "Optimization Iteration:   2497, Training Accuracy:  76.6%, Loss: 0.3609\n",
      "Optimization Iteration:   2561, Training Accuracy:  76.6%, Loss: 0.3607\n",
      "Optimization Iteration:   2625, Training Accuracy:  76.6%, Loss: 0.4173\n",
      "Optimization Iteration:   2689, Training Accuracy:  81.2%, Loss: 0.3196\n",
      "Optimization Iteration:   2753, Training Accuracy:  76.6%, Loss: 0.3404\n",
      "Optimization Iteration:   2817, Training Accuracy:  76.6%, Loss: 0.4120\n",
      "Optimization Iteration:   2881, Training Accuracy:  65.6%, Loss: 0.4425\n",
      "Optimization Iteration:   2945, Training Accuracy:  79.7%, Loss: 0.5207\n",
      "Optimization Iteration:   3009, Training Accuracy:  68.8%, Loss: 0.4530\n",
      "Optimization Iteration:   3073, Training Accuracy:  78.1%, Loss: 0.4159\n",
      "Optimization Iteration:   3137, Training Accuracy:  82.8%, Loss: 0.3743\n",
      "Optimization Iteration:   3201, Training Accuracy:  73.4%, Loss: 0.3878\n",
      "Optimization Iteration:   3265, Training Accuracy:  84.4%, Loss: 0.3293\n",
      "Optimization Iteration:   3329, Training Accuracy:  84.4%, Loss: 0.3285\n",
      "Optimization Iteration:   3393, Training Accuracy:  73.4%, Loss: 0.4392\n",
      "Optimization Iteration:   3457, Training Accuracy:  71.9%, Loss: 0.4514\n",
      "Optimization Iteration:   3521, Training Accuracy:  75.0%, Loss: 0.3692\n",
      "Optimization Iteration:   3585, Training Accuracy:  78.1%, Loss: 0.4283\n",
      "Optimization Iteration:   3649, Training Accuracy:  71.9%, Loss: 0.4661\n",
      "Optimization Iteration:   3713, Training Accuracy:  73.4%, Loss: 0.4172\n",
      "Optimization Iteration:   3777, Training Accuracy:  68.8%, Loss: 0.4361\n",
      "Optimization Iteration:   3841, Training Accuracy:  73.4%, Loss: 0.4045\n",
      "Optimization Iteration:   3905, Training Accuracy:  79.7%, Loss: 0.3370\n",
      "Optimization Iteration:   3969, Training Accuracy:  79.7%, Loss: 0.3856\n",
      "Optimization Iteration:   4033, Training Accuracy:  85.9%, Loss: 0.3399\n",
      "Optimization Iteration:   4097, Training Accuracy:  75.0%, Loss: 0.4118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   4161, Training Accuracy:  73.4%, Loss: 0.4092\n",
      "Optimization Iteration:   4225, Training Accuracy:  82.8%, Loss: 0.3213\n",
      "Optimization Iteration:   4289, Training Accuracy:  73.4%, Loss: 0.4100\n",
      "Optimization Iteration:   4353, Training Accuracy:  71.9%, Loss: 0.4806\n",
      "Optimization Iteration:   4417, Training Accuracy:  73.4%, Loss: 0.4060\n",
      "Optimization Iteration:   4481, Training Accuracy:  78.1%, Loss: 0.3906\n",
      "Optimization Iteration:   4545, Training Accuracy:  64.1%, Loss: 0.4053\n",
      "Optimization Iteration:   4609, Training Accuracy:  78.1%, Loss: 0.3503\n",
      "Optimization Iteration:   4673, Training Accuracy:  81.2%, Loss: 0.3472\n",
      "Optimization Iteration:   4737, Training Accuracy:  73.4%, Loss: 0.4084\n",
      "Optimization Iteration:   4801, Training Accuracy:  70.3%, Loss: 0.4201\n",
      "Optimization Iteration:   4865, Training Accuracy:  81.2%, Loss: 0.3924\n",
      "Optimization Iteration:   4929, Training Accuracy:  79.7%, Loss: 0.3405\n",
      "Optimization Iteration:   4993, Training Accuracy:  76.6%, Loss: 0.3864\n",
      "Optimization Iteration:   5057, Training Accuracy:  65.6%, Loss: 0.4623\n",
      "Optimization Iteration:   5121, Training Accuracy:  78.1%, Loss: 0.3610\n",
      "Optimization Iteration:   5185, Training Accuracy:  75.0%, Loss: 0.4136\n",
      "Optimization Iteration:   5249, Training Accuracy:  60.9%, Loss: 0.4322\n",
      "Optimization Iteration:   5313, Training Accuracy:  82.8%, Loss: 0.3316\n",
      "Optimization Iteration:   5377, Training Accuracy:  75.0%, Loss: 0.4057\n",
      "Optimization Iteration:   5441, Training Accuracy:  75.0%, Loss: 0.3799\n",
      "Optimization Iteration:   5505, Training Accuracy:  78.1%, Loss: 0.3461\n",
      "Optimization Iteration:   5569, Training Accuracy:  79.7%, Loss: 0.3394\n",
      "Optimization Iteration:   5633, Training Accuracy:  79.7%, Loss: 0.3209\n",
      "Optimization Iteration:   5697, Training Accuracy:  78.1%, Loss: 0.4042\n",
      "Optimization Iteration:   5761, Training Accuracy:  81.2%, Loss: 0.3177\n",
      "Optimization Iteration:   5825, Training Accuracy:  76.6%, Loss: 0.4094\n",
      "Optimization Iteration:   5889, Training Accuracy:  82.8%, Loss: 0.3756\n",
      "Optimization Iteration:   5953, Training Accuracy:  76.6%, Loss: 0.3553\n",
      "Optimization Iteration:   6017, Training Accuracy:  67.2%, Loss: 0.4666\n",
      "Optimization Iteration:   6081, Training Accuracy:  71.9%, Loss: 0.4305\n",
      "Optimization Iteration:   6145, Training Accuracy:  71.9%, Loss: 0.4744\n",
      "Optimization Iteration:   6209, Training Accuracy:  73.4%, Loss: 0.3589\n",
      "Optimization Iteration:   6273, Training Accuracy:  68.8%, Loss: 0.4456\n",
      "Optimization Iteration:   6337, Training Accuracy:  70.3%, Loss: 0.3946\n",
      "Optimization Iteration:   6401, Training Accuracy:  73.4%, Loss: 0.3987\n",
      "Optimization Iteration:   6465, Training Accuracy:  89.1%, Loss: 0.3313\n",
      "Optimization Iteration:   6529, Training Accuracy:  78.1%, Loss: 0.3724\n",
      "Optimization Iteration:   6593, Training Accuracy:  84.4%, Loss: 0.3257\n",
      "Optimization Iteration:   6657, Training Accuracy:  73.4%, Loss: 0.3869\n",
      "Optimization Iteration:   6721, Training Accuracy:  84.4%, Loss: 0.2705\n",
      "Optimization Iteration:   6785, Training Accuracy:  73.4%, Loss: 0.3594\n",
      "Optimization Iteration:   6849, Training Accuracy:  68.8%, Loss: 0.4252\n",
      "Optimization Iteration:   6913, Training Accuracy:  81.2%, Loss: 0.3419\n",
      "Optimization Iteration:   6977, Training Accuracy:  75.0%, Loss: 0.3961\n",
      "Optimization Iteration:   7041, Training Accuracy:  85.9%, Loss: 0.3282\n",
      "Optimization Iteration:   7105, Training Accuracy:  85.9%, Loss: 0.3547\n",
      "Optimization Iteration:   7169, Training Accuracy:  71.9%, Loss: 0.3967\n",
      "Optimization Iteration:   7233, Training Accuracy:  71.9%, Loss: 0.4406\n",
      "Optimization Iteration:   7297, Training Accuracy:  75.0%, Loss: 0.4644\n",
      "Optimization Iteration:   7361, Training Accuracy:  78.1%, Loss: 0.3661\n",
      "Optimization Iteration:   7425, Training Accuracy:  73.4%, Loss: 0.3761\n",
      "Optimization Iteration:   7489, Training Accuracy:  79.7%, Loss: 0.3663\n",
      "Optimization Iteration:   7553, Training Accuracy:  73.4%, Loss: 0.4401\n",
      "Optimization Iteration:   7617, Training Accuracy:  84.4%, Loss: 0.4268\n",
      "Optimization Iteration:   7681, Training Accuracy:  75.0%, Loss: 0.4635\n",
      "Optimization Iteration:   7745, Training Accuracy:  78.1%, Loss: 0.3513\n",
      "Optimization Iteration:   7809, Training Accuracy:  79.7%, Loss: 0.4074\n",
      "Optimization Iteration:   7873, Training Accuracy:  71.9%, Loss: 0.3598\n",
      "Optimization Iteration:   7937, Training Accuracy:  78.1%, Loss: 0.3474\n",
      "Optimization Iteration:   8001, Training Accuracy:  70.3%, Loss: 0.3986\n",
      "Optimization Iteration:   8065, Training Accuracy:  70.3%, Loss: 0.3677\n",
      "Optimization Iteration:   8129, Training Accuracy:  76.6%, Loss: 0.3693\n",
      "Optimization Iteration:   8193, Training Accuracy:  73.4%, Loss: 0.4261\n",
      "Optimization Iteration:   8257, Training Accuracy:  76.6%, Loss: 0.3830\n",
      "Optimization Iteration:   8321, Training Accuracy:  79.7%, Loss: 0.3910\n",
      "Optimization Iteration:   8385, Training Accuracy:  70.3%, Loss: 0.4485\n",
      "Optimization Iteration:   8449, Training Accuracy:  73.4%, Loss: 0.4851\n",
      "Optimization Iteration:   8513, Training Accuracy:  75.0%, Loss: 0.3636\n",
      "Optimization Iteration:   8577, Training Accuracy:  73.4%, Loss: 0.4415\n",
      "Optimization Iteration:   8641, Training Accuracy:  75.0%, Loss: 0.4036\n",
      "Optimization Iteration:   8705, Training Accuracy:  73.4%, Loss: 0.3605\n",
      "Optimization Iteration:   8769, Training Accuracy:  75.0%, Loss: 0.4292\n",
      "Optimization Iteration:   8833, Training Accuracy:  73.4%, Loss: 0.3951\n",
      "Optimization Iteration:   8897, Training Accuracy:  78.1%, Loss: 0.3881\n",
      "Optimization Iteration:   8961, Training Accuracy:  70.3%, Loss: 0.4295\n",
      "Optimization Iteration:   9025, Training Accuracy:  71.9%, Loss: 0.4467\n",
      "Optimization Iteration:   9089, Training Accuracy:  65.6%, Loss: 0.4716\n",
      "Optimization Iteration:   9153, Training Accuracy:  71.9%, Loss: 0.4274\n",
      "Optimization Iteration:   9217, Training Accuracy:  75.0%, Loss: 0.3959\n",
      "Optimization Iteration:   9281, Training Accuracy:  75.0%, Loss: 0.3837\n",
      "Optimization Iteration:   9345, Training Accuracy:  82.8%, Loss: 0.3753\n",
      "Optimization Iteration:   9409, Training Accuracy:  68.8%, Loss: 0.4589\n",
      "Optimization Iteration:   9473, Training Accuracy:  81.2%, Loss: 0.3659\n",
      "Optimization Iteration:   9537, Training Accuracy:  85.9%, Loss: 0.2931\n",
      "Optimization Iteration:   9601, Training Accuracy:  75.0%, Loss: 0.4709\n",
      "Optimization Iteration:   9665, Training Accuracy:  73.4%, Loss: 0.3841\n",
      "Optimization Iteration:   9729, Training Accuracy:  71.9%, Loss: 0.4177\n",
      "Optimization Iteration:   9793, Training Accuracy:  79.7%, Loss: 0.3853\n",
      "Optimization Iteration:   9857, Training Accuracy:  73.4%, Loss: 0.3874\n",
      "Optimization Iteration:   9921, Training Accuracy:  79.7%, Loss: 0.3109\n",
      "Optimization Iteration:   9985, Training Accuracy:  67.2%, Loss: 0.4617\n",
      "Optimization Iteration:  10049, Training Accuracy:  79.7%, Loss: 0.3809\n",
      "Optimization Iteration:  10113, Training Accuracy:  73.4%, Loss: 0.4043\n",
      "Optimization Iteration:  10177, Training Accuracy:  82.8%, Loss: 0.4104\n",
      "Optimization Iteration:  10241, Training Accuracy:  75.0%, Loss: 0.4388\n",
      "Optimization Iteration:  10305, Training Accuracy:  82.8%, Loss: 0.3670\n",
      "Optimization Iteration:  10369, Training Accuracy:  81.2%, Loss: 0.3633\n",
      "Optimization Iteration:  10433, Training Accuracy:  70.3%, Loss: 0.4371\n",
      "Optimization Iteration:  10497, Training Accuracy:  70.3%, Loss: 0.4794\n",
      "Optimization Iteration:  10561, Training Accuracy:  73.4%, Loss: 0.3809\n",
      "Optimization Iteration:  10625, Training Accuracy:  78.1%, Loss: 0.3752\n",
      "Optimization Iteration:  10689, Training Accuracy:  75.0%, Loss: 0.3426\n",
      "Optimization Iteration:  10753, Training Accuracy:  71.9%, Loss: 0.4261\n",
      "Optimization Iteration:  10817, Training Accuracy:  75.0%, Loss: 0.4526\n",
      "Optimization Iteration:  10881, Training Accuracy:  85.9%, Loss: 0.3188\n",
      "Optimization Iteration:  10945, Training Accuracy:  76.6%, Loss: 0.3728\n",
      "Optimization Iteration:  11009, Training Accuracy:  81.2%, Loss: 0.3487\n",
      "Optimization Iteration:  11073, Training Accuracy:  79.7%, Loss: 0.3306\n",
      "Optimization Iteration:  11137, Training Accuracy:  81.2%, Loss: 0.3716\n",
      "Optimization Iteration:  11201, Training Accuracy:  73.4%, Loss: 0.3794\n",
      "Optimization Iteration:  11265, Training Accuracy:  87.5%, Loss: 0.2764\n",
      "Optimization Iteration:  11329, Training Accuracy:  79.7%, Loss: 0.4136\n",
      "Optimization Iteration:  11393, Training Accuracy:  81.2%, Loss: 0.3805\n",
      "Optimization Iteration:  11457, Training Accuracy:  79.7%, Loss: 0.3209\n",
      "Optimization Iteration:  11521, Training Accuracy:  71.9%, Loss: 0.4413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  11585, Training Accuracy:  79.7%, Loss: 0.3214\n",
      "Optimization Iteration:  11649, Training Accuracy:  62.5%, Loss: 0.5564\n",
      "Optimization Iteration:  11713, Training Accuracy:  76.6%, Loss: 0.3960\n",
      "Optimization Iteration:  11777, Training Accuracy:  76.6%, Loss: 0.4056\n",
      "Optimization Iteration:  11841, Training Accuracy:  90.6%, Loss: 0.3479\n",
      "Optimization Iteration:  11905, Training Accuracy:  84.4%, Loss: 0.3160\n",
      "Optimization Iteration:  11969, Training Accuracy:  78.1%, Loss: 0.3567\n",
      "Optimization Iteration:  12033, Training Accuracy:  73.4%, Loss: 0.4610\n",
      "Optimization Iteration:  12097, Training Accuracy:  70.3%, Loss: 0.3995\n",
      "Optimization Iteration:  12161, Training Accuracy:  73.4%, Loss: 0.4555\n",
      "Optimization Iteration:  12225, Training Accuracy:  81.2%, Loss: 0.3290\n",
      "Optimization Iteration:  12289, Training Accuracy:  79.7%, Loss: 0.3646\n",
      "Optimization Iteration:  12353, Training Accuracy:  81.2%, Loss: 0.3596\n",
      "Optimization Iteration:  12417, Training Accuracy:  79.7%, Loss: 0.3607\n",
      "Optimization Iteration:  12481, Training Accuracy:  79.7%, Loss: 0.3656\n",
      "Optimization Iteration:  12545, Training Accuracy:  70.3%, Loss: 0.4011\n",
      "Optimization Iteration:  12609, Training Accuracy:  68.8%, Loss: 0.3629\n",
      "Optimization Iteration:  12673, Training Accuracy:  78.1%, Loss: 0.3969\n",
      "Optimization Iteration:  12737, Training Accuracy:  68.8%, Loss: 0.4619\n",
      "Optimization Iteration:  12801, Training Accuracy:  76.6%, Loss: 0.4093\n",
      "Optimization Iteration:  12865, Training Accuracy:  76.6%, Loss: 0.3845\n",
      "Optimization Iteration:  12929, Training Accuracy:  75.0%, Loss: 0.3874\n",
      "Optimization Iteration:  12993, Training Accuracy:  78.1%, Loss: 0.3530\n",
      "Optimization Iteration:  13057, Training Accuracy:  75.0%, Loss: 0.4437\n",
      "Optimization Iteration:  13121, Training Accuracy:  84.4%, Loss: 0.3178\n",
      "Optimization Iteration:  13185, Training Accuracy:  75.0%, Loss: 0.4279\n",
      "Optimization Iteration:  13249, Training Accuracy:  78.1%, Loss: 0.4021\n",
      "Optimization Iteration:  13313, Training Accuracy:  70.3%, Loss: 0.4844\n",
      "Optimization Iteration:  13377, Training Accuracy:  73.4%, Loss: 0.4182\n",
      "Optimization Iteration:  13441, Training Accuracy:  84.4%, Loss: 0.3123\n",
      "Optimization Iteration:  13505, Training Accuracy:  79.7%, Loss: 0.3729\n",
      "Optimization Iteration:  13569, Training Accuracy:  87.5%, Loss: 0.2932\n",
      "Optimization Iteration:  13633, Training Accuracy:  82.8%, Loss: 0.3502\n",
      "Optimization Iteration:  13697, Training Accuracy:  78.1%, Loss: 0.3646\n",
      "Optimization Iteration:  13761, Training Accuracy:  84.4%, Loss: 0.3883\n",
      "Optimization Iteration:  13825, Training Accuracy:  73.4%, Loss: 0.4102\n",
      "Optimization Iteration:  13889, Training Accuracy:  76.6%, Loss: 0.5039\n",
      "Optimization Iteration:  13953, Training Accuracy:  82.8%, Loss: 0.3717\n",
      "Optimization Iteration:  14017, Training Accuracy:  76.6%, Loss: 0.3641\n",
      "Optimization Iteration:  14081, Training Accuracy:  79.7%, Loss: 0.3773\n",
      "Optimization Iteration:  14145, Training Accuracy:  81.2%, Loss: 0.3527\n",
      "Optimization Iteration:  14209, Training Accuracy:  81.2%, Loss: 0.3692\n",
      "Optimization Iteration:  14273, Training Accuracy:  67.2%, Loss: 0.4572\n",
      "Optimization Iteration:  14337, Training Accuracy:  90.6%, Loss: 0.2751\n",
      "Optimization Iteration:  14401, Training Accuracy:  85.9%, Loss: 0.2901\n",
      "Optimization Iteration:  14465, Training Accuracy:  71.9%, Loss: 0.4868\n",
      "Optimization Iteration:  14529, Training Accuracy:  84.4%, Loss: 0.3532\n",
      "Optimization Iteration:  14593, Training Accuracy:  79.7%, Loss: 0.3462\n",
      "Optimization Iteration:  14657, Training Accuracy:  75.0%, Loss: 0.4780\n",
      "Optimization Iteration:  14721, Training Accuracy:  84.4%, Loss: 0.3649\n",
      "Optimization Iteration:  14785, Training Accuracy:  73.4%, Loss: 0.4260\n",
      "Optimization Iteration:  14849, Training Accuracy:  79.7%, Loss: 0.3885\n",
      "Optimization Iteration:  14913, Training Accuracy:  78.1%, Loss: 0.3328\n",
      "Optimization Iteration:  14977, Training Accuracy:  75.0%, Loss: 0.4167\n",
      "Optimization Iteration:  15041, Training Accuracy:  78.1%, Loss: 0.3896\n",
      "Optimization Iteration:  15105, Training Accuracy:  82.8%, Loss: 0.3251\n",
      "Optimization Iteration:  15169, Training Accuracy:  81.2%, Loss: 0.3426\n",
      "Optimization Iteration:  15233, Training Accuracy:  71.9%, Loss: 0.4765\n",
      "Optimization Iteration:  15297, Training Accuracy:  82.8%, Loss: 0.3888\n",
      "Optimization Iteration:  15361, Training Accuracy:  84.4%, Loss: 0.3239\n",
      "Optimization Iteration:  15425, Training Accuracy:  68.8%, Loss: 0.4274\n",
      "Optimization Iteration:  15489, Training Accuracy:  64.1%, Loss: 0.4949\n",
      "Optimization Iteration:  15553, Training Accuracy:  76.6%, Loss: 0.3578\n",
      "Optimization Iteration:  15617, Training Accuracy:  78.1%, Loss: 0.3312\n",
      "Optimization Iteration:  15681, Training Accuracy:  79.7%, Loss: 0.4041\n",
      "Optimization Iteration:  15745, Training Accuracy:  79.7%, Loss: 0.3291\n",
      "Optimization Iteration:  15809, Training Accuracy:  75.0%, Loss: 0.4315\n",
      "Optimization Iteration:  15873, Training Accuracy:  79.7%, Loss: 0.4036\n",
      "Optimization Iteration:  15937, Training Accuracy:  68.8%, Loss: 0.3790\n",
      "Optimization Iteration:  16001, Training Accuracy:  76.6%, Loss: 0.4042\n",
      "Optimization Iteration:  16065, Training Accuracy:  62.5%, Loss: 0.4343\n",
      "Optimization Iteration:  16129, Training Accuracy:  81.2%, Loss: 0.3359\n",
      "Optimization Iteration:  16193, Training Accuracy:  75.0%, Loss: 0.3992\n",
      "Optimization Iteration:  16257, Training Accuracy:  89.1%, Loss: 0.2899\n",
      "Optimization Iteration:  16321, Training Accuracy:  82.8%, Loss: 0.3601\n",
      "Optimization Iteration:  16385, Training Accuracy:  85.9%, Loss: 0.3454\n",
      "Optimization Iteration:  16449, Training Accuracy:  81.2%, Loss: 0.3519\n",
      "Optimization Iteration:  16513, Training Accuracy:  76.6%, Loss: 0.4461\n",
      "Optimization Iteration:  16577, Training Accuracy:  79.7%, Loss: 0.3383\n",
      "Optimization Iteration:  16641, Training Accuracy:  75.0%, Loss: 0.4429\n",
      "Optimization Iteration:  16705, Training Accuracy:  78.1%, Loss: 0.3452\n",
      "Optimization Iteration:  16769, Training Accuracy:  73.4%, Loss: 0.3384\n",
      "Optimization Iteration:  16833, Training Accuracy:  65.6%, Loss: 0.4329\n",
      "Optimization Iteration:  16897, Training Accuracy:  71.9%, Loss: 0.3880\n",
      "Optimization Iteration:  16961, Training Accuracy:  76.6%, Loss: 0.3760\n",
      "Optimization Iteration:  17025, Training Accuracy:  65.6%, Loss: 0.4274\n",
      "Optimization Iteration:  17089, Training Accuracy:  73.4%, Loss: 0.5060\n",
      "Optimization Iteration:  17153, Training Accuracy:  70.3%, Loss: 0.3906\n",
      "Optimization Iteration:  17217, Training Accuracy:  76.6%, Loss: 0.4297\n",
      "Optimization Iteration:  17281, Training Accuracy:  73.4%, Loss: 0.3880\n",
      "Optimization Iteration:  17345, Training Accuracy:  84.4%, Loss: 0.3286\n",
      "Optimization Iteration:  17409, Training Accuracy:  76.6%, Loss: 0.3904\n",
      "Optimization Iteration:  17473, Training Accuracy:  68.8%, Loss: 0.5367\n",
      "Optimization Iteration:  17537, Training Accuracy:  81.2%, Loss: 0.3261\n",
      "Optimization Iteration:  17601, Training Accuracy:  79.7%, Loss: 0.4310\n",
      "Optimization Iteration:  17665, Training Accuracy:  82.8%, Loss: 0.3521\n",
      "Optimization Iteration:  17729, Training Accuracy:  71.9%, Loss: 0.4176\n",
      "Optimization Iteration:  17793, Training Accuracy:  62.5%, Loss: 0.4249\n",
      "Optimization Iteration:  17857, Training Accuracy:  68.8%, Loss: 0.4695\n",
      "Optimization Iteration:  17921, Training Accuracy:  79.7%, Loss: 0.3421\n",
      "Optimization Iteration:  17985, Training Accuracy:  85.9%, Loss: 0.2749\n",
      "Optimization Iteration:  18049, Training Accuracy:  81.2%, Loss: 0.3709\n",
      "Optimization Iteration:  18113, Training Accuracy:  71.9%, Loss: 0.4303\n",
      "Optimization Iteration:  18177, Training Accuracy:  75.0%, Loss: 0.4135\n",
      "Optimization Iteration:  18241, Training Accuracy:  76.6%, Loss: 0.3925\n",
      "Optimization Iteration:  18305, Training Accuracy:  68.8%, Loss: 0.4224\n",
      "Optimization Iteration:  18369, Training Accuracy:  79.7%, Loss: 0.3532\n",
      "Optimization Iteration:  18433, Training Accuracy:  68.8%, Loss: 0.4217\n",
      "Optimization Iteration:  18497, Training Accuracy:  82.8%, Loss: 0.3143\n",
      "Optimization Iteration:  18561, Training Accuracy:  78.1%, Loss: 0.3765\n",
      "Optimization Iteration:  18625, Training Accuracy:  68.8%, Loss: 0.4739\n",
      "Optimization Iteration:  18689, Training Accuracy:  68.8%, Loss: 0.4030\n",
      "Optimization Iteration:  18753, Training Accuracy:  78.1%, Loss: 0.3829\n",
      "Optimization Iteration:  18817, Training Accuracy:  82.8%, Loss: 0.3799\n",
      "Optimization Iteration:  18881, Training Accuracy:  75.0%, Loss: 0.4205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  18945, Training Accuracy:  75.0%, Loss: 0.4008\n",
      "Optimization Iteration:  19009, Training Accuracy:  75.0%, Loss: 0.3723\n",
      "Optimization Iteration:  19073, Training Accuracy:  78.1%, Loss: 0.4038\n",
      "Optimization Iteration:  19137, Training Accuracy:  68.8%, Loss: 0.5112\n",
      "Optimization Iteration:  19201, Training Accuracy:  73.4%, Loss: 0.4649\n",
      "Optimization Iteration:  19265, Training Accuracy:  79.7%, Loss: 0.3688\n",
      "Optimization Iteration:  19329, Training Accuracy:  79.7%, Loss: 0.3512\n",
      "Optimization Iteration:  19393, Training Accuracy:  78.1%, Loss: 0.3501\n",
      "Optimization Iteration:  19457, Training Accuracy:  76.6%, Loss: 0.3692\n",
      "Optimization Iteration:  19521, Training Accuracy:  84.4%, Loss: 0.3540\n",
      "Optimization Iteration:  19585, Training Accuracy:  79.7%, Loss: 0.4094\n",
      "Optimization Iteration:  19649, Training Accuracy:  79.7%, Loss: 0.4019\n",
      "Optimization Iteration:  19713, Training Accuracy:  78.1%, Loss: 0.3618\n",
      "Optimization Iteration:  19777, Training Accuracy:  71.9%, Loss: 0.4136\n",
      "Optimization Iteration:  19841, Training Accuracy:  68.8%, Loss: 0.4372\n",
      "Optimization Iteration:  19905, Training Accuracy:  71.9%, Loss: 0.3871\n",
      "Optimization Iteration:  19969, Training Accuracy:  75.0%, Loss: 0.3697\n",
      "Optimization Iteration:  20033, Training Accuracy:  73.4%, Loss: 0.4267\n",
      "Optimization Iteration:  20097, Training Accuracy:  68.8%, Loss: 0.4607\n",
      "Optimization Iteration:  20161, Training Accuracy:  76.6%, Loss: 0.3510\n",
      "Optimization Iteration:  20225, Training Accuracy:  79.7%, Loss: 0.4375\n",
      "Optimization Iteration:  20289, Training Accuracy:  64.1%, Loss: 0.4605\n",
      "Optimization Iteration:  20353, Training Accuracy:  81.2%, Loss: 0.3687\n",
      "Optimization Iteration:  20417, Training Accuracy:  71.9%, Loss: 0.4589\n",
      "Optimization Iteration:  20481, Training Accuracy:  89.1%, Loss: 0.3367\n",
      "Optimization Iteration:  20545, Training Accuracy:  81.2%, Loss: 0.3617\n",
      "Optimization Iteration:  20609, Training Accuracy:  73.4%, Loss: 0.4537\n",
      "Optimization Iteration:  20673, Training Accuracy:  81.2%, Loss: 0.3310\n",
      "Optimization Iteration:  20737, Training Accuracy:  82.8%, Loss: 0.3749\n",
      "Optimization Iteration:  20801, Training Accuracy:  78.1%, Loss: 0.3688\n",
      "Optimization Iteration:  20865, Training Accuracy:  79.7%, Loss: 0.3339\n",
      "Optimization Iteration:  20929, Training Accuracy:  81.2%, Loss: 0.4061\n",
      "Optimization Iteration:  20993, Training Accuracy:  76.6%, Loss: 0.4356\n",
      "Optimization Iteration:  21057, Training Accuracy:  87.5%, Loss: 0.3251\n",
      "Optimization Iteration:  21121, Training Accuracy:  75.0%, Loss: 0.3714\n",
      "Optimization Iteration:  21185, Training Accuracy:  73.4%, Loss: 0.4020\n",
      "Optimization Iteration:  21249, Training Accuracy:  57.8%, Loss: 0.4804\n",
      "Optimization Iteration:  21313, Training Accuracy:  75.0%, Loss: 0.4114\n",
      "Optimization Iteration:  21377, Training Accuracy:  73.4%, Loss: 0.4152\n",
      "Optimization Iteration:  21441, Training Accuracy:  73.4%, Loss: 0.4540\n",
      "Optimization Iteration:  21505, Training Accuracy:  75.0%, Loss: 0.4217\n",
      "Optimization Iteration:  21569, Training Accuracy:  73.4%, Loss: 0.3431\n",
      "Optimization Iteration:  21633, Training Accuracy:  82.8%, Loss: 0.3089\n",
      "Optimization Iteration:  21697, Training Accuracy:  73.4%, Loss: 0.4989\n",
      "Optimization Iteration:  21761, Training Accuracy:  84.4%, Loss: 0.2942\n",
      "Optimization Iteration:  21825, Training Accuracy:  68.8%, Loss: 0.4514\n",
      "Optimization Iteration:  21889, Training Accuracy:  81.2%, Loss: 0.3354\n",
      "Optimization Iteration:  21953, Training Accuracy:  76.6%, Loss: 0.4310\n",
      "Optimization Iteration:  22017, Training Accuracy:  82.8%, Loss: 0.3543\n",
      "Optimization Iteration:  22081, Training Accuracy:  78.1%, Loss: 0.3434\n",
      "Optimization Iteration:  22145, Training Accuracy:  82.8%, Loss: 0.3664\n",
      "Optimization Iteration:  22209, Training Accuracy:  79.7%, Loss: 0.3727\n",
      "Optimization Iteration:  22273, Training Accuracy:  79.7%, Loss: 0.3706\n",
      "Optimization Iteration:  22337, Training Accuracy:  76.6%, Loss: 0.3429\n",
      "Optimization Iteration:  22401, Training Accuracy:  76.6%, Loss: 0.4113\n",
      "Optimization Iteration:  22465, Training Accuracy:  68.8%, Loss: 0.4478\n",
      "Optimization Iteration:  22529, Training Accuracy:  71.9%, Loss: 0.4266\n",
      "Optimization Iteration:  22593, Training Accuracy:  76.6%, Loss: 0.3660\n",
      "Optimization Iteration:  22657, Training Accuracy:  79.7%, Loss: 0.4165\n",
      "Optimization Iteration:  22721, Training Accuracy:  65.6%, Loss: 0.4079\n",
      "Optimization Iteration:  22785, Training Accuracy:  75.0%, Loss: 0.3972\n",
      "Optimization Iteration:  22849, Training Accuracy:  79.7%, Loss: 0.3940\n",
      "Optimization Iteration:  22913, Training Accuracy:  73.4%, Loss: 0.4037\n",
      "Optimization Iteration:  22977, Training Accuracy:  78.1%, Loss: 0.3797\n",
      "Optimization Iteration:  23041, Training Accuracy:  68.8%, Loss: 0.3661\n",
      "Optimization Iteration:  23105, Training Accuracy:  81.2%, Loss: 0.2962\n",
      "Optimization Iteration:  23169, Training Accuracy:  84.4%, Loss: 0.3196\n",
      "Optimization Iteration:  23233, Training Accuracy:  76.6%, Loss: 0.3964\n",
      "Optimization Iteration:  23297, Training Accuracy:  75.0%, Loss: 0.4416\n",
      "Optimization Iteration:  23361, Training Accuracy:  81.2%, Loss: 0.4089\n",
      "Optimization Iteration:  23425, Training Accuracy:  87.5%, Loss: 0.3290\n",
      "Optimization Iteration:  23489, Training Accuracy:  78.1%, Loss: 0.4091\n",
      "Optimization Iteration:  23553, Training Accuracy:  75.0%, Loss: 0.3635\n",
      "Optimization Iteration:  23617, Training Accuracy:  73.4%, Loss: 0.4716\n",
      "Optimization Iteration:  23681, Training Accuracy:  71.9%, Loss: 0.4387\n",
      "Optimization Iteration:  23745, Training Accuracy:  70.3%, Loss: 0.4083\n",
      "Optimization Iteration:  23809, Training Accuracy:  75.0%, Loss: 0.4467\n",
      "Optimization Iteration:  23873, Training Accuracy:  76.6%, Loss: 0.3474\n",
      "Optimization Iteration:  23937, Training Accuracy:  71.9%, Loss: 0.3984\n",
      "Optimization Iteration:  24001, Training Accuracy:  79.7%, Loss: 0.3145\n",
      "Optimization Iteration:  24065, Training Accuracy:  68.8%, Loss: 0.4068\n",
      "Optimization Iteration:  24129, Training Accuracy:  78.1%, Loss: 0.3828\n",
      "Optimization Iteration:  24193, Training Accuracy:  81.2%, Loss: 0.3720\n",
      "Optimization Iteration:  24257, Training Accuracy:  76.6%, Loss: 0.4363\n",
      "Optimization Iteration:  24321, Training Accuracy:  70.3%, Loss: 0.4493\n",
      "Optimization Iteration:  24385, Training Accuracy:  68.8%, Loss: 0.4637\n",
      "Optimization Iteration:  24449, Training Accuracy:  78.1%, Loss: 0.3676\n",
      "Optimization Iteration:  24513, Training Accuracy:  73.4%, Loss: 0.3710\n",
      "Optimization Iteration:  24577, Training Accuracy:  70.3%, Loss: 0.4602\n",
      "Optimization Iteration:  24641, Training Accuracy:  78.1%, Loss: 0.3629\n",
      "Optimization Iteration:  24705, Training Accuracy:  79.7%, Loss: 0.3474\n",
      "Optimization Iteration:  24769, Training Accuracy:  79.7%, Loss: 0.4182\n",
      "Optimization Iteration:  24833, Training Accuracy:  73.4%, Loss: 0.3265\n",
      "Optimization Iteration:  24897, Training Accuracy:  73.4%, Loss: 0.3707\n",
      "Optimization Iteration:  24961, Training Accuracy:  70.3%, Loss: 0.3733\n",
      "Optimization Iteration:  25025, Training Accuracy:  76.6%, Loss: 0.3825\n",
      "Optimization Iteration:  25089, Training Accuracy:  78.1%, Loss: 0.3715\n",
      "Optimization Iteration:  25153, Training Accuracy:  79.7%, Loss: 0.4303\n",
      "Optimization Iteration:  25217, Training Accuracy:  71.9%, Loss: 0.4349\n",
      "Optimization Iteration:  25281, Training Accuracy:  76.6%, Loss: 0.3635\n",
      "Optimization Iteration:  25345, Training Accuracy:  67.2%, Loss: 0.4487\n",
      "Optimization Iteration:  25409, Training Accuracy:  79.7%, Loss: 0.4126\n",
      "Optimization Iteration:  25473, Training Accuracy:  71.9%, Loss: 0.4737\n",
      "Optimization Iteration:  25537, Training Accuracy:  71.9%, Loss: 0.3670\n",
      "Optimization Iteration:  25601, Training Accuracy:  65.6%, Loss: 0.4819\n",
      "Optimization Iteration:  25665, Training Accuracy:  81.2%, Loss: 0.3805\n",
      "Optimization Iteration:  25729, Training Accuracy:  76.6%, Loss: 0.3589\n",
      "Optimization Iteration:  25793, Training Accuracy:  76.6%, Loss: 0.3929\n",
      "Optimization Iteration:  25857, Training Accuracy:  78.1%, Loss: 0.4026\n",
      "Optimization Iteration:  25921, Training Accuracy:  73.4%, Loss: 0.4165\n",
      "Optimization Iteration:  25985, Training Accuracy:  75.0%, Loss: 0.4027\n",
      "Optimization Iteration:  26049, Training Accuracy:  79.7%, Loss: 0.3719\n",
      "Optimization Iteration:  26113, Training Accuracy:  76.6%, Loss: 0.3660\n",
      "Optimization Iteration:  26177, Training Accuracy:  81.2%, Loss: 0.3597\n",
      "Optimization Iteration:  26241, Training Accuracy:  79.7%, Loss: 0.3703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  26305, Training Accuracy:  78.1%, Loss: 0.4234\n",
      "Optimization Iteration:  26369, Training Accuracy:  79.7%, Loss: 0.3055\n",
      "Optimization Iteration:  26433, Training Accuracy:  76.6%, Loss: 0.4324\n",
      "Optimization Iteration:  26497, Training Accuracy:  85.9%, Loss: 0.3657\n",
      "Optimization Iteration:  26561, Training Accuracy:  87.5%, Loss: 0.2731\n",
      "Optimization Iteration:  26625, Training Accuracy:  76.6%, Loss: 0.3266\n",
      "Optimization Iteration:  26689, Training Accuracy:  81.2%, Loss: 0.3390\n",
      "Optimization Iteration:  26753, Training Accuracy:  71.9%, Loss: 0.4491\n",
      "Optimization Iteration:  26817, Training Accuracy:  79.7%, Loss: 0.3969\n",
      "Optimization Iteration:  26881, Training Accuracy:  89.1%, Loss: 0.3320\n",
      "Optimization Iteration:  26945, Training Accuracy:  68.8%, Loss: 0.4092\n",
      "Optimization Iteration:  27009, Training Accuracy:  78.1%, Loss: 0.3543\n",
      "Optimization Iteration:  27073, Training Accuracy:  81.2%, Loss: 0.3598\n",
      "Optimization Iteration:  27137, Training Accuracy:  85.9%, Loss: 0.3137\n",
      "Optimization Iteration:  27201, Training Accuracy:  79.7%, Loss: 0.3343\n",
      "Optimization Iteration:  27265, Training Accuracy:  75.0%, Loss: 0.4554\n",
      "Optimization Iteration:  27329, Training Accuracy:  71.9%, Loss: 0.3776\n",
      "Optimization Iteration:  27393, Training Accuracy:  75.0%, Loss: 0.4140\n",
      "Optimization Iteration:  27457, Training Accuracy:  76.6%, Loss: 0.4080\n",
      "Optimization Iteration:  27521, Training Accuracy:  82.8%, Loss: 0.4285\n",
      "Optimization Iteration:  27585, Training Accuracy:  75.0%, Loss: 0.3904\n",
      "Optimization Iteration:  27649, Training Accuracy:  84.4%, Loss: 0.3451\n",
      "Optimization Iteration:  27713, Training Accuracy:  75.0%, Loss: 0.3754\n",
      "Optimization Iteration:  27777, Training Accuracy:  84.4%, Loss: 0.3399\n",
      "Optimization Iteration:  27841, Training Accuracy:  76.6%, Loss: 0.4499\n",
      "Optimization Iteration:  27905, Training Accuracy:  79.7%, Loss: 0.4175\n",
      "Optimization Iteration:  27969, Training Accuracy:  70.3%, Loss: 0.4363\n",
      "Optimization Iteration:  28033, Training Accuracy:  79.7%, Loss: 0.3156\n",
      "Optimization Iteration:  28097, Training Accuracy:  79.7%, Loss: 0.3238\n",
      "Optimization Iteration:  28161, Training Accuracy:  85.9%, Loss: 0.3122\n",
      "Optimization Iteration:  28225, Training Accuracy:  78.1%, Loss: 0.3852\n",
      "Optimization Iteration:  28289, Training Accuracy:  76.6%, Loss: 0.4141\n",
      "Optimization Iteration:  28353, Training Accuracy:  71.9%, Loss: 0.3839\n",
      "Optimization Iteration:  28417, Training Accuracy:  76.6%, Loss: 0.4536\n",
      "Optimization Iteration:  28481, Training Accuracy:  82.8%, Loss: 0.2883\n",
      "Optimization Iteration:  28545, Training Accuracy:  81.2%, Loss: 0.3173\n",
      "Optimization Iteration:  28609, Training Accuracy:  84.4%, Loss: 0.2773\n",
      "Optimization Iteration:  28673, Training Accuracy:  70.3%, Loss: 0.4574\n",
      "Optimization Iteration:  28737, Training Accuracy:  79.7%, Loss: 0.3567\n",
      "Optimization Iteration:  28801, Training Accuracy:  71.9%, Loss: 0.3788\n",
      "Optimization Iteration:  28865, Training Accuracy:  87.5%, Loss: 0.2921\n",
      "Optimization Iteration:  28929, Training Accuracy:  79.7%, Loss: 0.3588\n",
      "Optimization Iteration:  28993, Training Accuracy:  71.9%, Loss: 0.4617\n",
      "Optimization Iteration:  29057, Training Accuracy:  65.6%, Loss: 0.4712\n",
      "Optimization Iteration:  29121, Training Accuracy:  75.0%, Loss: 0.3790\n",
      "Optimization Iteration:  29185, Training Accuracy:  78.1%, Loss: 0.3345\n",
      "Optimization Iteration:  29249, Training Accuracy:  78.1%, Loss: 0.3589\n",
      "Optimization Iteration:  29313, Training Accuracy:  78.1%, Loss: 0.3708\n",
      "Optimization Iteration:  29377, Training Accuracy:  81.2%, Loss: 0.3388\n",
      "Optimization Iteration:  29441, Training Accuracy:  81.2%, Loss: 0.4061\n",
      "Optimization Iteration:  29505, Training Accuracy:  78.1%, Loss: 0.4682\n",
      "Optimization Iteration:  29569, Training Accuracy:  75.0%, Loss: 0.4513\n",
      "Optimization Iteration:  29633, Training Accuracy:  71.9%, Loss: 0.4242\n",
      "Optimization Iteration:  29697, Training Accuracy:  70.3%, Loss: 0.4236\n",
      "Optimization Iteration:  29761, Training Accuracy:  89.1%, Loss: 0.3211\n",
      "Optimization Iteration:  29825, Training Accuracy:  76.6%, Loss: 0.3775\n",
      "Optimization Iteration:  29889, Training Accuracy:  87.5%, Loss: 0.3374\n",
      "Optimization Iteration:  29953, Training Accuracy:  75.0%, Loss: 0.4294\n",
      "Optimization Iteration:  30017, Training Accuracy:  84.4%, Loss: 0.3051\n",
      "Optimization Iteration:  30081, Training Accuracy:  71.9%, Loss: 0.3812\n",
      "Optimization Iteration:  30145, Training Accuracy:  75.0%, Loss: 0.4210\n",
      "Optimization Iteration:  30209, Training Accuracy:  73.4%, Loss: 0.3939\n",
      "Optimization Iteration:  30273, Training Accuracy:  68.8%, Loss: 0.4487\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.3895\n",
      "Optimization Iteration:  30401, Training Accuracy:  81.2%, Loss: 0.4142\n",
      "Optimization Iteration:  30465, Training Accuracy:  73.4%, Loss: 0.3655\n",
      "Optimization Iteration:  30529, Training Accuracy:  76.6%, Loss: 0.3692\n",
      "Optimization Iteration:  30593, Training Accuracy:  78.1%, Loss: 0.3401\n",
      "Optimization Iteration:  30657, Training Accuracy:  76.6%, Loss: 0.3813\n",
      "Optimization Iteration:  30721, Training Accuracy:  78.1%, Loss: 0.3031\n",
      "Optimization Iteration:  30785, Training Accuracy:  71.9%, Loss: 0.3923\n",
      "Optimization Iteration:  30849, Training Accuracy:  78.1%, Loss: 0.4118\n",
      "Optimization Iteration:  30913, Training Accuracy:  76.6%, Loss: 0.3657\n",
      "Optimization Iteration:  30977, Training Accuracy:  75.0%, Loss: 0.4277\n",
      "Optimization Iteration:  31041, Training Accuracy:  75.0%, Loss: 0.4390\n",
      "Optimization Iteration:  31105, Training Accuracy:  68.8%, Loss: 0.4047\n",
      "Optimization Iteration:  31169, Training Accuracy:  75.0%, Loss: 0.3352\n",
      "Optimization Iteration:  31233, Training Accuracy:  78.1%, Loss: 0.3375\n",
      "Optimization Iteration:  31297, Training Accuracy:  71.9%, Loss: 0.3603\n",
      "Optimization Iteration:  31361, Training Accuracy:  68.8%, Loss: 0.4309\n",
      "Optimization Iteration:  31425, Training Accuracy:  75.0%, Loss: 0.3696\n",
      "Optimization Iteration:  31489, Training Accuracy:  87.5%, Loss: 0.3027\n",
      "Optimization Iteration:  31553, Training Accuracy:  67.2%, Loss: 0.4600\n",
      "Optimization Iteration:  31617, Training Accuracy:  75.0%, Loss: 0.4107\n",
      "Optimization Iteration:  31681, Training Accuracy:  64.1%, Loss: 0.5353\n",
      "Optimization Iteration:  31745, Training Accuracy:  75.0%, Loss: 0.3782\n",
      "Optimization Iteration:  31809, Training Accuracy:  62.5%, Loss: 0.4616\n",
      "Optimization Iteration:  31873, Training Accuracy:  79.7%, Loss: 0.3704\n",
      "Optimization Iteration:  31937, Training Accuracy:  68.8%, Loss: 0.4383\n",
      "Optimization Iteration:  32001, Training Accuracy:  75.0%, Loss: 0.4125\n",
      "Optimization Iteration:  32065, Training Accuracy:  73.4%, Loss: 0.3723\n",
      "Optimization Iteration:  32129, Training Accuracy:  78.1%, Loss: 0.3915\n",
      "Optimization Iteration:  32193, Training Accuracy:  65.6%, Loss: 0.4745\n",
      "Optimization Iteration:  32257, Training Accuracy:  76.6%, Loss: 0.4223\n",
      "Optimization Iteration:  32321, Training Accuracy:  75.0%, Loss: 0.3497\n",
      "Optimization Iteration:  32385, Training Accuracy:  68.8%, Loss: 0.4433\n",
      "Optimization Iteration:  32449, Training Accuracy:  71.9%, Loss: 0.4399\n",
      "Optimization Iteration:  32513, Training Accuracy:  82.8%, Loss: 0.3090\n",
      "Optimization Iteration:  32577, Training Accuracy:  76.6%, Loss: 0.3703\n",
      "Optimization Iteration:  32641, Training Accuracy:  71.9%, Loss: 0.4228\n",
      "Optimization Iteration:  32705, Training Accuracy:  78.1%, Loss: 0.3633\n",
      "Optimization Iteration:  32769, Training Accuracy:  67.2%, Loss: 0.4652\n",
      "Optimization Iteration:  32833, Training Accuracy:  76.6%, Loss: 0.3685\n",
      "Optimization Iteration:  32897, Training Accuracy:  81.2%, Loss: 0.4278\n",
      "Optimization Iteration:  32961, Training Accuracy:  75.0%, Loss: 0.3872\n",
      "Optimization Iteration:  33025, Training Accuracy:  71.9%, Loss: 0.4288\n",
      "Optimization Iteration:  33089, Training Accuracy:  75.0%, Loss: 0.3983\n",
      "Optimization Iteration:  33153, Training Accuracy:  76.6%, Loss: 0.4457\n",
      "Optimization Iteration:  33217, Training Accuracy:  73.4%, Loss: 0.3841\n",
      "Optimization Iteration:  33281, Training Accuracy:  70.3%, Loss: 0.4013\n",
      "Optimization Iteration:  33345, Training Accuracy:  75.0%, Loss: 0.4354\n",
      "Optimization Iteration:  33409, Training Accuracy:  71.9%, Loss: 0.3828\n",
      "Optimization Iteration:  33473, Training Accuracy:  79.7%, Loss: 0.3871\n",
      "Optimization Iteration:  33537, Training Accuracy:  68.8%, Loss: 0.4321\n",
      "Optimization Iteration:  33601, Training Accuracy:  76.6%, Loss: 0.4013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  33665, Training Accuracy:  75.0%, Loss: 0.3942\n",
      "Optimization Iteration:  33729, Training Accuracy:  73.4%, Loss: 0.4414\n",
      "Optimization Iteration:  33793, Training Accuracy:  71.9%, Loss: 0.5120\n",
      "Optimization Iteration:  33857, Training Accuracy:  81.2%, Loss: 0.3297\n",
      "Optimization Iteration:  33921, Training Accuracy:  78.1%, Loss: 0.3532\n",
      "Optimization Iteration:  33985, Training Accuracy:  79.7%, Loss: 0.3776\n",
      "Optimization Iteration:  34049, Training Accuracy:  78.1%, Loss: 0.4020\n",
      "Optimization Iteration:  34113, Training Accuracy:  78.1%, Loss: 0.3183\n",
      "Optimization Iteration:  34177, Training Accuracy:  65.6%, Loss: 0.4096\n",
      "Optimization Iteration:  34241, Training Accuracy:  76.6%, Loss: 0.3557\n",
      "Optimization Iteration:  34305, Training Accuracy:  64.1%, Loss: 0.4462\n",
      "Optimization Iteration:  34369, Training Accuracy:  76.6%, Loss: 0.3593\n",
      "Optimization Iteration:  34433, Training Accuracy:  75.0%, Loss: 0.5018\n",
      "Optimization Iteration:  34497, Training Accuracy:  84.4%, Loss: 0.2776\n",
      "Optimization Iteration:  34561, Training Accuracy:  73.4%, Loss: 0.4204\n",
      "Optimization Iteration:  34625, Training Accuracy:  79.7%, Loss: 0.3549\n",
      "Optimization Iteration:  34689, Training Accuracy:  73.4%, Loss: 0.4936\n",
      "Optimization Iteration:  34753, Training Accuracy:  68.8%, Loss: 0.4599\n",
      "Optimization Iteration:  34817, Training Accuracy:  75.0%, Loss: 0.4172\n",
      "Optimization Iteration:  34881, Training Accuracy:  71.9%, Loss: 0.3834\n",
      "Optimization Iteration:  34945, Training Accuracy:  89.1%, Loss: 0.3336\n",
      "Optimization Iteration:  35009, Training Accuracy:  85.9%, Loss: 0.2836\n",
      "Optimization Iteration:  35073, Training Accuracy:  75.0%, Loss: 0.3632\n",
      "Optimization Iteration:  35137, Training Accuracy:  81.2%, Loss: 0.3594\n",
      "Optimization Iteration:  35201, Training Accuracy:  68.8%, Loss: 0.3682\n",
      "Optimization Iteration:  35265, Training Accuracy:  75.0%, Loss: 0.4091\n",
      "Optimization Iteration:  35329, Training Accuracy:  70.3%, Loss: 0.4746\n",
      "Optimization Iteration:  35393, Training Accuracy:  79.7%, Loss: 0.3328\n",
      "Optimization Iteration:  35457, Training Accuracy:  68.8%, Loss: 0.4346\n",
      "Optimization Iteration:  35521, Training Accuracy:  70.3%, Loss: 0.4090\n",
      "Optimization Iteration:  35585, Training Accuracy:  87.5%, Loss: 0.3045\n",
      "Optimization Iteration:  35649, Training Accuracy:  68.8%, Loss: 0.4631\n",
      "Optimization Iteration:  35713, Training Accuracy:  81.2%, Loss: 0.3932\n",
      "Optimization Iteration:  35777, Training Accuracy:  85.9%, Loss: 0.2744\n",
      "Optimization Iteration:  35841, Training Accuracy:  84.4%, Loss: 0.3573\n",
      "Optimization Iteration:  35905, Training Accuracy:  79.7%, Loss: 0.3180\n",
      "Optimization Iteration:  35969, Training Accuracy:  78.1%, Loss: 0.3747\n",
      "Optimization Iteration:  36033, Training Accuracy:  78.1%, Loss: 0.3688\n",
      "Optimization Iteration:  36097, Training Accuracy:  70.3%, Loss: 0.4339\n",
      "Optimization Iteration:  36161, Training Accuracy:  73.4%, Loss: 0.4817\n",
      "Optimization Iteration:  36225, Training Accuracy:  75.0%, Loss: 0.3105\n",
      "Optimization Iteration:  36289, Training Accuracy:  78.1%, Loss: 0.3660\n",
      "Optimization Iteration:  36353, Training Accuracy:  81.2%, Loss: 0.4011\n",
      "Optimization Iteration:  36417, Training Accuracy:  78.1%, Loss: 0.3726\n",
      "Optimization Iteration:  36481, Training Accuracy:  71.9%, Loss: 0.3750\n",
      "Optimization Iteration:  36545, Training Accuracy:  85.9%, Loss: 0.3311\n",
      "Optimization Iteration:  36609, Training Accuracy:  78.1%, Loss: 0.3462\n",
      "Optimization Iteration:  36673, Training Accuracy:  76.6%, Loss: 0.3796\n",
      "Optimization Iteration:  36737, Training Accuracy:  73.4%, Loss: 0.3884\n",
      "Optimization Iteration:  36801, Training Accuracy:  87.5%, Loss: 0.2925\n",
      "Optimization Iteration:  36865, Training Accuracy:  82.8%, Loss: 0.3056\n",
      "Optimization Iteration:  36929, Training Accuracy:  79.7%, Loss: 0.4405\n",
      "Optimization Iteration:  36993, Training Accuracy:  75.0%, Loss: 0.3769\n",
      "Optimization Iteration:  37057, Training Accuracy:  78.1%, Loss: 0.3354\n",
      "Optimization Iteration:  37121, Training Accuracy:  81.2%, Loss: 0.3117\n",
      "Optimization Iteration:  37185, Training Accuracy:  78.1%, Loss: 0.4187\n",
      "Optimization Iteration:  37249, Training Accuracy:  67.2%, Loss: 0.4257\n",
      "Optimization Iteration:  37313, Training Accuracy:  81.2%, Loss: 0.3169\n",
      "Optimization Iteration:  37377, Training Accuracy:  71.9%, Loss: 0.4647\n",
      "Optimization Iteration:  37441, Training Accuracy:  81.2%, Loss: 0.3556\n",
      "Optimization Iteration:  37505, Training Accuracy:  73.4%, Loss: 0.4112\n",
      "Optimization Iteration:  37569, Training Accuracy:  73.4%, Loss: 0.4176\n",
      "Optimization Iteration:  37633, Training Accuracy:  75.0%, Loss: 0.4213\n",
      "Optimization Iteration:  37697, Training Accuracy:  78.1%, Loss: 0.3337\n",
      "Optimization Iteration:  37761, Training Accuracy:  79.7%, Loss: 0.3786\n",
      "Optimization Iteration:  37825, Training Accuracy:  75.0%, Loss: 0.3952\n",
      "Optimization Iteration:  37889, Training Accuracy:  78.1%, Loss: 0.4362\n",
      "Optimization Iteration:  37953, Training Accuracy:  79.7%, Loss: 0.3231\n",
      "Optimization Iteration:  38017, Training Accuracy:  79.7%, Loss: 0.4085\n",
      "Optimization Iteration:  38081, Training Accuracy:  70.3%, Loss: 0.4439\n",
      "Optimization Iteration:  38145, Training Accuracy:  75.0%, Loss: 0.3227\n",
      "Optimization Iteration:  38209, Training Accuracy:  65.6%, Loss: 0.4350\n",
      "Optimization Iteration:  38273, Training Accuracy:  78.1%, Loss: 0.3396\n",
      "Optimization Iteration:  38337, Training Accuracy:  79.7%, Loss: 0.3684\n",
      "Optimization Iteration:  38401, Training Accuracy:  76.6%, Loss: 0.4102\n",
      "Optimization Iteration:  38465, Training Accuracy:  75.0%, Loss: 0.3830\n",
      "Optimization Iteration:  38529, Training Accuracy:  84.4%, Loss: 0.3658\n",
      "Optimization Iteration:  38593, Training Accuracy:  73.4%, Loss: 0.4940\n",
      "Optimization Iteration:  38657, Training Accuracy:  70.3%, Loss: 0.4975\n",
      "Optimization Iteration:  38721, Training Accuracy:  79.7%, Loss: 0.3538\n",
      "Optimization Iteration:  38785, Training Accuracy:  70.3%, Loss: 0.4154\n",
      "Optimization Iteration:  38849, Training Accuracy:  79.7%, Loss: 0.3308\n",
      "Optimization Iteration:  38913, Training Accuracy:  79.7%, Loss: 0.3661\n",
      "Optimization Iteration:  38977, Training Accuracy:  71.9%, Loss: 0.4166\n",
      "Optimization Iteration:  39041, Training Accuracy:  73.4%, Loss: 0.3972\n",
      "Optimization Iteration:  39105, Training Accuracy:  82.8%, Loss: 0.4786\n",
      "Optimization Iteration:  39169, Training Accuracy:  75.0%, Loss: 0.4058\n",
      "Optimization Iteration:  39233, Training Accuracy:  73.4%, Loss: 0.4365\n",
      "Optimization Iteration:  39297, Training Accuracy:  73.4%, Loss: 0.4180\n",
      "Optimization Iteration:  39361, Training Accuracy:  79.7%, Loss: 0.4067\n",
      "Optimization Iteration:  39425, Training Accuracy:  78.1%, Loss: 0.3951\n",
      "Optimization Iteration:  39489, Training Accuracy:  75.0%, Loss: 0.3509\n",
      "Optimization Iteration:  39553, Training Accuracy:  81.2%, Loss: 0.3890\n",
      "Optimization Iteration:  39617, Training Accuracy:  76.6%, Loss: 0.4745\n",
      "Optimization Iteration:  39681, Training Accuracy:  71.9%, Loss: 0.3910\n",
      "Optimization Iteration:  39745, Training Accuracy:  79.7%, Loss: 0.4170\n",
      "Optimization Iteration:  39809, Training Accuracy:  75.0%, Loss: 0.4341\n",
      "Optimization Iteration:  39873, Training Accuracy:  73.4%, Loss: 0.4755\n",
      "Optimization Iteration:  39937, Training Accuracy:  75.0%, Loss: 0.4443\n",
      "Optimization Iteration:  40001, Training Accuracy:  71.9%, Loss: 0.3918\n",
      "Optimization Iteration:  40065, Training Accuracy:  68.8%, Loss: 0.3495\n",
      "Optimization Iteration:  40129, Training Accuracy:  79.7%, Loss: 0.4175\n",
      "Optimization Iteration:  40193, Training Accuracy:  76.6%, Loss: 0.3935\n",
      "Optimization Iteration:  40257, Training Accuracy:  78.1%, Loss: 0.4453\n",
      "Optimization Iteration:  40321, Training Accuracy:  70.3%, Loss: 0.4436\n",
      "Optimization Iteration:  40385, Training Accuracy:  82.8%, Loss: 0.3730\n",
      "Optimization Iteration:  40449, Training Accuracy:  71.9%, Loss: 0.3761\n",
      "Optimization Iteration:  40513, Training Accuracy:  84.4%, Loss: 0.3291\n",
      "Optimization Iteration:  40577, Training Accuracy:  70.3%, Loss: 0.3691\n",
      "Optimization Iteration:  40641, Training Accuracy:  79.7%, Loss: 0.3794\n",
      "Optimization Iteration:  40705, Training Accuracy:  78.1%, Loss: 0.3645\n",
      "Optimization Iteration:  40769, Training Accuracy:  75.0%, Loss: 0.3301\n",
      "Optimization Iteration:  40833, Training Accuracy:  78.1%, Loss: 0.3300\n",
      "Optimization Iteration:  40897, Training Accuracy:  84.4%, Loss: 0.3319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  40961, Training Accuracy:  89.1%, Loss: 0.2926\n",
      "Optimization Iteration:  41025, Training Accuracy:  82.8%, Loss: 0.3138\n",
      "Optimization Iteration:  41089, Training Accuracy:  84.4%, Loss: 0.3279\n",
      "Optimization Iteration:  41153, Training Accuracy:  75.0%, Loss: 0.4299\n",
      "Optimization Iteration:  41217, Training Accuracy:  73.4%, Loss: 0.3379\n",
      "Optimization Iteration:  41281, Training Accuracy:  62.5%, Loss: 0.4711\n",
      "Optimization Iteration:  41345, Training Accuracy:  78.1%, Loss: 0.4278\n",
      "Optimization Iteration:  41409, Training Accuracy:  73.4%, Loss: 0.3322\n",
      "Optimization Iteration:  41473, Training Accuracy:  70.3%, Loss: 0.4610\n",
      "Optimization Iteration:  41537, Training Accuracy:  68.8%, Loss: 0.4295\n",
      "Optimization Iteration:  41601, Training Accuracy:  71.9%, Loss: 0.4048\n",
      "Optimization Iteration:  41665, Training Accuracy:  73.4%, Loss: 0.3756\n",
      "Optimization Iteration:  41729, Training Accuracy:  78.1%, Loss: 0.2906\n",
      "Optimization Iteration:  41793, Training Accuracy:  81.2%, Loss: 0.3908\n",
      "Optimization Iteration:  41857, Training Accuracy:  71.9%, Loss: 0.4075\n",
      "Optimization Iteration:  41921, Training Accuracy:  75.0%, Loss: 0.3887\n",
      "Optimization Iteration:  41985, Training Accuracy:  67.2%, Loss: 0.4407\n",
      "Optimization Iteration:  42049, Training Accuracy:  65.6%, Loss: 0.4678\n",
      "Optimization Iteration:  42113, Training Accuracy:  82.8%, Loss: 0.3551\n",
      "Optimization Iteration:  42177, Training Accuracy:  76.6%, Loss: 0.3959\n",
      "Optimization Iteration:  42241, Training Accuracy:  76.6%, Loss: 0.3911\n",
      "Optimization Iteration:  42305, Training Accuracy:  76.6%, Loss: 0.5113\n",
      "Optimization Iteration:  42369, Training Accuracy:  68.8%, Loss: 0.3636\n",
      "Optimization Iteration:  42433, Training Accuracy:  76.6%, Loss: 0.4575\n",
      "Optimization Iteration:  42497, Training Accuracy:  68.8%, Loss: 0.3730\n",
      "Optimization Iteration:  42561, Training Accuracy:  84.4%, Loss: 0.3128\n",
      "Optimization Iteration:  42625, Training Accuracy:  71.9%, Loss: 0.4732\n",
      "Optimization Iteration:  42689, Training Accuracy:  73.4%, Loss: 0.4019\n",
      "Optimization Iteration:  42753, Training Accuracy:  70.3%, Loss: 0.4502\n",
      "Optimization Iteration:  42817, Training Accuracy:  75.0%, Loss: 0.3582\n",
      "Optimization Iteration:  42881, Training Accuracy:  75.0%, Loss: 0.4050\n",
      "Optimization Iteration:  42945, Training Accuracy:  76.6%, Loss: 0.3653\n",
      "Optimization Iteration:  43009, Training Accuracy:  73.4%, Loss: 0.4261\n",
      "Optimization Iteration:  43073, Training Accuracy:  75.0%, Loss: 0.3797\n",
      "Optimization Iteration:  43137, Training Accuracy:  79.7%, Loss: 0.3582\n",
      "Optimization Iteration:  43201, Training Accuracy:  75.0%, Loss: 0.3586\n",
      "Optimization Iteration:  43265, Training Accuracy:  64.1%, Loss: 0.4404\n",
      "Optimization Iteration:  43329, Training Accuracy:  73.4%, Loss: 0.4524\n",
      "Optimization Iteration:  43393, Training Accuracy:  67.2%, Loss: 0.3939\n",
      "Optimization Iteration:  43457, Training Accuracy:  81.2%, Loss: 0.3427\n",
      "Optimization Iteration:  43521, Training Accuracy:  81.2%, Loss: 0.3593\n",
      "Optimization Iteration:  43585, Training Accuracy:  76.6%, Loss: 0.3341\n",
      "Optimization Iteration:  43649, Training Accuracy:  78.1%, Loss: 0.3849\n",
      "Optimization Iteration:  43713, Training Accuracy:  82.8%, Loss: 0.3178\n",
      "Optimization Iteration:  43777, Training Accuracy:  89.1%, Loss: 0.2974\n",
      "Optimization Iteration:  43841, Training Accuracy:  76.6%, Loss: 0.4059\n",
      "Optimization Iteration:  43905, Training Accuracy:  79.7%, Loss: 0.3562\n",
      "Optimization Iteration:  43969, Training Accuracy:  84.4%, Loss: 0.2895\n",
      "Optimization Iteration:  44033, Training Accuracy:  67.2%, Loss: 0.4202\n",
      "Optimization Iteration:  44097, Training Accuracy:  79.7%, Loss: 0.3019\n",
      "Optimization Iteration:  44161, Training Accuracy:  73.4%, Loss: 0.4412\n",
      "Optimization Iteration:  44225, Training Accuracy:  76.6%, Loss: 0.4020\n",
      "Optimization Iteration:  44289, Training Accuracy:  76.6%, Loss: 0.3980\n",
      "Optimization Iteration:  44353, Training Accuracy:  81.2%, Loss: 0.4117\n",
      "Optimization Iteration:  44417, Training Accuracy:  82.8%, Loss: 0.3273\n",
      "Optimization Iteration:  44481, Training Accuracy:  73.4%, Loss: 0.3900\n",
      "Optimization Iteration:  44545, Training Accuracy:  73.4%, Loss: 0.4274\n",
      "Optimization Iteration:  44609, Training Accuracy:  81.2%, Loss: 0.3508\n",
      "Optimization Iteration:  44673, Training Accuracy:  73.4%, Loss: 0.4273\n",
      "Optimization Iteration:  44737, Training Accuracy:  70.3%, Loss: 0.4064\n",
      "Optimization Iteration:  44801, Training Accuracy:  78.1%, Loss: 0.3873\n",
      "Optimization Iteration:  44865, Training Accuracy:  73.4%, Loss: 0.3826\n",
      "Optimization Iteration:  44929, Training Accuracy:  76.6%, Loss: 0.3785\n",
      "Optimization Iteration:  44993, Training Accuracy:  70.3%, Loss: 0.5748\n",
      "Optimization Iteration:  45057, Training Accuracy:  79.7%, Loss: 0.4400\n",
      "Optimization Iteration:  45121, Training Accuracy:  82.8%, Loss: 0.3273\n",
      "Optimization Iteration:  45185, Training Accuracy:  82.8%, Loss: 0.2629\n",
      "Optimization Iteration:  45249, Training Accuracy:  75.0%, Loss: 0.3985\n",
      "Optimization Iteration:  45313, Training Accuracy:  75.0%, Loss: 0.4786\n",
      "Optimization Iteration:  45377, Training Accuracy:  73.4%, Loss: 0.4465\n",
      "Optimization Iteration:  45441, Training Accuracy:  73.4%, Loss: 0.4641\n",
      "Optimization Iteration:  45505, Training Accuracy:  79.7%, Loss: 0.3395\n",
      "Optimization Iteration:  45569, Training Accuracy:  71.9%, Loss: 0.4150\n",
      "Optimization Iteration:  45633, Training Accuracy:  79.7%, Loss: 0.4174\n",
      "Optimization Iteration:  45697, Training Accuracy:  75.0%, Loss: 0.4139\n",
      "Optimization Iteration:  45761, Training Accuracy:  84.4%, Loss: 0.3621\n",
      "Optimization Iteration:  45825, Training Accuracy:  85.9%, Loss: 0.2769\n",
      "Optimization Iteration:  45889, Training Accuracy:  81.2%, Loss: 0.3441\n",
      "Optimization Iteration:  45953, Training Accuracy:  82.8%, Loss: 0.3649\n",
      "Optimization Iteration:  46017, Training Accuracy:  82.8%, Loss: 0.3194\n",
      "Optimization Iteration:  46081, Training Accuracy:  87.5%, Loss: 0.2642\n",
      "Optimization Iteration:  46145, Training Accuracy:  64.1%, Loss: 0.4562\n",
      "Optimization Iteration:  46209, Training Accuracy:  85.9%, Loss: 0.2951\n",
      "Optimization Iteration:  46273, Training Accuracy:  84.4%, Loss: 0.4068\n",
      "Optimization Iteration:  46337, Training Accuracy:  78.1%, Loss: 0.4563\n",
      "Optimization Iteration:  46401, Training Accuracy:  81.2%, Loss: 0.3973\n",
      "Optimization Iteration:  46465, Training Accuracy:  76.6%, Loss: 0.3900\n",
      "Optimization Iteration:  46529, Training Accuracy:  68.8%, Loss: 0.4485\n",
      "Optimization Iteration:  46593, Training Accuracy:  84.4%, Loss: 0.3361\n",
      "Optimization Iteration:  46657, Training Accuracy:  71.9%, Loss: 0.3839\n",
      "Optimization Iteration:  46721, Training Accuracy:  78.1%, Loss: 0.3518\n",
      "Optimization Iteration:  46785, Training Accuracy:  67.2%, Loss: 0.4601\n",
      "Optimization Iteration:  46849, Training Accuracy:  70.3%, Loss: 0.4187\n",
      "Optimization Iteration:  46913, Training Accuracy:  89.1%, Loss: 0.3484\n",
      "Optimization Iteration:  46977, Training Accuracy:  75.0%, Loss: 0.4191\n",
      "Optimization Iteration:  47041, Training Accuracy:  81.2%, Loss: 0.3435\n",
      "Optimization Iteration:  47105, Training Accuracy:  73.4%, Loss: 0.4138\n",
      "Optimization Iteration:  47169, Training Accuracy:  71.9%, Loss: 0.4186\n",
      "Optimization Iteration:  47233, Training Accuracy:  75.0%, Loss: 0.3931\n",
      "Optimization Iteration:  47297, Training Accuracy:  76.6%, Loss: 0.3481\n",
      "Optimization Iteration:  47361, Training Accuracy:  78.1%, Loss: 0.3365\n",
      "Optimization Iteration:  47425, Training Accuracy:  85.9%, Loss: 0.3028\n",
      "Optimization Iteration:  47489, Training Accuracy:  76.6%, Loss: 0.3728\n",
      "Optimization Iteration:  47553, Training Accuracy:  82.8%, Loss: 0.4593\n",
      "Optimization Iteration:  47617, Training Accuracy:  65.6%, Loss: 0.4564\n",
      "Optimization Iteration:  47681, Training Accuracy:  81.2%, Loss: 0.3368\n",
      "Optimization Iteration:  47745, Training Accuracy:  76.6%, Loss: 0.4325\n",
      "Optimization Iteration:  47809, Training Accuracy:  73.4%, Loss: 0.3998\n",
      "Optimization Iteration:  47873, Training Accuracy:  87.5%, Loss: 0.3137\n",
      "Optimization Iteration:  47937, Training Accuracy:  75.0%, Loss: 0.3540\n",
      "Optimization Iteration:  48001, Training Accuracy:  76.6%, Loss: 0.3597\n",
      "Optimization Iteration:  48065, Training Accuracy:  79.7%, Loss: 0.3217\n",
      "Optimization Iteration:  48129, Training Accuracy:  79.7%, Loss: 0.4448\n",
      "Optimization Iteration:  48193, Training Accuracy:  73.4%, Loss: 0.4964\n",
      "Optimization Iteration:  48257, Training Accuracy:  79.7%, Loss: 0.3800\n",
      "Optimization Iteration:  48321, Training Accuracy:  75.0%, Loss: 0.3875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  48385, Training Accuracy:  71.9%, Loss: 0.4004\n",
      "Optimization Iteration:  48449, Training Accuracy:  68.8%, Loss: 0.4496\n",
      "Optimization Iteration:  48513, Training Accuracy:  73.4%, Loss: 0.3921\n",
      "Optimization Iteration:  48577, Training Accuracy:  64.1%, Loss: 0.5133\n",
      "Optimization Iteration:  48641, Training Accuracy:  81.2%, Loss: 0.2930\n",
      "Optimization Iteration:  48705, Training Accuracy:  78.1%, Loss: 0.3212\n",
      "Optimization Iteration:  48769, Training Accuracy:  89.1%, Loss: 0.3403\n",
      "Optimization Iteration:  48833, Training Accuracy:  84.4%, Loss: 0.3356\n",
      "Optimization Iteration:  48897, Training Accuracy:  70.3%, Loss: 0.4432\n",
      "Optimization Iteration:  48961, Training Accuracy:  84.4%, Loss: 0.3779\n",
      "Optimization Iteration:  49025, Training Accuracy:  75.0%, Loss: 0.3987\n",
      "Optimization Iteration:  49089, Training Accuracy:  71.9%, Loss: 0.3707\n",
      "Optimization Iteration:  49153, Training Accuracy:  75.0%, Loss: 0.3853\n",
      "Optimization Iteration:  49217, Training Accuracy:  75.0%, Loss: 0.3821\n",
      "Optimization Iteration:  49281, Training Accuracy:  76.6%, Loss: 0.3404\n",
      "Optimization Iteration:  49345, Training Accuracy:  82.8%, Loss: 0.3049\n",
      "Optimization Iteration:  49409, Training Accuracy:  78.1%, Loss: 0.3988\n",
      "Optimization Iteration:  49473, Training Accuracy:  73.4%, Loss: 0.3456\n",
      "Optimization Iteration:  49537, Training Accuracy:  76.6%, Loss: 0.3424\n",
      "Optimization Iteration:  49601, Training Accuracy:  67.2%, Loss: 0.4652\n",
      "Optimization Iteration:  49665, Training Accuracy:  84.4%, Loss: 0.2884\n",
      "Optimization Iteration:  49729, Training Accuracy:  68.8%, Loss: 0.4663\n",
      "Optimization Iteration:  49793, Training Accuracy:  71.9%, Loss: 0.3946\n",
      "Optimization Iteration:  49857, Training Accuracy:  67.2%, Loss: 0.4304\n",
      "Optimization Iteration:  49921, Training Accuracy:  81.2%, Loss: 0.4284\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 26\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  75.0%, Loss: 0.4563\n",
      "Optimization Iteration:    129, Training Accuracy:  78.1%, Loss: 0.4288\n",
      "Optimization Iteration:    193, Training Accuracy:  81.2%, Loss: 0.3816\n",
      "Optimization Iteration:    257, Training Accuracy:  71.9%, Loss: 0.3927\n",
      "Optimization Iteration:    321, Training Accuracy:  76.6%, Loss: 0.3860\n",
      "Optimization Iteration:    385, Training Accuracy:  76.6%, Loss: 0.3674\n",
      "Optimization Iteration:    449, Training Accuracy:  84.4%, Loss: 0.2897\n",
      "Optimization Iteration:    513, Training Accuracy:  71.9%, Loss: 0.4808\n",
      "Optimization Iteration:    577, Training Accuracy:  70.3%, Loss: 0.4390\n",
      "Optimization Iteration:    641, Training Accuracy:  73.4%, Loss: 0.3830\n",
      "Optimization Iteration:    705, Training Accuracy:  78.1%, Loss: 0.4785\n",
      "Optimization Iteration:    769, Training Accuracy:  78.1%, Loss: 0.3712\n",
      "Optimization Iteration:    833, Training Accuracy:  73.4%, Loss: 0.3814\n",
      "Optimization Iteration:    897, Training Accuracy:  75.0%, Loss: 0.3720\n",
      "Optimization Iteration:    961, Training Accuracy:  79.7%, Loss: 0.3404\n",
      "Optimization Iteration:   1025, Training Accuracy:  81.2%, Loss: 0.3391\n",
      "Optimization Iteration:   1089, Training Accuracy:  65.6%, Loss: 0.5042\n",
      "Optimization Iteration:   1153, Training Accuracy:  70.3%, Loss: 0.4203\n",
      "Optimization Iteration:   1217, Training Accuracy:  78.1%, Loss: 0.3914\n",
      "Optimization Iteration:   1281, Training Accuracy:  75.0%, Loss: 0.3814\n",
      "Optimization Iteration:   1345, Training Accuracy:  75.0%, Loss: 0.3757\n",
      "Optimization Iteration:   1409, Training Accuracy:  81.2%, Loss: 0.3288\n",
      "Optimization Iteration:   1473, Training Accuracy:  68.8%, Loss: 0.4386\n",
      "Optimization Iteration:   1537, Training Accuracy:  81.2%, Loss: 0.3340\n",
      "Optimization Iteration:   1601, Training Accuracy:  84.4%, Loss: 0.3125\n",
      "Optimization Iteration:   1665, Training Accuracy:  79.7%, Loss: 0.3341\n",
      "Optimization Iteration:   1729, Training Accuracy:  81.2%, Loss: 0.3513\n",
      "Optimization Iteration:   1793, Training Accuracy:  73.4%, Loss: 0.4646\n",
      "Optimization Iteration:   1857, Training Accuracy:  81.2%, Loss: 0.3879\n",
      "Optimization Iteration:   1921, Training Accuracy:  75.0%, Loss: 0.4333\n",
      "Optimization Iteration:   1985, Training Accuracy:  75.0%, Loss: 0.3950\n",
      "Optimization Iteration:   2049, Training Accuracy:  78.1%, Loss: 0.3135\n",
      "Optimization Iteration:   2113, Training Accuracy:  85.9%, Loss: 0.3347\n",
      "Optimization Iteration:   2177, Training Accuracy:  76.6%, Loss: 0.3455\n",
      "Optimization Iteration:   2241, Training Accuracy:  78.1%, Loss: 0.3904\n",
      "Optimization Iteration:   2305, Training Accuracy:  79.7%, Loss: 0.3764\n",
      "Optimization Iteration:   2369, Training Accuracy:  73.4%, Loss: 0.4147\n",
      "Optimization Iteration:   2433, Training Accuracy:  71.9%, Loss: 0.4085\n",
      "Optimization Iteration:   2497, Training Accuracy:  75.0%, Loss: 0.3347\n",
      "Optimization Iteration:   2561, Training Accuracy:  75.0%, Loss: 0.3791\n",
      "Optimization Iteration:   2625, Training Accuracy:  84.4%, Loss: 0.3874\n",
      "Optimization Iteration:   2689, Training Accuracy:  78.1%, Loss: 0.3656\n",
      "Optimization Iteration:   2753, Training Accuracy:  73.4%, Loss: 0.3913\n",
      "Optimization Iteration:   2817, Training Accuracy:  73.4%, Loss: 0.4446\n",
      "Optimization Iteration:   2881, Training Accuracy:  78.1%, Loss: 0.3777\n",
      "Optimization Iteration:   2945, Training Accuracy:  75.0%, Loss: 0.4755\n",
      "Optimization Iteration:   3009, Training Accuracy:  81.2%, Loss: 0.3571\n",
      "Optimization Iteration:   3073, Training Accuracy:  67.2%, Loss: 0.4019\n",
      "Optimization Iteration:   3137, Training Accuracy:  87.5%, Loss: 0.3098\n",
      "Optimization Iteration:   3201, Training Accuracy:  87.5%, Loss: 0.2989\n",
      "Optimization Iteration:   3265, Training Accuracy:  78.1%, Loss: 0.4245\n",
      "Optimization Iteration:   3329, Training Accuracy:  76.6%, Loss: 0.3602\n",
      "Optimization Iteration:   3393, Training Accuracy:  71.9%, Loss: 0.4226\n",
      "Optimization Iteration:   3457, Training Accuracy:  78.1%, Loss: 0.3598\n",
      "Optimization Iteration:   3521, Training Accuracy:  71.9%, Loss: 0.4500\n",
      "Optimization Iteration:   3585, Training Accuracy:  78.1%, Loss: 0.3707\n",
      "Optimization Iteration:   3649, Training Accuracy:  84.4%, Loss: 0.3119\n",
      "Optimization Iteration:   3713, Training Accuracy:  70.3%, Loss: 0.4495\n",
      "Optimization Iteration:   3777, Training Accuracy:  67.2%, Loss: 0.4599\n",
      "Optimization Iteration:   3841, Training Accuracy:  73.4%, Loss: 0.4596\n",
      "Optimization Iteration:   3905, Training Accuracy:  73.4%, Loss: 0.3758\n",
      "Optimization Iteration:   3969, Training Accuracy:  76.6%, Loss: 0.3589\n",
      "Optimization Iteration:   4033, Training Accuracy:  78.1%, Loss: 0.3142\n",
      "Optimization Iteration:   4097, Training Accuracy:  75.0%, Loss: 0.3483\n",
      "Optimization Iteration:   4161, Training Accuracy:  75.0%, Loss: 0.4751\n",
      "Optimization Iteration:   4225, Training Accuracy:  75.0%, Loss: 0.3191\n",
      "Optimization Iteration:   4289, Training Accuracy:  79.7%, Loss: 0.3963\n",
      "Optimization Iteration:   4353, Training Accuracy:  81.2%, Loss: 0.3976\n",
      "Optimization Iteration:   4417, Training Accuracy:  78.1%, Loss: 0.3786\n",
      "Optimization Iteration:   4481, Training Accuracy:  82.8%, Loss: 0.3502\n",
      "Optimization Iteration:   4545, Training Accuracy:  85.9%, Loss: 0.3219\n",
      "Optimization Iteration:   4609, Training Accuracy:  81.2%, Loss: 0.3444\n",
      "Optimization Iteration:   4673, Training Accuracy:  76.6%, Loss: 0.4220\n",
      "Optimization Iteration:   4737, Training Accuracy:  75.0%, Loss: 0.3556\n",
      "Optimization Iteration:   4801, Training Accuracy:  71.9%, Loss: 0.4877\n",
      "Optimization Iteration:   4865, Training Accuracy:  78.1%, Loss: 0.4343\n",
      "Optimization Iteration:   4929, Training Accuracy:  79.7%, Loss: 0.3774\n",
      "Optimization Iteration:   4993, Training Accuracy:  82.8%, Loss: 0.3521\n",
      "Optimization Iteration:   5057, Training Accuracy:  79.7%, Loss: 0.4790\n",
      "Optimization Iteration:   5121, Training Accuracy:  73.4%, Loss: 0.4542\n",
      "Optimization Iteration:   5185, Training Accuracy:  82.8%, Loss: 0.3684\n",
      "Optimization Iteration:   5249, Training Accuracy:  62.5%, Loss: 0.5056\n",
      "Optimization Iteration:   5313, Training Accuracy:  85.9%, Loss: 0.2802\n",
      "Optimization Iteration:   5377, Training Accuracy:  82.8%, Loss: 0.3266\n",
      "Optimization Iteration:   5441, Training Accuracy:  70.3%, Loss: 0.4177\n",
      "Optimization Iteration:   5505, Training Accuracy:  81.2%, Loss: 0.2989\n",
      "Optimization Iteration:   5569, Training Accuracy:  79.7%, Loss: 0.3653\n",
      "Optimization Iteration:   5633, Training Accuracy:  79.7%, Loss: 0.3427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   5697, Training Accuracy:  78.1%, Loss: 0.4145\n",
      "Optimization Iteration:   5761, Training Accuracy:  81.2%, Loss: 0.2773\n",
      "Optimization Iteration:   5825, Training Accuracy:  75.0%, Loss: 0.4111\n",
      "Optimization Iteration:   5889, Training Accuracy:  82.8%, Loss: 0.3918\n",
      "Optimization Iteration:   5953, Training Accuracy:  79.7%, Loss: 0.4075\n",
      "Optimization Iteration:   6017, Training Accuracy:  57.8%, Loss: 0.4741\n",
      "Optimization Iteration:   6081, Training Accuracy:  68.8%, Loss: 0.4590\n",
      "Optimization Iteration:   6145, Training Accuracy:  75.0%, Loss: 0.4456\n",
      "Optimization Iteration:   6209, Training Accuracy:  71.9%, Loss: 0.4217\n",
      "Optimization Iteration:   6273, Training Accuracy:  79.7%, Loss: 0.3792\n",
      "Optimization Iteration:   6337, Training Accuracy:  68.8%, Loss: 0.4459\n",
      "Optimization Iteration:   6401, Training Accuracy:  82.8%, Loss: 0.3415\n",
      "Optimization Iteration:   6465, Training Accuracy:  81.2%, Loss: 0.3307\n",
      "Optimization Iteration:   6529, Training Accuracy:  84.4%, Loss: 0.4539\n",
      "Optimization Iteration:   6593, Training Accuracy:  85.9%, Loss: 0.3265\n",
      "Optimization Iteration:   6657, Training Accuracy:  75.0%, Loss: 0.4158\n",
      "Optimization Iteration:   6721, Training Accuracy:  81.2%, Loss: 0.3621\n",
      "Optimization Iteration:   6785, Training Accuracy:  78.1%, Loss: 0.4636\n",
      "Optimization Iteration:   6849, Training Accuracy:  71.9%, Loss: 0.4085\n",
      "Optimization Iteration:   6913, Training Accuracy:  78.1%, Loss: 0.3553\n",
      "Optimization Iteration:   6977, Training Accuracy:  70.3%, Loss: 0.4463\n",
      "Optimization Iteration:   7041, Training Accuracy:  76.6%, Loss: 0.3928\n",
      "Optimization Iteration:   7105, Training Accuracy:  79.7%, Loss: 0.3413\n",
      "Optimization Iteration:   7169, Training Accuracy:  68.8%, Loss: 0.4621\n",
      "Optimization Iteration:   7233, Training Accuracy:  78.1%, Loss: 0.3920\n",
      "Optimization Iteration:   7297, Training Accuracy:  71.9%, Loss: 0.4750\n",
      "Optimization Iteration:   7361, Training Accuracy:  84.4%, Loss: 0.3304\n",
      "Optimization Iteration:   7425, Training Accuracy:  73.4%, Loss: 0.3533\n",
      "Optimization Iteration:   7489, Training Accuracy:  76.6%, Loss: 0.3680\n",
      "Optimization Iteration:   7553, Training Accuracy:  71.9%, Loss: 0.3999\n",
      "Optimization Iteration:   7617, Training Accuracy:  79.7%, Loss: 0.3969\n",
      "Optimization Iteration:   7681, Training Accuracy:  73.4%, Loss: 0.4310\n",
      "Optimization Iteration:   7745, Training Accuracy:  73.4%, Loss: 0.3546\n",
      "Optimization Iteration:   7809, Training Accuracy:  81.2%, Loss: 0.3697\n",
      "Optimization Iteration:   7873, Training Accuracy:  79.7%, Loss: 0.2978\n",
      "Optimization Iteration:   7937, Training Accuracy:  84.4%, Loss: 0.3756\n",
      "Optimization Iteration:   8001, Training Accuracy:  85.9%, Loss: 0.3627\n",
      "Optimization Iteration:   8065, Training Accuracy:  76.6%, Loss: 0.4258\n",
      "Optimization Iteration:   8129, Training Accuracy:  67.2%, Loss: 0.4567\n",
      "Optimization Iteration:   8193, Training Accuracy:  76.6%, Loss: 0.3945\n",
      "Optimization Iteration:   8257, Training Accuracy:  76.6%, Loss: 0.4194\n",
      "Optimization Iteration:   8321, Training Accuracy:  62.5%, Loss: 0.4275\n",
      "Optimization Iteration:   8385, Training Accuracy:  73.4%, Loss: 0.4072\n",
      "Optimization Iteration:   8449, Training Accuracy:  78.1%, Loss: 0.4407\n",
      "Optimization Iteration:   8513, Training Accuracy:  78.1%, Loss: 0.3570\n",
      "Optimization Iteration:   8577, Training Accuracy:  79.7%, Loss: 0.4337\n",
      "Optimization Iteration:   8641, Training Accuracy:  84.4%, Loss: 0.4113\n",
      "Optimization Iteration:   8705, Training Accuracy:  78.1%, Loss: 0.3924\n",
      "Optimization Iteration:   8769, Training Accuracy:  73.4%, Loss: 0.3952\n",
      "Optimization Iteration:   8833, Training Accuracy:  82.8%, Loss: 0.3226\n",
      "Optimization Iteration:   8897, Training Accuracy:  76.6%, Loss: 0.4041\n",
      "Optimization Iteration:   8961, Training Accuracy:  65.6%, Loss: 0.4513\n",
      "Optimization Iteration:   9025, Training Accuracy:  67.2%, Loss: 0.5005\n",
      "Optimization Iteration:   9089, Training Accuracy:  78.1%, Loss: 0.3902\n",
      "Optimization Iteration:   9153, Training Accuracy:  78.1%, Loss: 0.3568\n",
      "Optimization Iteration:   9217, Training Accuracy:  75.0%, Loss: 0.3902\n",
      "Optimization Iteration:   9281, Training Accuracy:  68.8%, Loss: 0.4174\n",
      "Optimization Iteration:   9345, Training Accuracy:  75.0%, Loss: 0.4297\n",
      "Optimization Iteration:   9409, Training Accuracy:  85.9%, Loss: 0.3778\n",
      "Optimization Iteration:   9473, Training Accuracy:  79.7%, Loss: 0.3769\n",
      "Optimization Iteration:   9537, Training Accuracy:  78.1%, Loss: 0.3770\n",
      "Optimization Iteration:   9601, Training Accuracy:  73.4%, Loss: 0.3633\n",
      "Optimization Iteration:   9665, Training Accuracy:  65.6%, Loss: 0.4386\n",
      "Optimization Iteration:   9729, Training Accuracy:  71.9%, Loss: 0.4308\n",
      "Optimization Iteration:   9793, Training Accuracy:  73.4%, Loss: 0.3136\n",
      "Optimization Iteration:   9857, Training Accuracy:  67.2%, Loss: 0.4271\n",
      "Optimization Iteration:   9921, Training Accuracy:  76.6%, Loss: 0.3447\n",
      "Optimization Iteration:   9985, Training Accuracy:  73.4%, Loss: 0.4150\n",
      "Optimization Iteration:  10049, Training Accuracy:  81.2%, Loss: 0.3617\n",
      "Optimization Iteration:  10113, Training Accuracy:  73.4%, Loss: 0.3737\n",
      "Optimization Iteration:  10177, Training Accuracy:  70.3%, Loss: 0.4122\n",
      "Optimization Iteration:  10241, Training Accuracy:  71.9%, Loss: 0.5054\n",
      "Optimization Iteration:  10305, Training Accuracy:  82.8%, Loss: 0.3882\n",
      "Optimization Iteration:  10369, Training Accuracy:  78.1%, Loss: 0.3656\n",
      "Optimization Iteration:  10433, Training Accuracy:  78.1%, Loss: 0.3848\n",
      "Optimization Iteration:  10497, Training Accuracy:  75.0%, Loss: 0.4346\n",
      "Optimization Iteration:  10561, Training Accuracy:  79.7%, Loss: 0.3087\n",
      "Optimization Iteration:  10625, Training Accuracy:  79.7%, Loss: 0.3691\n",
      "Optimization Iteration:  10689, Training Accuracy:  82.8%, Loss: 0.2892\n",
      "Optimization Iteration:  10753, Training Accuracy:  79.7%, Loss: 0.3952\n",
      "Optimization Iteration:  10817, Training Accuracy:  71.9%, Loss: 0.4192\n",
      "Optimization Iteration:  10881, Training Accuracy:  79.7%, Loss: 0.3510\n",
      "Optimization Iteration:  10945, Training Accuracy:  85.9%, Loss: 0.3853\n",
      "Optimization Iteration:  11009, Training Accuracy:  78.1%, Loss: 0.3587\n",
      "Optimization Iteration:  11073, Training Accuracy:  82.8%, Loss: 0.3293\n",
      "Optimization Iteration:  11137, Training Accuracy:  78.1%, Loss: 0.3924\n",
      "Optimization Iteration:  11201, Training Accuracy:  84.4%, Loss: 0.3250\n",
      "Optimization Iteration:  11265, Training Accuracy:  76.6%, Loss: 0.3227\n",
      "Optimization Iteration:  11329, Training Accuracy:  81.2%, Loss: 0.3984\n",
      "Optimization Iteration:  11393, Training Accuracy:  76.6%, Loss: 0.4352\n",
      "Optimization Iteration:  11457, Training Accuracy:  79.7%, Loss: 0.3430\n",
      "Optimization Iteration:  11521, Training Accuracy:  70.3%, Loss: 0.4310\n",
      "Optimization Iteration:  11585, Training Accuracy:  68.8%, Loss: 0.3940\n",
      "Optimization Iteration:  11649, Training Accuracy:  75.0%, Loss: 0.3593\n",
      "Optimization Iteration:  11713, Training Accuracy:  78.1%, Loss: 0.3844\n",
      "Optimization Iteration:  11777, Training Accuracy:  78.1%, Loss: 0.4390\n",
      "Optimization Iteration:  11841, Training Accuracy:  78.1%, Loss: 0.3898\n",
      "Optimization Iteration:  11905, Training Accuracy:  89.1%, Loss: 0.2636\n",
      "Optimization Iteration:  11969, Training Accuracy:  82.8%, Loss: 0.3037\n",
      "Optimization Iteration:  12033, Training Accuracy:  75.0%, Loss: 0.3740\n",
      "Optimization Iteration:  12097, Training Accuracy:  89.1%, Loss: 0.2890\n",
      "Optimization Iteration:  12161, Training Accuracy:  81.2%, Loss: 0.4165\n",
      "Optimization Iteration:  12225, Training Accuracy:  84.4%, Loss: 0.2584\n",
      "Optimization Iteration:  12289, Training Accuracy:  70.3%, Loss: 0.4376\n",
      "Optimization Iteration:  12353, Training Accuracy:  78.1%, Loss: 0.3921\n",
      "Optimization Iteration:  12417, Training Accuracy:  73.4%, Loss: 0.3882\n",
      "Optimization Iteration:  12481, Training Accuracy:  81.2%, Loss: 0.4018\n",
      "Optimization Iteration:  12545, Training Accuracy:  81.2%, Loss: 0.4088\n",
      "Optimization Iteration:  12609, Training Accuracy:  81.2%, Loss: 0.3177\n",
      "Optimization Iteration:  12673, Training Accuracy:  78.1%, Loss: 0.3939\n",
      "Optimization Iteration:  12737, Training Accuracy:  56.2%, Loss: 0.5441\n",
      "Optimization Iteration:  12801, Training Accuracy:  76.6%, Loss: 0.4316\n",
      "Optimization Iteration:  12865, Training Accuracy:  78.1%, Loss: 0.3517\n",
      "Optimization Iteration:  12929, Training Accuracy:  70.3%, Loss: 0.4151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  12993, Training Accuracy:  75.0%, Loss: 0.3801\n",
      "Optimization Iteration:  13057, Training Accuracy:  73.4%, Loss: 0.4220\n",
      "Optimization Iteration:  13121, Training Accuracy:  81.2%, Loss: 0.3216\n",
      "Optimization Iteration:  13185, Training Accuracy:  79.7%, Loss: 0.4157\n",
      "Optimization Iteration:  13249, Training Accuracy:  76.6%, Loss: 0.4390\n",
      "Optimization Iteration:  13313, Training Accuracy:  73.4%, Loss: 0.4686\n",
      "Optimization Iteration:  13377, Training Accuracy:  75.0%, Loss: 0.4521\n",
      "Optimization Iteration:  13441, Training Accuracy:  79.7%, Loss: 0.3452\n",
      "Optimization Iteration:  13505, Training Accuracy:  75.0%, Loss: 0.3681\n",
      "Optimization Iteration:  13569, Training Accuracy:  81.2%, Loss: 0.3161\n",
      "Optimization Iteration:  13633, Training Accuracy:  76.6%, Loss: 0.4311\n",
      "Optimization Iteration:  13697, Training Accuracy:  81.2%, Loss: 0.3732\n",
      "Optimization Iteration:  13761, Training Accuracy:  76.6%, Loss: 0.3434\n",
      "Optimization Iteration:  13825, Training Accuracy:  70.3%, Loss: 0.4151\n",
      "Optimization Iteration:  13889, Training Accuracy:  78.1%, Loss: 0.3686\n",
      "Optimization Iteration:  13953, Training Accuracy:  79.7%, Loss: 0.3260\n",
      "Optimization Iteration:  14017, Training Accuracy:  82.8%, Loss: 0.3461\n",
      "Optimization Iteration:  14081, Training Accuracy:  68.8%, Loss: 0.4139\n",
      "Optimization Iteration:  14145, Training Accuracy:  75.0%, Loss: 0.3628\n",
      "Optimization Iteration:  14209, Training Accuracy:  78.1%, Loss: 0.3946\n",
      "Optimization Iteration:  14273, Training Accuracy:  70.3%, Loss: 0.4400\n",
      "Optimization Iteration:  14337, Training Accuracy:  75.0%, Loss: 0.3749\n",
      "Optimization Iteration:  14401, Training Accuracy:  79.7%, Loss: 0.3364\n",
      "Optimization Iteration:  14465, Training Accuracy:  76.6%, Loss: 0.4246\n",
      "Optimization Iteration:  14529, Training Accuracy:  81.2%, Loss: 0.3769\n",
      "Optimization Iteration:  14593, Training Accuracy:  85.9%, Loss: 0.2895\n",
      "Optimization Iteration:  14657, Training Accuracy:  71.9%, Loss: 0.4454\n",
      "Optimization Iteration:  14721, Training Accuracy:  78.1%, Loss: 0.3496\n",
      "Optimization Iteration:  14785, Training Accuracy:  75.0%, Loss: 0.4845\n",
      "Optimization Iteration:  14849, Training Accuracy:  71.9%, Loss: 0.4118\n",
      "Optimization Iteration:  14913, Training Accuracy:  82.8%, Loss: 0.4095\n",
      "Optimization Iteration:  14977, Training Accuracy:  82.8%, Loss: 0.3474\n",
      "Optimization Iteration:  15041, Training Accuracy:  73.4%, Loss: 0.4256\n",
      "Optimization Iteration:  15105, Training Accuracy:  81.2%, Loss: 0.3351\n",
      "Optimization Iteration:  15169, Training Accuracy:  71.9%, Loss: 0.3945\n",
      "Optimization Iteration:  15233, Training Accuracy:  75.0%, Loss: 0.3932\n",
      "Optimization Iteration:  15297, Training Accuracy:  73.4%, Loss: 0.3960\n",
      "Optimization Iteration:  15361, Training Accuracy:  84.4%, Loss: 0.2901\n",
      "Optimization Iteration:  15425, Training Accuracy:  70.3%, Loss: 0.4102\n",
      "Optimization Iteration:  15489, Training Accuracy:  70.3%, Loss: 0.4282\n",
      "Optimization Iteration:  15553, Training Accuracy:  78.1%, Loss: 0.3437\n",
      "Optimization Iteration:  15617, Training Accuracy:  70.3%, Loss: 0.3842\n",
      "Optimization Iteration:  15681, Training Accuracy:  73.4%, Loss: 0.4155\n",
      "Optimization Iteration:  15745, Training Accuracy:  87.5%, Loss: 0.2823\n",
      "Optimization Iteration:  15809, Training Accuracy:  75.0%, Loss: 0.4161\n",
      "Optimization Iteration:  15873, Training Accuracy:  76.6%, Loss: 0.3802\n",
      "Optimization Iteration:  15937, Training Accuracy:  78.1%, Loss: 0.3260\n",
      "Optimization Iteration:  16001, Training Accuracy:  75.0%, Loss: 0.3962\n",
      "Optimization Iteration:  16065, Training Accuracy:  76.6%, Loss: 0.4367\n",
      "Optimization Iteration:  16129, Training Accuracy:  71.9%, Loss: 0.3948\n",
      "Optimization Iteration:  16193, Training Accuracy:  73.4%, Loss: 0.3840\n",
      "Optimization Iteration:  16257, Training Accuracy:  82.8%, Loss: 0.4064\n",
      "Optimization Iteration:  16321, Training Accuracy:  78.1%, Loss: 0.4668\n",
      "Optimization Iteration:  16385, Training Accuracy:  73.4%, Loss: 0.3960\n",
      "Optimization Iteration:  16449, Training Accuracy:  70.3%, Loss: 0.4205\n",
      "Optimization Iteration:  16513, Training Accuracy:  75.0%, Loss: 0.4256\n",
      "Optimization Iteration:  16577, Training Accuracy:  73.4%, Loss: 0.3951\n",
      "Optimization Iteration:  16641, Training Accuracy:  79.7%, Loss: 0.4731\n",
      "Optimization Iteration:  16705, Training Accuracy:  76.6%, Loss: 0.4258\n",
      "Optimization Iteration:  16769, Training Accuracy:  82.8%, Loss: 0.3529\n",
      "Optimization Iteration:  16833, Training Accuracy:  76.6%, Loss: 0.3214\n",
      "Optimization Iteration:  16897, Training Accuracy:  78.1%, Loss: 0.3929\n",
      "Optimization Iteration:  16961, Training Accuracy:  76.6%, Loss: 0.3739\n",
      "Optimization Iteration:  17025, Training Accuracy:  70.3%, Loss: 0.4099\n",
      "Optimization Iteration:  17089, Training Accuracy:  82.8%, Loss: 0.3699\n",
      "Optimization Iteration:  17153, Training Accuracy:  75.0%, Loss: 0.4073\n",
      "Optimization Iteration:  17217, Training Accuracy:  78.1%, Loss: 0.4082\n",
      "Optimization Iteration:  17281, Training Accuracy:  73.4%, Loss: 0.4843\n",
      "Optimization Iteration:  17345, Training Accuracy:  81.2%, Loss: 0.3463\n",
      "Optimization Iteration:  17409, Training Accuracy:  73.4%, Loss: 0.3395\n",
      "Optimization Iteration:  17473, Training Accuracy:  71.9%, Loss: 0.3842\n",
      "Optimization Iteration:  17537, Training Accuracy:  73.4%, Loss: 0.3433\n",
      "Optimization Iteration:  17601, Training Accuracy:  76.6%, Loss: 0.3586\n",
      "Optimization Iteration:  17665, Training Accuracy:  81.2%, Loss: 0.3846\n",
      "Optimization Iteration:  17729, Training Accuracy:  75.0%, Loss: 0.4114\n",
      "Optimization Iteration:  17793, Training Accuracy:  75.0%, Loss: 0.4530\n",
      "Optimization Iteration:  17857, Training Accuracy:  75.0%, Loss: 0.4329\n",
      "Optimization Iteration:  17921, Training Accuracy:  81.2%, Loss: 0.3882\n",
      "Optimization Iteration:  17985, Training Accuracy:  85.9%, Loss: 0.3212\n",
      "Optimization Iteration:  18049, Training Accuracy:  82.8%, Loss: 0.3939\n",
      "Optimization Iteration:  18113, Training Accuracy:  67.2%, Loss: 0.4436\n",
      "Optimization Iteration:  18177, Training Accuracy:  76.6%, Loss: 0.3835\n",
      "Optimization Iteration:  18241, Training Accuracy:  70.3%, Loss: 0.4561\n",
      "Optimization Iteration:  18305, Training Accuracy:  78.1%, Loss: 0.3521\n",
      "Optimization Iteration:  18369, Training Accuracy:  71.9%, Loss: 0.3174\n",
      "Optimization Iteration:  18433, Training Accuracy:  71.9%, Loss: 0.4326\n",
      "Optimization Iteration:  18497, Training Accuracy:  82.8%, Loss: 0.3091\n",
      "Optimization Iteration:  18561, Training Accuracy:  79.7%, Loss: 0.3765\n",
      "Optimization Iteration:  18625, Training Accuracy:  76.6%, Loss: 0.4536\n",
      "Optimization Iteration:  18689, Training Accuracy:  78.1%, Loss: 0.3832\n",
      "Optimization Iteration:  18753, Training Accuracy:  84.4%, Loss: 0.3396\n",
      "Optimization Iteration:  18817, Training Accuracy:  75.0%, Loss: 0.3847\n",
      "Optimization Iteration:  18881, Training Accuracy:  76.6%, Loss: 0.4028\n",
      "Optimization Iteration:  18945, Training Accuracy:  75.0%, Loss: 0.4046\n",
      "Optimization Iteration:  19009, Training Accuracy:  71.9%, Loss: 0.3969\n",
      "Optimization Iteration:  19073, Training Accuracy:  78.1%, Loss: 0.4311\n",
      "Optimization Iteration:  19137, Training Accuracy:  73.4%, Loss: 0.4301\n",
      "Optimization Iteration:  19201, Training Accuracy:  75.0%, Loss: 0.4237\n",
      "Optimization Iteration:  19265, Training Accuracy:  82.8%, Loss: 0.3461\n",
      "Optimization Iteration:  19329, Training Accuracy:  81.2%, Loss: 0.3645\n",
      "Optimization Iteration:  19393, Training Accuracy:  84.4%, Loss: 0.3752\n",
      "Optimization Iteration:  19457, Training Accuracy:  82.8%, Loss: 0.3569\n",
      "Optimization Iteration:  19521, Training Accuracy:  85.9%, Loss: 0.3475\n",
      "Optimization Iteration:  19585, Training Accuracy:  75.0%, Loss: 0.4456\n",
      "Optimization Iteration:  19649, Training Accuracy:  73.4%, Loss: 0.4438\n",
      "Optimization Iteration:  19713, Training Accuracy:  76.6%, Loss: 0.3607\n",
      "Optimization Iteration:  19777, Training Accuracy:  76.6%, Loss: 0.4362\n",
      "Optimization Iteration:  19841, Training Accuracy:  70.3%, Loss: 0.3827\n",
      "Optimization Iteration:  19905, Training Accuracy:  76.6%, Loss: 0.3700\n",
      "Optimization Iteration:  19969, Training Accuracy:  71.9%, Loss: 0.4995\n",
      "Optimization Iteration:  20033, Training Accuracy:  81.2%, Loss: 0.3858\n",
      "Optimization Iteration:  20097, Training Accuracy:  70.3%, Loss: 0.4940\n",
      "Optimization Iteration:  20161, Training Accuracy:  76.6%, Loss: 0.3515\n",
      "Optimization Iteration:  20225, Training Accuracy:  70.3%, Loss: 0.4404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  20289, Training Accuracy:  71.9%, Loss: 0.4199\n",
      "Optimization Iteration:  20353, Training Accuracy:  79.7%, Loss: 0.3577\n",
      "Optimization Iteration:  20417, Training Accuracy:  73.4%, Loss: 0.4030\n",
      "Optimization Iteration:  20481, Training Accuracy:  81.2%, Loss: 0.3985\n",
      "Optimization Iteration:  20545, Training Accuracy:  79.7%, Loss: 0.3597\n",
      "Optimization Iteration:  20609, Training Accuracy:  81.2%, Loss: 0.3692\n",
      "Optimization Iteration:  20673, Training Accuracy:  78.1%, Loss: 0.3746\n",
      "Optimization Iteration:  20737, Training Accuracy:  85.9%, Loss: 0.3465\n",
      "Optimization Iteration:  20801, Training Accuracy:  81.2%, Loss: 0.3815\n",
      "Optimization Iteration:  20865, Training Accuracy:  67.2%, Loss: 0.4185\n",
      "Optimization Iteration:  20929, Training Accuracy:  78.1%, Loss: 0.3421\n",
      "Optimization Iteration:  20993, Training Accuracy:  68.8%, Loss: 0.4331\n",
      "Optimization Iteration:  21057, Training Accuracy:  79.7%, Loss: 0.3622\n",
      "Optimization Iteration:  21121, Training Accuracy:  73.4%, Loss: 0.4135\n",
      "Optimization Iteration:  21185, Training Accuracy:  79.7%, Loss: 0.3660\n",
      "Optimization Iteration:  21249, Training Accuracy:  67.2%, Loss: 0.5014\n",
      "Optimization Iteration:  21313, Training Accuracy:  76.6%, Loss: 0.4002\n",
      "Optimization Iteration:  21377, Training Accuracy:  73.4%, Loss: 0.3260\n",
      "Optimization Iteration:  21441, Training Accuracy:  71.9%, Loss: 0.4094\n",
      "Optimization Iteration:  21505, Training Accuracy:  73.4%, Loss: 0.3680\n",
      "Optimization Iteration:  21569, Training Accuracy:  76.6%, Loss: 0.3652\n",
      "Optimization Iteration:  21633, Training Accuracy:  89.1%, Loss: 0.2606\n",
      "Optimization Iteration:  21697, Training Accuracy:  76.6%, Loss: 0.4637\n",
      "Optimization Iteration:  21761, Training Accuracy:  78.1%, Loss: 0.3695\n",
      "Optimization Iteration:  21825, Training Accuracy:  71.9%, Loss: 0.4731\n",
      "Optimization Iteration:  21889, Training Accuracy:  70.3%, Loss: 0.4001\n",
      "Optimization Iteration:  21953, Training Accuracy:  67.2%, Loss: 0.5482\n",
      "Optimization Iteration:  22017, Training Accuracy:  84.4%, Loss: 0.3635\n",
      "Optimization Iteration:  22081, Training Accuracy:  73.4%, Loss: 0.4090\n",
      "Optimization Iteration:  22145, Training Accuracy:  76.6%, Loss: 0.4458\n",
      "Optimization Iteration:  22209, Training Accuracy:  81.2%, Loss: 0.3534\n",
      "Optimization Iteration:  22273, Training Accuracy:  76.6%, Loss: 0.3610\n",
      "Optimization Iteration:  22337, Training Accuracy:  76.6%, Loss: 0.2924\n",
      "Optimization Iteration:  22401, Training Accuracy:  73.4%, Loss: 0.4367\n",
      "Optimization Iteration:  22465, Training Accuracy:  75.0%, Loss: 0.4053\n",
      "Optimization Iteration:  22529, Training Accuracy:  76.6%, Loss: 0.3845\n",
      "Optimization Iteration:  22593, Training Accuracy:  73.4%, Loss: 0.4186\n",
      "Optimization Iteration:  22657, Training Accuracy:  73.4%, Loss: 0.4124\n",
      "Optimization Iteration:  22721, Training Accuracy:  78.1%, Loss: 0.3818\n",
      "Optimization Iteration:  22785, Training Accuracy:  78.1%, Loss: 0.3768\n",
      "Optimization Iteration:  22849, Training Accuracy:  78.1%, Loss: 0.4188\n",
      "Optimization Iteration:  22913, Training Accuracy:  71.9%, Loss: 0.4155\n",
      "Optimization Iteration:  22977, Training Accuracy:  75.0%, Loss: 0.4030\n",
      "Optimization Iteration:  23041, Training Accuracy:  76.6%, Loss: 0.3193\n",
      "Optimization Iteration:  23105, Training Accuracy:  76.6%, Loss: 0.3458\n",
      "Optimization Iteration:  23169, Training Accuracy:  84.4%, Loss: 0.3212\n",
      "Optimization Iteration:  23233, Training Accuracy:  70.3%, Loss: 0.4661\n",
      "Optimization Iteration:  23297, Training Accuracy:  78.1%, Loss: 0.4196\n",
      "Optimization Iteration:  23361, Training Accuracy:  81.2%, Loss: 0.3764\n",
      "Optimization Iteration:  23425, Training Accuracy:  81.2%, Loss: 0.3324\n",
      "Optimization Iteration:  23489, Training Accuracy:  84.4%, Loss: 0.3485\n",
      "Optimization Iteration:  23553, Training Accuracy:  76.6%, Loss: 0.3642\n",
      "Optimization Iteration:  23617, Training Accuracy:  68.8%, Loss: 0.5099\n",
      "Optimization Iteration:  23681, Training Accuracy:  71.9%, Loss: 0.4401\n",
      "Optimization Iteration:  23745, Training Accuracy:  71.9%, Loss: 0.3769\n",
      "Optimization Iteration:  23809, Training Accuracy:  70.3%, Loss: 0.4128\n",
      "Optimization Iteration:  23873, Training Accuracy:  71.9%, Loss: 0.3524\n",
      "Optimization Iteration:  23937, Training Accuracy:  75.0%, Loss: 0.4400\n",
      "Optimization Iteration:  24001, Training Accuracy:  84.4%, Loss: 0.3257\n",
      "Optimization Iteration:  24065, Training Accuracy:  76.6%, Loss: 0.3985\n",
      "Optimization Iteration:  24129, Training Accuracy:  79.7%, Loss: 0.3593\n",
      "Optimization Iteration:  24193, Training Accuracy:  79.7%, Loss: 0.3663\n",
      "Optimization Iteration:  24257, Training Accuracy:  76.6%, Loss: 0.3640\n",
      "Optimization Iteration:  24321, Training Accuracy:  76.6%, Loss: 0.4163\n",
      "Optimization Iteration:  24385, Training Accuracy:  73.4%, Loss: 0.4260\n",
      "Optimization Iteration:  24449, Training Accuracy:  79.7%, Loss: 0.3608\n",
      "Optimization Iteration:  24513, Training Accuracy:  76.6%, Loss: 0.3654\n",
      "Optimization Iteration:  24577, Training Accuracy:  71.9%, Loss: 0.5044\n",
      "Optimization Iteration:  24641, Training Accuracy:  78.1%, Loss: 0.4114\n",
      "Optimization Iteration:  24705, Training Accuracy:  84.4%, Loss: 0.3768\n",
      "Optimization Iteration:  24769, Training Accuracy:  73.4%, Loss: 0.4200\n",
      "Optimization Iteration:  24833, Training Accuracy:  78.1%, Loss: 0.3390\n",
      "Optimization Iteration:  24897, Training Accuracy:  78.1%, Loss: 0.4111\n",
      "Optimization Iteration:  24961, Training Accuracy:  84.4%, Loss: 0.2952\n",
      "Optimization Iteration:  25025, Training Accuracy:  71.9%, Loss: 0.4190\n",
      "Optimization Iteration:  25089, Training Accuracy:  75.0%, Loss: 0.3910\n",
      "Optimization Iteration:  25153, Training Accuracy:  68.8%, Loss: 0.4490\n",
      "Optimization Iteration:  25217, Training Accuracy:  71.9%, Loss: 0.5273\n",
      "Optimization Iteration:  25281, Training Accuracy:  82.8%, Loss: 0.4484\n",
      "Optimization Iteration:  25345, Training Accuracy:  84.4%, Loss: 0.4120\n",
      "Optimization Iteration:  25409, Training Accuracy:  70.3%, Loss: 0.4064\n",
      "Optimization Iteration:  25473, Training Accuracy:  71.9%, Loss: 0.4376\n",
      "Optimization Iteration:  25537, Training Accuracy:  76.6%, Loss: 0.3885\n",
      "Optimization Iteration:  25601, Training Accuracy:  67.2%, Loss: 0.4463\n",
      "Optimization Iteration:  25665, Training Accuracy:  78.1%, Loss: 0.4258\n",
      "Optimization Iteration:  25729, Training Accuracy:  89.1%, Loss: 0.2805\n",
      "Optimization Iteration:  25793, Training Accuracy:  73.4%, Loss: 0.3492\n",
      "Optimization Iteration:  25857, Training Accuracy:  70.3%, Loss: 0.4669\n",
      "Optimization Iteration:  25921, Training Accuracy:  79.7%, Loss: 0.4046\n",
      "Optimization Iteration:  25985, Training Accuracy:  76.6%, Loss: 0.3899\n",
      "Optimization Iteration:  26049, Training Accuracy:  78.1%, Loss: 0.3746\n",
      "Optimization Iteration:  26113, Training Accuracy:  75.0%, Loss: 0.3856\n",
      "Optimization Iteration:  26177, Training Accuracy:  76.6%, Loss: 0.3927\n",
      "Optimization Iteration:  26241, Training Accuracy:  76.6%, Loss: 0.3690\n",
      "Optimization Iteration:  26305, Training Accuracy:  71.9%, Loss: 0.4276\n",
      "Optimization Iteration:  26369, Training Accuracy:  82.8%, Loss: 0.3266\n",
      "Optimization Iteration:  26433, Training Accuracy:  76.6%, Loss: 0.4175\n",
      "Optimization Iteration:  26497, Training Accuracy:  73.4%, Loss: 0.4092\n",
      "Optimization Iteration:  26561, Training Accuracy:  81.2%, Loss: 0.3294\n",
      "Optimization Iteration:  26625, Training Accuracy:  76.6%, Loss: 0.4059\n",
      "Optimization Iteration:  26689, Training Accuracy:  85.9%, Loss: 0.3876\n",
      "Optimization Iteration:  26753, Training Accuracy:  75.0%, Loss: 0.4107\n",
      "Optimization Iteration:  26817, Training Accuracy:  73.4%, Loss: 0.4003\n",
      "Optimization Iteration:  26881, Training Accuracy:  81.2%, Loss: 0.3484\n",
      "Optimization Iteration:  26945, Training Accuracy:  68.8%, Loss: 0.4133\n",
      "Optimization Iteration:  27009, Training Accuracy:  75.0%, Loss: 0.3564\n",
      "Optimization Iteration:  27073, Training Accuracy:  78.1%, Loss: 0.3809\n",
      "Optimization Iteration:  27137, Training Accuracy:  78.1%, Loss: 0.4370\n",
      "Optimization Iteration:  27201, Training Accuracy:  81.2%, Loss: 0.3093\n",
      "Optimization Iteration:  27265, Training Accuracy:  73.4%, Loss: 0.4012\n",
      "Optimization Iteration:  27329, Training Accuracy:  78.1%, Loss: 0.3600\n",
      "Optimization Iteration:  27393, Training Accuracy:  67.2%, Loss: 0.4071\n",
      "Optimization Iteration:  27457, Training Accuracy:  71.9%, Loss: 0.4048\n",
      "Optimization Iteration:  27521, Training Accuracy:  81.2%, Loss: 0.3824\n",
      "Optimization Iteration:  27585, Training Accuracy:  75.0%, Loss: 0.3984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  27649, Training Accuracy:  81.2%, Loss: 0.3422\n",
      "Optimization Iteration:  27713, Training Accuracy:  71.9%, Loss: 0.4162\n",
      "Optimization Iteration:  27777, Training Accuracy:  79.7%, Loss: 0.3782\n",
      "Optimization Iteration:  27841, Training Accuracy:  78.1%, Loss: 0.4060\n",
      "Optimization Iteration:  27905, Training Accuracy:  70.3%, Loss: 0.3860\n",
      "Optimization Iteration:  27969, Training Accuracy:  70.3%, Loss: 0.4074\n",
      "Optimization Iteration:  28033, Training Accuracy:  84.4%, Loss: 0.3714\n",
      "Optimization Iteration:  28097, Training Accuracy:  76.6%, Loss: 0.3753\n",
      "Optimization Iteration:  28161, Training Accuracy:  82.8%, Loss: 0.3384\n",
      "Optimization Iteration:  28225, Training Accuracy:  82.8%, Loss: 0.3296\n",
      "Optimization Iteration:  28289, Training Accuracy:  67.2%, Loss: 0.4101\n",
      "Optimization Iteration:  28353, Training Accuracy:  81.2%, Loss: 0.4239\n",
      "Optimization Iteration:  28417, Training Accuracy:  76.6%, Loss: 0.4081\n",
      "Optimization Iteration:  28481, Training Accuracy:  71.9%, Loss: 0.3798\n",
      "Optimization Iteration:  28545, Training Accuracy:  85.9%, Loss: 0.2983\n",
      "Optimization Iteration:  28609, Training Accuracy:  84.4%, Loss: 0.2768\n",
      "Optimization Iteration:  28673, Training Accuracy:  75.0%, Loss: 0.4262\n",
      "Optimization Iteration:  28737, Training Accuracy:  79.7%, Loss: 0.3218\n",
      "Optimization Iteration:  28801, Training Accuracy:  81.2%, Loss: 0.3796\n",
      "Optimization Iteration:  28865, Training Accuracy:  79.7%, Loss: 0.3426\n",
      "Optimization Iteration:  28929, Training Accuracy:  84.4%, Loss: 0.3141\n",
      "Optimization Iteration:  28993, Training Accuracy:  67.2%, Loss: 0.4693\n",
      "Optimization Iteration:  29057, Training Accuracy:  65.6%, Loss: 0.4213\n",
      "Optimization Iteration:  29121, Training Accuracy:  68.8%, Loss: 0.4812\n",
      "Optimization Iteration:  29185, Training Accuracy:  76.6%, Loss: 0.3713\n",
      "Optimization Iteration:  29249, Training Accuracy:  78.1%, Loss: 0.3997\n",
      "Optimization Iteration:  29313, Training Accuracy:  73.4%, Loss: 0.3925\n",
      "Optimization Iteration:  29377, Training Accuracy:  85.9%, Loss: 0.3276\n",
      "Optimization Iteration:  29441, Training Accuracy:  82.8%, Loss: 0.4086\n",
      "Optimization Iteration:  29505, Training Accuracy:  78.1%, Loss: 0.5076\n",
      "Optimization Iteration:  29569, Training Accuracy:  82.8%, Loss: 0.4093\n",
      "Optimization Iteration:  29633, Training Accuracy:  68.8%, Loss: 0.4441\n",
      "Optimization Iteration:  29697, Training Accuracy:  78.1%, Loss: 0.3625\n",
      "Optimization Iteration:  29761, Training Accuracy:  79.7%, Loss: 0.3640\n",
      "Optimization Iteration:  29825, Training Accuracy:  78.1%, Loss: 0.4080\n",
      "Optimization Iteration:  29889, Training Accuracy:  71.9%, Loss: 0.5325\n",
      "Optimization Iteration:  29953, Training Accuracy:  71.9%, Loss: 0.4169\n",
      "Optimization Iteration:  30017, Training Accuracy:  85.9%, Loss: 0.2980\n",
      "Optimization Iteration:  30081, Training Accuracy:  85.9%, Loss: 0.3361\n",
      "Optimization Iteration:  30145, Training Accuracy:  87.5%, Loss: 0.3284\n",
      "Optimization Iteration:  30209, Training Accuracy:  73.4%, Loss: 0.4297\n",
      "Optimization Iteration:  30273, Training Accuracy:  81.2%, Loss: 0.3333\n",
      "Optimization Iteration:  30337, Training Accuracy:  78.1%, Loss: 0.3485\n",
      "Optimization Iteration:  30401, Training Accuracy:  79.7%, Loss: 0.3792\n",
      "Optimization Iteration:  30465, Training Accuracy:  70.3%, Loss: 0.4432\n",
      "Optimization Iteration:  30529, Training Accuracy:  78.1%, Loss: 0.3436\n",
      "Optimization Iteration:  30593, Training Accuracy:  76.6%, Loss: 0.4140\n",
      "Optimization Iteration:  30657, Training Accuracy:  75.0%, Loss: 0.3897\n",
      "Optimization Iteration:  30721, Training Accuracy:  76.6%, Loss: 0.3690\n",
      "Optimization Iteration:  30785, Training Accuracy:  73.4%, Loss: 0.3887\n",
      "Optimization Iteration:  30849, Training Accuracy:  73.4%, Loss: 0.4042\n",
      "Optimization Iteration:  30913, Training Accuracy:  78.1%, Loss: 0.3172\n",
      "Optimization Iteration:  30977, Training Accuracy:  73.4%, Loss: 0.4262\n",
      "Optimization Iteration:  31041, Training Accuracy:  81.2%, Loss: 0.3346\n",
      "Optimization Iteration:  31105, Training Accuracy:  75.0%, Loss: 0.4267\n",
      "Optimization Iteration:  31169, Training Accuracy:  79.7%, Loss: 0.3026\n",
      "Optimization Iteration:  31233, Training Accuracy:  67.2%, Loss: 0.4283\n",
      "Optimization Iteration:  31297, Training Accuracy:  78.1%, Loss: 0.3264\n",
      "Optimization Iteration:  31361, Training Accuracy:  75.0%, Loss: 0.3885\n",
      "Optimization Iteration:  31425, Training Accuracy:  76.6%, Loss: 0.3007\n",
      "Optimization Iteration:  31489, Training Accuracy:  89.1%, Loss: 0.3473\n",
      "Optimization Iteration:  31553, Training Accuracy:  70.3%, Loss: 0.3588\n",
      "Optimization Iteration:  31617, Training Accuracy:  78.1%, Loss: 0.2842\n",
      "Optimization Iteration:  31681, Training Accuracy:  84.4%, Loss: 0.3272\n",
      "Optimization Iteration:  31745, Training Accuracy:  70.3%, Loss: 0.3763\n",
      "Optimization Iteration:  31809, Training Accuracy:  70.3%, Loss: 0.4966\n",
      "Optimization Iteration:  31873, Training Accuracy:  82.8%, Loss: 0.3111\n",
      "Optimization Iteration:  31937, Training Accuracy:  68.8%, Loss: 0.4238\n",
      "Optimization Iteration:  32001, Training Accuracy:  78.1%, Loss: 0.4548\n",
      "Optimization Iteration:  32065, Training Accuracy:  70.3%, Loss: 0.3947\n",
      "Optimization Iteration:  32129, Training Accuracy:  70.3%, Loss: 0.4264\n",
      "Optimization Iteration:  32193, Training Accuracy:  65.6%, Loss: 0.4872\n",
      "Optimization Iteration:  32257, Training Accuracy:  78.1%, Loss: 0.4336\n",
      "Optimization Iteration:  32321, Training Accuracy:  75.0%, Loss: 0.3712\n",
      "Optimization Iteration:  32385, Training Accuracy:  73.4%, Loss: 0.4087\n",
      "Optimization Iteration:  32449, Training Accuracy:  70.3%, Loss: 0.4458\n",
      "Optimization Iteration:  32513, Training Accuracy:  73.4%, Loss: 0.3225\n",
      "Optimization Iteration:  32577, Training Accuracy:  81.2%, Loss: 0.3346\n",
      "Optimization Iteration:  32641, Training Accuracy:  78.1%, Loss: 0.4894\n",
      "Optimization Iteration:  32705, Training Accuracy:  79.7%, Loss: 0.3909\n",
      "Optimization Iteration:  32769, Training Accuracy:  70.3%, Loss: 0.4269\n",
      "Optimization Iteration:  32833, Training Accuracy:  73.4%, Loss: 0.3862\n",
      "Optimization Iteration:  32897, Training Accuracy:  73.4%, Loss: 0.3811\n",
      "Optimization Iteration:  32961, Training Accuracy:  79.7%, Loss: 0.4145\n",
      "Optimization Iteration:  33025, Training Accuracy:  75.0%, Loss: 0.4250\n",
      "Optimization Iteration:  33089, Training Accuracy:  75.0%, Loss: 0.4229\n",
      "Optimization Iteration:  33153, Training Accuracy:  78.1%, Loss: 0.3583\n",
      "Optimization Iteration:  33217, Training Accuracy:  75.0%, Loss: 0.3195\n",
      "Optimization Iteration:  33281, Training Accuracy:  62.5%, Loss: 0.5350\n",
      "Optimization Iteration:  33345, Training Accuracy:  78.1%, Loss: 0.4048\n",
      "Optimization Iteration:  33409, Training Accuracy:  71.9%, Loss: 0.4824\n",
      "Optimization Iteration:  33473, Training Accuracy:  73.4%, Loss: 0.4050\n",
      "Optimization Iteration:  33537, Training Accuracy:  68.8%, Loss: 0.4193\n",
      "Optimization Iteration:  33601, Training Accuracy:  84.4%, Loss: 0.3973\n",
      "Optimization Iteration:  33665, Training Accuracy:  79.7%, Loss: 0.3814\n",
      "Optimization Iteration:  33729, Training Accuracy:  67.2%, Loss: 0.4704\n",
      "Optimization Iteration:  33793, Training Accuracy:  65.6%, Loss: 0.4845\n",
      "Optimization Iteration:  33857, Training Accuracy:  82.8%, Loss: 0.3264\n",
      "Optimization Iteration:  33921, Training Accuracy:  85.9%, Loss: 0.3891\n",
      "Optimization Iteration:  33985, Training Accuracy:  82.8%, Loss: 0.3284\n",
      "Optimization Iteration:  34049, Training Accuracy:  71.9%, Loss: 0.4283\n",
      "Optimization Iteration:  34113, Training Accuracy:  82.8%, Loss: 0.3241\n",
      "Optimization Iteration:  34177, Training Accuracy:  68.8%, Loss: 0.4347\n",
      "Optimization Iteration:  34241, Training Accuracy:  75.0%, Loss: 0.3719\n",
      "Optimization Iteration:  34305, Training Accuracy:  76.6%, Loss: 0.3597\n",
      "Optimization Iteration:  34369, Training Accuracy:  84.4%, Loss: 0.2750\n",
      "Optimization Iteration:  34433, Training Accuracy:  70.3%, Loss: 0.4717\n",
      "Optimization Iteration:  34497, Training Accuracy:  89.1%, Loss: 0.3043\n",
      "Optimization Iteration:  34561, Training Accuracy:  75.0%, Loss: 0.3679\n",
      "Optimization Iteration:  34625, Training Accuracy:  65.6%, Loss: 0.4504\n",
      "Optimization Iteration:  34689, Training Accuracy:  76.6%, Loss: 0.3664\n",
      "Optimization Iteration:  34753, Training Accuracy:  75.0%, Loss: 0.4490\n",
      "Optimization Iteration:  34817, Training Accuracy:  82.8%, Loss: 0.3205\n",
      "Optimization Iteration:  34881, Training Accuracy:  76.6%, Loss: 0.3383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  34945, Training Accuracy:  84.4%, Loss: 0.3832\n",
      "Optimization Iteration:  35009, Training Accuracy:  85.9%, Loss: 0.3230\n",
      "Optimization Iteration:  35073, Training Accuracy:  78.1%, Loss: 0.3517\n",
      "Optimization Iteration:  35137, Training Accuracy:  76.6%, Loss: 0.3573\n",
      "Optimization Iteration:  35201, Training Accuracy:  65.6%, Loss: 0.4022\n",
      "Optimization Iteration:  35265, Training Accuracy:  78.1%, Loss: 0.3585\n",
      "Optimization Iteration:  35329, Training Accuracy:  75.0%, Loss: 0.4762\n",
      "Optimization Iteration:  35393, Training Accuracy:  78.1%, Loss: 0.3681\n",
      "Optimization Iteration:  35457, Training Accuracy:  76.6%, Loss: 0.4683\n",
      "Optimization Iteration:  35521, Training Accuracy:  75.0%, Loss: 0.3591\n",
      "Optimization Iteration:  35585, Training Accuracy:  82.8%, Loss: 0.3458\n",
      "Optimization Iteration:  35649, Training Accuracy:  73.4%, Loss: 0.4519\n",
      "Optimization Iteration:  35713, Training Accuracy:  78.1%, Loss: 0.4179\n",
      "Optimization Iteration:  35777, Training Accuracy:  85.9%, Loss: 0.2861\n",
      "Optimization Iteration:  35841, Training Accuracy:  82.8%, Loss: 0.3728\n",
      "Optimization Iteration:  35905, Training Accuracy:  84.4%, Loss: 0.2949\n",
      "Optimization Iteration:  35969, Training Accuracy:  75.0%, Loss: 0.4350\n",
      "Optimization Iteration:  36033, Training Accuracy:  85.9%, Loss: 0.3205\n",
      "Optimization Iteration:  36097, Training Accuracy:  68.8%, Loss: 0.4638\n",
      "Optimization Iteration:  36161, Training Accuracy:  71.9%, Loss: 0.4475\n",
      "Optimization Iteration:  36225, Training Accuracy:  81.2%, Loss: 0.3169\n",
      "Optimization Iteration:  36289, Training Accuracy:  82.8%, Loss: 0.3406\n",
      "Optimization Iteration:  36353, Training Accuracy:  71.9%, Loss: 0.3809\n",
      "Optimization Iteration:  36417, Training Accuracy:  78.1%, Loss: 0.3551\n",
      "Optimization Iteration:  36481, Training Accuracy:  79.7%, Loss: 0.3406\n",
      "Optimization Iteration:  36545, Training Accuracy:  82.8%, Loss: 0.3575\n",
      "Optimization Iteration:  36609, Training Accuracy:  78.1%, Loss: 0.3580\n",
      "Optimization Iteration:  36673, Training Accuracy:  73.4%, Loss: 0.4013\n",
      "Optimization Iteration:  36737, Training Accuracy:  81.2%, Loss: 0.3500\n",
      "Optimization Iteration:  36801, Training Accuracy:  79.7%, Loss: 0.3708\n",
      "Optimization Iteration:  36865, Training Accuracy:  68.8%, Loss: 0.4033\n",
      "Optimization Iteration:  36929, Training Accuracy:  76.6%, Loss: 0.3874\n",
      "Optimization Iteration:  36993, Training Accuracy:  81.2%, Loss: 0.3499\n",
      "Optimization Iteration:  37057, Training Accuracy:  78.1%, Loss: 0.3399\n",
      "Optimization Iteration:  37121, Training Accuracy:  79.7%, Loss: 0.3329\n",
      "Optimization Iteration:  37185, Training Accuracy:  75.0%, Loss: 0.3754\n",
      "Optimization Iteration:  37249, Training Accuracy:  76.6%, Loss: 0.4400\n",
      "Optimization Iteration:  37313, Training Accuracy:  81.2%, Loss: 0.3521\n",
      "Optimization Iteration:  37377, Training Accuracy:  73.4%, Loss: 0.4638\n",
      "Optimization Iteration:  37441, Training Accuracy:  70.3%, Loss: 0.3458\n",
      "Optimization Iteration:  37505, Training Accuracy:  85.9%, Loss: 0.3581\n",
      "Optimization Iteration:  37569, Training Accuracy:  73.4%, Loss: 0.4496\n",
      "Optimization Iteration:  37633, Training Accuracy:  75.0%, Loss: 0.3689\n",
      "Optimization Iteration:  37697, Training Accuracy:  70.3%, Loss: 0.4207\n",
      "Optimization Iteration:  37761, Training Accuracy:  81.2%, Loss: 0.3823\n",
      "Optimization Iteration:  37825, Training Accuracy:  75.0%, Loss: 0.4086\n",
      "Optimization Iteration:  37889, Training Accuracy:  78.1%, Loss: 0.4895\n",
      "Optimization Iteration:  37953, Training Accuracy:  71.9%, Loss: 0.3787\n",
      "Optimization Iteration:  38017, Training Accuracy:  76.6%, Loss: 0.4067\n",
      "Optimization Iteration:  38081, Training Accuracy:  79.7%, Loss: 0.3393\n",
      "Optimization Iteration:  38145, Training Accuracy:  71.9%, Loss: 0.3847\n",
      "Optimization Iteration:  38209, Training Accuracy:  79.7%, Loss: 0.3569\n",
      "Optimization Iteration:  38273, Training Accuracy:  71.9%, Loss: 0.3696\n",
      "Optimization Iteration:  38337, Training Accuracy:  82.8%, Loss: 0.2917\n",
      "Optimization Iteration:  38401, Training Accuracy:  75.0%, Loss: 0.3342\n",
      "Optimization Iteration:  38465, Training Accuracy:  68.8%, Loss: 0.4330\n",
      "Optimization Iteration:  38529, Training Accuracy:  78.1%, Loss: 0.4033\n",
      "Optimization Iteration:  38593, Training Accuracy:  71.9%, Loss: 0.4930\n",
      "Optimization Iteration:  38657, Training Accuracy:  73.4%, Loss: 0.4513\n",
      "Optimization Iteration:  38721, Training Accuracy:  82.8%, Loss: 0.3795\n",
      "Optimization Iteration:  38785, Training Accuracy:  76.6%, Loss: 0.4598\n",
      "Optimization Iteration:  38849, Training Accuracy:  78.1%, Loss: 0.3266\n",
      "Optimization Iteration:  38913, Training Accuracy:  79.7%, Loss: 0.4003\n",
      "Optimization Iteration:  38977, Training Accuracy:  65.6%, Loss: 0.4941\n",
      "Optimization Iteration:  39041, Training Accuracy:  76.6%, Loss: 0.4043\n",
      "Optimization Iteration:  39105, Training Accuracy:  81.2%, Loss: 0.4352\n",
      "Optimization Iteration:  39169, Training Accuracy:  67.2%, Loss: 0.4945\n",
      "Optimization Iteration:  39233, Training Accuracy:  71.9%, Loss: 0.4565\n",
      "Optimization Iteration:  39297, Training Accuracy:  71.9%, Loss: 0.3592\n",
      "Optimization Iteration:  39361, Training Accuracy:  75.0%, Loss: 0.3566\n",
      "Optimization Iteration:  39425, Training Accuracy:  73.4%, Loss: 0.4217\n",
      "Optimization Iteration:  39489, Training Accuracy:  84.4%, Loss: 0.3434\n",
      "Optimization Iteration:  39553, Training Accuracy:  75.0%, Loss: 0.4096\n",
      "Optimization Iteration:  39617, Training Accuracy:  73.4%, Loss: 0.5048\n",
      "Optimization Iteration:  39681, Training Accuracy:  64.1%, Loss: 0.3954\n",
      "Optimization Iteration:  39745, Training Accuracy:  78.1%, Loss: 0.4064\n",
      "Optimization Iteration:  39809, Training Accuracy:  73.4%, Loss: 0.4405\n",
      "Optimization Iteration:  39873, Training Accuracy:  73.4%, Loss: 0.4600\n",
      "Optimization Iteration:  39937, Training Accuracy:  70.3%, Loss: 0.4407\n",
      "Optimization Iteration:  40001, Training Accuracy:  75.0%, Loss: 0.4033\n",
      "Optimization Iteration:  40065, Training Accuracy:  75.0%, Loss: 0.3461\n",
      "Optimization Iteration:  40129, Training Accuracy:  78.1%, Loss: 0.4066\n",
      "Optimization Iteration:  40193, Training Accuracy:  78.1%, Loss: 0.3433\n",
      "Optimization Iteration:  40257, Training Accuracy:  75.0%, Loss: 0.3671\n",
      "Optimization Iteration:  40321, Training Accuracy:  70.3%, Loss: 0.4372\n",
      "Optimization Iteration:  40385, Training Accuracy:  76.6%, Loss: 0.3656\n",
      "Optimization Iteration:  40449, Training Accuracy:  84.4%, Loss: 0.3684\n",
      "Optimization Iteration:  40513, Training Accuracy:  76.6%, Loss: 0.3998\n",
      "Optimization Iteration:  40577, Training Accuracy:  81.2%, Loss: 0.3633\n",
      "Optimization Iteration:  40641, Training Accuracy:  71.9%, Loss: 0.3552\n",
      "Optimization Iteration:  40705, Training Accuracy:  78.1%, Loss: 0.4118\n",
      "Optimization Iteration:  40769, Training Accuracy:  84.4%, Loss: 0.2879\n",
      "Optimization Iteration:  40833, Training Accuracy:  79.7%, Loss: 0.3412\n",
      "Optimization Iteration:  40897, Training Accuracy:  79.7%, Loss: 0.3269\n",
      "Optimization Iteration:  40961, Training Accuracy:  85.9%, Loss: 0.3308\n",
      "Optimization Iteration:  41025, Training Accuracy:  79.7%, Loss: 0.3798\n",
      "Optimization Iteration:  41089, Training Accuracy:  81.2%, Loss: 0.3956\n",
      "Optimization Iteration:  41153, Training Accuracy:  75.0%, Loss: 0.4057\n",
      "Optimization Iteration:  41217, Training Accuracy:  79.7%, Loss: 0.3524\n",
      "Optimization Iteration:  41281, Training Accuracy:  71.9%, Loss: 0.4579\n",
      "Optimization Iteration:  41345, Training Accuracy:  73.4%, Loss: 0.4004\n",
      "Optimization Iteration:  41409, Training Accuracy:  75.0%, Loss: 0.3598\n",
      "Optimization Iteration:  41473, Training Accuracy:  60.9%, Loss: 0.4797\n",
      "Optimization Iteration:  41537, Training Accuracy:  73.4%, Loss: 0.4214\n",
      "Optimization Iteration:  41601, Training Accuracy:  81.2%, Loss: 0.3505\n",
      "Optimization Iteration:  41665, Training Accuracy:  71.9%, Loss: 0.3821\n",
      "Optimization Iteration:  41729, Training Accuracy:  76.6%, Loss: 0.3111\n",
      "Optimization Iteration:  41793, Training Accuracy:  79.7%, Loss: 0.4334\n",
      "Optimization Iteration:  41857, Training Accuracy:  73.4%, Loss: 0.3888\n",
      "Optimization Iteration:  41921, Training Accuracy:  82.8%, Loss: 0.3848\n",
      "Optimization Iteration:  41985, Training Accuracy:  71.9%, Loss: 0.4559\n",
      "Optimization Iteration:  42049, Training Accuracy:  78.1%, Loss: 0.4541\n",
      "Optimization Iteration:  42113, Training Accuracy:  79.7%, Loss: 0.3870\n",
      "Optimization Iteration:  42177, Training Accuracy:  70.3%, Loss: 0.4074\n",
      "Optimization Iteration:  42241, Training Accuracy:  68.8%, Loss: 0.3997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  42305, Training Accuracy:  73.4%, Loss: 0.5313\n",
      "Optimization Iteration:  42369, Training Accuracy:  70.3%, Loss: 0.4218\n",
      "Optimization Iteration:  42433, Training Accuracy:  75.0%, Loss: 0.4291\n",
      "Optimization Iteration:  42497, Training Accuracy:  76.6%, Loss: 0.3437\n",
      "Optimization Iteration:  42561, Training Accuracy:  82.8%, Loss: 0.3816\n",
      "Optimization Iteration:  42625, Training Accuracy:  81.2%, Loss: 0.3350\n",
      "Optimization Iteration:  42689, Training Accuracy:  73.4%, Loss: 0.3767\n",
      "Optimization Iteration:  42753, Training Accuracy:  79.7%, Loss: 0.4104\n",
      "Optimization Iteration:  42817, Training Accuracy:  85.9%, Loss: 0.2575\n",
      "Optimization Iteration:  42881, Training Accuracy:  79.7%, Loss: 0.4145\n",
      "Optimization Iteration:  42945, Training Accuracy:  73.4%, Loss: 0.3714\n",
      "Optimization Iteration:  43009, Training Accuracy:  82.8%, Loss: 0.4111\n",
      "Optimization Iteration:  43073, Training Accuracy:  84.4%, Loss: 0.3751\n",
      "Optimization Iteration:  43137, Training Accuracy:  81.2%, Loss: 0.3576\n",
      "Optimization Iteration:  43201, Training Accuracy:  82.8%, Loss: 0.3262\n",
      "Optimization Iteration:  43265, Training Accuracy:  82.8%, Loss: 0.3353\n",
      "Optimization Iteration:  43329, Training Accuracy:  79.7%, Loss: 0.4435\n",
      "Optimization Iteration:  43393, Training Accuracy:  71.9%, Loss: 0.3636\n",
      "Optimization Iteration:  43457, Training Accuracy:  78.1%, Loss: 0.4103\n",
      "Optimization Iteration:  43521, Training Accuracy:  81.2%, Loss: 0.4009\n",
      "Optimization Iteration:  43585, Training Accuracy:  82.8%, Loss: 0.3173\n",
      "Optimization Iteration:  43649, Training Accuracy:  71.9%, Loss: 0.4064\n",
      "Optimization Iteration:  43713, Training Accuracy:  78.1%, Loss: 0.3579\n",
      "Optimization Iteration:  43777, Training Accuracy:  79.7%, Loss: 0.3477\n",
      "Optimization Iteration:  43841, Training Accuracy:  68.8%, Loss: 0.4272\n",
      "Optimization Iteration:  43905, Training Accuracy:  75.0%, Loss: 0.3767\n",
      "Optimization Iteration:  43969, Training Accuracy:  81.2%, Loss: 0.3187\n",
      "Optimization Iteration:  44033, Training Accuracy:  73.4%, Loss: 0.3282\n",
      "Optimization Iteration:  44097, Training Accuracy:  75.0%, Loss: 0.3430\n",
      "Optimization Iteration:  44161, Training Accuracy:  82.8%, Loss: 0.2840\n",
      "Optimization Iteration:  44225, Training Accuracy:  78.1%, Loss: 0.3748\n",
      "Optimization Iteration:  44289, Training Accuracy:  78.1%, Loss: 0.4006\n",
      "Optimization Iteration:  44353, Training Accuracy:  67.2%, Loss: 0.4276\n",
      "Optimization Iteration:  44417, Training Accuracy:  79.7%, Loss: 0.3354\n",
      "Optimization Iteration:  44481, Training Accuracy:  75.0%, Loss: 0.3611\n",
      "Optimization Iteration:  44545, Training Accuracy:  78.1%, Loss: 0.3623\n",
      "Optimization Iteration:  44609, Training Accuracy:  75.0%, Loss: 0.3605\n",
      "Optimization Iteration:  44673, Training Accuracy:  76.6%, Loss: 0.6299\n",
      "Optimization Iteration:  44737, Training Accuracy:  78.1%, Loss: 0.3768\n",
      "Optimization Iteration:  44801, Training Accuracy:  75.0%, Loss: 0.3917\n",
      "Optimization Iteration:  44865, Training Accuracy:  78.1%, Loss: 0.4383\n",
      "Optimization Iteration:  44929, Training Accuracy:  85.9%, Loss: 0.3456\n",
      "Optimization Iteration:  44993, Training Accuracy:  71.9%, Loss: 0.6898\n",
      "Optimization Iteration:  45057, Training Accuracy:  71.9%, Loss: 0.4229\n",
      "Optimization Iteration:  45121, Training Accuracy:  75.0%, Loss: 0.4206\n",
      "Optimization Iteration:  45185, Training Accuracy:  81.2%, Loss: 0.3152\n",
      "Optimization Iteration:  45249, Training Accuracy:  79.7%, Loss: 0.3964\n",
      "Optimization Iteration:  45313, Training Accuracy:  79.7%, Loss: 0.4080\n",
      "Optimization Iteration:  45377, Training Accuracy:  78.1%, Loss: 0.4067\n",
      "Optimization Iteration:  45441, Training Accuracy:  81.2%, Loss: 0.3331\n",
      "Optimization Iteration:  45505, Training Accuracy:  75.0%, Loss: 0.3875\n",
      "Optimization Iteration:  45569, Training Accuracy:  73.4%, Loss: 0.4369\n",
      "Optimization Iteration:  45633, Training Accuracy:  79.7%, Loss: 0.4338\n",
      "Optimization Iteration:  45697, Training Accuracy:  73.4%, Loss: 0.4305\n",
      "Optimization Iteration:  45761, Training Accuracy:  87.5%, Loss: 0.3372\n",
      "Optimization Iteration:  45825, Training Accuracy:  78.1%, Loss: 0.3008\n",
      "Optimization Iteration:  45889, Training Accuracy:  76.6%, Loss: 0.3691\n",
      "Optimization Iteration:  45953, Training Accuracy:  73.4%, Loss: 0.4068\n",
      "Optimization Iteration:  46017, Training Accuracy:  70.3%, Loss: 0.4366\n",
      "Optimization Iteration:  46081, Training Accuracy:  76.6%, Loss: 0.3210\n",
      "Optimization Iteration:  46145, Training Accuracy:  70.3%, Loss: 0.4454\n",
      "Optimization Iteration:  46209, Training Accuracy:  71.9%, Loss: 0.4344\n",
      "Optimization Iteration:  46273, Training Accuracy:  73.4%, Loss: 0.4340\n",
      "Optimization Iteration:  46337, Training Accuracy:  71.9%, Loss: 0.4715\n",
      "Optimization Iteration:  46401, Training Accuracy:  79.7%, Loss: 0.3742\n",
      "Optimization Iteration:  46465, Training Accuracy:  81.2%, Loss: 0.4238\n",
      "Optimization Iteration:  46529, Training Accuracy:  78.1%, Loss: 0.4331\n",
      "Optimization Iteration:  46593, Training Accuracy:  82.8%, Loss: 0.3728\n",
      "Optimization Iteration:  46657, Training Accuracy:  75.0%, Loss: 0.3813\n",
      "Optimization Iteration:  46721, Training Accuracy:  67.2%, Loss: 0.4593\n",
      "Optimization Iteration:  46785, Training Accuracy:  64.1%, Loss: 0.4975\n",
      "Optimization Iteration:  46849, Training Accuracy:  70.3%, Loss: 0.4033\n",
      "Optimization Iteration:  46913, Training Accuracy:  75.0%, Loss: 0.3631\n",
      "Optimization Iteration:  46977, Training Accuracy:  82.8%, Loss: 0.4125\n",
      "Optimization Iteration:  47041, Training Accuracy:  78.1%, Loss: 0.3626\n",
      "Optimization Iteration:  47105, Training Accuracy:  75.0%, Loss: 0.4434\n",
      "Optimization Iteration:  47169, Training Accuracy:  65.6%, Loss: 0.4108\n",
      "Optimization Iteration:  47233, Training Accuracy:  73.4%, Loss: 0.4051\n",
      "Optimization Iteration:  47297, Training Accuracy:  73.4%, Loss: 0.3770\n",
      "Optimization Iteration:  47361, Training Accuracy:  85.9%, Loss: 0.2826\n",
      "Optimization Iteration:  47425, Training Accuracy:  82.8%, Loss: 0.3619\n",
      "Optimization Iteration:  47489, Training Accuracy:  71.9%, Loss: 0.4251\n",
      "Optimization Iteration:  47553, Training Accuracy:  78.1%, Loss: 0.4163\n",
      "Optimization Iteration:  47617, Training Accuracy:  76.6%, Loss: 0.4276\n",
      "Optimization Iteration:  47681, Training Accuracy:  84.4%, Loss: 0.3450\n",
      "Optimization Iteration:  47745, Training Accuracy:  68.8%, Loss: 0.4613\n",
      "Optimization Iteration:  47809, Training Accuracy:  81.2%, Loss: 0.3343\n",
      "Optimization Iteration:  47873, Training Accuracy:  82.8%, Loss: 0.2813\n",
      "Optimization Iteration:  47937, Training Accuracy:  75.0%, Loss: 0.4167\n",
      "Optimization Iteration:  48001, Training Accuracy:  73.4%, Loss: 0.4263\n",
      "Optimization Iteration:  48065, Training Accuracy:  73.4%, Loss: 0.3891\n",
      "Optimization Iteration:  48129, Training Accuracy:  85.9%, Loss: 0.4154\n",
      "Optimization Iteration:  48193, Training Accuracy:  70.3%, Loss: 0.4691\n",
      "Optimization Iteration:  48257, Training Accuracy:  82.8%, Loss: 0.3481\n",
      "Optimization Iteration:  48321, Training Accuracy:  73.4%, Loss: 0.3584\n",
      "Optimization Iteration:  48385, Training Accuracy:  71.9%, Loss: 0.3758\n",
      "Optimization Iteration:  48449, Training Accuracy:  76.6%, Loss: 0.4213\n",
      "Optimization Iteration:  48513, Training Accuracy:  87.5%, Loss: 0.3394\n",
      "Optimization Iteration:  48577, Training Accuracy:  73.4%, Loss: 0.4922\n",
      "Optimization Iteration:  48641, Training Accuracy:  84.4%, Loss: 0.3543\n",
      "Optimization Iteration:  48705, Training Accuracy:  79.7%, Loss: 0.3460\n",
      "Optimization Iteration:  48769, Training Accuracy:  81.2%, Loss: 0.3398\n",
      "Optimization Iteration:  48833, Training Accuracy:  79.7%, Loss: 0.3791\n",
      "Optimization Iteration:  48897, Training Accuracy:  85.9%, Loss: 0.3164\n",
      "Optimization Iteration:  48961, Training Accuracy:  78.1%, Loss: 0.4128\n",
      "Optimization Iteration:  49025, Training Accuracy:  76.6%, Loss: 0.4042\n",
      "Optimization Iteration:  49089, Training Accuracy:  76.6%, Loss: 0.3371\n",
      "Optimization Iteration:  49153, Training Accuracy:  82.8%, Loss: 0.3764\n",
      "Optimization Iteration:  49217, Training Accuracy:  70.3%, Loss: 0.4491\n",
      "Optimization Iteration:  49281, Training Accuracy:  70.3%, Loss: 0.4376\n",
      "Optimization Iteration:  49345, Training Accuracy:  75.0%, Loss: 0.3619\n",
      "Optimization Iteration:  49409, Training Accuracy:  78.1%, Loss: 0.3759\n",
      "Optimization Iteration:  49473, Training Accuracy:  78.1%, Loss: 0.3486\n",
      "Optimization Iteration:  49537, Training Accuracy:  76.6%, Loss: 0.3876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  49601, Training Accuracy:  81.2%, Loss: 0.3399\n",
      "Optimization Iteration:  49665, Training Accuracy:  81.2%, Loss: 0.2891\n",
      "Optimization Iteration:  49729, Training Accuracy:  64.1%, Loss: 0.4654\n",
      "Optimization Iteration:  49793, Training Accuracy:  68.8%, Loss: 0.3850\n",
      "Optimization Iteration:  49857, Training Accuracy:  71.9%, Loss: 0.3842\n",
      "Optimization Iteration:  49921, Training Accuracy:  71.9%, Loss: 0.4487\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 27\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  73.4%, Loss: 0.4225\n",
      "Optimization Iteration:    129, Training Accuracy:  70.3%, Loss: 0.4386\n",
      "Optimization Iteration:    193, Training Accuracy:  70.3%, Loss: 0.4648\n",
      "Optimization Iteration:    257, Training Accuracy:  70.3%, Loss: 0.3625\n",
      "Optimization Iteration:    321, Training Accuracy:  79.7%, Loss: 0.4118\n",
      "Optimization Iteration:    385, Training Accuracy:  78.1%, Loss: 0.3701\n",
      "Optimization Iteration:    449, Training Accuracy:  81.2%, Loss: 0.3439\n",
      "Optimization Iteration:    513, Training Accuracy:  76.6%, Loss: 0.4406\n",
      "Optimization Iteration:    577, Training Accuracy:  70.3%, Loss: 0.4902\n",
      "Optimization Iteration:    641, Training Accuracy:  79.7%, Loss: 0.3830\n",
      "Optimization Iteration:    705, Training Accuracy:  75.0%, Loss: 0.4640\n",
      "Optimization Iteration:    769, Training Accuracy:  78.1%, Loss: 0.3785\n",
      "Optimization Iteration:    833, Training Accuracy:  76.6%, Loss: 0.3471\n",
      "Optimization Iteration:    897, Training Accuracy:  75.0%, Loss: 0.3631\n",
      "Optimization Iteration:    961, Training Accuracy:  78.1%, Loss: 0.3492\n",
      "Optimization Iteration:   1025, Training Accuracy:  79.7%, Loss: 0.3558\n",
      "Optimization Iteration:   1089, Training Accuracy:  79.7%, Loss: 0.4056\n",
      "Optimization Iteration:   1153, Training Accuracy:  73.4%, Loss: 0.3811\n",
      "Optimization Iteration:   1217, Training Accuracy:  82.8%, Loss: 0.4031\n",
      "Optimization Iteration:   1281, Training Accuracy:  79.7%, Loss: 0.3884\n",
      "Optimization Iteration:   1345, Training Accuracy:  78.1%, Loss: 0.3540\n",
      "Optimization Iteration:   1409, Training Accuracy:  79.7%, Loss: 0.3983\n",
      "Optimization Iteration:   1473, Training Accuracy:  78.1%, Loss: 0.3260\n",
      "Optimization Iteration:   1537, Training Accuracy:  71.9%, Loss: 0.3647\n",
      "Optimization Iteration:   1601, Training Accuracy:  85.9%, Loss: 0.2845\n",
      "Optimization Iteration:   1665, Training Accuracy:  85.9%, Loss: 0.2906\n",
      "Optimization Iteration:   1729, Training Accuracy:  75.0%, Loss: 0.3911\n",
      "Optimization Iteration:   1793, Training Accuracy:  67.2%, Loss: 0.3729\n",
      "Optimization Iteration:   1857, Training Accuracy:  73.4%, Loss: 0.3674\n",
      "Optimization Iteration:   1921, Training Accuracy:  78.1%, Loss: 0.3974\n",
      "Optimization Iteration:   1985, Training Accuracy:  76.6%, Loss: 0.3449\n",
      "Optimization Iteration:   2049, Training Accuracy:  76.6%, Loss: 0.3258\n",
      "Optimization Iteration:   2113, Training Accuracy:  82.8%, Loss: 0.4123\n",
      "Optimization Iteration:   2177, Training Accuracy:  79.7%, Loss: 0.3604\n",
      "Optimization Iteration:   2241, Training Accuracy:  81.2%, Loss: 0.4005\n",
      "Optimization Iteration:   2305, Training Accuracy:  67.2%, Loss: 0.4105\n",
      "Optimization Iteration:   2369, Training Accuracy:  73.4%, Loss: 0.4089\n",
      "Optimization Iteration:   2433, Training Accuracy:  70.3%, Loss: 0.3985\n",
      "Optimization Iteration:   2497, Training Accuracy:  76.6%, Loss: 0.3402\n",
      "Optimization Iteration:   2561, Training Accuracy:  73.4%, Loss: 0.3411\n",
      "Optimization Iteration:   2625, Training Accuracy:  81.2%, Loss: 0.3884\n",
      "Optimization Iteration:   2689, Training Accuracy:  75.0%, Loss: 0.3911\n",
      "Optimization Iteration:   2753, Training Accuracy:  76.6%, Loss: 0.3852\n",
      "Optimization Iteration:   2817, Training Accuracy:  85.9%, Loss: 0.3515\n",
      "Optimization Iteration:   2881, Training Accuracy:  75.0%, Loss: 0.3803\n",
      "Optimization Iteration:   2945, Training Accuracy:  75.0%, Loss: 0.4550\n",
      "Optimization Iteration:   3009, Training Accuracy:  84.4%, Loss: 0.3305\n",
      "Optimization Iteration:   3073, Training Accuracy:  71.9%, Loss: 0.3685\n",
      "Optimization Iteration:   3137, Training Accuracy:  79.7%, Loss: 0.3653\n",
      "Optimization Iteration:   3201, Training Accuracy:  84.4%, Loss: 0.3600\n",
      "Optimization Iteration:   3265, Training Accuracy:  71.9%, Loss: 0.3551\n",
      "Optimization Iteration:   3329, Training Accuracy:  82.8%, Loss: 0.3857\n",
      "Optimization Iteration:   3393, Training Accuracy:  70.3%, Loss: 0.3838\n",
      "Optimization Iteration:   3457, Training Accuracy:  79.7%, Loss: 0.4031\n",
      "Optimization Iteration:   3521, Training Accuracy:  81.2%, Loss: 0.3972\n",
      "Optimization Iteration:   3585, Training Accuracy:  81.2%, Loss: 0.4319\n",
      "Optimization Iteration:   3649, Training Accuracy:  82.8%, Loss: 0.3771\n",
      "Optimization Iteration:   3713, Training Accuracy:  78.1%, Loss: 0.3689\n",
      "Optimization Iteration:   3777, Training Accuracy:  73.4%, Loss: 0.3967\n",
      "Optimization Iteration:   3841, Training Accuracy:  68.8%, Loss: 0.4438\n",
      "Optimization Iteration:   3905, Training Accuracy:  81.2%, Loss: 0.4230\n",
      "Optimization Iteration:   3969, Training Accuracy:  81.2%, Loss: 0.3541\n",
      "Optimization Iteration:   4033, Training Accuracy:  85.9%, Loss: 0.3396\n",
      "Optimization Iteration:   4097, Training Accuracy:  75.0%, Loss: 0.4326\n",
      "Optimization Iteration:   4161, Training Accuracy:  73.4%, Loss: 0.4621\n",
      "Optimization Iteration:   4225, Training Accuracy:  78.1%, Loss: 0.3549\n",
      "Optimization Iteration:   4289, Training Accuracy:  79.7%, Loss: 0.3597\n",
      "Optimization Iteration:   4353, Training Accuracy:  73.4%, Loss: 0.4074\n",
      "Optimization Iteration:   4417, Training Accuracy:  68.8%, Loss: 0.4238\n",
      "Optimization Iteration:   4481, Training Accuracy:  71.9%, Loss: 0.4631\n",
      "Optimization Iteration:   4545, Training Accuracy:  81.2%, Loss: 0.3719\n",
      "Optimization Iteration:   4609, Training Accuracy:  68.8%, Loss: 0.3893\n",
      "Optimization Iteration:   4673, Training Accuracy:  76.6%, Loss: 0.4182\n",
      "Optimization Iteration:   4737, Training Accuracy:  78.1%, Loss: 0.3964\n",
      "Optimization Iteration:   4801, Training Accuracy:  73.4%, Loss: 0.4707\n",
      "Optimization Iteration:   4865, Training Accuracy:  79.7%, Loss: 0.4006\n",
      "Optimization Iteration:   4929, Training Accuracy:  79.7%, Loss: 0.4022\n",
      "Optimization Iteration:   4993, Training Accuracy:  76.6%, Loss: 0.3705\n",
      "Optimization Iteration:   5057, Training Accuracy:  71.9%, Loss: 0.4141\n",
      "Optimization Iteration:   5121, Training Accuracy:  84.4%, Loss: 0.3024\n",
      "Optimization Iteration:   5185, Training Accuracy:  79.7%, Loss: 0.3592\n",
      "Optimization Iteration:   5249, Training Accuracy:  59.4%, Loss: 0.4997\n",
      "Optimization Iteration:   5313, Training Accuracy:  82.8%, Loss: 0.3456\n",
      "Optimization Iteration:   5377, Training Accuracy:  75.0%, Loss: 0.3627\n",
      "Optimization Iteration:   5441, Training Accuracy:  68.8%, Loss: 0.4828\n",
      "Optimization Iteration:   5505, Training Accuracy:  79.7%, Loss: 0.3047\n",
      "Optimization Iteration:   5569, Training Accuracy:  79.7%, Loss: 0.3167\n",
      "Optimization Iteration:   5633, Training Accuracy:  79.7%, Loss: 0.3368\n",
      "Optimization Iteration:   5697, Training Accuracy:  81.2%, Loss: 0.4686\n",
      "Optimization Iteration:   5761, Training Accuracy:  81.2%, Loss: 0.3026\n",
      "Optimization Iteration:   5825, Training Accuracy:  79.7%, Loss: 0.4283\n",
      "Optimization Iteration:   5889, Training Accuracy:  81.2%, Loss: 0.4109\n",
      "Optimization Iteration:   5953, Training Accuracy:  70.3%, Loss: 0.4600\n",
      "Optimization Iteration:   6017, Training Accuracy:  59.4%, Loss: 0.5363\n",
      "Optimization Iteration:   6081, Training Accuracy:  76.6%, Loss: 0.3429\n",
      "Optimization Iteration:   6145, Training Accuracy:  70.3%, Loss: 0.4873\n",
      "Optimization Iteration:   6209, Training Accuracy:  67.2%, Loss: 0.3993\n",
      "Optimization Iteration:   6273, Training Accuracy:  75.0%, Loss: 0.4024\n",
      "Optimization Iteration:   6337, Training Accuracy:  71.9%, Loss: 0.4088\n",
      "Optimization Iteration:   6401, Training Accuracy:  90.6%, Loss: 0.3015\n",
      "Optimization Iteration:   6465, Training Accuracy:  85.9%, Loss: 0.2530\n",
      "Optimization Iteration:   6529, Training Accuracy:  81.2%, Loss: 0.3746\n",
      "Optimization Iteration:   6593, Training Accuracy:  78.1%, Loss: 0.3139\n",
      "Optimization Iteration:   6657, Training Accuracy:  73.4%, Loss: 0.4083\n",
      "Optimization Iteration:   6721, Training Accuracy:  84.4%, Loss: 0.3117\n",
      "Optimization Iteration:   6785, Training Accuracy:  71.9%, Loss: 0.4188\n",
      "Optimization Iteration:   6849, Training Accuracy:  70.3%, Loss: 0.4192\n",
      "Optimization Iteration:   6913, Training Accuracy:  76.6%, Loss: 0.3740\n",
      "Optimization Iteration:   6977, Training Accuracy:  76.6%, Loss: 0.3963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7041, Training Accuracy:  84.4%, Loss: 0.3139\n",
      "Optimization Iteration:   7105, Training Accuracy:  76.6%, Loss: 0.3264\n",
      "Optimization Iteration:   7169, Training Accuracy:  78.1%, Loss: 0.3435\n",
      "Optimization Iteration:   7233, Training Accuracy:  75.0%, Loss: 0.4632\n",
      "Optimization Iteration:   7297, Training Accuracy:  67.2%, Loss: 0.4731\n",
      "Optimization Iteration:   7361, Training Accuracy:  82.8%, Loss: 0.3208\n",
      "Optimization Iteration:   7425, Training Accuracy:  81.2%, Loss: 0.3090\n",
      "Optimization Iteration:   7489, Training Accuracy:  71.9%, Loss: 0.4115\n",
      "Optimization Iteration:   7553, Training Accuracy:  75.0%, Loss: 0.4925\n",
      "Optimization Iteration:   7617, Training Accuracy:  73.4%, Loss: 0.4070\n",
      "Optimization Iteration:   7681, Training Accuracy:  73.4%, Loss: 0.4327\n",
      "Optimization Iteration:   7745, Training Accuracy:  73.4%, Loss: 0.3848\n",
      "Optimization Iteration:   7809, Training Accuracy:  79.7%, Loss: 0.4811\n",
      "Optimization Iteration:   7873, Training Accuracy:  75.0%, Loss: 0.3484\n",
      "Optimization Iteration:   7937, Training Accuracy:  75.0%, Loss: 0.3487\n",
      "Optimization Iteration:   8001, Training Accuracy:  64.1%, Loss: 0.4395\n",
      "Optimization Iteration:   8065, Training Accuracy:  73.4%, Loss: 0.3834\n",
      "Optimization Iteration:   8129, Training Accuracy:  75.0%, Loss: 0.4151\n",
      "Optimization Iteration:   8193, Training Accuracy:  75.0%, Loss: 0.4037\n",
      "Optimization Iteration:   8257, Training Accuracy:  73.4%, Loss: 0.4378\n",
      "Optimization Iteration:   8321, Training Accuracy:  70.3%, Loss: 0.4406\n",
      "Optimization Iteration:   8385, Training Accuracy:  75.0%, Loss: 0.4001\n",
      "Optimization Iteration:   8449, Training Accuracy:  71.9%, Loss: 0.4409\n",
      "Optimization Iteration:   8513, Training Accuracy:  81.2%, Loss: 0.3420\n",
      "Optimization Iteration:   8577, Training Accuracy:  73.4%, Loss: 0.4826\n",
      "Optimization Iteration:   8641, Training Accuracy:  73.4%, Loss: 0.4375\n",
      "Optimization Iteration:   8705, Training Accuracy:  79.7%, Loss: 0.3301\n",
      "Optimization Iteration:   8769, Training Accuracy:  70.3%, Loss: 0.4274\n",
      "Optimization Iteration:   8833, Training Accuracy:  79.7%, Loss: 0.3945\n",
      "Optimization Iteration:   8897, Training Accuracy:  76.6%, Loss: 0.3809\n",
      "Optimization Iteration:   8961, Training Accuracy:  78.1%, Loss: 0.4000\n",
      "Optimization Iteration:   9025, Training Accuracy:  67.2%, Loss: 0.4750\n",
      "Optimization Iteration:   9089, Training Accuracy:  57.8%, Loss: 0.5057\n",
      "Optimization Iteration:   9153, Training Accuracy:  78.1%, Loss: 0.3665\n",
      "Optimization Iteration:   9217, Training Accuracy:  73.4%, Loss: 0.4300\n",
      "Optimization Iteration:   9281, Training Accuracy:  78.1%, Loss: 0.4255\n",
      "Optimization Iteration:   9345, Training Accuracy:  84.4%, Loss: 0.3928\n",
      "Optimization Iteration:   9409, Training Accuracy:  71.9%, Loss: 0.4649\n",
      "Optimization Iteration:   9473, Training Accuracy:  79.7%, Loss: 0.3608\n",
      "Optimization Iteration:   9537, Training Accuracy:  70.3%, Loss: 0.4086\n",
      "Optimization Iteration:   9601, Training Accuracy:  70.3%, Loss: 0.4282\n",
      "Optimization Iteration:   9665, Training Accuracy:  71.9%, Loss: 0.4334\n",
      "Optimization Iteration:   9729, Training Accuracy:  76.6%, Loss: 0.3831\n",
      "Optimization Iteration:   9793, Training Accuracy:  78.1%, Loss: 0.3218\n",
      "Optimization Iteration:   9857, Training Accuracy:  65.6%, Loss: 0.4464\n",
      "Optimization Iteration:   9921, Training Accuracy:  73.4%, Loss: 0.4082\n",
      "Optimization Iteration:   9985, Training Accuracy:  65.6%, Loss: 0.4544\n",
      "Optimization Iteration:  10049, Training Accuracy:  71.9%, Loss: 0.3909\n",
      "Optimization Iteration:  10113, Training Accuracy:  70.3%, Loss: 0.4434\n",
      "Optimization Iteration:  10177, Training Accuracy:  70.3%, Loss: 0.4633\n",
      "Optimization Iteration:  10241, Training Accuracy:  73.4%, Loss: 0.4518\n",
      "Optimization Iteration:  10305, Training Accuracy:  81.2%, Loss: 0.3412\n",
      "Optimization Iteration:  10369, Training Accuracy:  68.8%, Loss: 0.4208\n",
      "Optimization Iteration:  10433, Training Accuracy:  73.4%, Loss: 0.3773\n",
      "Optimization Iteration:  10497, Training Accuracy:  79.7%, Loss: 0.4721\n",
      "Optimization Iteration:  10561, Training Accuracy:  75.0%, Loss: 0.3350\n",
      "Optimization Iteration:  10625, Training Accuracy:  75.0%, Loss: 0.3606\n",
      "Optimization Iteration:  10689, Training Accuracy:  82.8%, Loss: 0.3399\n",
      "Optimization Iteration:  10753, Training Accuracy:  79.7%, Loss: 0.4517\n",
      "Optimization Iteration:  10817, Training Accuracy:  76.6%, Loss: 0.4289\n",
      "Optimization Iteration:  10881, Training Accuracy:  71.9%, Loss: 0.3666\n",
      "Optimization Iteration:  10945, Training Accuracy:  87.5%, Loss: 0.3610\n",
      "Optimization Iteration:  11009, Training Accuracy:  84.4%, Loss: 0.3183\n",
      "Optimization Iteration:  11073, Training Accuracy:  78.1%, Loss: 0.3633\n",
      "Optimization Iteration:  11137, Training Accuracy:  81.2%, Loss: 0.4244\n",
      "Optimization Iteration:  11201, Training Accuracy:  82.8%, Loss: 0.3644\n",
      "Optimization Iteration:  11265, Training Accuracy:  82.8%, Loss: 0.3668\n",
      "Optimization Iteration:  11329, Training Accuracy:  81.2%, Loss: 0.3995\n",
      "Optimization Iteration:  11393, Training Accuracy:  81.2%, Loss: 0.3933\n",
      "Optimization Iteration:  11457, Training Accuracy:  82.8%, Loss: 0.3707\n",
      "Optimization Iteration:  11521, Training Accuracy:  70.3%, Loss: 0.4047\n",
      "Optimization Iteration:  11585, Training Accuracy:  76.6%, Loss: 0.3978\n",
      "Optimization Iteration:  11649, Training Accuracy:  71.9%, Loss: 0.3796\n",
      "Optimization Iteration:  11713, Training Accuracy:  82.8%, Loss: 0.2945\n",
      "Optimization Iteration:  11777, Training Accuracy:  67.2%, Loss: 0.4562\n",
      "Optimization Iteration:  11841, Training Accuracy:  76.6%, Loss: 0.4082\n",
      "Optimization Iteration:  11905, Training Accuracy:  73.4%, Loss: 0.4340\n",
      "Optimization Iteration:  11969, Training Accuracy:  76.6%, Loss: 0.3786\n",
      "Optimization Iteration:  12033, Training Accuracy:  81.2%, Loss: 0.3600\n",
      "Optimization Iteration:  12097, Training Accuracy:  87.5%, Loss: 0.3509\n",
      "Optimization Iteration:  12161, Training Accuracy:  71.9%, Loss: 0.4296\n",
      "Optimization Iteration:  12225, Training Accuracy:  79.7%, Loss: 0.3489\n",
      "Optimization Iteration:  12289, Training Accuracy:  84.4%, Loss: 0.4486\n",
      "Optimization Iteration:  12353, Training Accuracy:  82.8%, Loss: 0.3394\n",
      "Optimization Iteration:  12417, Training Accuracy:  76.6%, Loss: 0.3718\n",
      "Optimization Iteration:  12481, Training Accuracy:  75.0%, Loss: 0.4073\n",
      "Optimization Iteration:  12545, Training Accuracy:  76.6%, Loss: 0.3825\n",
      "Optimization Iteration:  12609, Training Accuracy:  76.6%, Loss: 0.3465\n",
      "Optimization Iteration:  12673, Training Accuracy:  78.1%, Loss: 0.3671\n",
      "Optimization Iteration:  12737, Training Accuracy:  70.3%, Loss: 0.3875\n",
      "Optimization Iteration:  12801, Training Accuracy:  85.9%, Loss: 0.3326\n",
      "Optimization Iteration:  12865, Training Accuracy:  78.1%, Loss: 0.3694\n",
      "Optimization Iteration:  12929, Training Accuracy:  78.1%, Loss: 0.3307\n",
      "Optimization Iteration:  12993, Training Accuracy:  75.0%, Loss: 0.3735\n",
      "Optimization Iteration:  13057, Training Accuracy:  75.0%, Loss: 0.4622\n",
      "Optimization Iteration:  13121, Training Accuracy:  82.8%, Loss: 0.3480\n",
      "Optimization Iteration:  13185, Training Accuracy:  70.3%, Loss: 0.4692\n",
      "Optimization Iteration:  13249, Training Accuracy:  71.9%, Loss: 0.4474\n",
      "Optimization Iteration:  13313, Training Accuracy:  73.4%, Loss: 0.4599\n",
      "Optimization Iteration:  13377, Training Accuracy:  79.7%, Loss: 0.4271\n",
      "Optimization Iteration:  13441, Training Accuracy:  70.3%, Loss: 0.4138\n",
      "Optimization Iteration:  13505, Training Accuracy:  81.2%, Loss: 0.3890\n",
      "Optimization Iteration:  13569, Training Accuracy:  85.9%, Loss: 0.2848\n",
      "Optimization Iteration:  13633, Training Accuracy:  73.4%, Loss: 0.3717\n",
      "Optimization Iteration:  13697, Training Accuracy:  79.7%, Loss: 0.3531\n",
      "Optimization Iteration:  13761, Training Accuracy:  78.1%, Loss: 0.3594\n",
      "Optimization Iteration:  13825, Training Accuracy:  84.4%, Loss: 0.3230\n",
      "Optimization Iteration:  13889, Training Accuracy:  79.7%, Loss: 0.5308\n",
      "Optimization Iteration:  13953, Training Accuracy:  84.4%, Loss: 0.3288\n",
      "Optimization Iteration:  14017, Training Accuracy:  76.6%, Loss: 0.3981\n",
      "Optimization Iteration:  14081, Training Accuracy:  70.3%, Loss: 0.4163\n",
      "Optimization Iteration:  14145, Training Accuracy:  70.3%, Loss: 0.3619\n",
      "Optimization Iteration:  14209, Training Accuracy:  81.2%, Loss: 0.3470\n",
      "Optimization Iteration:  14273, Training Accuracy:  75.0%, Loss: 0.3813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  14337, Training Accuracy:  81.2%, Loss: 0.3050\n",
      "Optimization Iteration:  14401, Training Accuracy:  84.4%, Loss: 0.3682\n",
      "Optimization Iteration:  14465, Training Accuracy:  78.1%, Loss: 0.3715\n",
      "Optimization Iteration:  14529, Training Accuracy:  75.0%, Loss: 0.4337\n",
      "Optimization Iteration:  14593, Training Accuracy:  71.9%, Loss: 0.3925\n",
      "Optimization Iteration:  14657, Training Accuracy:  68.8%, Loss: 0.4859\n",
      "Optimization Iteration:  14721, Training Accuracy:  78.1%, Loss: 0.3564\n",
      "Optimization Iteration:  14785, Training Accuracy:  75.0%, Loss: 0.4940\n",
      "Optimization Iteration:  14849, Training Accuracy:  75.0%, Loss: 0.4242\n",
      "Optimization Iteration:  14913, Training Accuracy:  75.0%, Loss: 0.3666\n",
      "Optimization Iteration:  14977, Training Accuracy:  70.3%, Loss: 0.4281\n",
      "Optimization Iteration:  15041, Training Accuracy:  68.8%, Loss: 0.3961\n",
      "Optimization Iteration:  15105, Training Accuracy:  79.7%, Loss: 0.3509\n",
      "Optimization Iteration:  15169, Training Accuracy:  76.6%, Loss: 0.3502\n",
      "Optimization Iteration:  15233, Training Accuracy:  73.4%, Loss: 0.4082\n",
      "Optimization Iteration:  15297, Training Accuracy:  67.2%, Loss: 0.4010\n",
      "Optimization Iteration:  15361, Training Accuracy:  87.5%, Loss: 0.3694\n",
      "Optimization Iteration:  15425, Training Accuracy:  76.6%, Loss: 0.3914\n",
      "Optimization Iteration:  15489, Training Accuracy:  75.0%, Loss: 0.3746\n",
      "Optimization Iteration:  15553, Training Accuracy:  78.1%, Loss: 0.3419\n",
      "Optimization Iteration:  15617, Training Accuracy:  79.7%, Loss: 0.3510\n",
      "Optimization Iteration:  15681, Training Accuracy:  82.8%, Loss: 0.3059\n",
      "Optimization Iteration:  15745, Training Accuracy:  81.2%, Loss: 0.3620\n",
      "Optimization Iteration:  15809, Training Accuracy:  73.4%, Loss: 0.3702\n",
      "Optimization Iteration:  15873, Training Accuracy:  75.0%, Loss: 0.3858\n",
      "Optimization Iteration:  15937, Training Accuracy:  79.7%, Loss: 0.3334\n",
      "Optimization Iteration:  16001, Training Accuracy:  71.9%, Loss: 0.4383\n",
      "Optimization Iteration:  16065, Training Accuracy:  65.6%, Loss: 0.4755\n",
      "Optimization Iteration:  16129, Training Accuracy:  78.1%, Loss: 0.3808\n",
      "Optimization Iteration:  16193, Training Accuracy:  68.8%, Loss: 0.5149\n",
      "Optimization Iteration:  16257, Training Accuracy:  75.0%, Loss: 0.4704\n",
      "Optimization Iteration:  16321, Training Accuracy:  78.1%, Loss: 0.3995\n",
      "Optimization Iteration:  16385, Training Accuracy:  82.8%, Loss: 0.3605\n",
      "Optimization Iteration:  16449, Training Accuracy:  79.7%, Loss: 0.3381\n",
      "Optimization Iteration:  16513, Training Accuracy:  76.6%, Loss: 0.3937\n",
      "Optimization Iteration:  16577, Training Accuracy:  78.1%, Loss: 0.4266\n",
      "Optimization Iteration:  16641, Training Accuracy:  70.3%, Loss: 0.4564\n",
      "Optimization Iteration:  16705, Training Accuracy:  85.9%, Loss: 0.3458\n",
      "Optimization Iteration:  16769, Training Accuracy:  75.0%, Loss: 0.3418\n",
      "Optimization Iteration:  16833, Training Accuracy:  76.6%, Loss: 0.3390\n",
      "Optimization Iteration:  16897, Training Accuracy:  75.0%, Loss: 0.3851\n",
      "Optimization Iteration:  16961, Training Accuracy:  79.7%, Loss: 0.3629\n",
      "Optimization Iteration:  17025, Training Accuracy:  70.3%, Loss: 0.4718\n",
      "Optimization Iteration:  17089, Training Accuracy:  79.7%, Loss: 0.3974\n",
      "Optimization Iteration:  17153, Training Accuracy:  73.4%, Loss: 0.3863\n",
      "Optimization Iteration:  17217, Training Accuracy:  78.1%, Loss: 0.3958\n",
      "Optimization Iteration:  17281, Training Accuracy:  70.3%, Loss: 0.4039\n",
      "Optimization Iteration:  17345, Training Accuracy:  82.8%, Loss: 0.2706\n",
      "Optimization Iteration:  17409, Training Accuracy:  81.2%, Loss: 0.3016\n",
      "Optimization Iteration:  17473, Training Accuracy:  75.0%, Loss: 0.3976\n",
      "Optimization Iteration:  17537, Training Accuracy:  78.1%, Loss: 0.3925\n",
      "Optimization Iteration:  17601, Training Accuracy:  73.4%, Loss: 0.4348\n",
      "Optimization Iteration:  17665, Training Accuracy:  82.8%, Loss: 0.2970\n",
      "Optimization Iteration:  17729, Training Accuracy:  75.0%, Loss: 0.4105\n",
      "Optimization Iteration:  17793, Training Accuracy:  71.9%, Loss: 0.4227\n",
      "Optimization Iteration:  17857, Training Accuracy:  70.3%, Loss: 0.4327\n",
      "Optimization Iteration:  17921, Training Accuracy:  76.6%, Loss: 0.3857\n",
      "Optimization Iteration:  17985, Training Accuracy:  76.6%, Loss: 0.4069\n",
      "Optimization Iteration:  18049, Training Accuracy:  78.1%, Loss: 0.3720\n",
      "Optimization Iteration:  18113, Training Accuracy:  73.4%, Loss: 0.4433\n",
      "Optimization Iteration:  18177, Training Accuracy:  68.8%, Loss: 0.4535\n",
      "Optimization Iteration:  18241, Training Accuracy:  78.1%, Loss: 0.4045\n",
      "Optimization Iteration:  18305, Training Accuracy:  73.4%, Loss: 0.4232\n",
      "Optimization Iteration:  18369, Training Accuracy:  70.3%, Loss: 0.3664\n",
      "Optimization Iteration:  18433, Training Accuracy:  75.0%, Loss: 0.3748\n",
      "Optimization Iteration:  18497, Training Accuracy:  82.8%, Loss: 0.3332\n",
      "Optimization Iteration:  18561, Training Accuracy:  81.2%, Loss: 0.3081\n",
      "Optimization Iteration:  18625, Training Accuracy:  73.4%, Loss: 0.4407\n",
      "Optimization Iteration:  18689, Training Accuracy:  70.3%, Loss: 0.3981\n",
      "Optimization Iteration:  18753, Training Accuracy:  82.8%, Loss: 0.3668\n",
      "Optimization Iteration:  18817, Training Accuracy:  81.2%, Loss: 0.3444\n",
      "Optimization Iteration:  18881, Training Accuracy:  75.0%, Loss: 0.4141\n",
      "Optimization Iteration:  18945, Training Accuracy:  76.6%, Loss: 0.4153\n",
      "Optimization Iteration:  19009, Training Accuracy:  78.1%, Loss: 0.3420\n",
      "Optimization Iteration:  19073, Training Accuracy:  76.6%, Loss: 0.4228\n",
      "Optimization Iteration:  19137, Training Accuracy:  70.3%, Loss: 0.4872\n",
      "Optimization Iteration:  19201, Training Accuracy:  70.3%, Loss: 0.4282\n",
      "Optimization Iteration:  19265, Training Accuracy:  76.6%, Loss: 0.4033\n",
      "Optimization Iteration:  19329, Training Accuracy:  84.4%, Loss: 0.3324\n",
      "Optimization Iteration:  19393, Training Accuracy:  78.1%, Loss: 0.3805\n",
      "Optimization Iteration:  19457, Training Accuracy:  76.6%, Loss: 0.3896\n",
      "Optimization Iteration:  19521, Training Accuracy:  71.9%, Loss: 0.4367\n",
      "Optimization Iteration:  19585, Training Accuracy:  75.0%, Loss: 0.4279\n",
      "Optimization Iteration:  19649, Training Accuracy:  78.1%, Loss: 0.4140\n",
      "Optimization Iteration:  19713, Training Accuracy:  79.7%, Loss: 0.3481\n",
      "Optimization Iteration:  19777, Training Accuracy:  76.6%, Loss: 0.4511\n",
      "Optimization Iteration:  19841, Training Accuracy:  64.1%, Loss: 0.4790\n",
      "Optimization Iteration:  19905, Training Accuracy:  79.7%, Loss: 0.3444\n",
      "Optimization Iteration:  19969, Training Accuracy:  78.1%, Loss: 0.4122\n",
      "Optimization Iteration:  20033, Training Accuracy:  81.2%, Loss: 0.3489\n",
      "Optimization Iteration:  20097, Training Accuracy:  78.1%, Loss: 0.4269\n",
      "Optimization Iteration:  20161, Training Accuracy:  68.8%, Loss: 0.3957\n",
      "Optimization Iteration:  20225, Training Accuracy:  70.3%, Loss: 0.4222\n",
      "Optimization Iteration:  20289, Training Accuracy:  67.2%, Loss: 0.4405\n",
      "Optimization Iteration:  20353, Training Accuracy:  79.7%, Loss: 0.3962\n",
      "Optimization Iteration:  20417, Training Accuracy:  78.1%, Loss: 0.3533\n",
      "Optimization Iteration:  20481, Training Accuracy:  82.8%, Loss: 0.3146\n",
      "Optimization Iteration:  20545, Training Accuracy:  81.2%, Loss: 0.3595\n",
      "Optimization Iteration:  20609, Training Accuracy:  76.6%, Loss: 0.4198\n",
      "Optimization Iteration:  20673, Training Accuracy:  71.9%, Loss: 0.3982\n",
      "Optimization Iteration:  20737, Training Accuracy:  82.8%, Loss: 0.4052\n",
      "Optimization Iteration:  20801, Training Accuracy:  78.1%, Loss: 0.3387\n",
      "Optimization Iteration:  20865, Training Accuracy:  81.2%, Loss: 0.3733\n",
      "Optimization Iteration:  20929, Training Accuracy:  75.0%, Loss: 0.4391\n",
      "Optimization Iteration:  20993, Training Accuracy:  75.0%, Loss: 0.4329\n",
      "Optimization Iteration:  21057, Training Accuracy:  81.2%, Loss: 0.3913\n",
      "Optimization Iteration:  21121, Training Accuracy:  64.1%, Loss: 0.4820\n",
      "Optimization Iteration:  21185, Training Accuracy:  76.6%, Loss: 0.3927\n",
      "Optimization Iteration:  21249, Training Accuracy:  79.7%, Loss: 0.3735\n",
      "Optimization Iteration:  21313, Training Accuracy:  78.1%, Loss: 0.3293\n",
      "Optimization Iteration:  21377, Training Accuracy:  79.7%, Loss: 0.2866\n",
      "Optimization Iteration:  21441, Training Accuracy:  67.2%, Loss: 0.3895\n",
      "Optimization Iteration:  21505, Training Accuracy:  78.1%, Loss: 0.3716\n",
      "Optimization Iteration:  21569, Training Accuracy:  82.8%, Loss: 0.3229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  21633, Training Accuracy:  85.9%, Loss: 0.3343\n",
      "Optimization Iteration:  21697, Training Accuracy:  76.6%, Loss: 0.4136\n",
      "Optimization Iteration:  21761, Training Accuracy:  79.7%, Loss: 0.3772\n",
      "Optimization Iteration:  21825, Training Accuracy:  70.3%, Loss: 0.4385\n",
      "Optimization Iteration:  21889, Training Accuracy:  89.1%, Loss: 0.3100\n",
      "Optimization Iteration:  21953, Training Accuracy:  81.2%, Loss: 0.4576\n",
      "Optimization Iteration:  22017, Training Accuracy:  87.5%, Loss: 0.3351\n",
      "Optimization Iteration:  22081, Training Accuracy:  79.7%, Loss: 0.4164\n",
      "Optimization Iteration:  22145, Training Accuracy:  79.7%, Loss: 0.4120\n",
      "Optimization Iteration:  22209, Training Accuracy:  78.1%, Loss: 0.3945\n",
      "Optimization Iteration:  22273, Training Accuracy:  76.6%, Loss: 0.3817\n",
      "Optimization Iteration:  22337, Training Accuracy:  71.9%, Loss: 0.3638\n",
      "Optimization Iteration:  22401, Training Accuracy:  79.7%, Loss: 0.3885\n",
      "Optimization Iteration:  22465, Training Accuracy:  70.3%, Loss: 0.4425\n",
      "Optimization Iteration:  22529, Training Accuracy:  73.4%, Loss: 0.4198\n",
      "Optimization Iteration:  22593, Training Accuracy:  76.6%, Loss: 0.3837\n",
      "Optimization Iteration:  22657, Training Accuracy:  68.8%, Loss: 0.4713\n",
      "Optimization Iteration:  22721, Training Accuracy:  76.6%, Loss: 0.3627\n",
      "Optimization Iteration:  22785, Training Accuracy:  67.2%, Loss: 0.4897\n",
      "Optimization Iteration:  22849, Training Accuracy:  78.1%, Loss: 0.3884\n",
      "Optimization Iteration:  22913, Training Accuracy:  67.2%, Loss: 0.4265\n",
      "Optimization Iteration:  22977, Training Accuracy:  79.7%, Loss: 0.3390\n",
      "Optimization Iteration:  23041, Training Accuracy:  76.6%, Loss: 0.3226\n",
      "Optimization Iteration:  23105, Training Accuracy:  71.9%, Loss: 0.3647\n",
      "Optimization Iteration:  23169, Training Accuracy:  87.5%, Loss: 0.3525\n",
      "Optimization Iteration:  23233, Training Accuracy:  64.1%, Loss: 0.5026\n",
      "Optimization Iteration:  23297, Training Accuracy:  81.2%, Loss: 0.3912\n",
      "Optimization Iteration:  23361, Training Accuracy:  70.3%, Loss: 0.4675\n",
      "Optimization Iteration:  23425, Training Accuracy:  67.2%, Loss: 0.4723\n",
      "Optimization Iteration:  23489, Training Accuracy:  76.6%, Loss: 0.4250\n",
      "Optimization Iteration:  23553, Training Accuracy:  75.0%, Loss: 0.4205\n",
      "Optimization Iteration:  23617, Training Accuracy:  78.1%, Loss: 0.4089\n",
      "Optimization Iteration:  23681, Training Accuracy:  71.9%, Loss: 0.3928\n",
      "Optimization Iteration:  23745, Training Accuracy:  71.9%, Loss: 0.3323\n",
      "Optimization Iteration:  23809, Training Accuracy:  78.1%, Loss: 0.4285\n",
      "Optimization Iteration:  23873, Training Accuracy:  78.1%, Loss: 0.3702\n",
      "Optimization Iteration:  23937, Training Accuracy:  76.6%, Loss: 0.3892\n",
      "Optimization Iteration:  24001, Training Accuracy:  82.8%, Loss: 0.2908\n",
      "Optimization Iteration:  24065, Training Accuracy:  78.1%, Loss: 0.3660\n",
      "Optimization Iteration:  24129, Training Accuracy:  84.4%, Loss: 0.3267\n",
      "Optimization Iteration:  24193, Training Accuracy:  78.1%, Loss: 0.3692\n",
      "Optimization Iteration:  24257, Training Accuracy:  82.8%, Loss: 0.3437\n",
      "Optimization Iteration:  24321, Training Accuracy:  73.4%, Loss: 0.3923\n",
      "Optimization Iteration:  24385, Training Accuracy:  76.6%, Loss: 0.4272\n",
      "Optimization Iteration:  24449, Training Accuracy:  70.3%, Loss: 0.3767\n",
      "Optimization Iteration:  24513, Training Accuracy:  75.0%, Loss: 0.4274\n",
      "Optimization Iteration:  24577, Training Accuracy:  68.8%, Loss: 0.5216\n",
      "Optimization Iteration:  24641, Training Accuracy:  73.4%, Loss: 0.4171\n",
      "Optimization Iteration:  24705, Training Accuracy:  81.2%, Loss: 0.3365\n",
      "Optimization Iteration:  24769, Training Accuracy:  85.9%, Loss: 0.3369\n",
      "Optimization Iteration:  24833, Training Accuracy:  90.6%, Loss: 0.2505\n",
      "Optimization Iteration:  24897, Training Accuracy:  68.8%, Loss: 0.4242\n",
      "Optimization Iteration:  24961, Training Accuracy:  79.7%, Loss: 0.2783\n",
      "Optimization Iteration:  25025, Training Accuracy:  71.9%, Loss: 0.4321\n",
      "Optimization Iteration:  25089, Training Accuracy:  82.8%, Loss: 0.3931\n",
      "Optimization Iteration:  25153, Training Accuracy:  76.6%, Loss: 0.4260\n",
      "Optimization Iteration:  25217, Training Accuracy:  68.8%, Loss: 0.4337\n",
      "Optimization Iteration:  25281, Training Accuracy:  75.0%, Loss: 0.4020\n",
      "Optimization Iteration:  25345, Training Accuracy:  75.0%, Loss: 0.4430\n",
      "Optimization Iteration:  25409, Training Accuracy:  85.9%, Loss: 0.3571\n",
      "Optimization Iteration:  25473, Training Accuracy:  71.9%, Loss: 0.4125\n",
      "Optimization Iteration:  25537, Training Accuracy:  71.9%, Loss: 0.4013\n",
      "Optimization Iteration:  25601, Training Accuracy:  64.1%, Loss: 0.5550\n",
      "Optimization Iteration:  25665, Training Accuracy:  76.6%, Loss: 0.4186\n",
      "Optimization Iteration:  25729, Training Accuracy:  71.9%, Loss: 0.3585\n",
      "Optimization Iteration:  25793, Training Accuracy:  73.4%, Loss: 0.3962\n",
      "Optimization Iteration:  25857, Training Accuracy:  73.4%, Loss: 0.4606\n",
      "Optimization Iteration:  25921, Training Accuracy:  78.1%, Loss: 0.4299\n",
      "Optimization Iteration:  25985, Training Accuracy:  71.9%, Loss: 0.4589\n",
      "Optimization Iteration:  26049, Training Accuracy:  76.6%, Loss: 0.4049\n",
      "Optimization Iteration:  26113, Training Accuracy:  81.2%, Loss: 0.3207\n",
      "Optimization Iteration:  26177, Training Accuracy:  78.1%, Loss: 0.3414\n",
      "Optimization Iteration:  26241, Training Accuracy:  71.9%, Loss: 0.4027\n",
      "Optimization Iteration:  26305, Training Accuracy:  81.2%, Loss: 0.4056\n",
      "Optimization Iteration:  26369, Training Accuracy:  71.9%, Loss: 0.3983\n",
      "Optimization Iteration:  26433, Training Accuracy:  85.9%, Loss: 0.3198\n",
      "Optimization Iteration:  26497, Training Accuracy:  82.8%, Loss: 0.3611\n",
      "Optimization Iteration:  26561, Training Accuracy:  82.8%, Loss: 0.3816\n",
      "Optimization Iteration:  26625, Training Accuracy:  82.8%, Loss: 0.3312\n",
      "Optimization Iteration:  26689, Training Accuracy:  78.1%, Loss: 0.4015\n",
      "Optimization Iteration:  26753, Training Accuracy:  71.9%, Loss: 0.4332\n",
      "Optimization Iteration:  26817, Training Accuracy:  68.8%, Loss: 0.4601\n",
      "Optimization Iteration:  26881, Training Accuracy:  78.1%, Loss: 0.3354\n",
      "Optimization Iteration:  26945, Training Accuracy:  82.8%, Loss: 0.3981\n",
      "Optimization Iteration:  27009, Training Accuracy:  76.6%, Loss: 0.3972\n",
      "Optimization Iteration:  27073, Training Accuracy:  89.1%, Loss: 0.3366\n",
      "Optimization Iteration:  27137, Training Accuracy:  82.8%, Loss: 0.3435\n",
      "Optimization Iteration:  27201, Training Accuracy:  79.7%, Loss: 0.3324\n",
      "Optimization Iteration:  27265, Training Accuracy:  75.0%, Loss: 0.3410\n",
      "Optimization Iteration:  27329, Training Accuracy:  75.0%, Loss: 0.4020\n",
      "Optimization Iteration:  27393, Training Accuracy:  76.6%, Loss: 0.4217\n",
      "Optimization Iteration:  27457, Training Accuracy:  78.1%, Loss: 0.3264\n",
      "Optimization Iteration:  27521, Training Accuracy:  85.9%, Loss: 0.3490\n",
      "Optimization Iteration:  27585, Training Accuracy:  71.9%, Loss: 0.3958\n",
      "Optimization Iteration:  27649, Training Accuracy:  73.4%, Loss: 0.3823\n",
      "Optimization Iteration:  27713, Training Accuracy:  75.0%, Loss: 0.3592\n",
      "Optimization Iteration:  27777, Training Accuracy:  78.1%, Loss: 0.3887\n",
      "Optimization Iteration:  27841, Training Accuracy:  71.9%, Loss: 0.4196\n",
      "Optimization Iteration:  27905, Training Accuracy:  70.3%, Loss: 0.4824\n",
      "Optimization Iteration:  27969, Training Accuracy:  79.7%, Loss: 0.4330\n",
      "Optimization Iteration:  28033, Training Accuracy:  76.6%, Loss: 0.3463\n",
      "Optimization Iteration:  28097, Training Accuracy:  87.5%, Loss: 0.2780\n",
      "Optimization Iteration:  28161, Training Accuracy:  90.6%, Loss: 0.3062\n",
      "Optimization Iteration:  28225, Training Accuracy:  71.9%, Loss: 0.3841\n",
      "Optimization Iteration:  28289, Training Accuracy:  76.6%, Loss: 0.3806\n",
      "Optimization Iteration:  28353, Training Accuracy:  78.1%, Loss: 0.4119\n",
      "Optimization Iteration:  28417, Training Accuracy:  73.4%, Loss: 0.4518\n",
      "Optimization Iteration:  28481, Training Accuracy:  82.8%, Loss: 0.3594\n",
      "Optimization Iteration:  28545, Training Accuracy:  76.6%, Loss: 0.3129\n",
      "Optimization Iteration:  28609, Training Accuracy:  70.3%, Loss: 0.3841\n",
      "Optimization Iteration:  28673, Training Accuracy:  75.0%, Loss: 0.4340\n",
      "Optimization Iteration:  28737, Training Accuracy:  75.0%, Loss: 0.4410\n",
      "Optimization Iteration:  28801, Training Accuracy:  79.7%, Loss: 0.3947\n",
      "Optimization Iteration:  28865, Training Accuracy:  81.2%, Loss: 0.3213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  28929, Training Accuracy:  84.4%, Loss: 0.3006\n",
      "Optimization Iteration:  28993, Training Accuracy:  78.1%, Loss: 0.3628\n",
      "Optimization Iteration:  29057, Training Accuracy:  67.2%, Loss: 0.4399\n",
      "Optimization Iteration:  29121, Training Accuracy:  67.2%, Loss: 0.4847\n",
      "Optimization Iteration:  29185, Training Accuracy:  71.9%, Loss: 0.3859\n",
      "Optimization Iteration:  29249, Training Accuracy:  84.4%, Loss: 0.3460\n",
      "Optimization Iteration:  29313, Training Accuracy:  70.3%, Loss: 0.4389\n",
      "Optimization Iteration:  29377, Training Accuracy:  73.4%, Loss: 0.3565\n",
      "Optimization Iteration:  29441, Training Accuracy:  78.1%, Loss: 0.4135\n",
      "Optimization Iteration:  29505, Training Accuracy:  78.1%, Loss: 0.4821\n",
      "Optimization Iteration:  29569, Training Accuracy:  79.7%, Loss: 0.3477\n",
      "Optimization Iteration:  29633, Training Accuracy:  68.8%, Loss: 0.4309\n",
      "Optimization Iteration:  29697, Training Accuracy:  78.1%, Loss: 0.3610\n",
      "Optimization Iteration:  29761, Training Accuracy:  71.9%, Loss: 0.3512\n",
      "Optimization Iteration:  29825, Training Accuracy:  70.3%, Loss: 0.4176\n",
      "Optimization Iteration:  29889, Training Accuracy:  78.1%, Loss: 0.4192\n",
      "Optimization Iteration:  29953, Training Accuracy:  70.3%, Loss: 0.4782\n",
      "Optimization Iteration:  30017, Training Accuracy:  87.5%, Loss: 0.2951\n",
      "Optimization Iteration:  30081, Training Accuracy:  75.0%, Loss: 0.3487\n",
      "Optimization Iteration:  30145, Training Accuracy:  79.7%, Loss: 0.3791\n",
      "Optimization Iteration:  30209, Training Accuracy:  71.9%, Loss: 0.3889\n",
      "Optimization Iteration:  30273, Training Accuracy:  73.4%, Loss: 0.3785\n",
      "Optimization Iteration:  30337, Training Accuracy:  81.2%, Loss: 0.3727\n",
      "Optimization Iteration:  30401, Training Accuracy:  82.8%, Loss: 0.3832\n",
      "Optimization Iteration:  30465, Training Accuracy:  71.9%, Loss: 0.4177\n",
      "Optimization Iteration:  30529, Training Accuracy:  76.6%, Loss: 0.3640\n",
      "Optimization Iteration:  30593, Training Accuracy:  76.6%, Loss: 0.3439\n",
      "Optimization Iteration:  30657, Training Accuracy:  78.1%, Loss: 0.3738\n",
      "Optimization Iteration:  30721, Training Accuracy:  82.8%, Loss: 0.3515\n",
      "Optimization Iteration:  30785, Training Accuracy:  68.8%, Loss: 0.4351\n",
      "Optimization Iteration:  30849, Training Accuracy:  78.1%, Loss: 0.3819\n",
      "Optimization Iteration:  30913, Training Accuracy:  78.1%, Loss: 0.3670\n",
      "Optimization Iteration:  30977, Training Accuracy:  75.0%, Loss: 0.3716\n",
      "Optimization Iteration:  31041, Training Accuracy:  79.7%, Loss: 0.3758\n",
      "Optimization Iteration:  31105, Training Accuracy:  76.6%, Loss: 0.4095\n",
      "Optimization Iteration:  31169, Training Accuracy:  78.1%, Loss: 0.3716\n",
      "Optimization Iteration:  31233, Training Accuracy:  75.0%, Loss: 0.3809\n",
      "Optimization Iteration:  31297, Training Accuracy:  79.7%, Loss: 0.3119\n",
      "Optimization Iteration:  31361, Training Accuracy:  76.6%, Loss: 0.4242\n",
      "Optimization Iteration:  31425, Training Accuracy:  87.5%, Loss: 0.2780\n",
      "Optimization Iteration:  31489, Training Accuracy:  85.9%, Loss: 0.3193\n",
      "Optimization Iteration:  31553, Training Accuracy:  82.8%, Loss: 0.3492\n",
      "Optimization Iteration:  31617, Training Accuracy:  78.1%, Loss: 0.3441\n",
      "Optimization Iteration:  31681, Training Accuracy:  78.1%, Loss: 0.4911\n",
      "Optimization Iteration:  31745, Training Accuracy:  78.1%, Loss: 0.3211\n",
      "Optimization Iteration:  31809, Training Accuracy:  68.8%, Loss: 0.5604\n",
      "Optimization Iteration:  31873, Training Accuracy:  76.6%, Loss: 0.3461\n",
      "Optimization Iteration:  31937, Training Accuracy:  70.3%, Loss: 0.4051\n",
      "Optimization Iteration:  32001, Training Accuracy:  70.3%, Loss: 0.4435\n",
      "Optimization Iteration:  32065, Training Accuracy:  71.9%, Loss: 0.3785\n",
      "Optimization Iteration:  32129, Training Accuracy:  73.4%, Loss: 0.4480\n",
      "Optimization Iteration:  32193, Training Accuracy:  76.6%, Loss: 0.3836\n",
      "Optimization Iteration:  32257, Training Accuracy:  76.6%, Loss: 0.3680\n",
      "Optimization Iteration:  32321, Training Accuracy:  70.3%, Loss: 0.4016\n",
      "Optimization Iteration:  32385, Training Accuracy:  78.1%, Loss: 0.3628\n",
      "Optimization Iteration:  32449, Training Accuracy:  70.3%, Loss: 0.4578\n",
      "Optimization Iteration:  32513, Training Accuracy:  78.1%, Loss: 0.2983\n",
      "Optimization Iteration:  32577, Training Accuracy:  67.2%, Loss: 0.4081\n",
      "Optimization Iteration:  32641, Training Accuracy:  73.4%, Loss: 0.4067\n",
      "Optimization Iteration:  32705, Training Accuracy:  67.2%, Loss: 0.4045\n",
      "Optimization Iteration:  32769, Training Accuracy:  64.1%, Loss: 0.4699\n",
      "Optimization Iteration:  32833, Training Accuracy:  75.0%, Loss: 0.3923\n",
      "Optimization Iteration:  32897, Training Accuracy:  75.0%, Loss: 0.4146\n",
      "Optimization Iteration:  32961, Training Accuracy:  75.0%, Loss: 0.3906\n",
      "Optimization Iteration:  33025, Training Accuracy:  70.3%, Loss: 0.4049\n",
      "Optimization Iteration:  33089, Training Accuracy:  76.6%, Loss: 0.3864\n",
      "Optimization Iteration:  33153, Training Accuracy:  81.2%, Loss: 0.4259\n",
      "Optimization Iteration:  33217, Training Accuracy:  68.8%, Loss: 0.4246\n",
      "Optimization Iteration:  33281, Training Accuracy:  75.0%, Loss: 0.4622\n",
      "Optimization Iteration:  33345, Training Accuracy:  76.6%, Loss: 0.3764\n",
      "Optimization Iteration:  33409, Training Accuracy:  79.7%, Loss: 0.3909\n",
      "Optimization Iteration:  33473, Training Accuracy:  82.8%, Loss: 0.3761\n",
      "Optimization Iteration:  33537, Training Accuracy:  76.6%, Loss: 0.4028\n",
      "Optimization Iteration:  33601, Training Accuracy:  73.4%, Loss: 0.4461\n",
      "Optimization Iteration:  33665, Training Accuracy:  76.6%, Loss: 0.3635\n",
      "Optimization Iteration:  33729, Training Accuracy:  65.6%, Loss: 0.4653\n",
      "Optimization Iteration:  33793, Training Accuracy:  73.4%, Loss: 0.4553\n",
      "Optimization Iteration:  33857, Training Accuracy:  76.6%, Loss: 0.3625\n",
      "Optimization Iteration:  33921, Training Accuracy:  78.1%, Loss: 0.4034\n",
      "Optimization Iteration:  33985, Training Accuracy:  76.6%, Loss: 0.3612\n",
      "Optimization Iteration:  34049, Training Accuracy:  71.9%, Loss: 0.4525\n",
      "Optimization Iteration:  34113, Training Accuracy:  81.2%, Loss: 0.3244\n",
      "Optimization Iteration:  34177, Training Accuracy:  73.4%, Loss: 0.4074\n",
      "Optimization Iteration:  34241, Training Accuracy:  84.4%, Loss: 0.3688\n",
      "Optimization Iteration:  34305, Training Accuracy:  67.2%, Loss: 0.4141\n",
      "Optimization Iteration:  34369, Training Accuracy:  76.6%, Loss: 0.3188\n",
      "Optimization Iteration:  34433, Training Accuracy:  75.0%, Loss: 0.4990\n",
      "Optimization Iteration:  34497, Training Accuracy:  81.2%, Loss: 0.3594\n",
      "Optimization Iteration:  34561, Training Accuracy:  76.6%, Loss: 0.3908\n",
      "Optimization Iteration:  34625, Training Accuracy:  70.3%, Loss: 0.4153\n",
      "Optimization Iteration:  34689, Training Accuracy:  73.4%, Loss: 0.4361\n",
      "Optimization Iteration:  34753, Training Accuracy:  76.6%, Loss: 0.3946\n",
      "Optimization Iteration:  34817, Training Accuracy:  73.4%, Loss: 0.3968\n",
      "Optimization Iteration:  34881, Training Accuracy:  81.2%, Loss: 0.3350\n",
      "Optimization Iteration:  34945, Training Accuracy:  76.6%, Loss: 0.3612\n",
      "Optimization Iteration:  35009, Training Accuracy:  84.4%, Loss: 0.2990\n",
      "Optimization Iteration:  35073, Training Accuracy:  73.4%, Loss: 0.3714\n",
      "Optimization Iteration:  35137, Training Accuracy:  59.4%, Loss: 0.4352\n",
      "Optimization Iteration:  35201, Training Accuracy:  78.1%, Loss: 0.3537\n",
      "Optimization Iteration:  35265, Training Accuracy:  65.6%, Loss: 0.4615\n",
      "Optimization Iteration:  35329, Training Accuracy:  75.0%, Loss: 0.4032\n",
      "Optimization Iteration:  35393, Training Accuracy:  81.2%, Loss: 0.2957\n",
      "Optimization Iteration:  35457, Training Accuracy:  73.4%, Loss: 0.3938\n",
      "Optimization Iteration:  35521, Training Accuracy:  71.9%, Loss: 0.3580\n",
      "Optimization Iteration:  35585, Training Accuracy:  84.4%, Loss: 0.3050\n",
      "Optimization Iteration:  35649, Training Accuracy:  67.2%, Loss: 0.4812\n",
      "Optimization Iteration:  35713, Training Accuracy:  76.6%, Loss: 0.4002\n",
      "Optimization Iteration:  35777, Training Accuracy:  81.2%, Loss: 0.3076\n",
      "Optimization Iteration:  35841, Training Accuracy:  81.2%, Loss: 0.2923\n",
      "Optimization Iteration:  35905, Training Accuracy:  70.3%, Loss: 0.4576\n",
      "Optimization Iteration:  35969, Training Accuracy:  71.9%, Loss: 0.3978\n",
      "Optimization Iteration:  36033, Training Accuracy:  73.4%, Loss: 0.3534\n",
      "Optimization Iteration:  36097, Training Accuracy:  73.4%, Loss: 0.4217\n",
      "Optimization Iteration:  36161, Training Accuracy:  67.2%, Loss: 0.4721\n",
      "Optimization Iteration:  36225, Training Accuracy:  78.1%, Loss: 0.3340\n",
      "Optimization Iteration:  36289, Training Accuracy:  82.8%, Loss: 0.3184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  36353, Training Accuracy:  73.4%, Loss: 0.3889\n",
      "Optimization Iteration:  36417, Training Accuracy:  79.7%, Loss: 0.3352\n",
      "Optimization Iteration:  36481, Training Accuracy:  78.1%, Loss: 0.3663\n",
      "Optimization Iteration:  36545, Training Accuracy:  82.8%, Loss: 0.3519\n",
      "Optimization Iteration:  36609, Training Accuracy:  79.7%, Loss: 0.3463\n",
      "Optimization Iteration:  36673, Training Accuracy:  76.6%, Loss: 0.3910\n",
      "Optimization Iteration:  36737, Training Accuracy:  79.7%, Loss: 0.3575\n",
      "Optimization Iteration:  36801, Training Accuracy:  81.2%, Loss: 0.3438\n",
      "Optimization Iteration:  36865, Training Accuracy:  76.6%, Loss: 0.3653\n",
      "Optimization Iteration:  36929, Training Accuracy:  73.4%, Loss: 0.3771\n",
      "Optimization Iteration:  36993, Training Accuracy:  79.7%, Loss: 0.3210\n",
      "Optimization Iteration:  37057, Training Accuracy:  84.4%, Loss: 0.3436\n",
      "Optimization Iteration:  37121, Training Accuracy:  85.9%, Loss: 0.2566\n",
      "Optimization Iteration:  37185, Training Accuracy:  81.2%, Loss: 0.3697\n",
      "Optimization Iteration:  37249, Training Accuracy:  79.7%, Loss: 0.3917\n",
      "Optimization Iteration:  37313, Training Accuracy:  84.4%, Loss: 0.3195\n",
      "Optimization Iteration:  37377, Training Accuracy:  70.3%, Loss: 0.4561\n",
      "Optimization Iteration:  37441, Training Accuracy:  78.1%, Loss: 0.3394\n",
      "Optimization Iteration:  37505, Training Accuracy:  81.2%, Loss: 0.3125\n",
      "Optimization Iteration:  37569, Training Accuracy:  76.6%, Loss: 0.4591\n",
      "Optimization Iteration:  37633, Training Accuracy:  73.4%, Loss: 0.4244\n",
      "Optimization Iteration:  37697, Training Accuracy:  75.0%, Loss: 0.3482\n",
      "Optimization Iteration:  37761, Training Accuracy:  78.1%, Loss: 0.3960\n",
      "Optimization Iteration:  37825, Training Accuracy:  73.4%, Loss: 0.3730\n",
      "Optimization Iteration:  37889, Training Accuracy:  81.2%, Loss: 0.3378\n",
      "Optimization Iteration:  37953, Training Accuracy:  76.6%, Loss: 0.3694\n",
      "Optimization Iteration:  38017, Training Accuracy:  76.6%, Loss: 0.4257\n",
      "Optimization Iteration:  38081, Training Accuracy:  71.9%, Loss: 0.4127\n",
      "Optimization Iteration:  38145, Training Accuracy:  76.6%, Loss: 0.3634\n",
      "Optimization Iteration:  38209, Training Accuracy:  82.8%, Loss: 0.4535\n",
      "Optimization Iteration:  38273, Training Accuracy:  75.0%, Loss: 0.3227\n",
      "Optimization Iteration:  38337, Training Accuracy:  85.9%, Loss: 0.2767\n",
      "Optimization Iteration:  38401, Training Accuracy:  79.7%, Loss: 0.3943\n",
      "Optimization Iteration:  38465, Training Accuracy:  68.8%, Loss: 0.4353\n",
      "Optimization Iteration:  38529, Training Accuracy:  76.6%, Loss: 0.3990\n",
      "Optimization Iteration:  38593, Training Accuracy:  73.4%, Loss: 0.5182\n",
      "Optimization Iteration:  38657, Training Accuracy:  71.9%, Loss: 0.4470\n",
      "Optimization Iteration:  38721, Training Accuracy:  81.2%, Loss: 0.3203\n",
      "Optimization Iteration:  38785, Training Accuracy:  67.2%, Loss: 0.4576\n",
      "Optimization Iteration:  38849, Training Accuracy:  79.7%, Loss: 0.3329\n",
      "Optimization Iteration:  38913, Training Accuracy:  71.9%, Loss: 0.4370\n",
      "Optimization Iteration:  38977, Training Accuracy:  79.7%, Loss: 0.4064\n",
      "Optimization Iteration:  39041, Training Accuracy:  81.2%, Loss: 0.3808\n",
      "Optimization Iteration:  39105, Training Accuracy:  81.2%, Loss: 0.3926\n",
      "Optimization Iteration:  39169, Training Accuracy:  73.4%, Loss: 0.4259\n",
      "Optimization Iteration:  39233, Training Accuracy:  71.9%, Loss: 0.4915\n",
      "Optimization Iteration:  39297, Training Accuracy:  70.3%, Loss: 0.4444\n",
      "Optimization Iteration:  39361, Training Accuracy:  75.0%, Loss: 0.3695\n",
      "Optimization Iteration:  39425, Training Accuracy:  76.6%, Loss: 0.4584\n",
      "Optimization Iteration:  39489, Training Accuracy:  73.4%, Loss: 0.3780\n",
      "Optimization Iteration:  39553, Training Accuracy:  78.1%, Loss: 0.3477\n",
      "Optimization Iteration:  39617, Training Accuracy:  73.4%, Loss: 0.4535\n",
      "Optimization Iteration:  39681, Training Accuracy:  71.9%, Loss: 0.4448\n",
      "Optimization Iteration:  39745, Training Accuracy:  73.4%, Loss: 0.4536\n",
      "Optimization Iteration:  39809, Training Accuracy:  75.0%, Loss: 0.3568\n",
      "Optimization Iteration:  39873, Training Accuracy:  67.2%, Loss: 0.5008\n",
      "Optimization Iteration:  39937, Training Accuracy:  79.7%, Loss: 0.4251\n",
      "Optimization Iteration:  40001, Training Accuracy:  75.0%, Loss: 0.3825\n",
      "Optimization Iteration:  40065, Training Accuracy:  62.5%, Loss: 0.4296\n",
      "Optimization Iteration:  40129, Training Accuracy:  81.2%, Loss: 0.3402\n",
      "Optimization Iteration:  40193, Training Accuracy:  78.1%, Loss: 0.3592\n",
      "Optimization Iteration:  40257, Training Accuracy:  76.6%, Loss: 0.3919\n",
      "Optimization Iteration:  40321, Training Accuracy:  84.4%, Loss: 0.4373\n",
      "Optimization Iteration:  40385, Training Accuracy:  82.8%, Loss: 0.4166\n",
      "Optimization Iteration:  40449, Training Accuracy:  75.0%, Loss: 0.4029\n",
      "Optimization Iteration:  40513, Training Accuracy:  78.1%, Loss: 0.3768\n",
      "Optimization Iteration:  40577, Training Accuracy:  84.4%, Loss: 0.3367\n",
      "Optimization Iteration:  40641, Training Accuracy:  75.0%, Loss: 0.3687\n",
      "Optimization Iteration:  40705, Training Accuracy:  87.5%, Loss: 0.3429\n",
      "Optimization Iteration:  40769, Training Accuracy:  71.9%, Loss: 0.4360\n",
      "Optimization Iteration:  40833, Training Accuracy:  78.1%, Loss: 0.3520\n",
      "Optimization Iteration:  40897, Training Accuracy:  75.0%, Loss: 0.3646\n",
      "Optimization Iteration:  40961, Training Accuracy:  81.2%, Loss: 0.3758\n",
      "Optimization Iteration:  41025, Training Accuracy:  81.2%, Loss: 0.3393\n",
      "Optimization Iteration:  41089, Training Accuracy:  78.1%, Loss: 0.4093\n",
      "Optimization Iteration:  41153, Training Accuracy:  76.6%, Loss: 0.3315\n",
      "Optimization Iteration:  41217, Training Accuracy:  81.2%, Loss: 0.3197\n",
      "Optimization Iteration:  41281, Training Accuracy:  71.9%, Loss: 0.4040\n",
      "Optimization Iteration:  41345, Training Accuracy:  78.1%, Loss: 0.3375\n",
      "Optimization Iteration:  41409, Training Accuracy:  78.1%, Loss: 0.3917\n",
      "Optimization Iteration:  41473, Training Accuracy:  73.4%, Loss: 0.4278\n",
      "Optimization Iteration:  41537, Training Accuracy:  79.7%, Loss: 0.3716\n",
      "Optimization Iteration:  41601, Training Accuracy:  68.8%, Loss: 0.4077\n",
      "Optimization Iteration:  41665, Training Accuracy:  75.0%, Loss: 0.3728\n",
      "Optimization Iteration:  41729, Training Accuracy:  84.4%, Loss: 0.3069\n",
      "Optimization Iteration:  41793, Training Accuracy:  81.2%, Loss: 0.4277\n",
      "Optimization Iteration:  41857, Training Accuracy:  68.8%, Loss: 0.4198\n",
      "Optimization Iteration:  41921, Training Accuracy:  79.7%, Loss: 0.3237\n",
      "Optimization Iteration:  41985, Training Accuracy:  76.6%, Loss: 0.4789\n",
      "Optimization Iteration:  42049, Training Accuracy:  75.0%, Loss: 0.3793\n",
      "Optimization Iteration:  42113, Training Accuracy:  81.2%, Loss: 0.3556\n",
      "Optimization Iteration:  42177, Training Accuracy:  79.7%, Loss: 0.3909\n",
      "Optimization Iteration:  42241, Training Accuracy:  75.0%, Loss: 0.4198\n",
      "Optimization Iteration:  42305, Training Accuracy:  81.2%, Loss: 0.4390\n",
      "Optimization Iteration:  42369, Training Accuracy:  79.7%, Loss: 0.3479\n",
      "Optimization Iteration:  42433, Training Accuracy:  71.9%, Loss: 0.3928\n",
      "Optimization Iteration:  42497, Training Accuracy:  81.2%, Loss: 0.3686\n",
      "Optimization Iteration:  42561, Training Accuracy:  75.0%, Loss: 0.4127\n",
      "Optimization Iteration:  42625, Training Accuracy:  79.7%, Loss: 0.4043\n",
      "Optimization Iteration:  42689, Training Accuracy:  78.1%, Loss: 0.3009\n",
      "Optimization Iteration:  42753, Training Accuracy:  84.4%, Loss: 0.3759\n",
      "Optimization Iteration:  42817, Training Accuracy:  81.2%, Loss: 0.3204\n",
      "Optimization Iteration:  42881, Training Accuracy:  81.2%, Loss: 0.3666\n",
      "Optimization Iteration:  42945, Training Accuracy:  79.7%, Loss: 0.3472\n",
      "Optimization Iteration:  43009, Training Accuracy:  68.8%, Loss: 0.3974\n",
      "Optimization Iteration:  43073, Training Accuracy:  81.2%, Loss: 0.3774\n",
      "Optimization Iteration:  43137, Training Accuracy:  95.3%, Loss: 0.2774\n",
      "Optimization Iteration:  43201, Training Accuracy:  75.0%, Loss: 0.4312\n",
      "Optimization Iteration:  43265, Training Accuracy:  73.4%, Loss: 0.3642\n",
      "Optimization Iteration:  43329, Training Accuracy:  81.2%, Loss: 0.3887\n",
      "Optimization Iteration:  43393, Training Accuracy:  79.7%, Loss: 0.3634\n",
      "Optimization Iteration:  43457, Training Accuracy:  82.8%, Loss: 0.3360\n",
      "Optimization Iteration:  43521, Training Accuracy:  82.8%, Loss: 0.3576\n",
      "Optimization Iteration:  43585, Training Accuracy:  81.2%, Loss: 0.3126\n",
      "Optimization Iteration:  43649, Training Accuracy:  70.3%, Loss: 0.4967\n",
      "Optimization Iteration:  43713, Training Accuracy:  79.7%, Loss: 0.3408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  43777, Training Accuracy:  73.4%, Loss: 0.3816\n",
      "Optimization Iteration:  43841, Training Accuracy:  82.8%, Loss: 0.3491\n",
      "Optimization Iteration:  43905, Training Accuracy:  78.1%, Loss: 0.3442\n",
      "Optimization Iteration:  43969, Training Accuracy:  84.4%, Loss: 0.3089\n",
      "Optimization Iteration:  44033, Training Accuracy:  76.6%, Loss: 0.3509\n",
      "Optimization Iteration:  44097, Training Accuracy:  71.9%, Loss: 0.4212\n",
      "Optimization Iteration:  44161, Training Accuracy:  71.9%, Loss: 0.3625\n",
      "Optimization Iteration:  44225, Training Accuracy:  76.6%, Loss: 0.3606\n",
      "Optimization Iteration:  44289, Training Accuracy:  70.3%, Loss: 0.4103\n",
      "Optimization Iteration:  44353, Training Accuracy:  73.4%, Loss: 0.4116\n",
      "Optimization Iteration:  44417, Training Accuracy:  75.0%, Loss: 0.3992\n",
      "Optimization Iteration:  44481, Training Accuracy:  75.0%, Loss: 0.4240\n",
      "Optimization Iteration:  44545, Training Accuracy:  84.4%, Loss: 0.3448\n",
      "Optimization Iteration:  44609, Training Accuracy:  79.7%, Loss: 0.3432\n",
      "Optimization Iteration:  44673, Training Accuracy:  73.4%, Loss: 0.4273\n",
      "Optimization Iteration:  44737, Training Accuracy:  70.3%, Loss: 0.4021\n",
      "Optimization Iteration:  44801, Training Accuracy:  81.2%, Loss: 0.3786\n",
      "Optimization Iteration:  44865, Training Accuracy:  68.8%, Loss: 0.4451\n",
      "Optimization Iteration:  44929, Training Accuracy:  76.6%, Loss: 0.3799\n",
      "Optimization Iteration:  44993, Training Accuracy:  76.6%, Loss: 0.3786\n",
      "Optimization Iteration:  45057, Training Accuracy:  73.4%, Loss: 0.4000\n",
      "Optimization Iteration:  45121, Training Accuracy:  87.5%, Loss: 0.3423\n",
      "Optimization Iteration:  45185, Training Accuracy:  76.6%, Loss: 0.3372\n",
      "Optimization Iteration:  45249, Training Accuracy:  78.1%, Loss: 0.4156\n",
      "Optimization Iteration:  45313, Training Accuracy:  84.4%, Loss: 0.3603\n",
      "Optimization Iteration:  45377, Training Accuracy:  78.1%, Loss: 0.4449\n",
      "Optimization Iteration:  45441, Training Accuracy:  75.0%, Loss: 0.4188\n",
      "Optimization Iteration:  45505, Training Accuracy:  78.1%, Loss: 0.3259\n",
      "Optimization Iteration:  45569, Training Accuracy:  76.6%, Loss: 0.4008\n",
      "Optimization Iteration:  45633, Training Accuracy:  79.7%, Loss: 0.3811\n",
      "Optimization Iteration:  45697, Training Accuracy:  84.4%, Loss: 0.3732\n",
      "Optimization Iteration:  45761, Training Accuracy:  81.2%, Loss: 0.3072\n",
      "Optimization Iteration:  45825, Training Accuracy:  81.2%, Loss: 0.3245\n",
      "Optimization Iteration:  45889, Training Accuracy:  79.7%, Loss: 0.3124\n",
      "Optimization Iteration:  45953, Training Accuracy:  68.8%, Loss: 0.4558\n",
      "Optimization Iteration:  46017, Training Accuracy:  71.9%, Loss: 0.4062\n",
      "Optimization Iteration:  46081, Training Accuracy:  82.8%, Loss: 0.3682\n",
      "Optimization Iteration:  46145, Training Accuracy:  70.3%, Loss: 0.4663\n",
      "Optimization Iteration:  46209, Training Accuracy:  71.9%, Loss: 0.3525\n",
      "Optimization Iteration:  46273, Training Accuracy:  75.0%, Loss: 0.4689\n",
      "Optimization Iteration:  46337, Training Accuracy:  75.0%, Loss: 0.4634\n",
      "Optimization Iteration:  46401, Training Accuracy:  73.4%, Loss: 0.4093\n",
      "Optimization Iteration:  46465, Training Accuracy:  79.7%, Loss: 0.3976\n",
      "Optimization Iteration:  46529, Training Accuracy:  76.6%, Loss: 0.4715\n",
      "Optimization Iteration:  46593, Training Accuracy:  75.0%, Loss: 0.4073\n",
      "Optimization Iteration:  46657, Training Accuracy:  82.8%, Loss: 0.3956\n",
      "Optimization Iteration:  46721, Training Accuracy:  79.7%, Loss: 0.3631\n",
      "Optimization Iteration:  46785, Training Accuracy:  75.0%, Loss: 0.4076\n",
      "Optimization Iteration:  46849, Training Accuracy:  68.8%, Loss: 0.4189\n",
      "Optimization Iteration:  46913, Training Accuracy:  78.1%, Loss: 0.3478\n",
      "Optimization Iteration:  46977, Training Accuracy:  70.3%, Loss: 0.4721\n",
      "Optimization Iteration:  47041, Training Accuracy:  76.6%, Loss: 0.3504\n",
      "Optimization Iteration:  47105, Training Accuracy:  68.8%, Loss: 0.4658\n",
      "Optimization Iteration:  47169, Training Accuracy:  78.1%, Loss: 0.4066\n",
      "Optimization Iteration:  47233, Training Accuracy:  71.9%, Loss: 0.4242\n",
      "Optimization Iteration:  47297, Training Accuracy:  81.2%, Loss: 0.3048\n",
      "Optimization Iteration:  47361, Training Accuracy:  81.2%, Loss: 0.3453\n",
      "Optimization Iteration:  47425, Training Accuracy:  71.9%, Loss: 0.3781\n",
      "Optimization Iteration:  47489, Training Accuracy:  71.9%, Loss: 0.4464\n",
      "Optimization Iteration:  47553, Training Accuracy:  78.1%, Loss: 0.4206\n",
      "Optimization Iteration:  47617, Training Accuracy:  76.6%, Loss: 0.3779\n",
      "Optimization Iteration:  47681, Training Accuracy:  85.9%, Loss: 0.3459\n",
      "Optimization Iteration:  47745, Training Accuracy:  75.0%, Loss: 0.4538\n",
      "Optimization Iteration:  47809, Training Accuracy:  79.7%, Loss: 0.3528\n",
      "Optimization Iteration:  47873, Training Accuracy:  84.4%, Loss: 0.3310\n",
      "Optimization Iteration:  47937, Training Accuracy:  65.6%, Loss: 0.4692\n",
      "Optimization Iteration:  48001, Training Accuracy:  81.2%, Loss: 0.3833\n",
      "Optimization Iteration:  48065, Training Accuracy:  81.2%, Loss: 0.3390\n",
      "Optimization Iteration:  48129, Training Accuracy:  64.1%, Loss: 0.5110\n",
      "Optimization Iteration:  48193, Training Accuracy:  79.7%, Loss: 0.4146\n",
      "Optimization Iteration:  48257, Training Accuracy:  75.0%, Loss: 0.3993\n",
      "Optimization Iteration:  48321, Training Accuracy:  76.6%, Loss: 0.3554\n",
      "Optimization Iteration:  48385, Training Accuracy:  79.7%, Loss: 0.3142\n",
      "Optimization Iteration:  48449, Training Accuracy:  79.7%, Loss: 0.3303\n",
      "Optimization Iteration:  48513, Training Accuracy:  78.1%, Loss: 0.3736\n",
      "Optimization Iteration:  48577, Training Accuracy:  70.3%, Loss: 0.4634\n",
      "Optimization Iteration:  48641, Training Accuracy:  76.6%, Loss: 0.3598\n",
      "Optimization Iteration:  48705, Training Accuracy:  84.4%, Loss: 0.3105\n",
      "Optimization Iteration:  48769, Training Accuracy:  84.4%, Loss: 0.3688\n",
      "Optimization Iteration:  48833, Training Accuracy:  81.2%, Loss: 0.4248\n",
      "Optimization Iteration:  48897, Training Accuracy:  81.2%, Loss: 0.3722\n",
      "Optimization Iteration:  48961, Training Accuracy:  84.4%, Loss: 0.3974\n",
      "Optimization Iteration:  49025, Training Accuracy:  73.4%, Loss: 0.4379\n",
      "Optimization Iteration:  49089, Training Accuracy:  79.7%, Loss: 0.3737\n",
      "Optimization Iteration:  49153, Training Accuracy:  73.4%, Loss: 0.3983\n",
      "Optimization Iteration:  49217, Training Accuracy:  78.1%, Loss: 0.3921\n",
      "Optimization Iteration:  49281, Training Accuracy:  70.3%, Loss: 0.4261\n",
      "Optimization Iteration:  49345, Training Accuracy:  78.1%, Loss: 0.3707\n",
      "Optimization Iteration:  49409, Training Accuracy:  78.1%, Loss: 0.3985\n",
      "Optimization Iteration:  49473, Training Accuracy:  73.4%, Loss: 0.3907\n",
      "Optimization Iteration:  49537, Training Accuracy:  81.2%, Loss: 0.3381\n",
      "Optimization Iteration:  49601, Training Accuracy:  73.4%, Loss: 0.3883\n",
      "Optimization Iteration:  49665, Training Accuracy:  78.1%, Loss: 0.3578\n",
      "Optimization Iteration:  49729, Training Accuracy:  65.6%, Loss: 0.4737\n",
      "Optimization Iteration:  49793, Training Accuracy:  75.0%, Loss: 0.3474\n",
      "Optimization Iteration:  49857, Training Accuracy:  84.4%, Loss: 0.2960\n",
      "Optimization Iteration:  49921, Training Accuracy:  71.9%, Loss: 0.4403\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 28\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  73.4%, Loss: 0.4489\n",
      "Optimization Iteration:    129, Training Accuracy:  75.0%, Loss: 0.4296\n",
      "Optimization Iteration:    193, Training Accuracy:  78.1%, Loss: 0.3693\n",
      "Optimization Iteration:    257, Training Accuracy:  70.3%, Loss: 0.3435\n",
      "Optimization Iteration:    321, Training Accuracy:  73.4%, Loss: 0.3814\n",
      "Optimization Iteration:    385, Training Accuracy:  75.0%, Loss: 0.3752\n",
      "Optimization Iteration:    449, Training Accuracy:  84.4%, Loss: 0.2877\n",
      "Optimization Iteration:    513, Training Accuracy:  68.8%, Loss: 0.4236\n",
      "Optimization Iteration:    577, Training Accuracy:  64.1%, Loss: 0.4695\n",
      "Optimization Iteration:    641, Training Accuracy:  78.1%, Loss: 0.3580\n",
      "Optimization Iteration:    705, Training Accuracy:  71.9%, Loss: 0.4414\n",
      "Optimization Iteration:    769, Training Accuracy:  71.9%, Loss: 0.4411\n",
      "Optimization Iteration:    833, Training Accuracy:  78.1%, Loss: 0.3913\n",
      "Optimization Iteration:    897, Training Accuracy:  78.1%, Loss: 0.3610\n",
      "Optimization Iteration:    961, Training Accuracy:  75.0%, Loss: 0.3124\n",
      "Optimization Iteration:   1025, Training Accuracy:  76.6%, Loss: 0.3764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   1089, Training Accuracy:  75.0%, Loss: 0.3371\n",
      "Optimization Iteration:   1153, Training Accuracy:  71.9%, Loss: 0.4038\n",
      "Optimization Iteration:   1217, Training Accuracy:  79.7%, Loss: 0.3689\n",
      "Optimization Iteration:   1281, Training Accuracy:  79.7%, Loss: 0.3919\n",
      "Optimization Iteration:   1345, Training Accuracy:  75.0%, Loss: 0.3765\n",
      "Optimization Iteration:   1409, Training Accuracy:  81.2%, Loss: 0.3436\n",
      "Optimization Iteration:   1473, Training Accuracy:  75.0%, Loss: 0.3915\n",
      "Optimization Iteration:   1537, Training Accuracy:  85.9%, Loss: 0.2883\n",
      "Optimization Iteration:   1601, Training Accuracy:  79.7%, Loss: 0.3101\n",
      "Optimization Iteration:   1665, Training Accuracy:  79.7%, Loss: 0.3923\n",
      "Optimization Iteration:   1729, Training Accuracy:  79.7%, Loss: 0.3254\n",
      "Optimization Iteration:   1793, Training Accuracy:  78.1%, Loss: 0.3759\n",
      "Optimization Iteration:   1857, Training Accuracy:  76.6%, Loss: 0.3605\n",
      "Optimization Iteration:   1921, Training Accuracy:  68.8%, Loss: 0.4795\n",
      "Optimization Iteration:   1985, Training Accuracy:  75.0%, Loss: 0.3672\n",
      "Optimization Iteration:   2049, Training Accuracy:  79.7%, Loss: 0.2824\n",
      "Optimization Iteration:   2113, Training Accuracy:  75.0%, Loss: 0.3720\n",
      "Optimization Iteration:   2177, Training Accuracy:  76.6%, Loss: 0.3998\n",
      "Optimization Iteration:   2241, Training Accuracy:  81.2%, Loss: 0.3764\n",
      "Optimization Iteration:   2305, Training Accuracy:  68.8%, Loss: 0.4310\n",
      "Optimization Iteration:   2369, Training Accuracy:  76.6%, Loss: 0.3829\n",
      "Optimization Iteration:   2433, Training Accuracy:  78.1%, Loss: 0.3808\n",
      "Optimization Iteration:   2497, Training Accuracy:  82.8%, Loss: 0.3258\n",
      "Optimization Iteration:   2561, Training Accuracy:  73.4%, Loss: 0.3796\n",
      "Optimization Iteration:   2625, Training Accuracy:  84.4%, Loss: 0.3397\n",
      "Optimization Iteration:   2689, Training Accuracy:  81.2%, Loss: 0.3209\n",
      "Optimization Iteration:   2753, Training Accuracy:  75.0%, Loss: 0.4200\n",
      "Optimization Iteration:   2817, Training Accuracy:  76.6%, Loss: 0.3939\n",
      "Optimization Iteration:   2881, Training Accuracy:  82.8%, Loss: 0.3499\n",
      "Optimization Iteration:   2945, Training Accuracy:  68.8%, Loss: 0.5305\n",
      "Optimization Iteration:   3009, Training Accuracy:  71.9%, Loss: 0.4539\n",
      "Optimization Iteration:   3073, Training Accuracy:  79.7%, Loss: 0.3880\n",
      "Optimization Iteration:   3137, Training Accuracy:  81.2%, Loss: 0.3884\n",
      "Optimization Iteration:   3201, Training Accuracy:  84.4%, Loss: 0.3021\n",
      "Optimization Iteration:   3265, Training Accuracy:  76.6%, Loss: 0.3995\n",
      "Optimization Iteration:   3329, Training Accuracy:  85.9%, Loss: 0.3704\n",
      "Optimization Iteration:   3393, Training Accuracy:  71.9%, Loss: 0.3222\n",
      "Optimization Iteration:   3457, Training Accuracy:  71.9%, Loss: 0.4463\n",
      "Optimization Iteration:   3521, Training Accuracy:  73.4%, Loss: 0.3676\n",
      "Optimization Iteration:   3585, Training Accuracy:  79.7%, Loss: 0.3879\n",
      "Optimization Iteration:   3649, Training Accuracy:  76.6%, Loss: 0.3675\n",
      "Optimization Iteration:   3713, Training Accuracy:  76.6%, Loss: 0.3819\n",
      "Optimization Iteration:   3777, Training Accuracy:  70.3%, Loss: 0.4156\n",
      "Optimization Iteration:   3841, Training Accuracy:  76.6%, Loss: 0.3890\n",
      "Optimization Iteration:   3905, Training Accuracy:  78.1%, Loss: 0.4061\n",
      "Optimization Iteration:   3969, Training Accuracy:  79.7%, Loss: 0.4195\n",
      "Optimization Iteration:   4033, Training Accuracy:  82.8%, Loss: 0.2982\n",
      "Optimization Iteration:   4097, Training Accuracy:  84.4%, Loss: 0.3265\n",
      "Optimization Iteration:   4161, Training Accuracy:  71.9%, Loss: 0.4917\n",
      "Optimization Iteration:   4225, Training Accuracy:  79.7%, Loss: 0.3482\n",
      "Optimization Iteration:   4289, Training Accuracy:  73.4%, Loss: 0.3790\n",
      "Optimization Iteration:   4353, Training Accuracy:  79.7%, Loss: 0.3450\n",
      "Optimization Iteration:   4417, Training Accuracy:  68.8%, Loss: 0.4065\n",
      "Optimization Iteration:   4481, Training Accuracy:  67.2%, Loss: 0.4505\n",
      "Optimization Iteration:   4545, Training Accuracy:  75.0%, Loss: 0.3747\n",
      "Optimization Iteration:   4609, Training Accuracy:  82.8%, Loss: 0.3459\n",
      "Optimization Iteration:   4673, Training Accuracy:  82.8%, Loss: 0.3563\n",
      "Optimization Iteration:   4737, Training Accuracy:  73.4%, Loss: 0.3984\n",
      "Optimization Iteration:   4801, Training Accuracy:  75.0%, Loss: 0.4198\n",
      "Optimization Iteration:   4865, Training Accuracy:  87.5%, Loss: 0.3168\n",
      "Optimization Iteration:   4929, Training Accuracy:  81.2%, Loss: 0.3216\n",
      "Optimization Iteration:   4993, Training Accuracy:  85.9%, Loss: 0.3478\n",
      "Optimization Iteration:   5057, Training Accuracy:  64.1%, Loss: 0.5275\n",
      "Optimization Iteration:   5121, Training Accuracy:  81.2%, Loss: 0.3539\n",
      "Optimization Iteration:   5185, Training Accuracy:  79.7%, Loss: 0.3668\n",
      "Optimization Iteration:   5249, Training Accuracy:  68.8%, Loss: 0.4646\n",
      "Optimization Iteration:   5313, Training Accuracy:  81.2%, Loss: 0.3498\n",
      "Optimization Iteration:   5377, Training Accuracy:  76.6%, Loss: 0.3645\n",
      "Optimization Iteration:   5441, Training Accuracy:  75.0%, Loss: 0.3463\n",
      "Optimization Iteration:   5505, Training Accuracy:  81.2%, Loss: 0.3616\n",
      "Optimization Iteration:   5569, Training Accuracy:  81.2%, Loss: 0.2846\n",
      "Optimization Iteration:   5633, Training Accuracy:  82.8%, Loss: 0.3002\n",
      "Optimization Iteration:   5697, Training Accuracy:  79.7%, Loss: 0.3663\n",
      "Optimization Iteration:   5761, Training Accuracy:  85.9%, Loss: 0.3451\n",
      "Optimization Iteration:   5825, Training Accuracy:  70.3%, Loss: 0.4253\n",
      "Optimization Iteration:   5889, Training Accuracy:  79.7%, Loss: 0.3951\n",
      "Optimization Iteration:   5953, Training Accuracy:  71.9%, Loss: 0.4324\n",
      "Optimization Iteration:   6017, Training Accuracy:  73.4%, Loss: 0.4173\n",
      "Optimization Iteration:   6081, Training Accuracy:  75.0%, Loss: 0.4010\n",
      "Optimization Iteration:   6145, Training Accuracy:  71.9%, Loss: 0.4575\n",
      "Optimization Iteration:   6209, Training Accuracy:  75.0%, Loss: 0.3373\n",
      "Optimization Iteration:   6273, Training Accuracy:  81.2%, Loss: 0.4055\n",
      "Optimization Iteration:   6337, Training Accuracy:  68.8%, Loss: 0.5041\n",
      "Optimization Iteration:   6401, Training Accuracy:  78.1%, Loss: 0.3906\n",
      "Optimization Iteration:   6465, Training Accuracy:  79.7%, Loss: 0.2951\n",
      "Optimization Iteration:   6529, Training Accuracy:  84.4%, Loss: 0.3738\n",
      "Optimization Iteration:   6593, Training Accuracy:  78.1%, Loss: 0.3529\n",
      "Optimization Iteration:   6657, Training Accuracy:  75.0%, Loss: 0.3952\n",
      "Optimization Iteration:   6721, Training Accuracy:  81.2%, Loss: 0.2868\n",
      "Optimization Iteration:   6785, Training Accuracy:  70.3%, Loss: 0.4460\n",
      "Optimization Iteration:   6849, Training Accuracy:  79.7%, Loss: 0.3446\n",
      "Optimization Iteration:   6913, Training Accuracy:  87.5%, Loss: 0.3389\n",
      "Optimization Iteration:   6977, Training Accuracy:  79.7%, Loss: 0.3518\n",
      "Optimization Iteration:   7041, Training Accuracy:  81.2%, Loss: 0.3225\n",
      "Optimization Iteration:   7105, Training Accuracy:  76.6%, Loss: 0.3518\n",
      "Optimization Iteration:   7169, Training Accuracy:  87.5%, Loss: 0.3324\n",
      "Optimization Iteration:   7233, Training Accuracy:  79.7%, Loss: 0.4721\n",
      "Optimization Iteration:   7297, Training Accuracy:  78.1%, Loss: 0.4607\n",
      "Optimization Iteration:   7361, Training Accuracy:  70.3%, Loss: 0.3608\n",
      "Optimization Iteration:   7425, Training Accuracy:  70.3%, Loss: 0.3705\n",
      "Optimization Iteration:   7489, Training Accuracy:  81.2%, Loss: 0.3661\n",
      "Optimization Iteration:   7553, Training Accuracy:  70.3%, Loss: 0.4748\n",
      "Optimization Iteration:   7617, Training Accuracy:  76.6%, Loss: 0.4197\n",
      "Optimization Iteration:   7681, Training Accuracy:  76.6%, Loss: 0.4556\n",
      "Optimization Iteration:   7745, Training Accuracy:  79.7%, Loss: 0.3484\n",
      "Optimization Iteration:   7809, Training Accuracy:  84.4%, Loss: 0.4031\n",
      "Optimization Iteration:   7873, Training Accuracy:  73.4%, Loss: 0.3836\n",
      "Optimization Iteration:   7937, Training Accuracy:  84.4%, Loss: 0.3182\n",
      "Optimization Iteration:   8001, Training Accuracy:  75.0%, Loss: 0.3779\n",
      "Optimization Iteration:   8065, Training Accuracy:  70.3%, Loss: 0.4356\n",
      "Optimization Iteration:   8129, Training Accuracy:  71.9%, Loss: 0.3809\n",
      "Optimization Iteration:   8193, Training Accuracy:  71.9%, Loss: 0.4358\n",
      "Optimization Iteration:   8257, Training Accuracy:  79.7%, Loss: 0.3715\n",
      "Optimization Iteration:   8321, Training Accuracy:  76.6%, Loss: 0.3787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   8385, Training Accuracy:  64.1%, Loss: 0.4670\n",
      "Optimization Iteration:   8449, Training Accuracy:  71.9%, Loss: 0.4541\n",
      "Optimization Iteration:   8513, Training Accuracy:  79.7%, Loss: 0.3704\n",
      "Optimization Iteration:   8577, Training Accuracy:  76.6%, Loss: 0.3889\n",
      "Optimization Iteration:   8641, Training Accuracy:  82.8%, Loss: 0.4102\n",
      "Optimization Iteration:   8705, Training Accuracy:  84.4%, Loss: 0.3601\n",
      "Optimization Iteration:   8769, Training Accuracy:  75.0%, Loss: 0.3734\n",
      "Optimization Iteration:   8833, Training Accuracy:  75.0%, Loss: 0.3468\n",
      "Optimization Iteration:   8897, Training Accuracy:  71.9%, Loss: 0.4535\n",
      "Optimization Iteration:   8961, Training Accuracy:  68.8%, Loss: 0.4067\n",
      "Optimization Iteration:   9025, Training Accuracy:  71.9%, Loss: 0.5041\n",
      "Optimization Iteration:   9089, Training Accuracy:  75.0%, Loss: 0.4482\n",
      "Optimization Iteration:   9153, Training Accuracy:  76.6%, Loss: 0.4088\n",
      "Optimization Iteration:   9217, Training Accuracy:  78.1%, Loss: 0.3915\n",
      "Optimization Iteration:   9281, Training Accuracy:  76.6%, Loss: 0.3610\n",
      "Optimization Iteration:   9345, Training Accuracy:  78.1%, Loss: 0.4647\n",
      "Optimization Iteration:   9409, Training Accuracy:  75.0%, Loss: 0.4411\n",
      "Optimization Iteration:   9473, Training Accuracy:  76.6%, Loss: 0.3521\n",
      "Optimization Iteration:   9537, Training Accuracy:  84.4%, Loss: 0.3090\n",
      "Optimization Iteration:   9601, Training Accuracy:  79.7%, Loss: 0.3942\n",
      "Optimization Iteration:   9665, Training Accuracy:  76.6%, Loss: 0.3868\n",
      "Optimization Iteration:   9729, Training Accuracy:  76.6%, Loss: 0.4163\n",
      "Optimization Iteration:   9793, Training Accuracy:  84.4%, Loss: 0.3365\n",
      "Optimization Iteration:   9857, Training Accuracy:  65.6%, Loss: 0.4602\n",
      "Optimization Iteration:   9921, Training Accuracy:  76.6%, Loss: 0.3097\n",
      "Optimization Iteration:   9985, Training Accuracy:  68.8%, Loss: 0.4744\n",
      "Optimization Iteration:  10049, Training Accuracy:  78.1%, Loss: 0.3473\n",
      "Optimization Iteration:  10113, Training Accuracy:  78.1%, Loss: 0.3709\n",
      "Optimization Iteration:  10177, Training Accuracy:  76.6%, Loss: 0.3840\n",
      "Optimization Iteration:  10241, Training Accuracy:  65.6%, Loss: 0.4177\n",
      "Optimization Iteration:  10305, Training Accuracy:  84.4%, Loss: 0.3383\n",
      "Optimization Iteration:  10369, Training Accuracy:  81.2%, Loss: 0.3755\n",
      "Optimization Iteration:  10433, Training Accuracy:  76.6%, Loss: 0.3679\n",
      "Optimization Iteration:  10497, Training Accuracy:  71.9%, Loss: 0.4730\n",
      "Optimization Iteration:  10561, Training Accuracy:  84.4%, Loss: 0.3213\n",
      "Optimization Iteration:  10625, Training Accuracy:  76.6%, Loss: 0.3777\n",
      "Optimization Iteration:  10689, Training Accuracy:  76.6%, Loss: 0.3958\n",
      "Optimization Iteration:  10753, Training Accuracy:  79.7%, Loss: 0.4255\n",
      "Optimization Iteration:  10817, Training Accuracy:  76.6%, Loss: 0.4289\n",
      "Optimization Iteration:  10881, Training Accuracy:  79.7%, Loss: 0.3236\n",
      "Optimization Iteration:  10945, Training Accuracy:  82.8%, Loss: 0.3865\n",
      "Optimization Iteration:  11009, Training Accuracy:  82.8%, Loss: 0.3684\n",
      "Optimization Iteration:  11073, Training Accuracy:  79.7%, Loss: 0.3311\n",
      "Optimization Iteration:  11137, Training Accuracy:  78.1%, Loss: 0.3760\n",
      "Optimization Iteration:  11201, Training Accuracy:  82.8%, Loss: 0.3121\n",
      "Optimization Iteration:  11265, Training Accuracy:  85.9%, Loss: 0.2939\n",
      "Optimization Iteration:  11329, Training Accuracy:  76.6%, Loss: 0.4437\n",
      "Optimization Iteration:  11393, Training Accuracy:  75.0%, Loss: 0.4329\n",
      "Optimization Iteration:  11457, Training Accuracy:  73.4%, Loss: 0.4352\n",
      "Optimization Iteration:  11521, Training Accuracy:  78.1%, Loss: 0.3867\n",
      "Optimization Iteration:  11585, Training Accuracy:  71.9%, Loss: 0.3759\n",
      "Optimization Iteration:  11649, Training Accuracy:  79.7%, Loss: 0.4287\n",
      "Optimization Iteration:  11713, Training Accuracy:  73.4%, Loss: 0.4004\n",
      "Optimization Iteration:  11777, Training Accuracy:  65.6%, Loss: 0.4978\n",
      "Optimization Iteration:  11841, Training Accuracy:  82.8%, Loss: 0.3466\n",
      "Optimization Iteration:  11905, Training Accuracy:  79.7%, Loss: 0.3771\n",
      "Optimization Iteration:  11969, Training Accuracy:  81.2%, Loss: 0.3622\n",
      "Optimization Iteration:  12033, Training Accuracy:  73.4%, Loss: 0.4214\n",
      "Optimization Iteration:  12097, Training Accuracy:  73.4%, Loss: 0.4468\n",
      "Optimization Iteration:  12161, Training Accuracy:  76.6%, Loss: 0.4463\n",
      "Optimization Iteration:  12225, Training Accuracy:  82.8%, Loss: 0.3103\n",
      "Optimization Iteration:  12289, Training Accuracy:  81.2%, Loss: 0.3577\n",
      "Optimization Iteration:  12353, Training Accuracy:  78.1%, Loss: 0.3281\n",
      "Optimization Iteration:  12417, Training Accuracy:  81.2%, Loss: 0.3096\n",
      "Optimization Iteration:  12481, Training Accuracy:  79.7%, Loss: 0.3708\n",
      "Optimization Iteration:  12545, Training Accuracy:  67.2%, Loss: 0.4448\n",
      "Optimization Iteration:  12609, Training Accuracy:  79.7%, Loss: 0.3754\n",
      "Optimization Iteration:  12673, Training Accuracy:  73.4%, Loss: 0.4468\n",
      "Optimization Iteration:  12737, Training Accuracy:  76.6%, Loss: 0.4438\n",
      "Optimization Iteration:  12801, Training Accuracy:  79.7%, Loss: 0.3904\n",
      "Optimization Iteration:  12865, Training Accuracy:  76.6%, Loss: 0.4082\n",
      "Optimization Iteration:  12929, Training Accuracy:  81.2%, Loss: 0.3499\n",
      "Optimization Iteration:  12993, Training Accuracy:  78.1%, Loss: 0.3513\n",
      "Optimization Iteration:  13057, Training Accuracy:  71.9%, Loss: 0.4871\n",
      "Optimization Iteration:  13121, Training Accuracy:  78.1%, Loss: 0.3628\n",
      "Optimization Iteration:  13185, Training Accuracy:  81.2%, Loss: 0.4422\n",
      "Optimization Iteration:  13249, Training Accuracy:  78.1%, Loss: 0.4414\n",
      "Optimization Iteration:  13313, Training Accuracy:  68.8%, Loss: 0.4805\n",
      "Optimization Iteration:  13377, Training Accuracy:  68.8%, Loss: 0.4830\n",
      "Optimization Iteration:  13441, Training Accuracy:  84.4%, Loss: 0.3088\n",
      "Optimization Iteration:  13505, Training Accuracy:  73.4%, Loss: 0.3984\n",
      "Optimization Iteration:  13569, Training Accuracy:  81.2%, Loss: 0.3479\n",
      "Optimization Iteration:  13633, Training Accuracy:  76.6%, Loss: 0.3936\n",
      "Optimization Iteration:  13697, Training Accuracy:  71.9%, Loss: 0.4063\n",
      "Optimization Iteration:  13761, Training Accuracy:  76.6%, Loss: 0.3657\n",
      "Optimization Iteration:  13825, Training Accuracy:  81.2%, Loss: 0.3157\n",
      "Optimization Iteration:  13889, Training Accuracy:  78.1%, Loss: 0.3795\n",
      "Optimization Iteration:  13953, Training Accuracy:  82.8%, Loss: 0.3718\n",
      "Optimization Iteration:  14017, Training Accuracy:  84.4%, Loss: 0.3491\n",
      "Optimization Iteration:  14081, Training Accuracy:  67.2%, Loss: 0.4180\n",
      "Optimization Iteration:  14145, Training Accuracy:  76.6%, Loss: 0.3523\n",
      "Optimization Iteration:  14209, Training Accuracy:  79.7%, Loss: 0.4340\n",
      "Optimization Iteration:  14273, Training Accuracy:  65.6%, Loss: 0.5020\n",
      "Optimization Iteration:  14337, Training Accuracy:  81.2%, Loss: 0.3103\n",
      "Optimization Iteration:  14401, Training Accuracy:  87.5%, Loss: 0.3663\n",
      "Optimization Iteration:  14465, Training Accuracy:  68.8%, Loss: 0.5075\n",
      "Optimization Iteration:  14529, Training Accuracy:  76.6%, Loss: 0.3752\n",
      "Optimization Iteration:  14593, Training Accuracy:  87.5%, Loss: 0.3238\n",
      "Optimization Iteration:  14657, Training Accuracy:  70.3%, Loss: 0.4903\n",
      "Optimization Iteration:  14721, Training Accuracy:  79.7%, Loss: 0.3828\n",
      "Optimization Iteration:  14785, Training Accuracy:  75.0%, Loss: 0.4455\n",
      "Optimization Iteration:  14849, Training Accuracy:  75.0%, Loss: 0.3621\n",
      "Optimization Iteration:  14913, Training Accuracy:  85.9%, Loss: 0.3079\n",
      "Optimization Iteration:  14977, Training Accuracy:  79.7%, Loss: 0.3613\n",
      "Optimization Iteration:  15041, Training Accuracy:  76.6%, Loss: 0.3408\n",
      "Optimization Iteration:  15105, Training Accuracy:  81.2%, Loss: 0.3717\n",
      "Optimization Iteration:  15169, Training Accuracy:  79.7%, Loss: 0.3783\n",
      "Optimization Iteration:  15233, Training Accuracy:  79.7%, Loss: 0.3711\n",
      "Optimization Iteration:  15297, Training Accuracy:  82.8%, Loss: 0.3174\n",
      "Optimization Iteration:  15361, Training Accuracy:  79.7%, Loss: 0.3735\n",
      "Optimization Iteration:  15425, Training Accuracy:  76.6%, Loss: 0.3778\n",
      "Optimization Iteration:  15489, Training Accuracy:  73.4%, Loss: 0.4631\n",
      "Optimization Iteration:  15553, Training Accuracy:  65.6%, Loss: 0.3904\n",
      "Optimization Iteration:  15617, Training Accuracy:  76.6%, Loss: 0.3335\n",
      "Optimization Iteration:  15681, Training Accuracy:  73.4%, Loss: 0.4022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  15745, Training Accuracy:  82.8%, Loss: 0.3102\n",
      "Optimization Iteration:  15809, Training Accuracy:  70.3%, Loss: 0.4212\n",
      "Optimization Iteration:  15873, Training Accuracy:  70.3%, Loss: 0.4122\n",
      "Optimization Iteration:  15937, Training Accuracy:  75.0%, Loss: 0.4310\n",
      "Optimization Iteration:  16001, Training Accuracy:  76.6%, Loss: 0.4190\n",
      "Optimization Iteration:  16065, Training Accuracy:  68.8%, Loss: 0.4337\n",
      "Optimization Iteration:  16129, Training Accuracy:  79.7%, Loss: 0.3665\n",
      "Optimization Iteration:  16193, Training Accuracy:  78.1%, Loss: 0.4346\n",
      "Optimization Iteration:  16257, Training Accuracy:  81.2%, Loss: 0.4094\n",
      "Optimization Iteration:  16321, Training Accuracy:  73.4%, Loss: 0.4330\n",
      "Optimization Iteration:  16385, Training Accuracy:  84.4%, Loss: 0.3499\n",
      "Optimization Iteration:  16449, Training Accuracy:  75.0%, Loss: 0.3909\n",
      "Optimization Iteration:  16513, Training Accuracy:  84.4%, Loss: 0.3568\n",
      "Optimization Iteration:  16577, Training Accuracy:  67.2%, Loss: 0.4100\n",
      "Optimization Iteration:  16641, Training Accuracy:  78.1%, Loss: 0.4103\n",
      "Optimization Iteration:  16705, Training Accuracy:  78.1%, Loss: 0.3917\n",
      "Optimization Iteration:  16769, Training Accuracy:  75.0%, Loss: 0.3647\n",
      "Optimization Iteration:  16833, Training Accuracy:  76.6%, Loss: 0.3382\n",
      "Optimization Iteration:  16897, Training Accuracy:  75.0%, Loss: 0.3543\n",
      "Optimization Iteration:  16961, Training Accuracy:  73.4%, Loss: 0.3945\n",
      "Optimization Iteration:  17025, Training Accuracy:  68.8%, Loss: 0.4489\n",
      "Optimization Iteration:  17089, Training Accuracy:  70.3%, Loss: 0.4704\n",
      "Optimization Iteration:  17153, Training Accuracy:  79.7%, Loss: 0.3790\n",
      "Optimization Iteration:  17217, Training Accuracy:  73.4%, Loss: 0.5122\n",
      "Optimization Iteration:  17281, Training Accuracy:  71.9%, Loss: 0.4281\n",
      "Optimization Iteration:  17345, Training Accuracy:  82.8%, Loss: 0.2905\n",
      "Optimization Iteration:  17409, Training Accuracy:  75.0%, Loss: 0.3822\n",
      "Optimization Iteration:  17473, Training Accuracy:  75.0%, Loss: 0.4251\n",
      "Optimization Iteration:  17537, Training Accuracy:  79.7%, Loss: 0.3188\n",
      "Optimization Iteration:  17601, Training Accuracy:  79.7%, Loss: 0.4277\n",
      "Optimization Iteration:  17665, Training Accuracy:  89.1%, Loss: 0.2664\n",
      "Optimization Iteration:  17729, Training Accuracy:  81.2%, Loss: 0.3255\n",
      "Optimization Iteration:  17793, Training Accuracy:  71.9%, Loss: 0.3826\n",
      "Optimization Iteration:  17857, Training Accuracy:  73.4%, Loss: 0.4399\n",
      "Optimization Iteration:  17921, Training Accuracy:  82.8%, Loss: 0.3355\n",
      "Optimization Iteration:  17985, Training Accuracy:  73.4%, Loss: 0.3699\n",
      "Optimization Iteration:  18049, Training Accuracy:  73.4%, Loss: 0.3848\n",
      "Optimization Iteration:  18113, Training Accuracy:  68.8%, Loss: 0.4516\n",
      "Optimization Iteration:  18177, Training Accuracy:  79.7%, Loss: 0.4125\n",
      "Optimization Iteration:  18241, Training Accuracy:  73.4%, Loss: 0.3844\n",
      "Optimization Iteration:  18305, Training Accuracy:  67.2%, Loss: 0.3967\n",
      "Optimization Iteration:  18369, Training Accuracy:  75.0%, Loss: 0.3561\n",
      "Optimization Iteration:  18433, Training Accuracy:  75.0%, Loss: 0.4258\n",
      "Optimization Iteration:  18497, Training Accuracy:  79.7%, Loss: 0.3341\n",
      "Optimization Iteration:  18561, Training Accuracy:  76.6%, Loss: 0.3472\n",
      "Optimization Iteration:  18625, Training Accuracy:  76.6%, Loss: 0.4357\n",
      "Optimization Iteration:  18689, Training Accuracy:  73.4%, Loss: 0.4792\n",
      "Optimization Iteration:  18753, Training Accuracy:  71.9%, Loss: 0.4156\n",
      "Optimization Iteration:  18817, Training Accuracy:  76.6%, Loss: 0.3366\n",
      "Optimization Iteration:  18881, Training Accuracy:  78.1%, Loss: 0.3960\n",
      "Optimization Iteration:  18945, Training Accuracy:  73.4%, Loss: 0.4175\n",
      "Optimization Iteration:  19009, Training Accuracy:  81.2%, Loss: 0.3542\n",
      "Optimization Iteration:  19073, Training Accuracy:  85.9%, Loss: 0.3391\n",
      "Optimization Iteration:  19137, Training Accuracy:  73.4%, Loss: 0.4795\n",
      "Optimization Iteration:  19201, Training Accuracy:  71.9%, Loss: 0.4303\n",
      "Optimization Iteration:  19265, Training Accuracy:  81.2%, Loss: 0.3648\n",
      "Optimization Iteration:  19329, Training Accuracy:  78.1%, Loss: 0.3576\n",
      "Optimization Iteration:  19393, Training Accuracy:  76.6%, Loss: 0.4023\n",
      "Optimization Iteration:  19457, Training Accuracy:  78.1%, Loss: 0.4049\n",
      "Optimization Iteration:  19521, Training Accuracy:  78.1%, Loss: 0.4303\n",
      "Optimization Iteration:  19585, Training Accuracy:  76.6%, Loss: 0.3782\n",
      "Optimization Iteration:  19649, Training Accuracy:  75.0%, Loss: 0.3766\n",
      "Optimization Iteration:  19713, Training Accuracy:  78.1%, Loss: 0.3635\n",
      "Optimization Iteration:  19777, Training Accuracy:  76.6%, Loss: 0.4320\n",
      "Optimization Iteration:  19841, Training Accuracy:  73.4%, Loss: 0.4530\n",
      "Optimization Iteration:  19905, Training Accuracy:  71.9%, Loss: 0.3970\n",
      "Optimization Iteration:  19969, Training Accuracy:  76.6%, Loss: 0.3529\n",
      "Optimization Iteration:  20033, Training Accuracy:  73.4%, Loss: 0.3795\n",
      "Optimization Iteration:  20097, Training Accuracy:  65.6%, Loss: 0.4617\n",
      "Optimization Iteration:  20161, Training Accuracy:  73.4%, Loss: 0.3663\n",
      "Optimization Iteration:  20225, Training Accuracy:  75.0%, Loss: 0.3883\n",
      "Optimization Iteration:  20289, Training Accuracy:  73.4%, Loss: 0.4210\n",
      "Optimization Iteration:  20353, Training Accuracy:  82.8%, Loss: 0.3330\n",
      "Optimization Iteration:  20417, Training Accuracy:  75.0%, Loss: 0.4342\n",
      "Optimization Iteration:  20481, Training Accuracy:  84.4%, Loss: 0.3130\n",
      "Optimization Iteration:  20545, Training Accuracy:  82.8%, Loss: 0.3346\n",
      "Optimization Iteration:  20609, Training Accuracy:  68.8%, Loss: 0.4946\n",
      "Optimization Iteration:  20673, Training Accuracy:  68.8%, Loss: 0.4451\n",
      "Optimization Iteration:  20737, Training Accuracy:  89.1%, Loss: 0.3775\n",
      "Optimization Iteration:  20801, Training Accuracy:  79.7%, Loss: 0.3682\n",
      "Optimization Iteration:  20865, Training Accuracy:  81.2%, Loss: 0.3525\n",
      "Optimization Iteration:  20929, Training Accuracy:  76.6%, Loss: 0.3393\n",
      "Optimization Iteration:  20993, Training Accuracy:  85.9%, Loss: 0.3628\n",
      "Optimization Iteration:  21057, Training Accuracy:  78.1%, Loss: 0.3499\n",
      "Optimization Iteration:  21121, Training Accuracy:  79.7%, Loss: 0.3156\n",
      "Optimization Iteration:  21185, Training Accuracy:  75.0%, Loss: 0.3868\n",
      "Optimization Iteration:  21249, Training Accuracy:  65.6%, Loss: 0.4575\n",
      "Optimization Iteration:  21313, Training Accuracy:  76.6%, Loss: 0.4332\n",
      "Optimization Iteration:  21377, Training Accuracy:  75.0%, Loss: 0.3265\n",
      "Optimization Iteration:  21441, Training Accuracy:  76.6%, Loss: 0.3298\n",
      "Optimization Iteration:  21505, Training Accuracy:  81.2%, Loss: 0.3676\n",
      "Optimization Iteration:  21569, Training Accuracy:  75.0%, Loss: 0.3530\n",
      "Optimization Iteration:  21633, Training Accuracy:  78.1%, Loss: 0.4328\n",
      "Optimization Iteration:  21697, Training Accuracy:  70.3%, Loss: 0.4856\n",
      "Optimization Iteration:  21761, Training Accuracy:  78.1%, Loss: 0.3140\n",
      "Optimization Iteration:  21825, Training Accuracy:  70.3%, Loss: 0.3989\n",
      "Optimization Iteration:  21889, Training Accuracy:  82.8%, Loss: 0.3273\n",
      "Optimization Iteration:  21953, Training Accuracy:  67.2%, Loss: 0.5343\n",
      "Optimization Iteration:  22017, Training Accuracy:  81.2%, Loss: 0.3467\n",
      "Optimization Iteration:  22081, Training Accuracy:  85.9%, Loss: 0.3683\n",
      "Optimization Iteration:  22145, Training Accuracy:  81.2%, Loss: 0.3539\n",
      "Optimization Iteration:  22209, Training Accuracy:  75.0%, Loss: 0.4315\n",
      "Optimization Iteration:  22273, Training Accuracy:  75.0%, Loss: 0.4248\n",
      "Optimization Iteration:  22337, Training Accuracy:  73.4%, Loss: 0.3391\n",
      "Optimization Iteration:  22401, Training Accuracy:  82.8%, Loss: 0.3633\n",
      "Optimization Iteration:  22465, Training Accuracy:  65.6%, Loss: 0.4396\n",
      "Optimization Iteration:  22529, Training Accuracy:  81.2%, Loss: 0.3310\n",
      "Optimization Iteration:  22593, Training Accuracy:  81.2%, Loss: 0.3596\n",
      "Optimization Iteration:  22657, Training Accuracy:  73.4%, Loss: 0.4641\n",
      "Optimization Iteration:  22721, Training Accuracy:  70.3%, Loss: 0.3617\n",
      "Optimization Iteration:  22785, Training Accuracy:  84.4%, Loss: 0.3782\n",
      "Optimization Iteration:  22849, Training Accuracy:  71.9%, Loss: 0.3889\n",
      "Optimization Iteration:  22913, Training Accuracy:  68.8%, Loss: 0.4852\n",
      "Optimization Iteration:  22977, Training Accuracy:  75.0%, Loss: 0.3688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  23041, Training Accuracy:  78.1%, Loss: 0.3641\n",
      "Optimization Iteration:  23105, Training Accuracy:  76.6%, Loss: 0.3254\n",
      "Optimization Iteration:  23169, Training Accuracy:  81.2%, Loss: 0.3737\n",
      "Optimization Iteration:  23233, Training Accuracy:  70.3%, Loss: 0.4397\n",
      "Optimization Iteration:  23297, Training Accuracy:  73.4%, Loss: 0.4206\n",
      "Optimization Iteration:  23361, Training Accuracy:  76.6%, Loss: 0.4346\n",
      "Optimization Iteration:  23425, Training Accuracy:  82.8%, Loss: 0.3874\n",
      "Optimization Iteration:  23489, Training Accuracy:  84.4%, Loss: 0.3636\n",
      "Optimization Iteration:  23553, Training Accuracy:  76.6%, Loss: 0.3701\n",
      "Optimization Iteration:  23617, Training Accuracy:  79.7%, Loss: 0.3580\n",
      "Optimization Iteration:  23681, Training Accuracy:  76.6%, Loss: 0.4488\n",
      "Optimization Iteration:  23745, Training Accuracy:  82.8%, Loss: 0.3600\n",
      "Optimization Iteration:  23809, Training Accuracy:  75.0%, Loss: 0.4200\n",
      "Optimization Iteration:  23873, Training Accuracy:  82.8%, Loss: 0.3604\n",
      "Optimization Iteration:  23937, Training Accuracy:  70.3%, Loss: 0.4278\n",
      "Optimization Iteration:  24001, Training Accuracy:  73.4%, Loss: 0.3595\n",
      "Optimization Iteration:  24065, Training Accuracy:  68.8%, Loss: 0.3946\n",
      "Optimization Iteration:  24129, Training Accuracy:  81.2%, Loss: 0.4166\n",
      "Optimization Iteration:  24193, Training Accuracy:  71.9%, Loss: 0.4574\n",
      "Optimization Iteration:  24257, Training Accuracy:  81.2%, Loss: 0.4112\n",
      "Optimization Iteration:  24321, Training Accuracy:  65.6%, Loss: 0.4617\n",
      "Optimization Iteration:  24385, Training Accuracy:  79.7%, Loss: 0.4175\n",
      "Optimization Iteration:  24449, Training Accuracy:  82.8%, Loss: 0.3107\n",
      "Optimization Iteration:  24513, Training Accuracy:  68.8%, Loss: 0.4525\n",
      "Optimization Iteration:  24577, Training Accuracy:  67.2%, Loss: 0.4708\n",
      "Optimization Iteration:  24641, Training Accuracy:  82.8%, Loss: 0.3475\n",
      "Optimization Iteration:  24705, Training Accuracy:  81.2%, Loss: 0.3158\n",
      "Optimization Iteration:  24769, Training Accuracy:  79.7%, Loss: 0.3523\n",
      "Optimization Iteration:  24833, Training Accuracy:  82.8%, Loss: 0.3253\n",
      "Optimization Iteration:  24897, Training Accuracy:  75.0%, Loss: 0.3907\n",
      "Optimization Iteration:  24961, Training Accuracy:  89.1%, Loss: 0.2564\n",
      "Optimization Iteration:  25025, Training Accuracy:  75.0%, Loss: 0.4072\n",
      "Optimization Iteration:  25089, Training Accuracy:  78.1%, Loss: 0.3528\n",
      "Optimization Iteration:  25153, Training Accuracy:  78.1%, Loss: 0.3529\n",
      "Optimization Iteration:  25217, Training Accuracy:  64.1%, Loss: 0.5147\n",
      "Optimization Iteration:  25281, Training Accuracy:  79.7%, Loss: 0.3747\n",
      "Optimization Iteration:  25345, Training Accuracy:  78.1%, Loss: 0.4612\n",
      "Optimization Iteration:  25409, Training Accuracy:  82.8%, Loss: 0.3691\n",
      "Optimization Iteration:  25473, Training Accuracy:  64.1%, Loss: 0.4527\n",
      "Optimization Iteration:  25537, Training Accuracy:  75.0%, Loss: 0.4038\n",
      "Optimization Iteration:  25601, Training Accuracy:  57.8%, Loss: 0.5026\n",
      "Optimization Iteration:  25665, Training Accuracy:  81.2%, Loss: 0.4021\n",
      "Optimization Iteration:  25729, Training Accuracy:  76.6%, Loss: 0.3254\n",
      "Optimization Iteration:  25793, Training Accuracy:  75.0%, Loss: 0.3721\n",
      "Optimization Iteration:  25857, Training Accuracy:  78.1%, Loss: 0.4210\n",
      "Optimization Iteration:  25921, Training Accuracy:  79.7%, Loss: 0.3434\n",
      "Optimization Iteration:  25985, Training Accuracy:  71.9%, Loss: 0.4754\n",
      "Optimization Iteration:  26049, Training Accuracy:  73.4%, Loss: 0.3949\n",
      "Optimization Iteration:  26113, Training Accuracy:  75.0%, Loss: 0.3942\n",
      "Optimization Iteration:  26177, Training Accuracy:  73.4%, Loss: 0.3627\n",
      "Optimization Iteration:  26241, Training Accuracy:  65.6%, Loss: 0.4218\n",
      "Optimization Iteration:  26305, Training Accuracy:  78.1%, Loss: 0.3663\n",
      "Optimization Iteration:  26369, Training Accuracy:  76.6%, Loss: 0.3594\n",
      "Optimization Iteration:  26433, Training Accuracy:  70.3%, Loss: 0.4350\n",
      "Optimization Iteration:  26497, Training Accuracy:  75.0%, Loss: 0.3970\n",
      "Optimization Iteration:  26561, Training Accuracy:  76.6%, Loss: 0.3583\n",
      "Optimization Iteration:  26625, Training Accuracy:  79.7%, Loss: 0.3577\n",
      "Optimization Iteration:  26689, Training Accuracy:  73.4%, Loss: 0.4016\n",
      "Optimization Iteration:  26753, Training Accuracy:  60.9%, Loss: 0.4773\n",
      "Optimization Iteration:  26817, Training Accuracy:  65.6%, Loss: 0.4428\n",
      "Optimization Iteration:  26881, Training Accuracy:  84.4%, Loss: 0.3160\n",
      "Optimization Iteration:  26945, Training Accuracy:  85.9%, Loss: 0.3646\n",
      "Optimization Iteration:  27009, Training Accuracy:  71.9%, Loss: 0.3967\n",
      "Optimization Iteration:  27073, Training Accuracy:  78.1%, Loss: 0.4257\n",
      "Optimization Iteration:  27137, Training Accuracy:  85.9%, Loss: 0.3470\n",
      "Optimization Iteration:  27201, Training Accuracy:  85.9%, Loss: 0.3094\n",
      "Optimization Iteration:  27265, Training Accuracy:  78.1%, Loss: 0.3756\n",
      "Optimization Iteration:  27329, Training Accuracy:  78.1%, Loss: 0.4013\n",
      "Optimization Iteration:  27393, Training Accuracy:  75.0%, Loss: 0.4182\n",
      "Optimization Iteration:  27457, Training Accuracy:  71.9%, Loss: 0.4391\n",
      "Optimization Iteration:  27521, Training Accuracy:  78.1%, Loss: 0.3961\n",
      "Optimization Iteration:  27585, Training Accuracy:  81.2%, Loss: 0.3988\n",
      "Optimization Iteration:  27649, Training Accuracy:  79.7%, Loss: 0.3117\n",
      "Optimization Iteration:  27713, Training Accuracy:  68.8%, Loss: 0.4429\n",
      "Optimization Iteration:  27777, Training Accuracy:  84.4%, Loss: 0.3038\n",
      "Optimization Iteration:  27841, Training Accuracy:  73.4%, Loss: 0.3856\n",
      "Optimization Iteration:  27905, Training Accuracy:  73.4%, Loss: 0.4367\n",
      "Optimization Iteration:  27969, Training Accuracy:  75.0%, Loss: 0.4028\n",
      "Optimization Iteration:  28033, Training Accuracy:  79.7%, Loss: 0.3527\n",
      "Optimization Iteration:  28097, Training Accuracy:  79.7%, Loss: 0.3223\n",
      "Optimization Iteration:  28161, Training Accuracy:  85.9%, Loss: 0.3351\n",
      "Optimization Iteration:  28225, Training Accuracy:  81.2%, Loss: 0.3180\n",
      "Optimization Iteration:  28289, Training Accuracy:  75.0%, Loss: 0.4050\n",
      "Optimization Iteration:  28353, Training Accuracy:  70.3%, Loss: 0.3773\n",
      "Optimization Iteration:  28417, Training Accuracy:  79.7%, Loss: 0.3872\n",
      "Optimization Iteration:  28481, Training Accuracy:  70.3%, Loss: 0.3903\n",
      "Optimization Iteration:  28545, Training Accuracy:  76.6%, Loss: 0.3308\n",
      "Optimization Iteration:  28609, Training Accuracy:  79.7%, Loss: 0.3557\n",
      "Optimization Iteration:  28673, Training Accuracy:  67.2%, Loss: 0.4383\n",
      "Optimization Iteration:  28737, Training Accuracy:  82.8%, Loss: 0.3483\n",
      "Optimization Iteration:  28801, Training Accuracy:  78.1%, Loss: 0.3107\n",
      "Optimization Iteration:  28865, Training Accuracy:  78.1%, Loss: 0.3891\n",
      "Optimization Iteration:  28929, Training Accuracy:  79.7%, Loss: 0.3789\n",
      "Optimization Iteration:  28993, Training Accuracy:  73.4%, Loss: 0.4638\n",
      "Optimization Iteration:  29057, Training Accuracy:  82.8%, Loss: 0.3523\n",
      "Optimization Iteration:  29121, Training Accuracy:  73.4%, Loss: 0.4434\n",
      "Optimization Iteration:  29185, Training Accuracy:  76.6%, Loss: 0.3629\n",
      "Optimization Iteration:  29249, Training Accuracy:  76.6%, Loss: 0.4285\n",
      "Optimization Iteration:  29313, Training Accuracy:  78.1%, Loss: 0.3531\n",
      "Optimization Iteration:  29377, Training Accuracy:  81.2%, Loss: 0.3358\n",
      "Optimization Iteration:  29441, Training Accuracy:  82.8%, Loss: 0.3852\n",
      "Optimization Iteration:  29505, Training Accuracy:  84.4%, Loss: 0.3022\n",
      "Optimization Iteration:  29569, Training Accuracy:  81.2%, Loss: 0.3478\n",
      "Optimization Iteration:  29633, Training Accuracy:  82.8%, Loss: 0.3238\n",
      "Optimization Iteration:  29697, Training Accuracy:  79.7%, Loss: 0.3523\n",
      "Optimization Iteration:  29761, Training Accuracy:  78.1%, Loss: 0.3844\n",
      "Optimization Iteration:  29825, Training Accuracy:  73.4%, Loss: 0.4238\n",
      "Optimization Iteration:  29889, Training Accuracy:  75.0%, Loss: 0.4273\n",
      "Optimization Iteration:  29953, Training Accuracy:  73.4%, Loss: 0.4038\n",
      "Optimization Iteration:  30017, Training Accuracy:  75.0%, Loss: 0.3633\n",
      "Optimization Iteration:  30081, Training Accuracy:  81.2%, Loss: 0.3629\n",
      "Optimization Iteration:  30145, Training Accuracy:  73.4%, Loss: 0.3903\n",
      "Optimization Iteration:  30209, Training Accuracy:  76.6%, Loss: 0.4269\n",
      "Optimization Iteration:  30273, Training Accuracy:  78.1%, Loss: 0.4000\n",
      "Optimization Iteration:  30337, Training Accuracy:  71.9%, Loss: 0.4127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  30401, Training Accuracy:  78.1%, Loss: 0.3927\n",
      "Optimization Iteration:  30465, Training Accuracy:  78.1%, Loss: 0.3804\n",
      "Optimization Iteration:  30529, Training Accuracy:  78.1%, Loss: 0.3759\n",
      "Optimization Iteration:  30593, Training Accuracy:  73.4%, Loss: 0.4016\n",
      "Optimization Iteration:  30657, Training Accuracy:  79.7%, Loss: 0.3721\n",
      "Optimization Iteration:  30721, Training Accuracy:  75.0%, Loss: 0.3917\n",
      "Optimization Iteration:  30785, Training Accuracy:  70.3%, Loss: 0.4215\n",
      "Optimization Iteration:  30849, Training Accuracy:  75.0%, Loss: 0.3533\n",
      "Optimization Iteration:  30913, Training Accuracy:  73.4%, Loss: 0.4309\n",
      "Optimization Iteration:  30977, Training Accuracy:  75.0%, Loss: 0.4743\n",
      "Optimization Iteration:  31041, Training Accuracy:  85.9%, Loss: 0.3206\n",
      "Optimization Iteration:  31105, Training Accuracy:  71.9%, Loss: 0.4100\n",
      "Optimization Iteration:  31169, Training Accuracy:  82.8%, Loss: 0.2791\n",
      "Optimization Iteration:  31233, Training Accuracy:  76.6%, Loss: 0.4145\n",
      "Optimization Iteration:  31297, Training Accuracy:  75.0%, Loss: 0.3594\n",
      "Optimization Iteration:  31361, Training Accuracy:  76.6%, Loss: 0.3698\n",
      "Optimization Iteration:  31425, Training Accuracy:  79.7%, Loss: 0.3322\n",
      "Optimization Iteration:  31489, Training Accuracy:  81.2%, Loss: 0.3529\n",
      "Optimization Iteration:  31553, Training Accuracy:  81.2%, Loss: 0.3583\n",
      "Optimization Iteration:  31617, Training Accuracy:  70.3%, Loss: 0.3466\n",
      "Optimization Iteration:  31681, Training Accuracy:  82.8%, Loss: 0.3556\n",
      "Optimization Iteration:  31745, Training Accuracy:  79.7%, Loss: 0.3674\n",
      "Optimization Iteration:  31809, Training Accuracy:  65.6%, Loss: 0.5101\n",
      "Optimization Iteration:  31873, Training Accuracy:  79.7%, Loss: 0.3366\n",
      "Optimization Iteration:  31937, Training Accuracy:  65.6%, Loss: 0.4335\n",
      "Optimization Iteration:  32001, Training Accuracy:  73.4%, Loss: 0.3975\n",
      "Optimization Iteration:  32065, Training Accuracy:  71.9%, Loss: 0.3710\n",
      "Optimization Iteration:  32129, Training Accuracy:  75.0%, Loss: 0.4627\n",
      "Optimization Iteration:  32193, Training Accuracy:  70.3%, Loss: 0.4642\n",
      "Optimization Iteration:  32257, Training Accuracy:  82.8%, Loss: 0.3968\n",
      "Optimization Iteration:  32321, Training Accuracy:  81.2%, Loss: 0.3633\n",
      "Optimization Iteration:  32385, Training Accuracy:  78.1%, Loss: 0.4518\n",
      "Optimization Iteration:  32449, Training Accuracy:  68.8%, Loss: 0.4903\n",
      "Optimization Iteration:  32513, Training Accuracy:  75.0%, Loss: 0.3410\n",
      "Optimization Iteration:  32577, Training Accuracy:  76.6%, Loss: 0.3726\n",
      "Optimization Iteration:  32641, Training Accuracy:  73.4%, Loss: 0.4576\n",
      "Optimization Iteration:  32705, Training Accuracy:  79.7%, Loss: 0.3590\n",
      "Optimization Iteration:  32769, Training Accuracy:  82.8%, Loss: 0.3787\n",
      "Optimization Iteration:  32833, Training Accuracy:  71.9%, Loss: 0.4532\n",
      "Optimization Iteration:  32897, Training Accuracy:  68.8%, Loss: 0.4821\n",
      "Optimization Iteration:  32961, Training Accuracy:  75.0%, Loss: 0.4064\n",
      "Optimization Iteration:  33025, Training Accuracy:  78.1%, Loss: 0.3703\n",
      "Optimization Iteration:  33089, Training Accuracy:  78.1%, Loss: 0.4136\n",
      "Optimization Iteration:  33153, Training Accuracy:  75.0%, Loss: 0.4585\n",
      "Optimization Iteration:  33217, Training Accuracy:  67.2%, Loss: 0.4073\n",
      "Optimization Iteration:  33281, Training Accuracy:  73.4%, Loss: 0.4211\n",
      "Optimization Iteration:  33345, Training Accuracy:  78.1%, Loss: 0.3711\n",
      "Optimization Iteration:  33409, Training Accuracy:  75.0%, Loss: 0.4111\n",
      "Optimization Iteration:  33473, Training Accuracy:  76.6%, Loss: 0.3988\n",
      "Optimization Iteration:  33537, Training Accuracy:  62.5%, Loss: 0.4493\n",
      "Optimization Iteration:  33601, Training Accuracy:  76.6%, Loss: 0.3835\n",
      "Optimization Iteration:  33665, Training Accuracy:  78.1%, Loss: 0.3659\n",
      "Optimization Iteration:  33729, Training Accuracy:  65.6%, Loss: 0.4998\n",
      "Optimization Iteration:  33793, Training Accuracy:  73.4%, Loss: 0.4583\n",
      "Optimization Iteration:  33857, Training Accuracy:  68.8%, Loss: 0.4569\n",
      "Optimization Iteration:  33921, Training Accuracy:  78.1%, Loss: 0.3687\n",
      "Optimization Iteration:  33985, Training Accuracy:  76.6%, Loss: 0.3484\n",
      "Optimization Iteration:  34049, Training Accuracy:  67.2%, Loss: 0.4966\n",
      "Optimization Iteration:  34113, Training Accuracy:  76.6%, Loss: 0.4119\n",
      "Optimization Iteration:  34177, Training Accuracy:  76.6%, Loss: 0.3229\n",
      "Optimization Iteration:  34241, Training Accuracy:  79.7%, Loss: 0.3563\n",
      "Optimization Iteration:  34305, Training Accuracy:  75.0%, Loss: 0.4308\n",
      "Optimization Iteration:  34369, Training Accuracy:  79.7%, Loss: 0.3774\n",
      "Optimization Iteration:  34433, Training Accuracy:  78.1%, Loss: 0.4583\n",
      "Optimization Iteration:  34497, Training Accuracy:  73.4%, Loss: 0.3325\n",
      "Optimization Iteration:  34561, Training Accuracy:  84.4%, Loss: 0.3080\n",
      "Optimization Iteration:  34625, Training Accuracy:  73.4%, Loss: 0.4629\n",
      "Optimization Iteration:  34689, Training Accuracy:  81.2%, Loss: 0.3343\n",
      "Optimization Iteration:  34753, Training Accuracy:  73.4%, Loss: 0.4403\n",
      "Optimization Iteration:  34817, Training Accuracy:  70.3%, Loss: 0.4338\n",
      "Optimization Iteration:  34881, Training Accuracy:  81.2%, Loss: 0.3922\n",
      "Optimization Iteration:  34945, Training Accuracy:  81.2%, Loss: 0.2999\n",
      "Optimization Iteration:  35009, Training Accuracy:  81.2%, Loss: 0.3538\n",
      "Optimization Iteration:  35073, Training Accuracy:  70.3%, Loss: 0.4004\n",
      "Optimization Iteration:  35137, Training Accuracy:  78.1%, Loss: 0.3230\n",
      "Optimization Iteration:  35201, Training Accuracy:  78.1%, Loss: 0.3723\n",
      "Optimization Iteration:  35265, Training Accuracy:  78.1%, Loss: 0.3680\n",
      "Optimization Iteration:  35329, Training Accuracy:  67.2%, Loss: 0.4949\n",
      "Optimization Iteration:  35393, Training Accuracy:  73.4%, Loss: 0.3335\n",
      "Optimization Iteration:  35457, Training Accuracy:  78.1%, Loss: 0.3580\n",
      "Optimization Iteration:  35521, Training Accuracy:  68.8%, Loss: 0.4302\n",
      "Optimization Iteration:  35585, Training Accuracy:  79.7%, Loss: 0.3686\n",
      "Optimization Iteration:  35649, Training Accuracy:  78.1%, Loss: 0.4181\n",
      "Optimization Iteration:  35713, Training Accuracy:  76.6%, Loss: 0.4164\n",
      "Optimization Iteration:  35777, Training Accuracy:  87.5%, Loss: 0.2728\n",
      "Optimization Iteration:  35841, Training Accuracy:  81.2%, Loss: 0.3257\n",
      "Optimization Iteration:  35905, Training Accuracy:  82.8%, Loss: 0.3473\n",
      "Optimization Iteration:  35969, Training Accuracy:  70.3%, Loss: 0.3942\n",
      "Optimization Iteration:  36033, Training Accuracy:  76.6%, Loss: 0.3502\n",
      "Optimization Iteration:  36097, Training Accuracy:  76.6%, Loss: 0.3883\n",
      "Optimization Iteration:  36161, Training Accuracy:  75.0%, Loss: 0.3857\n",
      "Optimization Iteration:  36225, Training Accuracy:  78.1%, Loss: 0.3317\n",
      "Optimization Iteration:  36289, Training Accuracy:  78.1%, Loss: 0.3486\n",
      "Optimization Iteration:  36353, Training Accuracy:  70.3%, Loss: 0.3542\n",
      "Optimization Iteration:  36417, Training Accuracy:  82.8%, Loss: 0.3201\n",
      "Optimization Iteration:  36481, Training Accuracy:  73.4%, Loss: 0.3925\n",
      "Optimization Iteration:  36545, Training Accuracy:  78.1%, Loss: 0.3486\n",
      "Optimization Iteration:  36609, Training Accuracy:  78.1%, Loss: 0.3264\n",
      "Optimization Iteration:  36673, Training Accuracy:  81.2%, Loss: 0.3438\n",
      "Optimization Iteration:  36737, Training Accuracy:  81.2%, Loss: 0.3308\n",
      "Optimization Iteration:  36801, Training Accuracy:  81.2%, Loss: 0.3337\n",
      "Optimization Iteration:  36865, Training Accuracy:  76.6%, Loss: 0.3844\n",
      "Optimization Iteration:  36929, Training Accuracy:  78.1%, Loss: 0.3585\n",
      "Optimization Iteration:  36993, Training Accuracy:  82.8%, Loss: 0.3921\n",
      "Optimization Iteration:  37057, Training Accuracy:  82.8%, Loss: 0.3396\n",
      "Optimization Iteration:  37121, Training Accuracy:  79.7%, Loss: 0.3335\n",
      "Optimization Iteration:  37185, Training Accuracy:  85.9%, Loss: 0.3178\n",
      "Optimization Iteration:  37249, Training Accuracy:  76.6%, Loss: 0.4007\n",
      "Optimization Iteration:  37313, Training Accuracy:  81.2%, Loss: 0.3279\n",
      "Optimization Iteration:  37377, Training Accuracy:  71.9%, Loss: 0.4215\n",
      "Optimization Iteration:  37441, Training Accuracy:  68.8%, Loss: 0.4149\n",
      "Optimization Iteration:  37505, Training Accuracy:  73.4%, Loss: 0.4110\n",
      "Optimization Iteration:  37569, Training Accuracy:  79.7%, Loss: 0.4345\n",
      "Optimization Iteration:  37633, Training Accuracy:  70.3%, Loss: 0.4362\n",
      "Optimization Iteration:  37697, Training Accuracy:  78.1%, Loss: 0.3502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  37761, Training Accuracy:  78.1%, Loss: 0.3393\n",
      "Optimization Iteration:  37825, Training Accuracy:  85.9%, Loss: 0.3100\n",
      "Optimization Iteration:  37889, Training Accuracy:  79.7%, Loss: 0.4431\n",
      "Optimization Iteration:  37953, Training Accuracy:  79.7%, Loss: 0.3459\n",
      "Optimization Iteration:  38017, Training Accuracy:  75.0%, Loss: 0.4985\n",
      "Optimization Iteration:  38081, Training Accuracy:  79.7%, Loss: 0.3726\n",
      "Optimization Iteration:  38145, Training Accuracy:  78.1%, Loss: 0.2832\n",
      "Optimization Iteration:  38209, Training Accuracy:  82.8%, Loss: 0.3577\n",
      "Optimization Iteration:  38273, Training Accuracy:  68.8%, Loss: 0.3772\n",
      "Optimization Iteration:  38337, Training Accuracy:  87.5%, Loss: 0.2743\n",
      "Optimization Iteration:  38401, Training Accuracy:  81.2%, Loss: 0.3187\n",
      "Optimization Iteration:  38465, Training Accuracy:  79.7%, Loss: 0.4305\n",
      "Optimization Iteration:  38529, Training Accuracy:  76.6%, Loss: 0.4189\n",
      "Optimization Iteration:  38593, Training Accuracy:  70.3%, Loss: 0.5045\n",
      "Optimization Iteration:  38657, Training Accuracy:  73.4%, Loss: 0.3913\n",
      "Optimization Iteration:  38721, Training Accuracy:  79.7%, Loss: 0.3530\n",
      "Optimization Iteration:  38785, Training Accuracy:  79.7%, Loss: 0.4244\n",
      "Optimization Iteration:  38849, Training Accuracy:  81.2%, Loss: 0.3492\n",
      "Optimization Iteration:  38913, Training Accuracy:  81.2%, Loss: 0.4230\n",
      "Optimization Iteration:  38977, Training Accuracy:  78.1%, Loss: 0.3696\n",
      "Optimization Iteration:  39041, Training Accuracy:  78.1%, Loss: 0.4236\n",
      "Optimization Iteration:  39105, Training Accuracy:  73.4%, Loss: 0.4625\n",
      "Optimization Iteration:  39169, Training Accuracy:  76.6%, Loss: 0.4633\n",
      "Optimization Iteration:  39233, Training Accuracy:  68.8%, Loss: 0.4913\n",
      "Optimization Iteration:  39297, Training Accuracy:  75.0%, Loss: 0.4634\n",
      "Optimization Iteration:  39361, Training Accuracy:  76.6%, Loss: 0.3538\n",
      "Optimization Iteration:  39425, Training Accuracy:  75.0%, Loss: 0.3983\n",
      "Optimization Iteration:  39489, Training Accuracy:  81.2%, Loss: 0.3155\n",
      "Optimization Iteration:  39553, Training Accuracy:  79.7%, Loss: 0.3687\n",
      "Optimization Iteration:  39617, Training Accuracy:  84.4%, Loss: 0.3948\n",
      "Optimization Iteration:  39681, Training Accuracy:  64.1%, Loss: 0.4008\n",
      "Optimization Iteration:  39745, Training Accuracy:  81.2%, Loss: 0.4437\n",
      "Optimization Iteration:  39809, Training Accuracy:  71.9%, Loss: 0.4096\n",
      "Optimization Iteration:  39873, Training Accuracy:  76.6%, Loss: 0.4132\n",
      "Optimization Iteration:  39937, Training Accuracy:  75.0%, Loss: 0.4798\n",
      "Optimization Iteration:  40001, Training Accuracy:  75.0%, Loss: 0.4356\n",
      "Optimization Iteration:  40065, Training Accuracy:  76.6%, Loss: 0.3220\n",
      "Optimization Iteration:  40129, Training Accuracy:  71.9%, Loss: 0.4179\n",
      "Optimization Iteration:  40193, Training Accuracy:  82.8%, Loss: 0.3525\n",
      "Optimization Iteration:  40257, Training Accuracy:  71.9%, Loss: 0.3661\n",
      "Optimization Iteration:  40321, Training Accuracy:  73.4%, Loss: 0.4318\n",
      "Optimization Iteration:  40385, Training Accuracy:  68.8%, Loss: 0.4269\n",
      "Optimization Iteration:  40449, Training Accuracy:  73.4%, Loss: 0.3687\n",
      "Optimization Iteration:  40513, Training Accuracy:  75.0%, Loss: 0.4329\n",
      "Optimization Iteration:  40577, Training Accuracy:  81.2%, Loss: 0.3643\n",
      "Optimization Iteration:  40641, Training Accuracy:  70.3%, Loss: 0.4146\n",
      "Optimization Iteration:  40705, Training Accuracy:  78.1%, Loss: 0.3496\n",
      "Optimization Iteration:  40769, Training Accuracy:  82.8%, Loss: 0.3062\n",
      "Optimization Iteration:  40833, Training Accuracy:  84.4%, Loss: 0.2847\n",
      "Optimization Iteration:  40897, Training Accuracy:  73.4%, Loss: 0.3631\n",
      "Optimization Iteration:  40961, Training Accuracy:  87.5%, Loss: 0.3286\n",
      "Optimization Iteration:  41025, Training Accuracy:  79.7%, Loss: 0.3616\n",
      "Optimization Iteration:  41089, Training Accuracy:  78.1%, Loss: 0.4388\n",
      "Optimization Iteration:  41153, Training Accuracy:  76.6%, Loss: 0.4708\n",
      "Optimization Iteration:  41217, Training Accuracy:  81.2%, Loss: 0.3064\n",
      "Optimization Iteration:  41281, Training Accuracy:  68.8%, Loss: 0.4155\n",
      "Optimization Iteration:  41345, Training Accuracy:  73.4%, Loss: 0.4178\n",
      "Optimization Iteration:  41409, Training Accuracy:  78.1%, Loss: 0.3782\n",
      "Optimization Iteration:  41473, Training Accuracy:  75.0%, Loss: 0.3765\n",
      "Optimization Iteration:  41537, Training Accuracy:  82.8%, Loss: 0.3614\n",
      "Optimization Iteration:  41601, Training Accuracy:  76.6%, Loss: 0.4380\n",
      "Optimization Iteration:  41665, Training Accuracy:  76.6%, Loss: 0.3898\n",
      "Optimization Iteration:  41729, Training Accuracy:  73.4%, Loss: 0.3294\n",
      "Optimization Iteration:  41793, Training Accuracy:  75.0%, Loss: 0.4499\n",
      "Optimization Iteration:  41857, Training Accuracy:  75.0%, Loss: 0.4396\n",
      "Optimization Iteration:  41921, Training Accuracy:  78.1%, Loss: 0.3497\n",
      "Optimization Iteration:  41985, Training Accuracy:  67.2%, Loss: 0.4951\n",
      "Optimization Iteration:  42049, Training Accuracy:  71.9%, Loss: 0.4317\n",
      "Optimization Iteration:  42113, Training Accuracy:  79.7%, Loss: 0.3496\n",
      "Optimization Iteration:  42177, Training Accuracy:  73.4%, Loss: 0.4285\n",
      "Optimization Iteration:  42241, Training Accuracy:  68.8%, Loss: 0.4878\n",
      "Optimization Iteration:  42305, Training Accuracy:  79.7%, Loss: 0.4237\n",
      "Optimization Iteration:  42369, Training Accuracy:  71.9%, Loss: 0.3971\n",
      "Optimization Iteration:  42433, Training Accuracy:  78.1%, Loss: 0.4059\n",
      "Optimization Iteration:  42497, Training Accuracy:  64.1%, Loss: 0.4665\n",
      "Optimization Iteration:  42561, Training Accuracy:  81.2%, Loss: 0.3424\n",
      "Optimization Iteration:  42625, Training Accuracy:  73.4%, Loss: 0.3962\n",
      "Optimization Iteration:  42689, Training Accuracy:  82.8%, Loss: 0.3635\n",
      "Optimization Iteration:  42753, Training Accuracy:  65.6%, Loss: 0.4193\n",
      "Optimization Iteration:  42817, Training Accuracy:  82.8%, Loss: 0.3424\n",
      "Optimization Iteration:  42881, Training Accuracy:  75.0%, Loss: 0.4150\n",
      "Optimization Iteration:  42945, Training Accuracy:  81.2%, Loss: 0.3739\n",
      "Optimization Iteration:  43009, Training Accuracy:  78.1%, Loss: 0.3900\n",
      "Optimization Iteration:  43073, Training Accuracy:  79.7%, Loss: 0.3466\n",
      "Optimization Iteration:  43137, Training Accuracy:  82.8%, Loss: 0.3150\n",
      "Optimization Iteration:  43201, Training Accuracy:  79.7%, Loss: 0.3518\n",
      "Optimization Iteration:  43265, Training Accuracy:  81.2%, Loss: 0.3392\n",
      "Optimization Iteration:  43329, Training Accuracy:  81.2%, Loss: 0.3765\n",
      "Optimization Iteration:  43393, Training Accuracy:  76.6%, Loss: 0.3864\n",
      "Optimization Iteration:  43457, Training Accuracy:  81.2%, Loss: 0.3258\n",
      "Optimization Iteration:  43521, Training Accuracy:  81.2%, Loss: 0.4340\n",
      "Optimization Iteration:  43585, Training Accuracy:  76.6%, Loss: 0.3309\n",
      "Optimization Iteration:  43649, Training Accuracy:  76.6%, Loss: 0.3835\n",
      "Optimization Iteration:  43713, Training Accuracy:  84.4%, Loss: 0.3268\n",
      "Optimization Iteration:  43777, Training Accuracy:  89.1%, Loss: 0.2697\n",
      "Optimization Iteration:  43841, Training Accuracy:  75.0%, Loss: 0.4259\n",
      "Optimization Iteration:  43905, Training Accuracy:  89.1%, Loss: 0.2846\n",
      "Optimization Iteration:  43969, Training Accuracy:  82.8%, Loss: 0.3018\n",
      "Optimization Iteration:  44033, Training Accuracy:  75.0%, Loss: 0.3441\n",
      "Optimization Iteration:  44097, Training Accuracy:  78.1%, Loss: 0.3960\n",
      "Optimization Iteration:  44161, Training Accuracy:  82.8%, Loss: 0.2889\n",
      "Optimization Iteration:  44225, Training Accuracy:  67.2%, Loss: 0.3789\n",
      "Optimization Iteration:  44289, Training Accuracy:  78.1%, Loss: 0.3902\n",
      "Optimization Iteration:  44353, Training Accuracy:  71.9%, Loss: 0.4101\n",
      "Optimization Iteration:  44417, Training Accuracy:  76.6%, Loss: 0.3166\n",
      "Optimization Iteration:  44481, Training Accuracy:  70.3%, Loss: 0.3820\n",
      "Optimization Iteration:  44545, Training Accuracy:  78.1%, Loss: 0.3152\n",
      "Optimization Iteration:  44609, Training Accuracy:  76.6%, Loss: 0.3995\n",
      "Optimization Iteration:  44673, Training Accuracy:  78.1%, Loss: 0.5804\n",
      "Optimization Iteration:  44737, Training Accuracy:  64.1%, Loss: 0.3525\n",
      "Optimization Iteration:  44801, Training Accuracy:  76.6%, Loss: 0.4053\n",
      "Optimization Iteration:  44865, Training Accuracy:  76.6%, Loss: 0.3909\n",
      "Optimization Iteration:  44929, Training Accuracy:  78.1%, Loss: 0.3565\n",
      "Optimization Iteration:  44993, Training Accuracy:  78.1%, Loss: 0.3278\n",
      "Optimization Iteration:  45057, Training Accuracy:  79.7%, Loss: 0.3958\n",
      "Optimization Iteration:  45121, Training Accuracy:  82.8%, Loss: 0.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  45185, Training Accuracy:  87.5%, Loss: 0.3140\n",
      "Optimization Iteration:  45249, Training Accuracy:  75.0%, Loss: 0.4357\n",
      "Optimization Iteration:  45313, Training Accuracy:  81.2%, Loss: 0.3907\n",
      "Optimization Iteration:  45377, Training Accuracy:  78.1%, Loss: 0.3920\n",
      "Optimization Iteration:  45441, Training Accuracy:  85.9%, Loss: 0.3184\n",
      "Optimization Iteration:  45505, Training Accuracy:  70.3%, Loss: 0.4457\n",
      "Optimization Iteration:  45569, Training Accuracy:  76.6%, Loss: 0.4205\n",
      "Optimization Iteration:  45633, Training Accuracy:  82.8%, Loss: 0.4096\n",
      "Optimization Iteration:  45697, Training Accuracy:  76.6%, Loss: 0.4044\n",
      "Optimization Iteration:  45761, Training Accuracy:  85.9%, Loss: 0.3277\n",
      "Optimization Iteration:  45825, Training Accuracy:  76.6%, Loss: 0.3319\n",
      "Optimization Iteration:  45889, Training Accuracy:  87.5%, Loss: 0.3141\n",
      "Optimization Iteration:  45953, Training Accuracy:  70.3%, Loss: 0.4062\n",
      "Optimization Iteration:  46017, Training Accuracy:  73.4%, Loss: 0.3907\n",
      "Optimization Iteration:  46081, Training Accuracy:  87.5%, Loss: 0.3561\n",
      "Optimization Iteration:  46145, Training Accuracy:  70.3%, Loss: 0.4802\n",
      "Optimization Iteration:  46209, Training Accuracy:  73.4%, Loss: 0.3624\n",
      "Optimization Iteration:  46273, Training Accuracy:  76.6%, Loss: 0.4180\n",
      "Optimization Iteration:  46337, Training Accuracy:  79.7%, Loss: 0.4197\n",
      "Optimization Iteration:  46401, Training Accuracy:  79.7%, Loss: 0.3363\n",
      "Optimization Iteration:  46465, Training Accuracy:  73.4%, Loss: 0.3891\n",
      "Optimization Iteration:  46529, Training Accuracy:  71.9%, Loss: 0.4082\n",
      "Optimization Iteration:  46593, Training Accuracy:  75.0%, Loss: 0.3477\n",
      "Optimization Iteration:  46657, Training Accuracy:  79.7%, Loss: 0.4460\n",
      "Optimization Iteration:  46721, Training Accuracy:  78.1%, Loss: 0.3947\n",
      "Optimization Iteration:  46785, Training Accuracy:  75.0%, Loss: 0.4303\n",
      "Optimization Iteration:  46849, Training Accuracy:  78.1%, Loss: 0.3126\n",
      "Optimization Iteration:  46913, Training Accuracy:  76.6%, Loss: 0.4204\n",
      "Optimization Iteration:  46977, Training Accuracy:  73.4%, Loss: 0.3839\n",
      "Optimization Iteration:  47041, Training Accuracy:  82.8%, Loss: 0.3789\n",
      "Optimization Iteration:  47105, Training Accuracy:  68.8%, Loss: 0.4626\n",
      "Optimization Iteration:  47169, Training Accuracy:  76.6%, Loss: 0.4041\n",
      "Optimization Iteration:  47233, Training Accuracy:  67.2%, Loss: 0.4354\n",
      "Optimization Iteration:  47297, Training Accuracy:  75.0%, Loss: 0.3334\n",
      "Optimization Iteration:  47361, Training Accuracy:  79.7%, Loss: 0.3572\n",
      "Optimization Iteration:  47425, Training Accuracy:  87.5%, Loss: 0.2877\n",
      "Optimization Iteration:  47489, Training Accuracy:  75.0%, Loss: 0.3888\n",
      "Optimization Iteration:  47553, Training Accuracy:  82.8%, Loss: 0.3966\n",
      "Optimization Iteration:  47617, Training Accuracy:  67.2%, Loss: 0.4588\n",
      "Optimization Iteration:  47681, Training Accuracy:  87.5%, Loss: 0.3384\n",
      "Optimization Iteration:  47745, Training Accuracy:  68.8%, Loss: 0.4400\n",
      "Optimization Iteration:  47809, Training Accuracy:  73.4%, Loss: 0.4388\n",
      "Optimization Iteration:  47873, Training Accuracy:  78.1%, Loss: 0.3323\n",
      "Optimization Iteration:  47937, Training Accuracy:  78.1%, Loss: 0.3357\n",
      "Optimization Iteration:  48001, Training Accuracy:  81.2%, Loss: 0.3640\n",
      "Optimization Iteration:  48065, Training Accuracy:  79.7%, Loss: 0.3803\n",
      "Optimization Iteration:  48129, Training Accuracy:  75.0%, Loss: 0.4231\n",
      "Optimization Iteration:  48193, Training Accuracy:  65.6%, Loss: 0.4489\n",
      "Optimization Iteration:  48257, Training Accuracy:  67.2%, Loss: 0.4359\n",
      "Optimization Iteration:  48321, Training Accuracy:  81.2%, Loss: 0.3387\n",
      "Optimization Iteration:  48385, Training Accuracy:  79.7%, Loss: 0.3193\n",
      "Optimization Iteration:  48449, Training Accuracy:  76.6%, Loss: 0.3527\n",
      "Optimization Iteration:  48513, Training Accuracy:  78.1%, Loss: 0.3459\n",
      "Optimization Iteration:  48577, Training Accuracy:  64.1%, Loss: 0.5244\n",
      "Optimization Iteration:  48641, Training Accuracy:  82.8%, Loss: 0.3279\n",
      "Optimization Iteration:  48705, Training Accuracy:  85.9%, Loss: 0.3376\n",
      "Optimization Iteration:  48769, Training Accuracy:  92.2%, Loss: 0.2800\n",
      "Optimization Iteration:  48833, Training Accuracy:  78.1%, Loss: 0.3624\n",
      "Optimization Iteration:  48897, Training Accuracy:  75.0%, Loss: 0.4220\n",
      "Optimization Iteration:  48961, Training Accuracy:  79.7%, Loss: 0.4228\n",
      "Optimization Iteration:  49025, Training Accuracy:  73.4%, Loss: 0.4120\n",
      "Optimization Iteration:  49089, Training Accuracy:  81.2%, Loss: 0.3450\n",
      "Optimization Iteration:  49153, Training Accuracy:  73.4%, Loss: 0.3695\n",
      "Optimization Iteration:  49217, Training Accuracy:  76.6%, Loss: 0.4596\n",
      "Optimization Iteration:  49281, Training Accuracy:  82.8%, Loss: 0.3271\n",
      "Optimization Iteration:  49345, Training Accuracy:  76.6%, Loss: 0.3268\n",
      "Optimization Iteration:  49409, Training Accuracy:  70.3%, Loss: 0.4130\n",
      "Optimization Iteration:  49473, Training Accuracy:  81.2%, Loss: 0.3477\n",
      "Optimization Iteration:  49537, Training Accuracy:  76.6%, Loss: 0.3774\n",
      "Optimization Iteration:  49601, Training Accuracy:  76.6%, Loss: 0.4126\n",
      "Optimization Iteration:  49665, Training Accuracy:  84.4%, Loss: 0.2601\n",
      "Optimization Iteration:  49729, Training Accuracy:  73.4%, Loss: 0.3716\n",
      "Optimization Iteration:  49793, Training Accuracy:  78.1%, Loss: 0.3149\n",
      "Optimization Iteration:  49857, Training Accuracy:  71.9%, Loss: 0.4012\n",
      "Optimization Iteration:  49921, Training Accuracy:  75.0%, Loss: 0.4693\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 29\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  73.4%, Loss: 0.4091\n",
      "Optimization Iteration:    129, Training Accuracy:  65.6%, Loss: 0.5269\n",
      "Optimization Iteration:    193, Training Accuracy:  82.8%, Loss: 0.4041\n",
      "Optimization Iteration:    257, Training Accuracy:  78.1%, Loss: 0.3430\n",
      "Optimization Iteration:    321, Training Accuracy:  71.9%, Loss: 0.4509\n",
      "Optimization Iteration:    385, Training Accuracy:  73.4%, Loss: 0.3966\n",
      "Optimization Iteration:    449, Training Accuracy:  84.4%, Loss: 0.3041\n",
      "Optimization Iteration:    513, Training Accuracy:  76.6%, Loss: 0.4410\n",
      "Optimization Iteration:    577, Training Accuracy:  73.4%, Loss: 0.4108\n",
      "Optimization Iteration:    641, Training Accuracy:  81.2%, Loss: 0.3810\n",
      "Optimization Iteration:    705, Training Accuracy:  71.9%, Loss: 0.4383\n",
      "Optimization Iteration:    769, Training Accuracy:  82.8%, Loss: 0.3790\n",
      "Optimization Iteration:    833, Training Accuracy:  75.0%, Loss: 0.3854\n",
      "Optimization Iteration:    897, Training Accuracy:  73.4%, Loss: 0.3198\n",
      "Optimization Iteration:    961, Training Accuracy:  79.7%, Loss: 0.3835\n",
      "Optimization Iteration:   1025, Training Accuracy:  81.2%, Loss: 0.3656\n",
      "Optimization Iteration:   1089, Training Accuracy:  71.9%, Loss: 0.3721\n",
      "Optimization Iteration:   1153, Training Accuracy:  76.6%, Loss: 0.3941\n",
      "Optimization Iteration:   1217, Training Accuracy:  71.9%, Loss: 0.4109\n",
      "Optimization Iteration:   1281, Training Accuracy:  78.1%, Loss: 0.2940\n",
      "Optimization Iteration:   1345, Training Accuracy:  84.4%, Loss: 0.3309\n",
      "Optimization Iteration:   1409, Training Accuracy:  76.6%, Loss: 0.3686\n",
      "Optimization Iteration:   1473, Training Accuracy:  64.1%, Loss: 0.4172\n",
      "Optimization Iteration:   1537, Training Accuracy:  75.0%, Loss: 0.4034\n",
      "Optimization Iteration:   1601, Training Accuracy:  87.5%, Loss: 0.3650\n",
      "Optimization Iteration:   1665, Training Accuracy:  78.1%, Loss: 0.3317\n",
      "Optimization Iteration:   1729, Training Accuracy:  71.9%, Loss: 0.3996\n",
      "Optimization Iteration:   1793, Training Accuracy:  73.4%, Loss: 0.3962\n",
      "Optimization Iteration:   1857, Training Accuracy:  78.1%, Loss: 0.3371\n",
      "Optimization Iteration:   1921, Training Accuracy:  75.0%, Loss: 0.3604\n",
      "Optimization Iteration:   1985, Training Accuracy:  75.0%, Loss: 0.3705\n",
      "Optimization Iteration:   2049, Training Accuracy:  71.9%, Loss: 0.3654\n",
      "Optimization Iteration:   2113, Training Accuracy:  81.2%, Loss: 0.3440\n",
      "Optimization Iteration:   2177, Training Accuracy:  73.4%, Loss: 0.3661\n",
      "Optimization Iteration:   2241, Training Accuracy:  71.9%, Loss: 0.4248\n",
      "Optimization Iteration:   2305, Training Accuracy:  71.9%, Loss: 0.3853\n",
      "Optimization Iteration:   2369, Training Accuracy:  75.0%, Loss: 0.4053\n",
      "Optimization Iteration:   2433, Training Accuracy:  73.4%, Loss: 0.4379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   2497, Training Accuracy:  75.0%, Loss: 0.3347\n",
      "Optimization Iteration:   2561, Training Accuracy:  73.4%, Loss: 0.3787\n",
      "Optimization Iteration:   2625, Training Accuracy:  76.6%, Loss: 0.3836\n",
      "Optimization Iteration:   2689, Training Accuracy:  75.0%, Loss: 0.4136\n",
      "Optimization Iteration:   2753, Training Accuracy:  71.9%, Loss: 0.3572\n",
      "Optimization Iteration:   2817, Training Accuracy:  82.8%, Loss: 0.3235\n",
      "Optimization Iteration:   2881, Training Accuracy:  75.0%, Loss: 0.3705\n",
      "Optimization Iteration:   2945, Training Accuracy:  68.8%, Loss: 0.5673\n",
      "Optimization Iteration:   3009, Training Accuracy:  73.4%, Loss: 0.3888\n",
      "Optimization Iteration:   3073, Training Accuracy:  81.2%, Loss: 0.3261\n",
      "Optimization Iteration:   3137, Training Accuracy:  82.8%, Loss: 0.3310\n",
      "Optimization Iteration:   3201, Training Accuracy:  85.9%, Loss: 0.3262\n",
      "Optimization Iteration:   3265, Training Accuracy:  78.1%, Loss: 0.4002\n",
      "Optimization Iteration:   3329, Training Accuracy:  81.2%, Loss: 0.3955\n",
      "Optimization Iteration:   3393, Training Accuracy:  78.1%, Loss: 0.3469\n",
      "Optimization Iteration:   3457, Training Accuracy:  75.0%, Loss: 0.4805\n",
      "Optimization Iteration:   3521, Training Accuracy:  78.1%, Loss: 0.3488\n",
      "Optimization Iteration:   3585, Training Accuracy:  71.9%, Loss: 0.3969\n",
      "Optimization Iteration:   3649, Training Accuracy:  76.6%, Loss: 0.4194\n",
      "Optimization Iteration:   3713, Training Accuracy:  70.3%, Loss: 0.4192\n",
      "Optimization Iteration:   3777, Training Accuracy:  68.8%, Loss: 0.4341\n",
      "Optimization Iteration:   3841, Training Accuracy:  67.2%, Loss: 0.4494\n",
      "Optimization Iteration:   3905, Training Accuracy:  81.2%, Loss: 0.3533\n",
      "Optimization Iteration:   3969, Training Accuracy:  81.2%, Loss: 0.3793\n",
      "Optimization Iteration:   4033, Training Accuracy:  81.2%, Loss: 0.3308\n",
      "Optimization Iteration:   4097, Training Accuracy:  76.6%, Loss: 0.3575\n",
      "Optimization Iteration:   4161, Training Accuracy:  81.2%, Loss: 0.4734\n",
      "Optimization Iteration:   4225, Training Accuracy:  76.6%, Loss: 0.3241\n",
      "Optimization Iteration:   4289, Training Accuracy:  75.0%, Loss: 0.3542\n",
      "Optimization Iteration:   4353, Training Accuracy:  76.6%, Loss: 0.3984\n",
      "Optimization Iteration:   4417, Training Accuracy:  76.6%, Loss: 0.3647\n",
      "Optimization Iteration:   4481, Training Accuracy:  71.9%, Loss: 0.3969\n",
      "Optimization Iteration:   4545, Training Accuracy:  73.4%, Loss: 0.4082\n",
      "Optimization Iteration:   4609, Training Accuracy:  82.8%, Loss: 0.3400\n",
      "Optimization Iteration:   4673, Training Accuracy:  78.1%, Loss: 0.4007\n",
      "Optimization Iteration:   4737, Training Accuracy:  73.4%, Loss: 0.3827\n",
      "Optimization Iteration:   4801, Training Accuracy:  62.5%, Loss: 0.4518\n",
      "Optimization Iteration:   4865, Training Accuracy:  81.2%, Loss: 0.3999\n",
      "Optimization Iteration:   4929, Training Accuracy:  81.2%, Loss: 0.3745\n",
      "Optimization Iteration:   4993, Training Accuracy:  81.2%, Loss: 0.3101\n",
      "Optimization Iteration:   5057, Training Accuracy:  75.0%, Loss: 0.4271\n",
      "Optimization Iteration:   5121, Training Accuracy:  85.9%, Loss: 0.3130\n",
      "Optimization Iteration:   5185, Training Accuracy:  81.2%, Loss: 0.3791\n",
      "Optimization Iteration:   5249, Training Accuracy:  67.2%, Loss: 0.4278\n",
      "Optimization Iteration:   5313, Training Accuracy:  84.4%, Loss: 0.2887\n",
      "Optimization Iteration:   5377, Training Accuracy:  79.7%, Loss: 0.3802\n",
      "Optimization Iteration:   5441, Training Accuracy:  70.3%, Loss: 0.4095\n",
      "Optimization Iteration:   5505, Training Accuracy:  79.7%, Loss: 0.3529\n",
      "Optimization Iteration:   5569, Training Accuracy:  81.2%, Loss: 0.3494\n",
      "Optimization Iteration:   5633, Training Accuracy:  68.8%, Loss: 0.3891\n",
      "Optimization Iteration:   5697, Training Accuracy:  76.6%, Loss: 0.4455\n",
      "Optimization Iteration:   5761, Training Accuracy:  84.4%, Loss: 0.3160\n",
      "Optimization Iteration:   5825, Training Accuracy:  81.2%, Loss: 0.4061\n",
      "Optimization Iteration:   5889, Training Accuracy:  73.4%, Loss: 0.3813\n",
      "Optimization Iteration:   5953, Training Accuracy:  68.8%, Loss: 0.3999\n",
      "Optimization Iteration:   6017, Training Accuracy:  59.4%, Loss: 0.4799\n",
      "Optimization Iteration:   6081, Training Accuracy:  76.6%, Loss: 0.3710\n",
      "Optimization Iteration:   6145, Training Accuracy:  71.9%, Loss: 0.4456\n",
      "Optimization Iteration:   6209, Training Accuracy:  71.9%, Loss: 0.3245\n",
      "Optimization Iteration:   6273, Training Accuracy:  81.2%, Loss: 0.3493\n",
      "Optimization Iteration:   6337, Training Accuracy:  59.4%, Loss: 0.4981\n",
      "Optimization Iteration:   6401, Training Accuracy:  87.5%, Loss: 0.3483\n",
      "Optimization Iteration:   6465, Training Accuracy:  81.2%, Loss: 0.3207\n",
      "Optimization Iteration:   6529, Training Accuracy:  87.5%, Loss: 0.3132\n",
      "Optimization Iteration:   6593, Training Accuracy:  71.9%, Loss: 0.3756\n",
      "Optimization Iteration:   6657, Training Accuracy:  67.2%, Loss: 0.4260\n",
      "Optimization Iteration:   6721, Training Accuracy:  79.7%, Loss: 0.3245\n",
      "Optimization Iteration:   6785, Training Accuracy:  70.3%, Loss: 0.4224\n",
      "Optimization Iteration:   6849, Training Accuracy:  75.0%, Loss: 0.3855\n",
      "Optimization Iteration:   6913, Training Accuracy:  76.6%, Loss: 0.3821\n",
      "Optimization Iteration:   6977, Training Accuracy:  71.9%, Loss: 0.4040\n",
      "Optimization Iteration:   7041, Training Accuracy:  82.8%, Loss: 0.3452\n",
      "Optimization Iteration:   7105, Training Accuracy:  78.1%, Loss: 0.3731\n",
      "Optimization Iteration:   7169, Training Accuracy:  73.4%, Loss: 0.4348\n",
      "Optimization Iteration:   7233, Training Accuracy:  76.6%, Loss: 0.4287\n",
      "Optimization Iteration:   7297, Training Accuracy:  79.7%, Loss: 0.3947\n",
      "Optimization Iteration:   7361, Training Accuracy:  73.4%, Loss: 0.3910\n",
      "Optimization Iteration:   7425, Training Accuracy:  68.8%, Loss: 0.3964\n",
      "Optimization Iteration:   7489, Training Accuracy:  79.7%, Loss: 0.3861\n",
      "Optimization Iteration:   7553, Training Accuracy:  79.7%, Loss: 0.3713\n",
      "Optimization Iteration:   7617, Training Accuracy:  82.8%, Loss: 0.3278\n",
      "Optimization Iteration:   7681, Training Accuracy:  81.2%, Loss: 0.3647\n",
      "Optimization Iteration:   7745, Training Accuracy:  68.8%, Loss: 0.4197\n",
      "Optimization Iteration:   7809, Training Accuracy:  67.2%, Loss: 0.4281\n",
      "Optimization Iteration:   7873, Training Accuracy:  79.7%, Loss: 0.3278\n",
      "Optimization Iteration:   7937, Training Accuracy:  84.4%, Loss: 0.3498\n",
      "Optimization Iteration:   8001, Training Accuracy:  79.7%, Loss: 0.3739\n",
      "Optimization Iteration:   8065, Training Accuracy:  78.1%, Loss: 0.3166\n",
      "Optimization Iteration:   8129, Training Accuracy:  78.1%, Loss: 0.3832\n",
      "Optimization Iteration:   8193, Training Accuracy:  71.9%, Loss: 0.4264\n",
      "Optimization Iteration:   8257, Training Accuracy:  70.3%, Loss: 0.4967\n",
      "Optimization Iteration:   8321, Training Accuracy:  73.4%, Loss: 0.3584\n",
      "Optimization Iteration:   8385, Training Accuracy:  70.3%, Loss: 0.4195\n",
      "Optimization Iteration:   8449, Training Accuracy:  78.1%, Loss: 0.4583\n",
      "Optimization Iteration:   8513, Training Accuracy:  84.4%, Loss: 0.3375\n",
      "Optimization Iteration:   8577, Training Accuracy:  78.1%, Loss: 0.4720\n",
      "Optimization Iteration:   8641, Training Accuracy:  71.9%, Loss: 0.3823\n",
      "Optimization Iteration:   8705, Training Accuracy:  76.6%, Loss: 0.3840\n",
      "Optimization Iteration:   8769, Training Accuracy:  79.7%, Loss: 0.3857\n",
      "Optimization Iteration:   8833, Training Accuracy:  75.0%, Loss: 0.3847\n",
      "Optimization Iteration:   8897, Training Accuracy:  71.9%, Loss: 0.4409\n",
      "Optimization Iteration:   8961, Training Accuracy:  76.6%, Loss: 0.4187\n",
      "Optimization Iteration:   9025, Training Accuracy:  78.1%, Loss: 0.3512\n",
      "Optimization Iteration:   9089, Training Accuracy:  70.3%, Loss: 0.4437\n",
      "Optimization Iteration:   9153, Training Accuracy:  68.8%, Loss: 0.4032\n",
      "Optimization Iteration:   9217, Training Accuracy:  76.6%, Loss: 0.3788\n",
      "Optimization Iteration:   9281, Training Accuracy:  71.9%, Loss: 0.4094\n",
      "Optimization Iteration:   9345, Training Accuracy:  85.9%, Loss: 0.3514\n",
      "Optimization Iteration:   9409, Training Accuracy:  65.6%, Loss: 0.5572\n",
      "Optimization Iteration:   9473, Training Accuracy:  81.2%, Loss: 0.3269\n",
      "Optimization Iteration:   9537, Training Accuracy:  75.0%, Loss: 0.3726\n",
      "Optimization Iteration:   9601, Training Accuracy:  71.9%, Loss: 0.3981\n",
      "Optimization Iteration:   9665, Training Accuracy:  68.8%, Loss: 0.4408\n",
      "Optimization Iteration:   9729, Training Accuracy:  71.9%, Loss: 0.4465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   9793, Training Accuracy:  76.6%, Loss: 0.3720\n",
      "Optimization Iteration:   9857, Training Accuracy:  68.8%, Loss: 0.4215\n",
      "Optimization Iteration:   9921, Training Accuracy:  81.2%, Loss: 0.3191\n",
      "Optimization Iteration:   9985, Training Accuracy:  76.6%, Loss: 0.4264\n",
      "Optimization Iteration:  10049, Training Accuracy:  78.1%, Loss: 0.4081\n",
      "Optimization Iteration:  10113, Training Accuracy:  81.2%, Loss: 0.3544\n",
      "Optimization Iteration:  10177, Training Accuracy:  75.0%, Loss: 0.4114\n",
      "Optimization Iteration:  10241, Training Accuracy:  71.9%, Loss: 0.4477\n",
      "Optimization Iteration:  10305, Training Accuracy:  75.0%, Loss: 0.4441\n",
      "Optimization Iteration:  10369, Training Accuracy:  75.0%, Loss: 0.3804\n",
      "Optimization Iteration:  10433, Training Accuracy:  82.8%, Loss: 0.3191\n",
      "Optimization Iteration:  10497, Training Accuracy:  71.9%, Loss: 0.4468\n",
      "Optimization Iteration:  10561, Training Accuracy:  68.8%, Loss: 0.3835\n",
      "Optimization Iteration:  10625, Training Accuracy:  73.4%, Loss: 0.3819\n",
      "Optimization Iteration:  10689, Training Accuracy:  85.9%, Loss: 0.2988\n",
      "Optimization Iteration:  10753, Training Accuracy:  78.1%, Loss: 0.4040\n",
      "Optimization Iteration:  10817, Training Accuracy:  75.0%, Loss: 0.4548\n",
      "Optimization Iteration:  10881, Training Accuracy:  68.8%, Loss: 0.3673\n",
      "Optimization Iteration:  10945, Training Accuracy:  71.9%, Loss: 0.3987\n",
      "Optimization Iteration:  11009, Training Accuracy:  84.4%, Loss: 0.2710\n",
      "Optimization Iteration:  11073, Training Accuracy:  79.7%, Loss: 0.3444\n",
      "Optimization Iteration:  11137, Training Accuracy:  76.6%, Loss: 0.3788\n",
      "Optimization Iteration:  11201, Training Accuracy:  81.2%, Loss: 0.3192\n",
      "Optimization Iteration:  11265, Training Accuracy:  82.8%, Loss: 0.3190\n",
      "Optimization Iteration:  11329, Training Accuracy:  82.8%, Loss: 0.3824\n",
      "Optimization Iteration:  11393, Training Accuracy:  76.6%, Loss: 0.4193\n",
      "Optimization Iteration:  11457, Training Accuracy:  73.4%, Loss: 0.3821\n",
      "Optimization Iteration:  11521, Training Accuracy:  70.3%, Loss: 0.3566\n",
      "Optimization Iteration:  11585, Training Accuracy:  73.4%, Loss: 0.3910\n",
      "Optimization Iteration:  11649, Training Accuracy:  75.0%, Loss: 0.4214\n",
      "Optimization Iteration:  11713, Training Accuracy:  79.7%, Loss: 0.3682\n",
      "Optimization Iteration:  11777, Training Accuracy:  78.1%, Loss: 0.3802\n",
      "Optimization Iteration:  11841, Training Accuracy:  87.5%, Loss: 0.2813\n",
      "Optimization Iteration:  11905, Training Accuracy:  76.6%, Loss: 0.3316\n",
      "Optimization Iteration:  11969, Training Accuracy:  75.0%, Loss: 0.3567\n",
      "Optimization Iteration:  12033, Training Accuracy:  78.1%, Loss: 0.4116\n",
      "Optimization Iteration:  12097, Training Accuracy:  81.2%, Loss: 0.3307\n",
      "Optimization Iteration:  12161, Training Accuracy:  85.9%, Loss: 0.3490\n",
      "Optimization Iteration:  12225, Training Accuracy:  82.8%, Loss: 0.3190\n",
      "Optimization Iteration:  12289, Training Accuracy:  79.7%, Loss: 0.3622\n",
      "Optimization Iteration:  12353, Training Accuracy:  87.5%, Loss: 0.3485\n",
      "Optimization Iteration:  12417, Training Accuracy:  79.7%, Loss: 0.3643\n",
      "Optimization Iteration:  12481, Training Accuracy:  78.1%, Loss: 0.4040\n",
      "Optimization Iteration:  12545, Training Accuracy:  75.0%, Loss: 0.4257\n",
      "Optimization Iteration:  12609, Training Accuracy:  78.1%, Loss: 0.3651\n",
      "Optimization Iteration:  12673, Training Accuracy:  75.0%, Loss: 0.4101\n",
      "Optimization Iteration:  12737, Training Accuracy:  73.4%, Loss: 0.4287\n",
      "Optimization Iteration:  12801, Training Accuracy:  73.4%, Loss: 0.3929\n",
      "Optimization Iteration:  12865, Training Accuracy:  70.3%, Loss: 0.3863\n",
      "Optimization Iteration:  12929, Training Accuracy:  75.0%, Loss: 0.3506\n",
      "Optimization Iteration:  12993, Training Accuracy:  71.9%, Loss: 0.3729\n",
      "Optimization Iteration:  13057, Training Accuracy:  71.9%, Loss: 0.4938\n",
      "Optimization Iteration:  13121, Training Accuracy:  84.4%, Loss: 0.3014\n",
      "Optimization Iteration:  13185, Training Accuracy:  84.4%, Loss: 0.4033\n",
      "Optimization Iteration:  13249, Training Accuracy:  71.9%, Loss: 0.4475\n",
      "Optimization Iteration:  13313, Training Accuracy:  68.8%, Loss: 0.4775\n",
      "Optimization Iteration:  13377, Training Accuracy:  67.2%, Loss: 0.4350\n",
      "Optimization Iteration:  13441, Training Accuracy:  78.1%, Loss: 0.3964\n",
      "Optimization Iteration:  13505, Training Accuracy:  76.6%, Loss: 0.4104\n",
      "Optimization Iteration:  13569, Training Accuracy:  87.5%, Loss: 0.2830\n",
      "Optimization Iteration:  13633, Training Accuracy:  78.1%, Loss: 0.3803\n",
      "Optimization Iteration:  13697, Training Accuracy:  82.8%, Loss: 0.3072\n",
      "Optimization Iteration:  13761, Training Accuracy:  84.4%, Loss: 0.2967\n",
      "Optimization Iteration:  13825, Training Accuracy:  79.7%, Loss: 0.3322\n",
      "Optimization Iteration:  13889, Training Accuracy:  76.6%, Loss: 0.3831\n",
      "Optimization Iteration:  13953, Training Accuracy:  75.0%, Loss: 0.3899\n",
      "Optimization Iteration:  14017, Training Accuracy:  79.7%, Loss: 0.3286\n",
      "Optimization Iteration:  14081, Training Accuracy:  71.9%, Loss: 0.3838\n",
      "Optimization Iteration:  14145, Training Accuracy:  76.6%, Loss: 0.3616\n",
      "Optimization Iteration:  14209, Training Accuracy:  81.2%, Loss: 0.3995\n",
      "Optimization Iteration:  14273, Training Accuracy:  65.6%, Loss: 0.4431\n",
      "Optimization Iteration:  14337, Training Accuracy:  81.2%, Loss: 0.2577\n",
      "Optimization Iteration:  14401, Training Accuracy:  85.9%, Loss: 0.3184\n",
      "Optimization Iteration:  14465, Training Accuracy:  81.2%, Loss: 0.4434\n",
      "Optimization Iteration:  14529, Training Accuracy:  84.4%, Loss: 0.3324\n",
      "Optimization Iteration:  14593, Training Accuracy:  79.7%, Loss: 0.3859\n",
      "Optimization Iteration:  14657, Training Accuracy:  70.3%, Loss: 0.4482\n",
      "Optimization Iteration:  14721, Training Accuracy:  73.4%, Loss: 0.4191\n",
      "Optimization Iteration:  14785, Training Accuracy:  71.9%, Loss: 0.4317\n",
      "Optimization Iteration:  14849, Training Accuracy:  71.9%, Loss: 0.4209\n",
      "Optimization Iteration:  14913, Training Accuracy:  84.4%, Loss: 0.3042\n",
      "Optimization Iteration:  14977, Training Accuracy:  76.6%, Loss: 0.4327\n",
      "Optimization Iteration:  15041, Training Accuracy:  75.0%, Loss: 0.3727\n",
      "Optimization Iteration:  15105, Training Accuracy:  79.7%, Loss: 0.3351\n",
      "Optimization Iteration:  15169, Training Accuracy:  70.3%, Loss: 0.3595\n",
      "Optimization Iteration:  15233, Training Accuracy:  76.6%, Loss: 0.3665\n",
      "Optimization Iteration:  15297, Training Accuracy:  76.6%, Loss: 0.3867\n",
      "Optimization Iteration:  15361, Training Accuracy:  85.9%, Loss: 0.3205\n",
      "Optimization Iteration:  15425, Training Accuracy:  78.1%, Loss: 0.3588\n",
      "Optimization Iteration:  15489, Training Accuracy:  82.8%, Loss: 0.4254\n",
      "Optimization Iteration:  15553, Training Accuracy:  70.3%, Loss: 0.3748\n",
      "Optimization Iteration:  15617, Training Accuracy:  78.1%, Loss: 0.3041\n",
      "Optimization Iteration:  15681, Training Accuracy:  84.4%, Loss: 0.3580\n",
      "Optimization Iteration:  15745, Training Accuracy:  85.9%, Loss: 0.3259\n",
      "Optimization Iteration:  15809, Training Accuracy:  76.6%, Loss: 0.3780\n",
      "Optimization Iteration:  15873, Training Accuracy:  65.6%, Loss: 0.4136\n",
      "Optimization Iteration:  15937, Training Accuracy:  85.9%, Loss: 0.3486\n",
      "Optimization Iteration:  16001, Training Accuracy:  68.8%, Loss: 0.4373\n",
      "Optimization Iteration:  16065, Training Accuracy:  76.6%, Loss: 0.3984\n",
      "Optimization Iteration:  16129, Training Accuracy:  78.1%, Loss: 0.3454\n",
      "Optimization Iteration:  16193, Training Accuracy:  78.1%, Loss: 0.3816\n",
      "Optimization Iteration:  16257, Training Accuracy:  81.2%, Loss: 0.3846\n",
      "Optimization Iteration:  16321, Training Accuracy:  82.8%, Loss: 0.3776\n",
      "Optimization Iteration:  16385, Training Accuracy:  76.6%, Loss: 0.3801\n",
      "Optimization Iteration:  16449, Training Accuracy:  68.8%, Loss: 0.3939\n",
      "Optimization Iteration:  16513, Training Accuracy:  75.0%, Loss: 0.4142\n",
      "Optimization Iteration:  16577, Training Accuracy:  76.6%, Loss: 0.3404\n",
      "Optimization Iteration:  16641, Training Accuracy:  70.3%, Loss: 0.5337\n",
      "Optimization Iteration:  16705, Training Accuracy:  81.2%, Loss: 0.3646\n",
      "Optimization Iteration:  16769, Training Accuracy:  76.6%, Loss: 0.3933\n",
      "Optimization Iteration:  16833, Training Accuracy:  76.6%, Loss: 0.3749\n",
      "Optimization Iteration:  16897, Training Accuracy:  81.2%, Loss: 0.3529\n",
      "Optimization Iteration:  16961, Training Accuracy:  76.6%, Loss: 0.3880\n",
      "Optimization Iteration:  17025, Training Accuracy:  67.2%, Loss: 0.5016\n",
      "Optimization Iteration:  17089, Training Accuracy:  78.1%, Loss: 0.4140\n",
      "Optimization Iteration:  17153, Training Accuracy:  78.1%, Loss: 0.3813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  17217, Training Accuracy:  81.2%, Loss: 0.4440\n",
      "Optimization Iteration:  17281, Training Accuracy:  71.9%, Loss: 0.3813\n",
      "Optimization Iteration:  17345, Training Accuracy:  79.7%, Loss: 0.3510\n",
      "Optimization Iteration:  17409, Training Accuracy:  73.4%, Loss: 0.3771\n",
      "Optimization Iteration:  17473, Training Accuracy:  57.8%, Loss: 0.4740\n",
      "Optimization Iteration:  17537, Training Accuracy:  79.7%, Loss: 0.3393\n",
      "Optimization Iteration:  17601, Training Accuracy:  75.0%, Loss: 0.4150\n",
      "Optimization Iteration:  17665, Training Accuracy:  81.2%, Loss: 0.3179\n",
      "Optimization Iteration:  17729, Training Accuracy:  71.9%, Loss: 0.3997\n",
      "Optimization Iteration:  17793, Training Accuracy:  73.4%, Loss: 0.3779\n",
      "Optimization Iteration:  17857, Training Accuracy:  78.1%, Loss: 0.3703\n",
      "Optimization Iteration:  17921, Training Accuracy:  71.9%, Loss: 0.3824\n",
      "Optimization Iteration:  17985, Training Accuracy:  76.6%, Loss: 0.3089\n",
      "Optimization Iteration:  18049, Training Accuracy:  67.2%, Loss: 0.3773\n",
      "Optimization Iteration:  18113, Training Accuracy:  68.8%, Loss: 0.4624\n",
      "Optimization Iteration:  18177, Training Accuracy:  65.6%, Loss: 0.4335\n",
      "Optimization Iteration:  18241, Training Accuracy:  71.9%, Loss: 0.4153\n",
      "Optimization Iteration:  18305, Training Accuracy:  79.7%, Loss: 0.3404\n",
      "Optimization Iteration:  18369, Training Accuracy:  71.9%, Loss: 0.3509\n",
      "Optimization Iteration:  18433, Training Accuracy:  75.0%, Loss: 0.4132\n",
      "Optimization Iteration:  18497, Training Accuracy:  81.2%, Loss: 0.2743\n",
      "Optimization Iteration:  18561, Training Accuracy:  85.9%, Loss: 0.3381\n",
      "Optimization Iteration:  18625, Training Accuracy:  68.8%, Loss: 0.4666\n",
      "Optimization Iteration:  18689, Training Accuracy:  79.7%, Loss: 0.3074\n",
      "Optimization Iteration:  18753, Training Accuracy:  78.1%, Loss: 0.3541\n",
      "Optimization Iteration:  18817, Training Accuracy:  75.0%, Loss: 0.3357\n",
      "Optimization Iteration:  18881, Training Accuracy:  71.9%, Loss: 0.3968\n",
      "Optimization Iteration:  18945, Training Accuracy:  73.4%, Loss: 0.4039\n",
      "Optimization Iteration:  19009, Training Accuracy:  75.0%, Loss: 0.3910\n",
      "Optimization Iteration:  19073, Training Accuracy:  82.8%, Loss: 0.3731\n",
      "Optimization Iteration:  19137, Training Accuracy:  68.8%, Loss: 0.5947\n",
      "Optimization Iteration:  19201, Training Accuracy:  78.1%, Loss: 0.3400\n",
      "Optimization Iteration:  19265, Training Accuracy:  71.9%, Loss: 0.4131\n",
      "Optimization Iteration:  19329, Training Accuracy:  73.4%, Loss: 0.3887\n",
      "Optimization Iteration:  19393, Training Accuracy:  82.8%, Loss: 0.3044\n",
      "Optimization Iteration:  19457, Training Accuracy:  73.4%, Loss: 0.3780\n",
      "Optimization Iteration:  19521, Training Accuracy:  82.8%, Loss: 0.3674\n",
      "Optimization Iteration:  19585, Training Accuracy:  75.0%, Loss: 0.4331\n",
      "Optimization Iteration:  19649, Training Accuracy:  73.4%, Loss: 0.4621\n",
      "Optimization Iteration:  19713, Training Accuracy:  73.4%, Loss: 0.4391\n",
      "Optimization Iteration:  19777, Training Accuracy:  78.1%, Loss: 0.4208\n",
      "Optimization Iteration:  19841, Training Accuracy:  64.1%, Loss: 0.4787\n",
      "Optimization Iteration:  19905, Training Accuracy:  75.0%, Loss: 0.3922\n",
      "Optimization Iteration:  19969, Training Accuracy:  75.0%, Loss: 0.3282\n",
      "Optimization Iteration:  20033, Training Accuracy:  87.5%, Loss: 0.3175\n",
      "Optimization Iteration:  20097, Training Accuracy:  75.0%, Loss: 0.3925\n",
      "Optimization Iteration:  20161, Training Accuracy:  70.3%, Loss: 0.4182\n",
      "Optimization Iteration:  20225, Training Accuracy:  62.5%, Loss: 0.4595\n",
      "Optimization Iteration:  20289, Training Accuracy:  76.6%, Loss: 0.4285\n",
      "Optimization Iteration:  20353, Training Accuracy:  85.9%, Loss: 0.3420\n",
      "Optimization Iteration:  20417, Training Accuracy:  75.0%, Loss: 0.3970\n",
      "Optimization Iteration:  20481, Training Accuracy:  81.2%, Loss: 0.3689\n",
      "Optimization Iteration:  20545, Training Accuracy:  75.0%, Loss: 0.4311\n",
      "Optimization Iteration:  20609, Training Accuracy:  81.2%, Loss: 0.4535\n",
      "Optimization Iteration:  20673, Training Accuracy:  82.8%, Loss: 0.3351\n",
      "Optimization Iteration:  20737, Training Accuracy:  90.6%, Loss: 0.2931\n",
      "Optimization Iteration:  20801, Training Accuracy:  78.1%, Loss: 0.3497\n",
      "Optimization Iteration:  20865, Training Accuracy:  71.9%, Loss: 0.3828\n",
      "Optimization Iteration:  20929, Training Accuracy:  92.2%, Loss: 0.2771\n",
      "Optimization Iteration:  20993, Training Accuracy:  81.2%, Loss: 0.3342\n",
      "Optimization Iteration:  21057, Training Accuracy:  81.2%, Loss: 0.3763\n",
      "Optimization Iteration:  21121, Training Accuracy:  75.0%, Loss: 0.3592\n",
      "Optimization Iteration:  21185, Training Accuracy:  73.4%, Loss: 0.4010\n",
      "Optimization Iteration:  21249, Training Accuracy:  73.4%, Loss: 0.4255\n",
      "Optimization Iteration:  21313, Training Accuracy:  73.4%, Loss: 0.3781\n",
      "Optimization Iteration:  21377, Training Accuracy:  85.9%, Loss: 0.2899\n",
      "Optimization Iteration:  21441, Training Accuracy:  75.0%, Loss: 0.3664\n",
      "Optimization Iteration:  21505, Training Accuracy:  81.2%, Loss: 0.3809\n",
      "Optimization Iteration:  21569, Training Accuracy:  78.1%, Loss: 0.3640\n",
      "Optimization Iteration:  21633, Training Accuracy:  89.1%, Loss: 0.2997\n",
      "Optimization Iteration:  21697, Training Accuracy:  78.1%, Loss: 0.4331\n",
      "Optimization Iteration:  21761, Training Accuracy:  84.4%, Loss: 0.2932\n",
      "Optimization Iteration:  21825, Training Accuracy:  76.6%, Loss: 0.3930\n",
      "Optimization Iteration:  21889, Training Accuracy:  87.5%, Loss: 0.2943\n",
      "Optimization Iteration:  21953, Training Accuracy:  82.8%, Loss: 0.3903\n",
      "Optimization Iteration:  22017, Training Accuracy:  76.6%, Loss: 0.3867\n",
      "Optimization Iteration:  22081, Training Accuracy:  78.1%, Loss: 0.4003\n",
      "Optimization Iteration:  22145, Training Accuracy:  78.1%, Loss: 0.3792\n",
      "Optimization Iteration:  22209, Training Accuracy:  84.4%, Loss: 0.3727\n",
      "Optimization Iteration:  22273, Training Accuracy:  78.1%, Loss: 0.3882\n",
      "Optimization Iteration:  22337, Training Accuracy:  79.7%, Loss: 0.3214\n",
      "Optimization Iteration:  22401, Training Accuracy:  87.5%, Loss: 0.3853\n",
      "Optimization Iteration:  22465, Training Accuracy:  79.7%, Loss: 0.3522\n",
      "Optimization Iteration:  22529, Training Accuracy:  79.7%, Loss: 0.3097\n",
      "Optimization Iteration:  22593, Training Accuracy:  76.6%, Loss: 0.3527\n",
      "Optimization Iteration:  22657, Training Accuracy:  71.9%, Loss: 0.4338\n",
      "Optimization Iteration:  22721, Training Accuracy:  82.8%, Loss: 0.3740\n",
      "Optimization Iteration:  22785, Training Accuracy:  70.3%, Loss: 0.4175\n",
      "Optimization Iteration:  22849, Training Accuracy:  78.1%, Loss: 0.3611\n",
      "Optimization Iteration:  22913, Training Accuracy:  71.9%, Loss: 0.3828\n",
      "Optimization Iteration:  22977, Training Accuracy:  78.1%, Loss: 0.3818\n",
      "Optimization Iteration:  23041, Training Accuracy:  81.2%, Loss: 0.3007\n",
      "Optimization Iteration:  23105, Training Accuracy:  78.1%, Loss: 0.3376\n",
      "Optimization Iteration:  23169, Training Accuracy:  70.3%, Loss: 0.4184\n",
      "Optimization Iteration:  23233, Training Accuracy:  75.0%, Loss: 0.4453\n",
      "Optimization Iteration:  23297, Training Accuracy:  81.2%, Loss: 0.3750\n",
      "Optimization Iteration:  23361, Training Accuracy:  81.2%, Loss: 0.3567\n",
      "Optimization Iteration:  23425, Training Accuracy:  76.6%, Loss: 0.3417\n",
      "Optimization Iteration:  23489, Training Accuracy:  82.8%, Loss: 0.3768\n",
      "Optimization Iteration:  23553, Training Accuracy:  79.7%, Loss: 0.3556\n",
      "Optimization Iteration:  23617, Training Accuracy:  73.4%, Loss: 0.4593\n",
      "Optimization Iteration:  23681, Training Accuracy:  76.6%, Loss: 0.3749\n",
      "Optimization Iteration:  23745, Training Accuracy:  70.3%, Loss: 0.3490\n",
      "Optimization Iteration:  23809, Training Accuracy:  75.0%, Loss: 0.4173\n",
      "Optimization Iteration:  23873, Training Accuracy:  81.2%, Loss: 0.3289\n",
      "Optimization Iteration:  23937, Training Accuracy:  70.3%, Loss: 0.4224\n",
      "Optimization Iteration:  24001, Training Accuracy:  81.2%, Loss: 0.3313\n",
      "Optimization Iteration:  24065, Training Accuracy:  82.8%, Loss: 0.3318\n",
      "Optimization Iteration:  24129, Training Accuracy:  78.1%, Loss: 0.3431\n",
      "Optimization Iteration:  24193, Training Accuracy:  73.4%, Loss: 0.4297\n",
      "Optimization Iteration:  24257, Training Accuracy:  78.1%, Loss: 0.3997\n",
      "Optimization Iteration:  24321, Training Accuracy:  75.0%, Loss: 0.4239\n",
      "Optimization Iteration:  24385, Training Accuracy:  75.0%, Loss: 0.4147\n",
      "Optimization Iteration:  24449, Training Accuracy:  76.6%, Loss: 0.3585\n",
      "Optimization Iteration:  24513, Training Accuracy:  71.9%, Loss: 0.4033\n",
      "Optimization Iteration:  24577, Training Accuracy:  71.9%, Loss: 0.4647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  24641, Training Accuracy:  76.6%, Loss: 0.3830\n",
      "Optimization Iteration:  24705, Training Accuracy:  81.2%, Loss: 0.2920\n",
      "Optimization Iteration:  24769, Training Accuracy:  78.1%, Loss: 0.3255\n",
      "Optimization Iteration:  24833, Training Accuracy:  79.7%, Loss: 0.3274\n",
      "Optimization Iteration:  24897, Training Accuracy:  79.7%, Loss: 0.3762\n",
      "Optimization Iteration:  24961, Training Accuracy:  85.9%, Loss: 0.2906\n",
      "Optimization Iteration:  25025, Training Accuracy:  82.8%, Loss: 0.3825\n",
      "Optimization Iteration:  25089, Training Accuracy:  79.7%, Loss: 0.3628\n",
      "Optimization Iteration:  25153, Training Accuracy:  75.0%, Loss: 0.4036\n",
      "Optimization Iteration:  25217, Training Accuracy:  67.2%, Loss: 0.4660\n",
      "Optimization Iteration:  25281, Training Accuracy:  73.4%, Loss: 0.4395\n",
      "Optimization Iteration:  25345, Training Accuracy:  73.4%, Loss: 0.4650\n",
      "Optimization Iteration:  25409, Training Accuracy:  76.6%, Loss: 0.4032\n",
      "Optimization Iteration:  25473, Training Accuracy:  75.0%, Loss: 0.4203\n",
      "Optimization Iteration:  25537, Training Accuracy:  81.2%, Loss: 0.3502\n",
      "Optimization Iteration:  25601, Training Accuracy:  70.3%, Loss: 0.4622\n",
      "Optimization Iteration:  25665, Training Accuracy:  76.6%, Loss: 0.3793\n",
      "Optimization Iteration:  25729, Training Accuracy:  82.8%, Loss: 0.2801\n",
      "Optimization Iteration:  25793, Training Accuracy:  64.1%, Loss: 0.5043\n",
      "Optimization Iteration:  25857, Training Accuracy:  73.4%, Loss: 0.4244\n",
      "Optimization Iteration:  25921, Training Accuracy:  82.8%, Loss: 0.3834\n",
      "Optimization Iteration:  25985, Training Accuracy:  79.7%, Loss: 0.3464\n",
      "Optimization Iteration:  26049, Training Accuracy:  82.8%, Loss: 0.4166\n",
      "Optimization Iteration:  26113, Training Accuracy:  65.6%, Loss: 0.4375\n",
      "Optimization Iteration:  26177, Training Accuracy:  71.9%, Loss: 0.3652\n",
      "Optimization Iteration:  26241, Training Accuracy:  73.4%, Loss: 0.3649\n",
      "Optimization Iteration:  26305, Training Accuracy:  79.7%, Loss: 0.3471\n",
      "Optimization Iteration:  26369, Training Accuracy:  64.1%, Loss: 0.4104\n",
      "Optimization Iteration:  26433, Training Accuracy:  68.8%, Loss: 0.4296\n",
      "Optimization Iteration:  26497, Training Accuracy:  84.4%, Loss: 0.3430\n",
      "Optimization Iteration:  26561, Training Accuracy:  79.7%, Loss: 0.3758\n",
      "Optimization Iteration:  26625, Training Accuracy:  78.1%, Loss: 0.3612\n",
      "Optimization Iteration:  26689, Training Accuracy:  75.0%, Loss: 0.4310\n",
      "Optimization Iteration:  26753, Training Accuracy:  76.6%, Loss: 0.3917\n",
      "Optimization Iteration:  26817, Training Accuracy:  71.9%, Loss: 0.3703\n",
      "Optimization Iteration:  26881, Training Accuracy:  82.8%, Loss: 0.3656\n",
      "Optimization Iteration:  26945, Training Accuracy:  68.8%, Loss: 0.3949\n",
      "Optimization Iteration:  27009, Training Accuracy:  71.9%, Loss: 0.3776\n",
      "Optimization Iteration:  27073, Training Accuracy:  81.2%, Loss: 0.4033\n",
      "Optimization Iteration:  27137, Training Accuracy:  78.1%, Loss: 0.4035\n",
      "Optimization Iteration:  27201, Training Accuracy:  76.6%, Loss: 0.3177\n",
      "Optimization Iteration:  27265, Training Accuracy:  81.2%, Loss: 0.2901\n",
      "Optimization Iteration:  27329, Training Accuracy:  78.1%, Loss: 0.3686\n",
      "Optimization Iteration:  27393, Training Accuracy:  75.0%, Loss: 0.4011\n",
      "Optimization Iteration:  27457, Training Accuracy:  78.1%, Loss: 0.4072\n",
      "Optimization Iteration:  27521, Training Accuracy:  82.8%, Loss: 0.3971\n",
      "Optimization Iteration:  27585, Training Accuracy:  75.0%, Loss: 0.3948\n",
      "Optimization Iteration:  27649, Training Accuracy:  75.0%, Loss: 0.3606\n",
      "Optimization Iteration:  27713, Training Accuracy:  71.9%, Loss: 0.4758\n",
      "Optimization Iteration:  27777, Training Accuracy:  82.8%, Loss: 0.3445\n",
      "Optimization Iteration:  27841, Training Accuracy:  76.6%, Loss: 0.4232\n",
      "Optimization Iteration:  27905, Training Accuracy:  76.6%, Loss: 0.3669\n",
      "Optimization Iteration:  27969, Training Accuracy:  64.1%, Loss: 0.4390\n",
      "Optimization Iteration:  28033, Training Accuracy:  82.8%, Loss: 0.3584\n",
      "Optimization Iteration:  28097, Training Accuracy:  73.4%, Loss: 0.3540\n",
      "Optimization Iteration:  28161, Training Accuracy:  81.2%, Loss: 0.3455\n",
      "Optimization Iteration:  28225, Training Accuracy:  78.1%, Loss: 0.3369\n",
      "Optimization Iteration:  28289, Training Accuracy:  76.6%, Loss: 0.3860\n",
      "Optimization Iteration:  28353, Training Accuracy:  81.2%, Loss: 0.3844\n",
      "Optimization Iteration:  28417, Training Accuracy:  71.9%, Loss: 0.4288\n",
      "Optimization Iteration:  28481, Training Accuracy:  71.9%, Loss: 0.3900\n",
      "Optimization Iteration:  28545, Training Accuracy:  82.8%, Loss: 0.3251\n",
      "Optimization Iteration:  28609, Training Accuracy:  78.1%, Loss: 0.3773\n",
      "Optimization Iteration:  28673, Training Accuracy:  71.9%, Loss: 0.5089\n",
      "Optimization Iteration:  28737, Training Accuracy:  81.2%, Loss: 0.3256\n",
      "Optimization Iteration:  28801, Training Accuracy:  75.0%, Loss: 0.3550\n",
      "Optimization Iteration:  28865, Training Accuracy:  82.8%, Loss: 0.3128\n",
      "Optimization Iteration:  28929, Training Accuracy:  82.8%, Loss: 0.3264\n",
      "Optimization Iteration:  28993, Training Accuracy:  71.9%, Loss: 0.3861\n",
      "Optimization Iteration:  29057, Training Accuracy:  71.9%, Loss: 0.4031\n",
      "Optimization Iteration:  29121, Training Accuracy:  78.1%, Loss: 0.4830\n",
      "Optimization Iteration:  29185, Training Accuracy:  81.2%, Loss: 0.3541\n",
      "Optimization Iteration:  29249, Training Accuracy:  82.8%, Loss: 0.3814\n",
      "Optimization Iteration:  29313, Training Accuracy:  76.6%, Loss: 0.3980\n",
      "Optimization Iteration:  29377, Training Accuracy:  79.7%, Loss: 0.3284\n",
      "Optimization Iteration:  29441, Training Accuracy:  73.4%, Loss: 0.4407\n",
      "Optimization Iteration:  29505, Training Accuracy:  78.1%, Loss: 0.4331\n",
      "Optimization Iteration:  29569, Training Accuracy:  78.1%, Loss: 0.4165\n",
      "Optimization Iteration:  29633, Training Accuracy:  73.4%, Loss: 0.3559\n",
      "Optimization Iteration:  29697, Training Accuracy:  84.4%, Loss: 0.3734\n",
      "Optimization Iteration:  29761, Training Accuracy:  75.0%, Loss: 0.3789\n",
      "Optimization Iteration:  29825, Training Accuracy:  76.6%, Loss: 0.4118\n",
      "Optimization Iteration:  29889, Training Accuracy:  71.9%, Loss: 0.4142\n",
      "Optimization Iteration:  29953, Training Accuracy:  71.9%, Loss: 0.4739\n",
      "Optimization Iteration:  30017, Training Accuracy:  84.4%, Loss: 0.3308\n",
      "Optimization Iteration:  30081, Training Accuracy:  84.4%, Loss: 0.3579\n",
      "Optimization Iteration:  30145, Training Accuracy:  87.5%, Loss: 0.3435\n",
      "Optimization Iteration:  30209, Training Accuracy:  79.7%, Loss: 0.3490\n",
      "Optimization Iteration:  30273, Training Accuracy:  76.6%, Loss: 0.3610\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.3779\n",
      "Optimization Iteration:  30401, Training Accuracy:  82.8%, Loss: 0.3417\n",
      "Optimization Iteration:  30465, Training Accuracy:  84.4%, Loss: 0.3703\n",
      "Optimization Iteration:  30529, Training Accuracy:  76.6%, Loss: 0.3737\n",
      "Optimization Iteration:  30593, Training Accuracy:  78.1%, Loss: 0.3606\n",
      "Optimization Iteration:  30657, Training Accuracy:  76.6%, Loss: 0.3786\n",
      "Optimization Iteration:  30721, Training Accuracy:  70.3%, Loss: 0.3843\n",
      "Optimization Iteration:  30785, Training Accuracy:  76.6%, Loss: 0.4171\n",
      "Optimization Iteration:  30849, Training Accuracy:  70.3%, Loss: 0.4154\n",
      "Optimization Iteration:  30913, Training Accuracy:  84.4%, Loss: 0.4427\n",
      "Optimization Iteration:  30977, Training Accuracy:  70.3%, Loss: 0.4206\n",
      "Optimization Iteration:  31041, Training Accuracy:  76.6%, Loss: 0.3493\n",
      "Optimization Iteration:  31105, Training Accuracy:  75.0%, Loss: 0.4534\n",
      "Optimization Iteration:  31169, Training Accuracy:  81.2%, Loss: 0.2912\n",
      "Optimization Iteration:  31233, Training Accuracy:  78.1%, Loss: 0.3372\n",
      "Optimization Iteration:  31297, Training Accuracy:  79.7%, Loss: 0.3349\n",
      "Optimization Iteration:  31361, Training Accuracy:  68.8%, Loss: 0.4026\n",
      "Optimization Iteration:  31425, Training Accuracy:  78.1%, Loss: 0.3294\n",
      "Optimization Iteration:  31489, Training Accuracy:  75.0%, Loss: 0.3651\n",
      "Optimization Iteration:  31553, Training Accuracy:  73.4%, Loss: 0.3765\n",
      "Optimization Iteration:  31617, Training Accuracy:  78.1%, Loss: 0.3941\n",
      "Optimization Iteration:  31681, Training Accuracy:  84.4%, Loss: 0.3027\n",
      "Optimization Iteration:  31745, Training Accuracy:  78.1%, Loss: 0.3425\n",
      "Optimization Iteration:  31809, Training Accuracy:  67.2%, Loss: 0.4944\n",
      "Optimization Iteration:  31873, Training Accuracy:  82.8%, Loss: 0.3329\n",
      "Optimization Iteration:  31937, Training Accuracy:  67.2%, Loss: 0.4681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  32001, Training Accuracy:  65.6%, Loss: 0.4336\n",
      "Optimization Iteration:  32065, Training Accuracy:  79.7%, Loss: 0.2779\n",
      "Optimization Iteration:  32129, Training Accuracy:  73.4%, Loss: 0.3931\n",
      "Optimization Iteration:  32193, Training Accuracy:  68.8%, Loss: 0.4796\n",
      "Optimization Iteration:  32257, Training Accuracy:  73.4%, Loss: 0.3869\n",
      "Optimization Iteration:  32321, Training Accuracy:  78.1%, Loss: 0.3580\n",
      "Optimization Iteration:  32385, Training Accuracy:  81.2%, Loss: 0.3262\n",
      "Optimization Iteration:  32449, Training Accuracy:  71.9%, Loss: 0.4743\n",
      "Optimization Iteration:  32513, Training Accuracy:  71.9%, Loss: 0.3423\n",
      "Optimization Iteration:  32577, Training Accuracy:  71.9%, Loss: 0.3728\n",
      "Optimization Iteration:  32641, Training Accuracy:  75.0%, Loss: 0.3987\n",
      "Optimization Iteration:  32705, Training Accuracy:  78.1%, Loss: 0.3381\n",
      "Optimization Iteration:  32769, Training Accuracy:  78.1%, Loss: 0.3762\n",
      "Optimization Iteration:  32833, Training Accuracy:  78.1%, Loss: 0.3616\n",
      "Optimization Iteration:  32897, Training Accuracy:  85.9%, Loss: 0.3642\n",
      "Optimization Iteration:  32961, Training Accuracy:  71.9%, Loss: 0.4963\n",
      "Optimization Iteration:  33025, Training Accuracy:  84.4%, Loss: 0.3585\n",
      "Optimization Iteration:  33089, Training Accuracy:  78.1%, Loss: 0.4256\n",
      "Optimization Iteration:  33153, Training Accuracy:  75.0%, Loss: 0.4674\n",
      "Optimization Iteration:  33217, Training Accuracy:  79.7%, Loss: 0.3721\n",
      "Optimization Iteration:  33281, Training Accuracy:  71.9%, Loss: 0.4686\n",
      "Optimization Iteration:  33345, Training Accuracy:  73.4%, Loss: 0.4018\n",
      "Optimization Iteration:  33409, Training Accuracy:  73.4%, Loss: 0.4037\n",
      "Optimization Iteration:  33473, Training Accuracy:  75.0%, Loss: 0.4008\n",
      "Optimization Iteration:  33537, Training Accuracy:  70.3%, Loss: 0.4210\n",
      "Optimization Iteration:  33601, Training Accuracy:  75.0%, Loss: 0.4777\n",
      "Optimization Iteration:  33665, Training Accuracy:  84.4%, Loss: 0.3728\n",
      "Optimization Iteration:  33729, Training Accuracy:  76.6%, Loss: 0.4370\n",
      "Optimization Iteration:  33793, Training Accuracy:  71.9%, Loss: 0.4901\n",
      "Optimization Iteration:  33857, Training Accuracy:  78.1%, Loss: 0.3609\n",
      "Optimization Iteration:  33921, Training Accuracy:  76.6%, Loss: 0.4193\n",
      "Optimization Iteration:  33985, Training Accuracy:  75.0%, Loss: 0.3626\n",
      "Optimization Iteration:  34049, Training Accuracy:  71.9%, Loss: 0.4058\n",
      "Optimization Iteration:  34113, Training Accuracy:  76.6%, Loss: 0.3645\n",
      "Optimization Iteration:  34177, Training Accuracy:  75.0%, Loss: 0.3639\n",
      "Optimization Iteration:  34241, Training Accuracy:  82.8%, Loss: 0.4115\n",
      "Optimization Iteration:  34305, Training Accuracy:  68.8%, Loss: 0.4145\n",
      "Optimization Iteration:  34369, Training Accuracy:  73.4%, Loss: 0.3350\n",
      "Optimization Iteration:  34433, Training Accuracy:  71.9%, Loss: 0.4762\n",
      "Optimization Iteration:  34497, Training Accuracy:  75.0%, Loss: 0.3822\n",
      "Optimization Iteration:  34561, Training Accuracy:  81.2%, Loss: 0.3532\n",
      "Optimization Iteration:  34625, Training Accuracy:  70.3%, Loss: 0.4322\n",
      "Optimization Iteration:  34689, Training Accuracy:  73.4%, Loss: 0.3884\n",
      "Optimization Iteration:  34753, Training Accuracy:  71.9%, Loss: 0.4835\n",
      "Optimization Iteration:  34817, Training Accuracy:  79.7%, Loss: 0.4039\n",
      "Optimization Iteration:  34881, Training Accuracy:  76.6%, Loss: 0.3572\n",
      "Optimization Iteration:  34945, Training Accuracy:  79.7%, Loss: 0.3635\n",
      "Optimization Iteration:  35009, Training Accuracy:  92.2%, Loss: 0.3447\n",
      "Optimization Iteration:  35073, Training Accuracy:  82.8%, Loss: 0.3505\n",
      "Optimization Iteration:  35137, Training Accuracy:  78.1%, Loss: 0.3564\n",
      "Optimization Iteration:  35201, Training Accuracy:  82.8%, Loss: 0.3894\n",
      "Optimization Iteration:  35265, Training Accuracy:  65.6%, Loss: 0.4413\n",
      "Optimization Iteration:  35329, Training Accuracy:  78.1%, Loss: 0.4534\n",
      "Optimization Iteration:  35393, Training Accuracy:  78.1%, Loss: 0.3905\n",
      "Optimization Iteration:  35457, Training Accuracy:  76.6%, Loss: 0.3551\n",
      "Optimization Iteration:  35521, Training Accuracy:  76.6%, Loss: 0.3593\n",
      "Optimization Iteration:  35585, Training Accuracy:  84.4%, Loss: 0.2835\n",
      "Optimization Iteration:  35649, Training Accuracy:  60.9%, Loss: 0.5050\n",
      "Optimization Iteration:  35713, Training Accuracy:  62.5%, Loss: 0.4597\n",
      "Optimization Iteration:  35777, Training Accuracy:  82.8%, Loss: 0.2795\n",
      "Optimization Iteration:  35841, Training Accuracy:  81.2%, Loss: 0.3883\n",
      "Optimization Iteration:  35905, Training Accuracy:  84.4%, Loss: 0.3791\n",
      "Optimization Iteration:  35969, Training Accuracy:  75.0%, Loss: 0.4337\n",
      "Optimization Iteration:  36033, Training Accuracy:  79.7%, Loss: 0.3597\n",
      "Optimization Iteration:  36097, Training Accuracy:  70.3%, Loss: 0.4333\n",
      "Optimization Iteration:  36161, Training Accuracy:  75.0%, Loss: 0.4129\n",
      "Optimization Iteration:  36225, Training Accuracy:  78.1%, Loss: 0.3863\n",
      "Optimization Iteration:  36289, Training Accuracy:  76.6%, Loss: 0.3287\n",
      "Optimization Iteration:  36353, Training Accuracy:  78.1%, Loss: 0.3425\n",
      "Optimization Iteration:  36417, Training Accuracy:  76.6%, Loss: 0.3690\n",
      "Optimization Iteration:  36481, Training Accuracy:  82.8%, Loss: 0.3047\n",
      "Optimization Iteration:  36545, Training Accuracy:  81.2%, Loss: 0.3107\n",
      "Optimization Iteration:  36609, Training Accuracy:  79.7%, Loss: 0.3644\n",
      "Optimization Iteration:  36673, Training Accuracy:  75.0%, Loss: 0.3845\n",
      "Optimization Iteration:  36737, Training Accuracy:  82.8%, Loss: 0.3647\n",
      "Optimization Iteration:  36801, Training Accuracy:  78.1%, Loss: 0.3463\n",
      "Optimization Iteration:  36865, Training Accuracy:  78.1%, Loss: 0.4153\n",
      "Optimization Iteration:  36929, Training Accuracy:  75.0%, Loss: 0.4409\n",
      "Optimization Iteration:  36993, Training Accuracy:  79.7%, Loss: 0.3388\n",
      "Optimization Iteration:  37057, Training Accuracy:  81.2%, Loss: 0.3065\n",
      "Optimization Iteration:  37121, Training Accuracy:  90.6%, Loss: 0.2406\n",
      "Optimization Iteration:  37185, Training Accuracy:  71.9%, Loss: 0.4557\n",
      "Optimization Iteration:  37249, Training Accuracy:  67.2%, Loss: 0.4599\n",
      "Optimization Iteration:  37313, Training Accuracy:  81.2%, Loss: 0.3026\n",
      "Optimization Iteration:  37377, Training Accuracy:  82.8%, Loss: 0.3427\n",
      "Optimization Iteration:  37441, Training Accuracy:  68.8%, Loss: 0.4142\n",
      "Optimization Iteration:  37505, Training Accuracy:  75.0%, Loss: 0.4104\n",
      "Optimization Iteration:  37569, Training Accuracy:  67.2%, Loss: 0.4992\n",
      "Optimization Iteration:  37633, Training Accuracy:  70.3%, Loss: 0.4456\n",
      "Optimization Iteration:  37697, Training Accuracy:  76.6%, Loss: 0.3200\n",
      "Optimization Iteration:  37761, Training Accuracy:  76.6%, Loss: 0.3951\n",
      "Optimization Iteration:  37825, Training Accuracy:  73.4%, Loss: 0.4081\n",
      "Optimization Iteration:  37889, Training Accuracy:  79.7%, Loss: 0.3705\n",
      "Optimization Iteration:  37953, Training Accuracy:  78.1%, Loss: 0.3753\n",
      "Optimization Iteration:  38017, Training Accuracy:  81.2%, Loss: 0.4584\n",
      "Optimization Iteration:  38081, Training Accuracy:  76.6%, Loss: 0.4259\n",
      "Optimization Iteration:  38145, Training Accuracy:  76.6%, Loss: 0.3616\n",
      "Optimization Iteration:  38209, Training Accuracy:  79.7%, Loss: 0.3627\n",
      "Optimization Iteration:  38273, Training Accuracy:  82.8%, Loss: 0.3314\n",
      "Optimization Iteration:  38337, Training Accuracy:  81.2%, Loss: 0.2671\n",
      "Optimization Iteration:  38401, Training Accuracy:  79.7%, Loss: 0.3705\n",
      "Optimization Iteration:  38465, Training Accuracy:  81.2%, Loss: 0.3501\n",
      "Optimization Iteration:  38529, Training Accuracy:  75.0%, Loss: 0.3730\n",
      "Optimization Iteration:  38593, Training Accuracy:  76.6%, Loss: 0.4267\n",
      "Optimization Iteration:  38657, Training Accuracy:  73.4%, Loss: 0.4273\n",
      "Optimization Iteration:  38721, Training Accuracy:  87.5%, Loss: 0.3331\n",
      "Optimization Iteration:  38785, Training Accuracy:  76.6%, Loss: 0.3933\n",
      "Optimization Iteration:  38849, Training Accuracy:  84.4%, Loss: 0.3325\n",
      "Optimization Iteration:  38913, Training Accuracy:  75.0%, Loss: 0.3521\n",
      "Optimization Iteration:  38977, Training Accuracy:  82.8%, Loss: 0.3374\n",
      "Optimization Iteration:  39041, Training Accuracy:  73.4%, Loss: 0.3995\n",
      "Optimization Iteration:  39105, Training Accuracy:  68.8%, Loss: 0.4364\n",
      "Optimization Iteration:  39169, Training Accuracy:  65.6%, Loss: 0.4403\n",
      "Optimization Iteration:  39233, Training Accuracy:  71.9%, Loss: 0.4471\n",
      "Optimization Iteration:  39297, Training Accuracy:  79.7%, Loss: 0.3402\n",
      "Optimization Iteration:  39361, Training Accuracy:  79.7%, Loss: 0.3422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  39425, Training Accuracy:  76.6%, Loss: 0.4099\n",
      "Optimization Iteration:  39489, Training Accuracy:  76.6%, Loss: 0.3259\n",
      "Optimization Iteration:  39553, Training Accuracy:  81.2%, Loss: 0.3660\n",
      "Optimization Iteration:  39617, Training Accuracy:  79.7%, Loss: 0.4721\n",
      "Optimization Iteration:  39681, Training Accuracy:  71.9%, Loss: 0.4333\n",
      "Optimization Iteration:  39745, Training Accuracy:  73.4%, Loss: 0.4042\n",
      "Optimization Iteration:  39809, Training Accuracy:  78.1%, Loss: 0.3329\n",
      "Optimization Iteration:  39873, Training Accuracy:  67.2%, Loss: 0.5092\n",
      "Optimization Iteration:  39937, Training Accuracy:  75.0%, Loss: 0.4059\n",
      "Optimization Iteration:  40001, Training Accuracy:  75.0%, Loss: 0.3848\n",
      "Optimization Iteration:  40065, Training Accuracy:  59.4%, Loss: 0.4219\n",
      "Optimization Iteration:  40129, Training Accuracy:  70.3%, Loss: 0.4236\n",
      "Optimization Iteration:  40193, Training Accuracy:  85.9%, Loss: 0.3047\n",
      "Optimization Iteration:  40257, Training Accuracy:  78.1%, Loss: 0.4098\n",
      "Optimization Iteration:  40321, Training Accuracy:  70.3%, Loss: 0.4038\n",
      "Optimization Iteration:  40385, Training Accuracy:  73.4%, Loss: 0.3994\n",
      "Optimization Iteration:  40449, Training Accuracy:  70.3%, Loss: 0.4208\n",
      "Optimization Iteration:  40513, Training Accuracy:  85.9%, Loss: 0.3572\n",
      "Optimization Iteration:  40577, Training Accuracy:  73.4%, Loss: 0.3562\n",
      "Optimization Iteration:  40641, Training Accuracy:  78.1%, Loss: 0.3577\n",
      "Optimization Iteration:  40705, Training Accuracy:  82.8%, Loss: 0.3353\n",
      "Optimization Iteration:  40769, Training Accuracy:  79.7%, Loss: 0.3556\n",
      "Optimization Iteration:  40833, Training Accuracy:  82.8%, Loss: 0.3019\n",
      "Optimization Iteration:  40897, Training Accuracy:  78.1%, Loss: 0.3523\n",
      "Optimization Iteration:  40961, Training Accuracy:  82.8%, Loss: 0.3116\n",
      "Optimization Iteration:  41025, Training Accuracy:  79.7%, Loss: 0.3440\n",
      "Optimization Iteration:  41089, Training Accuracy:  78.1%, Loss: 0.3692\n",
      "Optimization Iteration:  41153, Training Accuracy:  78.1%, Loss: 0.4009\n",
      "Optimization Iteration:  41217, Training Accuracy:  75.0%, Loss: 0.3775\n",
      "Optimization Iteration:  41281, Training Accuracy:  60.9%, Loss: 0.4464\n",
      "Optimization Iteration:  41345, Training Accuracy:  82.8%, Loss: 0.4023\n",
      "Optimization Iteration:  41409, Training Accuracy:  70.3%, Loss: 0.4116\n",
      "Optimization Iteration:  41473, Training Accuracy:  78.1%, Loss: 0.3706\n",
      "Optimization Iteration:  41537, Training Accuracy:  78.1%, Loss: 0.4298\n",
      "Optimization Iteration:  41601, Training Accuracy:  71.9%, Loss: 0.3947\n",
      "Optimization Iteration:  41665, Training Accuracy:  78.1%, Loss: 0.3705\n",
      "Optimization Iteration:  41729, Training Accuracy:  78.1%, Loss: 0.2750\n",
      "Optimization Iteration:  41793, Training Accuracy:  71.9%, Loss: 0.4415\n",
      "Optimization Iteration:  41857, Training Accuracy:  78.1%, Loss: 0.4063\n",
      "Optimization Iteration:  41921, Training Accuracy:  78.1%, Loss: 0.3300\n",
      "Optimization Iteration:  41985, Training Accuracy:  81.2%, Loss: 0.4323\n",
      "Optimization Iteration:  42049, Training Accuracy:  76.6%, Loss: 0.3900\n",
      "Optimization Iteration:  42113, Training Accuracy:  71.9%, Loss: 0.3807\n",
      "Optimization Iteration:  42177, Training Accuracy:  79.7%, Loss: 0.3778\n",
      "Optimization Iteration:  42241, Training Accuracy:  79.7%, Loss: 0.4280\n",
      "Optimization Iteration:  42305, Training Accuracy:  68.8%, Loss: 0.5036\n",
      "Optimization Iteration:  42369, Training Accuracy:  71.9%, Loss: 0.3893\n",
      "Optimization Iteration:  42433, Training Accuracy:  75.0%, Loss: 0.4394\n",
      "Optimization Iteration:  42497, Training Accuracy:  76.6%, Loss: 0.3840\n",
      "Optimization Iteration:  42561, Training Accuracy:  78.1%, Loss: 0.3960\n",
      "Optimization Iteration:  42625, Training Accuracy:  76.6%, Loss: 0.3274\n",
      "Optimization Iteration:  42689, Training Accuracy:  75.0%, Loss: 0.3522\n",
      "Optimization Iteration:  42753, Training Accuracy:  76.6%, Loss: 0.3915\n",
      "Optimization Iteration:  42817, Training Accuracy:  82.8%, Loss: 0.3094\n",
      "Optimization Iteration:  42881, Training Accuracy:  64.1%, Loss: 0.4886\n",
      "Optimization Iteration:  42945, Training Accuracy:  75.0%, Loss: 0.3936\n",
      "Optimization Iteration:  43009, Training Accuracy:  71.9%, Loss: 0.4665\n",
      "Optimization Iteration:  43073, Training Accuracy:  81.2%, Loss: 0.3540\n",
      "Optimization Iteration:  43137, Training Accuracy:  84.4%, Loss: 0.3633\n",
      "Optimization Iteration:  43201, Training Accuracy:  76.6%, Loss: 0.3878\n",
      "Optimization Iteration:  43265, Training Accuracy:  84.4%, Loss: 0.3477\n",
      "Optimization Iteration:  43329, Training Accuracy:  81.2%, Loss: 0.3754\n",
      "Optimization Iteration:  43393, Training Accuracy:  73.4%, Loss: 0.3521\n",
      "Optimization Iteration:  43457, Training Accuracy:  79.7%, Loss: 0.3322\n",
      "Optimization Iteration:  43521, Training Accuracy:  84.4%, Loss: 0.4195\n",
      "Optimization Iteration:  43585, Training Accuracy:  70.3%, Loss: 0.4106\n",
      "Optimization Iteration:  43649, Training Accuracy:  81.2%, Loss: 0.3443\n",
      "Optimization Iteration:  43713, Training Accuracy:  84.4%, Loss: 0.3547\n",
      "Optimization Iteration:  43777, Training Accuracy:  84.4%, Loss: 0.3134\n",
      "Optimization Iteration:  43841, Training Accuracy:  82.8%, Loss: 0.3531\n",
      "Optimization Iteration:  43905, Training Accuracy:  81.2%, Loss: 0.3478\n",
      "Optimization Iteration:  43969, Training Accuracy:  79.7%, Loss: 0.3083\n",
      "Optimization Iteration:  44033, Training Accuracy:  76.6%, Loss: 0.3582\n",
      "Optimization Iteration:  44097, Training Accuracy:  84.4%, Loss: 0.3667\n",
      "Optimization Iteration:  44161, Training Accuracy:  76.6%, Loss: 0.3700\n",
      "Optimization Iteration:  44225, Training Accuracy:  73.4%, Loss: 0.4341\n",
      "Optimization Iteration:  44289, Training Accuracy:  81.2%, Loss: 0.3738\n",
      "Optimization Iteration:  44353, Training Accuracy:  76.6%, Loss: 0.3962\n",
      "Optimization Iteration:  44417, Training Accuracy:  81.2%, Loss: 0.3351\n",
      "Optimization Iteration:  44481, Training Accuracy:  73.4%, Loss: 0.4152\n",
      "Optimization Iteration:  44545, Training Accuracy:  70.3%, Loss: 0.3909\n",
      "Optimization Iteration:  44609, Training Accuracy:  81.2%, Loss: 0.3469\n",
      "Optimization Iteration:  44673, Training Accuracy:  81.2%, Loss: 0.4596\n",
      "Optimization Iteration:  44737, Training Accuracy:  70.3%, Loss: 0.3746\n",
      "Optimization Iteration:  44801, Training Accuracy:  78.1%, Loss: 0.4324\n",
      "Optimization Iteration:  44865, Training Accuracy:  71.9%, Loss: 0.4382\n",
      "Optimization Iteration:  44929, Training Accuracy:  81.2%, Loss: 0.3999\n",
      "Optimization Iteration:  44993, Training Accuracy:  73.4%, Loss: 0.4181\n",
      "Optimization Iteration:  45057, Training Accuracy:  65.6%, Loss: 0.4580\n",
      "Optimization Iteration:  45121, Training Accuracy:  79.7%, Loss: 0.3669\n",
      "Optimization Iteration:  45185, Training Accuracy:  79.7%, Loss: 0.3059\n",
      "Optimization Iteration:  45249, Training Accuracy:  78.1%, Loss: 0.4311\n",
      "Optimization Iteration:  45313, Training Accuracy:  81.2%, Loss: 0.3652\n",
      "Optimization Iteration:  45377, Training Accuracy:  78.1%, Loss: 0.4181\n",
      "Optimization Iteration:  45441, Training Accuracy:  71.9%, Loss: 0.4183\n",
      "Optimization Iteration:  45505, Training Accuracy:  73.4%, Loss: 0.4578\n",
      "Optimization Iteration:  45569, Training Accuracy:  76.6%, Loss: 0.4673\n",
      "Optimization Iteration:  45633, Training Accuracy:  78.1%, Loss: 0.3750\n",
      "Optimization Iteration:  45697, Training Accuracy:  70.3%, Loss: 0.3516\n",
      "Optimization Iteration:  45761, Training Accuracy:  82.8%, Loss: 0.3317\n",
      "Optimization Iteration:  45825, Training Accuracy:  78.1%, Loss: 0.3695\n",
      "Optimization Iteration:  45889, Training Accuracy:  78.1%, Loss: 0.3422\n",
      "Optimization Iteration:  45953, Training Accuracy:  81.2%, Loss: 0.3581\n",
      "Optimization Iteration:  46017, Training Accuracy:  82.8%, Loss: 0.3937\n",
      "Optimization Iteration:  46081, Training Accuracy:  84.4%, Loss: 0.2647\n",
      "Optimization Iteration:  46145, Training Accuracy:  79.7%, Loss: 0.4079\n",
      "Optimization Iteration:  46209, Training Accuracy:  75.0%, Loss: 0.3401\n",
      "Optimization Iteration:  46273, Training Accuracy:  73.4%, Loss: 0.4686\n",
      "Optimization Iteration:  46337, Training Accuracy:  78.1%, Loss: 0.4172\n",
      "Optimization Iteration:  46401, Training Accuracy:  78.1%, Loss: 0.3950\n",
      "Optimization Iteration:  46465, Training Accuracy:  73.4%, Loss: 0.3989\n",
      "Optimization Iteration:  46529, Training Accuracy:  71.9%, Loss: 0.4025\n",
      "Optimization Iteration:  46593, Training Accuracy:  76.6%, Loss: 0.3892\n",
      "Optimization Iteration:  46657, Training Accuracy:  76.6%, Loss: 0.4271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  46721, Training Accuracy:  70.3%, Loss: 0.4263\n",
      "Optimization Iteration:  46785, Training Accuracy:  70.3%, Loss: 0.4686\n",
      "Optimization Iteration:  46849, Training Accuracy:  78.1%, Loss: 0.3958\n",
      "Optimization Iteration:  46913, Training Accuracy:  87.5%, Loss: 0.3439\n",
      "Optimization Iteration:  46977, Training Accuracy:  78.1%, Loss: 0.4065\n",
      "Optimization Iteration:  47041, Training Accuracy:  78.1%, Loss: 0.4281\n",
      "Optimization Iteration:  47105, Training Accuracy:  76.6%, Loss: 0.4374\n",
      "Optimization Iteration:  47169, Training Accuracy:  75.0%, Loss: 0.4765\n",
      "Optimization Iteration:  47233, Training Accuracy:  65.6%, Loss: 0.4806\n",
      "Optimization Iteration:  47297, Training Accuracy:  75.0%, Loss: 0.3343\n",
      "Optimization Iteration:  47361, Training Accuracy:  85.9%, Loss: 0.3142\n",
      "Optimization Iteration:  47425, Training Accuracy:  81.2%, Loss: 0.3073\n",
      "Optimization Iteration:  47489, Training Accuracy:  73.4%, Loss: 0.4197\n",
      "Optimization Iteration:  47553, Training Accuracy:  81.2%, Loss: 0.3723\n",
      "Optimization Iteration:  47617, Training Accuracy:  76.6%, Loss: 0.3991\n",
      "Optimization Iteration:  47681, Training Accuracy:  78.1%, Loss: 0.3821\n",
      "Optimization Iteration:  47745, Training Accuracy:  71.9%, Loss: 0.4473\n",
      "Optimization Iteration:  47809, Training Accuracy:  84.4%, Loss: 0.3030\n",
      "Optimization Iteration:  47873, Training Accuracy:  82.8%, Loss: 0.2956\n",
      "Optimization Iteration:  47937, Training Accuracy:  82.8%, Loss: 0.3108\n",
      "Optimization Iteration:  48001, Training Accuracy:  73.4%, Loss: 0.3977\n",
      "Optimization Iteration:  48065, Training Accuracy:  82.8%, Loss: 0.3378\n",
      "Optimization Iteration:  48129, Training Accuracy:  73.4%, Loss: 0.4927\n",
      "Optimization Iteration:  48193, Training Accuracy:  81.2%, Loss: 0.4225\n",
      "Optimization Iteration:  48257, Training Accuracy:  75.0%, Loss: 0.4022\n",
      "Optimization Iteration:  48321, Training Accuracy:  67.2%, Loss: 0.3724\n",
      "Optimization Iteration:  48385, Training Accuracy:  87.5%, Loss: 0.3094\n",
      "Optimization Iteration:  48449, Training Accuracy:  76.6%, Loss: 0.3901\n",
      "Optimization Iteration:  48513, Training Accuracy:  82.8%, Loss: 0.3956\n",
      "Optimization Iteration:  48577, Training Accuracy:  70.3%, Loss: 0.5101\n",
      "Optimization Iteration:  48641, Training Accuracy:  79.7%, Loss: 0.3397\n",
      "Optimization Iteration:  48705, Training Accuracy:  82.8%, Loss: 0.3049\n",
      "Optimization Iteration:  48769, Training Accuracy:  85.9%, Loss: 0.3429\n",
      "Optimization Iteration:  48833, Training Accuracy:  84.4%, Loss: 0.3358\n",
      "Optimization Iteration:  48897, Training Accuracy:  78.1%, Loss: 0.4610\n",
      "Optimization Iteration:  48961, Training Accuracy:  81.2%, Loss: 0.4152\n",
      "Optimization Iteration:  49025, Training Accuracy:  76.6%, Loss: 0.4549\n",
      "Optimization Iteration:  49089, Training Accuracy:  82.8%, Loss: 0.3443\n",
      "Optimization Iteration:  49153, Training Accuracy:  82.8%, Loss: 0.3071\n",
      "Optimization Iteration:  49217, Training Accuracy:  76.6%, Loss: 0.4237\n",
      "Optimization Iteration:  49281, Training Accuracy:  78.1%, Loss: 0.3605\n",
      "Optimization Iteration:  49345, Training Accuracy:  78.1%, Loss: 0.3879\n",
      "Optimization Iteration:  49409, Training Accuracy:  79.7%, Loss: 0.4091\n",
      "Optimization Iteration:  49473, Training Accuracy:  79.7%, Loss: 0.3719\n",
      "Optimization Iteration:  49537, Training Accuracy:  71.9%, Loss: 0.3774\n",
      "Optimization Iteration:  49601, Training Accuracy:  70.3%, Loss: 0.4556\n",
      "Optimization Iteration:  49665, Training Accuracy:  85.9%, Loss: 0.3205\n",
      "Optimization Iteration:  49729, Training Accuracy:  73.4%, Loss: 0.3603\n",
      "Optimization Iteration:  49793, Training Accuracy:  70.3%, Loss: 0.4069\n",
      "Optimization Iteration:  49857, Training Accuracy:  82.8%, Loss: 0.3799\n",
      "Optimization Iteration:  49921, Training Accuracy:  75.0%, Loss: 0.4070\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Epoch: 30\n",
      "INFO:tensorflow:Restoring parameters from SD/50kSD_Model.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:  73.4%, Loss: 0.4020\n",
      "Optimization Iteration:    129, Training Accuracy:  76.6%, Loss: 0.4394\n",
      "Optimization Iteration:    193, Training Accuracy:  79.7%, Loss: 0.3480\n",
      "Optimization Iteration:    257, Training Accuracy:  71.9%, Loss: 0.3992\n",
      "Optimization Iteration:    321, Training Accuracy:  76.6%, Loss: 0.4072\n",
      "Optimization Iteration:    385, Training Accuracy:  79.7%, Loss: 0.3670\n",
      "Optimization Iteration:    449, Training Accuracy:  78.1%, Loss: 0.3134\n",
      "Optimization Iteration:    513, Training Accuracy:  78.1%, Loss: 0.3999\n",
      "Optimization Iteration:    577, Training Accuracy:  67.2%, Loss: 0.4512\n",
      "Optimization Iteration:    641, Training Accuracy:  78.1%, Loss: 0.4078\n",
      "Optimization Iteration:    705, Training Accuracy:  68.8%, Loss: 0.5089\n",
      "Optimization Iteration:    769, Training Accuracy:  78.1%, Loss: 0.3918\n",
      "Optimization Iteration:    833, Training Accuracy:  75.0%, Loss: 0.3396\n",
      "Optimization Iteration:    897, Training Accuracy:  73.4%, Loss: 0.3904\n",
      "Optimization Iteration:    961, Training Accuracy:  78.1%, Loss: 0.3288\n",
      "Optimization Iteration:   1025, Training Accuracy:  79.7%, Loss: 0.3974\n",
      "Optimization Iteration:   1089, Training Accuracy:  71.9%, Loss: 0.4226\n",
      "Optimization Iteration:   1153, Training Accuracy:  67.2%, Loss: 0.4752\n",
      "Optimization Iteration:   1217, Training Accuracy:  75.0%, Loss: 0.3753\n",
      "Optimization Iteration:   1281, Training Accuracy:  73.4%, Loss: 0.3843\n",
      "Optimization Iteration:   1345, Training Accuracy:  81.2%, Loss: 0.3562\n",
      "Optimization Iteration:   1409, Training Accuracy:  75.0%, Loss: 0.3869\n",
      "Optimization Iteration:   1473, Training Accuracy:  75.0%, Loss: 0.4040\n",
      "Optimization Iteration:   1537, Training Accuracy:  78.1%, Loss: 0.4003\n",
      "Optimization Iteration:   1601, Training Accuracy:  82.8%, Loss: 0.3156\n",
      "Optimization Iteration:   1665, Training Accuracy:  82.8%, Loss: 0.3112\n",
      "Optimization Iteration:   1729, Training Accuracy:  70.3%, Loss: 0.3869\n",
      "Optimization Iteration:   1793, Training Accuracy:  73.4%, Loss: 0.3668\n",
      "Optimization Iteration:   1857, Training Accuracy:  76.6%, Loss: 0.4119\n",
      "Optimization Iteration:   1921, Training Accuracy:  81.2%, Loss: 0.3981\n",
      "Optimization Iteration:   1985, Training Accuracy:  76.6%, Loss: 0.4281\n",
      "Optimization Iteration:   2049, Training Accuracy:  81.2%, Loss: 0.2895\n",
      "Optimization Iteration:   2113, Training Accuracy:  79.7%, Loss: 0.3513\n",
      "Optimization Iteration:   2177, Training Accuracy:  79.7%, Loss: 0.3199\n",
      "Optimization Iteration:   2241, Training Accuracy:  73.4%, Loss: 0.4175\n",
      "Optimization Iteration:   2305, Training Accuracy:  71.9%, Loss: 0.4221\n",
      "Optimization Iteration:   2369, Training Accuracy:  79.7%, Loss: 0.3720\n",
      "Optimization Iteration:   2433, Training Accuracy:  78.1%, Loss: 0.3944\n",
      "Optimization Iteration:   2497, Training Accuracy:  84.4%, Loss: 0.4058\n",
      "Optimization Iteration:   2561, Training Accuracy:  84.4%, Loss: 0.3586\n",
      "Optimization Iteration:   2625, Training Accuracy:  81.2%, Loss: 0.3538\n",
      "Optimization Iteration:   2689, Training Accuracy:  75.0%, Loss: 0.3893\n",
      "Optimization Iteration:   2753, Training Accuracy:  81.2%, Loss: 0.3349\n",
      "Optimization Iteration:   2817, Training Accuracy:  73.4%, Loss: 0.3682\n",
      "Optimization Iteration:   2881, Training Accuracy:  76.6%, Loss: 0.3741\n",
      "Optimization Iteration:   2945, Training Accuracy:  79.7%, Loss: 0.4131\n",
      "Optimization Iteration:   3009, Training Accuracy:  76.6%, Loss: 0.3665\n",
      "Optimization Iteration:   3073, Training Accuracy:  82.8%, Loss: 0.3263\n",
      "Optimization Iteration:   3137, Training Accuracy:  81.2%, Loss: 0.3087\n",
      "Optimization Iteration:   3201, Training Accuracy:  79.7%, Loss: 0.3827\n",
      "Optimization Iteration:   3265, Training Accuracy:  78.1%, Loss: 0.3796\n",
      "Optimization Iteration:   3329, Training Accuracy:  79.7%, Loss: 0.3876\n",
      "Optimization Iteration:   3393, Training Accuracy:  81.2%, Loss: 0.3244\n",
      "Optimization Iteration:   3457, Training Accuracy:  73.4%, Loss: 0.3914\n",
      "Optimization Iteration:   3521, Training Accuracy:  79.7%, Loss: 0.3635\n",
      "Optimization Iteration:   3585, Training Accuracy:  81.2%, Loss: 0.3488\n",
      "Optimization Iteration:   3649, Training Accuracy:  75.0%, Loss: 0.3788\n",
      "Optimization Iteration:   3713, Training Accuracy:  71.9%, Loss: 0.3903\n",
      "Optimization Iteration:   3777, Training Accuracy:  67.2%, Loss: 0.5304\n",
      "Optimization Iteration:   3841, Training Accuracy:  71.9%, Loss: 0.4251\n",
      "Optimization Iteration:   3905, Training Accuracy:  81.2%, Loss: 0.3252\n",
      "Optimization Iteration:   3969, Training Accuracy:  75.0%, Loss: 0.3837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   4033, Training Accuracy:  85.9%, Loss: 0.2962\n",
      "Optimization Iteration:   4097, Training Accuracy:  75.0%, Loss: 0.3403\n",
      "Optimization Iteration:   4161, Training Accuracy:  71.9%, Loss: 0.3988\n",
      "Optimization Iteration:   4225, Training Accuracy:  82.8%, Loss: 0.3061\n",
      "Optimization Iteration:   4289, Training Accuracy:  78.1%, Loss: 0.3383\n",
      "Optimization Iteration:   4353, Training Accuracy:  78.1%, Loss: 0.3526\n",
      "Optimization Iteration:   4417, Training Accuracy:  75.0%, Loss: 0.3941\n",
      "Optimization Iteration:   4481, Training Accuracy:  76.6%, Loss: 0.3698\n",
      "Optimization Iteration:   4545, Training Accuracy:  73.4%, Loss: 0.3848\n",
      "Optimization Iteration:   4609, Training Accuracy:  79.7%, Loss: 0.3791\n",
      "Optimization Iteration:   4673, Training Accuracy:  79.7%, Loss: 0.4164\n",
      "Optimization Iteration:   4737, Training Accuracy:  81.2%, Loss: 0.3062\n",
      "Optimization Iteration:   4801, Training Accuracy:  71.9%, Loss: 0.4353\n",
      "Optimization Iteration:   4865, Training Accuracy:  75.0%, Loss: 0.4152\n",
      "Optimization Iteration:   4929, Training Accuracy:  81.2%, Loss: 0.3438\n",
      "Optimization Iteration:   4993, Training Accuracy:  85.9%, Loss: 0.3588\n",
      "Optimization Iteration:   5057, Training Accuracy:  67.2%, Loss: 0.4820\n",
      "Optimization Iteration:   5121, Training Accuracy:  84.4%, Loss: 0.2979\n",
      "Optimization Iteration:   5185, Training Accuracy:  76.6%, Loss: 0.3950\n",
      "Optimization Iteration:   5249, Training Accuracy:  70.3%, Loss: 0.4388\n",
      "Optimization Iteration:   5313, Training Accuracy:  89.1%, Loss: 0.2537\n",
      "Optimization Iteration:   5377, Training Accuracy:  71.9%, Loss: 0.4008\n",
      "Optimization Iteration:   5441, Training Accuracy:  76.6%, Loss: 0.3491\n",
      "Optimization Iteration:   5505, Training Accuracy:  85.9%, Loss: 0.3237\n",
      "Optimization Iteration:   5569, Training Accuracy:  79.7%, Loss: 0.3675\n",
      "Optimization Iteration:   5633, Training Accuracy:  70.3%, Loss: 0.3520\n",
      "Optimization Iteration:   5697, Training Accuracy:  75.0%, Loss: 0.4558\n",
      "Optimization Iteration:   5761, Training Accuracy:  71.9%, Loss: 0.3498\n",
      "Optimization Iteration:   5825, Training Accuracy:  75.0%, Loss: 0.4394\n",
      "Optimization Iteration:   5889, Training Accuracy:  82.8%, Loss: 0.4721\n",
      "Optimization Iteration:   5953, Training Accuracy:  75.0%, Loss: 0.4394\n",
      "Optimization Iteration:   6017, Training Accuracy:  73.4%, Loss: 0.4121\n",
      "Optimization Iteration:   6081, Training Accuracy:  75.0%, Loss: 0.4514\n",
      "Optimization Iteration:   6145, Training Accuracy:  68.8%, Loss: 0.4820\n",
      "Optimization Iteration:   6209, Training Accuracy:  75.0%, Loss: 0.3861\n",
      "Optimization Iteration:   6273, Training Accuracy:  75.0%, Loss: 0.4697\n",
      "Optimization Iteration:   6337, Training Accuracy:  71.9%, Loss: 0.4365\n",
      "Optimization Iteration:   6401, Training Accuracy:  78.1%, Loss: 0.3565\n",
      "Optimization Iteration:   6465, Training Accuracy:  85.9%, Loss: 0.3410\n",
      "Optimization Iteration:   6529, Training Accuracy:  75.0%, Loss: 0.4288\n",
      "Optimization Iteration:   6593, Training Accuracy:  73.4%, Loss: 0.3491\n",
      "Optimization Iteration:   6657, Training Accuracy:  71.9%, Loss: 0.4382\n",
      "Optimization Iteration:   6721, Training Accuracy:  84.4%, Loss: 0.3763\n",
      "Optimization Iteration:   6785, Training Accuracy:  70.3%, Loss: 0.4300\n",
      "Optimization Iteration:   6849, Training Accuracy:  70.3%, Loss: 0.3892\n",
      "Optimization Iteration:   6913, Training Accuracy:  78.1%, Loss: 0.3164\n",
      "Optimization Iteration:   6977, Training Accuracy:  71.9%, Loss: 0.4440\n",
      "Optimization Iteration:   7041, Training Accuracy:  78.1%, Loss: 0.3812\n",
      "Optimization Iteration:   7105, Training Accuracy:  78.1%, Loss: 0.3355\n",
      "Optimization Iteration:   7169, Training Accuracy:  79.7%, Loss: 0.3889\n",
      "Optimization Iteration:   7233, Training Accuracy:  71.9%, Loss: 0.5236\n",
      "Optimization Iteration:   7297, Training Accuracy:  73.4%, Loss: 0.4272\n",
      "Optimization Iteration:   7361, Training Accuracy:  79.7%, Loss: 0.3672\n",
      "Optimization Iteration:   7425, Training Accuracy:  81.2%, Loss: 0.3486\n",
      "Optimization Iteration:   7489, Training Accuracy:  81.2%, Loss: 0.3781\n",
      "Optimization Iteration:   7553, Training Accuracy:  76.6%, Loss: 0.4303\n",
      "Optimization Iteration:   7617, Training Accuracy:  78.1%, Loss: 0.3705\n",
      "Optimization Iteration:   7681, Training Accuracy:  70.3%, Loss: 0.3957\n",
      "Optimization Iteration:   7745, Training Accuracy:  84.4%, Loss: 0.3011\n",
      "Optimization Iteration:   7809, Training Accuracy:  78.1%, Loss: 0.3819\n",
      "Optimization Iteration:   7873, Training Accuracy:  76.6%, Loss: 0.3503\n",
      "Optimization Iteration:   7937, Training Accuracy:  78.1%, Loss: 0.3961\n",
      "Optimization Iteration:   8001, Training Accuracy:  78.1%, Loss: 0.3445\n",
      "Optimization Iteration:   8065, Training Accuracy:  67.2%, Loss: 0.4087\n",
      "Optimization Iteration:   8129, Training Accuracy:  68.8%, Loss: 0.4298\n",
      "Optimization Iteration:   8193, Training Accuracy:  76.6%, Loss: 0.3928\n",
      "Optimization Iteration:   8257, Training Accuracy:  70.3%, Loss: 0.4552\n",
      "Optimization Iteration:   8321, Training Accuracy:  81.2%, Loss: 0.3572\n",
      "Optimization Iteration:   8385, Training Accuracy:  75.0%, Loss: 0.4072\n",
      "Optimization Iteration:   8449, Training Accuracy:  79.7%, Loss: 0.4034\n",
      "Optimization Iteration:   8513, Training Accuracy:  85.9%, Loss: 0.2797\n",
      "Optimization Iteration:   8577, Training Accuracy:  76.6%, Loss: 0.3882\n",
      "Optimization Iteration:   8641, Training Accuracy:  84.4%, Loss: 0.3411\n",
      "Optimization Iteration:   8705, Training Accuracy:  71.9%, Loss: 0.3810\n",
      "Optimization Iteration:   8769, Training Accuracy:  70.3%, Loss: 0.3873\n",
      "Optimization Iteration:   8833, Training Accuracy:  78.1%, Loss: 0.3906\n",
      "Optimization Iteration:   8897, Training Accuracy:  78.1%, Loss: 0.4380\n",
      "Optimization Iteration:   8961, Training Accuracy:  82.8%, Loss: 0.3823\n",
      "Optimization Iteration:   9025, Training Accuracy:  73.4%, Loss: 0.4267\n",
      "Optimization Iteration:   9089, Training Accuracy:  67.2%, Loss: 0.5087\n",
      "Optimization Iteration:   9153, Training Accuracy:  62.5%, Loss: 0.4516\n",
      "Optimization Iteration:   9217, Training Accuracy:  73.4%, Loss: 0.3849\n",
      "Optimization Iteration:   9281, Training Accuracy:  73.4%, Loss: 0.3798\n",
      "Optimization Iteration:   9345, Training Accuracy:  82.8%, Loss: 0.3675\n",
      "Optimization Iteration:   9409, Training Accuracy:  73.4%, Loss: 0.4675\n",
      "Optimization Iteration:   9473, Training Accuracy:  79.7%, Loss: 0.3846\n",
      "Optimization Iteration:   9537, Training Accuracy:  81.2%, Loss: 0.3243\n",
      "Optimization Iteration:   9601, Training Accuracy:  71.9%, Loss: 0.3939\n",
      "Optimization Iteration:   9665, Training Accuracy:  71.9%, Loss: 0.3688\n",
      "Optimization Iteration:   9729, Training Accuracy:  71.9%, Loss: 0.4466\n",
      "Optimization Iteration:   9793, Training Accuracy:  75.0%, Loss: 0.3081\n",
      "Optimization Iteration:   9857, Training Accuracy:  71.9%, Loss: 0.4215\n",
      "Optimization Iteration:   9921, Training Accuracy:  71.9%, Loss: 0.3834\n",
      "Optimization Iteration:   9985, Training Accuracy:  76.6%, Loss: 0.3816\n",
      "Optimization Iteration:  10049, Training Accuracy:  64.1%, Loss: 0.4593\n",
      "Optimization Iteration:  10113, Training Accuracy:  76.6%, Loss: 0.3731\n",
      "Optimization Iteration:  10177, Training Accuracy:  79.7%, Loss: 0.4198\n",
      "Optimization Iteration:  10241, Training Accuracy:  76.6%, Loss: 0.4222\n",
      "Optimization Iteration:  10305, Training Accuracy:  76.6%, Loss: 0.3465\n",
      "Optimization Iteration:  10369, Training Accuracy:  76.6%, Loss: 0.4141\n",
      "Optimization Iteration:  10433, Training Accuracy:  79.7%, Loss: 0.3552\n",
      "Optimization Iteration:  10497, Training Accuracy:  76.6%, Loss: 0.4080\n",
      "Optimization Iteration:  10561, Training Accuracy:  76.6%, Loss: 0.3063\n",
      "Optimization Iteration:  10625, Training Accuracy:  78.1%, Loss: 0.3583\n",
      "Optimization Iteration:  10689, Training Accuracy:  82.8%, Loss: 0.3225\n",
      "Optimization Iteration:  10753, Training Accuracy:  78.1%, Loss: 0.4379\n",
      "Optimization Iteration:  10817, Training Accuracy:  76.6%, Loss: 0.4112\n",
      "Optimization Iteration:  10881, Training Accuracy:  71.9%, Loss: 0.4015\n",
      "Optimization Iteration:  10945, Training Accuracy:  81.2%, Loss: 0.3908\n",
      "Optimization Iteration:  11009, Training Accuracy:  84.4%, Loss: 0.3576\n",
      "Optimization Iteration:  11073, Training Accuracy:  73.4%, Loss: 0.4332\n",
      "Optimization Iteration:  11137, Training Accuracy:  79.7%, Loss: 0.4802\n",
      "Optimization Iteration:  11201, Training Accuracy:  84.4%, Loss: 0.3714\n",
      "Optimization Iteration:  11265, Training Accuracy:  82.8%, Loss: 0.3267\n",
      "Optimization Iteration:  11329, Training Accuracy:  78.1%, Loss: 0.4008\n",
      "Optimization Iteration:  11393, Training Accuracy:  82.8%, Loss: 0.3623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  11457, Training Accuracy:  81.2%, Loss: 0.3503\n",
      "Optimization Iteration:  11521, Training Accuracy:  78.1%, Loss: 0.3495\n",
      "Optimization Iteration:  11585, Training Accuracy:  84.4%, Loss: 0.3237\n",
      "Optimization Iteration:  11649, Training Accuracy:  81.2%, Loss: 0.4074\n",
      "Optimization Iteration:  11713, Training Accuracy:  79.7%, Loss: 0.3117\n",
      "Optimization Iteration:  11777, Training Accuracy:  75.0%, Loss: 0.4644\n",
      "Optimization Iteration:  11841, Training Accuracy:  79.7%, Loss: 0.3357\n",
      "Optimization Iteration:  11905, Training Accuracy:  71.9%, Loss: 0.4293\n",
      "Optimization Iteration:  11969, Training Accuracy:  79.7%, Loss: 0.3584\n",
      "Optimization Iteration:  12033, Training Accuracy:  76.6%, Loss: 0.3961\n",
      "Optimization Iteration:  12097, Training Accuracy:  79.7%, Loss: 0.3987\n",
      "Optimization Iteration:  12161, Training Accuracy:  75.0%, Loss: 0.3917\n",
      "Optimization Iteration:  12225, Training Accuracy:  90.6%, Loss: 0.3009\n",
      "Optimization Iteration:  12289, Training Accuracy:  81.2%, Loss: 0.3498\n",
      "Optimization Iteration:  12353, Training Accuracy:  81.2%, Loss: 0.3974\n",
      "Optimization Iteration:  12417, Training Accuracy:  81.2%, Loss: 0.3731\n",
      "Optimization Iteration:  12481, Training Accuracy:  85.9%, Loss: 0.3977\n",
      "Optimization Iteration:  12545, Training Accuracy:  75.0%, Loss: 0.4095\n",
      "Optimization Iteration:  12609, Training Accuracy:  75.0%, Loss: 0.3394\n",
      "Optimization Iteration:  12673, Training Accuracy:  82.8%, Loss: 0.3644\n",
      "Optimization Iteration:  12737, Training Accuracy:  71.9%, Loss: 0.3995\n",
      "Optimization Iteration:  12801, Training Accuracy:  75.0%, Loss: 0.4099\n",
      "Optimization Iteration:  12865, Training Accuracy:  79.7%, Loss: 0.3849\n",
      "Optimization Iteration:  12929, Training Accuracy:  75.0%, Loss: 0.3479\n",
      "Optimization Iteration:  12993, Training Accuracy:  81.2%, Loss: 0.3474\n",
      "Optimization Iteration:  13057, Training Accuracy:  68.8%, Loss: 0.4499\n",
      "Optimization Iteration:  13121, Training Accuracy:  82.8%, Loss: 0.3304\n",
      "Optimization Iteration:  13185, Training Accuracy:  78.1%, Loss: 0.3755\n",
      "Optimization Iteration:  13249, Training Accuracy:  67.2%, Loss: 0.4315\n",
      "Optimization Iteration:  13313, Training Accuracy:  65.6%, Loss: 0.4909\n",
      "Optimization Iteration:  13377, Training Accuracy:  75.0%, Loss: 0.4436\n",
      "Optimization Iteration:  13441, Training Accuracy:  76.6%, Loss: 0.3624\n",
      "Optimization Iteration:  13505, Training Accuracy:  70.3%, Loss: 0.4094\n",
      "Optimization Iteration:  13569, Training Accuracy:  85.9%, Loss: 0.2731\n",
      "Optimization Iteration:  13633, Training Accuracy:  81.2%, Loss: 0.3385\n",
      "Optimization Iteration:  13697, Training Accuracy:  76.6%, Loss: 0.3563\n",
      "Optimization Iteration:  13761, Training Accuracy:  81.2%, Loss: 0.3479\n",
      "Optimization Iteration:  13825, Training Accuracy:  82.8%, Loss: 0.3807\n",
      "Optimization Iteration:  13889, Training Accuracy:  79.7%, Loss: 0.3509\n",
      "Optimization Iteration:  13953, Training Accuracy:  81.2%, Loss: 0.3442\n",
      "Optimization Iteration:  14017, Training Accuracy:  75.0%, Loss: 0.4177\n",
      "Optimization Iteration:  14081, Training Accuracy:  71.9%, Loss: 0.4196\n",
      "Optimization Iteration:  14145, Training Accuracy:  79.7%, Loss: 0.3626\n",
      "Optimization Iteration:  14209, Training Accuracy:  75.0%, Loss: 0.3696\n",
      "Optimization Iteration:  14273, Training Accuracy:  70.3%, Loss: 0.4665\n",
      "Optimization Iteration:  14337, Training Accuracy:  84.4%, Loss: 0.3174\n",
      "Optimization Iteration:  14401, Training Accuracy:  87.5%, Loss: 0.3243\n",
      "Optimization Iteration:  14465, Training Accuracy:  68.8%, Loss: 0.4485\n",
      "Optimization Iteration:  14529, Training Accuracy:  82.8%, Loss: 0.3250\n",
      "Optimization Iteration:  14593, Training Accuracy:  76.6%, Loss: 0.3951\n",
      "Optimization Iteration:  14657, Training Accuracy:  73.4%, Loss: 0.4374\n",
      "Optimization Iteration:  14721, Training Accuracy:  79.7%, Loss: 0.2970\n",
      "Optimization Iteration:  14785, Training Accuracy:  71.9%, Loss: 0.4079\n",
      "Optimization Iteration:  14849, Training Accuracy:  73.4%, Loss: 0.3930\n",
      "Optimization Iteration:  14913, Training Accuracy:  79.7%, Loss: 0.3354\n",
      "Optimization Iteration:  14977, Training Accuracy:  76.6%, Loss: 0.3135\n",
      "Optimization Iteration:  15041, Training Accuracy:  79.7%, Loss: 0.3111\n",
      "Optimization Iteration:  15105, Training Accuracy:  81.2%, Loss: 0.3545\n",
      "Optimization Iteration:  15169, Training Accuracy:  73.4%, Loss: 0.3321\n",
      "Optimization Iteration:  15233, Training Accuracy:  73.4%, Loss: 0.4324\n",
      "Optimization Iteration:  15297, Training Accuracy:  78.1%, Loss: 0.3970\n",
      "Optimization Iteration:  15361, Training Accuracy:  79.7%, Loss: 0.3200\n",
      "Optimization Iteration:  15425, Training Accuracy:  78.1%, Loss: 0.3863\n",
      "Optimization Iteration:  15489, Training Accuracy:  71.9%, Loss: 0.5180\n",
      "Optimization Iteration:  15553, Training Accuracy:  79.7%, Loss: 0.2938\n",
      "Optimization Iteration:  15617, Training Accuracy:  82.8%, Loss: 0.2949\n",
      "Optimization Iteration:  15681, Training Accuracy:  82.8%, Loss: 0.3201\n",
      "Optimization Iteration:  15745, Training Accuracy:  81.2%, Loss: 0.3014\n",
      "Optimization Iteration:  15809, Training Accuracy:  71.9%, Loss: 0.3873\n",
      "Optimization Iteration:  15873, Training Accuracy:  76.6%, Loss: 0.4054\n",
      "Optimization Iteration:  15937, Training Accuracy:  76.6%, Loss: 0.3613\n",
      "Optimization Iteration:  16001, Training Accuracy:  76.6%, Loss: 0.4262\n",
      "Optimization Iteration:  16065, Training Accuracy:  62.5%, Loss: 0.5230\n",
      "Optimization Iteration:  16129, Training Accuracy:  82.8%, Loss: 0.2817\n",
      "Optimization Iteration:  16193, Training Accuracy:  71.9%, Loss: 0.4070\n",
      "Optimization Iteration:  16257, Training Accuracy:  81.2%, Loss: 0.4200\n",
      "Optimization Iteration:  16321, Training Accuracy:  87.5%, Loss: 0.3661\n",
      "Optimization Iteration:  16385, Training Accuracy:  81.2%, Loss: 0.3459\n",
      "Optimization Iteration:  16449, Training Accuracy:  78.1%, Loss: 0.4040\n",
      "Optimization Iteration:  16513, Training Accuracy:  78.1%, Loss: 0.4904\n",
      "Optimization Iteration:  16577, Training Accuracy:  78.1%, Loss: 0.3489\n",
      "Optimization Iteration:  16641, Training Accuracy:  64.1%, Loss: 0.5867\n",
      "Optimization Iteration:  16705, Training Accuracy:  71.9%, Loss: 0.4162\n",
      "Optimization Iteration:  16769, Training Accuracy:  79.7%, Loss: 0.3364\n",
      "Optimization Iteration:  16833, Training Accuracy:  71.9%, Loss: 0.4002\n",
      "Optimization Iteration:  16897, Training Accuracy:  79.7%, Loss: 0.3411\n",
      "Optimization Iteration:  16961, Training Accuracy:  79.7%, Loss: 0.3411\n",
      "Optimization Iteration:  17025, Training Accuracy:  60.9%, Loss: 0.4920\n",
      "Optimization Iteration:  17089, Training Accuracy:  78.1%, Loss: 0.3700\n",
      "Optimization Iteration:  17153, Training Accuracy:  70.3%, Loss: 0.4116\n",
      "Optimization Iteration:  17217, Training Accuracy:  79.7%, Loss: 0.3815\n",
      "Optimization Iteration:  17281, Training Accuracy:  67.2%, Loss: 0.4608\n",
      "Optimization Iteration:  17345, Training Accuracy:  84.4%, Loss: 0.3002\n",
      "Optimization Iteration:  17409, Training Accuracy:  70.3%, Loss: 0.4164\n",
      "Optimization Iteration:  17473, Training Accuracy:  79.7%, Loss: 0.4486\n",
      "Optimization Iteration:  17537, Training Accuracy:  64.1%, Loss: 0.4196\n",
      "Optimization Iteration:  17601, Training Accuracy:  71.9%, Loss: 0.4193\n",
      "Optimization Iteration:  17665, Training Accuracy:  84.4%, Loss: 0.3097\n",
      "Optimization Iteration:  17729, Training Accuracy:  79.7%, Loss: 0.3842\n",
      "Optimization Iteration:  17793, Training Accuracy:  76.6%, Loss: 0.4108\n",
      "Optimization Iteration:  17857, Training Accuracy:  81.2%, Loss: 0.3867\n",
      "Optimization Iteration:  17921, Training Accuracy:  82.8%, Loss: 0.3172\n",
      "Optimization Iteration:  17985, Training Accuracy:  75.0%, Loss: 0.2886\n",
      "Optimization Iteration:  18049, Training Accuracy:  84.4%, Loss: 0.3549\n",
      "Optimization Iteration:  18113, Training Accuracy:  70.3%, Loss: 0.5122\n",
      "Optimization Iteration:  18177, Training Accuracy:  68.8%, Loss: 0.4438\n",
      "Optimization Iteration:  18241, Training Accuracy:  70.3%, Loss: 0.5099\n",
      "Optimization Iteration:  18305, Training Accuracy:  78.1%, Loss: 0.3751\n",
      "Optimization Iteration:  18369, Training Accuracy:  73.4%, Loss: 0.3420\n",
      "Optimization Iteration:  18433, Training Accuracy:  73.4%, Loss: 0.4165\n",
      "Optimization Iteration:  18497, Training Accuracy:  76.6%, Loss: 0.3339\n",
      "Optimization Iteration:  18561, Training Accuracy:  71.9%, Loss: 0.4723\n",
      "Optimization Iteration:  18625, Training Accuracy:  73.4%, Loss: 0.4216\n",
      "Optimization Iteration:  18689, Training Accuracy:  73.4%, Loss: 0.3915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  18753, Training Accuracy:  75.0%, Loss: 0.3883\n",
      "Optimization Iteration:  18817, Training Accuracy:  76.6%, Loss: 0.4243\n",
      "Optimization Iteration:  18881, Training Accuracy:  73.4%, Loss: 0.3838\n",
      "Optimization Iteration:  18945, Training Accuracy:  73.4%, Loss: 0.4021\n",
      "Optimization Iteration:  19009, Training Accuracy:  73.4%, Loss: 0.3498\n",
      "Optimization Iteration:  19073, Training Accuracy:  79.7%, Loss: 0.3852\n",
      "Optimization Iteration:  19137, Training Accuracy:  76.6%, Loss: 0.4434\n",
      "Optimization Iteration:  19201, Training Accuracy:  75.0%, Loss: 0.4054\n",
      "Optimization Iteration:  19265, Training Accuracy:  78.1%, Loss: 0.3933\n",
      "Optimization Iteration:  19329, Training Accuracy:  75.0%, Loss: 0.3142\n",
      "Optimization Iteration:  19393, Training Accuracy:  76.6%, Loss: 0.3666\n",
      "Optimization Iteration:  19457, Training Accuracy:  75.0%, Loss: 0.4032\n",
      "Optimization Iteration:  19521, Training Accuracy:  79.7%, Loss: 0.3697\n",
      "Optimization Iteration:  19585, Training Accuracy:  71.9%, Loss: 0.4069\n",
      "Optimization Iteration:  19649, Training Accuracy:  84.4%, Loss: 0.3478\n",
      "Optimization Iteration:  19713, Training Accuracy:  76.6%, Loss: 0.3366\n",
      "Optimization Iteration:  19777, Training Accuracy:  81.2%, Loss: 0.3090\n",
      "Optimization Iteration:  19841, Training Accuracy:  75.0%, Loss: 0.4295\n",
      "Optimization Iteration:  19905, Training Accuracy:  73.4%, Loss: 0.4186\n",
      "Optimization Iteration:  19969, Training Accuracy:  84.4%, Loss: 0.3774\n",
      "Optimization Iteration:  20033, Training Accuracy:  87.5%, Loss: 0.2911\n",
      "Optimization Iteration:  20097, Training Accuracy:  73.4%, Loss: 0.4400\n",
      "Optimization Iteration:  20161, Training Accuracy:  82.8%, Loss: 0.3257\n",
      "Optimization Iteration:  20225, Training Accuracy:  75.0%, Loss: 0.3618\n",
      "Optimization Iteration:  20289, Training Accuracy:  75.0%, Loss: 0.4168\n",
      "Optimization Iteration:  20353, Training Accuracy:  75.0%, Loss: 0.3790\n",
      "Optimization Iteration:  20417, Training Accuracy:  67.2%, Loss: 0.4274\n",
      "Optimization Iteration:  20481, Training Accuracy:  76.6%, Loss: 0.3595\n",
      "Optimization Iteration:  20545, Training Accuracy:  76.6%, Loss: 0.3614\n",
      "Optimization Iteration:  20609, Training Accuracy:  82.8%, Loss: 0.4313\n",
      "Optimization Iteration:  20673, Training Accuracy:  76.6%, Loss: 0.3957\n",
      "Optimization Iteration:  20737, Training Accuracy:  79.7%, Loss: 0.4174\n",
      "Optimization Iteration:  20801, Training Accuracy:  84.4%, Loss: 0.3824\n",
      "Optimization Iteration:  20865, Training Accuracy:  82.8%, Loss: 0.3717\n",
      "Optimization Iteration:  20929, Training Accuracy:  78.1%, Loss: 0.3850\n",
      "Optimization Iteration:  20993, Training Accuracy:  79.7%, Loss: 0.3876\n",
      "Optimization Iteration:  21057, Training Accuracy:  79.7%, Loss: 0.3376\n",
      "Optimization Iteration:  21121, Training Accuracy:  70.3%, Loss: 0.4011\n",
      "Optimization Iteration:  21185, Training Accuracy:  79.7%, Loss: 0.3888\n",
      "Optimization Iteration:  21249, Training Accuracy:  65.6%, Loss: 0.4294\n",
      "Optimization Iteration:  21313, Training Accuracy:  81.2%, Loss: 0.3958\n",
      "Optimization Iteration:  21377, Training Accuracy:  81.2%, Loss: 0.2915\n",
      "Optimization Iteration:  21441, Training Accuracy:  75.0%, Loss: 0.4005\n",
      "Optimization Iteration:  21505, Training Accuracy:  79.7%, Loss: 0.3855\n",
      "Optimization Iteration:  21569, Training Accuracy:  71.9%, Loss: 0.3692\n",
      "Optimization Iteration:  21633, Training Accuracy:  90.6%, Loss: 0.2441\n",
      "Optimization Iteration:  21697, Training Accuracy:  82.8%, Loss: 0.4108\n",
      "Optimization Iteration:  21761, Training Accuracy:  85.9%, Loss: 0.2889\n",
      "Optimization Iteration:  21825, Training Accuracy:  75.0%, Loss: 0.4229\n",
      "Optimization Iteration:  21889, Training Accuracy:  82.8%, Loss: 0.3390\n",
      "Optimization Iteration:  21953, Training Accuracy:  79.7%, Loss: 0.5015\n",
      "Optimization Iteration:  22017, Training Accuracy:  78.1%, Loss: 0.4197\n",
      "Optimization Iteration:  22081, Training Accuracy:  85.9%, Loss: 0.3864\n",
      "Optimization Iteration:  22145, Training Accuracy:  79.7%, Loss: 0.3322\n",
      "Optimization Iteration:  22209, Training Accuracy:  89.1%, Loss: 0.3200\n",
      "Optimization Iteration:  22273, Training Accuracy:  73.4%, Loss: 0.4447\n",
      "Optimization Iteration:  22337, Training Accuracy:  73.4%, Loss: 0.2996\n",
      "Optimization Iteration:  22401, Training Accuracy:  79.7%, Loss: 0.3977\n",
      "Optimization Iteration:  22465, Training Accuracy:  78.1%, Loss: 0.4055\n",
      "Optimization Iteration:  22529, Training Accuracy:  79.7%, Loss: 0.3850\n",
      "Optimization Iteration:  22593, Training Accuracy:  79.7%, Loss: 0.4024\n",
      "Optimization Iteration:  22657, Training Accuracy:  79.7%, Loss: 0.3991\n",
      "Optimization Iteration:  22721, Training Accuracy:  71.9%, Loss: 0.4187\n",
      "Optimization Iteration:  22785, Training Accuracy:  71.9%, Loss: 0.3966\n",
      "Optimization Iteration:  22849, Training Accuracy:  70.3%, Loss: 0.4188\n",
      "Optimization Iteration:  22913, Training Accuracy:  73.4%, Loss: 0.4337\n",
      "Optimization Iteration:  22977, Training Accuracy:  85.9%, Loss: 0.3641\n",
      "Optimization Iteration:  23041, Training Accuracy:  71.9%, Loss: 0.3541\n",
      "Optimization Iteration:  23105, Training Accuracy:  70.3%, Loss: 0.3631\n",
      "Optimization Iteration:  23169, Training Accuracy:  84.4%, Loss: 0.3508\n",
      "Optimization Iteration:  23233, Training Accuracy:  76.6%, Loss: 0.3278\n",
      "Optimization Iteration:  23297, Training Accuracy:  79.7%, Loss: 0.4290\n",
      "Optimization Iteration:  23361, Training Accuracy:  79.7%, Loss: 0.3578\n",
      "Optimization Iteration:  23425, Training Accuracy:  87.5%, Loss: 0.3803\n",
      "Optimization Iteration:  23489, Training Accuracy:  76.6%, Loss: 0.4386\n",
      "Optimization Iteration:  23553, Training Accuracy:  82.8%, Loss: 0.3156\n",
      "Optimization Iteration:  23617, Training Accuracy:  71.9%, Loss: 0.4508\n",
      "Optimization Iteration:  23681, Training Accuracy:  75.0%, Loss: 0.4051\n",
      "Optimization Iteration:  23745, Training Accuracy:  78.1%, Loss: 0.3678\n",
      "Optimization Iteration:  23809, Training Accuracy:  71.9%, Loss: 0.4447\n",
      "Optimization Iteration:  23873, Training Accuracy:  75.0%, Loss: 0.4006\n",
      "Optimization Iteration:  23937, Training Accuracy:  62.5%, Loss: 0.4616\n",
      "Optimization Iteration:  24001, Training Accuracy:  82.8%, Loss: 0.3218\n",
      "Optimization Iteration:  24065, Training Accuracy:  78.1%, Loss: 0.3316\n",
      "Optimization Iteration:  24129, Training Accuracy:  81.2%, Loss: 0.3536\n",
      "Optimization Iteration:  24193, Training Accuracy:  73.4%, Loss: 0.3764\n",
      "Optimization Iteration:  24257, Training Accuracy:  76.6%, Loss: 0.3886\n",
      "Optimization Iteration:  24321, Training Accuracy:  70.3%, Loss: 0.4443\n",
      "Optimization Iteration:  24385, Training Accuracy:  70.3%, Loss: 0.4507\n",
      "Optimization Iteration:  24449, Training Accuracy:  82.8%, Loss: 0.3046\n",
      "Optimization Iteration:  24513, Training Accuracy:  78.1%, Loss: 0.3949\n",
      "Optimization Iteration:  24577, Training Accuracy:  71.9%, Loss: 0.4677\n",
      "Optimization Iteration:  24641, Training Accuracy:  79.7%, Loss: 0.3686\n",
      "Optimization Iteration:  24705, Training Accuracy:  81.2%, Loss: 0.3459\n",
      "Optimization Iteration:  24769, Training Accuracy:  75.0%, Loss: 0.3487\n",
      "Optimization Iteration:  24833, Training Accuracy:  79.7%, Loss: 0.3494\n",
      "Optimization Iteration:  24897, Training Accuracy:  76.6%, Loss: 0.4020\n",
      "Optimization Iteration:  24961, Training Accuracy:  93.8%, Loss: 0.2491\n",
      "Optimization Iteration:  25025, Training Accuracy:  76.6%, Loss: 0.3927\n",
      "Optimization Iteration:  25089, Training Accuracy:  76.6%, Loss: 0.3943\n",
      "Optimization Iteration:  25153, Training Accuracy:  76.6%, Loss: 0.3799\n",
      "Optimization Iteration:  25217, Training Accuracy:  65.6%, Loss: 0.4783\n",
      "Optimization Iteration:  25281, Training Accuracy:  79.7%, Loss: 0.3871\n",
      "Optimization Iteration:  25345, Training Accuracy:  79.7%, Loss: 0.4313\n",
      "Optimization Iteration:  25409, Training Accuracy:  78.1%, Loss: 0.3526\n",
      "Optimization Iteration:  25473, Training Accuracy:  75.0%, Loss: 0.4257\n",
      "Optimization Iteration:  25537, Training Accuracy:  76.6%, Loss: 0.4005\n",
      "Optimization Iteration:  25601, Training Accuracy:  71.9%, Loss: 0.4521\n",
      "Optimization Iteration:  25665, Training Accuracy:  79.7%, Loss: 0.4123\n",
      "Optimization Iteration:  25729, Training Accuracy:  81.2%, Loss: 0.2835\n",
      "Optimization Iteration:  25793, Training Accuracy:  81.2%, Loss: 0.3116\n",
      "Optimization Iteration:  25857, Training Accuracy:  76.6%, Loss: 0.3600\n",
      "Optimization Iteration:  25921, Training Accuracy:  75.0%, Loss: 0.3925\n",
      "Optimization Iteration:  25985, Training Accuracy:  70.3%, Loss: 0.3811\n",
      "Optimization Iteration:  26049, Training Accuracy:  76.6%, Loss: 0.4172\n",
      "Optimization Iteration:  26113, Training Accuracy:  78.1%, Loss: 0.3383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  26177, Training Accuracy:  78.1%, Loss: 0.3461\n",
      "Optimization Iteration:  26241, Training Accuracy:  73.4%, Loss: 0.3824\n",
      "Optimization Iteration:  26305, Training Accuracy:  78.1%, Loss: 0.3823\n",
      "Optimization Iteration:  26369, Training Accuracy:  79.7%, Loss: 0.3606\n",
      "Optimization Iteration:  26433, Training Accuracy:  78.1%, Loss: 0.3579\n",
      "Optimization Iteration:  26497, Training Accuracy:  78.1%, Loss: 0.3861\n",
      "Optimization Iteration:  26561, Training Accuracy:  84.4%, Loss: 0.2871\n",
      "Optimization Iteration:  26625, Training Accuracy:  75.0%, Loss: 0.3966\n",
      "Optimization Iteration:  26689, Training Accuracy:  73.4%, Loss: 0.3730\n",
      "Optimization Iteration:  26753, Training Accuracy:  73.4%, Loss: 0.3875\n",
      "Optimization Iteration:  26817, Training Accuracy:  78.1%, Loss: 0.3483\n",
      "Optimization Iteration:  26881, Training Accuracy:  73.4%, Loss: 0.3744\n",
      "Optimization Iteration:  26945, Training Accuracy:  67.2%, Loss: 0.4192\n",
      "Optimization Iteration:  27009, Training Accuracy:  71.9%, Loss: 0.4201\n",
      "Optimization Iteration:  27073, Training Accuracy:  78.1%, Loss: 0.3884\n",
      "Optimization Iteration:  27137, Training Accuracy:  75.0%, Loss: 0.3341\n",
      "Optimization Iteration:  27201, Training Accuracy:  79.7%, Loss: 0.2972\n",
      "Optimization Iteration:  27265, Training Accuracy:  79.7%, Loss: 0.4083\n",
      "Optimization Iteration:  27329, Training Accuracy:  78.1%, Loss: 0.3619\n",
      "Optimization Iteration:  27393, Training Accuracy:  73.4%, Loss: 0.4189\n",
      "Optimization Iteration:  27457, Training Accuracy:  78.1%, Loss: 0.3513\n",
      "Optimization Iteration:  27521, Training Accuracy:  84.4%, Loss: 0.3674\n",
      "Optimization Iteration:  27585, Training Accuracy:  81.2%, Loss: 0.3484\n",
      "Optimization Iteration:  27649, Training Accuracy:  71.9%, Loss: 0.4037\n",
      "Optimization Iteration:  27713, Training Accuracy:  75.0%, Loss: 0.4480\n",
      "Optimization Iteration:  27777, Training Accuracy:  81.2%, Loss: 0.3484\n",
      "Optimization Iteration:  27841, Training Accuracy:  78.1%, Loss: 0.4037\n",
      "Optimization Iteration:  27905, Training Accuracy:  76.6%, Loss: 0.3384\n",
      "Optimization Iteration:  27969, Training Accuracy:  71.9%, Loss: 0.4297\n",
      "Optimization Iteration:  28033, Training Accuracy:  82.8%, Loss: 0.3551\n",
      "Optimization Iteration:  28097, Training Accuracy:  73.4%, Loss: 0.3510\n",
      "Optimization Iteration:  28161, Training Accuracy:  87.5%, Loss: 0.2953\n",
      "Optimization Iteration:  28225, Training Accuracy:  82.8%, Loss: 0.3722\n",
      "Optimization Iteration:  28289, Training Accuracy:  76.6%, Loss: 0.3887\n",
      "Optimization Iteration:  28353, Training Accuracy:  71.9%, Loss: 0.3882\n",
      "Optimization Iteration:  28417, Training Accuracy:  82.8%, Loss: 0.3668\n",
      "Optimization Iteration:  28481, Training Accuracy:  78.1%, Loss: 0.3582\n",
      "Optimization Iteration:  28545, Training Accuracy:  84.4%, Loss: 0.2580\n",
      "Optimization Iteration:  28609, Training Accuracy:  84.4%, Loss: 0.2815\n",
      "Optimization Iteration:  28673, Training Accuracy:  64.1%, Loss: 0.5128\n",
      "Optimization Iteration:  28737, Training Accuracy:  78.1%, Loss: 0.3291\n",
      "Optimization Iteration:  28801, Training Accuracy:  82.8%, Loss: 0.2992\n",
      "Optimization Iteration:  28865, Training Accuracy:  75.0%, Loss: 0.3678\n",
      "Optimization Iteration:  28929, Training Accuracy:  81.2%, Loss: 0.3105\n",
      "Optimization Iteration:  28993, Training Accuracy:  81.2%, Loss: 0.3759\n",
      "Optimization Iteration:  29057, Training Accuracy:  67.2%, Loss: 0.3756\n",
      "Optimization Iteration:  29121, Training Accuracy:  70.3%, Loss: 0.4546\n",
      "Optimization Iteration:  29185, Training Accuracy:  78.1%, Loss: 0.3242\n",
      "Optimization Iteration:  29249, Training Accuracy:  82.8%, Loss: 0.3752\n",
      "Optimization Iteration:  29313, Training Accuracy:  84.4%, Loss: 0.3389\n",
      "Optimization Iteration:  29377, Training Accuracy:  81.2%, Loss: 0.3793\n",
      "Optimization Iteration:  29441, Training Accuracy:  79.7%, Loss: 0.4380\n",
      "Optimization Iteration:  29505, Training Accuracy:  79.7%, Loss: 0.4635\n",
      "Optimization Iteration:  29569, Training Accuracy:  70.3%, Loss: 0.4657\n",
      "Optimization Iteration:  29633, Training Accuracy:  73.4%, Loss: 0.3949\n",
      "Optimization Iteration:  29697, Training Accuracy:  78.1%, Loss: 0.3813\n",
      "Optimization Iteration:  29761, Training Accuracy:  82.8%, Loss: 0.3620\n",
      "Optimization Iteration:  29825, Training Accuracy:  67.2%, Loss: 0.4752\n",
      "Optimization Iteration:  29889, Training Accuracy:  71.9%, Loss: 0.4082\n",
      "Optimization Iteration:  29953, Training Accuracy:  78.1%, Loss: 0.3745\n",
      "Optimization Iteration:  30017, Training Accuracy:  93.8%, Loss: 0.2687\n",
      "Optimization Iteration:  30081, Training Accuracy:  76.6%, Loss: 0.3573\n",
      "Optimization Iteration:  30145, Training Accuracy:  79.7%, Loss: 0.3815\n",
      "Optimization Iteration:  30209, Training Accuracy:  76.6%, Loss: 0.3977\n",
      "Optimization Iteration:  30273, Training Accuracy:  78.1%, Loss: 0.4128\n",
      "Optimization Iteration:  30337, Training Accuracy:  79.7%, Loss: 0.3894\n",
      "Optimization Iteration:  30401, Training Accuracy:  76.6%, Loss: 0.3967\n",
      "Optimization Iteration:  30465, Training Accuracy:  76.6%, Loss: 0.3932\n",
      "Optimization Iteration:  30529, Training Accuracy:  76.6%, Loss: 0.3575\n",
      "Optimization Iteration:  30593, Training Accuracy:  84.4%, Loss: 0.3488\n",
      "Optimization Iteration:  30657, Training Accuracy:  76.6%, Loss: 0.3671\n",
      "Optimization Iteration:  30721, Training Accuracy:  85.9%, Loss: 0.3162\n",
      "Optimization Iteration:  30785, Training Accuracy:  75.0%, Loss: 0.3328\n",
      "Optimization Iteration:  30849, Training Accuracy:  81.2%, Loss: 0.4024\n",
      "Optimization Iteration:  30913, Training Accuracy:  82.8%, Loss: 0.3709\n",
      "Optimization Iteration:  30977, Training Accuracy:  71.9%, Loss: 0.4278\n",
      "Optimization Iteration:  31041, Training Accuracy:  76.6%, Loss: 0.4191\n",
      "Optimization Iteration:  31105, Training Accuracy:  71.9%, Loss: 0.3908\n",
      "Optimization Iteration:  31169, Training Accuracy:  68.8%, Loss: 0.3989\n",
      "Optimization Iteration:  31233, Training Accuracy:  76.6%, Loss: 0.3149\n",
      "Optimization Iteration:  31297, Training Accuracy:  76.6%, Loss: 0.3306\n",
      "Optimization Iteration:  31361, Training Accuracy:  78.1%, Loss: 0.4009\n",
      "Optimization Iteration:  31425, Training Accuracy:  75.0%, Loss: 0.3448\n",
      "Optimization Iteration:  31489, Training Accuracy:  85.9%, Loss: 0.3043\n",
      "Optimization Iteration:  31553, Training Accuracy:  78.1%, Loss: 0.3864\n",
      "Optimization Iteration:  31617, Training Accuracy:  71.9%, Loss: 0.3466\n",
      "Optimization Iteration:  31681, Training Accuracy:  82.8%, Loss: 0.4031\n",
      "Optimization Iteration:  31745, Training Accuracy:  81.2%, Loss: 0.3546\n",
      "Optimization Iteration:  31809, Training Accuracy:  68.8%, Loss: 0.4875\n",
      "Optimization Iteration:  31873, Training Accuracy:  79.7%, Loss: 0.3283\n",
      "Optimization Iteration:  31937, Training Accuracy:  75.0%, Loss: 0.3903\n",
      "Optimization Iteration:  32001, Training Accuracy:  71.9%, Loss: 0.4051\n",
      "Optimization Iteration:  32065, Training Accuracy:  70.3%, Loss: 0.3942\n",
      "Optimization Iteration:  32129, Training Accuracy:  70.3%, Loss: 0.3909\n",
      "Optimization Iteration:  32193, Training Accuracy:  78.1%, Loss: 0.4281\n",
      "Optimization Iteration:  32257, Training Accuracy:  75.0%, Loss: 0.3962\n",
      "Optimization Iteration:  32321, Training Accuracy:  78.1%, Loss: 0.3292\n",
      "Optimization Iteration:  32385, Training Accuracy:  76.6%, Loss: 0.3651\n",
      "Optimization Iteration:  32449, Training Accuracy:  60.9%, Loss: 0.4990\n",
      "Optimization Iteration:  32513, Training Accuracy:  71.9%, Loss: 0.3928\n",
      "Optimization Iteration:  32577, Training Accuracy:  76.6%, Loss: 0.3933\n",
      "Optimization Iteration:  32641, Training Accuracy:  71.9%, Loss: 0.4354\n",
      "Optimization Iteration:  32705, Training Accuracy:  81.2%, Loss: 0.3876\n",
      "Optimization Iteration:  32769, Training Accuracy:  81.2%, Loss: 0.3071\n",
      "Optimization Iteration:  32833, Training Accuracy:  81.2%, Loss: 0.3742\n",
      "Optimization Iteration:  32897, Training Accuracy:  73.4%, Loss: 0.4267\n",
      "Optimization Iteration:  32961, Training Accuracy:  75.0%, Loss: 0.3949\n",
      "Optimization Iteration:  33025, Training Accuracy:  79.7%, Loss: 0.3361\n",
      "Optimization Iteration:  33089, Training Accuracy:  85.9%, Loss: 0.4334\n",
      "Optimization Iteration:  33153, Training Accuracy:  79.7%, Loss: 0.3799\n",
      "Optimization Iteration:  33217, Training Accuracy:  68.8%, Loss: 0.4092\n",
      "Optimization Iteration:  33281, Training Accuracy:  67.2%, Loss: 0.4744\n",
      "Optimization Iteration:  33345, Training Accuracy:  81.2%, Loss: 0.4011\n",
      "Optimization Iteration:  33409, Training Accuracy:  81.2%, Loss: 0.4526\n",
      "Optimization Iteration:  33473, Training Accuracy:  75.0%, Loss: 0.3931\n",
      "Optimization Iteration:  33537, Training Accuracy:  70.3%, Loss: 0.4386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  33601, Training Accuracy:  65.6%, Loss: 0.4130\n",
      "Optimization Iteration:  33665, Training Accuracy:  76.6%, Loss: 0.4369\n",
      "Optimization Iteration:  33729, Training Accuracy:  75.0%, Loss: 0.4270\n",
      "Optimization Iteration:  33793, Training Accuracy:  70.3%, Loss: 0.5291\n",
      "Optimization Iteration:  33857, Training Accuracy:  79.7%, Loss: 0.3831\n",
      "Optimization Iteration:  33921, Training Accuracy:  76.6%, Loss: 0.4100\n",
      "Optimization Iteration:  33985, Training Accuracy:  67.2%, Loss: 0.4570\n",
      "Optimization Iteration:  34049, Training Accuracy:  71.9%, Loss: 0.4722\n",
      "Optimization Iteration:  34113, Training Accuracy:  78.1%, Loss: 0.3837\n",
      "Optimization Iteration:  34177, Training Accuracy:  71.9%, Loss: 0.3890\n",
      "Optimization Iteration:  34241, Training Accuracy:  75.0%, Loss: 0.4277\n",
      "Optimization Iteration:  34305, Training Accuracy:  81.2%, Loss: 0.3503\n",
      "Optimization Iteration:  34369, Training Accuracy:  75.0%, Loss: 0.3544\n",
      "Optimization Iteration:  34433, Training Accuracy:  75.0%, Loss: 0.4327\n",
      "Optimization Iteration:  34497, Training Accuracy:  75.0%, Loss: 0.3810\n",
      "Optimization Iteration:  34561, Training Accuracy:  82.8%, Loss: 0.2943\n",
      "Optimization Iteration:  34625, Training Accuracy:  76.6%, Loss: 0.4284\n",
      "Optimization Iteration:  34689, Training Accuracy:  71.9%, Loss: 0.4509\n",
      "Optimization Iteration:  34753, Training Accuracy:  70.3%, Loss: 0.4423\n",
      "Optimization Iteration:  34817, Training Accuracy:  78.1%, Loss: 0.3693\n",
      "Optimization Iteration:  34881, Training Accuracy:  71.9%, Loss: 0.3840\n",
      "Optimization Iteration:  34945, Training Accuracy:  78.1%, Loss: 0.3789\n",
      "Optimization Iteration:  35009, Training Accuracy:  84.4%, Loss: 0.3719\n",
      "Optimization Iteration:  35073, Training Accuracy:  76.6%, Loss: 0.3978\n",
      "Optimization Iteration:  35137, Training Accuracy:  76.6%, Loss: 0.3195\n",
      "Optimization Iteration:  35201, Training Accuracy:  78.1%, Loss: 0.3737\n",
      "Optimization Iteration:  35265, Training Accuracy:  70.3%, Loss: 0.3910\n",
      "Optimization Iteration:  35329, Training Accuracy:  84.4%, Loss: 0.3342\n",
      "Optimization Iteration:  35393, Training Accuracy:  84.4%, Loss: 0.3029\n",
      "Optimization Iteration:  35457, Training Accuracy:  78.1%, Loss: 0.3441\n",
      "Optimization Iteration:  35521, Training Accuracy:  62.5%, Loss: 0.4203\n",
      "Optimization Iteration:  35585, Training Accuracy:  76.6%, Loss: 0.3341\n",
      "Optimization Iteration:  35649, Training Accuracy:  76.6%, Loss: 0.4379\n",
      "Optimization Iteration:  35713, Training Accuracy:  79.7%, Loss: 0.3765\n",
      "Optimization Iteration:  35777, Training Accuracy:  81.2%, Loss: 0.3773\n",
      "Optimization Iteration:  35841, Training Accuracy:  70.3%, Loss: 0.4319\n",
      "Optimization Iteration:  35905, Training Accuracy:  79.7%, Loss: 0.3127\n",
      "Optimization Iteration:  35969, Training Accuracy:  73.4%, Loss: 0.4776\n",
      "Optimization Iteration:  36033, Training Accuracy:  70.3%, Loss: 0.3603\n",
      "Optimization Iteration:  36097, Training Accuracy:  64.1%, Loss: 0.4747\n",
      "Optimization Iteration:  36161, Training Accuracy:  75.0%, Loss: 0.3982\n",
      "Optimization Iteration:  36225, Training Accuracy:  85.9%, Loss: 0.3160\n",
      "Optimization Iteration:  36289, Training Accuracy:  71.9%, Loss: 0.3499\n",
      "Optimization Iteration:  36353, Training Accuracy:  78.1%, Loss: 0.3498\n",
      "Optimization Iteration:  36417, Training Accuracy:  84.4%, Loss: 0.3690\n",
      "Optimization Iteration:  36481, Training Accuracy:  82.8%, Loss: 0.2680\n",
      "Optimization Iteration:  36545, Training Accuracy:  84.4%, Loss: 0.3231\n",
      "Optimization Iteration:  36609, Training Accuracy:  81.2%, Loss: 0.3329\n",
      "Optimization Iteration:  36673, Training Accuracy:  75.0%, Loss: 0.4298\n",
      "Optimization Iteration:  36737, Training Accuracy:  81.2%, Loss: 0.3554\n",
      "Optimization Iteration:  36801, Training Accuracy:  73.4%, Loss: 0.3461\n",
      "Optimization Iteration:  36865, Training Accuracy:  71.9%, Loss: 0.4852\n",
      "Optimization Iteration:  36929, Training Accuracy:  73.4%, Loss: 0.3701\n",
      "Optimization Iteration:  36993, Training Accuracy:  71.9%, Loss: 0.3670\n",
      "Optimization Iteration:  37057, Training Accuracy:  81.2%, Loss: 0.3212\n",
      "Optimization Iteration:  37121, Training Accuracy:  93.8%, Loss: 0.2046\n",
      "Optimization Iteration:  37185, Training Accuracy:  78.1%, Loss: 0.3734\n",
      "Optimization Iteration:  37249, Training Accuracy:  71.9%, Loss: 0.4664\n",
      "Optimization Iteration:  37313, Training Accuracy:  79.7%, Loss: 0.3077\n",
      "Optimization Iteration:  37377, Training Accuracy:  78.1%, Loss: 0.4083\n",
      "Optimization Iteration:  37441, Training Accuracy:  75.0%, Loss: 0.3632\n",
      "Optimization Iteration:  37505, Training Accuracy:  79.7%, Loss: 0.3919\n",
      "Optimization Iteration:  37569, Training Accuracy:  73.4%, Loss: 0.4742\n",
      "Optimization Iteration:  37633, Training Accuracy:  73.4%, Loss: 0.4457\n",
      "Optimization Iteration:  37697, Training Accuracy:  79.7%, Loss: 0.3476\n",
      "Optimization Iteration:  37761, Training Accuracy:  76.6%, Loss: 0.4324\n",
      "Optimization Iteration:  37825, Training Accuracy:  85.9%, Loss: 0.2875\n",
      "Optimization Iteration:  37889, Training Accuracy:  84.4%, Loss: 0.2914\n",
      "Optimization Iteration:  37953, Training Accuracy:  76.6%, Loss: 0.3347\n",
      "Optimization Iteration:  38017, Training Accuracy:  79.7%, Loss: 0.4093\n",
      "Optimization Iteration:  38081, Training Accuracy:  78.1%, Loss: 0.3866\n",
      "Optimization Iteration:  38145, Training Accuracy:  78.1%, Loss: 0.3926\n",
      "Optimization Iteration:  38209, Training Accuracy:  81.2%, Loss: 0.3592\n",
      "Optimization Iteration:  38273, Training Accuracy:  79.7%, Loss: 0.3505\n",
      "Optimization Iteration:  38337, Training Accuracy:  79.7%, Loss: 0.3606\n",
      "Optimization Iteration:  38401, Training Accuracy:  82.8%, Loss: 0.3094\n",
      "Optimization Iteration:  38465, Training Accuracy:  70.3%, Loss: 0.4109\n",
      "Optimization Iteration:  38529, Training Accuracy:  79.7%, Loss: 0.3747\n",
      "Optimization Iteration:  38593, Training Accuracy:  76.6%, Loss: 0.4682\n",
      "Optimization Iteration:  38657, Training Accuracy:  64.1%, Loss: 0.5298\n",
      "Optimization Iteration:  38721, Training Accuracy:  65.6%, Loss: 0.3932\n",
      "Optimization Iteration:  38785, Training Accuracy:  70.3%, Loss: 0.4556\n",
      "Optimization Iteration:  38849, Training Accuracy:  85.9%, Loss: 0.2829\n",
      "Optimization Iteration:  38913, Training Accuracy:  78.1%, Loss: 0.3786\n",
      "Optimization Iteration:  38977, Training Accuracy:  70.3%, Loss: 0.4294\n",
      "Optimization Iteration:  39041, Training Accuracy:  78.1%, Loss: 0.3676\n",
      "Optimization Iteration:  39105, Training Accuracy:  78.1%, Loss: 0.5026\n",
      "Optimization Iteration:  39169, Training Accuracy:  67.2%, Loss: 0.4691\n",
      "Optimization Iteration:  39233, Training Accuracy:  79.7%, Loss: 0.4209\n",
      "Optimization Iteration:  39297, Training Accuracy:  70.3%, Loss: 0.4176\n",
      "Optimization Iteration:  39361, Training Accuracy:  75.0%, Loss: 0.3686\n",
      "Optimization Iteration:  39425, Training Accuracy:  75.0%, Loss: 0.4344\n",
      "Optimization Iteration:  39489, Training Accuracy:  84.4%, Loss: 0.3029\n",
      "Optimization Iteration:  39553, Training Accuracy:  81.2%, Loss: 0.2958\n",
      "Optimization Iteration:  39617, Training Accuracy:  76.6%, Loss: 0.4245\n",
      "Optimization Iteration:  39681, Training Accuracy:  67.2%, Loss: 0.4351\n",
      "Optimization Iteration:  39745, Training Accuracy:  79.7%, Loss: 0.3718\n",
      "Optimization Iteration:  39809, Training Accuracy:  76.6%, Loss: 0.4264\n",
      "Optimization Iteration:  39873, Training Accuracy:  78.1%, Loss: 0.3968\n",
      "Optimization Iteration:  39937, Training Accuracy:  79.7%, Loss: 0.4589\n",
      "Optimization Iteration:  40001, Training Accuracy:  75.0%, Loss: 0.4029\n",
      "Optimization Iteration:  40065, Training Accuracy:  68.8%, Loss: 0.3895\n",
      "Optimization Iteration:  40129, Training Accuracy:  71.9%, Loss: 0.4062\n",
      "Optimization Iteration:  40193, Training Accuracy:  81.2%, Loss: 0.3180\n",
      "Optimization Iteration:  40257, Training Accuracy:  68.8%, Loss: 0.4536\n",
      "Optimization Iteration:  40321, Training Accuracy:  78.1%, Loss: 0.3839\n",
      "Optimization Iteration:  40385, Training Accuracy:  75.0%, Loss: 0.4059\n",
      "Optimization Iteration:  40449, Training Accuracy:  79.7%, Loss: 0.3477\n",
      "Optimization Iteration:  40513, Training Accuracy:  85.9%, Loss: 0.3703\n",
      "Optimization Iteration:  40577, Training Accuracy:  75.0%, Loss: 0.3585\n",
      "Optimization Iteration:  40641, Training Accuracy:  79.7%, Loss: 0.3350\n",
      "Optimization Iteration:  40705, Training Accuracy:  75.0%, Loss: 0.3872\n",
      "Optimization Iteration:  40769, Training Accuracy:  82.8%, Loss: 0.3206\n",
      "Optimization Iteration:  40833, Training Accuracy:  85.9%, Loss: 0.3320\n",
      "Optimization Iteration:  40897, Training Accuracy:  76.6%, Loss: 0.3361\n",
      "Optimization Iteration:  40961, Training Accuracy:  85.9%, Loss: 0.3032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  41025, Training Accuracy:  75.0%, Loss: 0.3550\n",
      "Optimization Iteration:  41089, Training Accuracy:  82.8%, Loss: 0.3279\n",
      "Optimization Iteration:  41153, Training Accuracy:  81.2%, Loss: 0.3621\n",
      "Optimization Iteration:  41217, Training Accuracy:  79.7%, Loss: 0.3411\n",
      "Optimization Iteration:  41281, Training Accuracy:  70.3%, Loss: 0.4193\n",
      "Optimization Iteration:  41345, Training Accuracy:  75.0%, Loss: 0.4112\n",
      "Optimization Iteration:  41409, Training Accuracy:  76.6%, Loss: 0.4211\n",
      "Optimization Iteration:  41473, Training Accuracy:  78.1%, Loss: 0.3928\n",
      "Optimization Iteration:  41537, Training Accuracy:  73.4%, Loss: 0.3947\n",
      "Optimization Iteration:  41601, Training Accuracy:  73.4%, Loss: 0.4048\n",
      "Optimization Iteration:  41665, Training Accuracy:  73.4%, Loss: 0.3924\n",
      "Optimization Iteration:  41729, Training Accuracy:  90.6%, Loss: 0.2390\n",
      "Optimization Iteration:  41793, Training Accuracy:  76.6%, Loss: 0.3968\n",
      "Optimization Iteration:  41857, Training Accuracy:  76.6%, Loss: 0.4255\n",
      "Optimization Iteration:  41921, Training Accuracy:  79.7%, Loss: 0.3420\n",
      "Optimization Iteration:  41985, Training Accuracy:  70.3%, Loss: 0.5294\n",
      "Optimization Iteration:  42049, Training Accuracy:  71.9%, Loss: 0.4350\n",
      "Optimization Iteration:  42113, Training Accuracy:  79.7%, Loss: 0.3956\n",
      "Optimization Iteration:  42177, Training Accuracy:  78.1%, Loss: 0.3423\n",
      "Optimization Iteration:  42241, Training Accuracy:  78.1%, Loss: 0.3548\n",
      "Optimization Iteration:  42305, Training Accuracy:  81.2%, Loss: 0.4995\n",
      "Optimization Iteration:  42369, Training Accuracy:  81.2%, Loss: 0.3808\n",
      "Optimization Iteration:  42433, Training Accuracy:  75.0%, Loss: 0.4196\n",
      "Optimization Iteration:  42497, Training Accuracy:  75.0%, Loss: 0.4046\n",
      "Optimization Iteration:  42561, Training Accuracy:  73.4%, Loss: 0.4015\n",
      "Optimization Iteration:  42625, Training Accuracy:  70.3%, Loss: 0.3916\n",
      "Optimization Iteration:  42689, Training Accuracy:  81.2%, Loss: 0.3647\n",
      "Optimization Iteration:  42753, Training Accuracy:  73.4%, Loss: 0.4291\n",
      "Optimization Iteration:  42817, Training Accuracy:  79.7%, Loss: 0.3396\n",
      "Optimization Iteration:  42881, Training Accuracy:  79.7%, Loss: 0.4131\n",
      "Optimization Iteration:  42945, Training Accuracy:  71.9%, Loss: 0.3300\n",
      "Optimization Iteration:  43009, Training Accuracy:  78.1%, Loss: 0.3436\n",
      "Optimization Iteration:  43073, Training Accuracy:  82.8%, Loss: 0.3675\n",
      "Optimization Iteration:  43137, Training Accuracy:  85.9%, Loss: 0.3359\n",
      "Optimization Iteration:  43201, Training Accuracy:  81.2%, Loss: 0.3320\n",
      "Optimization Iteration:  43265, Training Accuracy:  79.7%, Loss: 0.3365\n",
      "Optimization Iteration:  43329, Training Accuracy:  76.6%, Loss: 0.4114\n",
      "Optimization Iteration:  43393, Training Accuracy:  68.8%, Loss: 0.4167\n",
      "Optimization Iteration:  43457, Training Accuracy:  82.8%, Loss: 0.3146\n",
      "Optimization Iteration:  43521, Training Accuracy:  89.1%, Loss: 0.3349\n",
      "Optimization Iteration:  43585, Training Accuracy:  79.7%, Loss: 0.3940\n",
      "Optimization Iteration:  43649, Training Accuracy:  82.8%, Loss: 0.4217\n",
      "Optimization Iteration:  43713, Training Accuracy:  82.8%, Loss: 0.3646\n",
      "Optimization Iteration:  43777, Training Accuracy:  84.4%, Loss: 0.3461\n",
      "Optimization Iteration:  43841, Training Accuracy:  78.1%, Loss: 0.3829\n",
      "Optimization Iteration:  43905, Training Accuracy:  78.1%, Loss: 0.3398\n",
      "Optimization Iteration:  43969, Training Accuracy:  84.4%, Loss: 0.2997\n",
      "Optimization Iteration:  44033, Training Accuracy:  76.6%, Loss: 0.3928\n",
      "Optimization Iteration:  44097, Training Accuracy:  78.1%, Loss: 0.3636\n",
      "Optimization Iteration:  44161, Training Accuracy:  75.0%, Loss: 0.3860\n",
      "Optimization Iteration:  44225, Training Accuracy:  81.2%, Loss: 0.4382\n",
      "Optimization Iteration:  44289, Training Accuracy:  73.4%, Loss: 0.3776\n",
      "Optimization Iteration:  44353, Training Accuracy:  67.2%, Loss: 0.4384\n",
      "Optimization Iteration:  44417, Training Accuracy:  81.2%, Loss: 0.3703\n",
      "Optimization Iteration:  44481, Training Accuracy:  73.4%, Loss: 0.3813\n",
      "Optimization Iteration:  44545, Training Accuracy:  84.4%, Loss: 0.3418\n",
      "Optimization Iteration:  44609, Training Accuracy:  78.1%, Loss: 0.3940\n",
      "Optimization Iteration:  44673, Training Accuracy:  64.1%, Loss: 0.4412\n",
      "Optimization Iteration:  44737, Training Accuracy:  68.8%, Loss: 0.3824\n",
      "Optimization Iteration:  44801, Training Accuracy:  78.1%, Loss: 0.4013\n",
      "Optimization Iteration:  44865, Training Accuracy:  71.9%, Loss: 0.3993\n",
      "Optimization Iteration:  44929, Training Accuracy:  79.7%, Loss: 0.3554\n",
      "Optimization Iteration:  44993, Training Accuracy:  79.7%, Loss: 0.3414\n",
      "Optimization Iteration:  45057, Training Accuracy:  78.1%, Loss: 0.4354\n",
      "Optimization Iteration:  45121, Training Accuracy:  82.8%, Loss: 0.3567\n",
      "Optimization Iteration:  45185, Training Accuracy:  71.9%, Loss: 0.3803\n",
      "Optimization Iteration:  45249, Training Accuracy:  82.8%, Loss: 0.3845\n",
      "Optimization Iteration:  45313, Training Accuracy:  85.9%, Loss: 0.3317\n",
      "Optimization Iteration:  45377, Training Accuracy:  76.6%, Loss: 0.4156\n",
      "Optimization Iteration:  45441, Training Accuracy:  78.1%, Loss: 0.4357\n",
      "Optimization Iteration:  45505, Training Accuracy:  82.8%, Loss: 0.3795\n",
      "Optimization Iteration:  45569, Training Accuracy:  78.1%, Loss: 0.3829\n",
      "Optimization Iteration:  45633, Training Accuracy:  76.6%, Loss: 0.4015\n",
      "Optimization Iteration:  45697, Training Accuracy:  81.2%, Loss: 0.3531\n",
      "Optimization Iteration:  45761, Training Accuracy:  85.9%, Loss: 0.3354\n",
      "Optimization Iteration:  45825, Training Accuracy:  73.4%, Loss: 0.3586\n",
      "Optimization Iteration:  45889, Training Accuracy:  79.7%, Loss: 0.3181\n",
      "Optimization Iteration:  45953, Training Accuracy:  71.9%, Loss: 0.4280\n",
      "Optimization Iteration:  46017, Training Accuracy:  73.4%, Loss: 0.4182\n",
      "Optimization Iteration:  46081, Training Accuracy:  76.6%, Loss: 0.3453\n",
      "Optimization Iteration:  46145, Training Accuracy:  70.3%, Loss: 0.4201\n",
      "Optimization Iteration:  46209, Training Accuracy:  85.9%, Loss: 0.3209\n",
      "Optimization Iteration:  46273, Training Accuracy:  73.4%, Loss: 0.3869\n",
      "Optimization Iteration:  46337, Training Accuracy:  81.2%, Loss: 0.3778\n",
      "Optimization Iteration:  46401, Training Accuracy:  82.8%, Loss: 0.3194\n",
      "Optimization Iteration:  46465, Training Accuracy:  78.1%, Loss: 0.3962\n",
      "Optimization Iteration:  46529, Training Accuracy:  68.8%, Loss: 0.4481\n",
      "Optimization Iteration:  46593, Training Accuracy:  71.9%, Loss: 0.4211\n",
      "Optimization Iteration:  46657, Training Accuracy:  73.4%, Loss: 0.3991\n",
      "Optimization Iteration:  46721, Training Accuracy:  82.8%, Loss: 0.3105\n",
      "Optimization Iteration:  46785, Training Accuracy:  71.9%, Loss: 0.4181\n",
      "Optimization Iteration:  46849, Training Accuracy:  75.0%, Loss: 0.3585\n",
      "Optimization Iteration:  46913, Training Accuracy:  78.1%, Loss: 0.3675\n",
      "Optimization Iteration:  46977, Training Accuracy:  76.6%, Loss: 0.4317\n",
      "Optimization Iteration:  47041, Training Accuracy:  78.1%, Loss: 0.4078\n",
      "Optimization Iteration:  47105, Training Accuracy:  70.3%, Loss: 0.5325\n",
      "Optimization Iteration:  47169, Training Accuracy:  76.6%, Loss: 0.4102\n",
      "Optimization Iteration:  47233, Training Accuracy:  81.2%, Loss: 0.3797\n",
      "Optimization Iteration:  47297, Training Accuracy:  78.1%, Loss: 0.3278\n",
      "Optimization Iteration:  47361, Training Accuracy:  78.1%, Loss: 0.3218\n",
      "Optimization Iteration:  47425, Training Accuracy:  79.7%, Loss: 0.3198\n",
      "Optimization Iteration:  47489, Training Accuracy:  71.9%, Loss: 0.4172\n",
      "Optimization Iteration:  47553, Training Accuracy:  78.1%, Loss: 0.4327\n",
      "Optimization Iteration:  47617, Training Accuracy:  75.0%, Loss: 0.3936\n",
      "Optimization Iteration:  47681, Training Accuracy:  76.6%, Loss: 0.4070\n",
      "Optimization Iteration:  47745, Training Accuracy:  73.4%, Loss: 0.3697\n",
      "Optimization Iteration:  47809, Training Accuracy:  75.0%, Loss: 0.3662\n",
      "Optimization Iteration:  47873, Training Accuracy:  84.4%, Loss: 0.3448\n",
      "Optimization Iteration:  47937, Training Accuracy:  67.2%, Loss: 0.4570\n",
      "Optimization Iteration:  48001, Training Accuracy:  79.7%, Loss: 0.3589\n",
      "Optimization Iteration:  48065, Training Accuracy:  79.7%, Loss: 0.3223\n",
      "Optimization Iteration:  48129, Training Accuracy:  70.3%, Loss: 0.4759\n",
      "Optimization Iteration:  48193, Training Accuracy:  79.7%, Loss: 0.4273\n",
      "Optimization Iteration:  48257, Training Accuracy:  79.7%, Loss: 0.3711\n",
      "Optimization Iteration:  48321, Training Accuracy:  78.1%, Loss: 0.3529\n",
      "Optimization Iteration:  48385, Training Accuracy:  81.2%, Loss: 0.3132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  48449, Training Accuracy:  68.8%, Loss: 0.4089\n",
      "Optimization Iteration:  48513, Training Accuracy:  71.9%, Loss: 0.4365\n",
      "Optimization Iteration:  48577, Training Accuracy:  71.9%, Loss: 0.4408\n",
      "Optimization Iteration:  48641, Training Accuracy:  84.4%, Loss: 0.3599\n",
      "Optimization Iteration:  48705, Training Accuracy:  82.8%, Loss: 0.3129\n",
      "Optimization Iteration:  48769, Training Accuracy:  92.2%, Loss: 0.2690\n",
      "Optimization Iteration:  48833, Training Accuracy:  85.9%, Loss: 0.3292\n",
      "Optimization Iteration:  48897, Training Accuracy:  76.6%, Loss: 0.4363\n",
      "Optimization Iteration:  48961, Training Accuracy:  73.4%, Loss: 0.4342\n",
      "Optimization Iteration:  49025, Training Accuracy:  81.2%, Loss: 0.4422\n",
      "Optimization Iteration:  49089, Training Accuracy:  71.9%, Loss: 0.4244\n",
      "Optimization Iteration:  49153, Training Accuracy:  71.9%, Loss: 0.4043\n",
      "Optimization Iteration:  49217, Training Accuracy:  81.2%, Loss: 0.4096\n",
      "Optimization Iteration:  49281, Training Accuracy:  78.1%, Loss: 0.3676\n",
      "Optimization Iteration:  49345, Training Accuracy:  70.3%, Loss: 0.3907\n",
      "Optimization Iteration:  49409, Training Accuracy:  67.2%, Loss: 0.4515\n",
      "Optimization Iteration:  49473, Training Accuracy:  79.7%, Loss: 0.3346\n",
      "Optimization Iteration:  49537, Training Accuracy:  71.9%, Loss: 0.3573\n",
      "Optimization Iteration:  49601, Training Accuracy:  79.7%, Loss: 0.3848\n",
      "Optimization Iteration:  49665, Training Accuracy:  76.6%, Loss: 0.3609\n",
      "Optimization Iteration:  49729, Training Accuracy:  78.1%, Loss: 0.4100\n",
      "Optimization Iteration:  49793, Training Accuracy:  84.4%, Loss: 0.3524\n",
      "Optimization Iteration:  49857, Training Accuracy:  71.9%, Loss: 0.4391\n",
      "Optimization Iteration:  49921, Training Accuracy:  82.8%, Loss: 0.3643\n",
      "Model saved in file: SD/50kSD_Model.ckpt\n",
      "Time usage: 0:51:29\n",
      "[0.734375, 0.765625, 0.796875, 0.71875, 0.765625, 0.796875, 0.78125, 0.78125, 0.671875, 0.78125, 0.6875, 0.78125, 0.75, 0.734375, 0.78125, 0.796875, 0.71875, 0.671875, 0.75, 0.734375, 0.8125, 0.75, 0.75, 0.78125, 0.828125, 0.828125, 0.703125, 0.734375, 0.765625, 0.8125, 0.765625, 0.8125, 0.796875, 0.796875, 0.734375, 0.71875, 0.796875, 0.78125, 0.84375, 0.84375, 0.8125, 0.75, 0.8125, 0.734375, 0.765625, 0.796875, 0.765625, 0.828125, 0.8125, 0.796875, 0.78125, 0.796875, 0.8125, 0.734375, 0.796875, 0.8125, 0.75, 0.71875, 0.671875, 0.71875, 0.8125, 0.75, 0.859375, 0.75, 0.71875, 0.828125, 0.78125, 0.78125, 0.75, 0.765625, 0.734375, 0.796875, 0.796875, 0.8125, 0.71875, 0.75, 0.8125, 0.859375, 0.671875, 0.84375, 0.765625, 0.703125, 0.890625, 0.71875, 0.765625, 0.859375, 0.796875, 0.703125, 0.75, 0.71875, 0.75, 0.828125, 0.75, 0.734375, 0.75, 0.6875, 0.75, 0.75, 0.71875, 0.78125, 0.859375, 0.75, 0.734375, 0.71875, 0.84375, 0.703125, 0.703125, 0.78125, 0.71875, 0.78125, 0.78125, 0.796875, 0.71875, 0.734375, 0.796875, 0.8125, 0.8125, 0.765625, 0.78125, 0.703125, 0.84375, 0.78125, 0.765625, 0.78125, 0.78125, 0.671875, 0.6875, 0.765625, 0.703125, 0.8125, 0.75, 0.796875, 0.859375, 0.765625, 0.84375, 0.71875, 0.703125, 0.78125, 0.78125, 0.828125, 0.734375, 0.671875, 0.625, 0.734375, 0.734375, 0.828125, 0.734375, 0.796875, 0.8125, 0.71875, 0.71875, 0.71875, 0.75, 0.71875, 0.71875, 0.765625, 0.640625, 0.765625, 0.796875, 0.765625, 0.765625, 0.765625, 0.796875, 0.765625, 0.765625, 0.78125, 0.828125, 0.78125, 0.765625, 0.71875, 0.8125, 0.84375, 0.734375, 0.796875, 0.84375, 0.828125, 0.78125, 0.828125, 0.8125, 0.78125, 0.84375, 0.8125, 0.796875, 0.75, 0.796875, 0.71875, 0.796875, 0.765625, 0.796875, 0.75, 0.90625, 0.8125, 0.8125, 0.8125, 0.859375, 0.75, 0.75, 0.828125, 0.71875, 0.75, 0.796875, 0.75, 0.8125, 0.6875, 0.828125, 0.78125, 0.671875, 0.65625, 0.75, 0.765625, 0.703125, 0.859375, 0.8125, 0.765625, 0.8125, 0.828125, 0.796875, 0.8125, 0.75, 0.71875, 0.796875, 0.75, 0.703125, 0.84375, 0.875, 0.6875, 0.828125, 0.765625, 0.734375, 0.796875, 0.71875, 0.734375, 0.796875, 0.765625, 0.796875, 0.8125, 0.734375, 0.734375, 0.78125, 0.796875, 0.78125, 0.71875, 0.796875, 0.828125, 0.828125, 0.8125, 0.71875, 0.765625, 0.765625, 0.765625, 0.625, 0.828125, 0.71875, 0.8125, 0.875, 0.8125, 0.78125, 0.78125, 0.78125, 0.640625, 0.71875, 0.796875, 0.71875, 0.796875, 0.796875, 0.609375, 0.78125, 0.703125, 0.796875, 0.671875, 0.84375, 0.703125, 0.796875, 0.640625, 0.71875, 0.84375, 0.796875, 0.765625, 0.8125, 0.828125, 0.75, 0.84375, 0.703125, 0.6875, 0.703125, 0.78125, 0.734375, 0.734375, 0.765625, 0.71875, 0.734375, 0.734375, 0.75, 0.765625, 0.734375, 0.734375, 0.734375, 0.796875, 0.765625, 0.75, 0.78125, 0.75, 0.765625, 0.75, 0.796875, 0.71875, 0.84375, 0.765625, 0.8125, 0.75, 0.734375, 0.84375, 0.875, 0.734375, 0.828125, 0.75, 0.75, 0.75, 0.671875, 0.765625, 0.765625, 0.828125, 0.765625, 0.796875, 0.84375, 0.828125, 0.78125, 0.796875, 0.796875, 0.703125, 0.796875, 0.65625, 0.8125, 0.8125, 0.75, 0.796875, 0.71875, 0.90625, 0.828125, 0.859375, 0.75, 0.828125, 0.796875, 0.78125, 0.859375, 0.796875, 0.890625, 0.734375, 0.734375, 0.796875, 0.78125, 0.796875, 0.796875, 0.796875, 0.71875, 0.71875, 0.703125, 0.734375, 0.859375, 0.71875, 0.703125, 0.84375, 0.765625, 0.796875, 0.796875, 0.875, 0.765625, 0.828125, 0.71875, 0.75, 0.78125, 0.71875, 0.75, 0.625, 0.828125, 0.78125, 0.8125, 0.734375, 0.765625, 0.703125, 0.703125, 0.828125, 0.78125, 0.71875, 0.796875, 0.8125, 0.75, 0.796875, 0.765625, 0.9375, 0.765625, 0.765625, 0.765625, 0.65625, 0.796875, 0.796875, 0.78125, 0.75, 0.765625, 0.71875, 0.796875, 0.8125, 0.8125, 0.765625, 0.75, 0.703125, 0.765625, 0.78125, 0.78125, 0.734375, 0.78125, 0.796875, 0.78125, 0.78125, 0.84375, 0.75, 0.734375, 0.734375, 0.78125, 0.734375, 0.671875, 0.71875, 0.78125, 0.75, 0.796875, 0.796875, 0.78125, 0.734375, 0.78125, 0.84375, 0.8125, 0.71875, 0.75, 0.8125, 0.78125, 0.765625, 0.71875, 0.828125, 0.734375, 0.875, 0.828125, 0.765625, 0.71875, 0.828125, 0.78125, 0.84375, 0.84375, 0.640625, 0.78125, 0.828125, 0.75, 0.8125, 0.8125, 0.671875, 0.703125, 0.78125, 0.828125, 0.84375, 0.8125, 0.796875, 0.796875, 0.703125, 0.734375, 0.78125, 0.828125, 0.671875, 0.71875, 0.78125, 0.9375, 0.765625, 0.796875, 0.765625, 0.78125, 0.796875, 0.765625, 0.765625, 0.765625, 0.84375, 0.765625, 0.859375, 0.75, 0.8125, 0.828125, 0.71875, 0.765625, 0.71875, 0.6875, 0.765625, 0.765625, 0.78125, 0.75, 0.859375, 0.78125, 0.71875, 0.828125, 0.8125, 0.6875, 0.796875, 0.75, 0.71875, 0.703125, 0.703125, 0.78125, 0.75, 0.78125, 0.765625, 0.609375, 0.71875, 0.765625, 0.71875, 0.8125, 0.8125, 0.8125, 0.734375, 0.75, 0.796875, 0.859375, 0.796875, 0.6875, 0.671875, 0.8125, 0.8125, 0.75, 0.703125, 0.65625, 0.765625, 0.75, 0.703125, 0.796875, 0.765625, 0.671875, 0.71875, 0.78125, 0.71875, 0.75, 0.8125, 0.75, 0.75, 0.75, 0.828125, 0.765625, 0.71875, 0.703125, 0.78125, 0.71875, 0.78125, 0.84375, 0.765625, 0.765625, 0.78125, 0.703125, 0.84375, 0.84375, 0.78125, 0.625, 0.765625, 0.765625, 0.796875, 0.8125, 0.703125, 0.796875, 0.734375, 0.703125, 0.640625, 0.75, 0.859375, 0.71875, 0.78125, 0.84375, 0.828125, 0.84375, 0.8125, 0.75, 0.8125, 0.734375, 0.71875, 0.734375, 0.71875, 0.8125, 0.9375, 0.78125, 0.71875, 0.796875, 0.78125, 0.75, 0.796875, 0.734375, 0.734375, 0.796875, 0.765625, 0.859375, 0.84375, 0.765625, 0.796875, 0.78125, 0.78125, 0.8125, 0.796875, 0.796875, 0.828125, 0.703125, 0.796875, 0.765625, 0.640625, 0.65625, 0.703125, 0.859375, 0.78125, 0.703125, 0.78125, 0.78125, 0.671875, 0.796875, 0.703125, 0.75, 0.75, 0.84375, 0.8125, 0.765625, 0.671875, 0.796875, 0.765625, 0.78125, 0.796875, 0.75, 0.6875, 0.71875, 0.8125, 0.6875, 0.78125, 0.75, 0.796875, 0.859375, 0.75, 0.796875, 0.75, 0.828125, 0.859375, 0.765625, 0.859375, 0.75, 0.828125, 0.8125, 0.796875, 0.703125, 0.75, 0.765625, 0.78125, 0.734375, 0.734375, 0.734375, 0.90625, 0.765625, 0.765625, 0.796875, 0.703125, 0.71875, 0.796875, 0.78125, 0.78125, 0.8125, 0.8125, 0.75, 0.75, 0.734375, 0.703125, 0.8125, 0.734375, 0.796875, 0.796875, 0.71875, 0.78125, 0.828125, 0.859375, 0.8125, 0.796875, 0.765625, 0.6875, 0.828125, 0.890625, 0.796875, 0.828125, 0.828125, 0.84375, 0.78125, 0.78125, 0.84375, 0.765625, 0.78125, 0.75, 0.8125, 0.734375, 0.671875, 0.8125, 0.734375, 0.84375, 0.78125, 0.640625, 0.6875, 0.78125, 0.71875, 0.796875, 0.796875, 0.78125, 0.828125, 0.71875, 0.828125, 0.859375, 0.765625, 0.78125, 0.828125, 0.78125, 0.765625, 0.8125, 0.859375, 0.734375, 0.796875, 0.71875, 0.734375, 0.765625, 0.703125, 0.859375, 0.734375, 0.8125, 0.828125, 0.78125, 0.6875, 0.71875, 0.734375, 0.828125, 0.71875, 0.75, 0.78125, 0.765625, 0.78125, 0.703125, 0.765625, 0.8125, 0.78125, 0.78125, 0.796875, 0.71875, 0.78125, 0.75, 0.765625, 0.734375, 0.75, 0.84375, 0.671875, 0.796875, 0.796875, 0.703125, 0.796875, 0.796875, 0.78125, 0.8125, 0.6875, 0.71875, 0.71875, 0.84375, 0.828125, 0.921875, 0.859375, 0.765625, 0.734375, 0.8125, 0.71875, 0.71875, 0.8125, 0.78125, 0.703125, 0.671875, 0.796875, 0.71875, 0.796875, 0.765625, 0.78125, 0.84375, 0.71875, 0.828125]\n",
      "[65, 129, 193, 257, 321, 385, 449, 513, 577, 641, 705, 769, 833, 897, 961, 1025, 1089, 1153, 1217, 1281, 1345, 1409, 1473, 1537, 1601, 1665, 1729, 1793, 1857, 1921, 1985, 2049, 2113, 2177, 2241, 2305, 2369, 2433, 2497, 2561, 2625, 2689, 2753, 2817, 2881, 2945, 3009, 3073, 3137, 3201, 3265, 3329, 3393, 3457, 3521, 3585, 3649, 3713, 3777, 3841, 3905, 3969, 4033, 4097, 4161, 4225, 4289, 4353, 4417, 4481, 4545, 4609, 4673, 4737, 4801, 4865, 4929, 4993, 5057, 5121, 5185, 5249, 5313, 5377, 5441, 5505, 5569, 5633, 5697, 5761, 5825, 5889, 5953, 6017, 6081, 6145, 6209, 6273, 6337, 6401, 6465, 6529, 6593, 6657, 6721, 6785, 6849, 6913, 6977, 7041, 7105, 7169, 7233, 7297, 7361, 7425, 7489, 7553, 7617, 7681, 7745, 7809, 7873, 7937, 8001, 8065, 8129, 8193, 8257, 8321, 8385, 8449, 8513, 8577, 8641, 8705, 8769, 8833, 8897, 8961, 9025, 9089, 9153, 9217, 9281, 9345, 9409, 9473, 9537, 9601, 9665, 9729, 9793, 9857, 9921, 9985, 10049, 10113, 10177, 10241, 10305, 10369, 10433, 10497, 10561, 10625, 10689, 10753, 10817, 10881, 10945, 11009, 11073, 11137, 11201, 11265, 11329, 11393, 11457, 11521, 11585, 11649, 11713, 11777, 11841, 11905, 11969, 12033, 12097, 12161, 12225, 12289, 12353, 12417, 12481, 12545, 12609, 12673, 12737, 12801, 12865, 12929, 12993, 13057, 13121, 13185, 13249, 13313, 13377, 13441, 13505, 13569, 13633, 13697, 13761, 13825, 13889, 13953, 14017, 14081, 14145, 14209, 14273, 14337, 14401, 14465, 14529, 14593, 14657, 14721, 14785, 14849, 14913, 14977, 15041, 15105, 15169, 15233, 15297, 15361, 15425, 15489, 15553, 15617, 15681, 15745, 15809, 15873, 15937, 16001, 16065, 16129, 16193, 16257, 16321, 16385, 16449, 16513, 16577, 16641, 16705, 16769, 16833, 16897, 16961, 17025, 17089, 17153, 17217, 17281, 17345, 17409, 17473, 17537, 17601, 17665, 17729, 17793, 17857, 17921, 17985, 18049, 18113, 18177, 18241, 18305, 18369, 18433, 18497, 18561, 18625, 18689, 18753, 18817, 18881, 18945, 19009, 19073, 19137, 19201, 19265, 19329, 19393, 19457, 19521, 19585, 19649, 19713, 19777, 19841, 19905, 19969, 20033, 20097, 20161, 20225, 20289, 20353, 20417, 20481, 20545, 20609, 20673, 20737, 20801, 20865, 20929, 20993, 21057, 21121, 21185, 21249, 21313, 21377, 21441, 21505, 21569, 21633, 21697, 21761, 21825, 21889, 21953, 22017, 22081, 22145, 22209, 22273, 22337, 22401, 22465, 22529, 22593, 22657, 22721, 22785, 22849, 22913, 22977, 23041, 23105, 23169, 23233, 23297, 23361, 23425, 23489, 23553, 23617, 23681, 23745, 23809, 23873, 23937, 24001, 24065, 24129, 24193, 24257, 24321, 24385, 24449, 24513, 24577, 24641, 24705, 24769, 24833, 24897, 24961, 25025, 25089, 25153, 25217, 25281, 25345, 25409, 25473, 25537, 25601, 25665, 25729, 25793, 25857, 25921, 25985, 26049, 26113, 26177, 26241, 26305, 26369, 26433, 26497, 26561, 26625, 26689, 26753, 26817, 26881, 26945, 27009, 27073, 27137, 27201, 27265, 27329, 27393, 27457, 27521, 27585, 27649, 27713, 27777, 27841, 27905, 27969, 28033, 28097, 28161, 28225, 28289, 28353, 28417, 28481, 28545, 28609, 28673, 28737, 28801, 28865, 28929, 28993, 29057, 29121, 29185, 29249, 29313, 29377, 29441, 29505, 29569, 29633, 29697, 29761, 29825, 29889, 29953, 30017, 30081, 30145, 30209, 30273, 30337, 30401, 30465, 30529, 30593, 30657, 30721, 30785, 30849, 30913, 30977, 31041, 31105, 31169, 31233, 31297, 31361, 31425, 31489, 31553, 31617, 31681, 31745, 31809, 31873, 31937, 32001, 32065, 32129, 32193, 32257, 32321, 32385, 32449, 32513, 32577, 32641, 32705, 32769, 32833, 32897, 32961, 33025, 33089, 33153, 33217, 33281, 33345, 33409, 33473, 33537, 33601, 33665, 33729, 33793, 33857, 33921, 33985, 34049, 34113, 34177, 34241, 34305, 34369, 34433, 34497, 34561, 34625, 34689, 34753, 34817, 34881, 34945, 35009, 35073, 35137, 35201, 35265, 35329, 35393, 35457, 35521, 35585, 35649, 35713, 35777, 35841, 35905, 35969, 36033, 36097, 36161, 36225, 36289, 36353, 36417, 36481, 36545, 36609, 36673, 36737, 36801, 36865, 36929, 36993, 37057, 37121, 37185, 37249, 37313, 37377, 37441, 37505, 37569, 37633, 37697, 37761, 37825, 37889, 37953, 38017, 38081, 38145, 38209, 38273, 38337, 38401, 38465, 38529, 38593, 38657, 38721, 38785, 38849, 38913, 38977, 39041, 39105, 39169, 39233, 39297, 39361, 39425, 39489, 39553, 39617, 39681, 39745, 39809, 39873, 39937, 40001, 40065, 40129, 40193, 40257, 40321, 40385, 40449, 40513, 40577, 40641, 40705, 40769, 40833, 40897, 40961, 41025, 41089, 41153, 41217, 41281, 41345, 41409, 41473, 41537, 41601, 41665, 41729, 41793, 41857, 41921, 41985, 42049, 42113, 42177, 42241, 42305, 42369, 42433, 42497, 42561, 42625, 42689, 42753, 42817, 42881, 42945, 43009, 43073, 43137, 43201, 43265, 43329, 43393, 43457, 43521, 43585, 43649, 43713, 43777, 43841, 43905, 43969, 44033, 44097, 44161, 44225, 44289, 44353, 44417, 44481, 44545, 44609, 44673, 44737, 44801, 44865, 44929, 44993, 45057, 45121, 45185, 45249, 45313, 45377, 45441, 45505, 45569, 45633, 45697, 45761, 45825, 45889, 45953, 46017, 46081, 46145, 46209, 46273, 46337, 46401, 46465, 46529, 46593, 46657, 46721, 46785, 46849, 46913, 46977, 47041, 47105, 47169, 47233, 47297, 47361, 47425, 47489, 47553, 47617, 47681, 47745, 47809, 47873, 47937, 48001, 48065, 48129, 48193, 48257, 48321, 48385, 48449, 48513, 48577, 48641, 48705, 48769, 48833, 48897, 48961, 49025, 49089, 49153, 49217, 49281, 49345, 49409, 49473, 49537, 49601, 49665, 49729, 49793, 49857, 49921]\n",
      "[0.5964508642765685, 0.685759443021767, 0.7221510883482715, 0.7329745518565941, 0.7377560819462228, 0.7417373559539052, 0.7426176376440461, 0.7411371638924455, 0.7472391165172856, 0.7490196862996159, 0.7513404289372599, 0.751280409731114, 0.7525808258642765, 0.7539412612035852, 0.7538012163892446, 0.7568221830985915, 0.7538012163892446, 0.7589828745198464, 0.7596830985915493, 0.7593629961587708, 0.7561219590268886, 0.7599631882202305, 0.7578625160051217, 0.7599631882202305, 0.7632842509603073, 0.765685019206146, 0.7645646606914213, 0.7671854993597952, 0.7670454545454546, 0.7695062419974392]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "save_model = True\n",
    "save_name = model50_SD\n",
    "restore_model=False\n",
    "restore_name=model50_SD\n",
    "\n",
    "optimize(num_epochs=30, save_model=True,save_name=model50_SD,restore_model=False,restore_name=model50_SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_sr_plot = [0.5, 0.75, 0.78125, 0.8125, 0.8125, 0.8125, 0.8125, 0.828125, 0.875, 0.90625, 0.78125, 0.90625, 0.78125, 0.921875, 0.828125, 0.921875]\n",
    "accuracy_sd_plot = [0.421875, 0.484375, 0.484375, 0.453125, 0.578125, 0.515625, 0.5625, 0.5625, 0.5, 0.5625, 0.671875, 0.59375, 0.421875, 0.5625, 0.484375, 0.515625]\n",
    "accuracy_sd_patchonly_plot = [0.578125, 0.890625, 0.8125, 0.890625, 0.890625, 0.8125, 0.796875, 0.9375, 0.90625, 0.890625, 0.90625, 0.84375, 0.859375, 0.828125, 0.9375, 0.890625]\n",
    "accuracy_sd_conv_plot = [0.609375, 0.671875, 0.828125, 0.84375, 0.78125, 0.8125, 0.859375, 0.828125, 0.84375, 0.890625, 0.953125, 0.90625, 0.921875, 0.84375, 0.921875, 0.859375]\n",
    "training_size_sd_plot = [64, 64064, 128064, 192064, 256064, 320064, 384064, 448064, 512064, 576064, 640064, 704064, 768064, 832064, 896064, 960064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAFNCAYAAABi9TTFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTaWUUspDmjSVUkopD2nSVEoppTz0/w0tr/NEU9XnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ac9936fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "global name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7aea0860f50d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fig_no, training_size, accuracy, loss, start_size, end_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgenerate_size_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_size_sd_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_sd_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_sr_plot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_sd_patchonly_plot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_sd_conv_plot\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m960064\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-83111aa31fa9>\u001b[0m in \u001b[0;36mgenerate_size_graph\u001b[0;34m(fig_no, training_size, accuracy, loss, patch_only, patch_conv, start_size, end_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/batch_graphs/'\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "# fig_no, training_size, accuracy, loss, start_size, end_size\n",
    "\n",
    "generate_size_graph(1, training_size_sd_plot, accuracy_sd_plot, accuracy_sr_plot,accuracy_sd_patchonly_plot,accuracy_sd_conv_plot,  64, 960064)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred, correct):\n",
    "    # This function is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # correct is a boolean array whether the predicted class\n",
    "    # is equal to the true class for each image in the test-set.\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = data.test.images[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = data.test.cls[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])\n",
    "    \n",
    "def plot_confusion_matrix(cls_pred):\n",
    "    # This is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = data.test.cls\n",
    "    \n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.matshow(cm)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the test-set into smaller batches of this size.\n",
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    # Number of images in the test-set.\n",
    "    num_test = len(data.test.images)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        # Get the images from the test-set between index i and j.\n",
    "        images = data.test.images[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = data.test.labels[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the test-set.\n",
    "    cls_true = data.test.cls\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the test-set.\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "\n",
    "    # Plot some examples of mis-classifications, if desired.\n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "    # Plot the confusion matrix, if desired.\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_batch, y_true_batch = data.test.next_batch(64)\n",
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(data.train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[0.84375, 0.8125, 0.78125, 0.859375, 0.796875, 0.84375, 0.796875, 0.71875, 0.6875, 0.8125, 0.890625, 0.8125, 0.84375, 0.796875, 0.75, 0.890625, 0.78125, 0.859375, 0.78125, 0.78125, 0.765625, 0.828125, 0.75, 0.796875, 0.796875, 0.734375, 0.84375, 0.828125, 0.84375, 0.6875, 0.796875, 0.84375, 0.796875, 0.84375, 0.828125, 0.859375, 0.828125, 0.84375, 0.78125, 0.90625, 0.84375, 0.875, 0.65625, 0.828125, 0.828125, 0.734375, 0.84375, 0.796875, 0.875, 0.828125, 0.71875, 0.875, 0.75, 0.875, 0.828125, 0.765625, 0.84375, 0.875, 0.734375, 0.75, 0.84375, 0.84375, 0.8125, 0.796875, 0.8125, 0.828125, 0.8125, 0.8125, 0.8125, 0.859375, 0.890625, 0.859375, 0.859375, 0.75, 0.75, 0.8125, 0.78125, 0.828125, 0.84375, 0.78125, 0.78125, 0.84375, 0.8125, 0.859375, 0.796875, 0.859375, 0.875, 0.828125, 0.75, 0.84375, 0.796875, 0.90625, 0.75, 0.859375, 0.828125, 0.828125, 0.859375, 0.90625, 0.859375, 0.734375, 0.859375, 0.90625, 0.84375, 0.859375, 0.71875, 0.765625, 0.796875, 0.890625, 0.75, 0.828125, 0.828125, 0.875, 0.796875, 0.765625, 0.890625, 0.8125, 0.828125, 0.78125, 0.890625, 0.734375, 0.796875, 0.90625, 0.84375, 0.75, 0.859375, 0.8125, 0.828125, 0.890625, 0.796875, 0.859375, 0.765625, 0.84375, 0.796875, 0.78125, 0.8125, 0.734375, 0.875, 0.8125, 0.78125, 0.8125, 0.71875, 0.78125, 0.859375, 0.78125, 0.890625, 0.90625, 0.8125, 0.78125, 0.828125, 0.8125, 0.78125, 0.78125, 0.796875, 0.734375, 0.859375, 0.765625, 0.8125, 0.828125, 0.828125, 0.84375, 0.84375, 0.859375, 0.78125, 0.765625, 0.8125, 0.8125, 0.765625, 0.875, 0.8125, 0.828125, 0.875, 0.875, 0.765625, 0.796875, 0.890625, 0.828125, 0.859375, 0.734375, 0.8125, 0.765625, 0.859375, 0.78125, 0.875, 0.78125, 0.890625, 0.765625, 0.8125, 0.875, 0.84375, 0.890625, 0.796875, 0.8125, 0.828125, 0.765625, 0.8125, 0.890625, 0.859375, 0.78125, 0.828125, 0.8125, 0.96875, 0.875, 0.78125, 0.78125, 0.875, 0.703125, 0.796875, 0.875, 0.78125, 0.828125, 0.84375, 0.796875, 0.84375, 0.796875, 0.84375, 0.921875, 0.828125, 0.828125, 0.859375, 0.796875, 0.78125, 0.78125, 0.8125, 0.78125, 0.828125, 0.890625, 0.875, 0.75, 0.796875, 0.90625, 0.859375, 0.859375, 0.875, 0.8125, 0.78125, 0.90625, 0.75, 0.828125, 0.875, 0.765625, 0.828125, 0.859375, 0.859375, 0.828125, 0.78125, 0.8125, 0.8125, 0.859375, 0.84375, 0.875, 0.84375, 0.859375, 0.875, 0.828125, 0.84375, 0.796875, 0.875, 0.84375, 0.796875, 0.78125, 0.859375, 0.859375, 0.8125, 0.859375, 0.796875, 0.703125, 0.828125, 0.875, 0.859375, 0.796875, 0.828125, 0.875, 0.84375, 0.890625, 0.859375, 0.796875, 0.8125, 0.875, 0.796875, 0.859375, 0.875, 0.828125, 0.703125, 0.78125, 0.703125, 0.84375, 0.796875, 0.875, 0.890625, 0.890625, 0.8125, 0.84375, 0.78125, 0.84375, 0.84375, 0.875, 0.8125, 0.859375, 0.796875, 0.828125, 0.84375, 0.859375, 0.859375, 0.8125, 0.828125, 0.796875, 0.8125, 0.8125, 0.84375, 0.84375, 0.8125, 0.828125, 0.828125, 0.8125, 0.890625, 0.78125, 0.796875, 0.796875, 0.828125, 0.84375, 0.90625, 0.859375, 0.84375, 0.875, 0.75, 0.84375, 0.890625, 0.765625, 0.875, 0.84375, 0.84375, 0.84375, 0.859375, 0.921875, 0.75, 0.859375, 0.828125, 0.75, 0.875, 0.765625, 0.859375, 0.875, 0.78125, 0.90625, 0.75, 0.71875, 0.75, 0.859375, 0.78125, 0.78125, 0.84375, 0.875, 0.859375, 0.765625, 0.84375, 0.78125, 0.890625, 0.78125, 0.703125, 0.796875, 0.78125, 0.78125, 0.875, 0.875, 0.859375, 0.8125, 0.859375, 0.8125, 0.859375, 0.765625, 0.765625, 0.78125, 0.8125, 0.84375, 0.859375, 0.8125, 0.859375, 0.78125, 0.78125, 0.75, 0.84375, 0.765625, 0.859375, 0.78125, 0.78125, 0.8125, 0.703125, 0.828125, 0.75, 0.90625, 0.8125, 0.828125, 0.84375, 0.859375, 0.75, 0.796875, 0.890625, 0.890625, 0.78125, 0.8125, 0.71875, 0.796875, 0.859375, 0.84375, 0.859375, 0.8125, 0.828125, 0.84375, 0.8125, 0.84375, 0.828125, 0.78125, 0.8125, 0.828125, 0.8125, 0.828125, 0.765625, 0.765625, 0.765625, 0.703125, 0.828125, 0.734375, 0.875, 0.875, 0.84375, 0.8125, 0.84375, 0.734375, 0.84375, 0.890625, 0.859375, 0.8125, 0.84375, 0.859375, 0.828125, 0.765625, 0.890625, 0.84375, 0.796875, 0.890625, 0.8125, 0.734375, 0.703125, 0.921875, 0.859375, 0.90625, 0.78125, 0.84375, 0.71875, 0.828125, 0.828125, 0.84375, 0.875, 0.828125, 0.8125, 0.78125, 0.828125, 0.890625, 0.921875, 0.828125, 0.828125, 0.84375, 0.84375, 0.828125, 0.828125, 0.84375, 0.859375, 0.859375, 0.84375, 0.765625, 0.78125, 0.8125, 0.828125, 0.796875, 0.84375, 0.84375, 0.75, 0.765625, 0.890625, 0.765625, 0.859375, 0.875, 0.875, 0.734375, 0.859375, 0.796875, 0.859375, 0.859375, 0.828125, 0.84375, 0.8125, 0.71875, 0.890625, 0.828125, 0.765625, 0.84375, 0.78125, 0.90625, 0.71875, 0.828125, 0.84375, 0.796875, 0.828125, 0.875, 0.875, 0.875, 0.828125, 0.78125, 0.859375, 0.84375, 0.796875, 0.75, 0.890625, 0.8125, 0.875, 0.8125, 0.8125]\n",
    "[65, 129, 193, 257, 321, 385, 449, 513, 577, 641, 705, 769, 833, 897, 961, 1025, 1089, 1153, 1217, 1281, 1345, 1409, 1473, 1537, 1601, 1665, 1729, 1793, 1857, 1921, 1985, 2049, 2113, 2177, 2241, 2305, 2369, 2433, 2497, 2561, 2625, 2689, 2753, 2817, 2881, 2945, 3009, 3073, 3137, 3201, 3265, 3329, 3393, 3457, 3521, 3585, 3649, 3713, 3777, 3841, 3905, 3969, 4033, 4097, 4161, 4225, 4289, 4353, 4417, 4481, 4545, 4609, 4673, 4737, 4801, 4865, 4929, 4993, 5057, 5121, 5185, 5249, 5313, 5377, 5441, 5505, 5569, 5633, 5697, 5761, 5825, 5889, 5953, 6017, 6081, 6145, 6209, 6273, 6337, 6401, 6465, 6529, 6593, 6657, 6721, 6785, 6849, 6913, 6977, 7041, 7105, 7169, 7233, 7297, 7361, 7425, 7489, 7553, 7617, 7681, 7745, 7809, 7873, 7937, 8001, 8065, 8129, 8193, 8257, 8321, 8385, 8449, 8513, 8577, 8641, 8705, 8769, 8833, 8897, 8961, 9025, 9089, 9153, 9217, 9281, 9345, 9409, 9473, 9537, 9601, 9665, 9729, 9793, 9857, 9921, 9985, 10049, 10113, 10177, 10241, 10305, 10369, 10433, 10497, 10561, 10625, 10689, 10753, 10817, 10881, 10945, 11009, 11073, 11137, 11201, 11265, 11329, 11393, 11457, 11521, 11585, 11649, 11713, 11777, 11841, 11905, 11969, 12033, 12097, 12161, 12225, 12289, 12353, 12417, 12481, 12545, 12609, 12673, 12737, 12801, 12865, 12929, 12993, 13057, 13121, 13185, 13249, 13313, 13377, 13441, 13505, 13569, 13633, 13697, 13761, 13825, 13889, 13953, 14017, 14081, 14145, 14209, 14273, 14337, 14401, 14465, 14529, 14593, 14657, 14721, 14785, 14849, 14913, 14977, 15041, 15105, 15169, 15233, 15297, 15361, 15425, 15489, 15553, 15617, 15681, 15745, 15809, 15873, 15937, 16001, 16065, 16129, 16193, 16257, 16321, 16385, 16449, 16513, 16577, 16641, 16705, 16769, 16833, 16897, 16961, 17025, 17089, 17153, 17217, 17281, 17345, 17409, 17473, 17537, 17601, 17665, 17729, 17793, 17857, 17921, 17985, 18049, 18113, 18177, 18241, 18305, 18369, 18433, 18497, 18561, 18625, 18689, 18753, 18817, 18881, 18945, 19009, 19073, 19137, 19201, 19265, 19329, 19393, 19457, 19521, 19585, 19649, 19713, 19777, 19841, 19905, 19969, 20033, 20097, 20161, 20225, 20289, 20353, 20417, 20481, 20545, 20609, 20673, 20737, 20801, 20865, 20929, 20993, 21057, 21121, 21185, 21249, 21313, 21377, 21441, 21505, 21569, 21633, 21697, 21761, 21825, 21889, 21953, 22017, 22081, 22145, 22209, 22273, 22337, 22401, 22465, 22529, 22593, 22657, 22721, 22785, 22849, 22913, 22977, 23041, 23105, 23169, 23233, 23297, 23361, 23425, 23489, 23553, 23617, 23681, 23745, 23809, 23873, 23937, 24001, 24065, 24129, 24193, 24257, 24321, 24385, 24449, 24513, 24577, 24641, 24705, 24769, 24833, 24897, 24961, 25025, 25089, 25153, 25217, 25281, 25345, 25409, 25473, 25537, 25601, 25665, 25729, 25793, 25857, 25921, 25985, 26049, 26113, 26177, 26241, 26305, 26369, 26433, 26497, 26561, 26625, 26689, 26753, 26817, 26881, 26945, 27009, 27073, 27137, 27201, 27265, 27329, 27393, 27457, 27521, 27585, 27649, 27713, 27777, 27841, 27905, 27969, 28033, 28097, 28161, 28225, 28289, 28353, 28417, 28481, 28545, 28609, 28673, 28737, 28801, 28865, 28929, 28993, 29057, 29121, 29185, 29249, 29313, 29377, 29441, 29505, 29569, 29633, 29697, 29761, 29825, 29889, 29953, 30017, 30081, 30145, 30209, 30273, 30337, 30401, 30465, 30529, 30593, 30657, 30721, 30785, 30849, 30913, 30977, 31041, 31105, 31169, 31233, 31297, 31361, 31425, 31489, 31553, 31617, 31681, 31745, 31809, 31873, 31937, 32001, 32065, 32129, 32193, 32257, 32321, 32385, 32449, 32513, 32577, 32641, 32705, 32769, 32833, 32897, 32961, 33025, 33089]\n",
    "[0.875, 0.953125, 0.796875, 0.890625, 0.875, 0.921875, 0.9375, 0.84375, 0.90625, 0.90625, 0.8125, 0.921875, 0.84375, 0.8125, 0.890625, 0.796875, 0.890625, 0.9375, 0.90625, 0.9375, 0.890625, 0.90625, 0.828125, 0.84375, 0.90625, 0.859375, 0.890625, 0.859375, 0.8125, 0.828125, 0.875, 0.796875, 0.796875, 0.796875, 0.90625, 0.890625, 0.921875, 0.875, 0.859375, 0.890625, 0.90625, 0.953125, 0.765625, 0.90625, 0.90625, 0.84375, 0.859375, 0.84375, 0.890625, 0.890625, 0.875, 0.859375, 0.953125, 0.90625, 0.84375, 0.796875, 0.84375, 0.9375, 0.90625, 0.84375, 0.78125, 0.90625, 0.8125, 0.8125, 0.859375, 0.875, 0.953125, 0.875, 0.859375, 0.875, 0.9375, 0.90625, 0.921875, 0.890625, 0.859375, 0.890625, 0.890625, 0.859375, 0.9375, 0.859375, 0.859375, 0.828125, 0.828125, 0.875, 0.796875, 0.890625, 0.8125, 0.828125, 0.828125, 0.921875, 0.78125, 0.828125, 0.90625, 0.875, 0.796875, 0.921875, 0.8125, 0.828125, 0.8125, 0.90625, 0.90625, 0.921875, 0.796875, 0.78125, 0.875, 0.859375, 0.90625, 0.828125, 0.84375, 0.828125, 0.828125, 0.828125, 0.890625, 0.84375, 0.953125, 0.828125, 0.890625, 0.859375, 0.9375, 0.921875, 0.859375, 0.859375, 0.921875, 0.890625, 0.90625, 0.828125, 0.90625, 0.859375, 0.921875, 0.90625, 0.90625, 0.921875, 0.828125, 0.859375, 0.890625, 0.859375, 0.890625, 0.9375, 0.765625, 0.859375, 0.8125, 0.859375, 0.84375, 0.90625, 0.90625, 0.828125, 0.859375, 0.90625, 0.84375, 0.875, 0.9375, 0.9375, 0.90625, 0.890625, 0.9375, 0.84375, 0.828125, 0.859375, 0.84375, 0.84375, 0.84375, 0.859375, 0.84375, 0.828125, 0.875, 0.921875, 0.875, 0.921875, 0.8125, 0.875, 0.875, 0.875, 0.84375, 0.875, 0.84375, 0.9375, 0.765625, 0.875, 0.890625, 0.828125, 0.875, 0.84375, 0.84375, 0.984375, 0.859375, 0.859375, 0.890625, 0.875, 0.828125, 0.9375, 0.875, 0.84375, 0.875, 0.875, 0.921875, 0.875, 0.921875, 0.875, 0.890625, 0.828125, 0.90625, 0.828125, 0.890625, 0.875, 0.796875, 0.765625, 0.9375, 0.859375, 0.921875, 0.875, 0.875, 0.875, 0.890625, 0.890625, 0.796875, 0.875, 0.875, 0.796875, 0.859375, 0.859375, 0.8125, 0.9375, 0.859375, 0.890625, 0.90625, 0.859375, 0.890625, 0.921875, 0.8125, 0.921875, 0.875, 0.859375, 0.875, 0.875, 0.828125, 0.828125, 0.875, 0.90625, 0.90625, 0.859375, 0.875, 0.953125, 0.875, 0.828125, 0.9375, 0.828125, 0.8125, 0.90625, 0.921875, 0.828125, 0.875, 0.890625, 0.921875, 0.890625, 0.796875, 0.84375, 0.875, 0.828125, 0.8125, 0.890625, 0.828125, 0.90625, 0.8125, 0.84375, 0.859375, 0.90625, 0.859375, 0.890625, 0.90625, 0.859375, 0.828125, 0.890625, 0.921875, 0.859375, 0.78125, 0.890625, 0.859375, 0.84375, 0.859375, 0.890625, 0.84375, 0.828125, 0.890625, 0.921875, 0.921875, 0.828125, 0.921875, 0.84375, 0.84375, 0.875, 0.90625, 0.875, 0.875, 0.84375, 0.90625, 0.921875, 0.921875, 0.90625, 0.84375, 0.890625, 0.8125, 0.734375, 0.9375, 0.84375, 0.875, 0.8125, 0.90625, 0.90625, 0.828125, 0.90625, 0.921875, 0.890625, 0.875, 0.875, 0.859375, 0.875, 0.765625, 0.828125, 0.890625, 0.875, 0.890625, 0.875, 0.890625, 0.875, 0.8125, 0.875, 0.84375, 0.875, 0.921875, 0.84375, 0.875, 0.84375, 0.84375, 0.90625, 0.90625, 0.921875, 0.859375, 0.859375, 0.828125, 0.953125, 0.84375, 0.875, 0.953125, 0.875, 0.84375, 0.84375, 0.875, 0.84375, 0.84375, 0.859375, 0.90625, 0.875, 0.921875, 0.90625, 0.765625, 0.84375, 0.859375, 0.859375, 0.84375, 0.890625, 0.828125, 0.8125, 0.84375, 0.90625, 0.890625, 0.8125, 0.890625, 0.828125, 0.90625, 0.875, 0.828125, 0.8125, 0.765625, 0.890625, 0.859375, 0.859375, 0.984375, 0.84375, 0.859375, 0.875, 0.921875, 0.890625, 0.96875, 0.828125, 0.84375, 0.84375, 0.90625, 0.890625, 0.875, 0.90625, 0.875, 0.9375, 0.859375, 0.84375, 0.8125, 0.828125, 0.890625, 0.84375, 0.875, 0.890625, 0.828125, 0.859375, 0.859375, 0.875, 0.890625, 0.859375, 0.875, 0.890625, 0.890625, 0.9375, 0.921875, 0.90625, 0.921875, 0.859375, 0.828125, 0.828125, 0.828125, 0.828125, 0.765625, 0.8125, 0.796875, 0.84375, 0.8125, 0.84375, 0.875, 0.828125, 0.8125, 0.84375, 0.90625, 0.875, 0.859375, 0.84375, 0.875, 0.890625, 0.921875, 0.796875, 0.859375, 0.859375, 0.90625, 0.859375, 0.828125, 0.84375, 0.828125, 0.90625, 0.84375, 0.875, 0.953125, 0.828125, 0.875, 0.921875, 0.890625, 0.8125, 0.90625, 0.8125, 0.875, 0.8125, 0.84375, 0.90625, 0.90625, 0.859375, 0.84375, 0.875, 0.859375, 0.828125, 0.875, 0.8125, 0.890625, 0.875, 0.8125, 0.875, 0.859375, 0.875, 0.875, 0.828125, 0.921875, 0.828125, 0.828125, 0.953125, 0.828125, 0.859375, 0.875, 0.890625, 0.90625, 0.796875, 0.859375, 0.890625, 0.859375, 0.859375, 0.84375, 0.90625, 0.8125, 0.875, 0.875, 0.859375, 0.828125, 0.890625, 0.890625, 0.875, 0.84375, 0.84375, 0.921875, 0.828125, 0.859375, 0.890625, 0.875, 0.890625, 0.859375, 0.859375, 0.84375, 0.84375, 0.875, 0.890625, 0.875, 0.859375, 0.84375, 0.875, 0.8125]\n",
    "[65, 129, 193, 257, 321, 385, 449, 513, 577, 641, 705, 769, 833, 897, 961, 1025, 1089, 1153, 1217, 1281, 1345, 1409, 1473, 1537, 1601, 1665, 1729, 1793, 1857, 1921, 1985, 2049, 2113, 2177, 2241, 2305, 2369, 2433, 2497, 2561, 2625, 2689, 2753, 2817, 2881, 2945, 3009, 3073, 3137, 3201, 3265, 3329, 3393, 3457, 3521, 3585, 3649, 3713, 3777, 3841, 3905, 3969, 4033, 4097, 4161, 4225, 4289, 4353, 4417, 4481, 4545, 4609, 4673, 4737, 4801, 4865, 4929, 4993, 5057, 5121, 5185, 5249, 5313, 5377, 5441, 5505, 5569, 5633, 5697, 5761, 5825, 5889, 5953, 6017, 6081, 6145, 6209, 6273, 6337, 6401, 6465, 6529, 6593, 6657, 6721, 6785, 6849, 6913, 6977, 7041, 7105, 7169, 7233, 7297, 7361, 7425, 7489, 7553, 7617, 7681, 7745, 7809, 7873, 7937, 8001, 8065, 8129, 8193, 8257, 8321, 8385, 8449, 8513, 8577, 8641, 8705, 8769, 8833, 8897, 8961, 9025, 9089, 9153, 9217, 9281, 9345, 9409, 9473, 9537, 9601, 9665, 9729, 9793, 9857, 9921, 9985, 10049, 10113, 10177, 10241, 10305, 10369, 10433, 10497, 10561, 10625, 10689, 10753, 10817, 10881, 10945, 11009, 11073, 11137, 11201, 11265, 11329, 11393, 11457, 11521, 11585, 11649, 11713, 11777, 11841, 11905, 11969, 12033, 12097, 12161, 12225, 12289, 12353, 12417, 12481, 12545, 12609, 12673, 12737, 12801, 12865, 12929, 12993, 13057, 13121, 13185, 13249, 13313, 13377, 13441, 13505, 13569, 13633, 13697, 13761, 13825, 13889, 13953, 14017, 14081, 14145, 14209, 14273, 14337, 14401, 14465, 14529, 14593, 14657, 14721, 14785, 14849, 14913, 14977, 15041, 15105, 15169, 15233, 15297, 15361, 15425, 15489, 15553, 15617, 15681, 15745, 15809, 15873, 15937, 16001, 16065, 16129, 16193, 16257, 16321, 16385, 16449, 16513, 16577, 16641, 16705, 16769, 16833, 16897, 16961, 17025, 17089, 17153, 17217, 17281, 17345, 17409, 17473, 17537, 17601, 17665, 17729, 17793, 17857, 17921, 17985, 18049, 18113, 18177, 18241, 18305, 18369, 18433, 18497, 18561, 18625, 18689, 18753, 18817, 18881, 18945, 19009, 19073, 19137, 19201, 19265, 19329, 19393, 19457, 19521, 19585, 19649, 19713, 19777, 19841, 19905, 19969, 20033, 20097, 20161, 20225, 20289, 20353, 20417, 20481, 20545, 20609, 20673, 20737, 20801, 20865, 20929, 20993, 21057, 21121, 21185, 21249, 21313, 21377, 21441, 21505, 21569, 21633, 21697, 21761, 21825, 21889, 21953, 22017, 22081, 22145, 22209, 22273, 22337, 22401, 22465, 22529, 22593, 22657, 22721, 22785, 22849, 22913, 22977, 23041, 23105, 23169, 23233, 23297, 23361, 23425, 23489, 23553, 23617, 23681, 23745, 23809, 23873, 23937, 24001, 24065, 24129, 24193, 24257, 24321, 24385, 24449, 24513, 24577, 24641, 24705, 24769, 24833, 24897, 24961, 25025, 25089, 25153, 25217, 25281, 25345, 25409, 25473, 25537, 25601, 25665, 25729, 25793, 25857, 25921, 25985, 26049, 26113, 26177, 26241, 26305, 26369, 26433, 26497, 26561, 26625, 26689, 26753, 26817, 26881, 26945, 27009, 27073, 27137, 27201, 27265, 27329, 27393, 27457, 27521, 27585, 27649, 27713, 27777, 27841, 27905, 27969, 28033, 28097, 28161, 28225, 28289, 28353, 28417, 28481, 28545, 28609, 28673, 28737, 28801, 28865, 28929, 28993, 29057, 29121, 29185, 29249, 29313, 29377, 29441, 29505, 29569, 29633, 29697, 29761, 29825, 29889, 29953, 30017, 30081, 30145, 30209, 30273, 30337, 30401, 30465, 30529, 30593, 30657, 30721, 30785, 30849, 30913, 30977, 31041, 31105, 31169, 31233, 31297, 31361, 31425, 31489, 31553, 31617, 31681, 31745, 31809, 31873, 31937, 32001, 32065, 32129, 32193, 32257, 32321, 32385, 32449, 32513, 32577, 32641, 32705, 32769, 32833, 32897, 32961, 33025, 33089]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.682583252895753, 0.7848998552123552, 0.8154862451737451, 0.823871862934363, 0.8351532335907336, 0.838531611969112, 0.8439611486486487, 0.8454391891891891, 0.8443532818532818, 0.8474601833976834, 0.8517434845559846, 0.8527992277992278, 0.8534930019305019, 0.8545789092664092, 0.8536438223938224, 0.8558458011583011, 0.8557251447876448, 0.8581081081081081, 0.8593448359073359, 0.8613055019305019, 0.8607625482625483, 0.8619087837837838, 0.8626930501930502, 0.86652388996139, 0.8641710907335908, 0.8649855212355212, 0.8659809362934363, 0.868846525096525, 0.8675494691119691, 0.8706865347490348]\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
    "[0.682583252895753, 0.7848998552123552, 0.8154862451737451, 0.823871862934363, 0.8351532335907336, 0.838531611969112, 0.8439611486486487, 0.8454391891891891, 0.8443532818532818, 0.8474601833976834, 0.8517434845559846, 0.8527992277992278, 0.8534930019305019, 0.8545789092664092, 0.8536438223938224, 0.8558458011583011, 0.8557251447876448, 0.8581081081081081, 0.8593448359073359, 0.8613055019305019, 0.8607625482625483, 0.8619087837837838, 0.8626930501930502, 0.86652388996139, 0.8641710907335908, 0.8649855212355212, 0.8659809362934363, 0.868846525096525, 0.8675494691119691, 0.8706865347490348]\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sd = [0.5181587837837838, 0.5230755308880309, 0.5339346042471043, 0.5334218146718147, 0.5387910231660231, 0.5470258204633205, 0.5545668436293436, 0.567386583011583, 0.5835847007722008, 0.6008083976833977, 0.619449806949807, 0.6399915540540541, 0.6607142857142857, 0.6763694498069498, 0.6886763996138996, 0.699867277992278, 0.7165178571428571, 0.7225808397683398, 0.7372104247104247, 0.7440878378378378, 0.753921332046332, 0.7609797297297297, 0.7618544884169884, 0.7700289575289575, 0.7795004826254827, 0.783210666023166, 0.7914152992277992, 0.7912946428571429, 0.800132722007722, 0.8066180019305019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
    "accuracy_patch = [0.682583252895753, 0.7848998552123552, 0.8154862451737451, 0.823871862934363, 0.8351532335907336, 0.838531611969112, 0.8439611486486487, 0.8454391891891891, 0.8443532818532818, 0.8474601833976834, 0.8517434845559846, 0.8527992277992278, 0.8534930019305019, 0.8545789092664092, 0.8536438223938224, 0.8558458011583011, 0.8557251447876448, 0.8581081081081081, 0.8593448359073359, 0.8613055019305019, 0.8607625482625483, 0.8619087837837838, 0.8626930501930502, 0.86652388996139, 0.8641710907335908, 0.8649855212355212, 0.8659809362934363, 0.868846525096525, 0.8675494691119691, 0.8706865347490348]\n",
    "accuracy_patch_honest = [0.5964508642765685, 0.685759443021767, 0.7221510883482715, 0.7329745518565941, 0.7377560819462228, 0.7417373559539052, 0.7426176376440461, 0.7411371638924455, 0.7472391165172856, 0.7490196862996159, 0.7513404289372599, 0.751280409731114, 0.7525808258642765, 0.7539412612035852, 0.7538012163892446, 0.7568221830985915, 0.7538012163892446, 0.7589828745198464, 0.7596830985915493, 0.7593629961587708, 0.7561219590268886, 0.7599631882202305, 0.7578625160051217, 0.7599631882202305, 0.7632842509603073, 0.765685019206146, 0.7645646606914213, 0.7671854993597952, 0.7670454545454546, 0.7695062419974392]\n",
    "accuracy_sd = [0.5181587837837838, 0.5230755308880309, 0.5339346042471043, 0.5334218146718147, 0.5387910231660231, 0.5470258204633205, 0.5545668436293436, 0.567386583011583, 0.5835847007722008, 0.6008083976833977, 0.619449806949807, 0.6399915540540541, 0.6607142857142857, 0.6763694498069498, 0.6886763996138996, 0.699867277992278, 0.7165178571428571, 0.7225808397683398, 0.7372104247104247, 0.7440878378378378, 0.753921332046332, 0.7609797297297297, 0.7618544884169884, 0.7700289575289575, 0.7795004826254827, 0.783210666023166, 0.7914152992277992, 0.7912946428571429, 0.800132722007722, 0.8066180019305019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 560x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_graph(1, training_size_sd_plot, accuracy_patch, accuracy_sd, \"Accuracy\", \"Patch\", \"SD Image\", 33000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plt.figure(1,figsize=(7,5))\n",
    "    plt.plot(epochs,accuracy_patch)\n",
    "    plt.plot(epochs,accuracy_patch_honest)\n",
    "    plt.plot(epochs,accuracy_sd)    \n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"SD Image/Perfect Patch/Valid Patch\" + '( Samples:' + str(50000) + ')')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['Perfect Patch','Valid Patch', 'SD'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
