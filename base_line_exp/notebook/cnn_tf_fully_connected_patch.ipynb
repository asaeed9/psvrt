{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../original_images/psvrt.py:3: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-fce1b3103be7>\", line 1, in <module>\n",
      "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2131, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-107>\", line 2, in matplotlib\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/Users/as186233/anaconda2/envs/py36/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2, os, math, time, sys\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle\n",
    "sys.path.append('../../original_images')\n",
    "from gen_data_batch import generate_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configuration\n",
    "\"\"\"\n",
    "Data Configurations/Paths\n",
    "\"\"\"\n",
    "img_dir_patch=\"./SD/predicted_patches\"\n",
    "img_dir_orig = \"../../original_images/SD\"\n",
    "\n",
    "model20m = 'SD/model20m.ckpt'\n",
    "# img_type = \"original\"\n",
    "img_type = \"patch\"\n",
    "\n",
    "##\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 4          # Convolution filters are 4 x 4 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters2 = 32         # There are 32 of these filters.\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters3 = 64         # There are 64 of these filters.\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size4 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters4 = 128         # There are 128 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 256             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label_dimensions(labels):\n",
    "    label_temp = np.zeros((len(labels), 2))\n",
    "    \n",
    "    for idx in range(0, len(labels)):\n",
    "        if labels[idx] == 1:\n",
    "            label_temp[idx][1] = 1\n",
    "        else:\n",
    "            label_temp[idx][0] = 1\n",
    "    \n",
    "    return label_temp\n",
    "\n",
    "def load_data(img_dir, img_type=\"patch\"):\n",
    "        list_of_imgs = []\n",
    "        list_same_diff = []\n",
    "        for img_no in os.listdir(img_dir):\n",
    "            img_no_path = os.path.join(img_dir, img_no)\n",
    "            for img_label in os.listdir(img_no_path):\n",
    "                    \n",
    "                list_same_diff.append(int(img_label))\n",
    "                img_lbl_path = os.path.join(img_no_path, img_label)\n",
    "#                 print(img_lbl_path)\n",
    "                if img_type == \"original\":\n",
    "                    img_lbl_path = img_lbl_path + \"/img/\"\n",
    "                    \n",
    "                if img_type == \"patch\":\n",
    "                    for img in os.listdir(img_lbl_path):\n",
    "#                         if img == \"labels\":\n",
    "                        img_path = os.path.join(img_lbl_path, img)\n",
    "#                             img_path = img_path + \"/merged_patch.png\"\n",
    "                        list_of_imgs.append(img_path)\n",
    "                else:    \n",
    "                    for img in os.listdir(img_lbl_path):\n",
    "                        img_path = os.path.join(img_lbl_path, img)\n",
    "                        list_of_imgs.append(img_path)\n",
    "#         print(list_of_imgs)\n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_same_diff = np.array(list_same_diff)\n",
    "\n",
    "        return data_imgs, data_same_diff\n",
    "\n",
    "# def load_data(img_dir):\n",
    "#         list_of_imgs = []\n",
    "#         list_same_diff = []\n",
    "#         for img_no in os.listdir(img_dir):\n",
    "#             if img_no == \".DS_Store\":\n",
    "#                 continue\n",
    "\n",
    "#             img_no_path = os.path.join(img_dir, img_no)\n",
    "#             for img_label in os.listdir(img_no_path):\n",
    "#                 if img_label == \".DS_Store\":\n",
    "#                     continue\n",
    "                    \n",
    "#                 list_same_diff.append(int(img_label))\n",
    "#                 img_lbl_path = os.path.join(img_no_path, img_label)\n",
    "#                 for img in os.listdir(img_lbl_path):\n",
    "#                     img_path = os.path.join(img_lbl_path, img)\n",
    "#                     list_of_imgs.append(img_path)\n",
    "\n",
    "#         data_imgs = np.array(list_of_imgs)\n",
    "#         data_same_diff = np.array(list_same_diff)\n",
    "\n",
    "#         return data_imgs, data_same_diff\n",
    "\n",
    "    \n",
    "def get_batch_images(data, same_diff, type_img = \"patch\"):\n",
    "        list_of_imgs = []\n",
    "        list_of_same_diff = []\n",
    "        for img, img_type in zip(data, same_diff):\n",
    "            orig_img = cv2.imread(img)\n",
    "            #only first image as a label\n",
    "            if orig_img is None:\n",
    "                    print (\"Unable to read image{}\".format(img))\n",
    "                    continue\n",
    "            \n",
    "            if type_img == \"original\":\n",
    "                flattened_img = orig_img.flatten()\n",
    "                list_of_imgs.append(np.asarray(flattened_img, dtype=np.float32))\n",
    "                \n",
    "                if img_type == 1: #0 is same and 1 is different\n",
    "                    list_of_same_diff.append([0,1])\n",
    "                else:\n",
    "                    list_of_same_diff.append([1,0])\n",
    "            else:            \n",
    "                if orig_img.shape == (4, 2, 3):\n",
    "                    flattened_img = orig_img.flatten()\n",
    "                    list_of_imgs.append(np.asarray(flattened_img, dtype=np.float32))\n",
    "\n",
    "                    if img_type == 1: #0 is same and 1 is different\n",
    "                        list_of_same_diff.append([0,1])\n",
    "                    else:\n",
    "                        list_of_same_diff.append([1,0])\n",
    "        \n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_img_type = np.array(list_of_same_diff)\n",
    "        \n",
    "        return data_imgs, data_img_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Batch Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of colour channels for the images: 3 channel for RGB.\n",
    "num_channels = 3\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (60, 60, num_channels)\n",
    "\n",
    "# Number of classes, one class for same and one for different image\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(cv2.imread(images[i]).flatten().reshape((8,4, 3)), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def generate_size_graph(fig_no, training_size, accuracy, loss, patch_only,patch_conv, start_size, end_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(training_size,accuracy)\n",
    "    plt.plot(training_size,loss)\n",
    "    plt.plot(training_size, patch_only)\n",
    "    plt.plot(training_size, patch_conv)\n",
    "    plt.xlabel('Training Size')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Size vs Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['SD Original Accuracy','SR Accuracy', 'SD Patch Accuracy', 'SD Patch Conv'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(path + '/batch_graphs/' +  str(start_size) + '_' + str(end_size) + '.jpg') \n",
    "        \n",
    "def generate_graph(fig_no, epochs, train, val, label, train_title, val_title, train_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(epochs,train)\n",
    "    plt.plot(epochs,val)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel(label)\n",
    "    plt.title(train_title + ' vs ' + val_title + '( Samples:' + str(train_size) + ')')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['Patch','SD'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "#     plt.savefig(results_path + '/batch_graphs/' +  label + '_' + str(train_size) + '.jpg')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Helper Functions for TF Graph Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape))\n",
    "#     return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def new_bias(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,\n",
    "                   num_input_channels,\n",
    "                   filter_size,\n",
    "                   num_filters,\n",
    "                   use_pooling=True):\n",
    "\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    weights = new_weights(shape)\n",
    "    biases = new_bias(length=num_filters)\n",
    "    \n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                     filter=weights,\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                     padding='SAME')\n",
    "    layer += biases\n",
    "\n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 3, 3, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                use_relu=True):\n",
    "\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_bias(length=num_outputs)\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    \n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(60), Dimension(60), Dimension(3)]),\n",
       " <tf.Tensor 'y_true:0' shape=(?, 2) dtype=float32>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_shape[0]*img_shape[1]*num_channels], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_shape[0], img_shape[1], num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)\n",
    "x_image.shape, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
    "                                            num_input_channels=num_channels,\n",
    "                                            filter_size=filter_size1,\n",
    "                                            num_filters=num_filters1,\n",
    "                                            use_pooling=True)\n",
    "\n",
    "layer2_conv2, weights_conv2 =  new_conv_layer(input=layer1_conv1,\n",
    "                                           num_input_channels=num_filters1,\n",
    "                                           filter_size=filter_size2,\n",
    "                                           num_filters=num_filters2,\n",
    "                                           use_pooling=True)\n",
    "\n",
    "layer3_conv3, weights_conv3 =  new_conv_layer(input=layer2_conv2,\n",
    "                                           num_input_channels=num_filters2,\n",
    "                                           filter_size=filter_size3,\n",
    "                                           num_filters=num_filters3,\n",
    "                                           use_pooling=True)\n",
    "\n",
    "layer4_conv4, weights_conv4 =  new_conv_layer(input=layer3_conv3,\n",
    "                                           num_input_channels=num_filters3,\n",
    "                                           filter_size=filter_size4,\n",
    "                                           num_filters=num_filters4,\n",
    "                                           use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer4_conv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "\n",
    "\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=False)\n",
    "\n",
    "layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=False)\n",
    "\n",
    "layer_fc4 = new_fc_layer(input=layer_fc3,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)\n",
    "\n",
    "drop_out = tf.nn.dropout(layer_fc4, 0.5)\n",
    "\n",
    "##Normalize the numbers(apply softmax!)\n",
    "\n",
    "y_pred = tf.nn.softmax(drop_out)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=drop_out,\n",
    "                                                        labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "## some more performance measures\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tensorflow on Defined Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(num_epochs, save_model=True,save_name= \"base_model\",restore_model=False,restore_name=None):\n",
    "    total_iterations = 0\n",
    "    done_train_imgs = 0\n",
    "    start_time = time.time()\n",
    "    start_batch=0\n",
    "    end_batch = train_batch_size\n",
    "    plot_accuracy=[]\n",
    "    plot_accuracy_epoch=[]\n",
    "    plot_training_size=[]\n",
    "    plot_training_size_epoch=[]\n",
    "    saver = tf.train.Saver()\n",
    "    sum_accuracy = 0.0\n",
    "    n = 1\n",
    "    \n",
    "        #to save the model\n",
    "    for i in range(0, num_epochs):   \n",
    "        start_batch=0\n",
    "        end_batch = train_batch_size\n",
    "        \n",
    "        print(\"Epoch:\", i + 1)\n",
    "        \n",
    "        if restore_model==True:\n",
    "            if restore_name==None:\n",
    "                print(\"No model file specified\")\n",
    "                return\n",
    "            else:\n",
    "                saver.restore(session,restore_name)\n",
    "        \n",
    "        sum_accuracy = 0.0\n",
    "        n = 1\n",
    "        while end_batch < total_imgs:\n",
    "#             train = train_data[start_batch:end_batch]\n",
    "#             labels = train_labels[start_batch:end_batch]\n",
    "#             train, labels = get_batch_images(train, labels, img_type)\n",
    "            train, labels = generate_batch(train_batch_size, img_shape)\n",
    "            if not len(train) and not len(labels):\n",
    "                print(\"All images have been processed.\")\n",
    "                break;\n",
    "\n",
    "            x_batch, y_true_batch = next_batch(len(train), train, labels)\n",
    "            feed_dict_train = {x: x_batch,\n",
    "                       y_true: y_true_batch}\n",
    "            \n",
    "            session.run(optimizer, feed_dict=feed_dict_train)\n",
    "    \n",
    "            acc,co = session.run([accuracy, cost], feed_dict=feed_dict_train)\n",
    "            sum_accuracy += acc\n",
    "            n+=1\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "            print(msg.format(end_batch + 1, acc, co))\n",
    "            if end_batch % 100:\n",
    "                plot_accuracy.append(acc)\n",
    "                plot_training_size.append(end_batch + 1)\n",
    "\n",
    "            start_batch += train_batch_size\n",
    "            end_batch += train_batch_size\n",
    "    \n",
    "        if save_model==True:\n",
    "            if save_name==None:\n",
    "                print(\"No model specified, model not being saved\")\n",
    "                return\n",
    "            else:\n",
    "                save_path = saver.save(session, save_name)\n",
    "                restore_model = True\n",
    "                print(\"Model saved in file: %s\" % save_name)\n",
    "        plot_accuracy_epoch.append(sum_accuracy/n)\n",
    "        plot_training_size_epoch.append(i + 1)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))  \n",
    "    print(plot_accuracy)\n",
    "    print(plot_training_size)\n",
    "    print(plot_accuracy_epoch)\n",
    "    print(plot_training_size_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance/Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "generate_batch() missing 2 required positional arguments: 'itm_size' and 'n_itms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0bd88dfdf3fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel20m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrestore_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrestore_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel20m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-ec88bf37df6b>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(num_epochs, save_model, save_name, restore_model, restore_name)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#             labels = train_labels[start_batch:end_batch]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#             train, labels = get_batch_images(train, labels, img_type)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All images have been processed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: generate_batch() missing 2 required positional arguments: 'itm_size' and 'n_itms'"
     ]
    }
   ],
   "source": [
    "total_imgs = 1024\n",
    "train_batch_size = 50\n",
    "\n",
    "save_model = True\n",
    "save_name = model20m\n",
    "restore_model=False\n",
    "restore_name=model20m\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "optimize(num_epochs=1, save_model=True,save_name=model20m,restore_model=False,restore_name=model20m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x:0',\n",
       " 'Reshape/shape:0',\n",
       " 'Reshape:0',\n",
       " 'y_true:0',\n",
       " 'ArgMax/dimension:0',\n",
       " 'ArgMax:0',\n",
       " 'random_uniform/shape:0',\n",
       " 'random_uniform/min:0',\n",
       " 'random_uniform/max:0',\n",
       " 'random_uniform/RandomUniform:0',\n",
       " 'random_uniform/sub:0',\n",
       " 'random_uniform/mul:0',\n",
       " 'random_uniform:0',\n",
       " 'Variable:0',\n",
       " 'Variable/Assign:0',\n",
       " 'Variable/read:0',\n",
       " 'Const:0',\n",
       " 'Variable_1:0',\n",
       " 'Variable_1/Assign:0',\n",
       " 'Variable_1/read:0',\n",
       " 'Conv2D:0',\n",
       " 'add:0',\n",
       " 'MaxPool:0',\n",
       " 'Relu:0',\n",
       " 'random_uniform_1/shape:0',\n",
       " 'random_uniform_1/min:0',\n",
       " 'random_uniform_1/max:0',\n",
       " 'random_uniform_1/RandomUniform:0',\n",
       " 'random_uniform_1/sub:0',\n",
       " 'random_uniform_1/mul:0',\n",
       " 'random_uniform_1:0',\n",
       " 'Variable_2:0',\n",
       " 'Variable_2/Assign:0',\n",
       " 'Variable_2/read:0',\n",
       " 'Const_1:0',\n",
       " 'Variable_3:0',\n",
       " 'Variable_3/Assign:0',\n",
       " 'Variable_3/read:0',\n",
       " 'Conv2D_1:0',\n",
       " 'add_1:0',\n",
       " 'MaxPool_1:0',\n",
       " 'Relu_1:0',\n",
       " 'random_uniform_2/shape:0',\n",
       " 'random_uniform_2/min:0',\n",
       " 'random_uniform_2/max:0',\n",
       " 'random_uniform_2/RandomUniform:0',\n",
       " 'random_uniform_2/sub:0',\n",
       " 'random_uniform_2/mul:0',\n",
       " 'random_uniform_2:0',\n",
       " 'Variable_4:0',\n",
       " 'Variable_4/Assign:0',\n",
       " 'Variable_4/read:0',\n",
       " 'Const_2:0',\n",
       " 'Variable_5:0',\n",
       " 'Variable_5/Assign:0',\n",
       " 'Variable_5/read:0',\n",
       " 'Conv2D_2:0',\n",
       " 'add_2:0',\n",
       " 'MaxPool_2:0',\n",
       " 'Relu_2:0',\n",
       " 'random_uniform_3/shape:0',\n",
       " 'random_uniform_3/min:0',\n",
       " 'random_uniform_3/max:0',\n",
       " 'random_uniform_3/RandomUniform:0',\n",
       " 'random_uniform_3/sub:0',\n",
       " 'random_uniform_3/mul:0',\n",
       " 'random_uniform_3:0',\n",
       " 'Variable_6:0',\n",
       " 'Variable_6/Assign:0',\n",
       " 'Variable_6/read:0',\n",
       " 'Const_3:0',\n",
       " 'Variable_7:0',\n",
       " 'Variable_7/Assign:0',\n",
       " 'Variable_7/read:0',\n",
       " 'Conv2D_3:0',\n",
       " 'add_3:0',\n",
       " 'MaxPool_3:0',\n",
       " 'Relu_3:0',\n",
       " 'Reshape_1/shape:0',\n",
       " 'Reshape_1:0',\n",
       " 'random_uniform_4/shape:0',\n",
       " 'random_uniform_4/min:0',\n",
       " 'random_uniform_4/max:0',\n",
       " 'random_uniform_4/RandomUniform:0',\n",
       " 'random_uniform_4/sub:0',\n",
       " 'random_uniform_4/mul:0',\n",
       " 'random_uniform_4:0',\n",
       " 'Variable_8:0',\n",
       " 'Variable_8/Assign:0',\n",
       " 'Variable_8/read:0',\n",
       " 'Const_4:0',\n",
       " 'Variable_9:0',\n",
       " 'Variable_9/Assign:0',\n",
       " 'Variable_9/read:0',\n",
       " 'MatMul:0',\n",
       " 'add_4:0',\n",
       " 'Relu_4:0',\n",
       " 'random_uniform_5/shape:0',\n",
       " 'random_uniform_5/min:0',\n",
       " 'random_uniform_5/max:0',\n",
       " 'random_uniform_5/RandomUniform:0',\n",
       " 'random_uniform_5/sub:0',\n",
       " 'random_uniform_5/mul:0',\n",
       " 'random_uniform_5:0',\n",
       " 'Variable_10:0',\n",
       " 'Variable_10/Assign:0',\n",
       " 'Variable_10/read:0',\n",
       " 'Const_5:0',\n",
       " 'Variable_11:0',\n",
       " 'Variable_11/Assign:0',\n",
       " 'Variable_11/read:0',\n",
       " 'MatMul_1:0',\n",
       " 'add_5:0',\n",
       " 'random_uniform_6/shape:0',\n",
       " 'random_uniform_6/min:0',\n",
       " 'random_uniform_6/max:0',\n",
       " 'random_uniform_6/RandomUniform:0',\n",
       " 'random_uniform_6/sub:0',\n",
       " 'random_uniform_6/mul:0',\n",
       " 'random_uniform_6:0',\n",
       " 'Variable_12:0',\n",
       " 'Variable_12/Assign:0',\n",
       " 'Variable_12/read:0',\n",
       " 'Const_6:0',\n",
       " 'Variable_13:0',\n",
       " 'Variable_13/Assign:0',\n",
       " 'Variable_13/read:0',\n",
       " 'MatMul_2:0',\n",
       " 'add_6:0',\n",
       " 'random_uniform_7/shape:0',\n",
       " 'random_uniform_7/min:0',\n",
       " 'random_uniform_7/max:0',\n",
       " 'random_uniform_7/RandomUniform:0',\n",
       " 'random_uniform_7/sub:0',\n",
       " 'random_uniform_7/mul:0',\n",
       " 'random_uniform_7:0',\n",
       " 'Variable_14:0',\n",
       " 'Variable_14/Assign:0',\n",
       " 'Variable_14/read:0',\n",
       " 'Const_7:0',\n",
       " 'Variable_15:0',\n",
       " 'Variable_15/Assign:0',\n",
       " 'Variable_15/read:0',\n",
       " 'MatMul_3:0',\n",
       " 'add_7:0',\n",
       " 'dropout/keep_prob:0',\n",
       " 'dropout/Shape:0',\n",
       " 'dropout/random_uniform/min:0',\n",
       " 'dropout/random_uniform/max:0',\n",
       " 'dropout/random_uniform/RandomUniform:0',\n",
       " 'dropout/random_uniform/sub:0',\n",
       " 'dropout/random_uniform/mul:0',\n",
       " 'dropout/random_uniform:0',\n",
       " 'dropout/add:0',\n",
       " 'dropout/Floor:0',\n",
       " 'dropout/div:0',\n",
       " 'dropout/mul:0',\n",
       " 'Softmax:0',\n",
       " 'ArgMax_1/dimension:0',\n",
       " 'ArgMax_1:0',\n",
       " 'softmax_cross_entropy_with_logits/Rank:0',\n",
       " 'softmax_cross_entropy_with_logits/Shape:0',\n",
       " 'softmax_cross_entropy_with_logits/Rank_1:0',\n",
       " 'softmax_cross_entropy_with_logits/Shape_1:0',\n",
       " 'softmax_cross_entropy_with_logits/Sub/y:0',\n",
       " 'softmax_cross_entropy_with_logits/Sub:0',\n",
       " 'softmax_cross_entropy_with_logits/Slice/begin:0',\n",
       " 'softmax_cross_entropy_with_logits/Slice/size:0',\n",
       " 'softmax_cross_entropy_with_logits/Slice:0',\n",
       " 'softmax_cross_entropy_with_logits/concat/values_0:0',\n",
       " 'softmax_cross_entropy_with_logits/concat/axis:0',\n",
       " 'softmax_cross_entropy_with_logits/concat:0',\n",
       " 'softmax_cross_entropy_with_logits/Reshape:0',\n",
       " 'softmax_cross_entropy_with_logits/Rank_2:0',\n",
       " 'softmax_cross_entropy_with_logits/Shape_2:0',\n",
       " 'softmax_cross_entropy_with_logits/Sub_1/y:0',\n",
       " 'softmax_cross_entropy_with_logits/Sub_1:0',\n",
       " 'softmax_cross_entropy_with_logits/Slice_1/begin:0',\n",
       " 'softmax_cross_entropy_with_logits/Slice_1/size:0',\n",
       " 'softmax_cross_entropy_with_logits/Slice_1:0',\n",
       " 'softmax_cross_entropy_with_logits/concat_1/values_0:0',\n",
       " 'softmax_cross_entropy_with_logits/concat_1/axis:0',\n",
       " 'softmax_cross_entropy_with_logits/concat_1:0',\n",
       " 'softmax_cross_entropy_with_logits/Reshape_1:0',\n",
       " 'softmax_cross_entropy_with_logits:0',\n",
       " 'softmax_cross_entropy_with_logits:1',\n",
       " 'softmax_cross_entropy_with_logits/Sub_2/y:0',\n",
       " 'softmax_cross_entropy_with_logits/Sub_2:0',\n",
       " 'softmax_cross_entropy_with_logits/Slice_2/begin:0',\n",
       " 'softmax_cross_entropy_with_logits/Slice_2/size:0',\n",
       " 'softmax_cross_entropy_with_logits/Slice_2:0',\n",
       " 'softmax_cross_entropy_with_logits/Reshape_2:0',\n",
       " 'Const_8:0',\n",
       " 'Mean:0',\n",
       " 'gradients/Shape:0',\n",
       " 'gradients/grad_ys_0:0',\n",
       " 'gradients/Fill:0',\n",
       " 'gradients/Mean_grad/Reshape/shape:0',\n",
       " 'gradients/Mean_grad/Reshape:0',\n",
       " 'gradients/Mean_grad/Shape:0',\n",
       " 'gradients/Mean_grad/Tile:0',\n",
       " 'gradients/Mean_grad/Shape_1:0',\n",
       " 'gradients/Mean_grad/Shape_2:0',\n",
       " 'gradients/Mean_grad/Const:0',\n",
       " 'gradients/Mean_grad/Prod:0',\n",
       " 'gradients/Mean_grad/Const_1:0',\n",
       " 'gradients/Mean_grad/Prod_1:0',\n",
       " 'gradients/Mean_grad/Maximum/y:0',\n",
       " 'gradients/Mean_grad/Maximum:0',\n",
       " 'gradients/Mean_grad/floordiv:0',\n",
       " 'gradients/Mean_grad/Cast:0',\n",
       " 'gradients/Mean_grad/truediv:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape:0',\n",
       " 'gradients/zeros_like:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits_grad/ExpandDims/dim:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits_grad/ExpandDims:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits_grad/mul:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits_grad/Neg:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits_grad/ExpandDims_1:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits_grad/mul_1:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits_grad/tuple/control_dependency:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits/Reshape_grad/Shape:0',\n",
       " 'gradients/softmax_cross_entropy_with_logits/Reshape_grad/Reshape:0',\n",
       " 'gradients/dropout/mul_grad/Shape:0',\n",
       " 'gradients/dropout/mul_grad/Shape_1:0',\n",
       " 'gradients/dropout/mul_grad/BroadcastGradientArgs:0',\n",
       " 'gradients/dropout/mul_grad/BroadcastGradientArgs:1',\n",
       " 'gradients/dropout/mul_grad/Mul:0',\n",
       " 'gradients/dropout/mul_grad/Sum:0',\n",
       " 'gradients/dropout/mul_grad/Reshape:0',\n",
       " 'gradients/dropout/mul_grad/Mul_1:0',\n",
       " 'gradients/dropout/mul_grad/Sum_1:0',\n",
       " 'gradients/dropout/mul_grad/Reshape_1:0',\n",
       " 'gradients/dropout/mul_grad/tuple/control_dependency:0',\n",
       " 'gradients/dropout/mul_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/dropout/div_grad/Shape:0',\n",
       " 'gradients/dropout/div_grad/Shape_1:0',\n",
       " 'gradients/dropout/div_grad/BroadcastGradientArgs:0',\n",
       " 'gradients/dropout/div_grad/BroadcastGradientArgs:1',\n",
       " 'gradients/dropout/div_grad/RealDiv:0',\n",
       " 'gradients/dropout/div_grad/Sum:0',\n",
       " 'gradients/dropout/div_grad/Reshape:0',\n",
       " 'gradients/dropout/div_grad/Neg:0',\n",
       " 'gradients/dropout/div_grad/RealDiv_1:0',\n",
       " 'gradients/dropout/div_grad/RealDiv_2:0',\n",
       " 'gradients/dropout/div_grad/mul:0',\n",
       " 'gradients/dropout/div_grad/Sum_1:0',\n",
       " 'gradients/dropout/div_grad/Reshape_1:0',\n",
       " 'gradients/dropout/div_grad/tuple/control_dependency:0',\n",
       " 'gradients/dropout/div_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/add_7_grad/Shape:0',\n",
       " 'gradients/add_7_grad/Shape_1:0',\n",
       " 'gradients/add_7_grad/BroadcastGradientArgs:0',\n",
       " 'gradients/add_7_grad/BroadcastGradientArgs:1',\n",
       " 'gradients/add_7_grad/Sum:0',\n",
       " 'gradients/add_7_grad/Reshape:0',\n",
       " 'gradients/add_7_grad/Sum_1:0',\n",
       " 'gradients/add_7_grad/Reshape_1:0',\n",
       " 'gradients/add_7_grad/tuple/control_dependency:0',\n",
       " 'gradients/add_7_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/MatMul_3_grad/MatMul:0',\n",
       " 'gradients/MatMul_3_grad/MatMul_1:0',\n",
       " 'gradients/MatMul_3_grad/tuple/control_dependency:0',\n",
       " 'gradients/MatMul_3_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/add_6_grad/Shape:0',\n",
       " 'gradients/add_6_grad/Shape_1:0',\n",
       " 'gradients/add_6_grad/BroadcastGradientArgs:0',\n",
       " 'gradients/add_6_grad/BroadcastGradientArgs:1',\n",
       " 'gradients/add_6_grad/Sum:0',\n",
       " 'gradients/add_6_grad/Reshape:0',\n",
       " 'gradients/add_6_grad/Sum_1:0',\n",
       " 'gradients/add_6_grad/Reshape_1:0',\n",
       " 'gradients/add_6_grad/tuple/control_dependency:0',\n",
       " 'gradients/add_6_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/MatMul_2_grad/MatMul:0',\n",
       " 'gradients/MatMul_2_grad/MatMul_1:0',\n",
       " 'gradients/MatMul_2_grad/tuple/control_dependency:0',\n",
       " 'gradients/MatMul_2_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/add_5_grad/Shape:0',\n",
       " 'gradients/add_5_grad/Shape_1:0',\n",
       " 'gradients/add_5_grad/BroadcastGradientArgs:0',\n",
       " 'gradients/add_5_grad/BroadcastGradientArgs:1',\n",
       " 'gradients/add_5_grad/Sum:0',\n",
       " 'gradients/add_5_grad/Reshape:0',\n",
       " 'gradients/add_5_grad/Sum_1:0',\n",
       " 'gradients/add_5_grad/Reshape_1:0',\n",
       " 'gradients/add_5_grad/tuple/control_dependency:0',\n",
       " 'gradients/add_5_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/MatMul_1_grad/MatMul:0',\n",
       " 'gradients/MatMul_1_grad/MatMul_1:0',\n",
       " 'gradients/MatMul_1_grad/tuple/control_dependency:0',\n",
       " 'gradients/MatMul_1_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/Relu_4_grad/ReluGrad:0',\n",
       " 'gradients/add_4_grad/Shape:0',\n",
       " 'gradients/add_4_grad/Shape_1:0',\n",
       " 'gradients/add_4_grad/BroadcastGradientArgs:0',\n",
       " 'gradients/add_4_grad/BroadcastGradientArgs:1',\n",
       " 'gradients/add_4_grad/Sum:0',\n",
       " 'gradients/add_4_grad/Reshape:0',\n",
       " 'gradients/add_4_grad/Sum_1:0',\n",
       " 'gradients/add_4_grad/Reshape_1:0',\n",
       " 'gradients/add_4_grad/tuple/control_dependency:0',\n",
       " 'gradients/add_4_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/MatMul_grad/MatMul:0',\n",
       " 'gradients/MatMul_grad/MatMul_1:0',\n",
       " 'gradients/MatMul_grad/tuple/control_dependency:0',\n",
       " 'gradients/MatMul_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/Reshape_1_grad/Shape:0',\n",
       " 'gradients/Reshape_1_grad/Reshape:0',\n",
       " 'gradients/Relu_3_grad/ReluGrad:0',\n",
       " 'gradients/MaxPool_3_grad/MaxPoolGrad:0',\n",
       " 'gradients/add_3_grad/Shape:0',\n",
       " 'gradients/add_3_grad/Shape_1:0',\n",
       " 'gradients/add_3_grad/BroadcastGradientArgs:0',\n",
       " 'gradients/add_3_grad/BroadcastGradientArgs:1',\n",
       " 'gradients/add_3_grad/Sum:0',\n",
       " 'gradients/add_3_grad/Reshape:0',\n",
       " 'gradients/add_3_grad/Sum_1:0',\n",
       " 'gradients/add_3_grad/Reshape_1:0',\n",
       " 'gradients/add_3_grad/tuple/control_dependency:0',\n",
       " 'gradients/add_3_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/Conv2D_3_grad/ShapeN:0',\n",
       " 'gradients/Conv2D_3_grad/ShapeN:1',\n",
       " 'gradients/Conv2D_3_grad/Conv2DBackpropInput:0',\n",
       " 'gradients/Conv2D_3_grad/Conv2DBackpropFilter:0',\n",
       " 'gradients/Conv2D_3_grad/tuple/control_dependency:0',\n",
       " 'gradients/Conv2D_3_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/Relu_2_grad/ReluGrad:0',\n",
       " 'gradients/MaxPool_2_grad/MaxPoolGrad:0',\n",
       " 'gradients/add_2_grad/Shape:0',\n",
       " 'gradients/add_2_grad/Shape_1:0',\n",
       " 'gradients/add_2_grad/BroadcastGradientArgs:0',\n",
       " 'gradients/add_2_grad/BroadcastGradientArgs:1',\n",
       " 'gradients/add_2_grad/Sum:0',\n",
       " 'gradients/add_2_grad/Reshape:0',\n",
       " 'gradients/add_2_grad/Sum_1:0',\n",
       " 'gradients/add_2_grad/Reshape_1:0',\n",
       " 'gradients/add_2_grad/tuple/control_dependency:0',\n",
       " 'gradients/add_2_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/Conv2D_2_grad/ShapeN:0',\n",
       " 'gradients/Conv2D_2_grad/ShapeN:1',\n",
       " 'gradients/Conv2D_2_grad/Conv2DBackpropInput:0',\n",
       " 'gradients/Conv2D_2_grad/Conv2DBackpropFilter:0',\n",
       " 'gradients/Conv2D_2_grad/tuple/control_dependency:0',\n",
       " 'gradients/Conv2D_2_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/Relu_1_grad/ReluGrad:0',\n",
       " 'gradients/MaxPool_1_grad/MaxPoolGrad:0',\n",
       " 'gradients/add_1_grad/Shape:0',\n",
       " 'gradients/add_1_grad/Shape_1:0',\n",
       " 'gradients/add_1_grad/BroadcastGradientArgs:0',\n",
       " 'gradients/add_1_grad/BroadcastGradientArgs:1',\n",
       " 'gradients/add_1_grad/Sum:0',\n",
       " 'gradients/add_1_grad/Reshape:0',\n",
       " 'gradients/add_1_grad/Sum_1:0',\n",
       " 'gradients/add_1_grad/Reshape_1:0',\n",
       " 'gradients/add_1_grad/tuple/control_dependency:0',\n",
       " 'gradients/add_1_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/Conv2D_1_grad/ShapeN:0',\n",
       " 'gradients/Conv2D_1_grad/ShapeN:1',\n",
       " 'gradients/Conv2D_1_grad/Conv2DBackpropInput:0',\n",
       " 'gradients/Conv2D_1_grad/Conv2DBackpropFilter:0',\n",
       " 'gradients/Conv2D_1_grad/tuple/control_dependency:0',\n",
       " 'gradients/Conv2D_1_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/Relu_grad/ReluGrad:0',\n",
       " 'gradients/MaxPool_grad/MaxPoolGrad:0',\n",
       " 'gradients/add_grad/Shape:0',\n",
       " 'gradients/add_grad/Shape_1:0',\n",
       " 'gradients/add_grad/BroadcastGradientArgs:0',\n",
       " 'gradients/add_grad/BroadcastGradientArgs:1',\n",
       " 'gradients/add_grad/Sum:0',\n",
       " 'gradients/add_grad/Reshape:0',\n",
       " 'gradients/add_grad/Sum_1:0',\n",
       " 'gradients/add_grad/Reshape_1:0',\n",
       " 'gradients/add_grad/tuple/control_dependency:0',\n",
       " 'gradients/add_grad/tuple/control_dependency_1:0',\n",
       " 'gradients/Conv2D_grad/ShapeN:0',\n",
       " 'gradients/Conv2D_grad/ShapeN:1',\n",
       " 'gradients/Conv2D_grad/Conv2DBackpropInput:0',\n",
       " 'gradients/Conv2D_grad/Conv2DBackpropFilter:0',\n",
       " 'gradients/Conv2D_grad/tuple/control_dependency:0',\n",
       " 'gradients/Conv2D_grad/tuple/control_dependency_1:0',\n",
       " 'beta1_power/initial_value:0',\n",
       " 'beta1_power:0',\n",
       " 'beta1_power/Assign:0',\n",
       " 'beta1_power/read:0',\n",
       " 'beta2_power/initial_value:0',\n",
       " 'beta2_power:0',\n",
       " 'beta2_power/Assign:0',\n",
       " 'beta2_power/read:0',\n",
       " 'Variable/Adam/Initializer/zeros:0',\n",
       " 'Variable/Adam:0',\n",
       " 'Variable/Adam/Assign:0',\n",
       " 'Variable/Adam/read:0',\n",
       " 'Variable/Adam_1/Initializer/zeros:0',\n",
       " 'Variable/Adam_1:0',\n",
       " 'Variable/Adam_1/Assign:0',\n",
       " 'Variable/Adam_1/read:0',\n",
       " 'Variable_1/Adam/Initializer/zeros:0',\n",
       " 'Variable_1/Adam:0',\n",
       " 'Variable_1/Adam/Assign:0',\n",
       " 'Variable_1/Adam/read:0',\n",
       " 'Variable_1/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_1/Adam_1:0',\n",
       " 'Variable_1/Adam_1/Assign:0',\n",
       " 'Variable_1/Adam_1/read:0',\n",
       " 'Variable_2/Adam/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_2/Adam/Initializer/zeros/Const:0',\n",
       " 'Variable_2/Adam/Initializer/zeros:0',\n",
       " 'Variable_2/Adam:0',\n",
       " 'Variable_2/Adam/Assign:0',\n",
       " 'Variable_2/Adam/read:0',\n",
       " 'Variable_2/Adam_1/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_2/Adam_1/Initializer/zeros/Const:0',\n",
       " 'Variable_2/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_2/Adam_1:0',\n",
       " 'Variable_2/Adam_1/Assign:0',\n",
       " 'Variable_2/Adam_1/read:0',\n",
       " 'Variable_3/Adam/Initializer/zeros:0',\n",
       " 'Variable_3/Adam:0',\n",
       " 'Variable_3/Adam/Assign:0',\n",
       " 'Variable_3/Adam/read:0',\n",
       " 'Variable_3/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_3/Adam_1:0',\n",
       " 'Variable_3/Adam_1/Assign:0',\n",
       " 'Variable_3/Adam_1/read:0',\n",
       " 'Variable_4/Adam/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_4/Adam/Initializer/zeros/Const:0',\n",
       " 'Variable_4/Adam/Initializer/zeros:0',\n",
       " 'Variable_4/Adam:0',\n",
       " 'Variable_4/Adam/Assign:0',\n",
       " 'Variable_4/Adam/read:0',\n",
       " 'Variable_4/Adam_1/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_4/Adam_1/Initializer/zeros/Const:0',\n",
       " 'Variable_4/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_4/Adam_1:0',\n",
       " 'Variable_4/Adam_1/Assign:0',\n",
       " 'Variable_4/Adam_1/read:0',\n",
       " 'Variable_5/Adam/Initializer/zeros:0',\n",
       " 'Variable_5/Adam:0',\n",
       " 'Variable_5/Adam/Assign:0',\n",
       " 'Variable_5/Adam/read:0',\n",
       " 'Variable_5/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_5/Adam_1:0',\n",
       " 'Variable_5/Adam_1/Assign:0',\n",
       " 'Variable_5/Adam_1/read:0',\n",
       " 'Variable_6/Adam/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_6/Adam/Initializer/zeros/Const:0',\n",
       " 'Variable_6/Adam/Initializer/zeros:0',\n",
       " 'Variable_6/Adam:0',\n",
       " 'Variable_6/Adam/Assign:0',\n",
       " 'Variable_6/Adam/read:0',\n",
       " 'Variable_6/Adam_1/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_6/Adam_1/Initializer/zeros/Const:0',\n",
       " 'Variable_6/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_6/Adam_1:0',\n",
       " 'Variable_6/Adam_1/Assign:0',\n",
       " 'Variable_6/Adam_1/read:0',\n",
       " 'Variable_7/Adam/Initializer/zeros:0',\n",
       " 'Variable_7/Adam:0',\n",
       " 'Variable_7/Adam/Assign:0',\n",
       " 'Variable_7/Adam/read:0',\n",
       " 'Variable_7/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_7/Adam_1:0',\n",
       " 'Variable_7/Adam_1/Assign:0',\n",
       " 'Variable_7/Adam_1/read:0',\n",
       " 'Variable_8/Adam/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_8/Adam/Initializer/zeros/Const:0',\n",
       " 'Variable_8/Adam/Initializer/zeros:0',\n",
       " 'Variable_8/Adam:0',\n",
       " 'Variable_8/Adam/Assign:0',\n",
       " 'Variable_8/Adam/read:0',\n",
       " 'Variable_8/Adam_1/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_8/Adam_1/Initializer/zeros/Const:0',\n",
       " 'Variable_8/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_8/Adam_1:0',\n",
       " 'Variable_8/Adam_1/Assign:0',\n",
       " 'Variable_8/Adam_1/read:0',\n",
       " 'Variable_9/Adam/Initializer/zeros:0',\n",
       " 'Variable_9/Adam:0',\n",
       " 'Variable_9/Adam/Assign:0',\n",
       " 'Variable_9/Adam/read:0',\n",
       " 'Variable_9/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_9/Adam_1:0',\n",
       " 'Variable_9/Adam_1/Assign:0',\n",
       " 'Variable_9/Adam_1/read:0',\n",
       " 'Variable_10/Adam/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_10/Adam/Initializer/zeros/Const:0',\n",
       " 'Variable_10/Adam/Initializer/zeros:0',\n",
       " 'Variable_10/Adam:0',\n",
       " 'Variable_10/Adam/Assign:0',\n",
       " 'Variable_10/Adam/read:0',\n",
       " 'Variable_10/Adam_1/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_10/Adam_1/Initializer/zeros/Const:0',\n",
       " 'Variable_10/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_10/Adam_1:0',\n",
       " 'Variable_10/Adam_1/Assign:0',\n",
       " 'Variable_10/Adam_1/read:0',\n",
       " 'Variable_11/Adam/Initializer/zeros:0',\n",
       " 'Variable_11/Adam:0',\n",
       " 'Variable_11/Adam/Assign:0',\n",
       " 'Variable_11/Adam/read:0',\n",
       " 'Variable_11/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_11/Adam_1:0',\n",
       " 'Variable_11/Adam_1/Assign:0',\n",
       " 'Variable_11/Adam_1/read:0',\n",
       " 'Variable_12/Adam/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_12/Adam/Initializer/zeros/Const:0',\n",
       " 'Variable_12/Adam/Initializer/zeros:0',\n",
       " 'Variable_12/Adam:0',\n",
       " 'Variable_12/Adam/Assign:0',\n",
       " 'Variable_12/Adam/read:0',\n",
       " 'Variable_12/Adam_1/Initializer/zeros/shape_as_tensor:0',\n",
       " 'Variable_12/Adam_1/Initializer/zeros/Const:0',\n",
       " 'Variable_12/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_12/Adam_1:0',\n",
       " 'Variable_12/Adam_1/Assign:0',\n",
       " 'Variable_12/Adam_1/read:0',\n",
       " 'Variable_13/Adam/Initializer/zeros:0',\n",
       " 'Variable_13/Adam:0',\n",
       " 'Variable_13/Adam/Assign:0',\n",
       " 'Variable_13/Adam/read:0',\n",
       " 'Variable_13/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_13/Adam_1:0',\n",
       " 'Variable_13/Adam_1/Assign:0',\n",
       " 'Variable_13/Adam_1/read:0',\n",
       " 'Variable_14/Adam/Initializer/zeros:0',\n",
       " 'Variable_14/Adam:0',\n",
       " 'Variable_14/Adam/Assign:0',\n",
       " 'Variable_14/Adam/read:0',\n",
       " 'Variable_14/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_14/Adam_1:0',\n",
       " 'Variable_14/Adam_1/Assign:0',\n",
       " 'Variable_14/Adam_1/read:0',\n",
       " 'Variable_15/Adam/Initializer/zeros:0',\n",
       " 'Variable_15/Adam:0',\n",
       " 'Variable_15/Adam/Assign:0',\n",
       " 'Variable_15/Adam/read:0',\n",
       " 'Variable_15/Adam_1/Initializer/zeros:0',\n",
       " 'Variable_15/Adam_1:0',\n",
       " 'Variable_15/Adam_1/Assign:0',\n",
       " 'Variable_15/Adam_1/read:0',\n",
       " 'Adam/learning_rate:0',\n",
       " 'Adam/beta1:0',\n",
       " 'Adam/beta2:0',\n",
       " 'Adam/epsilon:0',\n",
       " 'Adam/update_Variable/ApplyAdam:0',\n",
       " 'Adam/update_Variable_1/ApplyAdam:0',\n",
       " 'Adam/update_Variable_2/ApplyAdam:0',\n",
       " 'Adam/update_Variable_3/ApplyAdam:0',\n",
       " 'Adam/update_Variable_4/ApplyAdam:0',\n",
       " 'Adam/update_Variable_5/ApplyAdam:0',\n",
       " 'Adam/update_Variable_6/ApplyAdam:0',\n",
       " 'Adam/update_Variable_7/ApplyAdam:0',\n",
       " 'Adam/update_Variable_8/ApplyAdam:0',\n",
       " 'Adam/update_Variable_9/ApplyAdam:0',\n",
       " 'Adam/update_Variable_10/ApplyAdam:0',\n",
       " 'Adam/update_Variable_11/ApplyAdam:0',\n",
       " 'Adam/update_Variable_12/ApplyAdam:0',\n",
       " 'Adam/update_Variable_13/ApplyAdam:0',\n",
       " 'Adam/update_Variable_14/ApplyAdam:0',\n",
       " 'Adam/update_Variable_15/ApplyAdam:0',\n",
       " 'Adam/mul:0',\n",
       " 'Adam/Assign:0',\n",
       " 'Adam/mul_1:0',\n",
       " 'Adam/Assign_1:0',\n",
       " 'Equal:0',\n",
       " 'Cast:0',\n",
       " 'Const_9:0',\n",
       " 'Mean_1:0',\n",
       " 'save/Const:0',\n",
       " 'save/SaveV2/tensor_names:0',\n",
       " 'save/SaveV2/shape_and_slices:0',\n",
       " 'save/control_dependency:0',\n",
       " 'save/RestoreV2/tensor_names:0',\n",
       " 'save/RestoreV2/shape_and_slices:0',\n",
       " 'save/RestoreV2:0',\n",
       " 'save/RestoreV2:1',\n",
       " 'save/RestoreV2:2',\n",
       " 'save/RestoreV2:3',\n",
       " 'save/RestoreV2:4',\n",
       " 'save/RestoreV2:5',\n",
       " 'save/RestoreV2:6',\n",
       " 'save/RestoreV2:7',\n",
       " 'save/RestoreV2:8',\n",
       " 'save/RestoreV2:9',\n",
       " 'save/RestoreV2:10',\n",
       " 'save/RestoreV2:11',\n",
       " 'save/RestoreV2:12',\n",
       " 'save/RestoreV2:13',\n",
       " 'save/RestoreV2:14',\n",
       " 'save/RestoreV2:15',\n",
       " 'save/RestoreV2:16',\n",
       " 'save/RestoreV2:17',\n",
       " 'save/RestoreV2:18',\n",
       " 'save/RestoreV2:19',\n",
       " 'save/RestoreV2:20',\n",
       " 'save/RestoreV2:21',\n",
       " 'save/RestoreV2:22',\n",
       " 'save/RestoreV2:23',\n",
       " 'save/RestoreV2:24',\n",
       " 'save/RestoreV2:25',\n",
       " 'save/RestoreV2:26',\n",
       " 'save/RestoreV2:27',\n",
       " 'save/RestoreV2:28',\n",
       " 'save/RestoreV2:29',\n",
       " 'save/RestoreV2:30',\n",
       " 'save/RestoreV2:31',\n",
       " 'save/RestoreV2:32',\n",
       " 'save/RestoreV2:33',\n",
       " 'save/RestoreV2:34',\n",
       " 'save/RestoreV2:35',\n",
       " 'save/RestoreV2:36',\n",
       " 'save/RestoreV2:37',\n",
       " 'save/RestoreV2:38',\n",
       " 'save/RestoreV2:39',\n",
       " 'save/RestoreV2:40',\n",
       " 'save/RestoreV2:41',\n",
       " 'save/RestoreV2:42',\n",
       " 'save/RestoreV2:43',\n",
       " 'save/RestoreV2:44',\n",
       " 'save/RestoreV2:45',\n",
       " 'save/RestoreV2:46',\n",
       " 'save/RestoreV2:47',\n",
       " 'save/RestoreV2:48',\n",
       " 'save/RestoreV2:49',\n",
       " 'save/Assign:0',\n",
       " 'save/Assign_1:0',\n",
       " 'save/Assign_2:0',\n",
       " 'save/Assign_3:0',\n",
       " 'save/Assign_4:0',\n",
       " 'save/Assign_5:0',\n",
       " 'save/Assign_6:0',\n",
       " 'save/Assign_7:0',\n",
       " 'save/Assign_8:0',\n",
       " 'save/Assign_9:0',\n",
       " 'save/Assign_10:0',\n",
       " 'save/Assign_11:0',\n",
       " 'save/Assign_12:0',\n",
       " 'save/Assign_13:0',\n",
       " 'save/Assign_14:0',\n",
       " 'save/Assign_15:0',\n",
       " 'save/Assign_16:0',\n",
       " 'save/Assign_17:0',\n",
       " 'save/Assign_18:0',\n",
       " 'save/Assign_19:0',\n",
       " 'save/Assign_20:0',\n",
       " 'save/Assign_21:0',\n",
       " 'save/Assign_22:0',\n",
       " 'save/Assign_23:0',\n",
       " 'save/Assign_24:0',\n",
       " 'save/Assign_25:0',\n",
       " 'save/Assign_26:0',\n",
       " 'save/Assign_27:0',\n",
       " 'save/Assign_28:0',\n",
       " 'save/Assign_29:0',\n",
       " 'save/Assign_30:0',\n",
       " 'save/Assign_31:0',\n",
       " 'save/Assign_32:0',\n",
       " 'save/Assign_33:0',\n",
       " 'save/Assign_34:0',\n",
       " 'save/Assign_35:0',\n",
       " 'save/Assign_36:0',\n",
       " 'save/Assign_37:0',\n",
       " 'save/Assign_38:0',\n",
       " 'save/Assign_39:0',\n",
       " 'save/Assign_40:0',\n",
       " 'save/Assign_41:0',\n",
       " 'save/Assign_42:0',\n",
       " 'save/Assign_43:0',\n",
       " 'save/Assign_44:0',\n",
       " 'save/Assign_45:0',\n",
       " 'save/Assign_46:0',\n",
       " 'save/Assign_47:0',\n",
       " 'save/Assign_48:0',\n",
       " 'save/Assign_49:0']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_names = [t.name for op in tf.get_default_graph().get_operations() for t in op.values()]\n",
    "tensor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sr_plot = [0.5, 0.75, 0.78125, 0.8125, 0.8125, 0.8125, 0.8125, 0.828125, 0.875, 0.90625, 0.78125, 0.90625, 0.78125, 0.921875, 0.828125, 0.921875]\n",
    "accuracy_sd_plot = [0.421875, 0.484375, 0.484375, 0.453125, 0.578125, 0.515625, 0.5625, 0.5625, 0.5, 0.5625, 0.671875, 0.59375, 0.421875, 0.5625, 0.484375, 0.515625]\n",
    "accuracy_sd_patchonly_plot = [0.578125, 0.890625, 0.8125, 0.890625, 0.890625, 0.8125, 0.796875, 0.9375, 0.90625, 0.890625, 0.90625, 0.84375, 0.859375, 0.828125, 0.9375, 0.890625]\n",
    "accuracy_sd_conv_plot = [0.609375, 0.671875, 0.828125, 0.84375, 0.78125, 0.8125, 0.859375, 0.828125, 0.84375, 0.890625, 0.953125, 0.90625, 0.921875, 0.84375, 0.921875, 0.859375]\n",
    "training_size_sd_plot = [64, 64064, 128064, 192064, 256064, 320064, 384064, 448064, 512064, 576064, 640064, 704064, 768064, 832064, 896064, 960064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_no, training_size, accuracy, loss, start_size, end_size\n",
    "\n",
    "generate_size_graph(1, training_size_sd_plot, accuracy_sd_plot, accuracy_sr_plot,accuracy_sd_patchonly_plot,accuracy_sd_conv_plot,  64, 960064)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred, correct):\n",
    "    # This function is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # correct is a boolean array whether the predicted class\n",
    "    # is equal to the true class for each image in the test-set.\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = data.test.images[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = data.test.cls[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])\n",
    "    \n",
    "def plot_confusion_matrix(cls_pred):\n",
    "    # This is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = data.test.cls\n",
    "    \n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.matshow(cm)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test-set into smaller batches of this size.\n",
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    # Number of images in the test-set.\n",
    "    num_test = len(data.test.images)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        # Get the images from the test-set between index i and j.\n",
    "        images = data.test.images[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = data.test.labels[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the test-set.\n",
    "    cls_true = data.test.cls\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the test-set.\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "\n",
    "    # Plot some examples of mis-classifications, if desired.\n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "    # Plot the confusion matrix, if desired.\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_true_batch = data.test.next_batch(64)\n",
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.84375, 0.8125, 0.78125, 0.859375, 0.796875, 0.84375, 0.796875, 0.71875, 0.6875, 0.8125, 0.890625, 0.8125, 0.84375, 0.796875, 0.75, 0.890625, 0.78125, 0.859375, 0.78125, 0.78125, 0.765625, 0.828125, 0.75, 0.796875, 0.796875, 0.734375, 0.84375, 0.828125, 0.84375, 0.6875, 0.796875, 0.84375, 0.796875, 0.84375, 0.828125, 0.859375, 0.828125, 0.84375, 0.78125, 0.90625, 0.84375, 0.875, 0.65625, 0.828125, 0.828125, 0.734375, 0.84375, 0.796875, 0.875, 0.828125, 0.71875, 0.875, 0.75, 0.875, 0.828125, 0.765625, 0.84375, 0.875, 0.734375, 0.75, 0.84375, 0.84375, 0.8125, 0.796875, 0.8125, 0.828125, 0.8125, 0.8125, 0.8125, 0.859375, 0.890625, 0.859375, 0.859375, 0.75, 0.75, 0.8125, 0.78125, 0.828125, 0.84375, 0.78125, 0.78125, 0.84375, 0.8125, 0.859375, 0.796875, 0.859375, 0.875, 0.828125, 0.75, 0.84375, 0.796875, 0.90625, 0.75, 0.859375, 0.828125, 0.828125, 0.859375, 0.90625, 0.859375, 0.734375, 0.859375, 0.90625, 0.84375, 0.859375, 0.71875, 0.765625, 0.796875, 0.890625, 0.75, 0.828125, 0.828125, 0.875, 0.796875, 0.765625, 0.890625, 0.8125, 0.828125, 0.78125, 0.890625, 0.734375, 0.796875, 0.90625, 0.84375, 0.75, 0.859375, 0.8125, 0.828125, 0.890625, 0.796875, 0.859375, 0.765625, 0.84375, 0.796875, 0.78125, 0.8125, 0.734375, 0.875, 0.8125, 0.78125, 0.8125, 0.71875, 0.78125, 0.859375, 0.78125, 0.890625, 0.90625, 0.8125, 0.78125, 0.828125, 0.8125, 0.78125, 0.78125, 0.796875, 0.734375, 0.859375, 0.765625, 0.8125, 0.828125, 0.828125, 0.84375, 0.84375, 0.859375, 0.78125, 0.765625, 0.8125, 0.8125, 0.765625, 0.875, 0.8125, 0.828125, 0.875, 0.875, 0.765625, 0.796875, 0.890625, 0.828125, 0.859375, 0.734375, 0.8125, 0.765625, 0.859375, 0.78125, 0.875, 0.78125, 0.890625, 0.765625, 0.8125, 0.875, 0.84375, 0.890625, 0.796875, 0.8125, 0.828125, 0.765625, 0.8125, 0.890625, 0.859375, 0.78125, 0.828125, 0.8125, 0.96875, 0.875, 0.78125, 0.78125, 0.875, 0.703125, 0.796875, 0.875, 0.78125, 0.828125, 0.84375, 0.796875, 0.84375, 0.796875, 0.84375, 0.921875, 0.828125, 0.828125, 0.859375, 0.796875, 0.78125, 0.78125, 0.8125, 0.78125, 0.828125, 0.890625, 0.875, 0.75, 0.796875, 0.90625, 0.859375, 0.859375, 0.875, 0.8125, 0.78125, 0.90625, 0.75, 0.828125, 0.875, 0.765625, 0.828125, 0.859375, 0.859375, 0.828125, 0.78125, 0.8125, 0.8125, 0.859375, 0.84375, 0.875, 0.84375, 0.859375, 0.875, 0.828125, 0.84375, 0.796875, 0.875, 0.84375, 0.796875, 0.78125, 0.859375, 0.859375, 0.8125, 0.859375, 0.796875, 0.703125, 0.828125, 0.875, 0.859375, 0.796875, 0.828125, 0.875, 0.84375, 0.890625, 0.859375, 0.796875, 0.8125, 0.875, 0.796875, 0.859375, 0.875, 0.828125, 0.703125, 0.78125, 0.703125, 0.84375, 0.796875, 0.875, 0.890625, 0.890625, 0.8125, 0.84375, 0.78125, 0.84375, 0.84375, 0.875, 0.8125, 0.859375, 0.796875, 0.828125, 0.84375, 0.859375, 0.859375, 0.8125, 0.828125, 0.796875, 0.8125, 0.8125, 0.84375, 0.84375, 0.8125, 0.828125, 0.828125, 0.8125, 0.890625, 0.78125, 0.796875, 0.796875, 0.828125, 0.84375, 0.90625, 0.859375, 0.84375, 0.875, 0.75, 0.84375, 0.890625, 0.765625, 0.875, 0.84375, 0.84375, 0.84375, 0.859375, 0.921875, 0.75, 0.859375, 0.828125, 0.75, 0.875, 0.765625, 0.859375, 0.875, 0.78125, 0.90625, 0.75, 0.71875, 0.75, 0.859375, 0.78125, 0.78125, 0.84375, 0.875, 0.859375, 0.765625, 0.84375, 0.78125, 0.890625, 0.78125, 0.703125, 0.796875, 0.78125, 0.78125, 0.875, 0.875, 0.859375, 0.8125, 0.859375, 0.8125, 0.859375, 0.765625, 0.765625, 0.78125, 0.8125, 0.84375, 0.859375, 0.8125, 0.859375, 0.78125, 0.78125, 0.75, 0.84375, 0.765625, 0.859375, 0.78125, 0.78125, 0.8125, 0.703125, 0.828125, 0.75, 0.90625, 0.8125, 0.828125, 0.84375, 0.859375, 0.75, 0.796875, 0.890625, 0.890625, 0.78125, 0.8125, 0.71875, 0.796875, 0.859375, 0.84375, 0.859375, 0.8125, 0.828125, 0.84375, 0.8125, 0.84375, 0.828125, 0.78125, 0.8125, 0.828125, 0.8125, 0.828125, 0.765625, 0.765625, 0.765625, 0.703125, 0.828125, 0.734375, 0.875, 0.875, 0.84375, 0.8125, 0.84375, 0.734375, 0.84375, 0.890625, 0.859375, 0.8125, 0.84375, 0.859375, 0.828125, 0.765625, 0.890625, 0.84375, 0.796875, 0.890625, 0.8125, 0.734375, 0.703125, 0.921875, 0.859375, 0.90625, 0.78125, 0.84375, 0.71875, 0.828125, 0.828125, 0.84375, 0.875, 0.828125, 0.8125, 0.78125, 0.828125, 0.890625, 0.921875, 0.828125, 0.828125, 0.84375, 0.84375, 0.828125, 0.828125, 0.84375, 0.859375, 0.859375, 0.84375, 0.765625, 0.78125, 0.8125, 0.828125, 0.796875, 0.84375, 0.84375, 0.75, 0.765625, 0.890625, 0.765625, 0.859375, 0.875, 0.875, 0.734375, 0.859375, 0.796875, 0.859375, 0.859375, 0.828125, 0.84375, 0.8125, 0.71875, 0.890625, 0.828125, 0.765625, 0.84375, 0.78125, 0.90625, 0.71875, 0.828125, 0.84375, 0.796875, 0.828125, 0.875, 0.875, 0.875, 0.828125, 0.78125, 0.859375, 0.84375, 0.796875, 0.75, 0.890625, 0.8125, 0.875, 0.8125, 0.8125]\n",
    "[65, 129, 193, 257, 321, 385, 449, 513, 577, 641, 705, 769, 833, 897, 961, 1025, 1089, 1153, 1217, 1281, 1345, 1409, 1473, 1537, 1601, 1665, 1729, 1793, 1857, 1921, 1985, 2049, 2113, 2177, 2241, 2305, 2369, 2433, 2497, 2561, 2625, 2689, 2753, 2817, 2881, 2945, 3009, 3073, 3137, 3201, 3265, 3329, 3393, 3457, 3521, 3585, 3649, 3713, 3777, 3841, 3905, 3969, 4033, 4097, 4161, 4225, 4289, 4353, 4417, 4481, 4545, 4609, 4673, 4737, 4801, 4865, 4929, 4993, 5057, 5121, 5185, 5249, 5313, 5377, 5441, 5505, 5569, 5633, 5697, 5761, 5825, 5889, 5953, 6017, 6081, 6145, 6209, 6273, 6337, 6401, 6465, 6529, 6593, 6657, 6721, 6785, 6849, 6913, 6977, 7041, 7105, 7169, 7233, 7297, 7361, 7425, 7489, 7553, 7617, 7681, 7745, 7809, 7873, 7937, 8001, 8065, 8129, 8193, 8257, 8321, 8385, 8449, 8513, 8577, 8641, 8705, 8769, 8833, 8897, 8961, 9025, 9089, 9153, 9217, 9281, 9345, 9409, 9473, 9537, 9601, 9665, 9729, 9793, 9857, 9921, 9985, 10049, 10113, 10177, 10241, 10305, 10369, 10433, 10497, 10561, 10625, 10689, 10753, 10817, 10881, 10945, 11009, 11073, 11137, 11201, 11265, 11329, 11393, 11457, 11521, 11585, 11649, 11713, 11777, 11841, 11905, 11969, 12033, 12097, 12161, 12225, 12289, 12353, 12417, 12481, 12545, 12609, 12673, 12737, 12801, 12865, 12929, 12993, 13057, 13121, 13185, 13249, 13313, 13377, 13441, 13505, 13569, 13633, 13697, 13761, 13825, 13889, 13953, 14017, 14081, 14145, 14209, 14273, 14337, 14401, 14465, 14529, 14593, 14657, 14721, 14785, 14849, 14913, 14977, 15041, 15105, 15169, 15233, 15297, 15361, 15425, 15489, 15553, 15617, 15681, 15745, 15809, 15873, 15937, 16001, 16065, 16129, 16193, 16257, 16321, 16385, 16449, 16513, 16577, 16641, 16705, 16769, 16833, 16897, 16961, 17025, 17089, 17153, 17217, 17281, 17345, 17409, 17473, 17537, 17601, 17665, 17729, 17793, 17857, 17921, 17985, 18049, 18113, 18177, 18241, 18305, 18369, 18433, 18497, 18561, 18625, 18689, 18753, 18817, 18881, 18945, 19009, 19073, 19137, 19201, 19265, 19329, 19393, 19457, 19521, 19585, 19649, 19713, 19777, 19841, 19905, 19969, 20033, 20097, 20161, 20225, 20289, 20353, 20417, 20481, 20545, 20609, 20673, 20737, 20801, 20865, 20929, 20993, 21057, 21121, 21185, 21249, 21313, 21377, 21441, 21505, 21569, 21633, 21697, 21761, 21825, 21889, 21953, 22017, 22081, 22145, 22209, 22273, 22337, 22401, 22465, 22529, 22593, 22657, 22721, 22785, 22849, 22913, 22977, 23041, 23105, 23169, 23233, 23297, 23361, 23425, 23489, 23553, 23617, 23681, 23745, 23809, 23873, 23937, 24001, 24065, 24129, 24193, 24257, 24321, 24385, 24449, 24513, 24577, 24641, 24705, 24769, 24833, 24897, 24961, 25025, 25089, 25153, 25217, 25281, 25345, 25409, 25473, 25537, 25601, 25665, 25729, 25793, 25857, 25921, 25985, 26049, 26113, 26177, 26241, 26305, 26369, 26433, 26497, 26561, 26625, 26689, 26753, 26817, 26881, 26945, 27009, 27073, 27137, 27201, 27265, 27329, 27393, 27457, 27521, 27585, 27649, 27713, 27777, 27841, 27905, 27969, 28033, 28097, 28161, 28225, 28289, 28353, 28417, 28481, 28545, 28609, 28673, 28737, 28801, 28865, 28929, 28993, 29057, 29121, 29185, 29249, 29313, 29377, 29441, 29505, 29569, 29633, 29697, 29761, 29825, 29889, 29953, 30017, 30081, 30145, 30209, 30273, 30337, 30401, 30465, 30529, 30593, 30657, 30721, 30785, 30849, 30913, 30977, 31041, 31105, 31169, 31233, 31297, 31361, 31425, 31489, 31553, 31617, 31681, 31745, 31809, 31873, 31937, 32001, 32065, 32129, 32193, 32257, 32321, 32385, 32449, 32513, 32577, 32641, 32705, 32769, 32833, 32897, 32961, 33025, 33089]\n",
    "[0.875, 0.953125, 0.796875, 0.890625, 0.875, 0.921875, 0.9375, 0.84375, 0.90625, 0.90625, 0.8125, 0.921875, 0.84375, 0.8125, 0.890625, 0.796875, 0.890625, 0.9375, 0.90625, 0.9375, 0.890625, 0.90625, 0.828125, 0.84375, 0.90625, 0.859375, 0.890625, 0.859375, 0.8125, 0.828125, 0.875, 0.796875, 0.796875, 0.796875, 0.90625, 0.890625, 0.921875, 0.875, 0.859375, 0.890625, 0.90625, 0.953125, 0.765625, 0.90625, 0.90625, 0.84375, 0.859375, 0.84375, 0.890625, 0.890625, 0.875, 0.859375, 0.953125, 0.90625, 0.84375, 0.796875, 0.84375, 0.9375, 0.90625, 0.84375, 0.78125, 0.90625, 0.8125, 0.8125, 0.859375, 0.875, 0.953125, 0.875, 0.859375, 0.875, 0.9375, 0.90625, 0.921875, 0.890625, 0.859375, 0.890625, 0.890625, 0.859375, 0.9375, 0.859375, 0.859375, 0.828125, 0.828125, 0.875, 0.796875, 0.890625, 0.8125, 0.828125, 0.828125, 0.921875, 0.78125, 0.828125, 0.90625, 0.875, 0.796875, 0.921875, 0.8125, 0.828125, 0.8125, 0.90625, 0.90625, 0.921875, 0.796875, 0.78125, 0.875, 0.859375, 0.90625, 0.828125, 0.84375, 0.828125, 0.828125, 0.828125, 0.890625, 0.84375, 0.953125, 0.828125, 0.890625, 0.859375, 0.9375, 0.921875, 0.859375, 0.859375, 0.921875, 0.890625, 0.90625, 0.828125, 0.90625, 0.859375, 0.921875, 0.90625, 0.90625, 0.921875, 0.828125, 0.859375, 0.890625, 0.859375, 0.890625, 0.9375, 0.765625, 0.859375, 0.8125, 0.859375, 0.84375, 0.90625, 0.90625, 0.828125, 0.859375, 0.90625, 0.84375, 0.875, 0.9375, 0.9375, 0.90625, 0.890625, 0.9375, 0.84375, 0.828125, 0.859375, 0.84375, 0.84375, 0.84375, 0.859375, 0.84375, 0.828125, 0.875, 0.921875, 0.875, 0.921875, 0.8125, 0.875, 0.875, 0.875, 0.84375, 0.875, 0.84375, 0.9375, 0.765625, 0.875, 0.890625, 0.828125, 0.875, 0.84375, 0.84375, 0.984375, 0.859375, 0.859375, 0.890625, 0.875, 0.828125, 0.9375, 0.875, 0.84375, 0.875, 0.875, 0.921875, 0.875, 0.921875, 0.875, 0.890625, 0.828125, 0.90625, 0.828125, 0.890625, 0.875, 0.796875, 0.765625, 0.9375, 0.859375, 0.921875, 0.875, 0.875, 0.875, 0.890625, 0.890625, 0.796875, 0.875, 0.875, 0.796875, 0.859375, 0.859375, 0.8125, 0.9375, 0.859375, 0.890625, 0.90625, 0.859375, 0.890625, 0.921875, 0.8125, 0.921875, 0.875, 0.859375, 0.875, 0.875, 0.828125, 0.828125, 0.875, 0.90625, 0.90625, 0.859375, 0.875, 0.953125, 0.875, 0.828125, 0.9375, 0.828125, 0.8125, 0.90625, 0.921875, 0.828125, 0.875, 0.890625, 0.921875, 0.890625, 0.796875, 0.84375, 0.875, 0.828125, 0.8125, 0.890625, 0.828125, 0.90625, 0.8125, 0.84375, 0.859375, 0.90625, 0.859375, 0.890625, 0.90625, 0.859375, 0.828125, 0.890625, 0.921875, 0.859375, 0.78125, 0.890625, 0.859375, 0.84375, 0.859375, 0.890625, 0.84375, 0.828125, 0.890625, 0.921875, 0.921875, 0.828125, 0.921875, 0.84375, 0.84375, 0.875, 0.90625, 0.875, 0.875, 0.84375, 0.90625, 0.921875, 0.921875, 0.90625, 0.84375, 0.890625, 0.8125, 0.734375, 0.9375, 0.84375, 0.875, 0.8125, 0.90625, 0.90625, 0.828125, 0.90625, 0.921875, 0.890625, 0.875, 0.875, 0.859375, 0.875, 0.765625, 0.828125, 0.890625, 0.875, 0.890625, 0.875, 0.890625, 0.875, 0.8125, 0.875, 0.84375, 0.875, 0.921875, 0.84375, 0.875, 0.84375, 0.84375, 0.90625, 0.90625, 0.921875, 0.859375, 0.859375, 0.828125, 0.953125, 0.84375, 0.875, 0.953125, 0.875, 0.84375, 0.84375, 0.875, 0.84375, 0.84375, 0.859375, 0.90625, 0.875, 0.921875, 0.90625, 0.765625, 0.84375, 0.859375, 0.859375, 0.84375, 0.890625, 0.828125, 0.8125, 0.84375, 0.90625, 0.890625, 0.8125, 0.890625, 0.828125, 0.90625, 0.875, 0.828125, 0.8125, 0.765625, 0.890625, 0.859375, 0.859375, 0.984375, 0.84375, 0.859375, 0.875, 0.921875, 0.890625, 0.96875, 0.828125, 0.84375, 0.84375, 0.90625, 0.890625, 0.875, 0.90625, 0.875, 0.9375, 0.859375, 0.84375, 0.8125, 0.828125, 0.890625, 0.84375, 0.875, 0.890625, 0.828125, 0.859375, 0.859375, 0.875, 0.890625, 0.859375, 0.875, 0.890625, 0.890625, 0.9375, 0.921875, 0.90625, 0.921875, 0.859375, 0.828125, 0.828125, 0.828125, 0.828125, 0.765625, 0.8125, 0.796875, 0.84375, 0.8125, 0.84375, 0.875, 0.828125, 0.8125, 0.84375, 0.90625, 0.875, 0.859375, 0.84375, 0.875, 0.890625, 0.921875, 0.796875, 0.859375, 0.859375, 0.90625, 0.859375, 0.828125, 0.84375, 0.828125, 0.90625, 0.84375, 0.875, 0.953125, 0.828125, 0.875, 0.921875, 0.890625, 0.8125, 0.90625, 0.8125, 0.875, 0.8125, 0.84375, 0.90625, 0.90625, 0.859375, 0.84375, 0.875, 0.859375, 0.828125, 0.875, 0.8125, 0.890625, 0.875, 0.8125, 0.875, 0.859375, 0.875, 0.875, 0.828125, 0.921875, 0.828125, 0.828125, 0.953125, 0.828125, 0.859375, 0.875, 0.890625, 0.90625, 0.796875, 0.859375, 0.890625, 0.859375, 0.859375, 0.84375, 0.90625, 0.8125, 0.875, 0.875, 0.859375, 0.828125, 0.890625, 0.890625, 0.875, 0.84375, 0.84375, 0.921875, 0.828125, 0.859375, 0.890625, 0.875, 0.890625, 0.859375, 0.859375, 0.84375, 0.84375, 0.875, 0.890625, 0.875, 0.859375, 0.84375, 0.875, 0.8125]\n",
    "[65, 129, 193, 257, 321, 385, 449, 513, 577, 641, 705, 769, 833, 897, 961, 1025, 1089, 1153, 1217, 1281, 1345, 1409, 1473, 1537, 1601, 1665, 1729, 1793, 1857, 1921, 1985, 2049, 2113, 2177, 2241, 2305, 2369, 2433, 2497, 2561, 2625, 2689, 2753, 2817, 2881, 2945, 3009, 3073, 3137, 3201, 3265, 3329, 3393, 3457, 3521, 3585, 3649, 3713, 3777, 3841, 3905, 3969, 4033, 4097, 4161, 4225, 4289, 4353, 4417, 4481, 4545, 4609, 4673, 4737, 4801, 4865, 4929, 4993, 5057, 5121, 5185, 5249, 5313, 5377, 5441, 5505, 5569, 5633, 5697, 5761, 5825, 5889, 5953, 6017, 6081, 6145, 6209, 6273, 6337, 6401, 6465, 6529, 6593, 6657, 6721, 6785, 6849, 6913, 6977, 7041, 7105, 7169, 7233, 7297, 7361, 7425, 7489, 7553, 7617, 7681, 7745, 7809, 7873, 7937, 8001, 8065, 8129, 8193, 8257, 8321, 8385, 8449, 8513, 8577, 8641, 8705, 8769, 8833, 8897, 8961, 9025, 9089, 9153, 9217, 9281, 9345, 9409, 9473, 9537, 9601, 9665, 9729, 9793, 9857, 9921, 9985, 10049, 10113, 10177, 10241, 10305, 10369, 10433, 10497, 10561, 10625, 10689, 10753, 10817, 10881, 10945, 11009, 11073, 11137, 11201, 11265, 11329, 11393, 11457, 11521, 11585, 11649, 11713, 11777, 11841, 11905, 11969, 12033, 12097, 12161, 12225, 12289, 12353, 12417, 12481, 12545, 12609, 12673, 12737, 12801, 12865, 12929, 12993, 13057, 13121, 13185, 13249, 13313, 13377, 13441, 13505, 13569, 13633, 13697, 13761, 13825, 13889, 13953, 14017, 14081, 14145, 14209, 14273, 14337, 14401, 14465, 14529, 14593, 14657, 14721, 14785, 14849, 14913, 14977, 15041, 15105, 15169, 15233, 15297, 15361, 15425, 15489, 15553, 15617, 15681, 15745, 15809, 15873, 15937, 16001, 16065, 16129, 16193, 16257, 16321, 16385, 16449, 16513, 16577, 16641, 16705, 16769, 16833, 16897, 16961, 17025, 17089, 17153, 17217, 17281, 17345, 17409, 17473, 17537, 17601, 17665, 17729, 17793, 17857, 17921, 17985, 18049, 18113, 18177, 18241, 18305, 18369, 18433, 18497, 18561, 18625, 18689, 18753, 18817, 18881, 18945, 19009, 19073, 19137, 19201, 19265, 19329, 19393, 19457, 19521, 19585, 19649, 19713, 19777, 19841, 19905, 19969, 20033, 20097, 20161, 20225, 20289, 20353, 20417, 20481, 20545, 20609, 20673, 20737, 20801, 20865, 20929, 20993, 21057, 21121, 21185, 21249, 21313, 21377, 21441, 21505, 21569, 21633, 21697, 21761, 21825, 21889, 21953, 22017, 22081, 22145, 22209, 22273, 22337, 22401, 22465, 22529, 22593, 22657, 22721, 22785, 22849, 22913, 22977, 23041, 23105, 23169, 23233, 23297, 23361, 23425, 23489, 23553, 23617, 23681, 23745, 23809, 23873, 23937, 24001, 24065, 24129, 24193, 24257, 24321, 24385, 24449, 24513, 24577, 24641, 24705, 24769, 24833, 24897, 24961, 25025, 25089, 25153, 25217, 25281, 25345, 25409, 25473, 25537, 25601, 25665, 25729, 25793, 25857, 25921, 25985, 26049, 26113, 26177, 26241, 26305, 26369, 26433, 26497, 26561, 26625, 26689, 26753, 26817, 26881, 26945, 27009, 27073, 27137, 27201, 27265, 27329, 27393, 27457, 27521, 27585, 27649, 27713, 27777, 27841, 27905, 27969, 28033, 28097, 28161, 28225, 28289, 28353, 28417, 28481, 28545, 28609, 28673, 28737, 28801, 28865, 28929, 28993, 29057, 29121, 29185, 29249, 29313, 29377, 29441, 29505, 29569, 29633, 29697, 29761, 29825, 29889, 29953, 30017, 30081, 30145, 30209, 30273, 30337, 30401, 30465, 30529, 30593, 30657, 30721, 30785, 30849, 30913, 30977, 31041, 31105, 31169, 31233, 31297, 31361, 31425, 31489, 31553, 31617, 31681, 31745, 31809, 31873, 31937, 32001, 32065, 32129, 32193, 32257, 32321, 32385, 32449, 32513, 32577, 32641, 32705, 32769, 32833, 32897, 32961, 33025, 33089]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.682583252895753, 0.7848998552123552, 0.8154862451737451, 0.823871862934363, 0.8351532335907336, 0.838531611969112, 0.8439611486486487, 0.8454391891891891, 0.8443532818532818, 0.8474601833976834, 0.8517434845559846, 0.8527992277992278, 0.8534930019305019, 0.8545789092664092, 0.8536438223938224, 0.8558458011583011, 0.8557251447876448, 0.8581081081081081, 0.8593448359073359, 0.8613055019305019, 0.8607625482625483, 0.8619087837837838, 0.8626930501930502, 0.86652388996139, 0.8641710907335908, 0.8649855212355212, 0.8659809362934363, 0.868846525096525, 0.8675494691119691, 0.8706865347490348]\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
    "[0.682583252895753, 0.7848998552123552, 0.8154862451737451, 0.823871862934363, 0.8351532335907336, 0.838531611969112, 0.8439611486486487, 0.8454391891891891, 0.8443532818532818, 0.8474601833976834, 0.8517434845559846, 0.8527992277992278, 0.8534930019305019, 0.8545789092664092, 0.8536438223938224, 0.8558458011583011, 0.8557251447876448, 0.8581081081081081, 0.8593448359073359, 0.8613055019305019, 0.8607625482625483, 0.8619087837837838, 0.8626930501930502, 0.86652388996139, 0.8641710907335908, 0.8649855212355212, 0.8659809362934363, 0.868846525096525, 0.8675494691119691, 0.8706865347490348]\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sd = [0.5181587837837838, 0.5230755308880309, 0.5339346042471043, 0.5334218146718147, 0.5387910231660231, 0.5470258204633205, 0.5545668436293436, 0.567386583011583, 0.5835847007722008, 0.6008083976833977, 0.619449806949807, 0.6399915540540541, 0.6607142857142857, 0.6763694498069498, 0.6886763996138996, 0.699867277992278, 0.7165178571428571, 0.7225808397683398, 0.7372104247104247, 0.7440878378378378, 0.753921332046332, 0.7609797297297297, 0.7618544884169884, 0.7700289575289575, 0.7795004826254827, 0.783210666023166, 0.7914152992277992, 0.7912946428571429, 0.800132722007722, 0.8066180019305019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
    "single_patch = [0.6778692455242967, 0.8157968350383632, 0.8419117647058824, 0.8459079283887468, 0.853360773657289, 0.8519421355498721, 0.853420716112532, 0.8556385869565217, 0.8560382033248082, 0.8580962276214834, 0.8550591432225064, 0.858196131713555, 0.85775655370844, 0.8592750959079284, 0.8586556905370843, 0.8573569373401535, 0.8583559782608695, 0.8637108375959079, 0.8586157289002557, 0.8654092071611253, 0.8638507033248082, 0.8644701086956522, 0.8628316815856778, 0.8632712595907929, 0.8638906649616368, 0.8634510869565217, 0.8638706841432225, 0.8648297634271099, 0.8664082480818415, 0.866628037084399]\n",
    "accuracy_patch = [0.682583252895753, 0.7848998552123552, 0.8154862451737451, 0.823871862934363, 0.8351532335907336, 0.838531611969112, 0.8439611486486487, 0.8454391891891891, 0.8443532818532818, 0.8474601833976834, 0.8517434845559846, 0.8527992277992278, 0.8534930019305019, 0.8545789092664092, 0.8536438223938224, 0.8558458011583011, 0.8557251447876448, 0.8581081081081081, 0.8593448359073359, 0.8613055019305019, 0.8607625482625483, 0.8619087837837838, 0.8626930501930502, 0.86652388996139, 0.8641710907335908, 0.8649855212355212, 0.8659809362934363, 0.868846525096525, 0.8675494691119691, 0.8706865347490348]\n",
    "accuracy_patch_honest = [0.5964508642765685, 0.685759443021767, 0.7221510883482715, 0.7329745518565941, 0.7377560819462228, 0.7417373559539052, 0.7426176376440461, 0.7411371638924455, 0.7472391165172856, 0.7490196862996159, 0.7513404289372599, 0.751280409731114, 0.7525808258642765, 0.7539412612035852, 0.7538012163892446, 0.7568221830985915, 0.7538012163892446, 0.7589828745198464, 0.7596830985915493, 0.7593629961587708, 0.7561219590268886, 0.7599631882202305, 0.7578625160051217, 0.7599631882202305, 0.7632842509603073, 0.765685019206146, 0.7645646606914213, 0.7671854993597952, 0.7670454545454546, 0.7695062419974392]\n",
    "accuracy_sd = [0.5181587837837838, 0.5230755308880309, 0.5339346042471043, 0.5334218146718147, 0.5387910231660231, 0.5470258204633205, 0.5545668436293436, 0.567386583011583, 0.5835847007722008, 0.6008083976833977, 0.619449806949807, 0.6399915540540541, 0.6607142857142857, 0.6763694498069498, 0.6886763996138996, 0.699867277992278, 0.7165178571428571, 0.7225808397683398, 0.7372104247104247, 0.7440878378378378, 0.753921332046332, 0.7609797297297297, 0.7618544884169884, 0.7700289575289575, 0.7795004826254827, 0.783210666023166, 0.7914152992277992, 0.7912946428571429, 0.800132722007722, 0.8066180019305019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_graph(1, training_size_sd_plot, accuracy_patch, accuracy_sd, \"Accuracy\", \"Patch\", \"SD Image\", 33000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = [0.57999999999999996, 0.57999999999999996, 0.52000000000000002, 0.44, 0.52000000000000002, 0.44, 0.52000000000000002, 0.59999999999999998, 0.47999999999999998, 0.52000000000000002, 0.5, 0.57999999999999996, 0.52000000000000002, 0.59999999999999998, 0.56000000000000005, 0.54000000000000004, 0.62, 0.5, 0.52000000000000002, 0.56000000000000005, 0.5, 0.59999999999999998, 0.40000000000000002, 0.62, 0.35999999999999999, 0.47999999999999998, 0.46000000000000002, 0.35999999999999999, 0.5, 0.57999999999999996, 0.54000000000000004, 0.38, 0.35999999999999999, 0.44, 0.62, 0.54000000000000004, 0.52000000000000002, 0.56000000000000005, 0.47999999999999998, 0.68000000000000005, 0.52000000000000002, 0.5, 0.59999999999999998, 0.46000000000000002, 0.54000000000000004, 0.44, 0.41999999999999998, 0.54000000000000004, 0.46000000000000002, 0.38, 0.52000000000000002, 0.47999999999999998, 0.54000000000000004, 0.57999999999999996, 0.40000000000000002, 0.40000000000000002, 0.40000000000000002, 0.57999999999999996, 0.41999999999999998, 0.38, 0.46000000000000002, 0.44, 0.5, 0.40000000000000002, 0.40000000000000002, 0.56000000000000005, 0.52000000000000002, 0.44, 0.47999999999999998, 0.35999999999999999, 0.40000000000000002, 0.64000000000000001, 0.69999999999999996, 0.71999999999999997, 0.83999999999999997, 0.69999999999999996, 0.85999999999999999, 0.76000000000000001, 0.76000000000000001, 0.62, 0.83999999999999997, 0.69999999999999996, 0.80000000000000004, 0.73999999999999999, 0.83999999999999997, 0.80000000000000004, 0.81999999999999995, 0.73999999999999999, 0.73999999999999999, 0.78000000000000003, 0.81999999999999995, 0.85999999999999999, 0.81999999999999995, 0.76000000000000001, 0.83999999999999997, 0.83999999999999997, 0.78000000000000003, 0.71999999999999997, 0.88, 0.78000000000000003, 0.76000000000000001, 0.80000000000000004, 0.83999999999999997, 0.88, 0.85999999999999999, 0.78000000000000003, 0.78000000000000003, 0.80000000000000004, 0.80000000000000004, 0.83999999999999997, 0.78000000000000003, 0.80000000000000004, 0.90000000000000002, 0.83999999999999997, 0.92000000000000004, 0.80000000000000004, 0.78000000000000003, 0.80000000000000004, 0.85999999999999999, 0.78000000000000003, 0.90000000000000002, 0.90000000000000002, 0.85999999999999999, 0.90000000000000002, 0.90000000000000002, 0.90000000000000002, 0.78000000000000003, 0.83999999999999997, 0.88, 0.92000000000000004, 0.81999999999999995, 0.93999999999999995, 0.81999999999999995, 0.83999999999999997, 0.81999999999999995, 0.85999999999999999, 0.88, 0.73999999999999999, 0.78000000000000003, 0.88, 0.81999999999999995, 0.85999999999999999, 0.85999999999999999, 0.83999999999999997, 0.83999999999999997, 0.81999999999999995, 0.76000000000000001, 0.80000000000000004, 0.80000000000000004, 0.88, 0.80000000000000004, 0.88, 0.83999999999999997, 0.85999999999999999, 0.81999999999999995, 0.81999999999999995, 0.92000000000000004, 0.81999999999999995, 0.83999999999999997, 0.83999999999999997, 0.76000000000000001, 0.93999999999999995, 0.83999999999999997, 0.81999999999999995, 0.81999999999999995, 0.80000000000000004, 0.76000000000000001, 0.90000000000000002, 0.76000000000000001, 0.78000000000000003, 0.80000000000000004, 0.83999999999999997, 0.81999999999999995, 0.85999999999999999, 0.88, 0.85999999999999999, 0.92000000000000004, 0.81999999999999995, 0.83999999999999997, 0.85999999999999999, 0.81999999999999995, 0.90000000000000002, 0.88, 0.83999999999999997, 0.88, 0.83999999999999997, 0.90000000000000002, 0.80000000000000004, 0.88, 0.78000000000000003, 0.76000000000000001, 0.90000000000000002, 0.90000000000000002, 0.85999999999999999, 0.83999999999999997, 0.85999999999999999, 0.88, 0.85999999999999999, 0.90000000000000002, 0.85999999999999999]\n",
    "train_size = [25051, 125051, 225051, 325051, 425051, 525051, 625051, 725051, 825051, 925051, 1025101, 1125101, 1225101, 1325101, 1425101, 1525101, 1625101, 1725101, 1825101, 1925101, 2025151, 2125151, 2225151, 2325151, 2425151, 2525151, 2625151, 2725151, 2825151, 2925151, 3025201, 3125201, 3225201, 3325201, 3425201, 3525201, 3625201, 3725201, 3825201, 3925201, 4025251, 4125251, 4225251, 4325251, 4425251, 4525251, 4625251, 4725251, 4825251, 4925251, 5025301, 5125301, 5225301, 5325301, 5425301, 5525301, 5625301, 5725301, 5825301, 5925301, 6025351, 6125351, 6225351, 6325351, 6425351, 6525351, 6625351, 6725351, 6825351, 6925351, 7025401, 7125401, 7225401, 7325401, 7425401, 7525401, 7625401, 7725401, 7825401, 7925401, 8025451, 8125451, 8225451, 8325451, 8425451, 8525451, 8625451, 8725451, 8825451, 8925451, 9025501, 9125501, 9225501, 9325501, 9425501, 9525501, 9625501, 9725501, 9825501, 9925501, 10025551, 10125551, 10225551, 10325551, 10425551, 10525551, 10625551, 10725551, 10825551, 10925551, 11025601, 11125601, 11225601, 11325601, 11425601, 11525601, 11625601, 11725601, 11825601, 11925601, 12025651, 12125651, 12225651, 12325651, 12425651, 12525651, 12625651, 12725651, 12825651, 12925651, 13025701, 13125701, 13225701, 13325701, 13425701, 13525701, 13625701, 13725701, 13825701, 13925701, 14025751, 14125751, 14225751, 14325751, 14425751, 14525751, 14625751, 14725751, 14825751, 14925751, 15025801, 15125801, 15225801, 15325801, 15425801, 15525801, 15625801, 15725801, 15825801, 15925801, 16025851, 16125851, 16225851, 16325851, 16425851, 16525851, 16625851, 16725851, 16825851, 16925851, 17025901, 17125901, 17225901, 17325901, 17425901, 17525901, 17625901, 17725901, 17825901, 17925901, 18025951, 18125951, 18225951, 18325951, 18425951, 18525951, 18625951, 18725951, 18825951, 18925951, 19026001, 19126001, 19226001, 19326001, 19426001, 19526001, 19626001, 19726001, 19826001, 19926001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc= [0.82, 0.8, 0.88, 0.86, 0.88, 0.9]\n",
    "train_size = [100001, 200001, 300001, 400001, 500001, 600001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plt.figure(1,figsize=(7,5))\n",
    "#     plt.plot(epochs,accuracy_patch)\n",
    "#     plt.plot(epochs, single_patch)\n",
    "#     plt.plot(epochs,accuracy_patch_honest)\n",
    "    plt.plot(train_size,train_acc)    \n",
    "    plt.xlabel('Training Size')\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"SR Image\" + '( Samples:' + str(700000) + ')')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['700k SR(60x60, 5 patch size)'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
