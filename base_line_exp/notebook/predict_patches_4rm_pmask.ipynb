{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "import cv2, os, math, time\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle\n",
    "from numpy.lib.stride_tricks import as_strided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configuration\n",
    "\"\"\"\n",
    "Data Configurations/Paths\n",
    "\"\"\"\n",
    "img_dir=\"../../original_images/SD\"\n",
    "img_lbls=\"\"\n",
    "base_model = 'SD/sd_01_.ckpt'\n",
    "model_20000 = 'SD/sd_20000.ckpt'\n",
    "model_30000 = 'SD/sd_30000.ckpt'\n",
    "model_40000 = 'SD/sd_40000.ckpt'\n",
    "model_50000 = 'SD/sd_50000.ckpt'\n",
    "model2_50000 = 'SD/sd2_50000.ckpt' #this model takes a 10x10 predicted mask from model:1 and predicts an image which combines all the patches.\n",
    "\n",
    "connected_model = 'SD/sd_conected.ckpt'\n",
    "\n",
    "##\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 4          # Convolution filters are 4 x 4 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# filter_size1 = 16          # Convolution filters are 4 x 4 pixels.\n",
    "# num_filters1 = 64         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 8          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters2 = 64         # There are 32 of these filters.\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 8          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters3 = 64         # There are 64 of these filters.\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size4 = 4          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters4 = 32         # There are 128 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 2000             # Number of neurons in fully-connected layer.\n",
    "\n",
    "# We know that images are 60 pixels in each dimension.\n",
    "# img_size = 8 * 4\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 10 * 10\n",
    "\n",
    "# Number of colour channels for the images: 3 channel for RGB.\n",
    "num_channels = 1\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (10, 10, num_channels)\n",
    "\n",
    "# Number of classes, one class for same or different image\n",
    "num_classes = 4*2\n",
    "patch_size = (2, 2, 3)\n",
    "npatches = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_dir):\n",
    "        list_of_orig_imgs = []\n",
    "        list_of_pred_imgs = []\n",
    "        list_of_labels = []\n",
    "        list_same_diff = []\n",
    "        list_img_keys = []\n",
    "        for img in os.listdir(img_dir):\n",
    "            \n",
    "            img_path = os.path.join(img_dir, img)\n",
    "            list_same_diff.append(int(os.listdir(img_path)[0]))\n",
    "            list_img_keys.append(img)\n",
    "            img_path = img_path + \"/\" + os.listdir(img_path)[0]\n",
    "            for img_label in os.listdir(img_path):\n",
    "                img_data = os.path.join(img_path, img_label)\n",
    "                if img_label == \"img\":\n",
    "#                     print(img_data + \"/img.png\")\n",
    "                    list_of_orig_imgs.append(img_data + \"/img.png\")\n",
    "                    list_of_pred_imgs.append(img_data + \"/predicted_mask.png\")\n",
    "                else:\n",
    "                    list_of_labels.append([os.path.join(img_data, label) for label in os.listdir(img_data)])\n",
    "\n",
    "        data_imgs = np.array([list_of_orig_imgs, list_of_pred_imgs])\n",
    "        data_labels = np.array(list_of_labels)\n",
    "        data_same_diff = np.array(list_same_diff)\n",
    "        data_img_keys = np.array(list_img_keys)\n",
    "\n",
    "        return data_imgs, data_labels, data_same_diff, data_img_keys\n",
    "\n",
    "    \n",
    "def get_batch_images(data_orig, data_pred, label, same_diff, img_keys, rshp, grey_scale):\n",
    "        list_of_orig_imgs = []\n",
    "        list_of_pred_imgs = []\n",
    "        list_of_labels = []\n",
    "        list_of_same_diff = []\n",
    "        list_of_img_keys = []\n",
    "        for img_orig, img_pred, lbl, img_type, img_key in zip(data_orig, data_pred, label, same_diff, img_keys):\n",
    "            if (grey_scale):\n",
    "                orig_img = cv2.imread(img_orig)\n",
    "                predicted_msk = cv2.imread(img_pred, cv2.IMREAD_GRAYSCALE)\n",
    "            else:\n",
    "                orig_img = cv2.imread(img[0])\n",
    "                \n",
    "            orig_lbl = cv2.imread(lbl)\n",
    "            if orig_img is None or orig_lbl is None:\n",
    "                    print (\"Unable to read image{} or {}\".format(img[0], lbl))\n",
    "                    continue\n",
    "            \n",
    "            if (grey_scale):\n",
    "                orig_lbl = rgb2grey(orig_lbl)\n",
    "\n",
    "            flattened_orig_img = orig_img.flatten()\n",
    "            flattened_pred_img = predicted_msk.flatten()\n",
    "            flattened_lbl = orig_lbl.flatten()\n",
    "            \n",
    "            if grey_scale:\n",
    "                flattened_lbl = np.reshape(flattened_lbl, [4, 2])\n",
    "#                 print(flattened_lbl)\n",
    "#                 flattened_lbl = normalize(flattened_lbl)\n",
    "#                 print(flattened_lbl)\n",
    "            \n",
    "            list_of_orig_imgs.append(np.asarray(flattened_orig_img, dtype=np.float32))\n",
    "            list_of_pred_imgs.append(np.asarray(flattened_pred_img, dtype=np.float32))\n",
    "        \n",
    "            list_of_labels.append(np.asarray(flattened_lbl, dtype=np.float32))\n",
    "            list_of_same_diff.append(img_type)\n",
    "            list_of_img_keys.append(img_key)\n",
    "\n",
    "        data_labels = np.array(list_of_labels)\n",
    "#         print(data_labels.shape)\n",
    "#         print(rshp)\n",
    "#         reshaped_labels = np.reshape(data_labels, rshp)\n",
    "#         data_labels = np.squeeze(reshaped_labels[:, :, :1])\n",
    "        data_imgs = np.array([list_of_orig_imgs, list_of_pred_imgs])\n",
    "        data_img_type = np.array(list_of_same_diff)\n",
    "        data_img_keys = np.array(list_of_img_keys)\n",
    "        \n",
    "        return data_imgs, data_labels, data_img_type, data_img_keys\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_orig = data[0, :]\n",
    "    data_pred = data[1, :]\n",
    "    data_orig_shuffle = [data[0, i] for i in idx]\n",
    "    data_pred_shuffle = [data[1, i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_orig_shuffle), np.asarray(data_pred_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "def rgb2grey(rgb):\n",
    "    return(np.dot(rgb[...,:3], [0.299, 0.587, 0.114]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape, layer_name):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape), name=layer_name+'_W')\n",
    "\n",
    "def new_bias(length, layer_name):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]), name=layer_name+'_b')\n",
    "\n",
    "def new_conv_layer(input,\n",
    "                   num_input_channels,\n",
    "                   filter_size,\n",
    "                   num_filters,\n",
    "                   name_scope,\n",
    "                   layer_name='',\n",
    "                   use_pooling=True):\n",
    "\n",
    "    with tf.name_scope(name_scope):\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "        weights = new_weights(shape, layer_name)\n",
    "        biases = new_bias(num_filters, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.nn.conv2d(input=input, filter=weights, strides=[1,1,1,1], padding='SAME'), biases, name=layer_name)\n",
    "\n",
    "        if use_pooling:\n",
    "            layer = tf.nn.max_pool(value=layer,\n",
    "                                   ksize=[1, 3, 3, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME', name=layer_name+'_max')\n",
    "            \n",
    "        layer = tf.nn.relu(layer, name=layer_name+'_activation')\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "def flatten_layer(layer, flag=False):\n",
    "    layer_shape = layer.get_shape()\n",
    "    if flag is True:\n",
    "        num_features = layer_shape.num_elements()\n",
    "        layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    else:\n",
    "        num_features = layer_shape[1:4].num_elements()\n",
    "        layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                name_scope,\n",
    "                layer_name='',\n",
    "                use_relu=True):\n",
    "    \n",
    "    with tf.name_scope(name_scope):\n",
    "        weights = new_weights([num_inputs, num_outputs], layer_name)\n",
    "        biases = new_bias(num_outputs, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.matmul(input, weights),biases,name=layer_name)\n",
    "    #     layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer, layer_name+'_activation')\n",
    "    \n",
    "    return layer\n",
    "\n",
    "\n",
    "def normalise_tensor(tensor):\n",
    "    return tf.div(\n",
    "   tf.subtract(\n",
    "      tensor, \n",
    "      tf.reduce_min(tensor)\n",
    "   ), \n",
    "   tf.subtract(\n",
    "      tf.reduce_max(tensor), \n",
    "      tf.reduce_min(tensor)\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_o = tf.placeholder(tf.float32, shape=[None, img_size_flat*3], name='x_orig')\n",
    "x_p = tf.placeholder(tf.float32, shape=[None, img_size_flat*num_channels], name='x_pred')\n",
    "\n",
    "x_orig_image = tf.reshape(x_o, [-1, 10, 10, 3])\n",
    "x_pred_image = tf.reshape(x_p, [-1, 10, 10, num_channels])\n",
    "\n",
    "dims = tf.constant([2,2])\n",
    "k = tf.constant(npatches)\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 4, 2], name='y_true')\n",
    "# y_true_cls = tf.argmax(y_true, axis=1)\n",
    "y_true_cls = tf.placeholder(tf.float32, shape=[None, 4, 2], name='y_true_cls')\n",
    "# x_image.shape, y_true\n",
    "\n",
    "# input = tf.placeholder(tf.float32, [None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_custom_layer(input,\n",
    "                     orig_img,\n",
    "                     dims_, \n",
    "                     k_,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                name_scope,\n",
    "                layer_name='',\n",
    "                use_relu=True):\n",
    "    \n",
    "    with tf.name_scope(name_scope):\n",
    "\n",
    "        resh_inp = tf.reshape(input, [-1, 10, 10])\n",
    "        input_shape = tf.shape(resh_inp)\n",
    "        print(resh_inp.get_shape())\n",
    "        rows, cols = input_shape[1], input_shape[2]\n",
    "        d_rows, d_cols = 2, 2\n",
    "        subm_rows, subm_cols = rows - d_rows + 1, cols - d_cols + 1\n",
    "# #         # Index grids\n",
    "        ii, jj = tf.meshgrid(tf.range(subm_rows), tf.range(subm_cols), indexing='ij')\n",
    "        d_ii, d_jj = tf.meshgrid(tf.range(d_rows), tf.range(d_cols), indexing='ij')\n",
    "        \n",
    "#         # Add indices\n",
    "        subm_ii = ii[:, :, tf.newaxis, tf.newaxis] + d_ii\n",
    "        subm_jj = jj[:, :, tf.newaxis, tf.newaxis] + d_jj\n",
    "#         # Make submatrices tensor\n",
    "        subm = tf.gather_nd(resh_inp[0, :, :], tf.stack([subm_ii, subm_jj], axis=-1), name=layer_name + \"_gather\")\n",
    "#         # Add submatrices\n",
    "        subm_sum = tf.reduce_sum(subm, axis=(2, 3), name=layer_name + \"_subm_sum\")\n",
    "#         # Use TopK to find top submatrices\n",
    "        _, top_idx = tf.nn.top_k(tf.reshape(subm_sum, [-1]), tf.minimum(k, tf.size(subm_sum)), name=layer_name + \"_top_idx\")\n",
    "#         # Get row and column\n",
    "        top_row = top_idx // subm_cols\n",
    "        top_col = top_idx % subm_cols\n",
    "        result = tf.stack([top_row, top_col], axis=-1, name=layer_name + \"_result\")\n",
    "  \n",
    "        patches = tf.map_fn(lambda x: tf.cast(resh_inp[:, x[0]:x[0] + patch_size[0], x[1]:x[1] + patch_size[1]], dtype=tf.float32), result, dtype=tf.float32)\n",
    "        print(patches)\n",
    "        patch_shape = tf.shape(patches)\n",
    "#         patch_shape = patches.get_shape()\n",
    "        comb_patches = tf.reshape(patches, [-1, patch_shape[1], patch_shape[2]* patch_shape[3], patch_shape[3]], name=layer_name + \"_comb_patches\")\n",
    "\n",
    "#         patches = tf.squeeze(tf.map_fn(lambda x: tf.cast(orig_img[:, x[0]:x[0] + patch_size[0], x[1]:x[1] + patch_size[1], :], dtype=tf.float32), result, dtype=tf.float32))\n",
    "#         patch_shape = tf.shape(patches)\n",
    "#         comb_patches = tf.reshape(patches, [-1, patch_shape[0] * patch_shape[1], patch_shape[2], patch_shape[3]], name=layer_name + \"_comb_patches\")\n",
    "    \n",
    "    return comb_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10, 10)\n",
      "Tensor(\"custom_2/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?, ?, ?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer1_conv1, weights_conv1 = new_conv_layer(input=x_pred_image,\n",
    "                                            num_input_channels=num_channels,\n",
    "                                            filter_size=filter_size1,\n",
    "                                            num_filters=num_filters1,\n",
    "                                             name_scope = 'cv',\n",
    "                                             layer_name='conv1',\n",
    "                                            use_pooling=True)\n",
    "\n",
    "# layer2_conv2, weights_conv2 =  new_conv_layer(input=layer1_conv1,\n",
    "#                                            num_input_channels=num_filters1,\n",
    "#                                            filter_size=filter_size2,\n",
    "#                                            num_filters=num_filters2,\n",
    "#                                              name_scope = 'cv',\n",
    "#                                              layer_name='conv2',\n",
    "#                                            use_pooling=True)\n",
    "\n",
    "# layer3_conv3, weights_conv3 =  new_conv_layer(input=layer2_conv2,\n",
    "#                                            num_input_channels=num_filters2,\n",
    "#                                            filter_size=filter_size3,\n",
    "#                                            num_filters=num_filters3,\n",
    "#                                              name_scope = 'cv',\n",
    "#                                              layer_name='conv3',\n",
    "#                                            use_pooling=True)\n",
    "\n",
    "# layer4_conv4, weights_conv4 =  new_conv_layer(input=layer3_conv3,\n",
    "#                                            num_input_channels=num_filters3,\n",
    "#                                            filter_size=filter_size4,\n",
    "#                                            num_filters=num_filters4,\n",
    "#                                              name_scope = 'cv',\n",
    "#                                              layer_name='conv4',\n",
    "#                                            use_pooling=True)\n",
    "\n",
    "\n",
    "layer_flat, num_features = flatten_layer(layer1_conv1)\n",
    "\n",
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=img_size_flat,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc_1',\n",
    "                         use_relu=False)\n",
    "\n",
    "\n",
    "# layer_fc2 = normalise_tensor(layer_fc1)\n",
    "\n",
    "# layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "#                          num_inputs=num_classes,\n",
    "#                          num_outputs=num_classes,\n",
    "#                          name_scope = 'fc',\n",
    "#                          layer_name = 'fc3',\n",
    "#                          use_relu=False)\n",
    "\n",
    "layer_fc3 = new_custom_layer(input=layer_fc1,\n",
    "                             orig_img = x_orig_image,\n",
    "                             dims_=dims, \n",
    "                             k_=k,\n",
    "                         num_inputs=img_size_flat,\n",
    "                         num_outputs=num_classes,\n",
    "                         name_scope = 'custom',\n",
    "                         layer_name = 'custom_1',\n",
    "                         use_relu=False)\n",
    "\n",
    "# layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "#                          num_inputs=num_classes,\n",
    "#                          num_outputs=num_classes,\n",
    "#                          name_scope = 'fc',\n",
    "#                          layer_name = 'fc2',\n",
    "#                          use_relu=False)\n",
    "\n",
    "\n",
    "# print(layer_fc2)\n",
    "y_pred_cls = layer_fc3\n",
    "# print(y_pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(y_true - y_pred_cls))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "# ## some more performance measures\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "session = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "train_labels = train_labels[:][:, 0]\n",
    "train_orig_data = train_data[0, :]\n",
    "train_pred_data = train_data[1, :]\n",
    "img_type = img_type[:]\n",
    "img_keys = img_keys[:]\n",
    "total_imgs = len(img_type)\n",
    "train_batch_size = 64\n",
    "\n",
    "def optimize(num_epochs, save_model=True,save_name= \"base_model\",restore_model=False,restore_name=None):\n",
    "    total_iterations = 0\n",
    "    done_train_imgs = 0\n",
    "    start_time = time.time()\n",
    "    start_ = 0\n",
    "    end_ = train_batch_size    \n",
    "    plot_accuracy=[]\n",
    "    plot_accuracy_epoch=[]\n",
    "    plot_training_size=[]\n",
    "    plot_training_size_epoch=[]\n",
    "    saver = tf.train.Saver()\n",
    "    sum_accuracy = 0.0\n",
    "    n = 1\n",
    "    \n",
    "        #to save the model\n",
    "    for i in range(0, num_epochs):   \n",
    "        start_batch=0\n",
    "        end_batch = train_batch_size\n",
    "        \n",
    "        print(\"Epoch:\", i + 1)\n",
    "        \n",
    "        if restore_model==True:\n",
    "            if restore_name==None:\n",
    "                print(\"No model file specified\")\n",
    "                return\n",
    "            else:\n",
    "                saver.restore(session,restore_name)\n",
    "        \n",
    "        sum_accuracy = 0.0\n",
    "        n = 1\n",
    "        while end_batch < total_imgs:\n",
    "            train_orig = train_orig_data[start_batch:end_batch]\n",
    "            train_pred = train_pred_data[start_batch:end_batch]\n",
    "            labels = train_labels[start_batch:end_batch]\n",
    "            img_type_lbl = img_type[start_:end_]\n",
    "            img_key = img_keys[start_:end_]\n",
    "            dims = (len(train_orig), num_classes, num_channels)\n",
    "            train, labels, img_type_lbl, img_key = get_batch_images(train_orig, train_pred, labels, img_type_lbl, img_key, dims, True)\n",
    "            if not len(train) and not len(labels):\n",
    "                print(\"All images have been processed.\")\n",
    "                break;\n",
    "\n",
    "            x_orig_batch, x_pred_batch, y_true_batch = next_batch(len(train[0]), train, labels)\n",
    "            feed_dict_train = {x_o: x_orig_batch, x_p: x_pred_batch,\n",
    "                       y_true: y_true_batch}\n",
    "            \n",
    "            session.run(optimizer, feed_dict=feed_dict_train)\n",
    "    \n",
    "            acc,co = session.run([accuracy, cost], feed_dict=feed_dict_train)\n",
    "            sum_accuracy += acc\n",
    "            n+=1\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "            print(msg.format(end_batch + 1, acc, co))\n",
    "            if i == num_epochs - 1:\n",
    "                plot_accuracy.append(acc)\n",
    "                plot_training_size.append(end_batch + 1)\n",
    "\n",
    "            start_batch += train_batch_size\n",
    "            end_batch += train_batch_size\n",
    "    \n",
    "        if save_model==True:\n",
    "            if save_name==None:\n",
    "                print(\"No model specified, model not being saved\")\n",
    "                return\n",
    "            else:\n",
    "                save_path = saver.save(session, save_name)\n",
    "                restore_model = True\n",
    "                print(\"Model saved in file: %s\" % save_name)\n",
    "        plot_accuracy_epoch.append(sum_accuracy/n)\n",
    "        plot_training_size_epoch.append(i + 1)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))  \n",
    "    print(plot_accuracy)\n",
    "    print(plot_training_size)\n",
    "    print(plot_accuracy_epoch)\n",
    "    print(plot_training_size_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 17027.0312\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 15837.3887\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 16558.1055\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 18966.4199\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 17794.8184\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 16021.8604\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 16910.2422\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 16276.7617\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 16394.4277\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 15195.0664\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 15272.9844\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 16178.9863\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 14295.3047\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 15191.3223\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 14810.0039\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 15136.5508\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 16836.0547\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 13531.7773\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 14629.1777\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 15038.4746\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 16016.0098\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 15220.9336\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 14546.9980\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 15194.1826\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 15722.4170\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 14473.4854\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 12906.4922\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 13988.1797\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 13838.9297\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 13848.7109\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 13568.4170\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 12909.3867\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 13644.2354\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 14270.6963\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 14158.1924\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 13810.5723\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 12124.2617\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 13638.2988\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 13481.7324\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 12531.5801\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 11924.0879\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 12313.3379\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 12312.6777\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 12280.1621\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 13575.4395\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 11912.9902\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 11999.2061\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 11538.9619\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 11574.0762\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 11749.4961\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 12933.9717\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 11405.3115\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 12790.1221\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 11779.7266\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 11704.5703\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 11777.4551\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 12125.6006\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 10586.1133\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 10569.6807\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 10661.3457\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 11650.7266\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 10469.1641\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 11666.3145\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 11248.8809\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 10764.0713\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 9889.7031\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 9611.3213\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 10357.3594\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 10798.9844\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 10630.8926\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 10147.1709\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 9632.3604\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 10626.8125\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 9760.9287\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 9997.2480\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 9092.8828\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 9003.1270\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 9628.6045\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 10082.9062\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 10244.6328\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 9409.1738\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 9839.2500\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 9465.6562\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 9013.8809\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 9820.5293\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 9822.4170\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 9265.2441\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 8644.7881\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 8570.2432\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 9756.4941\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 9164.3945\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 8936.7891\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 9701.7129\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 9200.6797\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 8609.2734\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 8937.4863\n",
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 9140.1777\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 8792.5957\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 9290.1924\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 8446.6230\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 8655.1699\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 9043.3672\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 8087.5664\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 8620.4883\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 8359.2383\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 9056.5322\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 9106.5703\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 8865.2715\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 8671.3359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 8776.0791\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 8499.3047\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 8209.7070\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 8412.7891\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 7857.8291\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 8050.8169\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 8110.9033\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 7698.9951\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 7918.2168\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 8056.1548\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 8601.7129\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 8394.5322\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 8428.4668\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 7880.7886\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 7460.7373\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 9007.0127\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 7121.0195\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 8199.0703\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 8400.8145\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 7114.1060\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 7833.9399\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 7596.9180\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 7952.1924\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 7803.6685\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 8592.8398\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 7575.9209\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 8302.5566\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 8064.8569\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 7759.1953\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 8108.3799\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 7915.7988\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 7570.7451\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 7524.6338\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 7344.4277\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 8348.1748\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 7996.7432\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 7060.0586\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 8295.5967\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 8065.9282\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 7334.9385\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 7592.3960\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 7641.3584\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 7468.5469\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 8201.6367\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 8025.8340\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 8251.3223\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 7345.1445\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 7860.0898\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 7508.4912\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 8167.6719\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 7849.6143\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 7348.3452\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 7675.9082\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 7783.7715\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 7843.8604\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 6801.1133\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 7342.9136\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 8111.7422\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 7723.4834\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 8084.9600\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 8447.9014\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 6937.9292\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 7786.4424\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 7875.0283\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 8176.1562\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 7092.3276\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 7302.1357\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 8204.7266\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 7237.3096\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 7656.0400\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 7837.2637\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 7324.5840\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 7906.6270\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 6901.5166\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 7576.7715\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 6620.7158\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 7631.6533\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 6921.1733\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 7982.4502\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 7239.8281\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 7713.5000\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 7781.0938\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 7648.2964\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 7404.0200\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 7809.9082\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 6981.1768\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 7647.3555\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 8247.5186\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 7625.6768\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 7695.8457\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 7979.2129\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 7543.4688\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 7585.5176\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 7303.4912\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 7630.9707\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 7178.6670\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 7776.0586\n",
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 7398.6729\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 7565.1709\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 7793.3408\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 7978.2793\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 7647.7109\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 7569.3984\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 7383.1079\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 7542.9224\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 7353.8096\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 7553.0283\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 7796.3564\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 7731.5381\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 8397.6816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 7428.8398\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 7006.3569\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 7285.0303\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 7207.0625\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 7398.6826\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 7331.1216\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 7094.5894\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 7071.2646\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 7293.6084\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 7471.3711\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 7283.8926\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 7779.6426\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 8144.1680\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 7079.5234\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 7662.3550\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 7212.5586\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 7797.5586\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 7985.1470\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 7063.9697\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 7713.4463\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 7699.8140\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 7305.7607\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 7468.9312\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 7510.0742\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 7433.4863\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 7109.4570\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 7169.1436\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 7353.7310\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 7308.9160\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 6959.3652\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 7642.6250\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 6843.9004\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 7656.5947\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 7110.1338\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 6999.5693\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 7456.3086\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 7510.4473\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 7412.2100\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 7707.8511\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 7178.6855\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 8009.0488\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 7922.1943\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 6906.3110\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 7920.7490\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 7099.1250\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 7826.0854\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 7446.9512\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 7047.0796\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 7148.7612\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 7670.6284\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 7995.4287\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 6952.5459\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 7071.1948\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 7131.6758\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 6716.9756\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 7448.0732\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 6401.6318\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 7679.5264\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 7567.9546\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 7238.1240\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 7420.3125\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 7252.5737\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 7599.0391\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 7475.9863\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 7483.7305\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 7404.7446\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 7243.3335\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 7531.3984\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 7491.2734\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 7267.1582\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 7225.8711\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 7274.3096\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 8279.6309\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 7199.1270\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 7622.7031\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 6656.6982\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 7349.6592\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 7061.7900\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 7418.3389\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 7763.5625\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 7210.6582\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 8421.5225\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 7583.2207\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 6488.1719\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 7448.7402\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 7854.8086\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 7086.8667\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 7355.5205\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 7196.3438\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 7051.3623\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 7351.9814\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 7642.2480\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 6737.8604\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 7624.0488\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 7972.0244\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 7422.2500\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 7341.5972\n",
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 7911.5703\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 7437.5801\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 7669.6177\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 7403.1851\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 7346.8115\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 7564.8984\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 7432.3286\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 7862.7900\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 7262.9258\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 8050.1709\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 7504.3960\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 7247.8027\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 7207.7158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 6913.6431\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 7536.8037\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 7842.8745\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 7432.6846\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 7051.2500\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 7493.6572\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 7656.5049\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 7309.9575\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 7747.2217\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 7057.3193\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 7160.4082\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 7521.8105\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 7742.5078\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 7494.6846\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 6696.6357\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 7771.0103\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 7319.8242\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 6463.2202\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 7520.3740\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 8126.8105\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 7860.9331\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 7745.1577\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 7611.5479\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 7607.2485\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 6750.5576\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 7060.2368\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 7136.1997\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 7262.0557\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 7326.0693\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 7262.4551\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 7472.8071\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 7353.6606\n",
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 7742.3203\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 7489.1533\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 7715.9385\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 7277.5132\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 7443.8032\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 8185.0137\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 7237.9648\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 7419.7705\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 7215.5596\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 7726.2383\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 7206.2842\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 7627.7695\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 7523.5479\n",
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 7520.9746\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 7363.2334\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 7299.1201\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 7828.9546\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 7208.3921\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 7323.8213\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 7439.3828\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 7169.3530\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 6313.4121\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 7184.6562\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 7821.3809\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 7765.5728\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 7862.5039\n",
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 7023.8677\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 7277.2593\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 7479.5054\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 8199.9619\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 7563.0283\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 7499.8672\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 7527.1689\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 7543.7173\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 7901.2344\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 7098.9639\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 7379.7871\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 7905.2773\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 7573.1011\n",
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 8239.5430\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 7107.4336\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 7736.2363\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 7652.1504\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 7360.6475\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 7981.8247\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 7481.6079\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 8215.4961\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 7072.1377\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 7485.1875\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 7059.2061\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 6916.2920\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 7484.7861\n",
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 7378.3340\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 7717.9727\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 7011.7329\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 7620.5942\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 7340.8608\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 7439.0781\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 7384.8179\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 7434.2983\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 7610.3003\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 7434.9165\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 7431.5332\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 7787.6572\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 7060.4336\n",
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 7405.7383\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 6468.3926\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 7859.5049\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 7481.1587\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 6829.6074\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 7177.2393\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 6796.7832\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 7357.3447\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 7063.5117\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 7382.2178\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 7472.3989\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 7714.7402\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 7096.3408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 7938.8511\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 7395.7998\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 7402.4907\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 8322.7393\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 7438.3755\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 8029.9790\n",
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 7619.4570\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 7133.8745\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 8005.9766\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 7999.6836\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 6964.6543\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 7550.3076\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 7215.9639\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 7715.1826\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 7361.8965\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 7801.5059\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 7887.3232\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 6670.5054\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 8315.6777\n",
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 7222.6050\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 7582.7568\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 7435.7559\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 7159.9316\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 7010.6895\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 7453.5371\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 7085.3818\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 7247.5015\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 7841.6699\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 7910.4668\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 8061.3330\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 7607.2100\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 7010.0869\n",
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 7579.3203\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 7120.7852\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 7120.3003\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 8180.4561\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 7565.1523\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 7044.0068\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 7018.7598\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 7995.2314\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 6846.7339\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 7355.3535\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 7772.9697\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 7619.0635\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 7371.3794\n",
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 7801.7520\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 7670.9214\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 7544.8511\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 7827.6172\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 7795.7676\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 7177.1860\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 7662.6875\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 7273.4814\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 7402.7725\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 7636.3828\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 7094.5742\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 6833.0894\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 7149.9014\n",
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 7625.2412\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 7506.7627\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 7670.2559\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 7015.3931\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 7472.4624\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 7428.5806\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 7636.0029\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 7621.8921\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 6824.2412\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 7294.9092\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 6878.8486\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 7370.7021\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 7543.2363\n",
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 7402.6284\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 7239.0693\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 7417.3184\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 7541.4795\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 7416.3848\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 7018.7412\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 7662.4019\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 7349.1504\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 8211.9355\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 7486.8354\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 7607.3320\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 7589.3638\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 6947.3457\n",
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 6909.3301\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 8400.9844\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 7507.3677\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 7268.7739\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 7508.3760\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 8173.9316\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 7236.9150\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 7885.6436\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 7825.7451\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 7889.6519\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 7536.4180\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 6797.9258\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 7696.7925\n",
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 7711.2124\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 7498.4038\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 8298.0957\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 7450.0264\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 8115.5825\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 7892.9194\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 7660.5576\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 7237.9185\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 6917.0273\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 7584.2998\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 7465.3560\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 7403.2437\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 7100.2158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 7301.4146\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 7497.0410\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 7408.1729\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 7688.1714\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 7371.5273\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 7790.8574\n",
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 6902.9160\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 7444.1357\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 8252.0176\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 7409.9727\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 7270.3989\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 7858.0327\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 7336.8975\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 7451.5264\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 7646.8481\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 7554.7808\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 7078.3418\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 7965.6328\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 6788.7690\n",
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 7052.4419\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 7319.3672\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 7984.1328\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 7197.8560\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 7666.3184\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 7710.6758\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 6742.7485\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 7958.1885\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 8171.9565\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 7202.6655\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 7465.2681\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 7617.0908\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 7334.9106\n",
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 6850.8369\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 7207.6074\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 7863.0996\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 7359.6387\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 8017.7305\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 7684.3745\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 7315.0513\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 7025.7124\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 7635.3369\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 7555.2432\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 6765.9858\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 7820.5405\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 7581.2329\n",
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 6922.8486\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 8045.9814\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 7927.1660\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 7356.6362\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 7676.5942\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 7111.0479\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 7234.7437\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 7314.4316\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 7081.1943\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 7365.3604\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 7694.3145\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 7091.7114\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 7900.7075\n",
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 7113.5562\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 7269.8247\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 7415.3921\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 7386.0420\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 6881.9531\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 7672.9521\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 7269.7158\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 7121.2915\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 7407.5308\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 7356.2949\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 7941.5391\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 7193.7891\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 7898.2104\n",
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 7583.3940\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 7269.0342\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 7591.4814\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 7246.2314\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 7475.2344\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 7472.0688\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 7289.0825\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 7944.1719\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 7183.9688\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 7813.7871\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 6842.5264\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 6793.6782\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 7315.4399\n",
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 7783.4751\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 7260.9111\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 7455.3545\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 7214.8608\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 7187.6973\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 6958.1006\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 6579.1812\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 6620.2812\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 7162.4614\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 7955.5054\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 6947.5430\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 7364.9883\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 7600.5400\n",
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 7779.1499\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 8213.6201\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 7879.3745\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 7139.7734\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 7175.7910\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 7134.7378\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 7231.1733\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 7319.5439\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 7408.0010\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 7623.8931\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 7672.6274\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 7420.3525\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 7143.1948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 7774.4834\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 7768.2295\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 6963.5371\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 7925.6562\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 7211.6006\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 7416.4067\n",
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 7014.2368\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 7430.0684\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 7162.4316\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 7237.7671\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 7725.8750\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 7443.1270\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 7732.8462\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 7102.6650\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 7476.4199\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 7595.7520\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 7574.1714\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 6868.7876\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 7631.8262\n",
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 7277.2261\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 6797.9297\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 7792.9023\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 7462.9736\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 6842.2334\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 7252.9844\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 8027.9858\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 7598.0820\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 7555.6128\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 7507.7959\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 7912.1909\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 7426.1499\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 7848.3545\n",
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 7623.9170\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 7655.9521\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 7580.8232\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 7218.0894\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 7508.2012\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 7332.9014\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 7200.6260\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 7220.6338\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 7505.6943\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 7264.1768\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 7543.3887\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 7385.4795\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 7580.4141\n",
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 7765.0024\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 7331.1201\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 7385.5547\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 6748.7173\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 7230.9619\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 7319.1689\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 6967.7861\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 8096.6416\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 7337.2183\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 7166.8770\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 7964.1118\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 7505.3096\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 7837.9209\n",
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 7395.7124\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 7080.2915\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 7237.9209\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 7167.3945\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 7503.1436\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 8476.2598\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 7666.1064\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 7065.5132\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 7343.8467\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 7542.9229\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 7500.1699\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 7622.9209\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 8157.2720\n",
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 7530.3955\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 7789.0425\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 7877.8369\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 7069.2168\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 7476.0830\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 6904.2842\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 7590.8335\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 7526.4346\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 7241.6084\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 7549.3701\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 7252.2256\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 7023.0371\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 7737.1494\n",
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 6724.8740\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 7386.5796\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 7204.5410\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 7873.3682\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 6823.4116\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 7774.7686\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 7435.9590\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 7741.2539\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 7131.5752\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 7897.3555\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 7302.6494\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 6970.8574\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 7275.1279\n",
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 7302.4629\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 7662.1777\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 7280.2163\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 6962.3896\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 7480.6416\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 7251.1611\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 7377.6055\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 7359.9404\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 7631.1938\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 8280.6455\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 8017.9648\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 7222.9912\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 6970.0957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 7021.7832\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 7312.5127\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 6881.3433\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 7296.0938\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 7446.1079\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 7853.1924\n",
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 7103.4062\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 7479.0547\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 6959.7520\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 7647.8037\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 8066.2451\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 7129.5127\n",
      "Model saved in file: SD/sd2_50000.ckpt\n",
      "Epoch: 2\n",
      "INFO:tensorflow:Restoring parameters from SD/sd2_50000.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 7782.1304\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 7414.3525\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 7882.3267\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 7620.1992\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 7587.8584\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 7218.2749\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 6983.9668\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 7525.0391\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 7225.6772\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 7266.0034\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 7518.7241\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 7814.7861\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 6749.6504\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 7511.5459\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 7369.2095\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 6728.3945\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 7137.3076\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 7314.0850\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 7483.8950\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 7575.8174\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 7333.0234\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 7333.2480\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 8226.0859\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 7586.5918\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 7638.9746\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 6721.4331\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 7350.1455\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 7310.4028\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 6944.7002\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 7124.0117\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 7885.3643\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 7460.5449\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 7497.3613\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 7649.9629\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 7565.0410\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 6988.1475\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 7354.9082\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 7587.7744\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 7109.9346\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 7337.4927\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 6802.1885\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 6650.5127\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 7307.5244\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 8153.0767\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 7853.5342\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 7715.4707\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 7938.5317\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 6648.3369\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 7412.3086\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 6945.1113\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 7253.4844\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 7500.2139\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 7961.9521\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 7396.1357\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 7689.8633\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 7685.2964\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 7339.4922\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 7012.3984\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 7351.9648\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 7147.4917\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 7378.6528\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 7470.2622\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 7438.9849\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 7587.6973\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 7357.1064\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 7879.6455\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 7085.0752\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 7316.0127\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 7385.8799\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 7402.4141\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 7337.8823\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 7204.6670\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 7800.0820\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 7797.2300\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 7229.0693\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 7226.5361\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 7102.0605\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 7472.2700\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 7057.7974\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 6928.0767\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 7278.4634\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 7255.2168\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 7678.9160\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 7192.5059\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 7271.3877\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 7744.7993\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 7352.8984\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 7147.2930\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 7162.7100\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 7450.5054\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 7708.3647\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 7435.6978\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 7820.7490\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 7129.6133\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 6675.0547\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 7097.3770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 7241.9541\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 7575.8701\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 7485.4150\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 7341.1323\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 7252.7461\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 7777.4565\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 7577.3394\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 7112.4854\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 7460.5615\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 7676.7754\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 7349.1533\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 7938.4668\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 7556.2217\n",
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 7402.8774\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 7720.7793\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 7244.5879\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 7708.3462\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 7211.1411\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 7270.7490\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 6874.0938\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 7066.2422\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 6987.4150\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 7248.0322\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 7689.5449\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 7441.0264\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 7488.1064\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 7159.4463\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 6769.4629\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 7843.2148\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 6774.5005\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 7766.4453\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 7736.7188\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 6602.6553\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 7056.1885\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 7445.2002\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 7723.4990\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 7504.5166\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 7841.8389\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 6999.4922\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 8399.2773\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 7190.6909\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 7358.5176\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 7610.1504\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 7484.4736\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 7015.1704\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 7020.7178\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 6972.7769\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 7829.9419\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 7418.3784\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 7091.8599\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 8201.7363\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 7627.3135\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 6566.1665\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 7522.5044\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 7309.0654\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 7104.0186\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 7799.6973\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 7403.8301\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 7858.7876\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 7115.8184\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 7458.1553\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 7366.2974\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 7907.9551\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 7357.1055\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 7206.2178\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 7205.0884\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 7413.9922\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 7621.9697\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 6672.7383\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 7259.0859\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 7812.3545\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 7473.2070\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 7987.0801\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 8068.3560\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 7004.4355\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 7693.0654\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 7488.1353\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 8088.0977\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 6939.8716\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 7029.4941\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 8082.5518\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 7217.8496\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 7195.0801\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 7361.3345\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 7047.7012\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 7872.1792\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 7037.0791\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 7069.4707\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 6543.0220\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 7195.9170\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 6925.7568\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 7839.9307\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 7045.7520\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 7529.4072\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 7527.5771\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 7653.1118\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 7210.0117\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 7643.6973\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 6853.9580\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 7485.0659\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 7901.1318\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 7508.3311\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 7440.4458\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 7840.1104\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 7475.6035\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 7528.2212\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 7198.1201\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 7366.9287\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 7434.8486\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 7633.8760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 7406.6504\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 7335.1392\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 7379.4629\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 8040.0371\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 7669.4629\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 7419.7812\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 7372.7075\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 7383.7393\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 7349.4043\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 7605.7178\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 7569.1196\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 7738.4941\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 8037.0918\n",
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 7252.8232\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 6936.6738\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 7078.7896\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 7448.3901\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 7021.9014\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 7287.1660\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 7048.8125\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 7006.1758\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 7311.3765\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 7412.8594\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 6993.6548\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 7571.6646\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 8107.8555\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 7054.9653\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 7500.9600\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 7066.5591\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 7936.4639\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 7864.6396\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 6899.0034\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 7631.7109\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 7670.7202\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 7235.4038\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 6963.5977\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 7209.9219\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 7138.5537\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 6862.3760\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 7113.7183\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 7229.8574\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 7098.3262\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 6991.3101\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 7705.0537\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 6911.5376\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 7458.1426\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 7215.6016\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 6961.0537\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 7337.6562\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 7138.9307\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 7213.5449\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 7708.9780\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 7283.6948\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 7919.7578\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 7972.0869\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 6748.8594\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 7717.3330\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 7033.1079\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 7701.3467\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 7356.5889\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 7059.3828\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 7018.5273\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 7653.3193\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 7737.1719\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 6902.7046\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 7057.5732\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 6996.1558\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 6562.7822\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 7592.3789\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 6208.9346\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 7617.4224\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 7477.5771\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 7087.0752\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 7085.0020\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 6884.0039\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 7620.9810\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 7411.7539\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 7510.1064\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 7277.9121\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 7312.6592\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 7442.2188\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 7499.5723\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 7130.5034\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 7049.3555\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 7159.5112\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 8071.0850\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 7141.5547\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 7578.4053\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 6611.5020\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 7252.3672\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 6985.4395\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 7025.7144\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 7638.8979\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 7296.7554\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 8351.5039\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 7307.3613\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 6401.3462\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 7263.7852\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 7926.9814\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 6914.0596\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 7153.7188\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 7153.9238\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 7145.0874\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 7087.0933\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 7462.3584\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 6730.9473\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 7760.1904\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 7911.0229\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 7353.0044\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 7195.5176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 7715.0532\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 7400.0376\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 7435.6406\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 7377.5576\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 7309.7686\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 7547.6094\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 7318.4648\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 8001.8477\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 7267.7920\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 8032.8232\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 7635.9873\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 7229.9326\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 7113.5190\n",
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 6724.7080\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 7576.2373\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 7512.7393\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 7445.1470\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 6850.0977\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 7427.5703\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 7661.4609\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 7328.3018\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 7556.0249\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 6986.5562\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 7506.9067\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 7408.5913\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 7483.3726\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 7468.8037\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 6765.7837\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 7566.9727\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 7408.0137\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 6500.6128\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 7523.7559\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 7966.0010\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 7781.3721\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 7612.2812\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 7705.3711\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 7507.1406\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 6762.5181\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 6857.8965\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 7178.0391\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 7353.0469\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 7319.8862\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 7271.6074\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 7294.0811\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 7257.7461\n",
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 7164.7373\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 7222.6006\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 7714.2095\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 7254.8901\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 7334.2173\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 8165.5449\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 7120.0889\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 7338.5908\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 7061.8164\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 7730.9619\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 7240.6191\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 7334.8545\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 7305.1299\n",
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 7423.7988\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 7507.1396\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 7266.4307\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 7856.5518\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 7205.1621\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 7251.9839\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 7432.1621\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 7163.5654\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 6397.8022\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 6987.9121\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 7739.2290\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 7716.2314\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 7664.8252\n",
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 6978.2344\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 7395.1797\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 7482.2852\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 7800.1680\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 7506.8984\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 7360.0820\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 7387.5117\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 7544.8174\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 7740.3047\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 7041.6162\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 7316.3462\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 7884.2275\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 7392.2090\n",
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 8092.7168\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 7020.3511\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 7701.4385\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 7557.6309\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 7292.8955\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 7943.0205\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 7434.3135\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 7979.1768\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 6956.2266\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 7527.9009\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 7309.5703\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 7000.3828\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 7451.1782\n",
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 7129.3936\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 7462.1533\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 7038.0542\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 7489.1201\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 7140.6890\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 7354.8887\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 7346.6943\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 7611.9243\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 7495.9902\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 7567.4604\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 7329.9634\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 7652.7637\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 7078.6523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 7251.1670\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 6377.2983\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 7697.9209\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 7281.3408\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 6848.5371\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 7047.3184\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 6855.6006\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 7390.8130\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 7208.4209\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 7198.1416\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 7212.7109\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 7567.0918\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 7116.6309\n",
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 7732.8086\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 7433.6523\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 7411.5962\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 8086.6309\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 7440.7822\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 7800.4990\n",
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 7411.8594\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 7271.3662\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 8137.5356\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 7841.0132\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 6857.4766\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 7237.5518\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 7171.9888\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 7570.9355\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 7200.9883\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 7869.8564\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 7663.4609\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 6780.9277\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 8132.4478\n",
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 7318.4951\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 7625.0908\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 7482.4395\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 7188.7988\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 7180.7334\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 7124.7988\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 7031.6987\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 7189.9990\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 7731.2832\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 8041.0801\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 7886.6641\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 7574.2271\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 6980.2725\n",
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 7481.3389\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 7317.9980\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 7061.7290\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 8145.6743\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 7630.0801\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 6881.3677\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 6897.8125\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 7832.2754\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 6890.3057\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 7162.7754\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 7466.6406\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 7411.3086\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 7296.3223\n",
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 7597.9424\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 7424.2764\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 7505.0703\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 7656.3999\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 7749.2852\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 7127.0674\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 7655.0664\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 7219.1035\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 7444.4272\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 7418.0635\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 6990.7676\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 6771.5947\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 7160.0635\n",
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 7597.8569\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 7345.4292\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 7420.4551\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 7187.2476\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 7326.2749\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 7440.7573\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 7486.4775\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 7797.1704\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 6691.1455\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 7468.1572\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 6894.3193\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 7515.0522\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 7487.8184\n",
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 7524.0713\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 7083.5532\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 7414.0391\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 7390.5415\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 7266.7705\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 6877.7188\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 7559.3936\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 7375.7227\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 8050.2812\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 7469.4385\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 7591.2129\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 7413.8262\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 6677.5288\n",
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 6816.6753\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 8467.7344\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 7619.4766\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 7070.5244\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 7224.7510\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 8016.7627\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 7171.9868\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 7823.7227\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 7844.0342\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 7930.2979\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 7624.5522\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 6663.7832\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 7706.5215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 7688.1040\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 7526.7939\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 8009.9971\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 7396.9185\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 7857.9639\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 7826.2803\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 7753.5039\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 7103.3511\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 6887.4717\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 7675.6157\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 7357.4268\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 7271.4414\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 7264.6758\n",
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 7271.7256\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 7460.8262\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 7289.7856\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 7574.1577\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 7397.8267\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 7763.2510\n",
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 6934.9238\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 7249.1519\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 8045.3726\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 7503.8530\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 7060.9336\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 7594.8711\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 7440.1401\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 7296.2910\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 7508.5537\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 7544.6494\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 6816.6543\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 7788.4102\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 6588.1401\n",
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 7196.6128\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 7172.7373\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 7892.6333\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 7317.1982\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 7552.1465\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 7906.3633\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 6733.8442\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 7847.8301\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 8226.4268\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 7033.2588\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 7624.6543\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 7735.4863\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 7171.0449\n",
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 6728.1807\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 7290.5469\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 7573.2119\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 7473.8535\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 7835.6426\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 7532.8701\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 7283.5352\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 6935.2051\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 7678.2061\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 7601.6025\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 6984.6855\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 7711.8887\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 7651.8770\n",
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 7009.3184\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 7931.1777\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 7805.3291\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 7381.1895\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 7473.6450\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 7075.3994\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 7257.0664\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 7308.7441\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 7254.7212\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 7457.0156\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 7611.7222\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 7171.5054\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 7725.8936\n",
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 6999.4390\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 7056.5215\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 7453.1001\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 7352.7656\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 6692.8774\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 7578.4907\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 7211.7690\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 7305.6758\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 7543.3525\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 7373.7588\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 7813.8335\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 7244.0391\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 7817.7480\n",
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 7516.2441\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 7310.9487\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 7355.0889\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 7354.3008\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 7207.0127\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 7318.7803\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 7383.3926\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 7920.3110\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 7106.2959\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 7659.7822\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 6876.7456\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 6860.9707\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 7227.3740\n",
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 7616.7910\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 7349.0117\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 7482.8115\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 7075.5171\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 7172.6562\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 6942.9395\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 6598.4414\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 6669.7422\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 7179.6631\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 7773.2715\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 6920.3604\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 7325.1152\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 7477.7422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 7656.8135\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 8136.5557\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 7888.1646\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 7172.3013\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 7134.7725\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 7257.9307\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 7112.9746\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 7312.7109\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 7444.7061\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 7516.2812\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 7722.2085\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 7533.8096\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 7118.2139\n",
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 7957.6270\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 7545.5527\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 6859.5303\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 8021.7920\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 7266.4385\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 7298.8784\n",
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 6885.4229\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 7454.4355\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 7203.4492\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 7086.1035\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 7522.5303\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 7392.1436\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 7684.0371\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 7194.8379\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 7528.0225\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 7466.1318\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 7295.7402\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 6826.1855\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 7442.0845\n",
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 7217.6592\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 6873.6543\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 7703.3018\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 7517.7334\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 6973.9824\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 7221.9434\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 7985.2529\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 7715.9575\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 7690.7075\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 7394.1567\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 8103.7661\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 7163.9521\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 7747.0259\n",
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 7572.9492\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 7703.4863\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 7550.0884\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 7021.3652\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 7340.1836\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 7368.0234\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 7134.6885\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 7026.4185\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 7613.0166\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 7346.9951\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 7343.8833\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 7372.5527\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 7470.0410\n",
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 7586.3027\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 7576.1992\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 7377.1738\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 6654.4146\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 7184.6562\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 7157.8428\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 6808.7295\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 8121.4800\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 7188.3008\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 7292.3457\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 7823.5996\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 7474.6260\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 7818.6831\n",
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 7266.4404\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 7155.8203\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 7163.3818\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 6888.0669\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 7508.1523\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 8272.4707\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 7740.2354\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 6898.2520\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 7461.4961\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 7448.1943\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 7618.7324\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 7602.8574\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 8182.8398\n",
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 7487.9541\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 7664.4326\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 7850.2812\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 7024.6875\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 7371.2656\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 6780.1289\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 7476.5024\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 7326.3345\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 7263.9038\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 7510.4175\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 7365.7090\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 7168.5732\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 7450.7729\n",
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 6631.5117\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 7224.0483\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 7342.4517\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 7856.0088\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 6765.2480\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 7850.4116\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 7445.0522\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 7569.1055\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 7047.8467\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 7706.4961\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 7381.2407\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 7157.9424\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 7323.4980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 7476.8486\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 7734.2803\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 7257.2144\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 7134.7393\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 7452.1162\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 7173.8628\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 7010.9277\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 7339.2197\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 7410.5576\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 7902.5806\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 7911.6499\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 7089.1421\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 6995.6904\n",
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 6994.7686\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 7403.7061\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 6975.6304\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 7272.6152\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 7338.2119\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 7982.2373\n",
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 6919.5898\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 7157.1309\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 7056.9844\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 7720.6509\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 7848.1748\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 7184.9082\n",
      "Model saved in file: SD/sd2_50000.ckpt\n",
      "Time usage: 0:09:26\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[65, 129, 193, 257, 321, 385, 449, 513, 577, 641, 705, 769, 833, 897, 961, 1025, 1089, 1153, 1217, 1281, 1345, 1409, 1473, 1537, 1601, 1665, 1729, 1793, 1857, 1921, 1985, 2049, 2113, 2177, 2241, 2305, 2369, 2433, 2497, 2561, 2625, 2689, 2753, 2817, 2881, 2945, 3009, 3073, 3137, 3201, 3265, 3329, 3393, 3457, 3521, 3585, 3649, 3713, 3777, 3841, 3905, 3969, 4033, 4097, 4161, 4225, 4289, 4353, 4417, 4481, 4545, 4609, 4673, 4737, 4801, 4865, 4929, 4993, 5057, 5121, 5185, 5249, 5313, 5377, 5441, 5505, 5569, 5633, 5697, 5761, 5825, 5889, 5953, 6017, 6081, 6145, 6209, 6273, 6337, 6401, 6465, 6529, 6593, 6657, 6721, 6785, 6849, 6913, 6977, 7041, 7105, 7169, 7233, 7297, 7361, 7425, 7489, 7553, 7617, 7681, 7745, 7809, 7873, 7937, 8001, 8065, 8129, 8193, 8257, 8321, 8385, 8449, 8513, 8577, 8641, 8705, 8769, 8833, 8897, 8961, 9025, 9089, 9153, 9217, 9281, 9345, 9409, 9473, 9537, 9601, 9665, 9729, 9793, 9857, 9921, 9985, 10049, 10113, 10177, 10241, 10305, 10369, 10433, 10497, 10561, 10625, 10689, 10753, 10817, 10881, 10945, 11009, 11073, 11137, 11201, 11265, 11329, 11393, 11457, 11521, 11585, 11649, 11713, 11777, 11841, 11905, 11969, 12033, 12097, 12161, 12225, 12289, 12353, 12417, 12481, 12545, 12609, 12673, 12737, 12801, 12865, 12929, 12993, 13057, 13121, 13185, 13249, 13313, 13377, 13441, 13505, 13569, 13633, 13697, 13761, 13825, 13889, 13953, 14017, 14081, 14145, 14209, 14273, 14337, 14401, 14465, 14529, 14593, 14657, 14721, 14785, 14849, 14913, 14977, 15041, 15105, 15169, 15233, 15297, 15361, 15425, 15489, 15553, 15617, 15681, 15745, 15809, 15873, 15937, 16001, 16065, 16129, 16193, 16257, 16321, 16385, 16449, 16513, 16577, 16641, 16705, 16769, 16833, 16897, 16961, 17025, 17089, 17153, 17217, 17281, 17345, 17409, 17473, 17537, 17601, 17665, 17729, 17793, 17857, 17921, 17985, 18049, 18113, 18177, 18241, 18305, 18369, 18433, 18497, 18561, 18625, 18689, 18753, 18817, 18881, 18945, 19009, 19073, 19137, 19201, 19265, 19329, 19393, 19457, 19521, 19585, 19649, 19713, 19777, 19841, 19905, 19969, 20033, 20097, 20161, 20225, 20289, 20353, 20417, 20481, 20545, 20609, 20673, 20737, 20801, 20865, 20929, 20993, 21057, 21121, 21185, 21249, 21313, 21377, 21441, 21505, 21569, 21633, 21697, 21761, 21825, 21889, 21953, 22017, 22081, 22145, 22209, 22273, 22337, 22401, 22465, 22529, 22593, 22657, 22721, 22785, 22849, 22913, 22977, 23041, 23105, 23169, 23233, 23297, 23361, 23425, 23489, 23553, 23617, 23681, 23745, 23809, 23873, 23937, 24001, 24065, 24129, 24193, 24257, 24321, 24385, 24449, 24513, 24577, 24641, 24705, 24769, 24833, 24897, 24961, 25025, 25089, 25153, 25217, 25281, 25345, 25409, 25473, 25537, 25601, 25665, 25729, 25793, 25857, 25921, 25985, 26049, 26113, 26177, 26241, 26305, 26369, 26433, 26497, 26561, 26625, 26689, 26753, 26817, 26881, 26945, 27009, 27073, 27137, 27201, 27265, 27329, 27393, 27457, 27521, 27585, 27649, 27713, 27777, 27841, 27905, 27969, 28033, 28097, 28161, 28225, 28289, 28353, 28417, 28481, 28545, 28609, 28673, 28737, 28801, 28865, 28929, 28993, 29057, 29121, 29185, 29249, 29313, 29377, 29441, 29505, 29569, 29633, 29697, 29761, 29825, 29889, 29953, 30017, 30081, 30145, 30209, 30273, 30337, 30401, 30465, 30529, 30593, 30657, 30721, 30785, 30849, 30913, 30977, 31041, 31105, 31169, 31233, 31297, 31361, 31425, 31489, 31553, 31617, 31681, 31745, 31809, 31873, 31937, 32001, 32065, 32129, 32193, 32257, 32321, 32385, 32449, 32513, 32577, 32641, 32705, 32769, 32833, 32897, 32961, 33025, 33089, 33153, 33217, 33281, 33345, 33409, 33473, 33537, 33601, 33665, 33729, 33793, 33857, 33921, 33985, 34049, 34113, 34177, 34241, 34305, 34369, 34433, 34497, 34561, 34625, 34689, 34753, 34817, 34881, 34945, 35009, 35073, 35137, 35201, 35265, 35329, 35393, 35457, 35521, 35585, 35649, 35713, 35777, 35841, 35905, 35969, 36033, 36097, 36161, 36225, 36289, 36353, 36417, 36481, 36545, 36609, 36673, 36737, 36801, 36865, 36929, 36993, 37057, 37121, 37185, 37249, 37313, 37377, 37441, 37505, 37569, 37633, 37697, 37761, 37825, 37889, 37953, 38017, 38081, 38145, 38209, 38273, 38337, 38401, 38465, 38529, 38593, 38657, 38721, 38785, 38849, 38913, 38977, 39041, 39105, 39169, 39233, 39297, 39361, 39425, 39489, 39553, 39617, 39681, 39745, 39809, 39873, 39937, 40001, 40065, 40129, 40193, 40257, 40321, 40385, 40449, 40513, 40577, 40641, 40705, 40769, 40833, 40897, 40961, 41025, 41089, 41153, 41217, 41281, 41345, 41409, 41473, 41537, 41601, 41665, 41729, 41793, 41857, 41921, 41985, 42049, 42113, 42177, 42241, 42305, 42369, 42433, 42497, 42561, 42625, 42689, 42753, 42817, 42881, 42945, 43009, 43073, 43137, 43201, 43265, 43329, 43393, 43457, 43521, 43585, 43649, 43713, 43777, 43841, 43905, 43969, 44033, 44097, 44161, 44225, 44289, 44353, 44417, 44481, 44545, 44609, 44673, 44737, 44801, 44865, 44929, 44993, 45057, 45121, 45185, 45249, 45313, 45377, 45441, 45505, 45569, 45633, 45697, 45761, 45825, 45889, 45953, 46017, 46081, 46145, 46209, 46273, 46337, 46401, 46465, 46529, 46593, 46657, 46721, 46785, 46849, 46913, 46977, 47041, 47105, 47169, 47233, 47297, 47361, 47425, 47489, 47553, 47617, 47681, 47745, 47809, 47873, 47937, 48001, 48065, 48129, 48193, 48257, 48321, 48385, 48449, 48513, 48577, 48641, 48705, 48769, 48833, 48897, 48961, 49025, 49089, 49153, 49217, 49281, 49345, 49409, 49473, 49537, 49601, 49665, 49729, 49793, 49857, 49921, 49985]\n",
      "[0.0, 0.0]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "save_model = True\n",
    "save_name = model2_50000\n",
    "restore_model=False\n",
    "restore_name=model2_50000\n",
    "# init = tf.global_variables_initializer()\n",
    "# session.run(init)\n",
    "\n",
    "optimize(2, save_model=True,save_name=model2_50000,restore_model=False,restore_name=model2_50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train = train_data[0:1]\n",
    "merged_patch_lbls = train_labels[0:1, 0]\n",
    "mask_lbls = train_labels[0:1, 1]\n",
    "img_type_lbl = img_type[0:1]\n",
    "img_key = img_keys[0:1]\n",
    "dims = (1, num_classes, num_channels)\n",
    "# print(train, merged_patch_lbls, mask_lbls)\n",
    "train, labels, img_type_lbl, img_key = get_batch_images(train, merged_patch_lbls, img_type_lbl, img_key, dims, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_see_layer(orig, pred, model_name=None, var_name=None):\n",
    "    with tf.Session('', tf.Graph()) as s:\n",
    "        with s.graph.as_default():\n",
    "            if ((model_name != None) and var_name != None):\n",
    "                saver = tf.train.import_meta_graph(model_name+\".meta\")\n",
    "                saver.restore(s, model_name)\n",
    "#                 print(pred.shape)\n",
    "                fd = {'x_orig:0': orig, 'x_pred:0':pred}\n",
    "#                 print(fd.shape)\n",
    "                var_name=var_name+\":0\"\n",
    "                \n",
    "                \n",
    "                \n",
    "                result = 0\n",
    "                result = s.run(var_name, feed_dict=fd)\n",
    "    return result\n",
    "\n",
    "def see_output(iNp,depth_filter_to_see=0,cmap=\"gray\",figsize=(4,4)):\n",
    "    img_x = iNp[0,:,:,:]\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if cmap == \"gray\":\n",
    "        plt.imshow(img_x, cmap=plt.get_cmap('gray'))\n",
    "    else:\n",
    "        plt.imshow(img_x, interpolation='none', aspect='auto')\n",
    "#     plt.colorbar(img_x, orientation='horizontal')\n",
    "    plt.show()\n",
    "    \n",
    "def save_patch_images(img_x1, lbl_x1, index):\n",
    "    if not os.path.exists('./SD/predicted_patches/' + str(index)):\n",
    "        os.makedirs('./SD/predicted_patches/' + str(index))\n",
    "        os.makedirs('./SD/predicted_patches/' + str(index) + \"/\" + str(lbl_x1))\n",
    "        \n",
    "    plt.imsave('./SD/predicted_patches/' + str(index) + \"/\" + str(lbl_x1) + '/img.png', np.squeeze(img_x1))\n",
    "    \n",
    "\n",
    "def predict_nd_save(train, labels, img_type_lbl, img_key, start_idx):\n",
    "\n",
    "    for index in range(0, len(train)):\n",
    "        img_x = train[index:index+1, :]\n",
    "        lbl_x = labels[index:index+1, :]\n",
    "        img_type_x = img_type_lbl[index]\n",
    "        img_key_x = img_key[index]\n",
    "        prediction = restore_see_layer(ix=img_x,model_name=model2_50000,var_name='custom/custom_1_comb_patches')\n",
    "        prediction = np.reshape(prediction, (1, 4, 2, 1))   \n",
    "        save_patch_images(prediction, img_type_x, img_key_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train_mask_labels = train_labels[:][:, 1]\n",
    "train_patch_labels = train_labels[:][:, 0]\n",
    "\n",
    "batch_s = 64\n",
    "total_iterations = 0\n",
    "start_ = 0\n",
    "end_ = batch_s\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "if not os.path.exists('./SD/predicted_patches'):\n",
    "    os.makedirs('./SD/predicted_patches')\n",
    "\n",
    "while True:\n",
    "    train = train_data[start_:end_]\n",
    "    labels = train_patch_labels[start_:end_]\n",
    "    img_type_lbl = img_type[start_:end_]\n",
    "    img_key = img_keys[start_:end_]\n",
    "    dims = (batch_s, num_classes, num_channels)\n",
    "    train, labels, img_type_lbl, img_key = get_batch_images(train, labels, img_type_lbl, img_key, dims, True)\n",
    "    predict_nd_save(train, labels, img_type_lbl, img_key, start_)\n",
    "    \n",
    "    #do my stuff\n",
    "    if len(train_data) < start_ + batch_s:\n",
    "        print(\"{} Images have been processed.\".format(total_iterations))\n",
    "        break\n",
    "    \n",
    "    total_iterations +=batch_s\n",
    "    start_ = end_\n",
    "    end_ = end_ + batch_s   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15970'] [0]\n",
      "(100,)\n",
      "INFO:tensorflow:Restoring parameters from SD/sd2_50000.ckpt\n",
      "[[[[131.8634  125.69505]\n",
      "   [136.16469 140.44868]\n",
      "   [139.29045 124.02174]\n",
      "   [123.15848 131.8634 ]]]]\n"
     ]
    }
   ],
   "source": [
    "train_orig = train_data[0, 0:1]\n",
    "train_pred = train_data[1, 0:1]\n",
    "labels = train_labels[0:1, 0]\n",
    "labels\n",
    "img_type_lbl = img_type[0:1]\n",
    "img_key = img_keys[0:1]\n",
    "dims = (1, num_classes, num_channels)\n",
    "train, labels, img_type_lbl, img_key = get_batch_images(train_orig, train_pred, labels, img_type_lbl, img_key, dims, True)\n",
    "# train[0:1]\n",
    "# img_x = cv2.imread(\"../../original_images/SD/15970/0/img/predicted_mask.png\")\n",
    "\n",
    "# img_x = np.expand_dims(img_x[:,:,0].flatten(), axis=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "# print(train)\n",
    "output_cl1 = restore_see_layer(orig=np.expand_dims(train[0][0], axis=0), pred=np.expand_dims(train[1][0], axis=0), model_name=model2_50000,var_name='custom/custom_1_comb_patches')\n",
    "# output_cl2 = restore_see_layer(ix=train,model_name=model2_50000,var_name='custom/custom_1_comb_patches')\n",
    "print(output_cl1)\n",
    "# show_img = np.expand_dims(np.reshape(output_cl1, (4,2)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x135d92f28>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(output_cl1.shape)\n",
    "new_img = np.reshape(output_cl1, [4, 2])\n",
    "fig = plt.figure(figsize=(2,4))\n",
    "plt.imshow(new_img, interpolation='none', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_x = cv2.imread(\"../../original_images/SD/15970/0/labels/merged_patch.png\")\n",
    "print(img_x.shape)\n",
    "reshaped_img_x = np.expand_dims(img_x, axis=0)\n",
    "\n",
    "grey_img = np.dot(img_x[...,:3], [0.299, 0.587, 0.114])\n",
    "print(grey_img.shape)\n",
    "\n",
    "# grey_img = normalize(grey_img)\n",
    "\n",
    "# see_output(reshaped_img_x, figsize=(2,4))\n",
    "\n",
    "fig = plt.figure(figsize=(2,4))\n",
    "# print(grey_img)\n",
    "plt.imshow(grey_img, interpolation='none', aspect='auto')\n",
    "# see_output(reshaped_img_x, figsize = (2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x_orig:0' shape=(?, 300) dtype=float32>,\n",
       " <tf.Tensor 'x_pred:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'Reshape/shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'Reshape:0' shape=(?, 10, 10, 3) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_1/shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'Reshape_1:0' shape=(?, 10, 10, 1) dtype=float32>,\n",
       " <tf.Tensor 'Const:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'Const_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'y_true:0' shape=(?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'y_true_cls:0' shape=(?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'cv/random_uniform/shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'cv/random_uniform/min:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'cv/random_uniform/max:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'cv/random_uniform/RandomUniform:0' shape=(4, 4, 1, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/random_uniform/sub:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'cv/random_uniform/mul:0' shape=(4, 4, 1, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/random_uniform:0' shape=(4, 4, 1, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_W:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_W/Assign:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_W/read:0' shape=(4, 4, 1, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/Const:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_b:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_b/Assign:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_b/read:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'cv/Conv2D:0' shape=(?, 10, 10, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1:0' shape=(?, 10, 10, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_max:0' shape=(?, 5, 5, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_activation:0' shape=(?, 5, 5, 16) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_2/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'Reshape_2:0' shape=(?, 400) dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc/random_uniform/min:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform/max:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform/RandomUniform:0' shape=(400, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform/sub:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform/mul:0' shape=(400, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform:0' shape=(400, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_W:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_W/Assign:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_W/read:0' shape=(400, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc/Const:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_b:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_b/Assign:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_b/read:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'fc/MatMul:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'custom/Reshape/shape:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'custom/Reshape:0' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'custom/Shape:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_1/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_1/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_1/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/sub/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/sub:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/add/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/add:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/sub_1/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/sub_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/add_1/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/add_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range/start:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range/delta:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'custom/range_1/start:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range_1/delta:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range_1:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/Reshape/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/Reshape:0' shape=(?, 1) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/Reshape_1/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/Reshape_1:0' shape=(1, ?) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/Size:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/Size_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/ones/mul:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/ones/Less/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/ones/Less:0' shape=() dtype=bool>,\n",
       " <tf.Tensor 'custom/meshgrid/ones/packed:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/ones/Const:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/ones:0' shape=(?, ?) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/mul:0' shape=(?, ?) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid/mul_1:0' shape=(?, ?) dtype=int32>,\n",
       " <tf.Tensor 'custom/range_2/start:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range_2/limit:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range_2/delta:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range_2:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/range_3/start:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range_3/limit:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range_3/delta:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/range_3:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/Reshape/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/Reshape:0' shape=(2, 1) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/Reshape_1/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/Reshape_1:0' shape=(1, 2) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/Size:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/Size_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/ones/mul:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/ones/Less/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/ones/Less:0' shape=() dtype=bool>,\n",
       " <tf.Tensor 'custom/meshgrid_1/ones/packed:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/ones/Const:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/ones:0' shape=(2, 2) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/mul:0' shape=(2, 2) dtype=int32>,\n",
       " <tf.Tensor 'custom/meshgrid_1/mul_1:0' shape=(2, 2) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_2/stack:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_2/stack_1:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_2/stack_2:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_2:0' shape=(?, ?, 1, 1) dtype=int32>,\n",
       " <tf.Tensor 'custom/add_2:0' shape=(?, ?, 2, 2) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_3/stack:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_3/stack_1:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_3/stack_2:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_3:0' shape=(?, ?, 1, 1) dtype=int32>,\n",
       " <tf.Tensor 'custom/add_3:0' shape=(?, ?, 2, 2) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_4/stack:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_4/stack_1:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_4/stack_2:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_4:0' shape=(10, 10) dtype=float32>,\n",
       " <tf.Tensor 'custom/stack:0' shape=(?, ?, 2, 2, 2) dtype=int32>,\n",
       " <tf.Tensor 'custom/custom_1_gather:0' shape=(?, ?, 2, 2) dtype=float32>,\n",
       " <tf.Tensor 'custom/custom_1_subm_sum/reduction_indices:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/custom_1_subm_sum:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'custom/Reshape_1/shape:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/Reshape_1:0' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'custom/Size:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/Minimum:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/custom_1_top_idx:0' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'custom/custom_1_top_idx:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'custom/floordiv:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'custom/mod:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'custom/custom_1_result:0' shape=(?, 2) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/Shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/strided_slice/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/strided_slice/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/strided_slice/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/strided_slice:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArray:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'custom/map/TensorArray:1' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayUnstack/Shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayUnstack/strided_slice/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayUnstack/strided_slice/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayUnstack/strided_slice/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayUnstack/strided_slice:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayUnstack/range/start:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayUnstack/range/delta:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayUnstack/range:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/Const:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArray_1:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'custom/map/TensorArray_1:1' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/iteration_counter:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Enter:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Enter_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Enter_2:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/Merge:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Merge:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Merge_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Merge_1:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Merge_2:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/Merge_2:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Less/Enter:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Less:0' shape=() dtype=bool>,\n",
       " <tf.Tensor 'custom/map/while/Less_1:0' shape=() dtype=bool>,\n",
       " <tf.Tensor 'custom/map/while/LogicalAnd:0' shape=() dtype=bool>,\n",
       " <tf.Tensor 'custom/map/while/LoopCond:0' shape=() dtype=bool>,\n",
       " <tf.Tensor 'custom/map/while/Switch:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Switch:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Switch_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Switch_1:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Switch_2:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/Switch_2:1' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/Identity:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Identity_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Identity_2:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/add/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/add:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/TensorArrayReadV3/Enter:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'custom/map/while/TensorArrayReadV3/Enter_1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/TensorArrayReadV3:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_1/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_1/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_1/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/add_1/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/add_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_2/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_2/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_2/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_2:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_3/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_3/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_3/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_3:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/add_2/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/add_2:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_4/stack/0:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_4/stack:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_4/stack_1/0:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_4/stack_1:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_4/stack_2:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_4/Enter:0' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/strided_slice_4:0' shape=(?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/TensorArrayWrite/TensorArrayWriteV3/Enter:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'custom/map/while/TensorArrayWrite/TensorArrayWriteV3:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/add_3/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/add_3:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/NextIteration:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/NextIteration_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/NextIteration_2:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/while/Exit:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Exit_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/while/Exit_2:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayStack/TensorArraySizeV3:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayStack/range/start:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayStack/range/delta:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayStack/range:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'custom/map/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'custom/Shape_1:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_5/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_5/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_5/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_5:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_6/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_6/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_6/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_6:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_7/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_7/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_7/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_7:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/mul:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_8/stack:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_8/stack_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_8/stack_2:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'custom/strided_slice_8:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/custom_1_comb_patches/shape/0:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'custom/custom_1_comb_patches/shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'custom/custom_1_comb_patches:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'sub:0' shape=(?, ?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'Square:0' shape=(?, ?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'Const_2:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'Mean:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/Shape:0' shape=(0,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/grad_ys_0:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/Fill:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/f_count:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/f_count_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Merge:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Merge:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Switch:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Switch:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Add/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Add:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/NextIteration:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/f_count_2:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/b_count:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/b_count_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Merge_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Merge_1:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/GreaterEqual/Enter:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/GreaterEqual:0' shape=() dtype=bool>,\n",
       " <tf.Tensor 'gradients/b_count_2:0' shape=() dtype=bool>,\n",
       " <tf.Tensor 'gradients/Switch_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Switch_1:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Sub:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/NextIteration_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/b_count_3:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Reshape/shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Reshape:0' shape=(1, 1, 1, 1) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Tile:0' shape=(?, ?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Shape_1:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Shape_2:0' shape=(0,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Const:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Prod:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Const_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Prod_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Maximum/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Maximum:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/floordiv:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Cast:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/truediv:0' shape=(?, ?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Square_grad/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/Square_grad/Mul:0' shape=(?, ?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Square_grad/Mul_1:0' shape=(?, ?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Shape:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Shape_1:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/sub_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/sub_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Reshape:0' shape=(?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Neg:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Reshape_1:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/tuple/control_dependency:0' shape=(?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/tuple/control_dependency_1:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/custom_1_comb_patches_grad/Shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/custom_1_comb_patches_grad/Reshape:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3:1' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/Exit_2_grad/b_exit:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/Switch_2_grad/b_switch:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/Switch_2_grad/b_switch:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/Merge_2_grad/Switch:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/Merge_2_grad/Switch:1' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/Merge_2_grad/tuple/control_dependency:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/Merge_2_grad/tuple/control_dependency_1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/Enter_2_grad/Exit:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3:1' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/Const:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/Enter:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPushV2:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2/Enter:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency:0' shape=(?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/Shape:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/Const:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/f_acc:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/Enter:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/StackPushV2:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2/Enter:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/Const_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/f_acc_1:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/Enter_1:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/StackPushV2_1:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2_1/Enter:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2_1:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/Const_2:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/f_acc_2:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/Enter_2:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/StackPushV2_2:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2_2/Enter:0' shape=(2,) dtype=resource>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2_2:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad/Const_3:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4_grad/StridedSliceGrad:0' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/Shape:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/zeros:0' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/b_acc:0' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/b_acc_1:0' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/b_acc_1:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/Switch:0' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/Switch:1' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/Add:0' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/NextIteration:0' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/strided_slice_4/Enter_grad/b_acc_2:0' shape=(?, 10, 10) dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/map/while/Switch_2_grad_1/NextIteration:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/custom/Reshape_grad/Shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/custom/Reshape_grad/Reshape:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc_1_grad/Shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc/fc_1_grad/Shape_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc/fc_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc/fc_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc/fc_1_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc_1_grad/Reshape:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc_1_grad/Reshape_1:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc_1_grad/tuple/control_dependency:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc_1_grad/tuple/control_dependency_1:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/MatMul_grad/MatMul:0' shape=(?, 400) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/MatMul_grad/MatMul_1:0' shape=(400, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/MatMul_grad/tuple/control_dependency:0' shape=(?, 400) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/MatMul_grad/tuple/control_dependency_1:0' shape=(400, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Reshape_2_grad/Shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Reshape_2_grad/Reshape:0' shape=(?, 5, 5, 16) dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_activation_grad/ReluGrad:0' shape=(?, 5, 5, 16) dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_max_grad/MaxPoolGrad:0' shape=(?, 10, 10, 16) dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_grad/Shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_grad/Shape_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_grad/Reshape:0' shape=(?, 10, 10, 16) dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_grad/Reshape_1:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_grad/tuple/control_dependency:0' shape=(?, 10, 10, 16) dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/conv1_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/cv/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/cv/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/Conv2D_grad/Conv2DBackpropFilter:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/Conv2D_grad/tuple/control_dependency:0' shape=(?, 10, 10, 1) dtype=float32>,\n",
       " <tf.Tensor 'gradients/cv/Conv2D_grad/tuple/control_dependency_1:0' shape=(4, 4, 1, 16) dtype=float32>,\n",
       " <tf.Tensor 'beta1_power/initial_value:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'beta1_power/Assign:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'beta1_power/read:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'beta2_power/initial_value:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'beta2_power/Assign:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'beta2_power/read:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_W/Adam/Initializer/zeros:0' shape=(4, 4, 1, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_W/Adam:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_W/Adam/Assign:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_W/Adam/read:0' shape=(4, 4, 1, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_W/Adam_1/Initializer/zeros:0' shape=(4, 4, 1, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_W/Adam_1:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_W/Adam_1/Assign:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_W/Adam_1/read:0' shape=(4, 4, 1, 16) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_b/Adam/Initializer/zeros:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_b/Adam:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_b/Adam/Assign:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_b/Adam/read:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_b/Adam_1/Initializer/zeros:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'cv/conv1_b/Adam_1:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_b/Adam_1/Assign:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'cv/conv1_b/Adam_1/read:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam/Initializer/zeros:0' shape=(400, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam/Assign:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam/read:0' shape=(400, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam_1/Initializer/zeros:0' shape=(400, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam_1:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam_1/Assign:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_W/Adam_1/read:0' shape=(400, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_b/Adam/Initializer/zeros:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_b/Adam:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_b/Adam/Assign:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_b/Adam/read:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_b/Adam_1/Initializer/zeros:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc_1_b/Adam_1:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_b/Adam_1/Assign:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc_1_b/Adam_1/read:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'Adam/learning_rate:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/beta1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/beta2:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/epsilon:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/update_cv/conv1_W/ApplyAdam:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_cv/conv1_b/ApplyAdam:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_fc/fc_1_W/ApplyAdam:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_fc/fc_1_b/ApplyAdam:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/Assign:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/Assign_1:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'Equal:0' shape=(?, ?, 4, 2) dtype=bool>,\n",
       " <tf.Tensor 'Cast:0' shape=(?, ?, 4, 2) dtype=float32>,\n",
       " <tf.Tensor 'Const_3:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'Mean_1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'save/Const:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'save/SaveV2/tensor_names:0' shape=(14,) dtype=string>,\n",
       " <tf.Tensor 'save/SaveV2/shape_and_slices:0' shape=(14,) dtype=string>,\n",
       " <tf.Tensor 'save/control_dependency:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'save/RestoreV2/tensor_names:0' shape=(14,) dtype=string>,\n",
       " <tf.Tensor 'save/RestoreV2/shape_and_slices:0' shape=(14,) dtype=string>,\n",
       " <tf.Tensor 'save/RestoreV2:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:1' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:2' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:3' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:4' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:5' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:6' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:7' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:8' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:9' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:10' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:11' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:12' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:13' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/Assign:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_1:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_2:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_3:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_4:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_5:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_6:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_7:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_8:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_9:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_10:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_11:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_12:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_13:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Const:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'save_1/SaveV2/tensor_names:0' shape=(14,) dtype=string>,\n",
       " <tf.Tensor 'save_1/SaveV2/shape_and_slices:0' shape=(14,) dtype=string>,\n",
       " <tf.Tensor 'save_1/control_dependency:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'save_1/RestoreV2/tensor_names:0' shape=(14,) dtype=string>,\n",
       " <tf.Tensor 'save_1/RestoreV2/shape_and_slices:0' shape=(14,) dtype=string>,\n",
       " <tf.Tensor 'save_1/RestoreV2:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:1' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:2' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:3' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:4' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:5' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:6' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:7' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:8' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:9' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:10' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:11' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:12' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/RestoreV2:13' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save_1/Assign:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_1:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_2:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_3:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_4:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_5:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_6:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_7:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_8:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_9:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_10:0' shape=(400, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_11:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_12:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save_1/Assign_13:0' shape=(100,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tensors(graph=tf.get_default_graph()):\n",
    "    return [t for op in graph.get_operations() for t in op.values()]\n",
    "get_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
