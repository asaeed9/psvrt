{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "import cv2, os, math, time\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from itertools import product\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configuration\n",
    "\"\"\"\n",
    "Data Configurations/Paths\n",
    "\"\"\"\n",
    "img_dir=\"../../original_images/SD\"\n",
    "img_lbls=\"\"\n",
    "base_model = 'SD/sd_01_.ckpt'\n",
    "model_20000 = 'SD/sd_20000.ckpt'\n",
    "model_30000 = 'SD/sd_30000.ckpt'\n",
    "model_40000 = 'SD/sd_40000.ckpt'\n",
    "model_50000 = 'SD/sd_50000.ckpt'\n",
    "model2_50000 = 'SD/sd2_50000.ckpt' #this model takes a 10x10 predicted mask from model:1 and predicts an image which combines all the patches.\n",
    "\n",
    "connected_model = 'SD/sd_conected.ckpt'\n",
    "\n",
    "##\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 4          # Convolution filters are 4 x 4 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# filter_size1 = 16          # Convolution filters are 4 x 4 pixels.\n",
    "# num_filters1 = 64         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 8          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters2 = 64         # There are 32 of these filters.\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 8          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters3 = 64         # There are 64 of these filters.\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size4 = 4          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters4 = 32         # There are 128 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 2000             # Number of neurons in fully-connected layer.\n",
    "\n",
    "# We know that images are 60 pixels in each dimension.\n",
    "# img_size = 8 * 4\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 10 * 10\n",
    "\n",
    "# Number of colour channels for the images: 3 channel for RGB.\n",
    "num_channels = 1\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (10, 10, num_channels)\n",
    "\n",
    "# Number of classes, one class for same or different image\n",
    "num_classes = 2*2\n",
    "patch_size = (2, 2, 3)\n",
    "npatches = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_dir):\n",
    "        list_of_orig_imgs = []\n",
    "        list_of_pred_imgs = []\n",
    "        list_of_labels = []\n",
    "        list_same_diff = []\n",
    "        list_img_keys = []\n",
    "        for img in os.listdir(img_dir):\n",
    "            \n",
    "            img_path = os.path.join(img_dir, img)\n",
    "            list_same_diff.append(int(os.listdir(img_path)[0]))\n",
    "            list_img_keys.append(img)\n",
    "            img_path = img_path + \"/\" + os.listdir(img_path)[0]\n",
    "            for img_label in os.listdir(img_path):\n",
    "                img_data = os.path.join(img_path, img_label)\n",
    "                if img_label == \"img\":\n",
    "#                     print(img_data + \"/img.png\")\n",
    "                    list_of_orig_imgs.append(img_data + \"/img.png\")\n",
    "                    list_of_pred_imgs.append(img_data + \"/predicted_mask.png\")\n",
    "                else:\n",
    "                    list_of_labels.append([os.path.join(img_data, label) for label in os.listdir(img_data)])\n",
    "\n",
    "        data_imgs = np.array([list_of_orig_imgs, list_of_pred_imgs])\n",
    "        data_labels = np.array(list_of_labels)\n",
    "        data_same_diff = np.array(list_same_diff)\n",
    "        data_img_keys = np.array(list_img_keys)\n",
    "\n",
    "        return data_imgs, data_labels, data_same_diff, data_img_keys\n",
    "\n",
    "    \n",
    "def get_batch_images(data_orig, data_pred, label, same_diff, img_keys, rshp, grey_scale):\n",
    "        list_of_orig_imgs = []\n",
    "        list_of_pred_imgs = []\n",
    "        list_of_labels = []\n",
    "        list_of_same_diff = []\n",
    "        list_of_img_keys = []\n",
    "        for img_orig, img_pred, lbl, img_type, img_key in zip(data_orig, data_pred, label, same_diff, img_keys):\n",
    "            if (grey_scale):\n",
    "                orig_img = cv2.imread(img_orig)\n",
    "                predicted_msk = cv2.imread(img_pred, cv2.IMREAD_GRAYSCALE)\n",
    "            else:\n",
    "                orig_img = cv2.imread(img[0])\n",
    "                \n",
    "            orig_lbl = cv2.imread(lbl)\n",
    "            if orig_img is None or orig_lbl is None:\n",
    "                    print (\"Unable to read image{} or {}\".format(img[0], lbl))\n",
    "                    continue\n",
    "            \n",
    "            if (grey_scale):\n",
    "                orig_lbl = rgb2grey(orig_lbl)\n",
    "\n",
    "            flattened_orig_img = orig_img.flatten()\n",
    "            flattened_pred_img = predicted_msk.flatten()\n",
    "            flattened_lbl = orig_lbl.flatten()\n",
    "            \n",
    "            if grey_scale:\n",
    "                flattened_lbl = np.reshape(flattened_lbl, [10, 10])\n",
    "#                 print(flattened_lbl)\n",
    "#                 flattened_lbl = normalize(flattened_lbl)\n",
    "#                 print(flattened_lbl)\n",
    "            \n",
    "            list_of_orig_imgs.append(np.asarray(flattened_orig_img, dtype=np.float32))\n",
    "            list_of_pred_imgs.append(np.asarray(flattened_pred_img, dtype=np.float32))\n",
    "        \n",
    "            list_of_labels.append(np.asarray(flattened_lbl, dtype=np.float32))\n",
    "            list_of_same_diff.append(img_type)\n",
    "            list_of_img_keys.append(img_key)\n",
    "\n",
    "        data_labels = np.array(list_of_labels)\n",
    "#         print(data_labels.shape)\n",
    "#         print(rshp)\n",
    "#         reshaped_labels = np.reshape(data_labels, rshp)\n",
    "#         data_labels = np.squeeze(reshaped_labels[:, :, :1])\n",
    "        data_imgs = np.array([list_of_orig_imgs, list_of_pred_imgs])\n",
    "        data_img_type = np.array(list_of_same_diff)\n",
    "        data_img_keys = np.array(list_of_img_keys)\n",
    "        \n",
    "        \"\"\"this function call locates top left location of each patch in the mask and return. Comment it if contents are required.\"\"\"\n",
    "#         print(data_labels.shape)\n",
    "#         data_labels = get_patch_loc(data_labels)\n",
    "        \n",
    "        return data_imgs, data_labels, data_img_type, data_img_keys\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_orig = data[0, :]\n",
    "    data_pred = data[1, :]\n",
    "    data_orig_shuffle = [data[0, i] for i in idx]\n",
    "    data_pred_shuffle = [data[1, i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_orig_shuffle), np.asarray(data_pred_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "def rgb2grey(rgb):\n",
    "    return(np.dot(rgb[...,:3], [0.299, 0.587, 0.114]))\n",
    "\n",
    "def get_patch_loc(imgs):\n",
    "    img_loc = []\n",
    "    for img in imgs:\n",
    "        img = np.squeeze(img)\n",
    "        img[np.where(img == 255)] = 1.\n",
    "        r = img_shape[0] - patch_size[0] + 1\n",
    "        c = img_shape[1] - patch_size[0] + 1\n",
    "\n",
    "        iter_o = np.array(list(product(range(0,patch_size[0]), range(0,patch_size[1]))))\n",
    "        left_corners = reduce(lambda x,y: np.multiply(x,y), map(lambda x, y: img[x:x+r, y:y+c], iter_o[:, 0], iter_o[:, 1]))\n",
    "        left_top_locations = np.transpose(np.where(left_corners == 1))\n",
    "        left_top_locations = np.array(left_top_locations, dtype=np.int32)\n",
    "        img_loc.append(left_top_locations)\n",
    "        \n",
    "    return np.array(img_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "\n",
    "train_org = train_data[0, 0:2]\n",
    "train_prd = train_data[1, 0:2]\n",
    "\n",
    "merged_patch_lbls = train_labels[0:2, 0]\n",
    "mask_lbls = train_labels[0:2, 1]\n",
    "img_type_lbl = img_type[0:2]\n",
    "img_key = img_keys[0:2]\n",
    "dims = (2, 100, num_channels)\n",
    "# print(train, merged_patch_lbls, mask_lbls)\n",
    "train, labels, img_type_lbl, img_key = get_batch_images(train_org, train_prd, mask_lbls, img_type_lbl, img_key, dims, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4 1]\n",
      "  [4 8]]\n",
      "\n",
      " [[1 3]\n",
      "  [7 8]]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape, layer_name):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape), name=layer_name+'_W')\n",
    "\n",
    "def new_bias(length, layer_name):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]), name=layer_name+'_b')\n",
    "\n",
    "def new_conv_layer(input,\n",
    "                   num_input_channels,\n",
    "                   filter_size,\n",
    "                   num_filters,\n",
    "                   name_scope,\n",
    "                   layer_name='',\n",
    "                   use_pooling=True):\n",
    "\n",
    "    with tf.name_scope(name_scope):\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "        weights = new_weights(shape, layer_name)\n",
    "        biases = new_bias(num_filters, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.nn.conv2d(input=input, filter=weights, strides=[1,1,1,1], padding='SAME'), biases, name=layer_name)\n",
    "\n",
    "        if use_pooling:\n",
    "            layer = tf.nn.max_pool(value=layer,\n",
    "                                   ksize=[1, 3, 3, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME', name=layer_name+'_max')\n",
    "            \n",
    "        layer = tf.nn.relu(layer, name=layer_name+'_activation')\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "def flatten_layer(layer, flag=False):\n",
    "    layer_shape = layer.get_shape()\n",
    "    if flag is True:\n",
    "        num_features = layer_shape.num_elements()\n",
    "        layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    else:\n",
    "        num_features = layer_shape[1:4].num_elements()\n",
    "        layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                name_scope,\n",
    "                layer_name='',\n",
    "                use_relu=True):\n",
    "    \n",
    "    with tf.name_scope(name_scope):\n",
    "        weights = new_weights([num_inputs, num_outputs], layer_name)\n",
    "        biases = new_bias(num_outputs, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.matmul(input, weights),biases,name=layer_name)\n",
    "    #     layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer, layer_name+'_activation')\n",
    "    \n",
    "    return layer\n",
    "\n",
    "\n",
    "def normalise_tensor(tensor):\n",
    "    return tf.div(\n",
    "   tf.subtract(\n",
    "      tensor, \n",
    "      tf.reduce_min(tensor)\n",
    "   ), \n",
    "   tf.subtract(\n",
    "      tf.reduce_max(tensor), \n",
    "      tf.reduce_min(tensor)\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p = tf.placeholder(tf.float32, shape=[None, img_size_flat*num_channels], name='x_p')\n",
    "x_o = tf.placeholder(tf.float32, shape=[None, img_size_flat*3], name='x_o')\n",
    "x_pred_image = tf.reshape(x_p, [-1, 10, 10, num_channels])\n",
    "x_orig_image = tf.reshape(x_p, [-1, 10, 10, 3])\n",
    "k = tf.constant(npatches)\n",
    "y_true = tf.placeholder(tf.int32, shape=[None, 2, 2], name='y_true')\n",
    "y_true_cls = tf.placeholder(tf.int32, shape=[None, 2, 2], name='y_true_cls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_custom_layer(input,\n",
    "                     orig_img,\n",
    "                     k_,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                name_scope,\n",
    "                layer_name='',\n",
    "                use_relu=True):\n",
    "    \n",
    "    with tf.name_scope(name_scope):\n",
    "        resh_inp = tf.reshape(input, [-1, 10, 10])\n",
    "        input_shape = tf.shape(resh_inp)\n",
    "        rows, cols = input_shape[1], input_shape[2]\n",
    "        d_rows, d_cols = 2, 2\n",
    "        subm_rows, subm_cols = rows - d_rows + 1, cols - d_cols + 1\n",
    "# #         # Index grids\n",
    "        ii, jj = tf.meshgrid(tf.range(subm_rows), tf.range(subm_cols), indexing='ij')\n",
    "        d_ii, d_jj = tf.meshgrid(tf.range(d_rows), tf.range(d_cols), indexing='ij')\n",
    "        \n",
    "#         # Add indices\n",
    "        subm_ii = ii[:, :, tf.newaxis, tf.newaxis] + d_ii\n",
    "        subm_jj = jj[:, :, tf.newaxis, tf.newaxis] + d_jj\n",
    "#         # Make submatrices tensor\n",
    "        subm = tf.gather_nd(resh_inp[0, :, :], tf.stack([subm_ii, subm_jj], axis=-1), name=layer_name + \"_gather\")\n",
    "#         # Add submatrices\n",
    "        subm_sum = tf.reduce_sum(subm, axis=(2, 3), name=layer_name + \"_subm_sum\")\n",
    "#         # Use TopK to find top submatrices\n",
    "        _, top_idx = tf.nn.top_k(tf.reshape(subm_sum, [-1]), tf.minimum(k, tf.size(subm_sum)), name=layer_name + \"_top_idx\")\n",
    "#         # Get row and column\n",
    "        top_row = top_idx // subm_cols\n",
    "        top_col = top_idx % subm_cols\n",
    "        result = tf.stack([top_row, top_col], axis=-1, name=layer_name + \"_result\")\n",
    "        result_shape = tf.shape(result)\n",
    "        result = tf.reshape(result, [-1, result_shape[0], result_shape[1]], name=layer_name + \"_shaped_result\")\n",
    "# Working Mask\n",
    "#         patches = tf.map_fn(lambda x: tf.cast(resh_inp[:, x[0]:x[0] + patch_size[0], x[1]:x[1] + patch_size[1]], dtype=tf.float32), result, dtype=tf.float32)\n",
    "#         patch_shape = tf.shape(patches)\n",
    "#         comb_patches = tf.reshape(patches, [-1, patch_shape[1], patch_shape[2]* patch_shape[3], patch_shape[3]], name=layer_name + \"_comb_patches\")\n",
    "\n",
    "#         patches = tf.squeeze(tf.map_fn(lambda x: tf.cast(resh_inp[:, x[0]:x[0] + patch_size[0], x[1]:x[1] + patch_size[1]], dtype=tf.float32), result, dtype=tf.float32))\n",
    "#         patch_shape = tf.shape(patches)\n",
    "#         comb_patches = tf.reshape(patches, [-1, patch_shape[0] * patch_shape[1], patch_shape[2], patch_shape[3]], name=layer_name + \"_comb_patches\")\n",
    "\n",
    "\n",
    "#Not working \n",
    "#         patches = tf.squeeze(tf.map_fn(lambda x: tf.cast(orig_img[:, x[0]:x[0] + patch_size[0], x[1]:x[1] + patch_size[1], :], dtype=tf.float32), result, dtype=tf.float32))\n",
    "#         patch_shape = tf.shape(patches)\n",
    "#         comb_patches = tf.reshape(patches, [-1, patch_shape[0] * patch_shape[1], patch_shape[2], patch_shape[3]], name=layer_name + \"_comb_patches\")\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"custom/custom_1_shaped_result:0\", shape=(?, ?, ?), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "layer1_conv1, weights_conv1 = new_conv_layer(input=x_pred_image,\n",
    "                                            num_input_channels=num_channels,\n",
    "                                            filter_size=filter_size1,\n",
    "                                            num_filters=num_filters1,\n",
    "                                             name_scope = 'cv',\n",
    "                                             layer_name='conv1',\n",
    "                                            use_pooling=True)\n",
    "\n",
    "# layer2_conv2, weights_conv2 =  new_conv_layer(input=layer1_conv1,\n",
    "#                                            num_input_channels=num_filters1,\n",
    "#                                            filter_size=filter_size2,\n",
    "#                                            num_filters=num_filters2,\n",
    "#                                              name_scope = 'cv',\n",
    "#                                              layer_name='conv2',\n",
    "#                                            use_pooling=True)\n",
    "\n",
    "# layer3_conv3, weights_conv3 =  new_conv_layer(input=layer2_conv2,\n",
    "#                                            num_input_channels=num_filters2,\n",
    "#                                            filter_size=filter_size3,\n",
    "#                                            num_filters=num_filters3,\n",
    "#                                              name_scope = 'cv',\n",
    "#                                              layer_name='conv3',\n",
    "#                                            use_pooling=True)\n",
    "\n",
    "# layer4_conv4, weights_conv4 =  new_conv_layer(input=layer3_conv3,\n",
    "#                                            num_input_channels=num_filters3,\n",
    "#                                            filter_size=filter_size4,\n",
    "#                                            num_filters=num_filters4,\n",
    "#                                              name_scope = 'cv',\n",
    "#                                              layer_name='conv4',\n",
    "#                                            use_pooling=True)\n",
    "\n",
    "\n",
    "layer_flat, num_features = flatten_layer(layer1_conv1)\n",
    "\n",
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=img_size_flat,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc_1',\n",
    "                         use_relu=False)\n",
    "\n",
    "\n",
    "# layer_fc2 = normalise_tensor(layer_fc1)\n",
    "\n",
    "# layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "#                          num_inputs=num_classes,\n",
    "#                          num_outputs=num_classes,\n",
    "#                          name_scope = 'fc',\n",
    "#                          layer_name = 'fc3',\n",
    "#                          use_relu=False)\n",
    "\n",
    "layer_fc3 = new_custom_layer(input=layer_fc1,\n",
    "                             orig_img = x_orig_image,\n",
    "                             k_=k,\n",
    "                         num_inputs=img_size_flat,\n",
    "                         num_outputs=num_classes,\n",
    "                         name_scope = 'custom',\n",
    "                         layer_name = 'custom_1',\n",
    "                         use_relu=False)\n",
    "\n",
    "# layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "#                          num_inputs=num_classes,\n",
    "#                          num_outputs=num_classes,\n",
    "#                          name_scope = 'fc',\n",
    "#                          layer_name = 'fc2',\n",
    "#                          use_relu=False)\n",
    "\n",
    "\n",
    "# print(layer_fc2)\n",
    "y_pred_cls = layer_fc3\n",
    "print(y_pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid type tf.int32 for Mean:0, expected: [tf.float32, tf.float64, tf.float16, tf.bfloat16].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5155ee855f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ## some more performance measures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# correct_prediction = tf.equal(y_pred_cls, y_true)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    489\u001b[0m                        \u001b[0;34m\"Optimizer.GATE_OP, Optimizer.GATE_GRAPH.  Not %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                        gate_gradients)\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_valid_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgrad_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_valid_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrad_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36m_assert_valid_dtypes\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    870\u001b[0m         raise ValueError(\n\u001b[1;32m    871\u001b[0m             \"Invalid type %r for %s, expected: %s.\" % (\n\u001b[0;32m--> 872\u001b[0;31m                 dtype, t.name, [v for v in valid_dtypes]))\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m   \u001b[0;31m# --------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid type tf.int32 for Mean:0, expected: [tf.float32, tf.float64, tf.float16, tf.bfloat16]."
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.square(y_true - y_pred_cls))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "# ## some more performance measures\n",
    "# correct_prediction = tf.equal(y_pred_cls, y_true)\n",
    "# accuracy, acc_op = tf.metrics.accuracy(labels=tf.argmax(y_true, axis=1), predictions=tf.argmax(y_pred_cls, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "session = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "train_labels = train_labels[:][:, 0]\n",
    "train_orig_data = train_data[0, :]\n",
    "train_pred_data = train_data[1, :]\n",
    "img_type = img_type[:]\n",
    "img_keys = img_keys[:]\n",
    "total_imgs = len(img_type)\n",
    "train_batch_size = 64\n",
    "\n",
    "def optimize(num_epochs, save_model=True,save_name= \"base_model\",restore_model=False,restore_name=None):\n",
    "    total_iterations = 0\n",
    "    done_train_imgs = 0\n",
    "    start_time = time.time()\n",
    "    start_ = 0\n",
    "    end_ = train_batch_size    \n",
    "    plot_accuracy=[]\n",
    "    plot_accuracy_epoch=[]\n",
    "    plot_training_size=[]\n",
    "    plot_training_size_epoch=[]\n",
    "    saver = tf.train.Saver()\n",
    "    sum_accuracy = 0.0\n",
    "    n = 1\n",
    "    \n",
    "        #to save the model\n",
    "    for i in range(0, num_epochs):   \n",
    "        start_batch=0\n",
    "        end_batch = train_batch_size\n",
    "        \n",
    "        print(\"Epoch:\", i + 1)\n",
    "        \n",
    "        if restore_model==True:\n",
    "            if restore_name==None:\n",
    "                print(\"No model file specified\")\n",
    "                return\n",
    "            else:\n",
    "                saver.restore(session,restore_name)\n",
    "        \n",
    "        sum_accuracy = 0.0\n",
    "        n = 1\n",
    "        while end_batch < total_imgs:\n",
    "            train_orig = train_orig_data[start_batch:end_batch]\n",
    "            train_pred = train_pred_data[start_batch:end_batch]\n",
    "            labels = train_labels[start_batch:end_batch]\n",
    "            img_type_lbl = img_type[start_:end_]\n",
    "            img_key = img_keys[start_:end_]\n",
    "            dims = (len(train_orig), num_classes, num_channels)\n",
    "            train, labels, img_type_lbl, img_key = get_batch_images(train_orig, train_pred, labels, img_type_lbl, img_key, dims, True)\n",
    "            if not len(train) and not len(labels):\n",
    "                print(\"All images have been processed.\")\n",
    "                break;\n",
    "\n",
    "            x_orig_batch, x_pred_batch, y_true_batch = next_batch(len(train[0]), train, labels)\n",
    "            feed_dict_train = {x_o: x_orig_batch, x_p: x_pred_batch,\n",
    "                       y_true: y_true_batch}\n",
    "            \n",
    "            session.run(optimizer, feed_dict=feed_dict_train)\n",
    "    \n",
    "            acc,co = session.run([accuracy, cost], feed_dict=feed_dict_train)\n",
    "            sum_accuracy += acc\n",
    "            n+=1\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "            print(msg.format(end_batch + 1, acc, co))\n",
    "            if i == num_epochs - 1:\n",
    "                plot_accuracy.append(acc)\n",
    "                plot_training_size.append(end_batch + 1)\n",
    "\n",
    "            start_batch += train_batch_size\n",
    "            end_batch += train_batch_size\n",
    "    \n",
    "        if save_model==True:\n",
    "            if save_name==None:\n",
    "                print(\"No model specified, model not being saved\")\n",
    "                return\n",
    "            else:\n",
    "                save_path = saver.save(session, save_name)\n",
    "                restore_model = True\n",
    "                print(\"Model saved in file: %s\" % save_name)\n",
    "        plot_accuracy_epoch.append(sum_accuracy/n)\n",
    "        plot_training_size_epoch.append(i + 1)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))  \n",
    "    print(plot_accuracy)\n",
    "    print(plot_training_size)\n",
    "    print(plot_accuracy_epoch)\n",
    "    print(plot_training_size_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_model = True\n",
    "save_name = model2_50000\n",
    "restore_model=False\n",
    "restore_name=model2_50000\n",
    "# init = tf.global_variables_initializer()\n",
    "# session.run(init)\n",
    "\n",
    "optimize(2, save_model=True,save_name=model2_50000,restore_model=False,restore_name=model2_50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train = train_data[0:1]\n",
    "merged_patch_lbls = train_labels[0:1, 0]\n",
    "mask_lbls = train_labels[0:1, 1]\n",
    "img_type_lbl = img_type[0:1]\n",
    "img_key = img_keys[0:1]\n",
    "dims = (1, num_classes, num_channels)\n",
    "# print(train, merged_patch_lbls, mask_lbls)\n",
    "train, labels, img_type_lbl, img_key = get_batch_images(train, merged_patch_lbls, img_type_lbl, img_key, dims, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_see_layer(orig, pred, model_name=None, var_name=None):\n",
    "    with tf.Session('', tf.Graph()) as s:\n",
    "        with s.graph.as_default():\n",
    "            if ((model_name != None) and var_name != None):\n",
    "                saver = tf.train.import_meta_graph(model_name+\".meta\")\n",
    "                saver.restore(s, model_name)\n",
    "#                 print(pred.shape)\n",
    "                fd = {'x_orig:0': orig, 'x_pred:0':pred}\n",
    "#                 print(fd.shape)\n",
    "                var_name=var_name+\":0\"\n",
    "                \n",
    "                \n",
    "                \n",
    "                result = 0\n",
    "                result = s.run(var_name, feed_dict=fd)\n",
    "    return result\n",
    "\n",
    "def see_output(iNp,depth_filter_to_see=0,cmap=\"gray\",figsize=(4,4)):\n",
    "    img_x = iNp[0,:,:,:]\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if cmap == \"gray\":\n",
    "        plt.imshow(img_x, cmap=plt.get_cmap('gray'))\n",
    "    else:\n",
    "        plt.imshow(img_x, interpolation='none', aspect='auto')\n",
    "#     plt.colorbar(img_x, orientation='horizontal')\n",
    "    plt.show()\n",
    "    \n",
    "def save_patch_images(img_x1, lbl_x1, index):\n",
    "    if not os.path.exists('./SD/predicted_patches/' + str(index)):\n",
    "        os.makedirs('./SD/predicted_patches/' + str(index))\n",
    "        os.makedirs('./SD/predicted_patches/' + str(index) + \"/\" + str(lbl_x1))\n",
    "        \n",
    "    plt.imsave('./SD/predicted_patches/' + str(index) + \"/\" + str(lbl_x1) + '/img.png', np.squeeze(img_x1))\n",
    "    \n",
    "\n",
    "def predict_nd_save(train, labels, img_type_lbl, img_key, start_idx):\n",
    "\n",
    "    for index in range(0, len(train)):\n",
    "        img_x = train[index:index+1, :]\n",
    "        lbl_x = labels[index:index+1, :]\n",
    "        img_type_x = img_type_lbl[index]\n",
    "        img_key_x = img_key[index]\n",
    "        prediction = restore_see_layer(ix=img_x,model_name=model2_50000,var_name='custom/custom_1_comb_patches')\n",
    "        prediction = np.reshape(prediction, (1, 4, 2, 1))   \n",
    "        save_patch_images(prediction, img_type_x, img_key_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train_mask_labels = train_labels[:][:, 1]\n",
    "train_patch_labels = train_labels[:][:, 0]\n",
    "\n",
    "batch_s = 64\n",
    "total_iterations = 0\n",
    "start_ = 0\n",
    "end_ = batch_s\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "if not os.path.exists('./SD/predicted_patches'):\n",
    "    os.makedirs('./SD/predicted_patches')\n",
    "\n",
    "while True:\n",
    "    train = train_data[start_:end_]\n",
    "    labels = train_patch_labels[start_:end_]\n",
    "    img_type_lbl = img_type[start_:end_]\n",
    "    img_key = img_keys[start_:end_]\n",
    "    dims = (batch_s, num_classes, num_channels)\n",
    "    train, labels, img_type_lbl, img_key = get_batch_images(train, labels, img_type_lbl, img_key, dims, True)\n",
    "    predict_nd_save(train, labels, img_type_lbl, img_key, start_)\n",
    "    \n",
    "    #do my stuff\n",
    "    if len(train_data) < start_ + batch_s:\n",
    "        print(\"{} Images have been processed.\".format(total_iterations))\n",
    "        break\n",
    "    \n",
    "    total_iterations +=batch_s\n",
    "    start_ = end_\n",
    "    end_ = end_ + batch_s   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig = train_data[0, 0:1]\n",
    "train_pred = train_data[1, 0:1]\n",
    "labels = train_labels[0:1, 0]\n",
    "labels\n",
    "img_type_lbl = img_type[0:1]\n",
    "img_key = img_keys[0:1]\n",
    "dims = (1, num_classes, num_channels)\n",
    "train, labels, img_type_lbl, img_key = get_batch_images(train_orig, train_pred, labels, img_type_lbl, img_key, dims, True)\n",
    "# train[0:1]\n",
    "# img_x = cv2.imread(\"../../original_images/SD/15970/0/img/predicted_mask.png\")\n",
    "\n",
    "# img_x = np.expand_dims(img_x[:,:,0].flatten(), axis=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "# print(train)\n",
    "output_cl1 = restore_see_layer(orig=np.expand_dims(train[0][0], axis=0), pred=np.expand_dims(train[1][0], axis=0), model_name=model2_50000,var_name='custom/custom_1_comb_patches')\n",
    "# output_cl2 = restore_see_layer(ix=train,model_name=model2_50000,var_name='custom/custom_1_comb_patches')\n",
    "print(output_cl1)\n",
    "# show_img = np.expand_dims(np.reshape(output_cl1, (4,2)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output_cl1.shape)\n",
    "new_img = np.reshape(output_cl1, [4, 2])\n",
    "fig = plt.figure(figsize=(2,4))\n",
    "plt.imshow(new_img, interpolation='none', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_x = cv2.imread(\"../../original_images/SD/15970/0/labels/merged_patch.png\")\n",
    "print(img_x.shape)\n",
    "reshaped_img_x = np.expand_dims(img_x, axis=0)\n",
    "\n",
    "grey_img = np.dot(img_x[...,:3], [0.299, 0.587, 0.114])\n",
    "print(grey_img.shape)\n",
    "\n",
    "# grey_img = normalize(grey_img)\n",
    "\n",
    "# see_output(reshaped_img_x, figsize=(2,4))\n",
    "\n",
    "fig = plt.figure(figsize=(2,4))\n",
    "# print(grey_img)\n",
    "plt.imshow(grey_img, interpolation='none', aspect='auto')\n",
    "# see_output(reshaped_img_x, figsize = (2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors(graph=tf.get_default_graph()):\n",
    "    return [t for op in graph.get_operations() for t in op.values()]\n",
    "get_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
