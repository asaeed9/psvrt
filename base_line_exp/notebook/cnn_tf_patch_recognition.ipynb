{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2, os, math, time\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configuration\n",
    "\"\"\"\n",
    "Data Configurations/Paths\n",
    "\"\"\"\n",
    "img_dir=\"../../original_images/SD\"\n",
    "\n",
    "##\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 4          # Convolution filters are 4 x 4 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters2 = 32         # There are 32 of these filters.\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters3 = 64         # There are 64 of these filters.\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size4 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters4 = 128         # There are 128 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 2000             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label_dimensions(labels):\n",
    "    label_temp = np.zeros((len(labels), 2))\n",
    "    \n",
    "    for idx in range(0, len(labels)):\n",
    "        if labels[idx] == 1:\n",
    "            label_temp[idx][1] = 1\n",
    "        else:\n",
    "            label_temp[idx][0] = 1\n",
    "    \n",
    "    return label_temp\n",
    "\n",
    "def load_data(img_dir):\n",
    "        list_of_imgs = []\n",
    "        list_of_labels = []\n",
    "        for img in os.listdir(img_dir):\n",
    "            img_path = os.path.join(img_dir, img)\n",
    "            for img_label in os.listdir(img_path):\n",
    "                img_data = os.path.join(img_path, img_label)\n",
    "                if img_label == \"img\":\n",
    "#                     print(img_data + \"/img.png\")\n",
    "                    list_of_imgs.append(img_data + \"/img.png\")\n",
    "                else:\n",
    "                        list_of_labels.append([os.path.join(img_data, label) for label in os.listdir(img_data)])\n",
    "\n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        data_labels = np.array(list_of_labels)\n",
    "\n",
    "        return data_imgs, data_labels\n",
    "\n",
    "\n",
    "# def load_data(img_dir, label):\n",
    "#         list_of_imgs = []\n",
    "#         list_of_labels = []\n",
    "#         for img in os.listdir(img_dir):\n",
    "#                 img = os.path.join(img_dir, img)\n",
    "# #                 print(img)\n",
    "#                 if not img.endswith(\".png\"):\n",
    "#                         continue\n",
    "\n",
    "#                 list_of_imgs.append(img)\n",
    "#                 list_of_labels.append(label)\n",
    "#         data_labels = np.asarray(list_of_labels, dtype=np.int32)\n",
    "#         data_imgs = np.array(list_of_imgs)\n",
    "# #         data_labels = np.array(list_of_labels)\n",
    "#         return data_imgs, data_labels\n",
    "    \n",
    "def get_batch_images(data, label):\n",
    "        list_of_imgs = []\n",
    "        list_of_labels = []\n",
    "        for img, lbl in zip(data, label):\n",
    "#             print(img, lbl)\n",
    "            orig_img = cv2.imread(img)\n",
    "            #only first image as a label\n",
    "            orig_lbl = cv2.imread(lbl[0])\n",
    "            if orig_img is None or orig_lbl is None:\n",
    "                    print (\"Unable to read image{} or {}\".format(img, lbl))\n",
    "                    continue\n",
    "            \n",
    "            flattened_img = orig_img.flatten()\n",
    "            flattened_lbl = orig_lbl.flatten()\n",
    "            \n",
    "#             flattened_a = tf.cast(flattened_a, tf.float32)\n",
    "                \n",
    "#             print(type(flattened_a.shape)) \n",
    "#             print(type(np.asarray(flattened_a, dtype=np.float32)))\n",
    "            \n",
    "            list_of_imgs.append(np.asarray(flattened_img, dtype=np.float32))\n",
    "            list_of_labels.append(np.asarray(flattened_lbl, dtype=np.float32))\n",
    "\n",
    "        data_labels = np.array(list_of_labels)\n",
    "        data_imgs = np.array(list_of_imgs)\n",
    "        \n",
    "#         print(data_imgs)\n",
    "#         print(data_labels)\n",
    "        \n",
    "        return data_imgs, data_labels\n",
    "\n",
    "# train_imgs, train_labels = load_data(img_dir)\n",
    "# train_imgs1, train_labels1 = get_batch_images(train_imgs[:5], train_labels[:5])\n",
    "\n",
    "# print(train_imgs1)\n",
    "# print(train_labels1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Batch Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that images are 60 pixels in each dimension.\n",
    "# img_size = 8 * 4\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 60 * 60\n",
    "\n",
    "# Number of colour channels for the images: 3 channel for RGB.\n",
    "num_channels = 3\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (60, 60, num_channels)\n",
    "\n",
    "\n",
    "# Number of classes, one class for same or different image\n",
    "num_classes = 20*20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getActivations(layer,stimuli):\n",
    "    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1,784],order='F'),keep_prob:1.0})\n",
    "    plotNNFilter(units)\n",
    "    \n",
    "def plotNNFilter(units):\n",
    "    filters = units.shape[3]\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")\n",
    "        \n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(cv2.imread(images[i]).flatten().reshape((8,4, 3)), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def generate_size_graph(fig_no, training_size, accuracy, loss, patch_only,patch_conv, start_size, end_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(training_size,accuracy)\n",
    "    plt.plot(training_size,loss)\n",
    "    plt.plot(training_size, patch_only)\n",
    "    plt.plot(training_size, patch_conv)\n",
    "    plt.xlabel('Training Size')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Size vs Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['SD Original Accuracy','SR Accuracy', 'SD Patch Accuracy', 'SD Patch Conv'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(path + '/batch_graphs/' +  str(start_size) + '_' + str(end_size) + '.jpg') \n",
    "        \n",
    "def generate_graph(fig_no, epochs, train, val, label, train_title, val_title, train_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(epochs,train)\n",
    "    plt.plot(epochs,val)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel(label)\n",
    "    plt.title(train_title + ' vs ' + val_title + '( Samples:' + str(train_size) + ')')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(results_path + '/batch_graphs/' +  label + '_' + str(train_size) + '.jpg')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Few Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first images from the train-set.\n",
    "images = train_data[0:9]\n",
    "# Get the true classes for those images.\n",
    "cls_true = train_labels[0:9]\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Helper Functions for TF Graph Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape, layer_name):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape), name=layer_name+'_W')\n",
    "#     return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def new_bias(length, layer_name):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]), name=layer_name+'_b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,\n",
    "                   num_input_channels,\n",
    "                   filter_size,\n",
    "                   num_filters,\n",
    "                   name_scope,\n",
    "                   layer_name='',\n",
    "                   use_pooling=True):\n",
    "\n",
    "    with tf.name_scope(name_scope):\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "        weights = new_weights(shape, layer_name)\n",
    "        biases = new_bias(num_filters, layer_name)\n",
    "    #     layer = tf.nn.conv2d(input=input,\n",
    "    #                      filter=weights,\n",
    "    #                      strides=[1, 1, 1, 1],\n",
    "    #                      padding='SAME')\n",
    "    #     layer += biases\n",
    "\n",
    "        layer = tf.add(tf.nn.conv2d(input=input, filter=weights, strides=[1,1,1,1], padding='SAME'), biases, name=layer_name)\n",
    "\n",
    "        if use_pooling:\n",
    "            layer = tf.nn.max_pool(value=layer,\n",
    "                                   ksize=[1, 3, 3, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME', name=layer_name+'_max')\n",
    "        layer = tf.nn.relu(layer, name=layer_name+'_activation')\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                name_scope,\n",
    "                layer_name='',\n",
    "                use_relu=True):\n",
    "    \n",
    "    with tf.name_scope(name_scope):\n",
    "        weights = new_weights([num_inputs, num_outputs], layer_name)\n",
    "        biases = new_bias(num_outputs, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.matmul(input, weights),biases,name=layer_name)\n",
    "    #     layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer, layer_name+'_activation')\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(60), Dimension(60), Dimension(3)]),\n",
       " <tf.Tensor 'y_true_3:0' shape=(?, 1200) dtype=float32>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat*num_channels], name='x')\n",
    "x_image = tf.reshape(x, [-1, 60, 60, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes * num_channels], name='y_true')\n",
    "# y_true_cls = tf.argmax(y_true, axis=1)\n",
    "y_true_cls = tf.placeholder(tf.float32, shape=[None, num_classes * num_channels], name='y_true_cls')\n",
    "x_image.shape, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
    "                                            num_input_channels=num_channels,\n",
    "                                            filter_size=filter_size1,\n",
    "                                            num_filters=num_filters1,\n",
    "                                             name_scope = 'cv',\n",
    "                                             layer_name='conv1',\n",
    "                                            use_pooling=True)\n",
    "\n",
    "layer2_conv2, weights_conv2 =  new_conv_layer(input=layer1_conv1,\n",
    "                                           num_input_channels=num_filters1,\n",
    "                                           filter_size=filter_size2,\n",
    "                                           num_filters=num_filters2,\n",
    "                                             name_scope = 'cv',\n",
    "                                             layer_name='conv2',\n",
    "                                           use_pooling=True)\n",
    "\n",
    "layer3_conv3, weights_conv3 =  new_conv_layer(input=layer2_conv2,\n",
    "                                           num_input_channels=num_filters2,\n",
    "                                           filter_size=filter_size3,\n",
    "                                           num_filters=num_filters3,\n",
    "                                             name_scope = 'cv',\n",
    "                                             layer_name='conv3',\n",
    "                                           use_pooling=True)\n",
    "\n",
    "layer4_conv4, weights_conv4 =  new_conv_layer(input=layer3_conv3,\n",
    "                                           num_input_channels=num_filters3,\n",
    "                                           filter_size=filter_size4,\n",
    "                                           num_filters=num_filters4,\n",
    "                                             name_scope = 'cv',\n",
    "                                             layer_name='conv4',\n",
    "                                           use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer4_conv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc1',\n",
    "                         use_relu=True)\n",
    "\n",
    "\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc2',\n",
    "                         use_relu=False)\n",
    "\n",
    "layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc3',\n",
    "                         use_relu=False)\n",
    "\n",
    "layer_fc4 = new_fc_layer(input=layer_fc3,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes * num_channels,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc4',\n",
    "                         use_relu=False)\n",
    "\n",
    "# drop_out = tf.nn.dropout(layer_fc4, 0.5)\n",
    "\n",
    "##Normalize the numbers(apply softmax!)\n",
    "y_pred_cls = layer_fc4\n",
    "y_pred = layer_fc4\n",
    "# y_pred = tf.nn.softmax(drop_out)\n",
    "# y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost = tf.reduce_mean(-tf.reduce_sum(y_pred_cls * tf.log(y_true), reduction_indices=[1]))\n",
    "cost = tf.reduce_mean(tf.square(y_true - y_pred_cls))\n",
    "# cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=y_pred,\n",
    "#                                                         labels=y_true)\n",
    "# cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "## some more performance measures\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tensorflow on Defined Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "train_data, train_labels = load_data(img_dir)\n",
    "train_batch_size = 64\n",
    "\n",
    "def optimize(num_iterations, save_model=True,save_name=base_model,restore_model=False,restore_name=None):\n",
    "    total_iterations = 0\n",
    "    done_train_imgs = 0\n",
    "    start_time = time.time()\n",
    "    start_batch=0\n",
    "    end_batch = train_batch_size\n",
    "    plot_accuracy=[]\n",
    "    plot_training_size=[]\n",
    "    \n",
    "    #to save the model\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    if restore_model==True:\n",
    "        if restore_name==None:\n",
    "            print(\"No model file specified\")\n",
    "            return\n",
    "        else:\n",
    "            saver.restore(session,restore_name)\n",
    "            \n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        total_iterations = 0\n",
    "        start_batch=0\n",
    "        end_batch = train_batch_size\n",
    "#         train_data, train_labels = load_data(img_dir)\n",
    "        while True:\n",
    "            train = train_data[start_batch:end_batch]\n",
    "            labels = train_labels[start_batch:end_batch]\n",
    "            train, labels = get_batch_images(train, labels)\n",
    "            if not len(train) and not len(labels):\n",
    "                print(\"All images have been processed.\")\n",
    "                break;\n",
    "\n",
    "            x_batch, y_true_batch = next_batch(train_batch_size, train, labels)\n",
    "    #         x_batch, y_true_batch = train_data[done_train_images:done_train_imgs+train_batch_size]\n",
    "            feed_dict_train = {x: x_batch,\n",
    "                       y_true: y_true_batch}\n",
    "            \n",
    "            session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "    #         if total_iterations%1000==0:    \n",
    "            acc,co = session.run([accuracy, cost], feed_dict=feed_dict_train)\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "            print(msg.format(total_iterations + 1, acc, co))\n",
    "            \n",
    "            plot_accuracy.append(acc)\n",
    "            plot_training_size.append((total_iterations + 1) * 64)\n",
    "\n",
    "                # Update the total number of iterations performed.\n",
    "    #         done_train_imgs+=train_batch_size\n",
    "            start_batch += train_batch_size\n",
    "            end_batch += train_batch_size\n",
    "            total_iterations +=1\n",
    "\n",
    "        if save_model==True:\n",
    "            if save_name==None:\n",
    "                print(\"No model specified, model not being saved\")\n",
    "                return\n",
    "            else:\n",
    "                save_path = saver.save(session, save_name)\n",
    "                print(\"Model saved in file: %s\" % save_name)\n",
    "        \n",
    "#         total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))  \n",
    "    print(plot_accuracy)\n",
    "    print(plot_training_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance/Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:   0.0%, Loss: 19872.1094\n",
      "Optimization Iteration:      2, Training Accuracy:   0.0%, Loss: 17603.2695\n",
      "Optimization Iteration:      3, Training Accuracy:   0.0%, Loss: 15479.3115\n",
      "Optimization Iteration:      4, Training Accuracy:   0.0%, Loss: 13197.9932\n",
      "Optimization Iteration:      5, Training Accuracy:   0.0%, Loss: 11338.6182\n",
      "Optimization Iteration:      6, Training Accuracy:   0.0%, Loss: 10457.6719\n",
      "Optimization Iteration:      7, Training Accuracy:   0.0%, Loss: 10236.4473\n",
      "Optimization Iteration:      8, Training Accuracy:   0.0%, Loss: 9455.6299\n",
      "Optimization Iteration:      9, Training Accuracy:   0.0%, Loss: 8681.0791\n",
      "Optimization Iteration:     10, Training Accuracy:   0.0%, Loss: 8190.6719\n",
      "Optimization Iteration:     11, Training Accuracy:   0.0%, Loss: 8048.7217\n",
      "Optimization Iteration:     12, Training Accuracy:   0.0%, Loss: 8117.8433\n",
      "Optimization Iteration:     13, Training Accuracy:   0.0%, Loss: 8256.5234\n",
      "Optimization Iteration:     14, Training Accuracy:   0.0%, Loss: 8216.1367\n",
      "Optimization Iteration:     15, Training Accuracy:   0.0%, Loss: 8132.4868\n",
      "Optimization Iteration:     16, Training Accuracy:   0.0%, Loss: 8082.4019\n",
      "Optimization Iteration:     17, Training Accuracy:   0.0%, Loss: 8031.2368\n",
      "Optimization Iteration:     18, Training Accuracy:   0.0%, Loss: 8012.9834\n",
      "Optimization Iteration:     19, Training Accuracy:   0.0%, Loss: 7976.0386\n",
      "Optimization Iteration:     20, Training Accuracy:   0.0%, Loss: 7892.4033\n",
      "Optimization Iteration:     21, Training Accuracy:   0.0%, Loss: 7797.4116\n",
      "Optimization Iteration:     22, Training Accuracy:   0.0%, Loss: 7764.5898\n",
      "Optimization Iteration:     23, Training Accuracy:   0.0%, Loss: 7718.0298\n",
      "Optimization Iteration:     24, Training Accuracy:   0.0%, Loss: 7728.8633\n",
      "Optimization Iteration:     25, Training Accuracy:   0.0%, Loss: 7684.0757\n",
      "Optimization Iteration:     26, Training Accuracy:   0.0%, Loss: 7643.7632\n",
      "Optimization Iteration:     27, Training Accuracy:   0.0%, Loss: 7635.9976\n",
      "Optimization Iteration:     28, Training Accuracy:   0.0%, Loss: 7620.7393\n",
      "Optimization Iteration:     29, Training Accuracy:   0.0%, Loss: 7627.0918\n",
      "Optimization Iteration:     30, Training Accuracy:   0.0%, Loss: 7622.1299\n",
      "Optimization Iteration:     31, Training Accuracy:   0.0%, Loss: 7586.4419\n",
      "Optimization Iteration:     32, Training Accuracy:   0.0%, Loss: 7613.2051\n",
      "Optimization Iteration:     33, Training Accuracy:   0.0%, Loss: 7567.7666\n",
      "Optimization Iteration:     34, Training Accuracy:   0.0%, Loss: 7556.3218\n",
      "Optimization Iteration:     35, Training Accuracy:   0.0%, Loss: 7572.9951\n",
      "Optimization Iteration:     36, Training Accuracy:   0.0%, Loss: 7551.9116\n",
      "Optimization Iteration:     37, Training Accuracy:   0.0%, Loss: 7555.7266\n",
      "Optimization Iteration:     38, Training Accuracy:   0.0%, Loss: 7563.7261\n",
      "Optimization Iteration:     39, Training Accuracy:   0.0%, Loss: 7580.0952\n",
      "Optimization Iteration:     40, Training Accuracy:   0.0%, Loss: 7542.7549\n",
      "Optimization Iteration:     41, Training Accuracy:   0.0%, Loss: 7531.4565\n",
      "Optimization Iteration:     42, Training Accuracy:   0.0%, Loss: 7540.1968\n",
      "Optimization Iteration:     43, Training Accuracy:   0.0%, Loss: 7521.2051\n",
      "Optimization Iteration:     44, Training Accuracy:   0.0%, Loss: 7546.4248\n",
      "Optimization Iteration:     45, Training Accuracy:   0.0%, Loss: 7522.2090\n",
      "Optimization Iteration:     46, Training Accuracy:   0.0%, Loss: 7525.4761\n",
      "Optimization Iteration:     47, Training Accuracy:   0.0%, Loss: 7513.1108\n",
      "Optimization Iteration:     48, Training Accuracy:   0.0%, Loss: 7507.1523\n",
      "Optimization Iteration:     49, Training Accuracy:   0.0%, Loss: 7518.4893\n",
      "Optimization Iteration:     50, Training Accuracy:   0.0%, Loss: 7526.0635\n",
      "Optimization Iteration:     51, Training Accuracy:   0.0%, Loss: 7514.5767\n",
      "Optimization Iteration:     52, Training Accuracy:   0.0%, Loss: 7520.6685\n",
      "Optimization Iteration:     53, Training Accuracy:   0.0%, Loss: 7509.7700\n",
      "Optimization Iteration:     54, Training Accuracy:   0.0%, Loss: 7516.2827\n",
      "Optimization Iteration:     55, Training Accuracy:   0.0%, Loss: 7499.9126\n",
      "Optimization Iteration:     56, Training Accuracy:   0.0%, Loss: 7500.8384\n",
      "Optimization Iteration:     57, Training Accuracy:   0.0%, Loss: 7506.3940\n",
      "Optimization Iteration:     58, Training Accuracy:   0.0%, Loss: 7510.6899\n",
      "Optimization Iteration:     59, Training Accuracy:   0.0%, Loss: 7502.3667\n",
      "Optimization Iteration:     60, Training Accuracy:   0.0%, Loss: 7503.2886\n",
      "Optimization Iteration:     61, Training Accuracy:   0.0%, Loss: 7509.8267\n",
      "Optimization Iteration:     62, Training Accuracy:   0.0%, Loss: 7501.4185\n",
      "Optimization Iteration:     63, Training Accuracy:   0.0%, Loss: 7480.5698\n",
      "All images have been processed.\n",
      "Model saved in file: SD/sd_01_.ckpt\n",
      "Optimization Iteration:      1, Training Accuracy:   0.0%, Loss: 7519.7915\n",
      "Optimization Iteration:      2, Training Accuracy:   0.0%, Loss: 7490.1484\n",
      "Optimization Iteration:      3, Training Accuracy:   0.0%, Loss: 7503.5635\n",
      "Optimization Iteration:      4, Training Accuracy:   0.0%, Loss: 7489.1650\n",
      "Optimization Iteration:      5, Training Accuracy:   0.0%, Loss: 7496.6719\n",
      "Optimization Iteration:      6, Training Accuracy:   0.0%, Loss: 7503.1416\n",
      "Optimization Iteration:      7, Training Accuracy:   0.0%, Loss: 7509.1489\n",
      "Optimization Iteration:      8, Training Accuracy:   0.0%, Loss: 7492.3794\n",
      "Optimization Iteration:      9, Training Accuracy:   0.0%, Loss: 7484.3340\n",
      "Optimization Iteration:     10, Training Accuracy:   0.0%, Loss: 7486.9941\n",
      "Optimization Iteration:     11, Training Accuracy:   0.0%, Loss: 7495.7202\n",
      "Optimization Iteration:     12, Training Accuracy:   0.0%, Loss: 7496.7773\n",
      "Optimization Iteration:     13, Training Accuracy:   0.0%, Loss: 7498.1533\n",
      "Optimization Iteration:     14, Training Accuracy:   0.0%, Loss: 7499.8477\n",
      "Optimization Iteration:     15, Training Accuracy:   0.0%, Loss: 7485.8867\n",
      "Optimization Iteration:     16, Training Accuracy:   0.0%, Loss: 7496.3535\n",
      "Optimization Iteration:     17, Training Accuracy:   0.0%, Loss: 7495.2324\n",
      "Optimization Iteration:     18, Training Accuracy:   0.0%, Loss: 7497.9082\n",
      "Optimization Iteration:     19, Training Accuracy:   0.0%, Loss: 7494.8657\n",
      "Optimization Iteration:     20, Training Accuracy:   0.0%, Loss: 7475.5981\n",
      "Optimization Iteration:     21, Training Accuracy:   0.0%, Loss: 7483.3276\n",
      "Optimization Iteration:     22, Training Accuracy:   0.0%, Loss: 7486.4517\n",
      "Optimization Iteration:     23, Training Accuracy:   0.0%, Loss: 7486.0269\n",
      "Optimization Iteration:     24, Training Accuracy:   0.0%, Loss: 7492.2393\n",
      "Optimization Iteration:     25, Training Accuracy:   0.0%, Loss: 7489.3442\n",
      "Optimization Iteration:     26, Training Accuracy:   0.0%, Loss: 7477.5850\n",
      "Optimization Iteration:     27, Training Accuracy:   0.0%, Loss: 7484.9702\n",
      "Optimization Iteration:     28, Training Accuracy:   0.0%, Loss: 7490.5200\n",
      "Optimization Iteration:     29, Training Accuracy:   0.0%, Loss: 7497.2935\n",
      "Optimization Iteration:     30, Training Accuracy:   0.0%, Loss: 7491.3916\n",
      "Optimization Iteration:     31, Training Accuracy:   0.0%, Loss: 7481.8965\n",
      "Optimization Iteration:     32, Training Accuracy:   0.0%, Loss: 7491.9360\n",
      "Optimization Iteration:     33, Training Accuracy:   0.0%, Loss: 7487.6650\n",
      "Optimization Iteration:     34, Training Accuracy:   0.0%, Loss: 7477.1064\n",
      "Optimization Iteration:     35, Training Accuracy:   0.0%, Loss: 7494.2686\n",
      "Optimization Iteration:     36, Training Accuracy:   0.0%, Loss: 7481.8799\n",
      "Optimization Iteration:     37, Training Accuracy:   0.0%, Loss: 7475.9668\n",
      "Optimization Iteration:     38, Training Accuracy:   0.0%, Loss: 7484.5659\n",
      "Optimization Iteration:     39, Training Accuracy:   0.0%, Loss: 7502.0186\n",
      "Optimization Iteration:     40, Training Accuracy:   0.0%, Loss: 7475.7666\n",
      "Optimization Iteration:     41, Training Accuracy:   0.0%, Loss: 7473.9048\n",
      "Optimization Iteration:     42, Training Accuracy:   0.0%, Loss: 7492.4951\n",
      "Optimization Iteration:     43, Training Accuracy:   0.0%, Loss: 7471.2231\n",
      "Optimization Iteration:     44, Training Accuracy:   0.0%, Loss: 7492.4502\n",
      "Optimization Iteration:     45, Training Accuracy:   0.0%, Loss: 7482.7183\n",
      "Optimization Iteration:     46, Training Accuracy:   0.0%, Loss: 7481.9932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:     47, Training Accuracy:   0.0%, Loss: 7476.6567\n",
      "Optimization Iteration:     48, Training Accuracy:   0.0%, Loss: 7480.4683\n",
      "Optimization Iteration:     49, Training Accuracy:   0.0%, Loss: 7485.8501\n",
      "Optimization Iteration:     50, Training Accuracy:   0.0%, Loss: 7497.4814\n",
      "Optimization Iteration:     51, Training Accuracy:   0.0%, Loss: 7490.0850\n",
      "Optimization Iteration:     52, Training Accuracy:   0.0%, Loss: 7495.8535\n",
      "Optimization Iteration:     53, Training Accuracy:   0.0%, Loss: 7483.4766\n",
      "Optimization Iteration:     54, Training Accuracy:   0.0%, Loss: 7486.4067\n",
      "Optimization Iteration:     55, Training Accuracy:   0.0%, Loss: 7482.1616\n",
      "Optimization Iteration:     56, Training Accuracy:   0.0%, Loss: 7475.3335\n",
      "Optimization Iteration:     57, Training Accuracy:   0.0%, Loss: 7484.2515\n",
      "Optimization Iteration:     58, Training Accuracy:   0.0%, Loss: 7487.8560\n",
      "Optimization Iteration:     59, Training Accuracy:   0.0%, Loss: 7479.3491\n",
      "Optimization Iteration:     60, Training Accuracy:   0.0%, Loss: 7485.7891\n",
      "Optimization Iteration:     61, Training Accuracy:   0.0%, Loss: 7487.7002\n",
      "Optimization Iteration:     62, Training Accuracy:   0.0%, Loss: 7482.9385\n",
      "Optimization Iteration:     63, Training Accuracy:   0.0%, Loss: 7463.3252\n",
      "All images have been processed.\n",
      "Model saved in file: SD/sd_01_.ckpt\n",
      "Optimization Iteration:      1, Training Accuracy:   0.0%, Loss: 7491.6436\n",
      "Optimization Iteration:      2, Training Accuracy:   0.0%, Loss: 7473.3691\n",
      "Optimization Iteration:      3, Training Accuracy:   0.0%, Loss: 7483.8052\n",
      "Optimization Iteration:      4, Training Accuracy:   0.0%, Loss: 7475.2866\n",
      "Optimization Iteration:      5, Training Accuracy:   0.0%, Loss: 7477.4165\n",
      "Optimization Iteration:      6, Training Accuracy:   0.0%, Loss: 7495.0386\n",
      "Optimization Iteration:      7, Training Accuracy:   0.0%, Loss: 7488.9351\n",
      "Optimization Iteration:      8, Training Accuracy:   0.0%, Loss: 7479.8799\n",
      "Optimization Iteration:      9, Training Accuracy:   0.0%, Loss: 7469.3540\n",
      "Optimization Iteration:     10, Training Accuracy:   0.0%, Loss: 7475.0508\n",
      "Optimization Iteration:     11, Training Accuracy:   0.0%, Loss: 7483.5532\n",
      "Optimization Iteration:     12, Training Accuracy:   0.0%, Loss: 7479.3750\n",
      "Optimization Iteration:     13, Training Accuracy:   0.0%, Loss: 7484.5669\n",
      "Optimization Iteration:     14, Training Accuracy:   0.0%, Loss: 7484.0483\n",
      "Optimization Iteration:     15, Training Accuracy:   0.0%, Loss: 7474.5200\n",
      "Optimization Iteration:     16, Training Accuracy:   0.0%, Loss: 7475.1118\n",
      "Optimization Iteration:     17, Training Accuracy:   0.0%, Loss: 7483.4551\n",
      "Optimization Iteration:     18, Training Accuracy:   0.0%, Loss: 7479.4707\n",
      "Optimization Iteration:     19, Training Accuracy:   0.0%, Loss: 7480.6323\n",
      "Optimization Iteration:     20, Training Accuracy:   0.0%, Loss: 7461.8574\n",
      "Optimization Iteration:     21, Training Accuracy:   0.0%, Loss: 7470.0308\n",
      "Optimization Iteration:     22, Training Accuracy:   0.0%, Loss: 7471.1001\n",
      "Optimization Iteration:     23, Training Accuracy:   0.0%, Loss: 7473.0835\n",
      "Optimization Iteration:     24, Training Accuracy:   0.0%, Loss: 7471.8281\n",
      "Optimization Iteration:     25, Training Accuracy:   0.0%, Loss: 7477.0151\n",
      "Optimization Iteration:     26, Training Accuracy:   0.0%, Loss: 7469.5601\n",
      "Optimization Iteration:     27, Training Accuracy:   0.0%, Loss: 7467.5698\n",
      "Optimization Iteration:     28, Training Accuracy:   0.0%, Loss: 7478.2456\n",
      "Optimization Iteration:     29, Training Accuracy:   0.0%, Loss: 7478.3184\n",
      "Optimization Iteration:     30, Training Accuracy:   0.0%, Loss: 7472.1699\n",
      "Optimization Iteration:     31, Training Accuracy:   0.0%, Loss: 7471.1802\n",
      "Optimization Iteration:     32, Training Accuracy:   0.0%, Loss: 7473.0591\n",
      "Optimization Iteration:     33, Training Accuracy:   0.0%, Loss: 7477.9668\n",
      "Optimization Iteration:     34, Training Accuracy:   0.0%, Loss: 7466.0000\n",
      "Optimization Iteration:     35, Training Accuracy:   0.0%, Loss: 7481.3218\n",
      "Optimization Iteration:     36, Training Accuracy:   0.0%, Loss: 7470.3501\n",
      "Optimization Iteration:     37, Training Accuracy:   0.0%, Loss: 7465.6157\n",
      "Optimization Iteration:     38, Training Accuracy:   0.0%, Loss: 7471.7383\n",
      "Optimization Iteration:     39, Training Accuracy:   0.0%, Loss: 7487.6152\n",
      "Optimization Iteration:     40, Training Accuracy:   0.0%, Loss: 7464.8467\n",
      "Optimization Iteration:     41, Training Accuracy:   0.0%, Loss: 7463.7007\n",
      "Optimization Iteration:     42, Training Accuracy:   0.0%, Loss: 7482.7251\n",
      "Optimization Iteration:     43, Training Accuracy:   0.0%, Loss: 7461.9834\n",
      "Optimization Iteration:     44, Training Accuracy:   0.0%, Loss: 7480.7515\n",
      "Optimization Iteration:     45, Training Accuracy:   0.0%, Loss: 7469.9292\n",
      "Optimization Iteration:     46, Training Accuracy:   0.0%, Loss: 7473.0859\n",
      "Optimization Iteration:     47, Training Accuracy:   0.0%, Loss: 7464.4531\n",
      "Optimization Iteration:     48, Training Accuracy:   0.0%, Loss: 7469.3652\n",
      "Optimization Iteration:     49, Training Accuracy:   0.0%, Loss: 7474.4731\n",
      "Optimization Iteration:     50, Training Accuracy:   0.0%, Loss: 7483.8867\n",
      "Optimization Iteration:     51, Training Accuracy:   0.0%, Loss: 7477.8511\n",
      "Optimization Iteration:     52, Training Accuracy:   0.0%, Loss: 7482.0767\n",
      "Optimization Iteration:     53, Training Accuracy:   0.0%, Loss: 7475.5010\n",
      "Optimization Iteration:     54, Training Accuracy:   0.0%, Loss: 7476.0498\n",
      "Optimization Iteration:     55, Training Accuracy:   0.0%, Loss: 7471.7100\n",
      "Optimization Iteration:     56, Training Accuracy:   0.0%, Loss: 7463.2690\n",
      "Optimization Iteration:     57, Training Accuracy:   0.0%, Loss: 7476.9932\n",
      "Optimization Iteration:     58, Training Accuracy:   0.0%, Loss: 7478.6777\n",
      "Optimization Iteration:     59, Training Accuracy:   0.0%, Loss: 7467.3901\n",
      "Optimization Iteration:     60, Training Accuracy:   0.0%, Loss: 7476.5269\n",
      "Optimization Iteration:     61, Training Accuracy:   0.0%, Loss: 7475.3027\n",
      "Optimization Iteration:     62, Training Accuracy:   0.0%, Loss: 7473.9800\n",
      "Optimization Iteration:     63, Training Accuracy:   0.0%, Loss: 7451.4702\n",
      "All images have been processed.\n",
      "Model saved in file: SD/sd_01_.ckpt\n",
      "Optimization Iteration:      1, Training Accuracy:   0.0%, Loss: 7479.0625\n",
      "Optimization Iteration:      2, Training Accuracy:   0.0%, Loss: 7466.5000\n",
      "Optimization Iteration:      3, Training Accuracy:   0.0%, Loss: 7474.3667\n",
      "Optimization Iteration:      4, Training Accuracy:   0.0%, Loss: 7468.2002\n",
      "Optimization Iteration:      5, Training Accuracy:   0.0%, Loss: 7470.1201\n",
      "Optimization Iteration:      6, Training Accuracy:   0.0%, Loss: 7485.5669\n",
      "Optimization Iteration:      7, Training Accuracy:   0.0%, Loss: 7477.9351\n",
      "Optimization Iteration:      8, Training Accuracy:   0.0%, Loss: 7472.2817\n",
      "Optimization Iteration:      9, Training Accuracy:   0.0%, Loss: 7461.0435\n",
      "Optimization Iteration:     10, Training Accuracy:   0.0%, Loss: 7465.1748\n",
      "Optimization Iteration:     11, Training Accuracy:   0.0%, Loss: 7475.5767\n",
      "Optimization Iteration:     12, Training Accuracy:   0.0%, Loss: 7471.1665\n",
      "Optimization Iteration:     13, Training Accuracy:   0.0%, Loss: 7473.6191\n",
      "Optimization Iteration:     14, Training Accuracy:   0.0%, Loss: 7473.8843\n",
      "Optimization Iteration:     15, Training Accuracy:   0.0%, Loss: 7469.0552\n",
      "Optimization Iteration:     16, Training Accuracy:   0.0%, Loss: 7466.1982\n",
      "Optimization Iteration:     17, Training Accuracy:   0.0%, Loss: 7475.2231\n",
      "Optimization Iteration:     18, Training Accuracy:   0.0%, Loss: 7471.5386\n",
      "Optimization Iteration:     19, Training Accuracy:   0.0%, Loss: 7473.1548\n",
      "Optimization Iteration:     20, Training Accuracy:   0.0%, Loss: 7452.6216\n",
      "Optimization Iteration:     21, Training Accuracy:   0.0%, Loss: 7460.9360\n",
      "Optimization Iteration:     22, Training Accuracy:   0.0%, Loss: 7463.2817\n",
      "Optimization Iteration:     23, Training Accuracy:   0.0%, Loss: 7466.9165\n",
      "Optimization Iteration:     24, Training Accuracy:   0.0%, Loss: 7462.4648\n",
      "Optimization Iteration:     25, Training Accuracy:   0.0%, Loss: 7469.5425\n",
      "Optimization Iteration:     26, Training Accuracy:   0.0%, Loss: 7464.2773\n",
      "Optimization Iteration:     27, Training Accuracy:   0.0%, Loss: 7459.5698\n",
      "Optimization Iteration:     28, Training Accuracy:   0.0%, Loss: 7470.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:     29, Training Accuracy:   0.0%, Loss: 7468.8408\n",
      "Optimization Iteration:     30, Training Accuracy:   0.0%, Loss: 7462.5684\n",
      "Optimization Iteration:     31, Training Accuracy:   0.0%, Loss: 7465.3999\n",
      "Optimization Iteration:     32, Training Accuracy:   0.0%, Loss: 7463.2715\n",
      "Optimization Iteration:     33, Training Accuracy:   0.0%, Loss: 7472.1099\n",
      "Optimization Iteration:     34, Training Accuracy:   0.0%, Loss: 7456.5850\n",
      "Optimization Iteration:     35, Training Accuracy:   0.0%, Loss: 7473.5298\n",
      "Optimization Iteration:     36, Training Accuracy:   0.0%, Loss: 7462.4360\n",
      "Optimization Iteration:     37, Training Accuracy:   0.0%, Loss: 7458.8174\n",
      "Optimization Iteration:     38, Training Accuracy:   0.0%, Loss: 7463.6567\n",
      "Optimization Iteration:     39, Training Accuracy:   0.0%, Loss: 7478.8467\n",
      "Optimization Iteration:     40, Training Accuracy:   0.0%, Loss: 7456.8765\n",
      "Optimization Iteration:     41, Training Accuracy:   0.0%, Loss: 7454.7285\n",
      "Optimization Iteration:     42, Training Accuracy:   0.0%, Loss: 7475.0957\n",
      "Optimization Iteration:     43, Training Accuracy:   0.0%, Loss: 7454.5640\n",
      "Optimization Iteration:     44, Training Accuracy:   0.0%, Loss: 7473.7417\n",
      "Optimization Iteration:     45, Training Accuracy:   0.0%, Loss: 7462.4424\n",
      "Optimization Iteration:     46, Training Accuracy:   0.0%, Loss: 7467.8218\n",
      "Optimization Iteration:     47, Training Accuracy:   0.0%, Loss: 7458.9399\n",
      "Optimization Iteration:     48, Training Accuracy:   0.0%, Loss: 7462.3511\n",
      "Optimization Iteration:     49, Training Accuracy:   0.0%, Loss: 7466.3564\n",
      "Optimization Iteration:     50, Training Accuracy:   0.0%, Loss: 7474.9624\n",
      "Optimization Iteration:     51, Training Accuracy:   0.0%, Loss: 7469.9199\n",
      "Optimization Iteration:     52, Training Accuracy:   0.0%, Loss: 7473.7983\n",
      "Optimization Iteration:     53, Training Accuracy:   0.0%, Loss: 7469.6040\n",
      "Optimization Iteration:     54, Training Accuracy:   0.0%, Loss: 7469.6299\n",
      "Optimization Iteration:     55, Training Accuracy:   0.0%, Loss: 7463.9526\n",
      "Optimization Iteration:     56, Training Accuracy:   0.0%, Loss: 7456.4551\n",
      "Optimization Iteration:     57, Training Accuracy:   0.0%, Loss: 7472.0610\n",
      "Optimization Iteration:     58, Training Accuracy:   0.0%, Loss: 7470.8564\n",
      "Optimization Iteration:     59, Training Accuracy:   0.0%, Loss: 7459.3691\n",
      "Optimization Iteration:     60, Training Accuracy:   0.0%, Loss: 7469.9800\n",
      "Optimization Iteration:     61, Training Accuracy:   0.0%, Loss: 7468.3267\n",
      "Optimization Iteration:     62, Training Accuracy:   0.0%, Loss: 7467.5249\n",
      "Optimization Iteration:     63, Training Accuracy:   0.0%, Loss: 7441.8433\n",
      "All images have been processed.\n",
      "Model saved in file: SD/sd_01_.ckpt\n",
      "Optimization Iteration:      1, Training Accuracy:   0.0%, Loss: 7471.4258\n",
      "Optimization Iteration:      2, Training Accuracy:   0.0%, Loss: 7462.7231\n",
      "Optimization Iteration:      3, Training Accuracy:   0.0%, Loss: 7466.2910\n",
      "Optimization Iteration:      4, Training Accuracy:   0.0%, Loss: 7461.9741\n",
      "Optimization Iteration:      5, Training Accuracy:   0.0%, Loss: 7464.5635\n",
      "Optimization Iteration:      6, Training Accuracy:   0.0%, Loss: 7477.8115\n",
      "Optimization Iteration:      7, Training Accuracy:   0.0%, Loss: 7469.2065\n",
      "Optimization Iteration:      8, Training Accuracy:   0.0%, Loss: 7466.9331\n",
      "Optimization Iteration:      9, Training Accuracy:   0.0%, Loss: 7455.0249\n",
      "Optimization Iteration:     10, Training Accuracy:   0.0%, Loss: 7460.7769\n",
      "Optimization Iteration:     11, Training Accuracy:   0.0%, Loss: 7468.0176\n",
      "Optimization Iteration:     12, Training Accuracy:   0.0%, Loss: 7463.9634\n",
      "Optimization Iteration:     13, Training Accuracy:   0.0%, Loss: 7465.6958\n",
      "Optimization Iteration:     14, Training Accuracy:   0.0%, Loss: 7465.9893\n",
      "Optimization Iteration:     15, Training Accuracy:   0.0%, Loss: 7463.9526\n",
      "Optimization Iteration:     16, Training Accuracy:   0.0%, Loss: 7459.4907\n",
      "Optimization Iteration:     17, Training Accuracy:   0.0%, Loss: 7469.2407\n",
      "Optimization Iteration:     18, Training Accuracy:   0.0%, Loss: 7466.3018\n",
      "Optimization Iteration:     19, Training Accuracy:   0.0%, Loss: 7466.4316\n",
      "Optimization Iteration:     20, Training Accuracy:   0.0%, Loss: 7445.4185\n",
      "Optimization Iteration:     21, Training Accuracy:   0.0%, Loss: 7454.5684\n",
      "Optimization Iteration:     22, Training Accuracy:   0.0%, Loss: 7457.1343\n",
      "Optimization Iteration:     23, Training Accuracy:   0.0%, Loss: 7460.6465\n",
      "Optimization Iteration:     24, Training Accuracy:   0.0%, Loss: 7455.8018\n",
      "Optimization Iteration:     25, Training Accuracy:   0.0%, Loss: 7463.6250\n",
      "Optimization Iteration:     26, Training Accuracy:   0.0%, Loss: 7459.4966\n",
      "Optimization Iteration:     27, Training Accuracy:   0.0%, Loss: 7454.2998\n",
      "Optimization Iteration:     28, Training Accuracy:   0.0%, Loss: 7464.3311\n",
      "Optimization Iteration:     29, Training Accuracy:   0.0%, Loss: 7462.3301\n",
      "Optimization Iteration:     30, Training Accuracy:   0.0%, Loss: 7455.9082\n",
      "Optimization Iteration:     31, Training Accuracy:   0.0%, Loss: 7459.5557\n",
      "Optimization Iteration:     32, Training Accuracy:   0.0%, Loss: 7457.1782\n",
      "Optimization Iteration:     33, Training Accuracy:   0.0%, Loss: 7466.7168\n",
      "Optimization Iteration:     34, Training Accuracy:   0.0%, Loss: 7449.8667\n",
      "Optimization Iteration:     35, Training Accuracy:   0.0%, Loss: 7467.5601\n",
      "Optimization Iteration:     36, Training Accuracy:   0.0%, Loss: 7456.6982\n",
      "Optimization Iteration:     37, Training Accuracy:   0.0%, Loss: 7453.6235\n",
      "Optimization Iteration:     38, Training Accuracy:   0.0%, Loss: 7457.5977\n",
      "Optimization Iteration:     39, Training Accuracy:   0.0%, Loss: 7472.1108\n",
      "Optimization Iteration:     40, Training Accuracy:   0.0%, Loss: 7450.7202\n",
      "Optimization Iteration:     41, Training Accuracy:   0.0%, Loss: 7447.9248\n",
      "Optimization Iteration:     42, Training Accuracy:   0.0%, Loss: 7468.1577\n",
      "Optimization Iteration:     43, Training Accuracy:   0.0%, Loss: 7448.2134\n",
      "Optimization Iteration:     44, Training Accuracy:   0.0%, Loss: 7467.1567\n",
      "Optimization Iteration:     45, Training Accuracy:   0.0%, Loss: 7456.5469\n",
      "Optimization Iteration:     46, Training Accuracy:   0.0%, Loss: 7462.8818\n",
      "Optimization Iteration:     47, Training Accuracy:   0.0%, Loss: 7454.5591\n",
      "Optimization Iteration:     48, Training Accuracy:   0.0%, Loss: 7455.9614\n",
      "Optimization Iteration:     49, Training Accuracy:   0.0%, Loss: 7460.9150\n",
      "Optimization Iteration:     50, Training Accuracy:   0.0%, Loss: 7467.9531\n",
      "Optimization Iteration:     51, Training Accuracy:   0.0%, Loss: 7463.2285\n",
      "Optimization Iteration:     52, Training Accuracy:   0.0%, Loss: 7467.5269\n",
      "Optimization Iteration:     53, Training Accuracy:   0.0%, Loss: 7463.1602\n",
      "Optimization Iteration:     54, Training Accuracy:   0.0%, Loss: 7462.6865\n",
      "Optimization Iteration:     55, Training Accuracy:   0.0%, Loss: 7456.8984\n",
      "Optimization Iteration:     56, Training Accuracy:   0.0%, Loss: 7449.9683\n",
      "Optimization Iteration:     57, Training Accuracy:   0.0%, Loss: 7467.4185\n",
      "Optimization Iteration:     58, Training Accuracy:   0.0%, Loss: 7464.4136\n",
      "Optimization Iteration:     59, Training Accuracy:   0.0%, Loss: 7452.6919\n",
      "Optimization Iteration:     60, Training Accuracy:   0.0%, Loss: 7464.4307\n",
      "Optimization Iteration:     61, Training Accuracy:   0.0%, Loss: 7462.2715\n",
      "Optimization Iteration:     62, Training Accuracy:   0.0%, Loss: 7461.3232\n",
      "Optimization Iteration:     63, Training Accuracy:   0.0%, Loss: 7434.6558\n",
      "All images have been processed.\n",
      "Model saved in file: SD/sd_01_.ckpt\n",
      "Optimization Iteration:      1, Training Accuracy:   0.0%, Loss: 7464.0386\n",
      "Optimization Iteration:      2, Training Accuracy:   0.0%, Loss: 7458.0933\n",
      "Optimization Iteration:      3, Training Accuracy:   0.0%, Loss: 7459.4731\n",
      "Optimization Iteration:      4, Training Accuracy:   0.0%, Loss: 7455.6226\n",
      "Optimization Iteration:      5, Training Accuracy:   0.0%, Loss: 7459.1733\n",
      "Optimization Iteration:      6, Training Accuracy:   0.0%, Loss: 7471.0269\n",
      "Optimization Iteration:      7, Training Accuracy:   0.0%, Loss: 7462.3936\n",
      "Optimization Iteration:      8, Training Accuracy:   0.0%, Loss: 7461.0083\n",
      "Optimization Iteration:      9, Training Accuracy:   0.0%, Loss: 7449.9160\n",
      "Optimization Iteration:     10, Training Accuracy:   0.0%, Loss: 7455.5527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:     11, Training Accuracy:   0.0%, Loss: 7461.5166\n",
      "Optimization Iteration:     12, Training Accuracy:   0.0%, Loss: 7458.3223\n",
      "Optimization Iteration:     13, Training Accuracy:   0.0%, Loss: 7457.6733\n",
      "Optimization Iteration:     14, Training Accuracy:   0.0%, Loss: 7459.8184\n",
      "Optimization Iteration:     15, Training Accuracy:   0.0%, Loss: 7457.6157\n",
      "Optimization Iteration:     16, Training Accuracy:   0.0%, Loss: 7455.0342\n",
      "Optimization Iteration:     17, Training Accuracy:   0.0%, Loss: 7463.7368\n",
      "Optimization Iteration:     18, Training Accuracy:   0.0%, Loss: 7462.2476\n",
      "Optimization Iteration:     19, Training Accuracy:   0.0%, Loss: 7461.0469\n",
      "Optimization Iteration:     20, Training Accuracy:   0.0%, Loss: 7439.5752\n",
      "Optimization Iteration:     21, Training Accuracy:   0.0%, Loss: 7447.9019\n",
      "Optimization Iteration:     22, Training Accuracy:   0.0%, Loss: 7451.9019\n",
      "Optimization Iteration:     23, Training Accuracy:   0.0%, Loss: 7454.7876\n",
      "Optimization Iteration:     24, Training Accuracy:   0.0%, Loss: 7450.2783\n",
      "Optimization Iteration:     25, Training Accuracy:   0.0%, Loss: 7458.3032\n",
      "Optimization Iteration:     26, Training Accuracy:   0.0%, Loss: 7453.9790\n",
      "Optimization Iteration:     27, Training Accuracy:   0.0%, Loss: 7449.7998\n",
      "Optimization Iteration:     28, Training Accuracy:   0.0%, Loss: 7458.9048\n",
      "Optimization Iteration:     29, Training Accuracy:   0.0%, Loss: 7456.1318\n",
      "Optimization Iteration:     30, Training Accuracy:   0.0%, Loss: 7451.0435\n",
      "Optimization Iteration:     31, Training Accuracy:   0.0%, Loss: 7454.1426\n",
      "Optimization Iteration:     32, Training Accuracy:   0.0%, Loss: 7450.9009\n",
      "Optimization Iteration:     33, Training Accuracy:   0.0%, Loss: 7461.5693\n",
      "Optimization Iteration:     34, Training Accuracy:   0.0%, Loss: 7444.4717\n",
      "Optimization Iteration:     35, Training Accuracy:   0.0%, Loss: 7462.4951\n",
      "Optimization Iteration:     36, Training Accuracy:   0.0%, Loss: 7450.7349\n",
      "Optimization Iteration:     37, Training Accuracy:   0.0%, Loss: 7448.3081\n",
      "Optimization Iteration:     38, Training Accuracy:   0.0%, Loss: 7452.0752\n",
      "Optimization Iteration:     39, Training Accuracy:   0.0%, Loss: 7466.5059\n",
      "Optimization Iteration:     40, Training Accuracy:   0.0%, Loss: 7445.2676\n",
      "Optimization Iteration:     41, Training Accuracy:   0.0%, Loss: 7443.0918\n",
      "Optimization Iteration:     42, Training Accuracy:   0.0%, Loss: 7462.5767\n",
      "Optimization Iteration:     43, Training Accuracy:   0.0%, Loss: 7442.9668\n",
      "Optimization Iteration:     44, Training Accuracy:   0.0%, Loss: 7462.0884\n",
      "Optimization Iteration:     45, Training Accuracy:   0.0%, Loss: 7450.9844\n",
      "Optimization Iteration:     46, Training Accuracy:   0.0%, Loss: 7457.8276\n",
      "Optimization Iteration:     47, Training Accuracy:   0.0%, Loss: 7449.5781\n",
      "Optimization Iteration:     48, Training Accuracy:   0.0%, Loss: 7449.7949\n",
      "Optimization Iteration:     49, Training Accuracy:   0.0%, Loss: 7455.5732\n",
      "Optimization Iteration:     50, Training Accuracy:   0.0%, Loss: 7461.7549\n",
      "Optimization Iteration:     51, Training Accuracy:   0.0%, Loss: 7456.5386\n",
      "Optimization Iteration:     52, Training Accuracy:   0.0%, Loss: 7462.1094\n",
      "Optimization Iteration:     53, Training Accuracy:   0.0%, Loss: 7456.5742\n",
      "Optimization Iteration:     54, Training Accuracy:   0.0%, Loss: 7457.8384\n",
      "Optimization Iteration:     55, Training Accuracy:   0.0%, Loss: 7450.9668\n",
      "Optimization Iteration:     56, Training Accuracy:   0.0%, Loss: 7444.2739\n",
      "Optimization Iteration:     57, Training Accuracy:   0.0%, Loss: 7463.6982\n",
      "Optimization Iteration:     58, Training Accuracy:   0.0%, Loss: 7457.7368\n",
      "Optimization Iteration:     59, Training Accuracy:   0.0%, Loss: 7447.2241\n",
      "Optimization Iteration:     60, Training Accuracy:   0.0%, Loss: 7459.8477\n",
      "Optimization Iteration:     61, Training Accuracy:   0.0%, Loss: 7456.7598\n",
      "Optimization Iteration:     62, Training Accuracy:   0.0%, Loss: 7457.3818\n",
      "Optimization Iteration:     63, Training Accuracy:   0.0%, Loss: 7426.7451\n",
      "All images have been processed.\n",
      "Model saved in file: SD/sd_01_.ckpt\n",
      "Optimization Iteration:      1, Training Accuracy:   0.0%, Loss: 7457.5215\n",
      "Optimization Iteration:      2, Training Accuracy:   0.0%, Loss: 7454.3750\n",
      "Optimization Iteration:      3, Training Accuracy:   0.0%, Loss: 7453.3184\n",
      "Optimization Iteration:      4, Training Accuracy:   0.0%, Loss: 7449.5098\n",
      "Optimization Iteration:      5, Training Accuracy:   0.0%, Loss: 7454.8857\n",
      "Optimization Iteration:      6, Training Accuracy:   0.0%, Loss: 7465.1992\n",
      "Optimization Iteration:      7, Training Accuracy:   0.0%, Loss: 7456.0356\n",
      "Optimization Iteration:      8, Training Accuracy:   0.0%, Loss: 7455.1543\n",
      "Optimization Iteration:      9, Training Accuracy:   0.0%, Loss: 7445.3110\n",
      "Optimization Iteration:     10, Training Accuracy:   0.0%, Loss: 7450.7715\n",
      "Optimization Iteration:     11, Training Accuracy:   0.0%, Loss: 7456.0186\n",
      "Optimization Iteration:     12, Training Accuracy:   0.0%, Loss: 7452.9199\n",
      "Optimization Iteration:     13, Training Accuracy:   0.0%, Loss: 7450.2627\n",
      "Optimization Iteration:     14, Training Accuracy:   0.0%, Loss: 7455.3560\n",
      "Optimization Iteration:     15, Training Accuracy:   0.0%, Loss: 7451.3857\n",
      "Optimization Iteration:     16, Training Accuracy:   0.0%, Loss: 7450.5835\n",
      "Optimization Iteration:     17, Training Accuracy:   0.0%, Loss: 7458.5483\n",
      "Optimization Iteration:     18, Training Accuracy:   0.0%, Loss: 7458.6299\n",
      "Optimization Iteration:     19, Training Accuracy:   0.0%, Loss: 7455.3618\n",
      "Optimization Iteration:     20, Training Accuracy:   0.0%, Loss: 7433.9614\n",
      "Optimization Iteration:     21, Training Accuracy:   0.0%, Loss: 7442.3257\n",
      "Optimization Iteration:     22, Training Accuracy:   0.0%, Loss: 7447.5752\n",
      "Optimization Iteration:     23, Training Accuracy:   0.0%, Loss: 7449.5933\n",
      "Optimization Iteration:     24, Training Accuracy:   0.0%, Loss: 7445.4434\n",
      "Optimization Iteration:     25, Training Accuracy:   0.0%, Loss: 7454.2832\n",
      "Optimization Iteration:     26, Training Accuracy:   0.0%, Loss: 7448.7017\n",
      "Optimization Iteration:     27, Training Accuracy:   0.0%, Loss: 7445.2485\n",
      "Optimization Iteration:     28, Training Accuracy:   0.0%, Loss: 7454.2500\n",
      "Optimization Iteration:     29, Training Accuracy:   0.0%, Loss: 7450.4048\n",
      "Optimization Iteration:     30, Training Accuracy:   0.0%, Loss: 7445.8193\n",
      "Optimization Iteration:     31, Training Accuracy:   0.0%, Loss: 7449.9331\n",
      "Optimization Iteration:     32, Training Accuracy:   0.0%, Loss: 7444.6816\n",
      "Optimization Iteration:     33, Training Accuracy:   0.0%, Loss: 7456.9048\n",
      "Optimization Iteration:     34, Training Accuracy:   0.0%, Loss: 7439.1782\n",
      "Optimization Iteration:     35, Training Accuracy:   0.0%, Loss: 7457.0591\n",
      "Optimization Iteration:     36, Training Accuracy:   0.0%, Loss: 7445.0767\n",
      "Optimization Iteration:     37, Training Accuracy:   0.0%, Loss: 7443.1831\n",
      "Optimization Iteration:     38, Training Accuracy:   0.0%, Loss: 7446.8115\n",
      "Optimization Iteration:     39, Training Accuracy:   0.0%, Loss: 7460.7466\n",
      "Optimization Iteration:     40, Training Accuracy:   0.0%, Loss: 7439.5034\n",
      "Optimization Iteration:     41, Training Accuracy:   0.0%, Loss: 7438.7866\n",
      "Optimization Iteration:     42, Training Accuracy:   0.0%, Loss: 7456.6890\n",
      "Optimization Iteration:     43, Training Accuracy:   0.0%, Loss: 7438.7817\n",
      "Optimization Iteration:     44, Training Accuracy:   0.0%, Loss: 7456.8364\n",
      "Optimization Iteration:     45, Training Accuracy:   0.0%, Loss: 7445.8374\n",
      "Optimization Iteration:     46, Training Accuracy:   0.0%, Loss: 7454.0483\n",
      "Optimization Iteration:     47, Training Accuracy:   0.0%, Loss: 7443.9648\n",
      "Optimization Iteration:     48, Training Accuracy:   0.0%, Loss: 7445.7998\n",
      "Optimization Iteration:     49, Training Accuracy:   0.0%, Loss: 7451.3032\n",
      "Optimization Iteration:     50, Training Accuracy:   0.0%, Loss: 7454.5518\n",
      "Optimization Iteration:     51, Training Accuracy:   0.0%, Loss: 7452.0117\n",
      "Optimization Iteration:     52, Training Accuracy:   0.0%, Loss: 7456.9458\n",
      "Optimization Iteration:     53, Training Accuracy:   0.0%, Loss: 7449.5781\n",
      "Optimization Iteration:     54, Training Accuracy:   0.0%, Loss: 7452.8550\n",
      "Optimization Iteration:     55, Training Accuracy:   0.0%, Loss: 7444.3394\n",
      "Optimization Iteration:     56, Training Accuracy:   0.0%, Loss: 7438.2134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:     57, Training Accuracy:   0.0%, Loss: 7460.4233\n",
      "Optimization Iteration:     58, Training Accuracy:   0.0%, Loss: 7450.9482\n",
      "Optimization Iteration:     59, Training Accuracy:   0.0%, Loss: 7444.0552\n",
      "Optimization Iteration:     60, Training Accuracy:   0.0%, Loss: 7454.9502\n",
      "Optimization Iteration:     61, Training Accuracy:   0.0%, Loss: 7451.6968\n",
      "Optimization Iteration:     62, Training Accuracy:   0.0%, Loss: 7454.0332\n",
      "Optimization Iteration:     63, Training Accuracy:   0.0%, Loss: 7418.5981\n",
      "All images have been processed.\n",
      "Model saved in file: SD/sd_01_.ckpt\n",
      "Optimization Iteration:      1, Training Accuracy:   0.0%, Loss: 7454.8232\n",
      "Optimization Iteration:      2, Training Accuracy:   0.0%, Loss: 7451.6401\n",
      "Optimization Iteration:      3, Training Accuracy:   0.0%, Loss: 7447.0098\n",
      "Optimization Iteration:      4, Training Accuracy:   0.0%, Loss: 7446.6831\n",
      "Optimization Iteration:      5, Training Accuracy:   0.0%, Loss: 7449.4136\n",
      "Optimization Iteration:      6, Training Accuracy:   0.0%, Loss: 7461.2642\n",
      "Optimization Iteration:      7, Training Accuracy:   0.0%, Loss: 7451.3965\n",
      "Optimization Iteration:      8, Training Accuracy:   0.0%, Loss: 7449.8149\n",
      "Optimization Iteration:      9, Training Accuracy:   0.0%, Loss: 7441.7852\n",
      "Optimization Iteration:     10, Training Accuracy:   0.0%, Loss: 7445.7007\n",
      "Optimization Iteration:     11, Training Accuracy:   0.0%, Loss: 7451.4731\n",
      "Optimization Iteration:     12, Training Accuracy:   0.0%, Loss: 7448.9917\n",
      "Optimization Iteration:     13, Training Accuracy:   0.0%, Loss: 7443.2109\n",
      "Optimization Iteration:     14, Training Accuracy:   0.0%, Loss: 7452.7573\n",
      "Optimization Iteration:     15, Training Accuracy:   0.0%, Loss: 7445.4043\n",
      "Optimization Iteration:     16, Training Accuracy:   0.0%, Loss: 7447.9648\n",
      "Optimization Iteration:     17, Training Accuracy:   0.0%, Loss: 7454.4883\n",
      "Optimization Iteration:     18, Training Accuracy:   0.0%, Loss: 7455.3125\n",
      "Optimization Iteration:     19, Training Accuracy:   0.0%, Loss: 7450.8481\n",
      "Optimization Iteration:     20, Training Accuracy:   0.0%, Loss: 7430.1948\n",
      "Optimization Iteration:     21, Training Accuracy:   0.0%, Loss: 7437.6240\n",
      "Optimization Iteration:     22, Training Accuracy:   0.0%, Loss: 7444.2773\n",
      "Optimization Iteration:     23, Training Accuracy:   0.0%, Loss: 7444.6807\n",
      "Optimization Iteration:     24, Training Accuracy:   0.0%, Loss: 7441.7334\n",
      "Optimization Iteration:     25, Training Accuracy:   0.0%, Loss: 7449.8032\n",
      "Optimization Iteration:     26, Training Accuracy:   0.0%, Loss: 7444.2100\n",
      "Optimization Iteration:     27, Training Accuracy:   0.0%, Loss: 7441.9199\n",
      "Optimization Iteration:     28, Training Accuracy:   0.0%, Loss: 7449.0200\n",
      "Optimization Iteration:     29, Training Accuracy:   0.0%, Loss: 7445.7383\n",
      "Optimization Iteration:     30, Training Accuracy:   0.0%, Loss: 7440.7935\n",
      "Optimization Iteration:     31, Training Accuracy:   0.0%, Loss: 7445.6382\n",
      "Optimization Iteration:     32, Training Accuracy:   0.0%, Loss: 7439.6489\n",
      "Optimization Iteration:     33, Training Accuracy:   0.0%, Loss: 7452.8750\n",
      "Optimization Iteration:     34, Training Accuracy:   0.0%, Loss: 7434.2651\n",
      "Optimization Iteration:     35, Training Accuracy:   0.0%, Loss: 7452.4365\n",
      "Optimization Iteration:     36, Training Accuracy:   0.0%, Loss: 7439.3643\n",
      "Optimization Iteration:     37, Training Accuracy:   0.0%, Loss: 7438.1636\n",
      "Optimization Iteration:     38, Training Accuracy:   0.0%, Loss: 7441.3843\n",
      "Optimization Iteration:     39, Training Accuracy:   0.0%, Loss: 7454.5635\n",
      "Optimization Iteration:     40, Training Accuracy:   0.0%, Loss: 7433.8701\n",
      "Optimization Iteration:     41, Training Accuracy:   0.0%, Loss: 7433.0352\n",
      "Optimization Iteration:     42, Training Accuracy:   0.0%, Loss: 7451.2300\n",
      "Optimization Iteration:     43, Training Accuracy:   0.0%, Loss: 7435.0234\n",
      "Optimization Iteration:     44, Training Accuracy:   0.0%, Loss: 7449.2593\n",
      "Optimization Iteration:     45, Training Accuracy:   0.0%, Loss: 7440.5410\n",
      "Optimization Iteration:     46, Training Accuracy:   0.0%, Loss: 7448.4600\n",
      "Optimization Iteration:     47, Training Accuracy:   0.0%, Loss: 7437.3823\n",
      "Optimization Iteration:     48, Training Accuracy:   0.0%, Loss: 7441.0698\n",
      "Optimization Iteration:     49, Training Accuracy:   0.0%, Loss: 7444.7534\n",
      "Optimization Iteration:     50, Training Accuracy:   0.0%, Loss: 7447.7485\n",
      "Optimization Iteration:     51, Training Accuracy:   0.0%, Loss: 7447.3599\n",
      "Optimization Iteration:     52, Training Accuracy:   0.0%, Loss: 7449.9136\n",
      "Optimization Iteration:     53, Training Accuracy:   0.0%, Loss: 7444.4419\n",
      "Optimization Iteration:     54, Training Accuracy:   0.0%, Loss: 7448.1260\n",
      "Optimization Iteration:     55, Training Accuracy:   0.0%, Loss: 7437.3682\n",
      "Optimization Iteration:     56, Training Accuracy:   0.0%, Loss: 7432.7368\n",
      "Optimization Iteration:     57, Training Accuracy:   0.0%, Loss: 7455.0850\n",
      "Optimization Iteration:     58, Training Accuracy:   0.0%, Loss: 7445.4634\n",
      "Optimization Iteration:     59, Training Accuracy:   0.0%, Loss: 7440.0815\n",
      "Optimization Iteration:     60, Training Accuracy:   0.0%, Loss: 7448.5449\n",
      "Optimization Iteration:     61, Training Accuracy:   0.0%, Loss: 7448.2300\n",
      "Optimization Iteration:     62, Training Accuracy:   0.0%, Loss: 7448.3901\n",
      "Optimization Iteration:     63, Training Accuracy:   0.0%, Loss: 7409.3936\n",
      "All images have been processed.\n",
      "Model saved in file: SD/sd_01_.ckpt\n",
      "Optimization Iteration:      1, Training Accuracy:   0.0%, Loss: 7451.4526\n",
      "Optimization Iteration:      2, Training Accuracy:   0.0%, Loss: 7444.6626\n",
      "Optimization Iteration:      3, Training Accuracy:   0.0%, Loss: 7443.3823\n",
      "Optimization Iteration:      4, Training Accuracy:   0.0%, Loss: 7440.2231\n",
      "Optimization Iteration:      5, Training Accuracy:   0.0%, Loss: 7445.3823\n",
      "Optimization Iteration:      6, Training Accuracy:   0.0%, Loss: 7458.7368\n",
      "Optimization Iteration:      7, Training Accuracy:   0.0%, Loss: 7445.6851\n",
      "Optimization Iteration:      8, Training Accuracy:   0.0%, Loss: 7447.3701\n",
      "Optimization Iteration:      9, Training Accuracy:   0.0%, Loss: 7435.8032\n",
      "Optimization Iteration:     10, Training Accuracy:   0.0%, Loss: 7440.5083\n",
      "Optimization Iteration:     11, Training Accuracy:   0.0%, Loss: 7448.8823\n",
      "Optimization Iteration:     12, Training Accuracy:   0.0%, Loss: 7441.6260\n",
      "Optimization Iteration:     13, Training Accuracy:   0.0%, Loss: 7438.1226\n",
      "Optimization Iteration:     14, Training Accuracy:   0.0%, Loss: 7449.1133\n",
      "Optimization Iteration:     15, Training Accuracy:   0.0%, Loss: 7439.0557\n",
      "Optimization Iteration:     16, Training Accuracy:   0.0%, Loss: 7449.4702\n",
      "Optimization Iteration:     17, Training Accuracy:   0.0%, Loss: 7447.6816\n",
      "Optimization Iteration:     18, Training Accuracy:   0.0%, Loss: 7455.3066\n",
      "Optimization Iteration:     19, Training Accuracy:   0.0%, Loss: 7445.8418\n",
      "Optimization Iteration:     20, Training Accuracy:   0.0%, Loss: 7423.8716\n",
      "Optimization Iteration:     21, Training Accuracy:   0.0%, Loss: 7436.7959\n",
      "Optimization Iteration:     22, Training Accuracy:   0.0%, Loss: 7437.9849\n",
      "Optimization Iteration:     23, Training Accuracy:   0.0%, Loss: 7440.4116\n",
      "Optimization Iteration:     24, Training Accuracy:   0.0%, Loss: 7439.2051\n",
      "Optimization Iteration:     25, Training Accuracy:   0.0%, Loss: 7443.0200\n",
      "Optimization Iteration:     26, Training Accuracy:   0.0%, Loss: 7442.1816\n",
      "Optimization Iteration:     27, Training Accuracy:   0.0%, Loss: 7436.9966\n",
      "Optimization Iteration:     28, Training Accuracy:   0.0%, Loss: 7444.8057\n",
      "Optimization Iteration:     29, Training Accuracy:   0.0%, Loss: 7442.7217\n",
      "Optimization Iteration:     30, Training Accuracy:   0.0%, Loss: 7434.1899\n",
      "Optimization Iteration:     31, Training Accuracy:   0.0%, Loss: 7444.5469\n",
      "Optimization Iteration:     32, Training Accuracy:   0.0%, Loss: 7434.5410\n",
      "Optimization Iteration:     33, Training Accuracy:   0.0%, Loss: 7449.0415\n",
      "Optimization Iteration:     34, Training Accuracy:   0.0%, Loss: 7431.0234\n",
      "Optimization Iteration:     35, Training Accuracy:   0.0%, Loss: 7447.0718\n",
      "Optimization Iteration:     36, Training Accuracy:   0.0%, Loss: 7434.5527\n",
      "Optimization Iteration:     37, Training Accuracy:   0.0%, Loss: 7433.5752\n",
      "Optimization Iteration:     38, Training Accuracy:   0.0%, Loss: 7434.7114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:     39, Training Accuracy:   0.0%, Loss: 7449.0918\n",
      "Optimization Iteration:     40, Training Accuracy:   0.0%, Loss: 7427.8867\n",
      "Optimization Iteration:     41, Training Accuracy:   0.0%, Loss: 7426.0757\n",
      "Optimization Iteration:     42, Training Accuracy:   0.0%, Loss: 7446.7939\n",
      "Optimization Iteration:     43, Training Accuracy:   0.0%, Loss: 7430.1782\n",
      "Optimization Iteration:     44, Training Accuracy:   0.0%, Loss: 7442.2690\n",
      "Optimization Iteration:     45, Training Accuracy:   0.0%, Loss: 7435.9067\n",
      "Optimization Iteration:     46, Training Accuracy:   0.0%, Loss: 7441.7393\n",
      "Optimization Iteration:     47, Training Accuracy:   0.0%, Loss: 7431.7227\n",
      "Optimization Iteration:     48, Training Accuracy:   0.0%, Loss: 7434.2769\n",
      "Optimization Iteration:     49, Training Accuracy:   0.0%, Loss: 7437.9868\n",
      "Optimization Iteration:     50, Training Accuracy:   0.0%, Loss: 7442.1592\n",
      "Optimization Iteration:     51, Training Accuracy:   0.0%, Loss: 7440.2383\n",
      "Optimization Iteration:     52, Training Accuracy:   0.0%, Loss: 7444.9634\n",
      "Optimization Iteration:     53, Training Accuracy:   0.0%, Loss: 7438.9751\n",
      "Optimization Iteration:     54, Training Accuracy:   0.0%, Loss: 7443.2456\n",
      "Optimization Iteration:     55, Training Accuracy:   0.0%, Loss: 7430.5400\n",
      "Optimization Iteration:     56, Training Accuracy:   0.0%, Loss: 7426.9106\n",
      "Optimization Iteration:     57, Training Accuracy:   0.0%, Loss: 7449.3101\n",
      "Optimization Iteration:     58, Training Accuracy:   0.0%, Loss: 7439.4883\n",
      "Optimization Iteration:     59, Training Accuracy:   0.0%, Loss: 7432.9624\n",
      "Optimization Iteration:     60, Training Accuracy:   0.0%, Loss: 7442.9658\n",
      "Optimization Iteration:     61, Training Accuracy:   0.0%, Loss: 7441.9067\n",
      "Optimization Iteration:     62, Training Accuracy:   0.0%, Loss: 7441.0049\n",
      "Optimization Iteration:     63, Training Accuracy:   0.0%, Loss: 7400.6582\n",
      "All images have been processed.\n",
      "Model saved in file: SD/sd_01_.ckpt\n",
      "Optimization Iteration:      1, Training Accuracy:   0.0%, Loss: 7442.5415\n",
      "Optimization Iteration:      2, Training Accuracy:   0.0%, Loss: 7438.6367\n",
      "Optimization Iteration:      3, Training Accuracy:   0.0%, Loss: 7436.5215\n",
      "Optimization Iteration:      4, Training Accuracy:   0.0%, Loss: 7432.2300\n",
      "Optimization Iteration:      5, Training Accuracy:   0.0%, Loss: 7441.1968\n",
      "Optimization Iteration:      6, Training Accuracy:   0.0%, Loss: 7450.7017\n",
      "Optimization Iteration:      7, Training Accuracy:   0.0%, Loss: 7441.1548\n",
      "Optimization Iteration:      8, Training Accuracy:   0.0%, Loss: 7441.6582\n",
      "Optimization Iteration:      9, Training Accuracy:   0.0%, Loss: 7428.4609\n",
      "Optimization Iteration:     10, Training Accuracy:   0.0%, Loss: 7435.7925\n",
      "Optimization Iteration:     11, Training Accuracy:   0.0%, Loss: 7441.6182\n",
      "Optimization Iteration:     12, Training Accuracy:   0.0%, Loss: 7435.3350\n",
      "Optimization Iteration:     13, Training Accuracy:   0.0%, Loss: 7432.5801\n",
      "Optimization Iteration:     14, Training Accuracy:   0.0%, Loss: 7440.2192\n",
      "Optimization Iteration:     15, Training Accuracy:   0.0%, Loss: 7435.0317\n",
      "Optimization Iteration:     16, Training Accuracy:   0.0%, Loss: 7442.2617\n",
      "Optimization Iteration:     17, Training Accuracy:   0.0%, Loss: 7440.7031\n",
      "Optimization Iteration:     18, Training Accuracy:   0.0%, Loss: 7453.8652\n",
      "Optimization Iteration:     19, Training Accuracy:   0.0%, Loss: 7435.7817\n",
      "Optimization Iteration:     20, Training Accuracy:   0.0%, Loss: 7420.7100\n",
      "Optimization Iteration:     21, Training Accuracy:   0.0%, Loss: 7431.6719\n",
      "Optimization Iteration:     22, Training Accuracy:   0.0%, Loss: 7430.1274\n",
      "Optimization Iteration:     23, Training Accuracy:   0.0%, Loss: 7437.4951\n",
      "Optimization Iteration:     24, Training Accuracy:   0.0%, Loss: 7429.3394\n",
      "Optimization Iteration:     25, Training Accuracy:   0.0%, Loss: 7437.9141\n",
      "Optimization Iteration:     26, Training Accuracy:   0.0%, Loss: 7436.5283\n",
      "Optimization Iteration:     27, Training Accuracy:   0.0%, Loss: 7428.0635\n",
      "Optimization Iteration:     28, Training Accuracy:   0.0%, Loss: 7442.1831\n",
      "Optimization Iteration:     29, Training Accuracy:   0.0%, Loss: 7434.9341\n",
      "Optimization Iteration:     30, Training Accuracy:   0.0%, Loss: 7429.4585\n",
      "Optimization Iteration:     31, Training Accuracy:   0.0%, Loss: 7439.8101\n",
      "Optimization Iteration:     32, Training Accuracy:   0.0%, Loss: 7427.6958\n",
      "Optimization Iteration:     33, Training Accuracy:   0.0%, Loss: 7445.4468\n",
      "Optimization Iteration:     34, Training Accuracy:   0.0%, Loss: 7424.6582\n",
      "Optimization Iteration:     35, Training Accuracy:   0.0%, Loss: 7443.0610\n",
      "Optimization Iteration:     36, Training Accuracy:   0.0%, Loss: 7429.3750\n",
      "Optimization Iteration:     37, Training Accuracy:   0.0%, Loss: 7427.0835\n",
      "Optimization Iteration:     38, Training Accuracy:   0.0%, Loss: 7428.6025\n",
      "Optimization Iteration:     39, Training Accuracy:   0.0%, Loss: 7443.0259\n",
      "Optimization Iteration:     40, Training Accuracy:   0.0%, Loss: 7422.2261\n",
      "Optimization Iteration:     41, Training Accuracy:   0.0%, Loss: 7420.0898\n",
      "Optimization Iteration:     42, Training Accuracy:   0.0%, Loss: 7441.7817\n",
      "Optimization Iteration:     43, Training Accuracy:   0.0%, Loss: 7425.3433\n",
      "Optimization Iteration:     44, Training Accuracy:   0.0%, Loss: 7436.3794\n",
      "Optimization Iteration:     45, Training Accuracy:   0.0%, Loss: 7429.9067\n",
      "Optimization Iteration:     46, Training Accuracy:   0.0%, Loss: 7436.2300\n",
      "Optimization Iteration:     47, Training Accuracy:   0.0%, Loss: 7425.5132\n",
      "Optimization Iteration:     48, Training Accuracy:   0.0%, Loss: 7426.7935\n",
      "Optimization Iteration:     49, Training Accuracy:   0.0%, Loss: 7432.1826\n",
      "Optimization Iteration:     50, Training Accuracy:   0.0%, Loss: 7435.1782\n",
      "Optimization Iteration:     51, Training Accuracy:   0.0%, Loss: 7434.6826\n",
      "Optimization Iteration:     52, Training Accuracy:   0.0%, Loss: 7438.7734\n",
      "Optimization Iteration:     53, Training Accuracy:   0.0%, Loss: 7432.8018\n",
      "Optimization Iteration:     54, Training Accuracy:   0.0%, Loss: 7438.0269\n",
      "Optimization Iteration:     55, Training Accuracy:   0.0%, Loss: 7423.5591\n",
      "Optimization Iteration:     56, Training Accuracy:   0.0%, Loss: 7420.4814\n",
      "Optimization Iteration:     57, Training Accuracy:   0.0%, Loss: 7445.0469\n",
      "Optimization Iteration:     58, Training Accuracy:   0.0%, Loss: 7433.5635\n",
      "Optimization Iteration:     59, Training Accuracy:   0.0%, Loss: 7428.4927\n",
      "Optimization Iteration:     60, Training Accuracy:   0.0%, Loss: 7437.5635\n",
      "Optimization Iteration:     61, Training Accuracy:   0.0%, Loss: 7436.6201\n",
      "Optimization Iteration:     62, Training Accuracy:   0.0%, Loss: 7435.8765\n",
      "Optimization Iteration:     63, Training Accuracy:   0.0%, Loss: 7391.7969\n",
      "All images have been processed.\n",
      "Model saved in file: SD/sd_01_.ckpt\n",
      "Time usage: 0:05:08\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024, 1088, 1152, 1216, 1280, 1344, 1408, 1472, 1536, 1600, 1664, 1728, 1792, 1856, 1920, 1984, 2048, 2112, 2176, 2240, 2304, 2368, 2432, 2496, 2560, 2624, 2688, 2752, 2816, 2880, 2944, 3008, 3072, 3136, 3200, 3264, 3328, 3392, 3456, 3520, 3584, 3648, 3712, 3776, 3840, 3904, 3968, 4032, 64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024, 1088, 1152, 1216, 1280, 1344, 1408, 1472, 1536, 1600, 1664, 1728, 1792, 1856, 1920, 1984, 2048, 2112, 2176, 2240, 2304, 2368, 2432, 2496, 2560, 2624, 2688, 2752, 2816, 2880, 2944, 3008, 3072, 3136, 3200, 3264, 3328, 3392, 3456, 3520, 3584, 3648, 3712, 3776, 3840, 3904, 3968, 4032, 64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024, 1088, 1152, 1216, 1280, 1344, 1408, 1472, 1536, 1600, 1664, 1728, 1792, 1856, 1920, 1984, 2048, 2112, 2176, 2240, 2304, 2368, 2432, 2496, 2560, 2624, 2688, 2752, 2816, 2880, 2944, 3008, 3072, 3136, 3200, 3264, 3328, 3392, 3456, 3520, 3584, 3648, 3712, 3776, 3840, 3904, 3968, 4032, 64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024, 1088, 1152, 1216, 1280, 1344, 1408, 1472, 1536, 1600, 1664, 1728, 1792, 1856, 1920, 1984, 2048, 2112, 2176, 2240, 2304, 2368, 2432, 2496, 2560, 2624, 2688, 2752, 2816, 2880, 2944, 3008, 3072, 3136, 3200, 3264, 3328, 3392, 3456, 3520, 3584, 3648, 3712, 3776, 3840, 3904, 3968, 4032, 64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024, 1088, 1152, 1216, 1280, 1344, 1408, 1472, 1536, 1600, 1664, 1728, 1792, 1856, 1920, 1984, 2048, 2112, 2176, 2240, 2304, 2368, 2432, 2496, 2560, 2624, 2688, 2752, 2816, 2880, 2944, 3008, 3072, 3136, 3200, 3264, 3328, 3392, 3456, 3520, 3584, 3648, 3712, 3776, 3840, 3904, 3968, 4032, 64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024, 1088, 1152, 1216, 1280, 1344, 1408, 1472, 1536, 1600, 1664, 1728, 1792, 1856, 1920, 1984, 2048, 2112, 2176, 2240, 2304, 2368, 2432, 2496, 2560, 2624, 2688, 2752, 2816, 2880, 2944, 3008, 3072, 3136, 3200, 3264, 3328, 3392, 3456, 3520, 3584, 3648, 3712, 3776, 3840, 3904, 3968, 4032, 64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024, 1088, 1152, 1216, 1280, 1344, 1408, 1472, 1536, 1600, 1664, 1728, 1792, 1856, 1920, 1984, 2048, 2112, 2176, 2240, 2304, 2368, 2432, 2496, 2560, 2624, 2688, 2752, 2816, 2880, 2944, 3008, 3072, 3136, 3200, 3264, 3328, 3392, 3456, 3520, 3584, 3648, 3712, 3776, 3840, 3904, 3968, 4032, 64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024, 1088, 1152, 1216, 1280, 1344, 1408, 1472, 1536, 1600, 1664, 1728, 1792, 1856, 1920, 1984, 2048, 2112, 2176, 2240, 2304, 2368, 2432, 2496, 2560, 2624, 2688, 2752, 2816, 2880, 2944, 3008, 3072, 3136, 3200, 3264, 3328, 3392, 3456, 3520, 3584, 3648, 3712, 3776, 3840, 3904, 3968, 4032, 64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024, 1088, 1152, 1216, 1280, 1344, 1408, 1472, 1536, 1600, 1664, 1728, 1792, 1856, 1920, 1984, 2048, 2112, 2176, 2240, 2304, 2368, 2432, 2496, 2560, 2624, 2688, 2752, 2816, 2880, 2944, 3008, 3072, 3136, 3200, 3264, 3328, 3392, 3456, 3520, 3584, 3648, 3712, 3776, 3840, 3904, 3968, 4032, 64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024, 1088, 1152, 1216, 1280, 1344, 1408, 1472, 1536, 1600, 1664, 1728, 1792, 1856, 1920, 1984, 2048, 2112, 2176, 2240, 2304, 2368, 2432, 2496, 2560, 2624, 2688, 2752, 2816, 2880, 2944, 3008, 3072, 3136, 3200, 3264, 3328, 3392, 3456, 3520, 3584, 3648, 3712, 3776, 3840, 3904, 3968, 4032]\n"
     ]
    }
   ],
   "source": [
    "base_model = 'SD/sd_01_.ckpt'\n",
    "save_model = True\n",
    "save_name = base_model\n",
    "restore_model=False\n",
    "restore_name=None\n",
    "\n",
    "optimize(num_iterations=10, save_model=True,save_name=base_model,restore_model=False,restore_name=base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_see_layer(ix, model_name=None, var_name=None):\n",
    "    with tf.Session('', tf.Graph()) as s:\n",
    "        with s.graph.as_default():\n",
    "            if ((model_name != None) and var_name != None):\n",
    "                saver = tf.train.import_meta_graph(model_name+\".meta\")\n",
    "                saver.restore(s, model_name)\n",
    "                fd = {'x_3:0':ix}\n",
    "                var_name=var_name+\":0\"\n",
    "                \n",
    "                \n",
    "#                 for i in s.graph.get_operations():\n",
    "#                     print(i.name)\n",
    "                    \n",
    "#                 result = 0\n",
    "                result = s.run(var_name, feed_dict=fd)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = load_data(img_dir)\n",
    "train = train_data[0:64]\n",
    "labels = train_labels[0:64]\n",
    "train, labels = get_batch_images(train, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10800)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:1, :].shape\n",
    "# np.expand_dims(train[0], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from SD/sd_01_.ckpt\n",
      "(1, 1200)\n"
     ]
    }
   ],
   "source": [
    "img_x = train[0:1, :]#np.expand_dims(train[0], axis=0).shape\n",
    "lbl_x = labels[0:1, :]\n",
    "output_cl1 = restore_see_layer(ix=img_x,model_name=base_model,var_name='fc_7/fc4')\n",
    "print(output_cl1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_output(iNp,depth_filter_to_see=0,cmap=\"gray\",figsize=(4,4)):\n",
    "    img_x = iNp[0,:,:,depth_filter_to_see]\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.imshow(img_x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1200)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a350d80f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3e0e8438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visual_image = np.reshape(output_cl1, (1, 20, 20, 3))\n",
    "visual_label = np.reshape(lbl_x, (1, 20, 20, 3))\n",
    "\n",
    "see_output(visual_image,1)\n",
    "see_output(visual_label, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sr_plot = [0.5, 0.75, 0.78125, 0.8125, 0.8125, 0.8125, 0.8125, 0.828125, 0.875, 0.90625, 0.78125, 0.90625, 0.78125, 0.921875, 0.828125, 0.921875]\n",
    "accuracy_sd_plot = [0.421875, 0.484375, 0.484375, 0.453125, 0.578125, 0.515625, 0.5625, 0.5625, 0.5, 0.5625, 0.671875, 0.59375, 0.421875, 0.5625, 0.484375, 0.515625]\n",
    "accuracy_sd_patchonly_plot = [0.578125, 0.890625, 0.8125, 0.890625, 0.890625, 0.8125, 0.796875, 0.9375, 0.90625, 0.890625, 0.90625, 0.84375, 0.859375, 0.828125, 0.9375, 0.890625]\n",
    "accuracy_sd_conv_plot = [0.609375, 0.671875, 0.828125, 0.84375, 0.78125, 0.8125, 0.859375, 0.828125, 0.84375, 0.890625, 0.953125, 0.90625, 0.921875, 0.84375, 0.921875, 0.859375]\n",
    "training_size_sd_plot = [64, 64064, 128064, 192064, 256064, 320064, 384064, 448064, 512064, 576064, 640064, 704064, 768064, 832064, 896064, 960064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_no, training_size, accuracy, loss, start_size, end_size\n",
    "\n",
    "generate_size_graph(1, training_size_sd_plot, accuracy_sd_plot, accuracy_sr_plot,accuracy_sd_patchonly_plot,accuracy_sd_conv_plot,  64, 960064)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred, correct):\n",
    "    # This function is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # correct is a boolean array whether the predicted class\n",
    "    # is equal to the true class for each image in the test-set.\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = data.test.images[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = data.test.cls[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])\n",
    "    \n",
    "def plot_confusion_matrix(cls_pred):\n",
    "    # This is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = data.test.cls\n",
    "    \n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.matshow(cm)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test-set into smaller batches of this size.\n",
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    # Number of images in the test-set.\n",
    "    num_test = len(data.test.images)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        # Get the images from the test-set between index i and j.\n",
    "        images = data.test.images[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = data.test.labels[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the test-set.\n",
    "    cls_true = data.test.cls\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the test-set.\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "\n",
    "    # Plot some examples of mis-classifications, if desired.\n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "    # Plot the confusion matrix, if desired.\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_true_batch = data.test.next_batch(64)\n",
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
