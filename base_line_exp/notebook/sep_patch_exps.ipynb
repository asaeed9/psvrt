{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2, os, math, time\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configuration\n",
    "\"\"\"\n",
    "Data Configurations/Paths\n",
    "\"\"\"\n",
    "img_dir_patch=\"./SD/predicted_patches\"\n",
    "img_dir_orig = \"./SD/original_images\"\n",
    "img_dir=\"../../original_images/SD\"\n",
    "model50_SD = 'SD/50kSD_Model.ckpt'\n",
    "model50_local_top_1 = 'SD/50k_local_top_Model.ckpt'\n",
    "model50_left_mask = 'SD/50k_left_mask.ckpt'\n",
    "\n",
    "img_type = \"original\"\n",
    "# img_type = \"patch\"\n",
    "\n",
    "##\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 4          # Convolution filters are 4 x 4 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters2 = 32         # There are 32 of these filters.\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters3 = 64         # There are 64 of these filters.\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size4 = 2          # Convolution filters are 2 x 2 pixels.\n",
    "num_filters4 = 128         # There are 128 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 2000             # Number of neurons in fully-connected layer.\n",
    "\n",
    "# We know that images are 60 pixels in each dimension.\n",
    "# img_size = 8 * 4\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 10 * 10\n",
    "\n",
    "# Number of colour channels for the images: 3 channel for RGB.\n",
    "num_channels = 3\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (10, 10, num_channels)\n",
    "\n",
    "# Number of classes, one class for same or different image\n",
    "num_classes = 10*10\n",
    "orig_patch_size = (2, 2, 3)\n",
    "npatches = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label_dimensions(labels):\n",
    "    label_temp = np.zeros((len(labels), 2))\n",
    "    \n",
    "    for idx in range(0, len(labels)):\n",
    "        if labels[idx] == 1:\n",
    "            label_temp[idx][1] = 1\n",
    "        else:\n",
    "            label_temp[idx][0] = 1\n",
    "    \n",
    "    return label_temp\n",
    "\n",
    "def load_data(img_dir):\n",
    "        list_of_orig_imgs = []\n",
    "        list_of_pred_imgs = []\n",
    "        list_of_labels = []\n",
    "        list_same_diff = []\n",
    "        list_img_keys = []\n",
    "        for img in os.listdir(img_dir):\n",
    "            \n",
    "            img_path = os.path.join(img_dir, img)\n",
    "            list_same_diff.append(int(os.listdir(img_path)[0]))\n",
    "            list_img_keys.append(img)\n",
    "            img_path = img_path + \"/\" + os.listdir(img_path)[0]\n",
    "            for img_label in os.listdir(img_path):\n",
    "                img_data = os.path.join(img_path, img_label)\n",
    "                if img_label == \"img\":\n",
    "#                     print(img_data + \"/img.png\")\n",
    "                    list_of_orig_imgs.append(img_data + \"/img.png\")\n",
    "                    list_of_pred_imgs.append(img_data + \"/predicted_mask.png\")\n",
    "                else:\n",
    "                    list_of_labels.append([os.path.join(img_data, label) for label in os.listdir(img_data)])\n",
    "\n",
    "        data_imgs = np.array([list_of_orig_imgs, list_of_pred_imgs])\n",
    "        data_labels = np.array(list_of_labels)\n",
    "        data_same_diff = np.array(list_same_diff)\n",
    "        data_img_keys = np.array(list_img_keys)\n",
    "\n",
    "        return data_imgs, data_labels, data_same_diff, data_img_keys\n",
    "\n",
    "    \n",
    "def get_batch_images(data_orig, data_pred, label, same_diff, img_keys, rshp, grey_scale):\n",
    "        list_of_orig_imgs = []\n",
    "        list_of_pred_imgs = []\n",
    "        list_of_labels = []\n",
    "        list_of_same_diff = []\n",
    "        list_of_img_keys = []\n",
    "        for img_orig, img_pred, lbl, img_type, img_key in zip(data_orig, data_pred, label, same_diff, img_keys):\n",
    "            if (grey_scale):\n",
    "                orig_img = cv2.imread(img_orig)\n",
    "                predicted_msk = cv2.imread(img_pred, cv2.IMREAD_GRAYSCALE)\n",
    "            else:\n",
    "                orig_img = cv2.imread(img[0])\n",
    "            \n",
    "#             print(lbl, type(lbl))\n",
    "            orig_lbl = cv2.imread(lbl, cv2.IMREAD_GRAYSCALE)\n",
    "            if orig_img is None or orig_lbl is None:\n",
    "                    print (\"Unable to read image{} or {}\".format(img[0], lbl))\n",
    "                    continue\n",
    "            \n",
    "#             if (grey_scale):\n",
    "#                 orig_lbl = rgb2grey(orig_lbl)\n",
    "\n",
    "            flattened_orig_img = orig_img.flatten()\n",
    "            flattened_pred_img = predicted_msk.flatten()\n",
    "            flattened_lbl = orig_lbl.flatten()\n",
    "            \n",
    "#             if grey_scale:\n",
    "#                 flattened_lbl = np.reshape(flattened_lbl, [10, 10])\n",
    "#                 print(flattened_lbl)\n",
    "#                 flattened_lbl = normalize(flattened_lbl)\n",
    "#                 print(flattened_lbl)\n",
    "            \n",
    "            list_of_orig_imgs.append(np.asarray(flattened_orig_img, dtype=np.float32))\n",
    "            list_of_pred_imgs.append(np.asarray(flattened_pred_img, dtype=np.float32))\n",
    "        \n",
    "            list_of_labels.append(np.asarray(flattened_lbl, dtype=np.float32))\n",
    "            list_of_same_diff.append(img_type)\n",
    "            list_of_img_keys.append(img_key)\n",
    "\n",
    "        data_labels = np.array(list_of_labels)\n",
    "        data_imgs = np.array([list_of_orig_imgs, list_of_pred_imgs])\n",
    "        data_img_type = np.array(list_of_same_diff)\n",
    "        data_img_keys = np.array(list_of_img_keys)\n",
    "        \n",
    "        \"\"\"this function call locates top left location of each patch in the mask and return. Comment it if contents are required.\"\"\"\n",
    "#         print(data_labels.shape)\n",
    "#         data_labels = get_patch_loc(data_labels)\n",
    "        \n",
    "        return data_imgs, data_labels, data_img_type, data_img_keys\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Batch Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_orig = data[0, :]\n",
    "    data_pred = data[1, :]\n",
    "    data_orig_shuffle = [data[0, i] for i in idx]\n",
    "    data_pred_shuffle = [data[1, i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_orig_shuffle), np.asarray(data_pred_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape, layer_name):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape), name=layer_name+'_W')\n",
    "\n",
    "def new_bias(length, layer_name):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]), name=layer_name+'_b')\n",
    "\n",
    "def new_conv_layer(input,\n",
    "                   num_input_channels,\n",
    "                   filter_size,\n",
    "                   num_filters,\n",
    "                   name_scope,\n",
    "                   layer_name='',\n",
    "                   use_pooling=True):\n",
    "\n",
    "    with tf.name_scope(name_scope):\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "        weights = new_weights(shape, layer_name)\n",
    "        biases = new_bias(num_filters, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.nn.conv2d(input=input, filter=weights, strides=[1,1,1,1], padding='SAME'), biases, name=layer_name)\n",
    "\n",
    "        if use_pooling:\n",
    "            layer = tf.nn.max_pool(value=layer,\n",
    "                                   ksize=[1, 3, 3, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME', name=layer_name+'_max')\n",
    "        layer = tf.nn.relu(layer, name=layer_name+'_activation')\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                name_scope,\n",
    "                layer_name='',\n",
    "                use_relu=True):\n",
    "    \n",
    "    with tf.name_scope(name_scope):\n",
    "        weights = new_weights([num_inputs, num_outputs], layer_name)\n",
    "        biases = new_bias(num_outputs, layer_name)\n",
    "\n",
    "        layer = tf.add(tf.matmul(input, weights),biases,name=layer_name)\n",
    "    #     layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer, layer_name+'_activation')\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def normalise(tensor):\n",
    "    return tf.div(\n",
    "   tf.subtract(\n",
    "      tensor, \n",
    "      tf.reduce_min(tensor)\n",
    "   ), \n",
    "   tf.subtract(\n",
    "      tf.reduce_max(tensor), \n",
    "      tf.reduce_min(tensor)\n",
    "   )\n",
    ")\n",
    "\n",
    "def normalized(arr):\n",
    "    return (arr - np.min(arr))/(np.max(arr) - np.min(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat*num_channels], name='x')\n",
    "x_image = tf.reshape(x, [-1, 10, 10, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
    "                                            num_input_channels=num_channels,\n",
    "                                            filter_size=filter_size1,\n",
    "                                            num_filters=num_filters1,\n",
    "                                             name_scope = 'conv',\n",
    "                                             layer_name = 'conv1',\n",
    "                                            use_pooling=True)\n",
    "\n",
    "layer2_conv2, weights_conv2 =  new_conv_layer(input=layer1_conv1,\n",
    "                                           num_input_channels=num_filters1,\n",
    "                                           filter_size=filter_size2,\n",
    "                                           num_filters=num_filters2,\n",
    "                                             name_scope = 'conv',\n",
    "                                             layer_name = 'conv2',\n",
    "                                              \n",
    "                                           use_pooling=True)\n",
    "\n",
    "layer3_conv3, weights_conv3 =  new_conv_layer(input=layer2_conv2,\n",
    "                                           num_input_channels=num_filters2,\n",
    "                                           filter_size=filter_size3,\n",
    "                                           num_filters=num_filters3,\n",
    "                                             name_scope = 'conv',\n",
    "                                             layer_name = 'conv3',\n",
    "                                              \n",
    "                                           use_pooling=True)\n",
    "\n",
    "layer4_conv4, weights_conv4 =  new_conv_layer(input=layer3_conv3,\n",
    "                                           num_input_channels=num_filters3,\n",
    "                                           filter_size=filter_size4,\n",
    "                                           num_filters=num_filters4,\n",
    "                                             name_scope = 'conv',\n",
    "                                             layer_name = 'conv4',\n",
    "                                           use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer4_conv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc1',\n",
    "                         use_relu=True)\n",
    "\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc2',\n",
    "                         use_relu=False)\n",
    "\n",
    "layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc3',\n",
    "                         use_relu=False)\n",
    "\n",
    "layer_fc4 = new_fc_layer(input=layer_fc3,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         name_scope = 'fc',\n",
    "                         layer_name = 'fc4',\n",
    "                         use_relu=False)\n",
    "\n",
    "# drop_out = tf.nn.dropout(layer_fc4, 0.5, name=\"drop_out\")\n",
    "\n",
    "y_pred = tf.nn.softmax(layer_fc4, name=\"softmax_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "# ## some more performance measures\n",
    "correct_prediction = tf.equal(y_pred, y_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tensorflow on Defined Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "session = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "train_labels = train_labels[:][:, 3]\n",
    "train_orig_data = train_data[0, :]\n",
    "train_pred_data = train_data[1, :]\n",
    "img_type = img_type[:]\n",
    "img_keys = img_keys[:]\n",
    "total_imgs = len(img_type)\n",
    "train_batch_size = 64\n",
    "\n",
    "def optimize(num_epochs, save_model=True,save_name= \"base_model\",restore_model=False,restore_name=None):\n",
    "    total_iterations = 0\n",
    "    done_train_imgs = 0\n",
    "    start_time = time.time()\n",
    "    start_ = 0\n",
    "    end_ = train_batch_size    \n",
    "    plot_accuracy=[]\n",
    "    plot_accuracy_epoch=[]\n",
    "    plot_training_size=[]\n",
    "    plot_training_size_epoch=[]\n",
    "    saver = tf.train.Saver()\n",
    "    sum_accuracy = 0.0\n",
    "    n = 1\n",
    "    \n",
    "        #to save the model\n",
    "    for i in range(0, num_epochs):   \n",
    "        start_batch=0\n",
    "        end_batch = train_batch_size\n",
    "        \n",
    "        print(\"Epoch:\", i + 1)\n",
    "        \n",
    "        if restore_model==True:\n",
    "            if restore_name==None:\n",
    "                print(\"No model file specified\")\n",
    "                return\n",
    "            else:\n",
    "                saver.restore(session,restore_name)\n",
    "        \n",
    "        sum_accuracy = 0.0\n",
    "        n = 1\n",
    "        while end_batch < total_imgs:\n",
    "            train_orig = train_orig_data[start_batch:end_batch]\n",
    "            train_pred = train_pred_data[start_batch:end_batch]\n",
    "            labels = train_labels[start_batch:end_batch]\n",
    "#             print('Labels:', labels)\n",
    "            img_type_lbl = img_type[start_:end_]\n",
    "            img_key = img_keys[start_:end_]\n",
    "            dims = (len(train_orig), num_classes, num_channels)\n",
    "            train, labels, img_type_lbl, img_key = get_batch_images(train_orig, train_pred, labels, img_type_lbl, img_key, dims, True)\n",
    "            if not len(train) and not len(labels):\n",
    "                print(\"All images have been processed.\")\n",
    "                break;\n",
    "\n",
    "            x_orig_batch, x_pred_batch, y_true_batch = next_batch(len(train[0]), train, labels)\n",
    "            feed_dict_train = {x: x_orig_batch,\n",
    "                       y_true: y_true_batch}\n",
    "            \n",
    "            session.run(optimizer, feed_dict=feed_dict_train)\n",
    "    \n",
    "            acc,co = session.run([accuracy, cost], feed_dict=feed_dict_train)\n",
    "            sum_accuracy += acc\n",
    "            n+=1\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}, Loss: {2:>.4f}\"\n",
    "            print(msg.format(end_batch + 1, acc, co))\n",
    "            if i == num_epochs - 1:\n",
    "                plot_accuracy.append(acc)\n",
    "                plot_training_size.append(end_batch + 1)\n",
    "\n",
    "            start_batch += train_batch_size\n",
    "            end_batch += train_batch_size\n",
    "    \n",
    "        if save_model==True:\n",
    "            if save_name==None:\n",
    "                print(\"No model specified, model not being saved\")\n",
    "                return\n",
    "            else:\n",
    "                save_path = saver.save(session, save_name)\n",
    "                restore_model = True\n",
    "                print(\"Model saved in file: %s\" % save_name)\n",
    "        plot_accuracy_epoch.append(sum_accuracy/n)\n",
    "        plot_training_size_epoch.append(i + 1)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))  \n",
    "    print(plot_accuracy)\n",
    "    print(plot_training_size)\n",
    "    print(plot_accuracy_epoch)\n",
    "    print(plot_training_size_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance/Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 2712.4099\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 2711.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 2711.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 2712.2366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 2712.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 2711.7163\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 2712.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Model saved in file: SD/50k_left_mask.ckpt\n",
      "Epoch: 2\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 2712.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 2711.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 2712.4099\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 2712.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 2712.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 2712.2366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 2711.7163\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Model saved in file: SD/50k_left_mask.ckpt\n",
      "Epoch: 3\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 2712.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 2712.2366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 2712.4099\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 2711.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 2711.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 2712.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 2712.0632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 2711.7163\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Model saved in file: SD/50k_left_mask.ckpt\n",
      "Epoch: 4\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 2712.0632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 2712.4099\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 2712.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 2712.0632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 2712.0632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 2711.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 2711.7163\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Model saved in file: SD/50k_left_mask.ckpt\n",
      "Epoch: 5\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 2712.2366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 2712.4099\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 2712.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 2712.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 2712.0632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 2711.7163\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Model saved in file: SD/50k_left_mask.ckpt\n",
      "Epoch: 6\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 2712.0632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 2712.4099\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 2712.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 2712.0632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 2712.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 2712.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 2711.7163\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Model saved in file: SD/50k_left_mask.ckpt\n",
      "Epoch: 7\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 2712.2944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 2712.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 2712.4099\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 2712.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 2711.7163\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Model saved in file: SD/50k_left_mask.ckpt\n",
      "Epoch: 8\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 2712.2366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 2712.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 2712.4099\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 2712.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 2712.2944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 2712.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 2711.7163\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Model saved in file: SD/50k_left_mask.ckpt\n",
      "Epoch: 9\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 2712.2366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 2712.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 2712.3523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 2712.4099\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 2712.3523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  22913, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  23233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23297, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23361, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  23425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  23553, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  23681, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23745, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  23809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  23873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  23937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24001, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24449, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24513, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  24577, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  24641, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24705, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  24769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  24833, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  24897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  24961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25025, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25153, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25217, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25409, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  25473, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  25537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  25601, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25665, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  25729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  25793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  25857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  25921, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  25985, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26049, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26113, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  26177, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  26241, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  26305, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26369, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  26433, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  26497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  26689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  26753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  26945, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  27009, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27073, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  27137, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27201, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  27265, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27329, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  27521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27585, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  27649, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  27713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27777, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27841, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  27905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  27969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28033, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28097, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  28161, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28225, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  28353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28417, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  28481, Training Accuracy:   0.0%, Loss: 2711.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  28545, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  28609, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28673, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  28737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  28801, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  28929, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  28993, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29057, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  29121, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29185, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29249, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29313, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  29377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  29441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  29505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29569, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29633, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29697, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  29761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29825, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  29889, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  29953, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30145, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30465, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30529, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  30593, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  30657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  30721, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  30785, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  30849, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  30913, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  30977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  31041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31169, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31233, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31297, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31361, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  31425, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  31553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31617, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  31745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  31809, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  31873, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  31937, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32001, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  32065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32257, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  32385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32513, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  32577, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  32769, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  32833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32897, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  32961, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  33025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  33281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33345, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33409, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  33473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  33537, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33729, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  33793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33857, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  33921, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  33985, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  34049, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  34177, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34241, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34305, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34369, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34561, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34625, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  34689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  34753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  34817, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  34881, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  34945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35009, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  35073, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35137, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  35329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  35393, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  35457, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35521, Training Accuracy:   0.0%, Loss: 2712.2944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  35585, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  35649, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  35713, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  35777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  35905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  35969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36161, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36289, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36353, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36417, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36481, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  36609, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  36673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  36801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  36865, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  36929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  36993, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37057, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  37121, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  37185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37377, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37569, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  37633, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  37697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  37761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  37825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  37889, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  37953, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  38017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38081, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38209, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38273, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  38337, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  38401, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38465, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  38529, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  38593, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  38657, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  38785, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  38849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  38977, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39105, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39169, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  39233, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  39297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39425, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  39489, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39617, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  39681, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  39745, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  39809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  39873, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  39937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40001, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  40065, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  40129, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40257, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  40321, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40449, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  40577, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40641, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  40705, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  40769, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  40897, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  40961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  41089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41153, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41281, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41345, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  41409, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41473, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  41537, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  41601, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  41665, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41729, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  41857, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  41921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  41985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42049, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42113, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  42241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42305, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  42433, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42497, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42561, Training Accuracy:   0.0%, Loss: 2712.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  42625, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  42689, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  42753, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  42817, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  42881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  42945, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43073, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43137, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  43201, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43265, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43329, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43393, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43457, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  43521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  43649, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  43713, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  43777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43841, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  43905, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  43969, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44033, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44161, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  44289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44353, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  44417, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44609, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  44673, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  44737, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  44801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  44865, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  44929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  44993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45121, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45185, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  45249, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  45313, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45377, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45441, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45505, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45633, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  45697, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  45825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  45889, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  45953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46017, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46081, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  46145, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  46209, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46273, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  46337, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46401, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  46465, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46529, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  46593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  46657, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46721, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  46849, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46913, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  46977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47041, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47105, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47233, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47297, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47489, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  47553, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  47617, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47681, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  47745, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  47809, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  47873, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  47937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48001, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  48065, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48129, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48193, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48257, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48321, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48385, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  48513, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  48577, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  48705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  48769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  48833, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  48961, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49025, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49089, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49153, Training Accuracy:   0.0%, Loss: 2711.7163\n",
      "Optimization Iteration:  49217, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  49281, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  49409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49473, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49537, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  49601, Training Accuracy:   0.0%, Loss: 2712.0632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  49665, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49729, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  49793, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  49857, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  49921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  49985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Model saved in file: SD/50k_left_mask.ckpt\n",
      "Epoch: 10\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "Optimization Iteration:     65, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:    129, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:    193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    257, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:    385, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    513, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:    577, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:    769, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    833, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:    897, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:    961, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1025, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1089, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1153, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1217, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   1281, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   1345, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1409, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1473, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1537, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   1601, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1665, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   1729, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   1793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1857, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   1921, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   1985, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2177, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2241, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   2305, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2433, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   2497, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2561, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2625, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   2689, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   2753, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   2817, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2881, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   2945, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   3009, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3073, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3137, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3201, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3329, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   3393, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3457, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3521, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3649, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   3713, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   3777, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   3841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   3905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   3969, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4033, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4097, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4161, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4225, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4289, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   4481, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4545, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   4609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4673, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   4737, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   4801, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   4865, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   4929, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   4993, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5057, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   5185, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5249, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   5441, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5505, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5569, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:   5633, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   5697, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   5761, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   5825, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   5889, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   5953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6017, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6081, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:   6145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6209, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6337, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   6401, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6465, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   6529, Training Accuracy:   0.0%, Loss: 2711.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   6593, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   6657, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6721, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   6785, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   6849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   6913, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   6977, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   7041, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7105, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:   7169, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7233, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7297, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   7361, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7425, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7489, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7553, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   7617, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   7681, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   7809, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7873, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   7937, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8065, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8129, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8193, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8257, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8321, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8385, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   8449, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8513, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   8577, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   8641, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   8705, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8769, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   8833, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   8897, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:   8961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9025, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9089, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9153, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:   9217, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9281, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9345, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9409, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9473, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:   9537, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9601, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9665, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:   9729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:   9793, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:   9857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:   9921, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:   9985, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10049, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10113, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10177, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10241, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  10369, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10433, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  10497, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  10561, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10625, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10689, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  10753, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  10817, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  10881, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  10945, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11009, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11073, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  11137, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11201, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11265, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  11329, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11393, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  11457, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  11521, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11585, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  11649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  11713, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11841, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  11905, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  11969, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12033, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12097, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  12161, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12289, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12353, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12417, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  12481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  12545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12609, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12673, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  12737, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  12801, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  12865, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  12929, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  12993, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13057, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13121, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13185, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13249, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13313, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13377, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13441, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  13505, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13569, Training Accuracy:   0.0%, Loss: 2712.2944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  13633, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  13697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  13761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  13825, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  13889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  13953, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14017, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14081, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14145, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14273, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14337, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  14401, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  14465, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  14529, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  14593, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14657, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  14721, Training Accuracy:   0.0%, Loss: 2712.4099\n",
      "Optimization Iteration:  14785, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  14849, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14913, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  14977, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15041, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15105, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15169, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  15233, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15297, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15361, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15425, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15489, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  15553, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  15617, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15681, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  15745, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  15809, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  15873, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  15937, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16001, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16065, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16129, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16193, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16257, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16321, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16385, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16449, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  16513, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  16577, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  16641, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16705, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  16769, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  16833, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16897, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  16961, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  17025, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17089, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17153, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17217, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17281, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17345, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  17409, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17473, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  17537, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  17601, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17665, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17729, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  17793, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  17857, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17921, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  17985, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18049, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  18113, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18177, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18241, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18305, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18369, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  18433, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  18497, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  18561, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18625, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18689, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  18753, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18817, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  18881, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  18945, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  19009, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19073, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19137, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  19201, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19265, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19329, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  19393, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19457, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19521, Training Accuracy:   0.0%, Loss: 2711.9475\n",
      "Optimization Iteration:  19585, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19649, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  19713, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  19777, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  19841, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19905, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  19969, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  20033, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20097, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20161, Training Accuracy:   0.0%, Loss: 2711.6584\n",
      "Optimization Iteration:  20225, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20289, Training Accuracy:   0.0%, Loss: 2711.8896\n",
      "Optimization Iteration:  20353, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20417, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20481, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20545, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  20609, Training Accuracy:   0.0%, Loss: 2712.2366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  20673, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  20737, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  20801, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20865, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  20929, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  20993, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21057, Training Accuracy:   0.0%, Loss: 2711.7742\n",
      "Optimization Iteration:  21121, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  21185, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21249, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21313, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21377, Training Accuracy:   0.0%, Loss: 2712.2944\n",
      "Optimization Iteration:  21441, Training Accuracy:   0.0%, Loss: 2712.3523\n",
      "Optimization Iteration:  21505, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21569, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21633, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  21697, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21761, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  21825, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  21889, Training Accuracy:   0.0%, Loss: 2712.0632\n",
      "Optimization Iteration:  21953, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22017, Training Accuracy:   0.0%, Loss: 2712.0054\n",
      "Optimization Iteration:  22081, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22145, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22209, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22273, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22337, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22401, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22465, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22529, Training Accuracy:   0.0%, Loss: 2711.8318\n",
      "Optimization Iteration:  22593, Training Accuracy:   0.0%, Loss: 2712.2366\n",
      "Optimization Iteration:  22657, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22721, Training Accuracy:   0.0%, Loss: 2712.1787\n",
      "Optimization Iteration:  22785, Training Accuracy:   0.0%, Loss: 2712.1208\n",
      "Optimization Iteration:  22849, Training Accuracy:   0.0%, Loss: 2712.0632\n"
     ]
    }
   ],
   "source": [
    "save_model = True\n",
    "save_name = model50_left_mask\n",
    "restore_model=True\n",
    "restore_name=model50_left_mask\n",
    "# init = tf.global_variables_initializer()\n",
    "# session.run(init)\n",
    "\n",
    "optimize(20, save_model=True,save_name=model50_left_mask,restore_model=restore_model,restore_name=model50_left_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_see_layer(orig, model_name=None, var_name=None):\n",
    "    with tf.Session('', tf.Graph()) as s:\n",
    "        with s.graph.as_default():\n",
    "            if ((model_name != None) and var_name != None):\n",
    "                saver = tf.train.import_meta_graph(model_name+\".meta\")\n",
    "                saver.restore(s, model_name)\n",
    "#                 print(pred.shape)\n",
    "                fd = {'x:0': orig}\n",
    "#                 print(fd.shape)\n",
    "                var_name=var_name+\":0\"\n",
    "                \n",
    "                result = 0\n",
    "                result = s.run(var_name, feed_dict=fd)\n",
    "    return result\n",
    "\n",
    "def see_output_grey(iNp,depth_filter_to_see=0,cmap=\"gray\",figsize=(4,4)):\n",
    "    img_x = iNp[0,:,:]\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.imshow(img_x, interpolation='none', aspect='auto')\n",
    "#     plt.colorbar(img_x, orientation='horizontal')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def see_output(iNp,depth_filter_to_see=0,cmap=\"gray\",figsize=(4,4)):\n",
    "    img_x = iNp[0,:,:,:]\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if cmap == \"gray\":\n",
    "        plt.imshow(img_x, cmap=plt.get_cmap('gray'))\n",
    "    else:\n",
    "        plt.imshow(img_x, interpolation='none', aspect='auto')\n",
    "#     plt.colorbar(img_x, orientation='horizontal')\n",
    "    plt.show()\n",
    "    \n",
    "def save_patch_images(img_x1, lbl_x1, index):\n",
    "    if not os.path.exists('./SD/predicted_patches/' + str(index)):\n",
    "        os.makedirs('./SD/predicted_patches/' + str(index))\n",
    "        os.makedirs('./SD/predicted_patches/' + str(index) + \"/\" + str(lbl_x1))\n",
    "        \n",
    "    plt.imsave('./SD/predicted_patches/' + str(index) + \"/\" + str(lbl_x1) + '/img.png', np.squeeze(img_x1))\n",
    "    \n",
    "\n",
    "def predict_nd_save(train, labels, img_type_lbl, img_key, start_idx):\n",
    "\n",
    "    for index in range(0, len(train)):\n",
    "        img_x = train[index:index+1, :]\n",
    "        lbl_x = labels[index:index+1, :]\n",
    "        img_type_x = img_type_lbl[index]\n",
    "        img_key_x = img_key[index]\n",
    "        prediction = restore_see_layer(ix=img_x,model_name=model2_50000,var_name='Softmax')\n",
    "        prediction = np.reshape(prediction, (1, 4, 2, 1))   \n",
    "        save_patch_images(prediction, img_type_x, img_key_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)\n",
    "train_mask_labels = train_labels[:][:, 1]\n",
    "train_patch_labels = train_labels[:][:, 0]\n",
    "\n",
    "batch_s = 64\n",
    "total_iterations = 0\n",
    "start_ = 0\n",
    "end_ = batch_s\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "if not os.path.exists('./SD/predicted_patches'):\n",
    "    os.makedirs('./SD/predicted_patches')\n",
    "\n",
    "while True:\n",
    "    train = train_data[start_:end_]\n",
    "    labels = train_patch_labels[start_:end_]\n",
    "    img_type_lbl = img_type[start_:end_]\n",
    "    img_key = img_keys[start_:end_]\n",
    "    dims = (batch_s, num_classes, num_channels)\n",
    "    train, labels, img_type_lbl, img_key = get_batch_images(train, labels, img_type_lbl, img_key, dims, True)\n",
    "    predict_nd_save(train, labels, img_type_lbl, img_key, start_)\n",
    "    \n",
    "    #do my stuff\n",
    "    if len(train_data) < start_ + batch_s:\n",
    "        print(\"{} Images have been processed.\".format(total_iterations))\n",
    "        break\n",
    "    \n",
    "    total_iterations +=batch_s\n",
    "    start_ = end_\n",
    "    end_ = end_ + batch_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=(?, 300) dtype=float32>,\n",
       " <tf.Tensor 'Reshape/shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'Reshape:0' shape=(?, 10, 10, 3) dtype=float32>,\n",
       " <tf.Tensor 'y_true:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'ArgMax/dimension:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'ArgMax:0' shape=(?,) dtype=int64>,\n",
       " <tf.Tensor 'conv/random_uniform/shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'conv/random_uniform/min:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv/random_uniform/max:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv/random_uniform/RandomUniform:0' shape=(4, 4, 3, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/random_uniform/sub:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv/random_uniform/mul:0' shape=(4, 4, 3, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/random_uniform:0' shape=(4, 4, 3, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_W:0' shape=(4, 4, 3, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_W/Assign:0' shape=(4, 4, 3, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_W/read:0' shape=(4, 4, 3, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/Const:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_b:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_b/Assign:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_b/read:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'conv/Conv2D:0' shape=(?, 10, 10, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1:0' shape=(?, 10, 10, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_max:0' shape=(?, 5, 5, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_activation:0' shape=(?, 5, 5, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/random_uniform/shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'conv_1/random_uniform/min:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_1/random_uniform/max:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_1/random_uniform/RandomUniform:0' shape=(2, 2, 16, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/random_uniform/sub:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_1/random_uniform/mul:0' shape=(2, 2, 16, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/random_uniform:0' shape=(2, 2, 16, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_W:0' shape=(2, 2, 16, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Assign:0' shape=(2, 2, 16, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_W/read:0' shape=(2, 2, 16, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/Const:0' shape=(32,) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_b:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_b/Assign:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_b/read:0' shape=(32,) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/Conv2D:0' shape=(?, 5, 5, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2:0' shape=(?, 5, 5, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_max:0' shape=(?, 3, 3, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_activation:0' shape=(?, 3, 3, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/random_uniform/shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'conv_2/random_uniform/min:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_2/random_uniform/max:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_2/random_uniform/RandomUniform:0' shape=(2, 2, 32, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/random_uniform/sub:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_2/random_uniform/mul:0' shape=(2, 2, 32, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/random_uniform:0' shape=(2, 2, 32, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_W:0' shape=(2, 2, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Assign:0' shape=(2, 2, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_W/read:0' shape=(2, 2, 32, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/Const:0' shape=(64,) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_b:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_b/Assign:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_b/read:0' shape=(64,) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/Conv2D:0' shape=(?, 3, 3, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3:0' shape=(?, 3, 3, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_max:0' shape=(?, 2, 2, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_activation:0' shape=(?, 2, 2, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/random_uniform/shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'conv_3/random_uniform/min:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_3/random_uniform/max:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_3/random_uniform/RandomUniform:0' shape=(2, 2, 64, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/random_uniform/sub:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_3/random_uniform/mul:0' shape=(2, 2, 64, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/random_uniform:0' shape=(2, 2, 64, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_W:0' shape=(2, 2, 64, 128) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Assign:0' shape=(2, 2, 64, 128) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_W/read:0' shape=(2, 2, 64, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/Const:0' shape=(128,) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_b:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_b/Assign:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_b/read:0' shape=(128,) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/Conv2D:0' shape=(?, 2, 2, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4:0' shape=(?, 2, 2, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_max:0' shape=(?, 1, 1, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_activation:0' shape=(?, 1, 1, 128) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_1/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'Reshape_1:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc/random_uniform/min:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform/max:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform/RandomUniform:0' shape=(128, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform/sub:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform/mul:0' shape=(128, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc/random_uniform:0' shape=(128, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_W:0' shape=(128, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_W/Assign:0' shape=(128, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_W/read:0' shape=(128, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc/Const:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_b:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_b/Assign:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_b/read:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc/MatMul:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_activation:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/random_uniform/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc_1/random_uniform/min:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_1/random_uniform/max:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_1/random_uniform/RandomUniform:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/random_uniform/sub:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_1/random_uniform/mul:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/random_uniform:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_W:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Assign:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_W/read:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/Const:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_b:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Assign:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_b/read:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/MatMul:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/random_uniform/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc_2/random_uniform/min:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_2/random_uniform/max:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_2/random_uniform/RandomUniform:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/random_uniform/sub:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_2/random_uniform/mul:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/random_uniform:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_W:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Assign:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_W/read:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/Const:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_b:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Assign:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_b/read:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/MatMul:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/random_uniform/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc_3/random_uniform/min:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_3/random_uniform/max:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_3/random_uniform/RandomUniform:0' shape=(2000, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/random_uniform/sub:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_3/random_uniform/mul:0' shape=(2000, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/random_uniform:0' shape=(2000, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_W:0' shape=(2000, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Assign:0' shape=(2000, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_W/read:0' shape=(2000, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/Const:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_b:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_b/Assign:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_b/read:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/MatMul:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'softmax_output:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'sub:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'Square:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'Const:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'Mean:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/Shape:0' shape=(0,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/grad_ys_0:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/Fill:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Reshape/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Reshape:0' shape=(1, 1) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Tile:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Shape_1:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Shape_2:0' shape=(0,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Const:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Prod:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Const_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Prod_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Maximum/y:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Maximum:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/floordiv:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/Cast:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/Mean_grad/truediv:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Square_grad/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'gradients/Square_grad/Mul:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Square_grad/Mul_1:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Shape_1:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/sub_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/sub_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Reshape:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Neg:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/Reshape_1:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/tuple/control_dependency:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/sub_grad/tuple/control_dependency_1:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/softmax_output_grad/mul:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/softmax_output_grad/Sum/reduction_indices:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/softmax_output_grad/Sum:0' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/softmax_output_grad/Reshape/shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/softmax_output_grad/Reshape:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'gradients/softmax_output_grad/sub:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/softmax_output_grad/mul_1:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_3/fc4_grad/Shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_3/fc4_grad/Shape_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_3/fc4_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_3/fc4_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_3/fc4_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_3/fc4_grad/Reshape:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_3/fc4_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_3/fc4_grad/Reshape_1:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_3/fc4_grad/tuple/control_dependency:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_3/fc4_grad/tuple/control_dependency_1:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_3/MatMul_grad/MatMul:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_3/MatMul_grad/MatMul_1:0' shape=(2000, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_3/MatMul_grad/tuple/control_dependency:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_3/MatMul_grad/tuple/control_dependency_1:0' shape=(2000, 100) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_2/fc3_grad/Shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_2/fc3_grad/Shape_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_2/fc3_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_2/fc3_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_2/fc3_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_2/fc3_grad/Reshape:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_2/fc3_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_2/fc3_grad/Reshape_1:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_2/fc3_grad/tuple/control_dependency:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_2/fc3_grad/tuple/control_dependency_1:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_2/MatMul_grad/MatMul:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_2/MatMul_grad/MatMul_1:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_2/MatMul_grad/tuple/control_dependency:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_2/MatMul_grad/tuple/control_dependency_1:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_1/fc2_grad/Shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_1/fc2_grad/Shape_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_1/fc2_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_1/fc2_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc_1/fc2_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_1/fc2_grad/Reshape:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_1/fc2_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_1/fc2_grad/Reshape_1:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_1/fc2_grad/tuple/control_dependency:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_1/fc2_grad/tuple/control_dependency_1:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_1/MatMul_grad/MatMul:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_1/MatMul_grad/MatMul_1:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_1/MatMul_grad/tuple/control_dependency:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc_1/MatMul_grad/tuple/control_dependency_1:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_activation_grad/ReluGrad:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_grad/Shape:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_grad/Shape_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_grad/Reshape:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_grad/Reshape_1:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_grad/tuple/control_dependency:0' shape=(?, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/fc1_grad/tuple/control_dependency_1:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/MatMul_grad/MatMul:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/MatMul_grad/MatMul_1:0' shape=(128, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/MatMul_grad/tuple/control_dependency:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'gradients/fc/MatMul_grad/tuple/control_dependency_1:0' shape=(128, 2000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/Reshape_1_grad/Shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/Reshape_1_grad/Reshape:0' shape=(?, 1, 1, 128) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_activation_grad/ReluGrad:0' shape=(?, 1, 1, 128) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_max_grad/MaxPoolGrad:0' shape=(?, 2, 2, 128) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_grad/Shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_grad/Shape_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_grad/Reshape:0' shape=(?, 2, 2, 128) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_grad/Reshape_1:0' shape=(128,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_grad/tuple/control_dependency:0' shape=(?, 2, 2, 128) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/conv4_grad/tuple/control_dependency_1:0' shape=(128,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_3/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_3/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/Conv2D_grad/Conv2DBackpropFilter:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/Conv2D_grad/tuple/control_dependency:0' shape=(?, 2, 2, 64) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_3/Conv2D_grad/tuple/control_dependency_1:0' shape=(2, 2, 64, 128) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_activation_grad/ReluGrad:0' shape=(?, 2, 2, 64) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_max_grad/MaxPoolGrad:0' shape=(?, 3, 3, 64) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_grad/Shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_grad/Shape_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_grad/Reshape:0' shape=(?, 3, 3, 64) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_grad/Reshape_1:0' shape=(64,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_grad/tuple/control_dependency:0' shape=(?, 3, 3, 64) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/conv3_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_2/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_2/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/Conv2D_grad/Conv2DBackpropFilter:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/Conv2D_grad/tuple/control_dependency:0' shape=(?, 3, 3, 32) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_2/Conv2D_grad/tuple/control_dependency_1:0' shape=(2, 2, 32, 64) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_activation_grad/ReluGrad:0' shape=(?, 3, 3, 32) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_max_grad/MaxPoolGrad:0' shape=(?, 5, 5, 32) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_grad/Shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_grad/Shape_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_grad/Reshape:0' shape=(?, 5, 5, 32) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_grad/Reshape_1:0' shape=(32,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_grad/tuple/control_dependency:0' shape=(?, 5, 5, 32) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/conv2_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_1/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv_1/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/Conv2D_grad/tuple/control_dependency:0' shape=(?, 5, 5, 16) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv_1/Conv2D_grad/tuple/control_dependency_1:0' shape=(2, 2, 16, 32) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_activation_grad/ReluGrad:0' shape=(?, 5, 5, 16) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_max_grad/MaxPoolGrad:0' shape=(?, 10, 10, 16) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_grad/Shape:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_grad/Shape_1:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_grad/Sum:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_grad/Reshape:0' shape=(?, 10, 10, 16) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_grad/Sum_1:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_grad/Reshape_1:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_grad/tuple/control_dependency:0' shape=(?, 10, 10, 16) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/conv1_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'gradients/conv/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/Conv2D_grad/Conv2DBackpropFilter:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/Conv2D_grad/tuple/control_dependency:0' shape=(?, 10, 10, 3) dtype=float32>,\n",
       " <tf.Tensor 'gradients/conv/Conv2D_grad/tuple/control_dependency_1:0' shape=(4, 4, 3, 16) dtype=float32>,\n",
       " <tf.Tensor 'beta1_power/initial_value:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'beta1_power/Assign:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'beta1_power/read:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'beta2_power/initial_value:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'beta2_power/Assign:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'beta2_power/read:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_W/Adam/Initializer/zeros:0' shape=(4, 4, 3, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_W/Adam:0' shape=(4, 4, 3, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_W/Adam/Assign:0' shape=(4, 4, 3, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_W/Adam/read:0' shape=(4, 4, 3, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_W/Adam_1/Initializer/zeros:0' shape=(4, 4, 3, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_W/Adam_1:0' shape=(4, 4, 3, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_W/Adam_1/Assign:0' shape=(4, 4, 3, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_W/Adam_1/read:0' shape=(4, 4, 3, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_b/Adam/Initializer/zeros:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_b/Adam:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_b/Adam/Assign:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_b/Adam/read:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_b/Adam_1/Initializer/zeros:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'conv/conv1_b/Adam_1:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_b/Adam_1/Assign:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv/conv1_b/Adam_1/read:0' shape=(16,) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam/Initializer/zeros:0' shape=(2, 2, 16, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam:0' shape=(2, 2, 16, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam/Assign:0' shape=(2, 2, 16, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam/read:0' shape=(2, 2, 16, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam_1/Initializer/zeros:0' shape=(2, 2, 16, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam_1:0' shape=(2, 2, 16, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam_1/Assign:0' shape=(2, 2, 16, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_W/Adam_1/read:0' shape=(2, 2, 16, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_b/Adam/Initializer/zeros:0' shape=(32,) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_b/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_b/Adam/Assign:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_b/Adam/read:0' shape=(32,) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_b/Adam_1/Initializer/zeros:0' shape=(32,) dtype=float32>,\n",
       " <tf.Tensor 'conv_1/conv2_b/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_b/Adam_1/Assign:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_1/conv2_b/Adam_1/read:0' shape=(32,) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam/Initializer/zeros:0' shape=(2, 2, 32, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam:0' shape=(2, 2, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam/Assign:0' shape=(2, 2, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam/read:0' shape=(2, 2, 32, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam_1/Initializer/zeros:0' shape=(2, 2, 32, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam_1:0' shape=(2, 2, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam_1/Assign:0' shape=(2, 2, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_W/Adam_1/read:0' shape=(2, 2, 32, 64) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_b/Adam/Initializer/zeros:0' shape=(64,) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_b/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_b/Adam/Assign:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_b/Adam/read:0' shape=(64,) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_b/Adam_1/Initializer/zeros:0' shape=(64,) dtype=float32>,\n",
       " <tf.Tensor 'conv_2/conv3_b/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_b/Adam_1/Assign:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_2/conv3_b/Adam_1/read:0' shape=(64,) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam/Initializer/zeros:0' shape=(2, 2, 64, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam:0' shape=(2, 2, 64, 128) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam/Assign:0' shape=(2, 2, 64, 128) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam/read:0' shape=(2, 2, 64, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam_1/Initializer/zeros:0' shape=(2, 2, 64, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam_1:0' shape=(2, 2, 64, 128) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam_1/Assign:0' shape=(2, 2, 64, 128) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_W/Adam_1/read:0' shape=(2, 2, 64, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_b/Adam/Initializer/zeros:0' shape=(128,) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_b/Adam:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_b/Adam/Assign:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_b/Adam/read:0' shape=(128,) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_b/Adam_1/Initializer/zeros:0' shape=(128,) dtype=float32>,\n",
       " <tf.Tensor 'conv_3/conv4_b/Adam_1:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_b/Adam_1/Assign:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Tensor 'conv_3/conv4_b/Adam_1/read:0' shape=(128,) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam/Initializer/zeros:0' shape=(128, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam:0' shape=(128, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam/Assign:0' shape=(128, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam/read:0' shape=(128, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam_1/Initializer/zeros:0' shape=(128, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam_1:0' shape=(128, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam_1/Assign:0' shape=(128, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_W/Adam_1/read:0' shape=(128, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam/Initializer/zeros:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam/Assign:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam/read:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam_1/Initializer/zeros:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam_1:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam_1/Assign:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc/fc1_b/Adam_1/read:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam/Initializer/zeros:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam/Assign:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam/read:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam_1/Initializer/zeros:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam_1:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam_1/Assign:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_W/Adam_1/read:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam/Initializer/zeros:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam/Assign:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam/read:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam_1/Initializer/zeros:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam_1:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam_1/Assign:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_1/fc2_b/Adam_1/read:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam/Initializer/zeros:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam/Assign:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam/read:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam_1/Initializer/zeros:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam_1:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam_1/Assign:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_W/Adam_1/read:0' shape=(2000, 2000) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam/Initializer/zeros:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam/Assign:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam/read:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam_1/Initializer/zeros:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam_1:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam_1/Assign:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_2/fc3_b/Adam_1/read:0' shape=(2000,) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam/Initializer/zeros:0' shape=(2000, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam:0' shape=(2000, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam/Assign:0' shape=(2000, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam/read:0' shape=(2000, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam_1/Initializer/zeros:0' shape=(2000, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam_1:0' shape=(2000, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam_1/Assign:0' shape=(2000, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_W/Adam_1/read:0' shape=(2000, 100) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_b/Adam/Initializer/zeros:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_b/Adam:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_b/Adam/Assign:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_b/Adam/read:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_b/Adam_1/Initializer/zeros:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'fc_3/fc4_b/Adam_1:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_b/Adam_1/Assign:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'fc_3/fc4_b/Adam_1/read:0' shape=(100,) dtype=float32>,\n",
       " <tf.Tensor 'Adam/learning_rate:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/beta1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/beta2:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/epsilon:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/update_conv/conv1_W/ApplyAdam:0' shape=(4, 4, 3, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_conv/conv1_b/ApplyAdam:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_conv_1/conv2_W/ApplyAdam:0' shape=(2, 2, 16, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_conv_1/conv2_b/ApplyAdam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_conv_2/conv3_W/ApplyAdam:0' shape=(2, 2, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_conv_2/conv3_b/ApplyAdam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_conv_3/conv4_W/ApplyAdam:0' shape=(2, 2, 64, 128) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_conv_3/conv4_b/ApplyAdam:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_fc/fc1_W/ApplyAdam:0' shape=(128, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_fc/fc1_b/ApplyAdam:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_fc_1/fc2_W/ApplyAdam:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_fc_1/fc2_b/ApplyAdam:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_fc_2/fc3_W/ApplyAdam:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_fc_2/fc3_b/ApplyAdam:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_fc_3/fc4_W/ApplyAdam:0' shape=(2000, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/update_fc_3/fc4_b/ApplyAdam:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/Assign:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Adam/Assign_1:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'Equal:0' shape=(?, 100) dtype=bool>,\n",
       " <tf.Tensor 'Cast:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'Const_1:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'Mean_1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'save/Const:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'save/SaveV2/tensor_names:0' shape=(50,) dtype=string>,\n",
       " <tf.Tensor 'save/SaveV2/shape_and_slices:0' shape=(50,) dtype=string>,\n",
       " <tf.Tensor 'save/control_dependency:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'save/RestoreV2/tensor_names:0' shape=(50,) dtype=string>,\n",
       " <tf.Tensor 'save/RestoreV2/shape_and_slices:0' shape=(50,) dtype=string>,\n",
       " <tf.Tensor 'save/RestoreV2:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:1' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:2' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:3' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:4' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:5' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:6' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:7' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:8' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:9' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:10' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:11' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:12' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:13' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:14' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:15' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:16' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:17' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:18' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:19' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:20' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:21' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:22' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:23' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:24' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:25' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:26' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:27' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:28' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:29' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:30' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:31' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:32' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:33' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:34' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:35' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:36' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:37' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:38' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:39' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:40' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:41' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:42' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:43' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:44' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:45' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:46' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:47' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:48' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/RestoreV2:49' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'save/Assign:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_1:0' shape=() dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_2:0' shape=(4, 4, 3, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_3:0' shape=(4, 4, 3, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_4:0' shape=(4, 4, 3, 16) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_5:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_6:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_7:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_8:0' shape=(2, 2, 16, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_9:0' shape=(2, 2, 16, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_10:0' shape=(2, 2, 16, 32) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_11:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_12:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_13:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_14:0' shape=(2, 2, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_15:0' shape=(2, 2, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_16:0' shape=(2, 2, 32, 64) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_17:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_18:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_19:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_20:0' shape=(2, 2, 64, 128) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_21:0' shape=(2, 2, 64, 128) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_22:0' shape=(2, 2, 64, 128) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_23:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_24:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_25:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_26:0' shape=(128, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_27:0' shape=(128, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_28:0' shape=(128, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_29:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_30:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_31:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_32:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_33:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_34:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_35:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_36:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_37:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_38:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_39:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_40:0' shape=(2000, 2000) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_41:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_42:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_43:0' shape=(2000,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_44:0' shape=(2000, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_45:0' shape=(2000, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_46:0' shape=(2000, 100) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_47:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_48:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Tensor 'save/Assign_49:0' shape=(100,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tensors(graph=tf.get_default_graph()):\n",
    "    return [t for op in graph.get_operations() for t in op.values()]\n",
    "get_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, img_type, img_keys = load_data(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../original_images/SD/15970/0/labels/mask_patch_1.png']\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "INFO:tensorflow:Restoring parameters from SD/50k_left_mask.ckpt\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]]\n",
      "[[0.38653535 0.4057966  0.36508724 0.39345306 0.37602678 0.39907455\n",
      "  0.38074392 0.3888056  0.34278107 0.3691759  0.35886088 0.35111886\n",
      "  0.4131743  0.38736975 0.3912501  0.37365112 0.39929292 0.38387197\n",
      "  0.33868736 0.36247176 0.36073625 0.41177985 0.40874842 0.38679218\n",
      "  0.4088831  0.41795057 0.3343268  0.39654467 0.35719928 0.38529855\n",
      "  0.35577607 0.4045641  0.41749442 0.39907858 0.40314427 0.37935904\n",
      "  0.35090786 0.37142724 0.34904832 0.3900527  0.4318654  0.4033997\n",
      "  1.         0.38182607 0.         0.42562225 0.34413567 0.41889477\n",
      "  0.38673854 0.41721117 0.38707075 0.40474916 0.36856622 0.39553115\n",
      "  0.43463498 0.4084795  0.37068793 0.42399535 0.38384712 0.36210397\n",
      "  0.3753633  0.35133103 0.41465062 0.3574061  0.37526354 0.41479462\n",
      "  0.35795864 0.40553817 0.35751435 0.39137512 0.38779032 0.4058443\n",
      "  0.36862084 0.40873265 0.33259994 0.38321725 0.38718948 0.3570338\n",
      "  0.3807881  0.344656   0.43093675 0.3672748  0.39916372 0.4114449\n",
      "  0.39383334 0.41138408 0.40047553 0.4003611  0.40294588 0.42244774\n",
      "  0.36853275 0.36859006 0.39260483 0.38874218 0.38153848 0.39226928\n",
      "  0.37589166 0.3949948  0.40105647 0.4180142 ]]\n"
     ]
    }
   ],
   "source": [
    "train_orig = train_data[0, 0:1]\n",
    "train_pred = train_data[1, 0:1]\n",
    "labels = train_labels[0:1, 3]\n",
    "print(labels)\n",
    "img_type_lbl = img_type[0:1]\n",
    "img_key = img_keys[0:1]\n",
    "dims = (1, num_classes, num_channels)\n",
    "train, labels, img_type_lbl, img_key = get_batch_images(train_orig, train_pred, labels, img_type_lbl, img_key, dims, True)\n",
    "# train[0:1]\n",
    "# img_x = cv2.imread(\"../../original_images/SD/15970/0/img/predicted_mask.png\")\n",
    "\n",
    "# img_x = np.expand_dims(img_x[:,:,0].flatten(), axis=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "output_cl1 = restore_see_layer(orig=np.expand_dims(train[0][0], axis=0), model_name=model50_left_mask,var_name='softmax_output')\n",
    "last_activs = restore_see_layer(orig=np.expand_dims(train[0][0], axis=0), model_name=model50_left_mask,var_name='fc_3/fc4')\n",
    "\n",
    "norm_labels = normalized(labels)\n",
    "norm_last_activs = normalized(last_activs)\n",
    "print(norm_labels)\n",
    "print(norm_last_activs)\n",
    "\n",
    "\n",
    "# see_output_grey(np.reshape(labels, [1, 10,10]))\n",
    "# see_output_grey(np.reshape(last_activs, [1, 10,10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
